diff --git a/__pycache__/patch_gen.cpython-38.pyc b/__pycache__/patch_gen.cpython-38.pyc
index 09f4bfb..83a1839 100644
Binary files a/__pycache__/patch_gen.cpython-38.pyc and b/__pycache__/patch_gen.cpython-38.pyc differ
diff --git a/__pycache__/patch_gen2.cpython-38.pyc b/__pycache__/patch_gen2.cpython-38.pyc
index 5c82b28..c2bb093 100644
Binary files a/__pycache__/patch_gen2.cpython-38.pyc and b/__pycache__/patch_gen2.cpython-38.pyc differ
diff --git a/__pycache__/patch_gen3.cpython-38.pyc b/__pycache__/patch_gen3.cpython-38.pyc
index 7513c2a..9695be1 100644
Binary files a/__pycache__/patch_gen3.cpython-38.pyc and b/__pycache__/patch_gen3.cpython-38.pyc differ
diff --git a/src/samples/Common/helper_cuda_hipified.h b/src/samples/Common/helper_cuda_hipified.h
index bc64004..e47b6f3 100755
--- a/src/samples/Common/helper_cuda_hipified.h
+++ b/src/samples/Common/helper_cuda_hipified.h
@@ -33,7 +33,6 @@
 
 #pragma once
 #include <hip/hip_runtime.h>
-#include <hip/hip_runtime_api.h>
 #include <stdint.h>
 #include <stdio.h>
 #include <stdlib.h>
@@ -63,8 +62,7 @@ static const char *_cudaGetErrorEnum(hipError_t error) {
 static const char *_cudaGetErrorEnum1(hipError_t error) {
   static char unknown[] = "<unknown>";
   const char *ret = NULL;
-  //hipGetErrorName(error, &ret);
-  hipGetErrorName(error);
+  hipGetErrorName(error, &ret);
   return ret ? ret : unknown;
 }
 #endif
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/Makefile b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/Makefile
index 46d27ce..e244dab 100755
--- a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/Makefile
+++ b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/Makefile
@@ -320,7 +320,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/NsightEclipse.xml b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/NsightEclipse.xml
index 9c1040e..744caa1 100755
--- a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/NsightEclipse.xml
@@ -57,6 +57,20 @@
     <scope>1:CUDA Systems Integration</scope>
     <scope>1:Unified Memory</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/README.md b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/README.md
index 37dbe8d..417cf3a 100755
--- a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/README.md
+++ b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/README.md
@@ -10,6 +10,8 @@ CUDA Systems Integration, OpenMP, CUBLAS, Multithreading, Unified Memory, CUDA S
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux, Windows
@@ -28,7 +30,7 @@ cudaStreamDestroy, cudaFree, cudaMallocManaged, cudaStreamAttachMemAsync, cudaSe
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu
index 2bf0ac9..2f3588a 100755
--- a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu
+++ b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu
@@ -46,7 +46,10 @@
 #include <cublas_v2.h>
 
 // utilities
-#include <helper_cuda.h>
+#include "helper_cuda_hipified.h"
+#include "hip/hip_runtime.h"
+#include "hip/hip_runtime_api.h"
+#include "HIPCHECK.h"
 
 #if defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64)
 // SRAND48 and DRAND48 don't exist on windows, but these are the equivalent
@@ -69,28 +72,28 @@ struct Task {
   Task(unsigned int s) : size(s), id(0), data(NULL), result(NULL) {
     // allocate unified memory -- the operation performed in this example will
     // be a DGEMV
-    checkCudaErrors(cudaMallocManaged(&data, sizeof(T) * size * size));
-    checkCudaErrors(cudaMallocManaged(&result, sizeof(T) * size));
-    checkCudaErrors(cudaMallocManaged(&vector, sizeof(T) * size));
-    checkCudaErrors(cudaDeviceSynchronize());
+    HIPCHECK(cudaMallocManaged(&data, sizeof(T) * size * size));
+    HIPCHECK(cudaMallocManaged(&result, sizeof(T) * size));
+    HIPCHECK(cudaMallocManaged(&vector, sizeof(T) * size));
+    HIPCHECK(cudaDeviceSynchronize());
   }
 
   ~Task() {
     // ensure all memory is deallocated
-    checkCudaErrors(cudaDeviceSynchronize());
-    checkCudaErrors(cudaFree(data));
-    checkCudaErrors(cudaFree(result));
-    checkCudaErrors(cudaFree(vector));
+    HIPCHECK(cudaDeviceSynchronize());
+    HIPCHECK(cudaFree(data));
+    HIPCHECK(cudaFree(result));
+    HIPCHECK(cudaFree(vector));
   }
 
   void allocate(const unsigned int s, const unsigned int unique_id) {
     // allocate unified memory outside of constructor
     id = unique_id;
     size = s;
-    checkCudaErrors(cudaMallocManaged(&data, sizeof(T) * size * size));
-    checkCudaErrors(cudaMallocManaged(&result, sizeof(T) * size));
-    checkCudaErrors(cudaMallocManaged(&vector, sizeof(T) * size));
-    checkCudaErrors(cudaDeviceSynchronize());
+    HIPCHECK(cudaMallocManaged(&data, sizeof(T) * size * size));
+    HIPCHECK(cudaMallocManaged(&result, sizeof(T) * size));
+    HIPCHECK(cudaMallocManaged(&vector, sizeof(T) * size));
+    HIPCHECK(cudaDeviceSynchronize());
 
     // populate data with random elements
     for (unsigned int i = 0; i < size * size; i++) {
@@ -147,14 +150,14 @@ void *execute(void *inpArgs) {
 
       // attach managed memory to a (dummy) stream to allow host access while
       // the device is running
-      checkCudaErrors(
+      HIPCHECK(
           cudaStreamAttachMemAsync(stream[0], t.data, 0, cudaMemAttachHost));
-      checkCudaErrors(
+      HIPCHECK(
           cudaStreamAttachMemAsync(stream[0], t.vector, 0, cudaMemAttachHost));
-      checkCudaErrors(
+      HIPCHECK(
           cudaStreamAttachMemAsync(stream[0], t.result, 0, cudaMemAttachHost));
       // necessary to ensure Async cudaStreamAttachMemAsync calls have finished
-      checkCudaErrors(cudaStreamSynchronize(stream[0]));
+      HIPCHECK(cudaStreamSynchronize(stream[0]));
       // call the host operation
       gemv(t.size, t.size, 1.0, t.data, t.vector, 0.0, t.result);
     } else {
@@ -165,15 +168,15 @@ void *execute(void *inpArgs) {
       double zero = 0.0;
 
       // attach managed memory to my stream
-      checkCudaErrors(cublasSetStream(handle[tid + 1], stream[tid + 1]));
-      checkCudaErrors(cudaStreamAttachMemAsync(stream[tid + 1], t.data, 0,
+      HIPCHECK(cublasSetStream(handle[tid + 1], stream[tid + 1]));
+      HIPCHECK(cudaStreamAttachMemAsync(stream[tid + 1], t.data, 0,
                                                cudaMemAttachSingle));
-      checkCudaErrors(cudaStreamAttachMemAsync(stream[tid + 1], t.vector, 0,
+      HIPCHECK(cudaStreamAttachMemAsync(stream[tid + 1], t.vector, 0,
                                                cudaMemAttachSingle));
-      checkCudaErrors(cudaStreamAttachMemAsync(stream[tid + 1], t.result, 0,
+      HIPCHECK(cudaStreamAttachMemAsync(stream[tid + 1], t.result, 0,
                                                cudaMemAttachSingle));
       // call the device operation
-      checkCudaErrors(cublasDgemv(handle[tid + 1], CUBLAS_OP_N, t.size, t.size,
+      HIPCHECK(cublasDgemv(handle[tid + 1], CUBLAS_OP_N, t.size, t.size,
                                   &one, t.data, t.size, t.vector, 1, &zero,
                                   t.result, 1));
     }
@@ -192,14 +195,14 @@ void execute(Task<T> &t, cublasHandle_t *handle, cudaStream_t *stream,
 
     // attach managed memory to a (dummy) stream to allow host access while the
     // device is running
-    checkCudaErrors(
+    HIPCHECK(
         cudaStreamAttachMemAsync(stream[0], t.data, 0, cudaMemAttachHost));
-    checkCudaErrors(
+    HIPCHECK(
         cudaStreamAttachMemAsync(stream[0], t.vector, 0, cudaMemAttachHost));
-    checkCudaErrors(
+    HIPCHECK(
         cudaStreamAttachMemAsync(stream[0], t.result, 0, cudaMemAttachHost));
     // necessary to ensure Async cudaStreamAttachMemAsync calls have finished
-    checkCudaErrors(cudaStreamSynchronize(stream[0]));
+    HIPCHECK(cudaStreamSynchronize(stream[0]));
     // call the host operation
     gemv(t.size, t.size, 1.0, t.data, t.vector, 0.0, t.result);
   } else {
@@ -210,15 +213,15 @@ void execute(Task<T> &t, cublasHandle_t *handle, cudaStream_t *stream,
     double zero = 0.0;
 
     // attach managed memory to my stream
-    checkCudaErrors(cublasSetStream(handle[tid + 1], stream[tid + 1]));
-    checkCudaErrors(cudaStreamAttachMemAsync(stream[tid + 1], t.data, 0,
+    HIPCHECK(cublasSetStream(handle[tid + 1], stream[tid + 1]));
+    HIPCHECK(cudaStreamAttachMemAsync(stream[tid + 1], t.data, 0,
                                              cudaMemAttachSingle));
-    checkCudaErrors(cudaStreamAttachMemAsync(stream[tid + 1], t.vector, 0,
+    HIPCHECK(cudaStreamAttachMemAsync(stream[tid + 1], t.vector, 0,
                                              cudaMemAttachSingle));
-    checkCudaErrors(cudaStreamAttachMemAsync(stream[tid + 1], t.result, 0,
+    HIPCHECK(cudaStreamAttachMemAsync(stream[tid + 1], t.result, 0,
                                              cudaMemAttachSingle));
     // call the device operation
-    checkCudaErrors(cublasDgemv(handle[tid + 1], CUBLAS_OP_N, t.size, t.size,
+    HIPCHECK(cublasDgemv(handle[tid + 1], CUBLAS_OP_N, t.size, t.size,
                                 &one, t.data, t.size, t.vector, 1, &zero,
                                 t.result, 1));
   }
@@ -240,7 +243,7 @@ int main(int argc, char **argv) {
   // set device
   cudaDeviceProp device_prop;
   int dev_id = findCudaDevice(argc, (const char **)argv);
-  checkCudaErrors(cudaGetDeviceProperties(&device_prop, dev_id));
+  HIPCHECK(cudaGetDeviceProperties(&device_prop, dev_id));
 
   if (!device_prop.managedMemory) {
     // This samples requires being run on a device that supports Unified Memory
@@ -270,8 +273,8 @@ int main(int argc, char **argv) {
   cublasHandle_t *handles = new cublasHandle_t[nthreads + 1];
 
   for (int i = 0; i < nthreads + 1; i++) {
-    checkCudaErrors(cudaStreamCreate(&streams[i]));
-    checkCudaErrors(cublasCreate(&handles[i]));
+    HIPCHECK(cudaStreamCreate(&streams[i]));
+    HIPCHECK(cublasCreate(&handles[i]));
   }
 
   // create list of N tasks
@@ -287,7 +290,7 @@ int main(int argc, char **argv) {
   threadData *InputToThreads = new threadData[nthreads];
 
   for (int i = 0; i < nthreads; i++) {
-    checkCudaErrors(cudaSetDevice(dev_id));
+    HIPCHECK(cudaSetDevice(dev_id));
     InputToThreads[i].tid = i;
     InputToThreads[i].streams = streams;
     InputToThreads[i].handles = handles;
@@ -319,7 +322,7 @@ int main(int argc, char **argv) {
   omp_set_num_threads(nthreads);
 #pragma omp parallel for schedule(dynamic)
   for (int i = 0; i < TaskList.size(); i++) {
-    checkCudaErrors(cudaSetDevice(dev_id));
+    HIPCHECK(cudaSetDevice(dev_id));
     int tid = omp_get_thread_num();
     execute(TaskList[i], handles, streams, tid);
   }
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu.hip b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu.hip
index 84fab07..879287e 100755
--- a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu.hip
+++ b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu.hip
@@ -343,8 +343,3 @@ int main(int argc, char **argv) {
   printf("All Done!\n");
   exit(EXIT_SUCCESS);
 }
-cuBlas handles
-  for (int i = 0; i < nthreads + 1; i++) {
-    hipStreamDestroy(streams[i]);
-    hipblasDestroy(handles[i]);
-  }
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2017.vcxproj b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2017.vcxproj
index 46b116d..9680c77 100755
--- a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/UnifiedMemoryStreams.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2019.vcxproj b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2019.vcxproj
index e5160a1..866e26d 100755
--- a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/UnifiedMemoryStreams.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2022.vcxproj b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2022.vcxproj
index 2a24e16..0747874 100755
--- a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/UnifiedMemoryStreams.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/Makefile b/src/samples/Samples/0_Introduction/asyncAPI/Makefile
index d58be21..71bb479 100755
--- a/src/samples/Samples/0_Introduction/asyncAPI/Makefile
+++ b/src/samples/Samples/0_Introduction/asyncAPI/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/NsightEclipse.xml b/src/samples/Samples/0_Introduction/asyncAPI/NsightEclipse.xml
index 2e6a65a..d823ac8 100755
--- a/src/samples/Samples/0_Introduction/asyncAPI/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/asyncAPI/NsightEclipse.xml
@@ -46,6 +46,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/README.md b/src/samples/Samples/0_Introduction/asyncAPI/README.md
index 742f2ef..7f4f3b4 100755
--- a/src/samples/Samples/0_Introduction/asyncAPI/README.md
+++ b/src/samples/Samples/0_Introduction/asyncAPI/README.md
@@ -10,7 +10,7 @@ Asynchronous Data Transfers, CUDA Streams and Events
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaProfilerStop, cudaMalloc, cudaMemcpyAsync, cudaFree, cudaMallocHost, cudaPro
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI.cu.hip b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI.cu.hip
index 45e60cd..8cbb076 100755
--- a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI.cu.hip
+++ b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -45,7 +44,8 @@
 #include <hip/hip_runtime_api.h>
 
 // includes, project
-#include "helper_cuda_hipified.h"
+//#include <helper_cuda.h>
+#include <helper_cuda_hipified.h>
 #include <helper_functions.h>  // helper utility functions
 
 __global__ void increment_kernel(int *g_data, int inc_value) {
@@ -107,7 +107,7 @@ int main(int argc, char *argv[]) {
   float gpu_time = 0.0f;
 
   // asynchronously issue work to the GPU (all to stream 0)
-  HIPCHECK(hipProfilerStart());
+  //HIPCHECK(rocprofiler_start());
   sdkStartTimer(&timer);
   hipEventRecord(start, 0);
   hipMemcpyAsync(d_a, a, nbytes, hipMemcpyHostToDevice, 0);
@@ -115,7 +115,7 @@ int main(int argc, char *argv[]) {
   hipMemcpyAsync(a, d_a, nbytes, hipMemcpyDeviceToHost, 0);
   hipEventRecord(stop, 0);
   sdkStopTimer(&timer);
-  HIPCHECK(hipProfilerStop());
+  //HIPCHECK(rocprofiler_stop());
 
   // have CPU do some work while waiting for stage 1 to finish
   unsigned long int counter = 0;
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI.out b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI.out
deleted file mode 100755
index dd9b019..0000000
Binary files a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI.out and /dev/null differ
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2017.vcxproj b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2017.vcxproj
index 597dadd..ccea698 100755
--- a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/asyncAPI.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2019.vcxproj b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2019.vcxproj
index 3c0d4d8..5648956 100755
--- a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/asyncAPI.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2022.vcxproj b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2022.vcxproj
index 4dc9f9c..c4b23b8 100755
--- a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/asyncAPI.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/Makefile b/src/samples/Samples/0_Introduction/c++11_cuda/Makefile
index e69b44e..d4c77f6 100755
--- a/src/samples/Samples/0_Introduction/c++11_cuda/Makefile
+++ b/src/samples/Samples/0_Introduction/c++11_cuda/Makefile
@@ -312,7 +312,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/NsightEclipse.xml b/src/samples/Samples/0_Introduction/c++11_cuda/NsightEclipse.xml
index ebceaae..ccb26ce 100755
--- a/src/samples/Samples/0_Introduction/c++11_cuda/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/c++11_cuda/NsightEclipse.xml
@@ -38,6 +38,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>1:C++11 CUDA</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/README.md b/src/samples/Samples/0_Introduction/c++11_cuda/README.md
index c35e0c9..a889fb7 100755
--- a/src/samples/Samples/0_Introduction/c++11_cuda/README.md
+++ b/src/samples/Samples/0_Introduction/c++11_cuda/README.md
@@ -10,7 +10,7 @@ CPP11 CUDA
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMalloc, cudaMemcpy, cudaMemset, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2017.vcxproj b/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2017.vcxproj
index c42c1a9..705e575 100755
--- a/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/c++11_cuda.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2019.vcxproj b/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2019.vcxproj
index 7ee4ae5..e4e93de 100755
--- a/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/c++11_cuda.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2022.vcxproj b/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2022.vcxproj
index 758d21a..8133b61 100755
--- a/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/c++11_cuda.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/clock/Makefile b/src/samples/Samples/0_Introduction/clock/Makefile
index 125eafc..df4722c 100755
--- a/src/samples/Samples/0_Introduction/clock/Makefile
+++ b/src/samples/Samples/0_Introduction/clock/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/clock/NsightEclipse.xml b/src/samples/Samples/0_Introduction/clock/NsightEclipse.xml
index 425c63c..6d8cfb0 100755
--- a/src/samples/Samples/0_Introduction/clock/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/clock/NsightEclipse.xml
@@ -34,6 +34,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/clock/README.md b/src/samples/Samples/0_Introduction/clock/README.md
index 0baff3c..11f9afd 100755
--- a/src/samples/Samples/0_Introduction/clock/README.md
+++ b/src/samples/Samples/0_Introduction/clock/README.md
@@ -10,7 +10,7 @@ Performance Strategies
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMalloc, cudaMemcpy, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/clock/clock.cu.hip b/src/samples/Samples/0_Introduction/clock/clock.cu.hip
index e69de29..d60759e 100755
--- a/src/samples/Samples/0_Introduction/clock/clock.cu.hip
+++ b/src/samples/Samples/0_Introduction/clock/clock.cu.hip
@@ -0,0 +1,156 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * This example shows how to use the clock function to measure the performance
+ * of block of threads of a kernel accurately. Blocks are executed in parallel
+ * and out of order. Since there's no synchronization mechanism between blocks,
+ * we measure the clock once for each block. The clock samples are written to
+ * device memory.
+ */
+
+// System includes
+#include <assert.h>
+#include <stdint.h>
+#include <stdio.h>
+#include "rocprofiler.h"
+#include "HIPCHECK.h"
+
+// CUDA runtime
+#include <hip/hip_runtime.h>
+
+// helper functions and utilities to work with CUDA
+#include "helper_cuda_hipified.h"
+#include "helper_functions.h"
+
+// This kernel computes a standard parallel reduction and evaluates the
+// time it takes to do that for each block. The timing results are stored
+// in device memory.
+__global__ static void timedReduction(const float *input, float *output,
+                                      clock_t *timer) {
+  // __shared__ float shared[2 * blockDim.x];
+  extern __shared__ float shared[];
+
+  const int tid = threadIdx.x;
+  const int bid = blockIdx.x;
+
+  if (tid == 0) timer[bid] = clock();
+
+  // Copy input.
+  shared[tid] = input[tid];
+  shared[tid + blockDim.x] = input[tid + blockDim.x];
+
+  // Perform reduction to find minimum.
+  for (int d = blockDim.x; d > 0; d /= 2) {
+    __syncthreads();
+
+    if (tid < d) {
+      float f0 = shared[tid];
+      float f1 = shared[tid + d];
+
+      if (f1 < f0) {
+        shared[tid] = f1;
+      }
+    }
+  }
+
+  // Write result.
+  if (tid == 0) output[bid] = shared[0];
+
+  __syncthreads();
+
+  if (tid == 0) timer[bid + gridDim.x] = clock();
+}
+
+#define NUM_BLOCKS 64
+#define NUM_THREADS 256
+
+// It's interesting to change the number of blocks and the number of threads to
+// understand how to keep the hardware busy.
+//
+// Here are some numbers I get on my G80:
+//    blocks - clocks
+//    1 - 3096
+//    8 - 3232
+//    16 - 3364
+//    32 - 4615
+//    64 - 9981
+//
+// With less than 16 blocks some of the multiprocessors of the device are idle.
+// With more than 16 you are using all the multiprocessors, but there's only one
+// block per multiprocessor and that doesn't allow you to hide the latency of
+// the memory. With more than 32 the speed scales linearly.
+
+// Start the main CUDA Sample here
+int main(int argc, char **argv) {
+  printf("CUDA Clock sample\n");
+
+  // This will pick the best possible CUDA capable device
+  int dev = findCudaDevice(argc, (const char **)argv);
+
+  float *dinput = NULL;
+  float *doutput = NULL;
+  clock_t *dtimer = NULL;
+
+  clock_t timer[NUM_BLOCKS * 2];
+  float input[NUM_THREADS * 2];
+
+  for (int i = 0; i < NUM_THREADS * 2; i++) {
+    input[i] = (float)i;
+  }
+
+  HIPCHECK(
+      hipMalloc((void **)&dinput, sizeof(float) * NUM_THREADS * 2));
+  HIPCHECK(hipMalloc((void **)&doutput, sizeof(float) * NUM_BLOCKS));
+  HIPCHECK(
+      hipMalloc((void **)&dtimer, sizeof(clock_t) * NUM_BLOCKS * 2));
+
+  HIPCHECK(hipMemcpy(dinput, input, sizeof(float) * NUM_THREADS * 2,
+                             hipMemcpyHostToDevice));
+
+  timedReduction<<<NUM_BLOCKS, NUM_THREADS, sizeof(float) * 2 * NUM_THREADS>>>(
+      dinput, doutput, dtimer);
+
+  HIPCHECK(hipMemcpy(timer, dtimer, sizeof(clock_t) * NUM_BLOCKS * 2,
+                             hipMemcpyDeviceToHost));
+
+  HIPCHECK(hipFree(dinput));
+  HIPCHECK(hipFree(doutput));
+  HIPCHECK(hipFree(dtimer));
+
+  long double avgElapsedClocks = 0;
+
+  for (int i = 0; i < NUM_BLOCKS; i++) {
+    avgElapsedClocks += (long double)(timer[i + NUM_BLOCKS] - timer[i]);
+  }
+
+  avgElapsedClocks = avgElapsedClocks / NUM_BLOCKS;
+  printf("Average clocks/block = %Lf\n", avgElapsedClocks);
+
+  return EXIT_SUCCESS;
+}
diff --git a/src/samples/Samples/0_Introduction/clock/clock_vs2017.vcxproj b/src/samples/Samples/0_Introduction/clock/clock_vs2017.vcxproj
index 616d9a2..2350f36 100755
--- a/src/samples/Samples/0_Introduction/clock/clock_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/clock/clock_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/clock.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/clock/clock_vs2019.vcxproj b/src/samples/Samples/0_Introduction/clock/clock_vs2019.vcxproj
index 513d6d5..6649bec 100755
--- a/src/samples/Samples/0_Introduction/clock/clock_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/clock/clock_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/clock.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/clock/clock_vs2022.vcxproj b/src/samples/Samples/0_Introduction/clock/clock_vs2022.vcxproj
index 97cb354..4cf6b89 100755
--- a/src/samples/Samples/0_Introduction/clock/clock_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/clock/clock_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/clock.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/README.md b/src/samples/Samples/0_Introduction/clock_nvrtc/README.md
index 6490d88..5e1dbf0 100755
--- a/src/samples/Samples/0_Introduction/clock_nvrtc/README.md
+++ b/src/samples/Samples/0_Introduction/clock_nvrtc/README.md
@@ -10,7 +10,7 @@ Performance Strategies, Runtime Compilation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaBlockSize, cudaGridSize
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_kernel.cu.hip b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_kernel.cu.hip
index e69de29..16c37ed 100755
--- a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_kernel.cu.hip
@@ -0,0 +1,75 @@
+
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * This example shows how to use the clock function to measure the performance
+ * of block of threads of a kernel accurately. Blocks are executed in parallel
+ * and out of order. Since there's no synchronization mechanism between blocks,
+ * we measure the clock once for each block. The clock samples are written to
+ * device memory.
+ */
+
+// This kernel computes a standard parallel reduction and evaluates the
+// time it takes to do that for each block. The timing results are stored
+// in device memory.
+//#include <hip/hip_cooperative_groups.h>
+extern "C" __global__ void timedReduction(const float *input, float *output,
+                                          clock_t *timer) {
+  // __shared__ float shared[2 * blockDim.x];
+  extern __shared__ float shared[];
+
+  const int tid = threadIdx.x;
+  const int bid = blockIdx.x;
+
+  if (tid == 0) timer[bid] = clock();
+
+  // Copy input.
+  shared[tid] = input[tid];
+  shared[tid + blockDim.x] = input[tid + blockDim.x];
+
+  // Perform reduction to find minimum.
+  for (int d = blockDim.x; d > 0; d /= 2) {
+    __syncthreads();
+
+    if (tid < d) {
+      float f0 = shared[tid];
+      float f1 = shared[tid + d];
+
+      if (f1 < f0) {
+        shared[tid] = f1;
+      }
+    }
+  }
+
+  // Write result.
+  if (tid == 0) output[bid] = shared[0];
+
+  __syncthreads();
+
+  if (tid == 0) timer[bid + gridDim.x] = clock();
+}
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2017.vcxproj b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2017.vcxproj
index b92f083..ec582a9 100755
--- a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2019.vcxproj b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2019.vcxproj
index 6ae9b39..e5b93b6 100755
--- a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2022.vcxproj b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2022.vcxproj
index 636b98f..825d8e0 100755
--- a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/Makefile b/src/samples/Samples/0_Introduction/concurrentKernels/Makefile
index 2d56dce..e6e4e24 100755
--- a/src/samples/Samples/0_Introduction/concurrentKernels/Makefile
+++ b/src/samples/Samples/0_Introduction/concurrentKernels/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/NsightEclipse.xml b/src/samples/Samples/0_Introduction/concurrentKernels/NsightEclipse.xml
index abaa7fb..edfb7ff 100755
--- a/src/samples/Samples/0_Introduction/concurrentKernels/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/concurrentKernels/NsightEclipse.xml
@@ -44,6 +44,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/README.md b/src/samples/Samples/0_Introduction/concurrentKernels/README.md
index 65aa99d..f83e3bd 100755
--- a/src/samples/Samples/0_Introduction/concurrentKernels/README.md
+++ b/src/samples/Samples/0_Introduction/concurrentKernels/README.md
@@ -10,7 +10,7 @@ Performance Strategies
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaStreamDestroy, cudaMalloc, cudaMemcpyAsync, cudaFree, cudaMallocHost, cudaEv
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.cu.hip b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.cu.hip
index 93677a6..dc425ee 100755
--- a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.cu.hip
+++ b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.cu.hip
@@ -36,9 +36,7 @@
 //
 #include <hip/hip_cooperative_groups.h>
 #include <stdio.h>
-#include "rocprofiler.h"
 #include "HIPCHECK.h"
-
 namespace cg = cooperative_groups;
 #include "helper_cuda_hipified.h"
 #include "helper_functions.h"
@@ -188,7 +186,7 @@ int main(int argc, char **argv) {
   // the commands in this stream get dispatched as soon as all the kernel events
   // have been recorded
   sum<<<1, 32, 0, streams[nstreams - 1]>>>(d_a, nkernels);
-  HIPCHECK(hipMemcpyAsync(
+  checkCudaErrors(hipMemcpyAsync(
       a, d_a, sizeof(clock_t), hipMemcpyDeviceToHost, streams[nstreams - 1]));
 
   // at this point the CPU has dispatched all work for the GPU and can continue
@@ -229,6 +227,3 @@ int main(int argc, char **argv) {
   printf("Test passed\n");
   exit(EXIT_SUCCESS);
 }
-Test failed!\n");
-    exit(EXIT_FAILURE);
-  }
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.out b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.out
index 972eea9..fa63078 100755
Binary files a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.out and b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.out differ
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2017.vcxproj b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2017.vcxproj
index be5db54..59cad7e 100755
--- a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/concurrentKernels.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2019.vcxproj b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2019.vcxproj
index 595d8b6..faee059 100755
--- a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/concurrentKernels.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2022.vcxproj b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2022.vcxproj
index 065c520..abf2d5e 100755
--- a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/concurrentKernels.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/Makefile b/src/samples/Samples/0_Introduction/cppIntegration/Makefile
index 5f98b59..ebe106e 100755
--- a/src/samples/Samples/0_Introduction/cppIntegration/Makefile
+++ b/src/samples/Samples/0_Introduction/cppIntegration/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/NsightEclipse.xml b/src/samples/Samples/0_Introduction/cppIntegration/NsightEclipse.xml
index 1cf6e68..9b5f9b4 100755
--- a/src/samples/Samples/0_Introduction/cppIntegration/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/cppIntegration/NsightEclipse.xml
@@ -28,6 +28,8 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/README.md b/src/samples/Samples/0_Introduction/cppIntegration/README.md
index dfd5045..4ac48bc 100755
--- a/src/samples/Samples/0_Introduction/cppIntegration/README.md
+++ b/src/samples/Samples/0_Introduction/cppIntegration/README.md
@@ -10,7 +10,7 @@ CPP-CUDA Integration
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMalloc, cudaMemcpy, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration.cu.hip b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration.cu.hip
index e69de29..7a95c75 100755
--- a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration.cu.hip
+++ b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration.cu.hip
@@ -0,0 +1,174 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/* 
+ * Example of integrating CUDA functions into an existing
+ * application / framework.
+ * Host part of the device code.
+ * Compiled with Cuda compiler.
+ */
+
+// System includes
+#include <stdlib.h>
+#include <stdio.h>
+//#include "rocprofiler.h"
+#include "HIPCHECK.h"
+#include <string.h>
+#include <math.h>
+#include <assert.h>
+
+// CUDA runtime
+#include <hip/hip_runtime.h>
+
+// helper functions and utilities to work with CUDA
+#include "helper_cuda_hipified.h"
+#include "helper_functions.h"
+
+#ifndef MAX
+#define MAX(a, b) (a > b ? a : b)
+#endif
+
+////////////////////////////////////////////////////////////////////////////////
+// declaration, forward
+
+extern "C" void computeGold(char *reference, char *idata,
+                            const unsigned int len);
+extern "C" void computeGold2(int2 *reference, int2 *idata,
+                             const unsigned int len);
+
+///////////////////////////////////////////////////////////////////////////////
+//! Simple test kernel for device functionality
+//! @param g_odata  memory to process (in and out)
+///////////////////////////////////////////////////////////////////////////////
+__global__ void kernel(int *g_data) {
+  // write data to global memory
+  const unsigned int tid = threadIdx.x;
+  int data = g_data[tid];
+
+  // use integer arithmetic to process all four bytes with one thread
+  // this serializes the execution, but is the simplest solutions to avoid
+  // bank conflicts for this very low number of threads
+  // in general it is more efficient to process each byte by a separate thread,
+  // to avoid bank conflicts the access pattern should be
+  // g_data[4 * wtid + wid], where wtid is the thread id within the half warp
+  // and wid is the warp id
+  // see also the programming guide for a more in depth discussion.
+  g_data[tid] =
+      ((((data << 0) >> 24) - 10) << 24) | ((((data << 8) >> 24) - 10) << 16) |
+      ((((data << 16) >> 24) - 10) << 8) | ((((data << 24) >> 24) - 10) << 0);
+}
+
+///////////////////////////////////////////////////////////////////////////////
+//! Demonstration that int2 data can be used in the cpp code
+//! @param g_odata  memory to process (in and out)
+///////////////////////////////////////////////////////////////////////////////
+__global__ void kernel2(int2 *g_data) {
+  // write data to global memory
+  const unsigned int tid = threadIdx.x;
+  int2 data = g_data[tid];
+
+  // use integer arithmetic to process all four bytes with one thread
+  // this serializes the execution, but is the simplest solutions to avoid
+  // bank conflicts for this very low number of threads
+  // in general it is more efficient to process each byte by a separate thread,
+  // to avoid bank conflicts the access pattern should be
+  // g_data[4 * wtid + wid], where wtid is the thread id within the half warp
+  // and wid is the warp id
+  // see also the programming guide for a more in depth discussion.
+  g_data[tid].x = data.x - data.y;
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Entry point for Cuda functionality on host side
+//! @param argc  command line argument count
+//! @param argv  command line arguments
+//! @param data  data to process on the device
+//! @param len   len of \a data
+////////////////////////////////////////////////////////////////////////////////
+extern "C" bool runTest(const int argc, const char **argv, char *data,
+                        int2 *data_int2, unsigned int len) {
+  // use command-line specified CUDA device, otherwise use device with highest
+  // Gflops/s
+  findCudaDevice(argc, (const char **)argv);
+
+  const unsigned int num_threads = len / 4;
+  assert(0 == (len % 4));
+  const unsigned int mem_size = sizeof(char) * len;
+  const unsigned int mem_size_int2 = sizeof(int2) * len;
+
+  // allocate device memory
+  char *d_data;
+  HIPCHECK(hipMalloc((void **)&d_data, mem_size));
+  // copy host memory to device
+  HIPCHECK(hipMemcpy(d_data, data, mem_size, hipMemcpyHostToDevice));
+  // allocate device memory for int2 version
+  int2 *d_data_int2;
+  HIPCHECK(hipMalloc((void **)&d_data_int2, mem_size_int2));
+  // copy host memory to device
+  HIPCHECK(hipMemcpy(d_data_int2, data_int2, mem_size_int2,
+                             hipMemcpyHostToDevice));
+
+  // setup execution parameters
+  dim3 grid(1, 1, 1);
+  dim3 threads(num_threads, 1, 1);
+  dim3 threads2(len, 1, 1);  // more threads needed fir separate int2 version
+  // execute the kernel
+  kernel<<<grid, threads>>>((int *)d_data);
+  kernel2<<<grid, threads2>>>(d_data_int2);
+
+  // check if kernel execution generated and error
+  getLastCudaError("Kernel execution failed");
+
+  // compute reference solutions
+  char *reference = (char *)malloc(mem_size);
+  computeGold(reference, data, len);
+  int2 *reference2 = (int2 *)malloc(mem_size_int2);
+  computeGold2(reference2, data_int2, len);
+
+  // copy results from device to host
+  HIPCHECK(hipMemcpy(data, d_data, mem_size, hipMemcpyDeviceToHost));
+  HIPCHECK(hipMemcpy(data_int2, d_data_int2, mem_size_int2,
+                             hipMemcpyDeviceToHost));
+
+  // check result
+  bool success = true;
+
+  for (unsigned int i = 0; i < len; i++) {
+    if (reference[i] != data[i] || reference2[i].x != data_int2[i].x ||
+        reference2[i].y != data_int2[i].y) {
+      success = false;
+    }
+  }
+
+  // cleanup memory
+  HIPCHECK(hipFree(d_data));
+  HIPCHECK(hipFree(d_data_int2));
+  free(reference);
+  free(reference2);
+
+  return success;
+}
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2017.vcxproj b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2017.vcxproj
index d79a20a..4070ae9 100755
--- a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/cppIntegration.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2019.vcxproj b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2019.vcxproj
index 86375d4..67d587a 100755
--- a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cppIntegration.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2022.vcxproj b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2022.vcxproj
index ac445af..8ed0d99 100755
--- a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cppIntegration.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/cppOverload/Makefile b/src/samples/Samples/0_Introduction/cppOverload/Makefile
index 468f196..a76aca0 100755
--- a/src/samples/Samples/0_Introduction/cppOverload/Makefile
+++ b/src/samples/Samples/0_Introduction/cppOverload/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/cppOverload/NsightEclipse.xml b/src/samples/Samples/0_Introduction/cppOverload/NsightEclipse.xml
index fd147a8..9ad898b 100755
--- a/src/samples/Samples/0_Introduction/cppOverload/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/cppOverload/NsightEclipse.xml
@@ -39,6 +39,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/cppOverload/README.md b/src/samples/Samples/0_Introduction/cppOverload/README.md
index 287659a..bc583bf 100755
--- a/src/samples/Samples/0_Introduction/cppOverload/README.md
+++ b/src/samples/Samples/0_Introduction/cppOverload/README.md
@@ -10,7 +10,7 @@ C++ Function Overloading, CUDA Streams and Events
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaFuncSetCacheConfig, cudaFree, cudaMallocHost, cudaSetDevice, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/cppOverload/cppOverload.cu.hip b/src/samples/Samples/0_Introduction/cppOverload/cppOverload.cu.hip
index 945c49c..5aa864c 100755
--- a/src/samples/Samples/0_Introduction/cppOverload/cppOverload.cu.hip
+++ b/src/samples/Samples/0_Introduction/cppOverload/cppOverload.cu.hip
@@ -90,12 +90,12 @@ int main(int argc, const char *argv[]) {
   printf("%s starting...\n", sampleName);
 
   int deviceCount;
-  checkCudaErrors(hipGetDeviceCount(&deviceCount));
+  HIPCHECK(hipGetDeviceCount(&deviceCount));
   printf("Device Count: %d\n", deviceCount);
 
   int deviceID = findCudaDevice(argc, argv);
   hipDeviceProp_t prop;
-  checkCudaErrors(hipGetDeviceProperties(&prop, deviceID));
+  HIPCHECK(hipGetDeviceProperties(&prop, deviceID));
   if (prop.major < 2) {
     printf(
         "ERROR: cppOverload requires GPU devices with compute SM 2.0 or "
@@ -105,22 +105,22 @@ int main(int argc, const char *argv[]) {
     exit(EXIT_WAIVED);
   }
 
-  checkCudaErrors(hipSetDevice(deviceID));
+  HIPCHECK(hipSetDevice(deviceID));
 
   // Allocate device memory
-  checkCudaErrors(hipMalloc(&dInput, sizeof(int) * N * 2));
-  checkCudaErrors(hipMalloc(&dOutput, sizeof(int) * N));
+  HIPCHECK(hipMalloc(&dInput, sizeof(int) * N * 2));
+  HIPCHECK(hipMalloc(&dOutput, sizeof(int) * N));
 
   // Allocate host memory
-  checkCudaErrors(hipHostMalloc(&hInput, sizeof(int) * N * 2));
-  checkCudaErrors(hipHostMalloc(&hOutput, sizeof(int) * N));
+  HIPCHECK(hipHostMalloc(&hInput, sizeof(int) * N * 2));
+  HIPCHECK(hipHostMalloc(&hOutput, sizeof(int) * N));
 
   for (int i = 0; i < N * 2; i++) {
     hInput[i] = i;
   }
 
   // Copy data from host to device
-  checkCudaErrors(
+  HIPCHECK(
       hipMemcpy(dInput, hInput, sizeof(int) * N * 2, hipMemcpyHostToDevice));
 
   // Test C++ overloading
@@ -136,11 +136,11 @@ int main(int argc, const char *argv[]) {
   // overload function 1
   func1 = simple_kernel;
   memset(&attr, 0, sizeof(attr));
-  checkCudaErrors(hipFuncSetCacheConfig(*func1, hipFuncCachePreferShared));
-  checkCudaErrors(hipFuncGetAttributes(&attr, *func1));
+  HIPCHECK(hipFuncSetCacheConfig(*func1, hipFuncCachePreferShared));
+  HIPCHECK(hipFuncGetAttributes(&attr, *func1));
   OUTPUT_ATTR(attr);
   (*func1)<<<DIV_UP(N, THREAD_N), THREAD_N>>>(dInput, dOutput, a);
-  checkCudaErrors(
+  HIPCHECK(
       hipMemcpy(hOutput, dOutput, sizeof(int) * N, hipMemcpyDeviceToHost));
   funcResult = check_func1(hInput, hOutput, a);
   printf("simple_kernel(const int *pIn, int *pOut, int a) %s\n\n",
@@ -150,11 +150,11 @@ int main(int argc, const char *argv[]) {
   // overload function 2
   func2 = simple_kernel;
   memset(&attr, 0, sizeof(attr));
-  checkCudaErrors(hipFuncSetCacheConfig(*func2, hipFuncCachePreferShared));
-  checkCudaErrors(hipFuncGetAttributes(&attr, *func2));
+  HIPCHECK(hipFuncSetCacheConfig(*func2, hipFuncCachePreferShared));
+  HIPCHECK(hipFuncGetAttributes(&attr, *func2));
   OUTPUT_ATTR(attr);
   (*func2)<<<DIV_UP(N, THREAD_N), THREAD_N>>>((int2 *)dInput, dOutput, a);
-  checkCudaErrors(
+  HIPCHECK(
       hipMemcpy(hOutput, dOutput, sizeof(int) * N, hipMemcpyDeviceToHost));
   funcResult = check_func2(reinterpret_cast<int2 *>(hInput), hOutput, a);
   printf("simple_kernel(const int2 *pIn, int *pOut, int a) %s\n\n",
@@ -164,11 +164,11 @@ int main(int argc, const char *argv[]) {
   // overload function 3
   func3 = simple_kernel;
   memset(&attr, 0, sizeof(attr));
-  checkCudaErrors(hipFuncSetCacheConfig(*func3, hipFuncCachePreferShared));
-  checkCudaErrors(hipFuncGetAttributes(&attr, *func3));
+  HIPCHECK(hipFuncSetCacheConfig(*func3, hipFuncCachePreferShared));
+  HIPCHECK(hipFuncGetAttributes(&attr, *func3));
   OUTPUT_ATTR(attr);
   (*func3)<<<DIV_UP(N, THREAD_N), THREAD_N>>>(dInput, dInput + N, dOutput, a);
-  checkCudaErrors(
+  HIPCHECK(
       hipMemcpy(hOutput, dOutput, sizeof(int) * N, hipMemcpyDeviceToHost));
   funcResult = check_func3(&hInput[0], &hInput[N], hOutput, a);
   printf(
@@ -177,12 +177,12 @@ int main(int argc, const char *argv[]) {
       funcResult ? "PASSED" : "FAILED");
   testResult &= funcResult;
 
-  checkCudaErrors(hipFree(dInput));
-  checkCudaErrors(hipFree(dOutput));
-  checkCudaErrors(hipHostFree(hOutput));
-  checkCudaErrors(hipHostFree(hInput));
+  HIPCHECK(hipFree(dInput));
+  HIPCHECK(hipFree(dOutput));
+  HIPCHECK(hipHostFree(hOutput));
+  HIPCHECK(hipHostFree(hInput));
 
-  checkCudaErrors(hipDeviceSynchronize());
+  HIPCHECK(hipDeviceSynchronize());
 
   exit(testResult ? EXIT_SUCCESS : EXIT_FAILURE);
 }
diff --git a/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2017.vcxproj b/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2017.vcxproj
index b21dfa4..4adb6ea 100755
--- a/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/cppOverload.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2019.vcxproj b/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2019.vcxproj
index 3498366..040f08c 100755
--- a/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cppOverload.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2022.vcxproj b/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2022.vcxproj
index 0bd7768..a9592ff 100755
--- a/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cppOverload.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/Makefile b/src/samples/Samples/0_Introduction/cudaOpenMP/Makefile
index 4389e76..277357e 100755
--- a/src/samples/Samples/0_Introduction/cudaOpenMP/Makefile
+++ b/src/samples/Samples/0_Introduction/cudaOpenMP/Makefile
@@ -323,7 +323,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/README.md b/src/samples/Samples/0_Introduction/cudaOpenMP/README.md
index ad64ddb..5a57d91 100755
--- a/src/samples/Samples/0_Introduction/cudaOpenMP/README.md
+++ b/src/samples/Samples/0_Introduction/cudaOpenMP/README.md
@@ -10,7 +10,7 @@ CUDA Systems Integration, OpenMP, Multithreading
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMemcpy, cudaGetErrorString, cudaFree, cudaGetLastError, cudaSetDevice, cudaG
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP.cu.hip b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP.cu.hip
index 7f4d166..dd4fdfe 100755
--- a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP.cu.hip
+++ b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP.cu.hip
@@ -1,3 +1,5 @@
+
+#include "HIPCHECK.h"
 #include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
@@ -31,10 +33,10 @@
  * needs a compiler that supports OpenMP 2.0
  */
 
-#include "helper_cuda_hipified.h"
+#include <helper_cuda.h>
 #include <omp.h>
 #include <stdio.h>  // stdio functions are used since C++ streams aren't necessarily thread safe
-#include "HIPCHECK.h"
+
 using namespace std;
 
 // a simple kernel that simply increments each array element by b
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2017.vcxproj b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2017.vcxproj
index da9c627..b6a822e 100755
--- a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/cudaOpenMP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2019.vcxproj b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2019.vcxproj
index 3b9947c..991ca21 100755
--- a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cudaOpenMP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2022.vcxproj b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2022.vcxproj
index a0d1a3e..adf1479 100755
--- a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cudaOpenMP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/README.md b/src/samples/Samples/0_Introduction/fp16ScalarProduct/README.md
index 22b3df9..4aa2b89 100755
--- a/src/samples/Samples/0_Introduction/fp16ScalarProduct/README.md
+++ b/src/samples/Samples/0_Introduction/fp16ScalarProduct/README.md
@@ -30,7 +30,7 @@ cudaMemcpy, cudaFree, cudaMallocHost, cudaFreeHost, cudaMalloc, cudaGetDevicePro
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.cu.hip b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.cu.hip
index cb95a39..893fd7a 100755
--- a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.cu.hip
+++ b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -26,8 +25,11 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
+
+#include <hip/hip_runtime.h>
 #include "hip/hip_fp16.h"
-#include "helper_cuda.h"
+#include "helper_cuda_hipified.h"
+#include "helper_functions.h"
 
 #include <cstdio>
 #include <cstdlib>
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.out b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.out
index 081f578..da0d903 100755
Binary files a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.out and b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.out differ
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2017.vcxproj b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2017.vcxproj
index ac47e1b..c4dbdc7 100755
--- a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2019.vcxproj b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2019.vcxproj
index 740ad4f..0b9a749 100755
--- a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2022.vcxproj b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2022.vcxproj
index 84a4aaf..ee4258a 100755
--- a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/matrixMul/Makefile b/src/samples/Samples/0_Introduction/matrixMul/Makefile
index 75d2752..a4d336b 100755
--- a/src/samples/Samples/0_Introduction/matrixMul/Makefile
+++ b/src/samples/Samples/0_Introduction/matrixMul/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/matrixMul/NsightEclipse.xml b/src/samples/Samples/0_Introduction/matrixMul/NsightEclipse.xml
index 1908af4..3f51796 100755
--- a/src/samples/Samples/0_Introduction/matrixMul/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/matrixMul/NsightEclipse.xml
@@ -43,6 +43,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/matrixMul/README.md b/src/samples/Samples/0_Introduction/matrixMul/README.md
index 5f03e96..b0e121b 100755
--- a/src/samples/Samples/0_Introduction/matrixMul/README.md
+++ b/src/samples/Samples/0_Introduction/matrixMul/README.md
@@ -10,7 +10,7 @@ CUDA Runtime API, Linear Algebra
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaStreamCreateWithFlags, cudaProfilerStop, cudaMalloc, cudaFree, cudaMallocHos
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/matrixMul/matrixMul.cu.hip b/src/samples/Samples/0_Introduction/matrixMul/matrixMul.cu.hip
index 3c0f3f9..50beffb 100755
--- a/src/samples/Samples/0_Introduction/matrixMul/matrixMul.cu.hip
+++ b/src/samples/Samples/0_Introduction/matrixMul/matrixMul.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -51,8 +50,9 @@
 #include <hip/hip_runtime_api.h>
 
 // Helper functions and utilities to work with CUDA
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
+#include <helper_functions.h>
+//#include <helper_cuda.h>
+#include <helper_cuda_hipified.h>
 
 /**
  * Matrix multiplication (CUDA Kernel) on the device: C = A * B
@@ -348,9 +348,9 @@ int main(int argc, char **argv) {
   printf("MatrixA(%d,%d), MatrixB(%d,%d)\n", dimsA.x, dimsA.y,
          dimsB.x, dimsB.y);
 
-  //HIPCHECK(hipProfilerStart());
+//  HIPCHECK(rocprofiler_start());
   int matrix_result = MatrixMultiply(argc, argv, block_size, dimsA, dimsB);
-  //HIPCHECK(hipProfilerStop());
+//  HIPCHECK(rocprofiler_stop());
 
   exit(matrix_result);
 }
diff --git a/src/samples/Samples/0_Introduction/matrixMul/matrixMul.out b/src/samples/Samples/0_Introduction/matrixMul/matrixMul.out
index 7ee5535..e74eb18 100755
Binary files a/src/samples/Samples/0_Introduction/matrixMul/matrixMul.out and b/src/samples/Samples/0_Introduction/matrixMul/matrixMul.out differ
diff --git a/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2017.vcxproj b/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2017.vcxproj
index 635677f..95f6a03 100755
--- a/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/matrixMul.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2019.vcxproj b/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2019.vcxproj
index 297357c..375f668 100755
--- a/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/matrixMul.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2022.vcxproj b/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2022.vcxproj
index 7c5cdf2..e406cc0 100755
--- a/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/matrixMul.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/Makefile b/src/samples/Samples/0_Introduction/matrixMulDrv/Makefile
index ce93fb2..8347698 100755
--- a/src/samples/Samples/0_Introduction/matrixMulDrv/Makefile
+++ b/src/samples/Samples/0_Introduction/matrixMulDrv/Makefile
@@ -285,7 +285,7 @@ FATBIN_FILE := matrixMul_kernel${TARGET_SIZE}.fatbin
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/README.md b/src/samples/Samples/0_Introduction/matrixMulDrv/README.md
index 56e00c0..682fb94 100755
--- a/src/samples/Samples/0_Introduction/matrixMulDrv/README.md
+++ b/src/samples/Samples/0_Introduction/matrixMulDrv/README.md
@@ -10,7 +10,7 @@ CUDA Driver API, Matrix Multiply
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cuMemcpyDtoH, cuLaunchKernel, cuMemcpyHtoD, cuDeviceGetName, cuDeviceTotalMem, c
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2017.vcxproj b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2017.vcxproj
index a265af2..7399876 100755
--- a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/matrixMulDrv.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2019.vcxproj b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2019.vcxproj
index f7c73f7..0805c97 100755
--- a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/matrixMulDrv.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2022.vcxproj b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2022.vcxproj
index 75f9ff2..a82bb69 100755
--- a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/matrixMulDrv.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/Makefile b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/Makefile
index cd0ca3d..f2b7957 100755
--- a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/Makefile
+++ b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/Makefile
@@ -287,8 +287,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/README.md b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/README.md
index 252316a..657811d 100755
--- a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/README.md
+++ b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/README.md
@@ -10,7 +10,7 @@ CUDA Driver API, CUDA Dynamically Linked Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cuMemcpyDtoH, cuDeviceGetName, cuParamSeti, cuModuleLoadDataEx, cuModuleGetFunct
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/cuda_drvapi_dynlink_cuda_hipified.h b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/cuda_drvapi_dynlink_cuda_hipified.h
index eb0ca3e..17c1433 100755
--- a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/cuda_drvapi_dynlink_cuda_hipified.h
+++ b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/cuda_drvapi_dynlink_cuda_hipified.h
@@ -328,7 +328,7 @@ typedef enum hipJitOption
      * Max number of registers that a thread may use.\n
      * Option type: unsigned int
      */
-    HIPRTC_JIT_MAX_REGISTERS = 0,
+    hipJitOptionMaxRegisters = 0,
 
     /**
      * IN: Specifies minimum number of threads per block to target compilation
@@ -341,22 +341,22 @@ typedef enum hipJitOption
      * shared memory utilization.\n
      * Option type: unsigned int
      */
-    HIPRTC_JIT_THREADS_PER_BLOCK,
+    hipJitOptionThreadsPerBlock,
 
     /**
      * Returns a float value in the option of the wall clock time, in
      * milliseconds, spent creating the cubin\n
      * Option type: float
      */
-    HIPRTC_JIT_WALL_TIME,
+    hipJitOptionWallTime,
 
     /**
      * Pointer to a buffer in which to print any log messsages from PTXAS
      * that are informational in nature (the buffer size is specified via
-     * option ::HIPRTC_JIT_INFO_LOG_BUFFER_SIZE_BYTES) \n
+     * option ::hipJitOptionInfoLogBufferSizeBytes) \n
      * Option type: char*
      */
-    HIPRTC_JIT_INFO_LOG_BUFFER,
+    hipJitOptionInfoLogBuffer,
 
     /**
      * IN: Log buffer size in bytes.  Log messages will be capped at this size
@@ -364,15 +364,15 @@ typedef enum hipJitOption
      * OUT: Amount of log buffer filled with messages\n
      * Option type: unsigned int
      */
-    HIPRTC_JIT_INFO_LOG_BUFFER_SIZE_BYTES,
+    hipJitOptionInfoLogBufferSizeBytes,
 
     /**
      * Pointer to a buffer in which to print any log messages from PTXAS that
      * reflect errors (the buffer size is specified via option
-     * ::HIPRTC_JIT_ERROR_LOG_BUFFER_SIZE_BYTES)\n
+     * ::hipJitOptionErrorLogBufferSizeBytes)\n
      * Option type: char*
      */
-    HIPRTC_JIT_ERROR_LOG_BUFFER,
+    hipJitOptionErrorLogBuffer,
 
     /**
      * IN: Log buffer size in bytes.  Log messages will be capped at this size
@@ -380,34 +380,34 @@ typedef enum hipJitOption
      * OUT: Amount of log buffer filled with messages\n
      * Option type: unsigned int
      */
-    HIPRTC_JIT_ERROR_LOG_BUFFER_SIZE_BYTES,
+    hipJitOptionErrorLogBufferSizeBytes,
 
     /**
      * Level of optimizations to apply to generated code (0 - 4), with 4
      * being the default and highest level of optimizations.\n
      * Option type: unsigned int
      */
-    HIPRTC_JIT_OPTIMIZATION_LEVEL,
+    hipJitOptionOptimizationLevel,
 
     /**
      * No option value required. Determines the target based on the current
      * attached context (default)\n
      * Option type: No option value needed
      */
-    HIPRTC_JIT_TARGET_FROM_HIPCONTEXT,
+    hipJitOptionTargetFromContext,
 
     /**
      * Target is chosen based on supplied ::CUjit_target_enum.\n
      * Option type: unsigned int for enumerated type ::CUjit_target_enum
      */
-    HIPRTC_JIT_TARGET,
+    hipJitOptionTarget,
 
     /**
      * Specifies choice of fallback strategy if matching cubin is not found.
      * Choice is based on supplied ::CUjit_fallback_enum.\n
      * Option type: unsigned int for enumerated type ::CUjit_fallback_enum
      */
-    HIPRTC_JIT_FALLBACK_STRATEGY
+    hipJitOptionFallbackStrategy
 
 } hipJitOption;
 
@@ -479,7 +479,7 @@ typedef enum CUarray_cubemap_face_enum
  */
 typedef enum hipLimit_t
 {
-    hipLimitStackSize        = 0x00, /**< GPU thread stack size */
+    CU_LIMIT_STACK_SIZE        = 0x00, /**< GPU thread stack size */
     hipLimitPrintfFifoSize  = 0x01, /**< GPU printf FIFO size */
     hipLimitMallocHeapSize  = 0x02  /**< GPU malloc heap size */
 } hipLimit_t;
@@ -1913,7 +1913,7 @@ extern tcuGraphicsResourceSetMapFlags        *cuGraphicsResourceSetMapFlags;
 extern tcuGraphicsMapResources               *hipGraphicsMapResources;
 extern tcuGraphicsUnmapResources             *hipGraphicsUnmapResources;
 extern tcuGetExportTable                     *cuGetExportTable;
-extern tcuCtxSetLimit                        *hipDeviceSetLimit;
+extern tcuCtxSetLimit                        *cuCtxSetLimit;
 extern tcuCtxGetLimit                        *hipDeviceGetLimit;
 
 // These functions could be using the CUDA 3.2 interface (_v2)
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_hipified.cpp b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_hipified.cpp
index 7ba4940..b37c858 100755
--- a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_hipified.cpp
+++ b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_hipified.cpp
@@ -173,17 +173,17 @@ hipError_t initCUDA(int argc, char **argv, hipFunction_t *pMatrixMul, int *block
         void **jitOptVals = new void *[jitNumOptions];
 
         // set up size of compilation log buffer
-        jitOptions[0] = HIPRTC_JIT_INFO_LOG_BUFFER_SIZE_BYTES;
+        jitOptions[0] = hipJitOptionInfoLogBufferSizeBytes;
         int jitLogBufferSize = 1024;
         jitOptVals[0] = (void *)(size_t)jitLogBufferSize;
 
         // set up pointer to the compilation log buffer
-        jitOptions[1] = HIPRTC_JIT_INFO_LOG_BUFFER;
+        jitOptions[1] = hipJitOptionInfoLogBuffer;
         char *jitLogBuffer = new char[jitLogBufferSize];
         jitOptVals[1] = jitLogBuffer;
 
         // set up pointer to set the Maximum # of registers for a particular kernel
-        jitOptions[2] = HIPRTC_JIT_MAX_REGISTERS;
+        jitOptions[2] = hipJitOptionMaxRegisters;
         int jitRegCount = 32;
         jitOptVals[2] = (void *)(size_t)jitRegCount;
 
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2017.vcxproj b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2017.vcxproj
index 9ce6371..8b146bd 100755
--- a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/matrixMulDynlinkJIT.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -116,6 +116,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2019.vcxproj b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2019.vcxproj
index cb9dfff..3fc6842 100755
--- a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/matrixMulDynlinkJIT.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -112,6 +112,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2022.vcxproj b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2022.vcxproj
index 966a381..732e0b2 100755
--- a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/matrixMulDynlinkJIT.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -112,6 +112,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/README.md b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/README.md
index 2c2d06d..224c3ee 100755
--- a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/README.md
+++ b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/README.md
@@ -10,7 +10,7 @@ CUDA Runtime API, Linear Algebra, Runtime Compilation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cuMemcpyDtoH, cuLaunchKernel, cuMemcpyHtoD, cuCtxSynchronize, cuMemAlloc, cuMemF
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_kernel.cu.hip b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_kernel.cu.hip
index e69de29..b365b74 100755
--- a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_kernel.cu.hip
@@ -0,0 +1,132 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/**
+ * Matrix multiplication: C = A * B.
+ * Host code.
+ *
+ * This sample implements matrix multiplication as described in Chapter 3
+ * of the programming guide.
+ * It has been written for clarity of exposition to illustrate various CUDA
+ * programming principles, not with the goal of providing the most
+ * performant generic kernel for matrix multiplication.
+ *
+ * See also:
+ * V. Volkov and J. Demmel, "Benchmarking GPUs to tune dense linear algebra,"
+ * in Proc. 2008 ACM/IEEE Conf. on Supercomputing (SC '08),
+ * Piscataway, NJ: IEEE Press, 2008, pp. Art. 31:1-11.
+ */
+
+/**
+ * Matrix multiplication (CUDA Kernel) on the device: C = A * B
+ * wA is A's width and wB is B's width
+ */
+
+#include <hip/hip_cooperative_groups.h>
+
+template <int BLOCK_SIZE>
+__device__ void matrixMulCUDA(float *C, float *A, float *B, int wA, int wB) {
+  // Handle to thread block group
+  cooperative_groups::thread_block cta =
+      cooperative_groups::this_thread_block();
+  // Block index
+  int bx = blockIdx.x;
+  int by = blockIdx.y;
+
+  // Thread index
+  int tx = threadIdx.x;
+  int ty = threadIdx.y;
+
+  // Index of the first sub-matrix of A processed by the block
+  int aBegin = wA * BLOCK_SIZE * by;
+
+  // Index of the last sub-matrix of A processed by the block
+  int aEnd = aBegin + wA - 1;
+
+  // Step size used to iterate through the sub-matrices of A
+  int aStep = BLOCK_SIZE;
+
+  // Index of the first sub-matrix of B processed by the block
+  int bBegin = BLOCK_SIZE * bx;
+
+  // Step size used to iterate through the sub-matrices of B
+  int bStep = BLOCK_SIZE * wB;
+
+  // Csub is used to store the element of the block sub-matrix
+  // that is computed by the thread
+  float Csub = 0;
+
+  // Loop over all the sub-matrices of A and B
+  // required to compute the block sub-matrix
+  for (int a = aBegin, b = bBegin; a <= aEnd; a += aStep, b += bStep) {
+    // Declaration of the shared memory array As used to
+    // store the sub-matrix of A
+    __shared__ float As[BLOCK_SIZE][BLOCK_SIZE];
+
+    // Declaration of the shared memory array Bs used to
+    // store the sub-matrix of B
+    __shared__ float Bs[BLOCK_SIZE][BLOCK_SIZE];
+
+    // Load the matrices from device memory
+    // to shared memory; each thread loads
+    // one element of each matrix
+    As[ty][tx] = A[a + wA * ty + tx];
+    Bs[ty][tx] = B[b + wB * ty + tx];
+
+    // Synchronize to make sure the matrices are loaded
+    cooperative_groups::sync(cta);
+
+// Multiply the two matrices together;
+// each thread computes one element
+// of the block sub-matrix
+#pragma unroll
+    for (int k = 0; k < BLOCK_SIZE; ++k) {
+      Csub += As[ty][k] * Bs[k][tx];
+    }
+
+    // Synchronize to make sure that the preceding
+    // computation is done before loading two new
+    // sub-matrices of A and B in the next iteration
+    cooperative_groups::sync(cta);
+  }
+
+  // Write the block sub-matrix to device memory;
+  // each thread writes one element
+  int c = wB * BLOCK_SIZE * by + BLOCK_SIZE * bx;
+  C[c + wB * ty + tx] = Csub;
+}
+
+extern "C" __global__ void matrixMulCUDA_block16(float *C, float *A, float *B,
+                                                 int wA, int wB) {
+  matrixMulCUDA<16>(C, A, B, wA, wB);
+}
+
+extern "C" __global__ void matrixMulCUDA_block32(float *C, float *A, float *B,
+                                                 int wA, int wB) {
+  matrixMulCUDA<32>(C, A, B, wA, wB);
+}
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2017.vcxproj b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2017.vcxproj
index eb54232..7833bb4 100755
--- a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -113,6 +113,6 @@ xcopy /y /e /s "$(CudaToolkitDir)include\cooperative_groups" .\cooperative_group
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2019.vcxproj b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2019.vcxproj
index 9c04bc2..d0b5836 100755
--- a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -109,6 +109,6 @@ xcopy /y /e /s "$(CudaToolkitDir)include\cooperative_groups" .\cooperative_group
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2022.vcxproj b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2022.vcxproj
index 334593a..6fa7922 100755
--- a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -109,6 +109,6 @@ xcopy /y /e /s "$(CudaToolkitDir)include\cooperative_groups" .\cooperative_group
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/mergeSort/Makefile b/src/samples/Samples/0_Introduction/mergeSort/Makefile
index 6ec5503..815268b 100755
--- a/src/samples/Samples/0_Introduction/mergeSort/Makefile
+++ b/src/samples/Samples/0_Introduction/mergeSort/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/mergeSort/NsightEclipse.xml b/src/samples/Samples/0_Introduction/mergeSort/NsightEclipse.xml
index 1848422..55cab90 100755
--- a/src/samples/Samples/0_Introduction/mergeSort/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/mergeSort/NsightEclipse.xml
@@ -33,6 +33,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>1:Data-Parallel Algorithms</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/mergeSort/README.md b/src/samples/Samples/0_Introduction/mergeSort/README.md
index 771f87d..d085389 100755
--- a/src/samples/Samples/0_Introduction/mergeSort/README.md
+++ b/src/samples/Samples/0_Introduction/mergeSort/README.md
@@ -10,7 +10,7 @@ Data-Parallel Algorithms
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMalloc, cudaDeviceSynchronize, cudaMemcpy, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/mergeSort/bitonic.cu.hip b/src/samples/Samples/0_Introduction/mergeSort/bitonic.cu.hip
index e69de29..f225214 100755
--- a/src/samples/Samples/0_Introduction/mergeSort/bitonic.cu.hip
+++ b/src/samples/Samples/0_Introduction/mergeSort/bitonic.cu.hip
@@ -0,0 +1,280 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+
+#include <hip/hip_runtime.h>
+#include <hip/hip_cooperative_groups.h>
+
+namespace cg = cooperative_groups;
+#include "helper_cuda_hipified.h"
+#include <assert.h>
+#include "mergeSort_common.h"
+
+inline __device__ void Comparator(uint &keyA, uint &valA, uint &keyB,
+                                  uint &valB, uint arrowDir) {
+  uint t;
+
+  if ((keyA > keyB) == arrowDir) {
+    t = keyA;
+    keyA = keyB;
+    keyB = t;
+    t = valA;
+    valA = valB;
+    valB = t;
+  }
+}
+
+__global__ void bitonicSortSharedKernel(uint *d_DstKey, uint *d_DstVal,
+                                        uint *d_SrcKey, uint *d_SrcVal,
+                                        uint arrayLength, uint sortDir) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  // Shared memory storage for one or more short vectors
+  __shared__ uint s_key[SHARED_SIZE_LIMIT];
+  __shared__ uint s_val[SHARED_SIZE_LIMIT];
+
+  // Offset to the beginning of subbatch and load data
+  d_SrcKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  d_SrcVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  d_DstKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  d_DstVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  s_key[threadIdx.x + 0] = d_SrcKey[0];
+  s_val[threadIdx.x + 0] = d_SrcVal[0];
+  s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
+      d_SrcKey[(SHARED_SIZE_LIMIT / 2)];
+  s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
+      d_SrcVal[(SHARED_SIZE_LIMIT / 2)];
+
+  for (uint size = 2; size < arrayLength; size <<= 1) {
+    // Bitonic merge
+    uint dir = (threadIdx.x & (size / 2)) != 0;
+
+    for (uint stride = size / 2; stride > 0; stride >>= 1) {
+      cg::sync(cta);
+      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
+      Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
+                 s_val[pos + stride], dir);
+    }
+  }
+
+  // ddd == sortDir for the last bitonic merge step
+  {
+    for (uint stride = arrayLength / 2; stride > 0; stride >>= 1) {
+      cg::sync(cta);
+      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
+      Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
+                 s_val[pos + stride], sortDir);
+    }
+  }
+
+  cg::sync(cta);
+  d_DstKey[0] = s_key[threadIdx.x + 0];
+  d_DstVal[0] = s_val[threadIdx.x + 0];
+  d_DstKey[(SHARED_SIZE_LIMIT / 2)] =
+      s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
+  d_DstVal[(SHARED_SIZE_LIMIT / 2)] =
+      s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
+}
+
+// Helper function (also used by odd-even merge sort)
+extern "C" uint factorRadix2(uint *log2L, uint L) {
+  if (!L) {
+    *log2L = 0;
+    return 0;
+  }
+ else {
+    for (*log2L = 0; (L & 1) == 0; L >>= 1, *log2L++) ;
+    return L;
+  }
+}
+
+extern "C" void bitonicSortShared(uint *d_DstKey, uint *d_DstVal,
+                                  uint *d_SrcKey, uint *d_SrcVal,
+                                  uint batchSize, uint arrayLength,
+                                  uint sortDir) {
+  // Nothing to sort
+  if (arrayLength < 2) {
+    return;
+  }
+
+  // Only power-of-two array lengths are supported by this implementation
+  uint log2L;
+  uint factorizationRemainder = factorRadix2(&log2L, arrayLength);
+  assert(factorizationRemainder == 1);
+
+  uint blockCount = batchSize * arrayLength / SHARED_SIZE_LIMIT;
+  uint threadCount = SHARED_SIZE_LIMIT / 2;
+
+  assert(arrayLength <= SHARED_SIZE_LIMIT);
+  assert((batchSize * arrayLength) % SHARED_SIZE_LIMIT == 0);
+
+  bitonicSortSharedKernel<<<blockCount, threadCount>>>(
+      d_DstKey, d_DstVal, d_SrcKey, d_SrcVal, arrayLength, sortDir);
+  getLastCudaError("bitonicSortSharedKernel<<<>>> failed!\n");
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Merge step 3: merge elementary intervals
+////////////////////////////////////////////////////////////////////////////////
+static inline __host__ __device__ uint iDivUp(uint a, uint b) {
+  return ((a % b) == 0) ? (a / b) : (a / b + 1);
+}
+
+static inline __host__ __device__ uint getSampleCount(uint dividend) {
+  return iDivUp(dividend, SAMPLE_STRIDE);
+}
+
+template <uint sortDir>
+static inline __device__ void ComparatorExtended(uint &keyA, uint &valA,
+                                                 uint &flagA, uint &keyB,
+                                                 uint &valB, uint &flagB,
+                                                 uint arrowDir) {
+  uint t;
+
+  if ((!(flagA || flagB) && ((keyA > keyB) == arrowDir)) ||
+      ((arrowDir == sortDir) && (flagA == 1)) ||
+      ((arrowDir != sortDir) && (flagB == 1))) {
+    t = keyA;
+    keyA = keyB;
+    keyB = t;
+    t = valA;
+    valA = valB;
+    valB = t;
+    t = flagA;
+    flagA = flagB;
+    flagB = t;
+  }
+}
+
+template <uint sortDir>
+__global__ void bitonicMergeElementaryIntervalsKernel(
+    uint *d_DstKey, uint *d_DstVal, uint *d_SrcKey, uint *d_SrcVal,
+    uint *d_LimitsA, uint *d_LimitsB, uint stride, uint N) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  __shared__ uint s_key[2 * SAMPLE_STRIDE];
+  __shared__ uint s_val[2 * SAMPLE_STRIDE];
+  __shared__ uint s_inf[2 * SAMPLE_STRIDE];
+
+  const uint intervalI = blockIdx.x & ((2 * stride) / SAMPLE_STRIDE - 1);
+  const uint segmentBase = (blockIdx.x - intervalI) * SAMPLE_STRIDE;
+  d_SrcKey += segmentBase;
+  d_SrcVal += segmentBase;
+  d_DstKey += segmentBase;
+  d_DstVal += segmentBase;
+
+  // Set up threadblock-wide parameters
+  __shared__ uint startSrcA, lenSrcA, startSrcB, lenSrcB, startDst;
+
+  if (threadIdx.x == 0) {
+    uint segmentElementsA = stride;
+    uint segmentElementsB =min(stride, N - segmentBase - stride);
+    uint segmentSamplesA = stride / SAMPLE_STRIDE;
+    uint segmentSamplesB = getSampleCount(segmentElementsB);
+    uint segmentSamples = segmentSamplesA + segmentSamplesB;
+
+    startSrcA = d_LimitsA[blockIdx.x];
+    startSrcB = d_LimitsB[blockIdx.x];
+    startDst = startSrcA + startSrcB;
+
+    uint endSrcA = (intervalI + 1 < segmentSamples) ? d_LimitsA[blockIdx.x + 1]
+                                                    : segmentElementsA;
+    uint endSrcB = (intervalI + 1 < segmentSamples) ? d_LimitsB[blockIdx.x + 1]
+                                                    : segmentElementsB;
+    lenSrcA = endSrcA - startSrcA;
+    lenSrcB = endSrcB - startSrcB;
+  }
+
+  s_inf[threadIdx.x + 0] = 1;
+  s_inf[threadIdx.x + SAMPLE_STRIDE] = 1;
+
+  // Load input data
+  cg::sync(cta);
+
+  if (threadIdx.x < lenSrcA) {
+    s_key[threadIdx.x] = d_SrcKey[0 + startSrcA + threadIdx.x];
+    s_val[threadIdx.x] = d_SrcVal[0 + startSrcA + threadIdx.x];
+    s_inf[threadIdx.x] = 0;
+  }
+
+  // Prepare for bitonic merge by inversing the ordering
+  if (threadIdx.x < lenSrcB) {
+    s_key[2 * SAMPLE_STRIDE - 1 - threadIdx.x] =
+        d_SrcKey[stride + startSrcB + threadIdx.x];
+    s_val[2 * SAMPLE_STRIDE - 1 - threadIdx.x] =
+        d_SrcVal[stride + startSrcB + threadIdx.x];
+    s_inf[2 * SAMPLE_STRIDE - 1 - threadIdx.x] = 0;
+  }
+
+  //"Extended" bitonic merge
+  for (uint stride = SAMPLE_STRIDE; stride > 0; stride >>= 1) {
+    cg::sync(cta);
+    uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
+    ComparatorExtended<sortDir>(s_key[pos + 0], s_val[pos + 0], s_inf[pos + 0],
+                                s_key[pos + stride], s_val[pos + stride],
+                                s_inf[pos + stride], sortDir);
+  }
+
+  // Store sorted data
+  cg::sync(cta);
+  d_DstKey += startDst;
+  d_DstVal += startDst;
+
+  if (threadIdx.x < lenSrcA) {
+    d_DstKey[threadIdx.x] = s_key[threadIdx.x];
+    d_DstVal[threadIdx.x] = s_val[threadIdx.x];
+  }
+
+  if (threadIdx.x < lenSrcB) {
+    d_DstKey[lenSrcA + threadIdx.x] = s_key[lenSrcA + threadIdx.x];
+    d_DstVal[lenSrcA + threadIdx.x] = s_val[lenSrcA + threadIdx.x];
+  }
+}
+
+extern "C" void bitonicMergeElementaryIntervals(uint *d_DstKey, uint *d_DstVal,
+                                                uint *d_SrcKey, uint *d_SrcVal,
+                                                uint *d_LimitsA,
+                                                uint *d_LimitsB, uint stride,
+                                                uint N, uint sortDir) {
+  uint lastSegmentElements = N % (2 * stride);
+
+  uint mergePairs = (lastSegmentElements > stride)
+                        ? getSampleCount(N)
+                        : (N - lastSegmentElements) / SAMPLE_STRIDE;
+
+  if (sortDir) {
+    bitonicMergeElementaryIntervalsKernel<1U><<<mergePairs, SAMPLE_STRIDE>>>(
+        d_DstKey, d_DstVal, d_SrcKey, d_SrcVal, d_LimitsA, d_LimitsB, stride,
+        N);
+    getLastCudaError("mergeElementaryIntervalsKernel<1> failed\n");
+  } else {
+    bitonicMergeElementaryIntervalsKernel<0U><<<mergePairs, SAMPLE_STRIDE>>>(
+        d_DstKey, d_DstVal, d_SrcKey, d_SrcVal, d_LimitsA, d_LimitsB, stride,
+        N);
+    getLastCudaError("mergeElementaryIntervalsKernel<0> failed\n");
+  }
+}
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort.cu.hip b/src/samples/Samples/0_Introduction/mergeSort/mergeSort.cu.hip
index 98047f5..97ee962 100755
--- a/src/samples/Samples/0_Introduction/mergeSort/mergeSort.cu.hip
+++ b/src/samples/Samples/0_Introduction/mergeSort/mergeSort.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -34,9 +33,11 @@
  * Victor Podlozhnyuk 09/24/2009
  */
 
+
+#include <hip/hip_runtime.h>
 #include <assert.h>
 #include <hip/hip_cooperative_groups.h>
-#inlcude "HIPCHECK.h"
+#include "HIPCHECK.h"
 namespace cg = cooperative_groups;
 
 #include "helper_cuda_hipified.h"
@@ -77,7 +78,7 @@ static inline __device__ uint binarySearchInclusive(uint val, uint *data,
   uint pos = 0;
 
   for (; stride > 0; stride >>= 1) {
-    uint newPos = umin(pos + stride, L);
+    uint newPos = min(pos + stride, L);
 
     if ((sortDir && (data[newPos - 1] <= val)) ||
         (!sortDir && (data[newPos - 1] >= val))) {
@@ -98,7 +99,7 @@ static inline __device__ uint binarySearchExclusive(uint val, uint *data,
   uint pos = 0;
 
   for (; stride > 0; stride >>= 1) {
-    uint newPos = umin(pos + stride, L);
+    uint newPos = min(pos + stride, L);
 
     if ((sortDir && (data[newPos - 1] < val)) ||
         (!sortDir && (data[newPos - 1] > val))) {
@@ -208,7 +209,7 @@ __global__ void generateSampleRanksKernel(uint *d_RanksA, uint *d_RanksB,
   d_RanksB += segmentBase / SAMPLE_STRIDE;
 
   const uint segmentElementsA = stride;
-  const uint segmentElementsB = umin(stride, N - segmentBase - stride);
+  const uint segmentElementsB = min(stride, N - segmentBase - stride);
   const uint segmentSamplesA = getSampleCount(segmentElementsA);
   const uint segmentSamplesB = getSampleCount(segmentElementsB);
 
@@ -264,7 +265,7 @@ __global__ void mergeRanksAndIndicesKernel(uint *d_Limits, uint *d_Ranks,
   d_Limits += (pos - i) * 2;
 
   const uint segmentElementsA = stride;
-  const uint segmentElementsB = umin(stride, N - segmentBase - stride);
+  const uint segmentElementsB = min(stride, N - segmentBase - stride);
   const uint segmentSamplesA = getSampleCount(segmentElementsA);
   const uint segmentSamplesB = getSampleCount(segmentElementsB);
 
@@ -362,7 +363,7 @@ __global__ void mergeElementaryIntervalsKernel(uint *d_DstKey, uint *d_DstVal,
 
   if (threadIdx.x == 0) {
     uint segmentElementsA = stride;
-    uint segmentElementsB = umin(stride, N - segmentBase - stride);
+    uint segmentElementsB = min(stride, N - segmentBase - stride);
     uint segmentSamplesA = getSampleCount(segmentElementsA);
     uint segmentSamplesB = getSampleCount(segmentElementsB);
     uint segmentSamples = segmentSamplesA + segmentSamplesB;
@@ -528,9 +529,3 @@ extern "C" void mergeSort(uint *d_DstKey, uint *d_DstVal, uint *d_BufKey,
     oval = t;
   }
 }
-key;
-    okey = t;
-    t = ival;
-    ival = oval;
-    oval = t;
-  }
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort.out b/src/samples/Samples/0_Introduction/mergeSort/mergeSort.out
index 8d1cc72..ff05194 100755
Binary files a/src/samples/Samples/0_Introduction/mergeSort/mergeSort.out and b/src/samples/Samples/0_Introduction/mergeSort/mergeSort.out differ
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_host_hipified.cpp b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_host_hipified.cpp
index 1006cf1..55f0411 100755
--- a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_host_hipified.cpp
+++ b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_host_hipified.cpp
@@ -47,7 +47,7 @@ static void checkOrder(uint *data, uint N, uint sortDir) {
     }
 }
 
-static uint umin(uint a, uint b) { return (a <= b) ? a : b; }
+static uint umin(uint a, uint b) { return (a<= b) ? a : b; }
 
 static uint getSampleCount(uint dividend) {
   return ((dividend % SAMPLE_STRIDE) != 0) ? (dividend / SAMPLE_STRIDE + 1)
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2017.vcxproj b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2017.vcxproj
index ad9bd36..0ef0701 100755
--- a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/mergeSort.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2019.vcxproj b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2019.vcxproj
index 29bbe5f..5796dda 100755
--- a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/mergeSort.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2022.vcxproj b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2022.vcxproj
index 03a9efb..ed951e9 100755
--- a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/mergeSort.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/README.md b/src/samples/Samples/0_Introduction/simpleAWBarrier/README.md
index 0b98b2e..064db83 100755
--- a/src/samples/Samples/0_Introduction/simpleAWBarrier/README.md
+++ b/src/samples/Samples/0_Introduction/simpleAWBarrier/README.md
@@ -30,7 +30,7 @@ cudaStreamCreateWithFlags, cudaFree, cudaDeviceGetAttribute, cudaMallocHost, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier.cu.hip b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier.cu.hip
index bc7610f..097e148 100755
--- a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier.cu.hip
@@ -31,7 +31,7 @@
 
 // Includes CUDA
 #include <hip/hip_runtime.h>
-#include "cuda/barrier"
+#include <cuda/barrier>
 #include <hip/hip_cooperative_groups.h>
 
 // Utilities and timing functions
@@ -254,15 +254,3 @@ int runNormVecByDotProductAWBarrier(int argc, char **argv, int deviceId) {
   checkCudaErrors(hipHostFree(vecB));
   return matches == size;
 }
-eckCudaErrors(hipFree(d_partialResults));
-
-  checkCudaErrors(hipHostFree(vecA));
-  checkCudaErrors(hipHostFree(vecB));
-  return matches == size;
-}
-eckCudaErrors(hipFree(d_partialResults));
-
-  checkCudaErrors(hipHostFree(vecA));
-  checkCudaErrors(hipHostFree(vecB));
-  return matches == size;
-}
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2017.vcxproj
index 4589add..ed13654 100755
--- a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2019.vcxproj
index ef93f03..eeddba2 100755
--- a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2022.vcxproj
index 7f89498..85eb24b 100755
--- a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/Makefile b/src/samples/Samples/0_Introduction/simpleAssert/Makefile
index 240e0db..bd790aa 100755
--- a/src/samples/Samples/0_Introduction/simpleAssert/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleAssert/Makefile
@@ -287,7 +287,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleAssert/NsightEclipse.xml
index d31a3f9..2ba03ec 100755
--- a/src/samples/Samples/0_Introduction/simpleAssert/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleAssert/NsightEclipse.xml
@@ -28,6 +28,8 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/README.md b/src/samples/Samples/0_Introduction/simpleAssert/README.md
index 1f95dce..05b753a 100755
--- a/src/samples/Samples/0_Introduction/simpleAssert/README.md
+++ b/src/samples/Samples/0_Introduction/simpleAssert/README.md
@@ -10,7 +10,7 @@ Assert
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaDeviceSynchronize, cudaGetErrorString
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert.cu.hip b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert.cu.hip
index 91432f5..40ec5e5 100755
--- a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert.cu.hip
@@ -42,10 +42,10 @@
 #include <hip/hip_runtime.h>
 
 // Utilities and timing functions
-#include "helper_functions.h"  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
+#include <helper_functions.h>  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
 
 // CUDA helper functions
-#include "helper_cuda_hipified.h"  // helper functions for CUDA error check
+#include <helper_cuda.h>  // helper functions for CUDA error check
 
 const char *sampleName = "simpleAssert";
 
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert.out b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert.out
index fb58ac5..c36dcf6 100755
Binary files a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert.out and b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert.out differ
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2017.vcxproj
index 87575cb..731833f 100755
--- a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleAssert.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2019.vcxproj
index dfa867f..88e2fa0 100755
--- a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleAssert.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2022.vcxproj
index 06d8aa9..ce93512 100755
--- a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleAssert.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/README.md b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/README.md
index 195bbcf..72c5de1 100755
--- a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/README.md
+++ b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/README.md
@@ -10,7 +10,7 @@ Assert, Runtime Compilation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cuModuleGetFunction, cuLaunchKernel, cuCtxSynchronize
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2017.vcxproj
index edb70f3..3fc089e 100755
--- a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2019.vcxproj
index 51c34ac..0714d83 100755
--- a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2022.vcxproj
index 8e25d35..fc010fb 100755
--- a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/Makefile b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/Makefile
index 5217ddd..b722244 100755
--- a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/NsightEclipse.xml
index b995297..e9252d1 100755
--- a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/NsightEclipse.xml
@@ -35,6 +35,8 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/README.md b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/README.md
index eb9cdcc..0fa5278 100755
--- a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/README.md
+++ b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/README.md
@@ -10,7 +10,7 @@ Atomic Intrinsics
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaStreamCreateWithFlags, cudaFree, cudaMallocHost, cudaFreeHost, cudaStreamSyn
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics.cu.hip b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics.cu.hip
index 11eaab2..24cfa48 100755
--- a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics.cu.hip
@@ -32,8 +32,6 @@
 // includes, system
 #include <stdlib.h>
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <string.h>
 #include <math.h>
 
@@ -47,11 +45,11 @@
 #include <hip/hip_runtime.h>
 
 // Utilities and timing functions
-#include "helper_functions.h"  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
+#include <helper_functions.h>  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
 
 // CUDA helper functions
-#include "helper_cuda_hipified.h"  // helper functions for CUDA error check
-#include "HIPCHECK.h"
+#include <helper_cuda.h>  // helper functions for CUDA error check
+
 // Includes, kernels
 #include "simpleAtomicIntrinsics_kernel.cuh"
 
@@ -134,3 +132,6 @@ void runTest(int argc, char **argv) {
   HIPCHECK(hipHostFree(hOData));
   HIPCHECK(hipFree(dOData));
 }
+ostFree(hOData));
+  checkCudaErrors(hipFree(dOData));
+}
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics.out b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics.out
index 58b791f..ba13918 100755
Binary files a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics.out and b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics.out differ
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2017.vcxproj
index 9dda17d..d122ae6 100755
--- a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleAtomicIntrinsics.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2019.vcxproj
index 759836b..7f05dcc 100755
--- a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleAtomicIntrinsics.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2022.vcxproj
index 74fbd8d..7dd8d89 100755
--- a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleAtomicIntrinsics.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/README.md b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/README.md
index fc56b28..a53e822 100755
--- a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/README.md
+++ b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/README.md
@@ -10,7 +10,7 @@ Atomic Intrinsics, Runtime Compilation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaBlockSize, cudaGridSize
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2017.vcxproj
index 842063b..9db171b 100755
--- a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2019.vcxproj
index 22b2b22..b43cec9 100755
--- a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2022.vcxproj
index 58dba57..bd705f4 100755
--- a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/Makefile b/src/samples/Samples/0_Introduction/simpleAttributes/Makefile
index 7ebecf5..e685dd6 100755
--- a/src/samples/Samples/0_Introduction/simpleAttributes/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleAttributes/Makefile
@@ -287,7 +287,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleAttributes/NsightEclipse.xml
index 60e8866..fcad823 100755
--- a/src/samples/Samples/0_Introduction/simpleAttributes/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleAttributes/NsightEclipse.xml
@@ -36,6 +36,8 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/README.md b/src/samples/Samples/0_Introduction/simpleAttributes/README.md
index f7db2f5..5dc1787 100755
--- a/src/samples/Samples/0_Introduction/simpleAttributes/README.md
+++ b/src/samples/Samples/0_Introduction/simpleAttributes/README.md
@@ -10,7 +10,7 @@ Attributes usage on stream
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaFree, cudaMallocHost, cudaFreeHost, cudaStreamSynchronize, cudaStreamSetAttr
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2017.vcxproj
index 5de9e13..a446d3a 100755
--- a/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleAttributes.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2019.vcxproj
index 3055641..e49167d 100755
--- a/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleAttributes.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2022.vcxproj
index a566c10..1eb6125 100755
--- a/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleAttributes.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/Makefile b/src/samples/Samples/0_Introduction/simpleCUDA2GL/Makefile
index 0bb05bd..80e3250 100755
--- a/src/samples/Samples/0_Introduction/simpleCUDA2GL/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleCUDA2GL/Makefile
@@ -313,7 +313,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleCUDA2GL/NsightEclipse.xml
index 257d776..1f40f86 100755
--- a/src/samples/Samples/0_Introduction/simpleCUDA2GL/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleCUDA2GL/NsightEclipse.xml
@@ -66,6 +66,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/README.md b/src/samples/Samples/0_Introduction/simpleCUDA2GL/README.md
index bce67a5..7c46fb7 100755
--- a/src/samples/Samples/0_Introduction/simpleCUDA2GL/README.md
+++ b/src/samples/Samples/0_Introduction/simpleCUDA2GL/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Image Processing, Performance Strategies
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaHostAlloc, cudaGraphicsUnmapResources, cudaMalloc, cudaFree, cudaGraphicsRes
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL.cu.hip b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL.cu.hip
index e69de29..7f0c62c 100755
--- a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL.cu.hip
@@ -0,0 +1,63 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+// Utilities and system includes
+
+#include "helper_cuda_hipified.h"
+
+// clamp x to range [a, b]
+__device__ float clamp(float x, float a, float b) { return max(a, min(b, x)); }
+
+__device__ int clamp(int x, int a, int b) { return max(a, min(b, x)); }
+
+// convert floating point rgb color to 8-bit integer
+__device__ int rgbToInt(float r, float g, float b) {
+  r = clamp(r, 0.0f, 255.0f);
+  g = clamp(g, 0.0f, 255.0f);
+  b = clamp(b, 0.0f, 255.0f);
+  return (int(b) << 16) | (int(g) << 8) | int(r);
+}
+
+__global__ void cudaProcess(unsigned int *g_odata, int imgw) {
+  extern __shared__ uchar4 sdata[];
+
+  int tx = threadIdx.x;
+  int ty = threadIdx.y;
+  int bw = blockDim.x;
+  int bh = blockDim.y;
+  int x = blockIdx.x * bw + tx;
+  int y = blockIdx.y * bh + ty;
+
+  uchar4 c4 = make_uchar4((x & 0x20) ? 100 : 0, 0, (y & 0x20) ? 100 : 0, 0);
+  g_odata[y * imgw + x] = rgbToInt(c4.z, c4.y, c4.x);
+}
+
+extern "C" void launch_cudaProcess(dim3 grid, dim3 block, int sbytes,
+                                   unsigned int *g_odata, int imgw) {
+  cudaProcess<<<grid, block, sbytes>>>(g_odata, imgw);
+}
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2017.vcxproj
index 7c3da80..6586511 100755
--- a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleCUDA2GL.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -118,6 +118,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2019.vcxproj
index 8bd8209..19ad1de 100755
--- a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCUDA2GL.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2022.vcxproj
index b1bb894..f2b071e 100755
--- a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCUDA2GL.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/Makefile b/src/samples/Samples/0_Introduction/simpleCallback/Makefile
index cc045b6..ff334a8 100755
--- a/src/samples/Samples/0_Introduction/simpleCallback/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleCallback/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleCallback/NsightEclipse.xml
index 3090b3f..931c7c6 100755
--- a/src/samples/Samples/0_Introduction/simpleCallback/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleCallback/NsightEclipse.xml
@@ -40,6 +40,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/README.md b/src/samples/Samples/0_Introduction/simpleCallback/README.md
index d0a20b9..4036856 100755
--- a/src/samples/Samples/0_Introduction/simpleCallback/README.md
+++ b/src/samples/Samples/0_Introduction/simpleCallback/README.md
@@ -10,7 +10,7 @@ CUDA Streams, Callback Functions, Multithreading
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaHostAlloc, cudaStreamDestroy, cudaFree, cudaSetDevice, cudaGetDeviceCount, c
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback.cu.hip b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback.cu.hip
index 3180829..55f896f 100755
--- a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback.cu.hip
@@ -42,21 +42,20 @@
 
 // System includes
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 
 // helper functions and utilities to work with CUDA
 #include "helper_functions.h"
 #include "helper_cuda_hipified.h"
-
+#include <hip/hip_runtime_api.h>
 #include "multithreading.h"
-
+#include "HIPCHECK.h"
 const int N_workloads = 8;
 const int N_elements_per_workload = 100000;
 
 CUTBarrier thread_barrier;
 
-void (CUDART_CB* myStreamCallback)(hipStream_t event, hipError_t status, void *data);
+void myStreamCallback(hipStream_t event, hipError_t status,
+                                void *data);
 
 struct heterogeneous_workload {
   int id;
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback.out b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback.out
deleted file mode 100755
index be03324..0000000
Binary files a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback.out and /dev/null differ
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2017.vcxproj
index d413615..ad8bf90 100755
--- a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleCallback.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2019.vcxproj
index cd59b44..b200ba6 100755
--- a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCallback.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2022.vcxproj
index 6643dd1..196f579 100755
--- a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCallback.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/Makefile b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/Makefile
index 737c4d5..22efbff 100755
--- a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/NsightEclipse.xml
index f5b0a45..939f68a 100755
--- a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/NsightEclipse.xml
@@ -31,6 +31,8 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/README.md b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/README.md
index a3bf7de..ab3e11c 100755
--- a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/README.md
+++ b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/README.md
@@ -10,7 +10,7 @@ Cooperative Groups
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaDeviceSynchronize, cudaGetErrorString
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups.cu.hip b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups.cu.hip
index e69de29..bf1c8e1 100755
--- a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups.cu.hip
@@ -0,0 +1,181 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/**
+ *
+ * This sample is a simple code that illustrates basic usage of
+ * cooperative groups within the thread block. The code launches a single
+ * thread block, creates a cooperative group of all threads in the block,
+ * and a set of tiled partition cooperative groups. For each, it uses a
+ * generic reduction function to calculate the sum of all the ranks in
+ * that group. In each case the result is printed, together with the
+ * expected answer (which is calculated using the analytical formula
+ * (n-1)*n)/2, noting that the ranks start at zero).
+ *
+ */
+
+
+#include <hip/hip_runtime.h>
+#include <stdio.h>
+#include "rocprofiler.h"
+#include "HIPCHECK.h"
+#include <hip/hip_cooperative_groups.h>
+
+using namespace cooperative_groups;
+
+/**
+ * CUDA device function
+ *
+ * calculates the sum of val across the group g. The workspace array, x,
+ * must be large enough to contain g.size() integers.
+ */
+__device__ int sumReduction(thread_group g, int *x, int val) {
+  // rank of this thread in the group
+  int lane = g.thread_rank();
+
+  // for each iteration of this loop, the number of threads active in the
+  // reduction, i, is halved, and each active thread (with index [lane])
+  // performs a single summation of it's own value with that
+  // of a "partner" (with index [lane+i]).
+  for (int i = g.size() / 2; i > 0; i /= 2) {
+    // store value for this thread in temporary array
+    x[lane] = val;
+
+    // synchronize all threads in group
+    g.sync();
+
+    if (lane < i)
+      // active threads perform summation of their value with
+      // their partner's value
+      val += x[lane + i];
+
+    // synchronize all threads in group
+    g.sync();
+  }
+
+  // master thread in group returns result, and others return -1.
+  if (g.thread_rank() == 0)
+    return val;
+  else
+    return -1;
+}
+
+/**
+ * CUDA kernel device code
+ *
+ * Creates cooperative groups and performs reductions
+ */
+__global__ void cgkernel() {
+  // threadBlockGroup includes all threads in the block
+  thread_block threadBlockGroup = this_thread_block();
+  int threadBlockGroupSize = threadBlockGroup.size();
+
+  // workspace array in shared memory required for reduction
+  extern __shared__ int workspace[];
+
+  int input, output, expectedOutput;
+
+  // input to reduction, for each thread, is its' rank in the group
+  input = threadBlockGroup.thread_rank();
+
+  // expected output from analytical formula (n-1)(n)/2
+  // (noting that indexing starts at 0 rather than 1)
+  expectedOutput = (threadBlockGroupSize - 1) * threadBlockGroupSize / 2;
+
+  // perform reduction
+  output = sumReduction(threadBlockGroup, workspace, input);
+
+  // master thread in group prints out result
+  if (threadBlockGroup.thread_rank() == 0) {
+    printf(
+        " Sum of all ranks 0..%d in threadBlockGroup is %d (expected %d)\n\n",
+        (int)threadBlockGroup.size() - 1, output, expectedOutput);
+
+    printf(" Now creating %d groups, each of size 16 threads:\n\n",
+           (int)threadBlockGroup.size() / 16);
+  }
+
+  threadBlockGroup.sync();
+
+  // each tiledPartition16 group includes 16 threads
+  thread_block_tile<16> tiledPartition16 =
+      tiled_partition<16>(threadBlockGroup);
+
+  // This offset allows each group to have its own unique area in the workspace
+  // array
+  int workspaceOffset =
+      threadBlockGroup.thread_rank() - tiledPartition16.thread_rank();
+
+  // input to reduction, for each thread, is its' rank in the group
+  input = tiledPartition16.thread_rank();
+
+  // expected output from analytical formula (n-1)(n)/2
+  // (noting that indexing starts at 0 rather than 1)
+  expectedOutput = 15 * 16 / 2;
+
+  // Perform reduction
+  output = sumReduction(tiledPartition16, workspace + workspaceOffset, input);
+
+  // each master thread prints out result
+  if (tiledPartition16.thread_rank() == 0)
+    printf(
+        "   Sum of all ranks 0..15 in this tiledPartition16 group is %d "
+        "(expected %d)\n",
+        output, expectedOutput);
+
+  return;
+}
+
+/**
+ * Host main routine
+ */
+int main() {
+  // Error code to check return values for CUDA calls
+  hipError_t err;
+
+  // Launch the kernel
+
+  int blocksPerGrid = 1;
+  int threadsPerBlock = 64;
+
+  printf("\nLaunching a single block with %d threads...\n\n", threadsPerBlock);
+
+  // we use the optional third argument to specify the size
+  // of shared memory required in the kernel
+  cgkernel<<<blocksPerGrid, threadsPerBlock, threadsPerBlock * sizeof(int)>>>();
+  err = hipDeviceSynchronize();
+
+  if (err != hipSuccess) {
+    fprintf(stderr, "Failed to launch kernel (error code %s)!\n",
+            hipGetErrorString(err));
+    exit(EXIT_FAILURE);
+  }
+
+  printf("\n...Done.\n\n");
+
+  return 0;
+}
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2017.vcxproj
index b3fb7cc..061538d 100755
--- a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleCooperativeGroups.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2019.vcxproj
index c3231e7..bf17882 100755
--- a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCooperativeGroups.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2022.vcxproj
index f924bc4..649221c 100755
--- a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCooperativeGroups.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/Makefile b/src/samples/Samples/0_Introduction/simpleCubemapTexture/Makefile
index 2a499ae..4c1fed1 100755
--- a/src/samples/Samples/0_Introduction/simpleCubemapTexture/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleCubemapTexture/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleCubemapTexture/NsightEclipse.xml
index ccdbdc0..1bf6b01 100755
--- a/src/samples/Samples/0_Introduction/simpleCubemapTexture/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleCubemapTexture/NsightEclipse.xml
@@ -39,6 +39,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Volume Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/README.md b/src/samples/Samples/0_Introduction/simpleCubemapTexture/README.md
index 39ea370..44c3896 100755
--- a/src/samples/Samples/0_Introduction/simpleCubemapTexture/README.md
+++ b/src/samples/Samples/0_Introduction/simpleCubemapTexture/README.md
@@ -10,7 +10,7 @@ Texture, Volume Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaCreateChannelDesc, cudaFreeArray, cudaFree, cudaPitchedPtr, cuda
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture.cu.hip b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture.cu.hip
index e69de29..791e52d 100755
--- a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture.cu.hip
@@ -0,0 +1,270 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+* This sample demonstrates how to use texture fetches from layered 2D textures
+* in CUDA C
+*
+* This sample first generates a 3D input data array for the layered texture
+* and the expected output. Then it starts CUDA C kernels, one for each layer,
+* which fetch their layer's texture data (using normalized texture coordinates)
+* transform it to the expected output, and write it to a 3D output data array.
+*/
+
+// includes, system
+#include <stdlib.h>
+#include <stdio.h>
+#include "rocprofiler.h"
+#include "HIPCHECK.h"
+#include <string.h>
+#include <math.h>
+
+// includes CUDA
+#include <hip/hip_runtime.h>
+
+// helper functions and utilities to work with CUDA
+#include "helper_functions.h"
+#include "helper_cuda_hipified.h"
+
+static const char *sSDKname = "simpleCubemapTexture";
+
+// includes, kernels
+
+////////////////////////////////////////////////////////////////////////////////
+//! Transform a cubemap face of a linear buffe using cubemap texture lookups
+//! @param g_odata  output data in global memory
+////////////////////////////////////////////////////////////////////////////////
+__global__ void transformKernel(float *g_odata, int width,
+                                hipTextureObject_t tex) {
+  // calculate this thread's data point
+  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
+  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
+
+  // 0.5f offset and division are necessary to access the original data points
+  // in the texture (such that bilinear interpolation will not be activated).
+  // For details, see also CUDA Programming Guide, Appendix D
+
+  float u = ((x + 0.5f) / (float)width) * 2.f - 1.f;
+  float v = ((y + 0.5f) / (float)width) * 2.f - 1.f;
+
+  float cx, cy, cz;
+
+  for (unsigned int face = 0; face < 6; face++) {
+    // Layer 0 is positive X face
+    if (face == 0) {
+      cx = 1;
+      cy = -v;
+      cz = -u;
+    }
+    // Layer 1 is negative X face
+    else if (face == 1) {
+      cx = -1;
+      cy = -v;
+      cz = u;
+    }
+    // Layer 2 is positive Y face
+    else if (face == 2) {
+      cx = u;
+      cy = 1;
+      cz = v;
+    }
+    // Layer 3 is negative Y face
+    else if (face == 3) {
+      cx = u;
+      cy = -1;
+      cz = -v;
+    }
+    // Layer 4 is positive Z face
+    else if (face == 4) {
+      cx = u;
+      cy = -v;
+      cz = 1;
+    }
+    // Layer 4 is negative Z face
+    else if (face == 5) {
+      cx = -u;
+      cy = -v;
+      cz = -1;
+    }
+
+    // read from texture, do expected transformation and write to global memory
+    g_odata[face * width * width + y * width + x] =
+        -texCubemap<float>(tex, cx, cy, cz);
+  }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Program main
+////////////////////////////////////////////////////////////////////////////////
+int main(int argc, char **argv) {
+  // use command-line specified CUDA device, otherwise use device with highest
+  // Gflops/s
+  int devID = findCudaDevice(argc, (const char **)argv);
+
+  bool bResult = true;
+
+  // get number of SMs on this GPU
+  hipDeviceProp_t deviceProps;
+
+  HIPCHECK(hipGetDeviceProperties(&deviceProps, devID));
+  printf("CUDA device [%s] has %d Multi-Processors ", deviceProps.name,
+         deviceProps.multiProcessorCount);
+  printf("SM %d.%d\n", deviceProps.major, deviceProps.minor);
+
+  if (deviceProps.major < 2) {
+    printf(
+        "%s requires SM 2.0 or higher for support of Texture Arrays.  Test "
+        "will exit... \n",
+        sSDKname);
+
+    exit(EXIT_WAIVED);
+  }
+
+  // generate input data for layered texture
+  unsigned int width = 64, num_faces = 6, num_layers = 1;
+  unsigned int cubemap_size = width * width * num_faces;
+  unsigned int size = cubemap_size * num_layers * sizeof(float);
+  float *h_data = (float *)malloc(size);
+
+  for (int i = 0; i < (int)(cubemap_size * num_layers); i++) {
+    h_data[i] = (float)i;
+  }
+
+  // this is the expected transformation of the input data (the expected output)
+  float *h_data_ref = (float *)malloc(size);
+
+  for (unsigned int layer = 0; layer < num_layers; layer++) {
+    for (int i = 0; i < (int)(cubemap_size); i++) {
+      h_data_ref[layer * cubemap_size + i] =
+          -h_data[layer * cubemap_size + i] + layer;
+    }
+  }
+
+  // allocate device memory for result
+  float *d_data = NULL;
+  HIPCHECK(hipMalloc((void **)&d_data, size));
+
+  // allocate array and copy image data
+  hipChannelFormatDesc channelDesc =
+      hipCreateChannelDesc(32, 0, 0, 0, hipChannelFormatKindFloat);
+  hipArray *cu_3darray;
+  //    HIPCHECK(cudaMalloc3DArray( &cu_3darray, &channelDesc,
+  //    make_cudaExtent(width, height, num_layers), cudaArrayLayered ));
+  HIPCHECK(hipMalloc3DArray(&cu_3darray, &channelDesc,
+                                    make_hipExtent(width, width, num_faces),
+                                    hipArrayCubemap));
+  hipMemcpy3DParms myparms = {0};
+  myparms.srcPos = make_hipPos(0, 0, 0);
+  myparms.dstPos = make_hipPos(0, 0, 0);
+  myparms.srcPtr =
+      make_hipPitchedPtr(h_data, width * sizeof(float), width, width);
+  myparms.dstArray = cu_3darray;
+  myparms.extent = make_hipExtent(width, width, num_faces);
+  myparms.kind = hipMemcpyHostToDevice;
+  HIPCHECK(hipMemcpy3D(&myparms));
+
+  hipTextureObject_t tex;
+  hipResourceDesc texRes;
+  memset(&texRes, 0, sizeof(hipResourceDesc));
+
+  texRes.resType = hipResourceTypeArray;
+  texRes.res.array.array = cu_3darray;
+
+  hipTextureDesc texDescr;
+  memset(&texDescr, 0, sizeof(hipTextureDesc));
+
+  texDescr.normalizedCoords = true;
+  texDescr.filterMode = hipFilterModeLinear;
+  texDescr.addressMode[0] = hipAddressModeWrap;
+  texDescr.addressMode[1] = hipAddressModeWrap;
+  texDescr.addressMode[2] = hipAddressModeWrap;
+  texDescr.readMode = hipReadModeElementType;
+
+  HIPCHECK(hipCreateTextureObject(&tex, &texRes, &texDescr, NULL));
+
+  dim3 dimBlock(8, 8, 1);
+  dim3 dimGrid(width / dimBlock.x, width / dimBlock.y, 1);
+
+  printf(
+      "Covering Cubemap data array of %d~3 x %d: Grid size is %d x %d, each "
+      "block has 8 x 8 threads\n",
+      width, num_layers, dimGrid.x, dimGrid.y);
+
+  transformKernel<<<dimGrid, dimBlock>>>(d_data, width,
+                                         tex);  // warmup (for better timing)
+
+  // check if kernel execution generated an error
+  getLastCudaError("warmup Kernel execution failed");
+
+  HIPCHECK(hipDeviceSynchronize());
+
+  StopWatchInterface *timer = NULL;
+  sdkCreateTimer(&timer);
+  sdkStartTimer(&timer);
+
+  // execute the kernel
+  transformKernel<<<dimGrid, dimBlock, 0>>>(d_data, width, tex);
+
+  // check if kernel execution generated an error
+  getLastCudaError("Kernel execution failed");
+
+  HIPCHECK(hipDeviceSynchronize());
+  sdkStopTimer(&timer);
+  printf("Processing time: %.3f msec\n", sdkGetTimerValue(&timer));
+  printf("%.2f Mtexlookups/sec\n",
+         (cubemap_size / (sdkGetTimerValue(&timer) / 1000.0f) / 1e6));
+  sdkDeleteTimer(&timer);
+
+  // allocate mem for the result on host side
+  float *h_odata = (float *)malloc(size);
+  // copy result from device to host
+  HIPCHECK(hipMemcpy(h_odata, d_data, size, hipMemcpyDeviceToHost));
+
+  // write regression file if necessary
+  if (checkCmdLineFlag(argc, (const char **)argv, "regression")) {
+    // write file for regression test
+    sdkWriteFile<float>("./data/regression.dat", h_odata, width * width, 0.0f,
+                        false);
+  } else {
+    printf("Comparing kernel output to expected data\n");
+
+#define MIN_EPSILON_ERROR 5e-3f
+    bResult =
+        compareData(h_odata, h_data_ref, cubemap_size, MIN_EPSILON_ERROR, 0.0f);
+  }
+
+  // cleanup memory
+  free(h_data);
+  free(h_data_ref);
+  free(h_odata);
+
+  HIPCHECK(hipDestroyTextureObject(tex));
+  HIPCHECK(hipFree(d_data));
+  HIPCHECK(hipFreeArray(cu_3darray));
+
+  exit(bResult ? EXIT_SUCCESS : EXIT_FAILURE);
+}
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2017.vcxproj
index 186f61d..307c528 100755
--- a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleCubemapTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2019.vcxproj
index 9471196..709f036 100755
--- a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCubemapTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2022.vcxproj
index ba270c3..3c332af 100755
--- a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCubemapTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/Makefile b/src/samples/Samples/0_Introduction/simpleDrvRuntime/Makefile
index 95222d5..46593a8 100755
--- a/src/samples/Samples/0_Introduction/simpleDrvRuntime/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleDrvRuntime/Makefile
@@ -285,7 +285,7 @@ FATBIN_FILE := vectorAdd_kernel${TARGET_SIZE}.fatbin
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/README.md b/src/samples/Samples/0_Introduction/simpleDrvRuntime/README.md
index 93b6593..158157e 100755
--- a/src/samples/Samples/0_Introduction/simpleDrvRuntime/README.md
+++ b/src/samples/Samples/0_Introduction/simpleDrvRuntime/README.md
@@ -10,7 +10,7 @@ CUDA Driver API, CUDA Runtime API, Vector Addition
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaStreamCreateWithFlags, cudaFree, cudaMallocHost, cudaFreeHost, cudaStreamSyn
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2017.vcxproj
index 67c8c88..019fc0c 100755
--- a/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleDrvRuntime.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2019.vcxproj
index 44d7fac..727c658 100755
--- a/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleDrvRuntime.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2022.vcxproj
index c25b9de..93b2ffa 100755
--- a/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleDrvRuntime.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/vectorAdd_kernel.cu.hip b/src/samples/Samples/0_Introduction/simpleDrvRuntime/vectorAdd_kernel.cu.hip
index e69de29..72e20f6 100755
--- a/src/samples/Samples/0_Introduction/simpleDrvRuntime/vectorAdd_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleDrvRuntime/vectorAdd_kernel.cu.hip
@@ -0,0 +1,43 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/* Vector addition: C = A + B.
+ *
+ * This sample is a very basic sample that implements element by element
+ * vector addition. It is the same as the sample illustrating Chapter 3
+ * of the programming guide with some additions like error checking.
+ *
+ */
+
+// Device code
+extern "C" __global__ void VecAdd_kernel(const float *A, const float *B,
+                                         float *C, int N) {
+  int i = blockDim.x * blockIdx.x + threadIdx.x;
+
+  if (i < N) C[i] = A[i] + B[i];
+}
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/Makefile b/src/samples/Samples/0_Introduction/simpleHyperQ/Makefile
index f0ab130..1614068 100755
--- a/src/samples/Samples/0_Introduction/simpleHyperQ/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleHyperQ/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleHyperQ/NsightEclipse.xml
index 48f842e..1a50384 100755
--- a/src/samples/Samples/0_Introduction/simpleHyperQ/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleHyperQ/NsightEclipse.xml
@@ -49,6 +49,8 @@
     <scope>1:Performance Strategies</scope>
     <scope>1:CUDA Systems Integration</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/README.md b/src/samples/Samples/0_Introduction/simpleHyperQ/README.md
index ef2bf87..467bc4b 100755
--- a/src/samples/Samples/0_Introduction/simpleHyperQ/README.md
+++ b/src/samples/Samples/0_Introduction/simpleHyperQ/README.md
@@ -10,7 +10,7 @@ CUDA Systems Integration, Performance Strategies
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaStreamDestroy, cudaMalloc, cudaFree, cudaMallocHost, cudaEventSy
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ.out b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ.out
index cdde666..2e1dcf9 100755
Binary files a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ.out and b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ.out differ
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2017.vcxproj
index f8fb9be..d2bbd16 100755
--- a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleHyperQ.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2019.vcxproj
index c0951ca..3a6cc72 100755
--- a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleHyperQ.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2022.vcxproj
index 5ddf1a6..c15d7ee 100755
--- a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleHyperQ.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/Makefile b/src/samples/Samples/0_Introduction/simpleIPC/Makefile
index 3e94b2d..914f1ab 100755
--- a/src/samples/Samples/0_Introduction/simpleIPC/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleIPC/Makefile
@@ -305,7 +305,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleIPC/NsightEclipse.xml
index 90c207a..d25608d 100755
--- a/src/samples/Samples/0_Introduction/simpleIPC/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleIPC/NsightEclipse.xml
@@ -58,6 +58,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>1:CUDA Systems Integration</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/README.md b/src/samples/Samples/0_Introduction/simpleIPC/README.md
index ef86960..a9d3336 100755
--- a/src/samples/Samples/0_Introduction/simpleIPC/README.md
+++ b/src/samples/Samples/0_Introduction/simpleIPC/README.md
@@ -10,7 +10,7 @@ CUDA Systems Integration, Peer to Peer, InterProcess Communication
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaSetDevice, cudaIpcCloseMemHandle, cudaEventDestroy, cudaGetDeviceCount, cuda
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu
index 711d161..fee3790 100755
--- a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu
+++ b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu
@@ -41,6 +41,7 @@ static const char shmName[] = "simpleIPCshm";
 #define MAX_DEVICES (32)
 #define DATA_SIZE (64ULL << 20ULL)  // 64MB
 
+/*
 #if defined(__linux__)
 #define cpu_atomic_add32(a, x) __sync_add_and_fetch(a, x)
 #elif defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64)
@@ -48,6 +49,9 @@ static const char shmName[] = "simpleIPCshm";
 #else
 #error Unsupported system
 #endif
+*/
+#define cpu_atomic_add32(a, x) __sync_add_and_fetch(a, x)
+
 
 typedef struct shmStruct_st {
   size_t nprocesses;
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu.hip b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu.hip
index 88c2fce..b0b4730 100755
--- a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -30,6 +29,8 @@
  * This sample demonstrates Inter Process Communication
  * using one process per GPU for computation.
  */
+
+#include <hip/hip_runtime.h>
 #include <stdio.h>
 #include "rocprofiler.h"
 #include "HIPCHECK.h"
@@ -44,6 +45,7 @@ static const char shmName[] = "simpleIPCshm";
 #define MAX_DEVICES (32)
 #define DATA_SIZE (64ULL << 20ULL)  // 64MB
 
+/*
 #if defined(__linux__)
 #define cpu_atomic_add32(a, x) __sync_add_and_fetch(a, x)
 #elif defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64)
@@ -51,6 +53,9 @@ static const char shmName[] = "simpleIPCshm";
 #else
 #error Unsupported system
 #endif
+*/
+#define cpu_atomic_add32(a, x) __sync_add_and_fetch(a, x)
+
 
 typedef struct shmStruct_st {
   size_t nprocesses;
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2017.vcxproj
index 3b63846..0377143 100755
--- a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleIPC.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2019.vcxproj
index a33b06c..4d8096a 100755
--- a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleIPC.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2022.vcxproj
index 72630da..df3aba1 100755
--- a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleIPC.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/Makefile b/src/samples/Samples/0_Introduction/simpleLayeredTexture/Makefile
index dcdf456..eeb6d7e 100755
--- a/src/samples/Samples/0_Introduction/simpleLayeredTexture/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleLayeredTexture/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleLayeredTexture/NsightEclipse.xml
index d4fa449..ff2bc6f 100755
--- a/src/samples/Samples/0_Introduction/simpleLayeredTexture/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleLayeredTexture/NsightEclipse.xml
@@ -39,6 +39,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Volume Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/README.md b/src/samples/Samples/0_Introduction/simpleLayeredTexture/README.md
index d33955f..5dc0eb7 100755
--- a/src/samples/Samples/0_Introduction/simpleLayeredTexture/README.md
+++ b/src/samples/Samples/0_Introduction/simpleLayeredTexture/README.md
@@ -10,7 +10,7 @@ Texture, Volume Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaCreateChannelDesc, cudaFreeArray, cudaFree, cudaPitchedPtr, cuda
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.cu.hip b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.cu.hip
index fd880bd..c509694 100755
--- a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -49,7 +48,7 @@
 
 // includes, project
 #include "helper_cuda_hipified.h"
-#include <helper_functions.h>  // helper for shared that are common to CUDA Samples
+#include "helper_functions.h"  // helper for shared that are common to CUDA Samples
 
 static const char *sSDKname = "simpleLayeredTexture";
 
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.out b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.out
index 484e31c..b4230c6 100755
Binary files a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.out and b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.out differ
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2017.vcxproj
index 02b449c..ee1e3e4 100755
--- a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleLayeredTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2019.vcxproj
index 47e3425..3ae1a4f 100755
--- a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleLayeredTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2022.vcxproj
index a6e5df1..0d29aae 100755
--- a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleLayeredTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/Makefile b/src/samples/Samples/0_Introduction/simpleMPI/Makefile
index 4b3041f..8726e03 100755
--- a/src/samples/Samples/0_Introduction/simpleMPI/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleMPI/Makefile
@@ -337,7 +337,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
@@ -356,7 +356,7 @@ GENCODE_FLAGS += -gencode arch=compute_$(HIGHEST_SM),code=compute_$(HIGHEST_SM)
 endif
 endif
 
-ALL_CCFLAGS += --threads 0 --std=c++11 -Xcompiler -fPIE
+ALL_CCFLAGS += --threads 0 --std=c++11
 
 LIBSIZE :=
 ifneq ($(TARGET_OS),darwin)
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/README.md b/src/samples/Samples/0_Introduction/simpleMPI/README.md
index 10192bf..5e0f97f 100755
--- a/src/samples/Samples/0_Introduction/simpleMPI/README.md
+++ b/src/samples/Samples/0_Introduction/simpleMPI/README.md
@@ -10,7 +10,7 @@ CUDA Systems Integration, MPI, Multithreading
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMalloc, cudaGetLastError, cudaMemcpy, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI.cu.hip b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI.cu.hip
index e69de29..b4baff3 100755
--- a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI.cu.hip
@@ -0,0 +1,104 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/* Simple example demonstrating how to use MPI with CUDA
+*
+*  Generate some random numbers on one node.
+*  Dispatch them to all nodes.
+*  Compute their square root on each node's GPU.
+*  Compute the average of the results using MPI.
+*
+*  simpleMPI.cu: GPU part, compiled with nvcc
+*/
+
+
+#include <hip/hip_runtime.h>
+#include <iostream>
+using std::cerr;
+using std::endl;
+
+#include "simpleMPI.h"
+
+// Error handling macro
+#define CUDA_CHECK(call)                                                 \
+  if ((call) != hipSuccess) {                                           \
+    hipError_t err = hipGetLastError();                                \
+    cerr << "CUDA error calling \"" #call "\", code is " << err << endl; \
+    my_abort(err);                                                       \
+  }
+
+// Device code
+// Very simple GPU Kernel that computes square roots of input numbers
+__global__ void simpleMPIKernel(float *input, float *output) {
+  int tid = blockIdx.x * blockDim.x + threadIdx.x;
+  output[tid] = sqrt(input[tid]);
+}
+
+// Initialize an array with random data (between 0 and 1)
+void initData(float *data, int dataSize) {
+  for (int i = 0; i < dataSize; i++) {
+    data[i] = (float)rand() / RAND_MAX;
+  }
+}
+
+// CUDA computation on each node
+// No MPI here, only CUDA
+void computeGPU(float *hostData, int blockSize, int gridSize) {
+  int dataSize = blockSize * gridSize;
+
+  // Allocate data on GPU memory
+  float *deviceInputData = NULL;
+  CUDA_CHECK(hipMalloc((void **)&deviceInputData, dataSize * sizeof(float)));
+
+  float *deviceOutputData = NULL;
+  CUDA_CHECK(hipMalloc((void **)&deviceOutputData, dataSize * sizeof(float)));
+
+  // Copy to GPU memory
+  CUDA_CHECK(hipMemcpy(deviceInputData, hostData, dataSize * sizeof(float),
+                        hipMemcpyHostToDevice));
+
+  // Run kernel
+  simpleMPIKernel<<<gridSize, blockSize>>>(deviceInputData, deviceOutputData);
+
+  // Copy data back to CPU memory
+  CUDA_CHECK(hipMemcpy(hostData, deviceOutputData, dataSize * sizeof(float),
+                        hipMemcpyDeviceToHost));
+
+  // Free GPU memory
+  CUDA_CHECK(hipFree(deviceInputData));
+  CUDA_CHECK(hipFree(deviceOutputData));
+}
+
+float sum(float *data, int size) {
+  float accum = 0.f;
+
+  for (int i = 0; i < size; i++) {
+    accum += data[i];
+  }
+
+  return accum;
+}
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_hipified.cpp b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_hipified.cpp
index a72f65f..220c807 100755
--- a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_hipified.cpp
+++ b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_hipified.cpp
@@ -47,7 +47,7 @@ using std::cerr;
 using std::endl;
 
 // User include
-#include "simpleMPI.h"
+#include "simpleMPI_hipified.h"
 
 // Error handling macros
 #define MPI_CHECK(call)                          \
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2017.vcxproj
index e8facf8..94e7761 100755
--- a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleMPI.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2019.vcxproj
index fb50022..9782222 100755
--- a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleMPI.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2022.vcxproj
index 3340904..8f6ea5a 100755
--- a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleMPI.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/Makefile b/src/samples/Samples/0_Introduction/simpleMultiCopy/Makefile
index d4d006a..d6d253c 100755
--- a/src/samples/Samples/0_Introduction/simpleMultiCopy/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleMultiCopy/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleMultiCopy/NsightEclipse.xml
index 5cc3fac..bb76ce8 100755
--- a/src/samples/Samples/0_Introduction/simpleMultiCopy/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleMultiCopy/NsightEclipse.xml
@@ -53,6 +53,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/README.md b/src/samples/Samples/0_Introduction/simpleMultiCopy/README.md
index 4d33727..7240428 100755
--- a/src/samples/Samples/0_Introduction/simpleMultiCopy/README.md
+++ b/src/samples/Samples/0_Introduction/simpleMultiCopy/README.md
@@ -10,7 +10,7 @@ CUDA Streams and Events, Asynchronous Data Transfers, Overlap Compute and Copy,
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaHostAlloc, cudaStreamDestroy, cudaMalloc, cudaMemcpyAsync, cudaFree, cudaSet
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.cu.hip b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.cu.hip
index c35b52a..1be49a1 100755
--- a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.cu.hip
@@ -1,4 +1,3 @@
-
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -45,16 +44,14 @@ const char *sSDKname = "simpleMultiCopy";
 
 // includes, system
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 
 // include CUDA
-#include <hip/hip_runtime.h>
+#include "hip/hip_runtime.h"
 
 // includes, project
 #include "helper_cuda_hipified.h"
-#include <helper_functions.h>  // helper for shared that are common to CUDA Samples
-
+#include "helper_functions.h"  // helper for shared that are common to CUDA Samples
+#include "HIPCHECK.h"
 // includes, kernels
 // Declare the CUDA kernels here and main() code that is needed to launch
 // Compute workload on the system
@@ -130,12 +127,12 @@ int main(int argc, char *argv[]) {
   } else {
     // Otherwise pick the device with the highest Gflops/s
     cuda_device = gpuGetMaxGflopsDeviceId();
-    checkCudaErrors(hipSetDevice(cuda_device));
-    checkCudaErrors(hipGetDeviceProperties(&deviceProp, cuda_device));
+    HIPCHECK(hipSetDevice(cuda_device));
+    HIPCHECK(hipGetDeviceProperties(&deviceProp, cuda_device));
     printf("> Using CUDA device [%d]: %s\n", cuda_device, deviceProp.name);
   }
 
-  checkCudaErrors(hipGetDeviceProperties(&deviceProp, cuda_device));
+  HIPCHECK(hipGetDeviceProperties(&deviceProp, cuda_device));
   printf("[%s] has %d MP(s) x %d (Cores/MP) = %d (Cores)\n", deviceProp.name,
          deviceProp.multiProcessorCount,
          _ConvertSMVer2Cores(deviceProp.major, deviceProp.minor),
@@ -169,12 +166,12 @@ int main(int argc, char *argv[]) {
 
   for (int i = 0; i < STREAM_COUNT; ++i) {
     HIPCHECK(
-        hipHostAlloc(&h_data_in[i], memsize, hipHostMallocDefault));
+        hipHostMalloc((void **)&h_data_in[i], memsize, hipHostMallocDefault));
     HIPCHECK(hipMalloc(&d_data_in[i], memsize));
     HIPCHECK(hipMemset(d_data_in[i], 0, memsize));
 
     HIPCHECK(
-        hipHostAlloc(&h_data_out[i], memsize, hipHostMallocDefault));
+        hipHostMalloc((void **)&h_data_out[i], memsize, hipHostMallocDefault));
     HIPCHECK(hipMalloc(&d_data_out[i], memsize));
 
     HIPCHECK(hipStreamCreate(&stream[i]));
@@ -193,7 +190,7 @@ int main(int argc, char *argv[]) {
 
   // Time copies and kernel
   hipEventRecord(start, 0);
-  checkCudaErrors(hipMemcpyAsync(d_data_in[0], h_data_in[0], memsize,
+  HIPCHECK(hipMemcpyAsync(d_data_in[0], h_data_in[0], memsize,
                                   hipMemcpyHostToDevice, 0));
   hipEventRecord(stop, 0);
   hipEventSynchronize(stop);
@@ -202,7 +199,7 @@ int main(int argc, char *argv[]) {
   hipEventElapsedTime(&memcpy_h2d_time, start, stop);
 
   hipEventRecord(start, 0);
-  checkCudaErrors(hipMemcpyAsync(h_data_out[0], d_data_out[0], memsize,
+  HIPCHECK(hipMemcpyAsync(h_data_out[0], d_data_out[0], memsize,
                                   hipMemcpyDeviceToHost, 0));
   hipEventRecord(stop, 0);
   hipEventSynchronize(stop);
@@ -220,18 +217,20 @@ int main(int argc, char *argv[]) {
 
   printf("\n");
   printf("Relevant properties of this CUDA device\n");
+  /*
   printf(
       "(%s) Can overlap one CPU<>GPU data transfer with GPU kernel execution "
       "(device property \"deviceOverlap\")\n",
       deviceProp.deviceOverlap ? "X" : " ");
+*/
   // printf("(%s) Can execute several GPU kernels simultaneously (compute
   // capability >= 2.0)\n", deviceProp.major >= 2 ? "X": " ");
-  printf(
+ /* printf(
       "(%s) Can overlap two CPU<>GPU data transfers with GPU kernel execution\n"
       "    (Compute Capability >= 2.0 AND (Tesla product OR Quadro "
       "4000/5000/6000/K5000)\n",
       (deviceProp.major >= 2 && deviceProp.asyncEngineCount > 1) ? "X" : " ");
-
+*/
   printf("\n");
   printf("Measured timings (throughput):\n");
   printf(" Memcpy host to device\t: %f ms (%f GB/s)\n", memcpy_h2d_time,
@@ -329,16 +328,16 @@ float processWithStreams(int streams_used) {
         d_data_out[current_stream], d_data_in[current_stream], N, inner_reps);
 
     // Upload next frame
-    checkCudaErrors(
+    HIPCHECK(
         hipMemcpyAsync(d_data_in[next_stream], h_data_in[next_stream], memsize,
                         hipMemcpyHostToDevice, stream[next_stream]));
 
     // Download current frame
-    checkCudaErrors(hipMemcpyAsync(
+    HIPCHECK(hipMemcpyAsync(
         h_data_out[current_stream], d_data_out[current_stream], memsize,
         hipMemcpyDeviceToHost, stream[current_stream]));
 
-    checkCudaErrors(
+    HIPCHECK(
         hipEventRecord(cycleDone[current_stream], stream[current_stream]));
 
     current_stream = next_stream;
@@ -374,7 +373,3 @@ bool test() {
 
   return passed;
 }
-    for (int i = 0; i < N; ++i) {
-      passed &= (h_data_out[j][i] == 1);
-    }
-  }
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.out b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.out
index 04afc3c..edf43db 100755
Binary files a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.out and b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.out differ
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2017.vcxproj
index 27d8115..8fbcf08 100755
--- a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleMultiCopy.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2019.vcxproj
index 47f3e5e..1f77866 100755
--- a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleMultiCopy.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2022.vcxproj
index 2328497..447b633 100755
--- a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleMultiCopy.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/Makefile b/src/samples/Samples/0_Introduction/simpleMultiGPU/Makefile
index efeabc8..15d13dd 100755
--- a/src/samples/Samples/0_Introduction/simpleMultiGPU/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleMultiGPU/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleMultiGPU/NsightEclipse.xml
index 280f922..a1e377e 100755
--- a/src/samples/Samples/0_Introduction/simpleMultiGPU/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleMultiGPU/NsightEclipse.xml
@@ -40,6 +40,8 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/README.md b/src/samples/Samples/0_Introduction/simpleMultiGPU/README.md
index dff51ab..284904f 100755
--- a/src/samples/Samples/0_Introduction/simpleMultiGPU/README.md
+++ b/src/samples/Samples/0_Introduction/simpleMultiGPU/README.md
@@ -10,7 +10,7 @@ Asynchronous Data Transfers, CUDA Streams and Events, Multithreading, Multi-GPU
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaStreamDestroy, cudaFree, cudaMallocHost, cudaSetDevice, cudaFreeHost, cudaSt
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.cu.hip b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.cu.hip
index e69de29..3eb406b 100755
--- a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.cu.hip
@@ -0,0 +1,238 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * This application demonstrates how to use the CUDA API to use multiple GPUs,
+ * with an emphasis on simple illustration of the techniques (not on
+ * performance).
+ *
+ * Note that in order to detect multiple GPUs in your system you have to disable
+ * SLI in the nvidia control panel. Otherwise only one GPU is visible to the
+ * application. On the other side, you can still extend your desktop to screens
+ * attached to both GPUs.
+ */
+
+// System includes
+#include <stdio.h>
+#include "rocprofiler.h"
+#include "HIPCHECK.h"
+#include <assert.h>
+
+// CUDA runtime
+#include <hip/hip_runtime.h>
+
+// helper functions and utilities to work with CUDA
+#include "helper_functions.h"
+#include "helper_cuda_hipified.h"
+
+#ifndef MAX
+#define MAX(a, b) (a > b ? a : b)
+#endif
+
+#include "simpleMultiGPU.h"
+
+////////////////////////////////////////////////////////////////////////////////
+// Data configuration
+////////////////////////////////////////////////////////////////////////////////
+const int MAX_GPU_COUNT = 32;
+const int DATA_N = 1048576 * 32;
+
+////////////////////////////////////////////////////////////////////////////////
+// Simple reduction kernel.
+// Refer to the 'reduction' CUDA Sample describing
+// reduction optimization strategies
+////////////////////////////////////////////////////////////////////////////////
+__global__ static void reduceKernel(float *d_Result, float *d_Input, int N) {
+  const int tid = blockIdx.x * blockDim.x + threadIdx.x;
+  const int threadN = gridDim.x * blockDim.x;
+  float sum = 0;
+
+  for (int pos = tid; pos < N; pos += threadN) sum += d_Input[pos];
+
+  d_Result[tid] = sum;
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Program main
+////////////////////////////////////////////////////////////////////////////////
+int main(int argc, char **argv) {
+  // Solver config
+  TGPUplan plan[MAX_GPU_COUNT];
+
+  // GPU reduction results
+  float h_SumGPU[MAX_GPU_COUNT];
+
+  float sumGPU;
+  double sumCPU, diff;
+
+  int i, j, gpuBase, GPU_N;
+
+  const int BLOCK_N = 32;
+  const int THREAD_N = 256;
+  const int ACCUM_N = BLOCK_N * THREAD_N;
+
+  printf("Starting simpleMultiGPU\n");
+  HIPCHECK(hipGetDeviceCount(&GPU_N));
+
+  if (GPU_N > MAX_GPU_COUNT) {
+    GPU_N = MAX_GPU_COUNT;
+  }
+
+  printf("CUDA-capable device count: %i\n", GPU_N);
+
+  printf("Generating input data...\n\n");
+
+  // Subdividing input data across GPUs
+  // Get data sizes for each GPU
+  for (i = 0; i < GPU_N; i++) {
+    plan[i].dataN = DATA_N / GPU_N;
+  }
+
+  // Take into account "odd" data sizes
+  for (i = 0; i < DATA_N % GPU_N; i++) {
+    plan[i].dataN++;
+  }
+
+  // Assign data ranges to GPUs
+  gpuBase = 0;
+
+  for (i = 0; i < GPU_N; i++) {
+    plan[i].h_Sum = h_SumGPU + i;
+    gpuBase += plan[i].dataN;
+  }
+
+  // Create streams for issuing GPU command asynchronously and allocate memory
+  // (GPU and System page-locked)
+  for (i = 0; i < GPU_N; i++) {
+    HIPCHECK(hipSetDevice(i));
+    HIPCHECK(hipStreamCreate(&plan[i].stream));
+    // Allocate memory
+    HIPCHECK(
+        hipMalloc((void **)&plan[i].d_Data, plan[i].dataN * sizeof(float)));
+    HIPCHECK(
+        hipMalloc((void **)&plan[i].d_Sum, ACCUM_N * sizeof(float)));
+    HIPCHECK(hipHostMalloc((void **)&plan[i].h_Sum_from_device,
+                                   ACCUM_N * sizeof(float)));
+    HIPCHECK(hipHostMalloc((void **)&plan[i].h_Data,
+                                   plan[i].dataN * sizeof(float)));
+
+    for (j = 0; j < plan[i].dataN; j++) {
+      plan[i].h_Data[j] = (float)rand() / (float)RAND_MAX;
+    }
+  }
+
+  // Start timing and compute on GPU(s)
+  printf("Computing with %d GPUs...\n", GPU_N);
+  // create and start timer
+  StopWatchInterface *timer = NULL;
+  sdkCreateTimer(&timer);
+
+  // start the timer
+  sdkStartTimer(&timer);
+
+  // Copy data to GPU, launch the kernel and copy data back. All asynchronously
+  for (i = 0; i < GPU_N; i++) {
+    // Set device
+    HIPCHECK(hipSetDevice(i));
+
+    // Copy input data from CPU
+    HIPCHECK(hipMemcpyAsync(plan[i].d_Data, plan[i].h_Data,
+                                    plan[i].dataN * sizeof(float),
+                                    hipMemcpyHostToDevice, plan[i].stream));
+
+    // Perform GPU computations
+    reduceKernel<<<BLOCK_N, THREAD_N, 0, plan[i].stream>>>(
+        plan[i].d_Sum, plan[i].d_Data, plan[i].dataN);
+    getLastCudaError("reduceKernel() execution failed.\n");
+
+    // Read back GPU results
+    HIPCHECK(hipMemcpyAsync(plan[i].h_Sum_from_device, plan[i].d_Sum,
+                                    ACCUM_N * sizeof(float),
+                                    hipMemcpyDeviceToHost, plan[i].stream));
+  }
+
+  // Process GPU results
+  for (i = 0; i < GPU_N; i++) {
+    float sum;
+
+    // Set device
+    HIPCHECK(hipSetDevice(i));
+
+    // Wait for all operations to finish
+    hipStreamSynchronize(plan[i].stream);
+
+    // Finalize GPU reduction for current subvector
+    sum = 0;
+
+    for (j = 0; j < ACCUM_N; j++) {
+      sum += plan[i].h_Sum_from_device[j];
+    }
+
+    *(plan[i].h_Sum) = (float)sum;
+
+    // Shut down this GPU
+    HIPCHECK(hipHostFree(plan[i].h_Sum_from_device));
+    HIPCHECK(hipFree(plan[i].d_Sum));
+    HIPCHECK(hipFree(plan[i].d_Data));
+    HIPCHECK(hipStreamDestroy(plan[i].stream));
+  }
+
+  sumGPU = 0;
+
+  for (i = 0; i < GPU_N; i++) {
+    sumGPU += h_SumGPU[i];
+  }
+
+  sdkStopTimer(&timer);
+  printf("  GPU Processing time: %f (ms)\n\n", sdkGetTimerValue(&timer));
+  sdkDeleteTimer(&timer);
+
+  // Compute on Host CPU
+  printf("Computing with Host CPU...\n\n");
+
+  sumCPU = 0;
+
+  for (i = 0; i < GPU_N; i++) {
+    for (j = 0; j < plan[i].dataN; j++) {
+      sumCPU += plan[i].h_Data[j];
+    }
+  }
+
+  // Compare GPU and CPU results
+  printf("Comparing GPU and Host CPU results...\n");
+  diff = fabs(sumCPU - sumGPU) / fabs(sumCPU);
+  printf("  GPU sum: %f\n  CPU sum: %f\n", sumGPU, sumCPU);
+  printf("  Relative difference: %E \n\n", diff);
+
+  // Cleanup and shutdown
+  for (i = 0; i < GPU_N; i++) {
+    HIPCHECK(hipSetDevice(i));
+    HIPCHECK(hipHostFree(plan[i].h_Data));
+  }
+
+  exit((diff < 1e-5) ? EXIT_SUCCESS : EXIT_FAILURE);
+}
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.out b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.out
index 62d020b..2c25f98 100755
Binary files a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.out and b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.out differ
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2017.vcxproj
index 1c9a2b0..a025b2e 100755
--- a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleMultiGPU.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2019.vcxproj
index 3fa5781..2a6ce25 100755
--- a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleMultiGPU.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2022.vcxproj
index 4b155bb..315059c 100755
--- a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleMultiGPU.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/Makefile b/src/samples/Samples/0_Introduction/simpleOccupancy/Makefile
index 923c92e..b735ec0 100755
--- a/src/samples/Samples/0_Introduction/simpleOccupancy/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleOccupancy/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleOccupancy/NsightEclipse.xml
index ab006bd..e4383b1 100755
--- a/src/samples/Samples/0_Introduction/simpleOccupancy/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleOccupancy/NsightEclipse.xml
@@ -39,6 +39,8 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/README.md b/src/samples/Samples/0_Introduction/simpleOccupancy/README.md
index d3e0aa2..ddc12f2 100755
--- a/src/samples/Samples/0_Introduction/simpleOccupancy/README.md
+++ b/src/samples/Samples/0_Introduction/simpleOccupancy/README.md
@@ -10,7 +10,7 @@ Occupancy Calculator
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaFree, cudaDeviceSynchronize, cudaEventRecord, cudaGetDevice, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.cu.hip b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.cu.hip
index 867d277..86c8e04 100755
--- a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -26,6 +25,8 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
+
+#include <hip/hip_runtime.h>
 #include <iostream>
 #include <helper_cuda.h>  // helper functions for CUDA error check
 #include "HIPCHECK.h"
@@ -87,7 +88,7 @@ static double reportPotentialOccupancy(void *kernel, int blockSize,
 ////////////////////////////////////////////////////////////////////////////////
 // Occupancy-based launch configurator
 //
-// The launch configurator, hipOccupancyMaxPotentialBlockSize and
+// The launch configurator, cudaOccupancyMaxPotentialBlockSize and
 // cudaOccupancyMaxPotentialBlockSizeVariableSMem, suggests a block
 // size that achieves the best theoretical occupancy. It also returns
 // the minimum number of blocks needed to achieve the occupancy on the
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.out b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.out
index f941cb7..373fae7 100755
Binary files a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.out and b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.out differ
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2017.vcxproj
index a23f516..d4d97a0 100755
--- a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleOccupancy.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2019.vcxproj
index 1f9bbcc..096cea4 100755
--- a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleOccupancy.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2022.vcxproj
index 8b6eea1..57de8a5 100755
--- a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleOccupancy.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/Makefile b/src/samples/Samples/0_Introduction/simpleP2P/Makefile
index fef5e36..804aa44 100755
--- a/src/samples/Samples/0_Introduction/simpleP2P/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleP2P/Makefile
@@ -305,7 +305,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleP2P/NsightEclipse.xml
index 19b666a..65fe83b 100755
--- a/src/samples/Samples/0_Introduction/simpleP2P/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleP2P/NsightEclipse.xml
@@ -54,6 +54,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/README.md b/src/samples/Samples/0_Introduction/simpleP2P/README.md
index 519d05c..56b4b8b 100755
--- a/src/samples/Samples/0_Introduction/simpleP2P/README.md
+++ b/src/samples/Samples/0_Introduction/simpleP2P/README.md
@@ -10,7 +10,7 @@ Performance Strategies, Asynchronous Data Transfers, Unified Virtual Address Spa
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMemcpy, cudaMalloc, cudaFree, cudaMallocHost, cudaEventCreateWithFlags, cuda
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.cu.hip b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.cu.hip
index 594eea3..0beb176 100755
--- a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -41,7 +40,7 @@
 #include <hip/hip_runtime.h>
 
 // includes, project
-#include "helper_cuda_hipified.h"
+#include <helper_cuda.h>
 #include <helper_functions.h>  // helper for shared that are common to CUDA Samples
 
 __global__ void SimpleKernel(float *src, float *dst) {
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.out b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.out
index 32121a5..4049f82 100755
Binary files a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.out and b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.out differ
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2017.vcxproj
index 8d3417c..41efff1 100755
--- a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleP2P.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2019.vcxproj
index 26057cb..d51f6d7 100755
--- a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleP2P.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2022.vcxproj
index 74c8a53..9ed3216 100755
--- a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleP2P.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/Makefile b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/Makefile
index f6becf9..98218e8 100755
--- a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/Makefile
+++ b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/NsightEclipse.xml
index 367647a..be7882b 100755
--- a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/NsightEclipse.xml
@@ -41,6 +41,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>2:Image Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/README.md b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/README.md
index 6656e72..95944a8 100755
--- a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/README.md
+++ b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/README.md
@@ -10,7 +10,7 @@ Texture, Image Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMallocArray, cudaFreeArray, cudaFree, cudaMallocPitch, cudaDestroyTextureObj
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.cu.hip b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.cu.hip
index 8a6520a..38e1b2b 100755
--- a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.cu.hip
+++ b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.cu.hip
@@ -40,8 +40,6 @@
 
 // includes, system
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 
 #ifdef _WIN32
 #define WINDOWS_LEAN_AND_MEAN
@@ -312,3 +310,10 @@ void runTest(int argc, char **argv) {
   HIPCHECK(hipEventDestroy(start));
   HIPCHECK(hipEventDestroy(stop));
 }
+dataPL));
+  checkCudaErrors(hipFreeArray(d_idataArray));
+  checkCudaErrors(hipFree(d_odata));
+
+  checkCudaErrors(hipEventDestroy(start));
+  checkCudaErrors(hipEventDestroy(stop));
+}
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.out b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.out
index 5504832..8f3e98f 100755
Binary files a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.out and b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.out differ
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2017.vcxproj
index ef143fd..f33a061 100755
--- a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simplePitchLinearTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2019.vcxproj
index b3b709e..c08e4de 100755
--- a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simplePitchLinearTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2022.vcxproj
index 671e8cc..441ae1c 100755
--- a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simplePitchLinearTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/Makefile b/src/samples/Samples/0_Introduction/simplePrintf/Makefile
index 7073877..3b8cf8a 100755
--- a/src/samples/Samples/0_Introduction/simplePrintf/Makefile
+++ b/src/samples/Samples/0_Introduction/simplePrintf/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/README.md b/src/samples/Samples/0_Introduction/simplePrintf/README.md
index d54817e..872faf8 100755
--- a/src/samples/Samples/0_Introduction/simplePrintf/README.md
+++ b/src/samples/Samples/0_Introduction/simplePrintf/README.md
@@ -10,7 +10,7 @@ Debugging
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaGetDeviceProperties, cudaDeviceSynchronize, cudaGetDevice
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf.cu.hip b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf.cu.hip
index e69de29..c126bd1 100755
--- a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf.cu.hip
+++ b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf.cu.hip
@@ -0,0 +1,75 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+// System includes
+#include <stdio.h>
+//#include "rocprofiler.h"
+#include <assert.h>
+
+// CUDA runtime
+#include <hip/hip_runtime.h>
+
+// helper functions and utilities to work with CUDA
+#include "helper_functions.h"
+#include "helper_cuda_hipified.h"
+#include "HIPCHECK.h"
+
+#ifndef MAX
+#define MAX(a, b) (a > b ? a : b)
+#endif
+
+__global__ void testKernel(int val) {
+  printf("[%d, %d]:\t\tValue is:%d\n", blockIdx.y * gridDim.x + blockIdx.x,
+         threadIdx.z * blockDim.x * blockDim.y + threadIdx.y * blockDim.x +
+             threadIdx.x,
+         val);
+}
+
+int main(int argc, char **argv) {
+  int devID;
+  hipDeviceProp_t props;
+
+  // This will pick the best possible CUDA capable device
+  devID = findCudaDevice(argc, (const char **)argv);
+
+  // Get GPU information
+  HIPCHECK(hipGetDevice(&devID));
+  HIPCHECK(hipGetDeviceProperties(&props, devID));
+  printf("Device %d: \"%s\" with Compute %d.%d capability\n", devID, props.name,
+         props.major, props.minor);
+
+  printf("printf() is called. Output:\n\n");
+
+  // Kernel configuration, where a two-dimensional grid and
+  // three-dimensional blocks are configured.
+  dim3 dimGrid(2, 2);
+  dim3 dimBlock(2, 2, 2);
+  testKernel<<<dimGrid, dimBlock>>>(10);
+  hipDeviceSynchronize();
+
+  return EXIT_SUCCESS;
+}
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2017.vcxproj
index 85125a8..861f30b 100755
--- a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simplePrintf.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2019.vcxproj
index 55e557c..6dcb3c5 100755
--- a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simplePrintf.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2022.vcxproj
index 4bc405d..e45b595 100755
--- a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simplePrintf.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/Makefile b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/Makefile
index 33135b6..5ebec1d 100755
--- a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/Makefile
@@ -281,7 +281,8 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+#SMS ?= 35 37 50 52 60 61 70 75 80 86 90
+SMS ?= 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/NsightEclipse.xml
index c3df129..2f1c15a 100755
--- a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/NsightEclipse.xml
@@ -43,6 +43,8 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/README.md b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/README.md
index f456931..a4b5448 100755
--- a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/README.md
+++ b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/README.md
@@ -10,7 +10,7 @@ Separate Compilation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaMemcpyFromSymbol, cudaFree, cudaGetLastError, cudaMalloc
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary.cu.hip b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary.cu.hip
index e69de29..910c157 100755
--- a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary.cu.hip
@@ -0,0 +1,31 @@
+
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+__device__ float multiplyByTwo(float number) { return number * 2.0f; }
+
+__device__ float divideByTwo(float number) { return number * 0.5f; }
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation.cu.hip b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation.cu.hip
index 3f01638..aad2f81 100755
--- a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -30,7 +29,7 @@
 #include <stdio.h>
 //#include "rocprofiler.h"
 #include <iostream>
-#include "HIPCHECK.h"
+
 // STL.
 #include <vector>
 
@@ -38,11 +37,17 @@
 #include <hip/hip_runtime.h>
 
 // Helper functions and utilities to work with CUDA.
-#include "helper_functions.h"
 #include "helper_cuda_hipified.h"
+#include <helper_functions.h>
+#include "HIPCHECK.h"
+//#include <helper_cuda.h>
 
 // Device library includes.
-#include "simpleDeviceLibrary.cuh"
+#include "simpleDeviceLibrary_hipified.cuh"
+
+extern __device__ float multiplyByTwo(float number);
+
+extern __device__ float divideByTwo(float number);
 
 using std::cout;
 using std::endl;
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2017.vcxproj
index 36f7e09..fc05d0f 100755
--- a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleSeparateCompilation.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2019.vcxproj
index dca38bc..d6f50cf 100755
--- a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleSeparateCompilation.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2022.vcxproj
index 237e913..758766e 100755
--- a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleSeparateCompilation.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/Makefile b/src/samples/Samples/0_Introduction/simpleStreams/Makefile
index ccc2abd..0e83a30 100755
--- a/src/samples/Samples/0_Introduction/simpleStreams/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleStreams/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleStreams/NsightEclipse.xml
index d550198..d7fb6d3 100755
--- a/src/samples/Samples/0_Introduction/simpleStreams/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleStreams/NsightEclipse.xml
@@ -48,6 +48,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/README.md b/src/samples/Samples/0_Introduction/simpleStreams/README.md
index 6204176..a9de18f 100755
--- a/src/samples/Samples/0_Introduction/simpleStreams/README.md
+++ b/src/samples/Samples/0_Introduction/simpleStreams/README.md
@@ -10,7 +10,7 @@ Asynchronous Data Transfers, CUDA Streams and Events
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaSetDeviceFlags, cudaSetDevice, cudaEventDestroy, cudaStreamCreat
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams.out b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams.out
index aa0690c..5216e54 100755
Binary files a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams.out and b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams.out differ
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2017.vcxproj
index 3c68d65..b0fc51d 100755
--- a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleStreams.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2019.vcxproj
index e0e3b8a..6b96b6b 100755
--- a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleStreams.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2022.vcxproj
index f8ab342..cf0c0e4 100755
--- a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleStreams.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/Makefile b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/Makefile
index e5d1f19..7440eee 100755
--- a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/NsightEclipse.xml
index 2646a7a..4d9153c 100755
--- a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/NsightEclipse.xml
@@ -48,6 +48,8 @@
     <scope>2:Texture</scope>
     <scope>2:Image Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/README.md b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/README.md
index cf898ef..944cf2f 100755
--- a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/README.md
+++ b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/README.md
@@ -10,7 +10,7 @@ Texture, Surface Writes, Image Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaCreateChannelDesc, cudaMallocArray, cudaFreeArray, cudaFree, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.cu.hip b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.cu.hip
index 273f932..c00946a 100755
--- a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.cu.hip
@@ -37,8 +37,6 @@
 // Includes, system
 #include <stdlib.h>
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <string.h>
 #include <math.h>
 
@@ -52,10 +50,10 @@
 #include <hip/hip_runtime.h>
 
 // Utilities and timing functions
-#include "helper_functions.h"  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
-#include "HIPCHECK.h"
+#include <helper_functions.h>  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
+
 // CUDA helper functions
-#include "helper_cuda_hipified.h"  // helper functions for CUDA error check
+#include <helper_cuda.h>  // helper functions for CUDA error check
 
 #define MIN_EPSILON_ERROR 5e-3f
 
@@ -83,8 +81,8 @@ __global__ void surfaceWriteKernel(float *gIData, int width, int height,
   unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
 
   // read from global memory and write to cuarray (via surface reference)
-  surf2Dwrite(gIData[y * width + x], outputSurface, x * 4, y);
-             // hipBoundaryModeTrap);
+  surf2Dwrite(gIData[y * width + x], outputSurface, x * 4, y,
+              hipBoundaryModeTrap);
 }
 
 ////////////////////////////////////////////////////////////////////////////////
@@ -296,3 +294,8 @@ void runTest(int argc, char **argv) {
   free(imagePath);
   free(refPath);
 }
+e(dData));
+  checkCudaErrors(hipFreeArray(cuArray));
+  free(imagePath);
+  free(refPath);
+}
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.out b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.out
index bc992e7..95307f1 100755
Binary files a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.out and b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.out differ
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2017.vcxproj
index 79ea372..8a65d23 100755
--- a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleSurfaceWrite.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2019.vcxproj
index ff6dd29..d61b868 100755
--- a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleSurfaceWrite.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2022.vcxproj
index 4f61d95..d5275f3 100755
--- a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleSurfaceWrite.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/Makefile b/src/samples/Samples/0_Introduction/simpleTemplates/Makefile
index a03cacf..beac3d7 100755
--- a/src/samples/Samples/0_Introduction/simpleTemplates/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleTemplates/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleTemplates/NsightEclipse.xml
index 4a276ee..3614926 100755
--- a/src/samples/Samples/0_Introduction/simpleTemplates/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleTemplates/NsightEclipse.xml
@@ -29,6 +29,8 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/README.md b/src/samples/Samples/0_Introduction/simpleTemplates/README.md
index 758a4ae..0db6715 100755
--- a/src/samples/Samples/0_Introduction/simpleTemplates/README.md
+++ b/src/samples/Samples/0_Introduction/simpleTemplates/README.md
@@ -10,7 +10,7 @@ C++ Templates
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMalloc, cudaMemcpy, cudaGetDeviceProperties, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates.cu.hip b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates.cu.hip
index e69de29..7987e41 100755
--- a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates.cu.hip
@@ -0,0 +1,266 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/* This sample is a templatized version of the template project.
+* It also shows how to correctly templatize dynamically allocated shared
+* memory arrays.
+* Host code.
+*/
+
+// System includes
+#include <stdio.h>
+#include "rocprofiler.h"
+#include "HIPCHECK.h"
+#include <assert.h>
+#include <string.h>
+#include <math.h>
+
+// CUDA runtime
+#include <hip/hip_runtime.h>
+
+// helper functions and utilities to work with CUDA
+#include "helper_functions.h"
+#include "helper_cuda_hipified.h"
+
+#ifndef MAX
+#define MAX(a, b) (a > b ? a : b)
+#endif
+
+// includes, kernels
+#include "sharedmem.cuh"
+
+int g_TotalFailures = 0;
+
+////////////////////////////////////////////////////////////////////////////////
+//! Simple test kernel for device functionality
+//! @param g_idata  input data in global memory
+//! @param g_odata  output data in global memory
+////////////////////////////////////////////////////////////////////////////////
+template <class T>
+__global__ void testKernel(T *g_idata, T *g_odata) {
+  // Shared mem size is determined by the host app at run time
+  SharedMemory<T> smem;
+  T *sdata = smem.getPointer();
+
+  // access thread id
+  const unsigned int tid = threadIdx.x;
+  // access number of threads in this block
+  const unsigned int num_threads = blockDim.x;
+
+  // read in input data from global memory
+  sdata[tid] = g_idata[tid];
+  __syncthreads();
+
+  // perform some computations
+  sdata[tid] = (T)num_threads * sdata[tid];
+  __syncthreads();
+
+  // write data to global memory
+  g_odata[tid] = sdata[tid];
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// declaration, forward
+template <class T>
+void runTest(int argc, char **argv, int len);
+
+template <class T>
+void computeGold(T *reference, T *idata, const unsigned int len) {
+  const T T_len = static_cast<T>(len);
+
+  for (unsigned int i = 0; i < len; ++i) {
+    reference[i] = idata[i] * T_len;
+  }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Program main
+////////////////////////////////////////////////////////////////////////////////
+int main(int argc, char **argv) {
+  printf("> runTest<float,32>\n");
+  runTest<float>(argc, argv, 32);
+  printf("> runTest<int,64>\n");
+  runTest<int>(argc, argv, 64);
+
+  printf("\n[simpleTemplates] -> Test Results: %d Failures\n", g_TotalFailures);
+
+  exit(g_TotalFailures == 0 ? EXIT_SUCCESS : EXIT_FAILURE);
+}
+
+// To completely templatize runTest (below) with cutil, we need to use
+// template specialization to wrap up CUTIL's array comparison and file writing
+// functions for different types.
+
+// Here's the generic wrapper for cutCompare*
+template <class T>
+class ArrayComparator {
+ public:
+  bool compare(const T *reference, T *data, unsigned int len) {
+    fprintf(stderr,
+            "Error: no comparison function implemented for this type\n");
+    return false;
+  }
+};
+
+// Here's the specialization for ints:
+template <>
+class ArrayComparator<int> {
+ public:
+  bool compare(const int *reference, int *data, unsigned int len) {
+    return compareData(reference, data, len, 0.15f, 0.0f);
+  }
+};
+
+// Here's the specialization for floats:
+template <>
+class ArrayComparator<float> {
+ public:
+  bool compare(const float *reference, float *data, unsigned int len) {
+    return compareData(reference, data, len, 0.15f, 0.15f);
+  }
+};
+
+// Here's the generic wrapper for cutWriteFile*
+template <class T>
+class ArrayFileWriter {
+ public:
+  bool write(const char *filename, T *data, unsigned int len, float epsilon) {
+    fprintf(stderr,
+            "Error: no file write function implemented for this type\n");
+    return false;
+  }
+};
+
+// Here's the specialization for ints:
+template <>
+class ArrayFileWriter<int> {
+ public:
+  bool write(const char *filename, int *data, unsigned int len, float epsilon) {
+    return sdkWriteFile(filename, data, len, epsilon, false);
+  }
+};
+
+// Here's the specialization for floats:
+template <>
+class ArrayFileWriter<float> {
+ public:
+  bool write(const char *filename, float *data, unsigned int len,
+             float epsilon) {
+    return sdkWriteFile(filename, data, len, epsilon, false);
+  }
+};
+
+////////////////////////////////////////////////////////////////////////////////
+//! Run a simple test for CUDA
+////////////////////////////////////////////////////////////////////////////////
+template <class T>
+void runTest(int argc, char **argv, int len) {
+  int devID;
+  hipDeviceProp_t deviceProps;
+
+  devID = findCudaDevice(argc, (const char **)argv);
+
+  // get number of SMs on this GPU
+  HIPCHECK(hipGetDeviceProperties(&deviceProps, devID));
+  printf("CUDA device [%s] has %d Multi-Processors\n", deviceProps.name,
+         deviceProps.multiProcessorCount);
+
+  // create and start timer
+  StopWatchInterface *timer = NULL;
+  sdkCreateTimer(&timer);
+
+  // start the timer
+  sdkStartTimer(&timer);
+
+  unsigned int num_threads = len;
+  unsigned int mem_size = sizeof(float) * num_threads;
+
+  // allocate host memory
+  T *h_idata = (T *)malloc(mem_size);
+
+  // initialize the memory
+  for (unsigned int i = 0; i < num_threads; ++i) {
+    h_idata[i] = (T)i;
+  }
+
+  // allocate device memory
+  T *d_idata;
+  HIPCHECK(hipMalloc((void **)&d_idata, mem_size));
+  // copy host memory to device
+  HIPCHECK(
+      hipMemcpy(d_idata, h_idata, mem_size, hipMemcpyHostToDevice));
+
+  // allocate device memory for result
+  T *d_odata;
+  HIPCHECK(hipMalloc((void **)&d_odata, mem_size));
+
+  // setup execution parameters
+  dim3 grid(1, 1, 1);
+  dim3 threads(num_threads, 1, 1);
+
+  // execute the kernel
+  testKernel<T><<<grid, threads, mem_size>>>(d_idata, d_odata);
+
+  // check if kernel execution generated and error
+  getLastCudaError("Kernel execution failed");
+
+  // allocate mem for the result on host side
+  T *h_odata = (T *)malloc(mem_size);
+  // copy result from device to host
+  HIPCHECK(hipMemcpy(h_odata, d_odata, sizeof(T) * num_threads,
+                             hipMemcpyDeviceToHost));
+
+  sdkStopTimer(&timer);
+  printf("Processing time: %f (ms)\n", sdkGetTimerValue(&timer));
+  sdkDeleteTimer(&timer);
+
+  // compute reference solution
+  T *reference = (T *)malloc(mem_size);
+  computeGold<T>(reference, h_idata, num_threads);
+
+  ArrayComparator<T> comparator;
+  ArrayFileWriter<T> writer;
+
+  // check result
+  if (checkCmdLineFlag(argc, (const char **)argv, "regression")) {
+    // write file for regression test
+    writer.write("./data/regression.dat", h_odata, num_threads, 0.0f);
+  } else {
+    // custom output handling when no regression test running
+    // in this case check if the result is equivalent to the expected solution
+    bool res = comparator.compare(reference, h_odata, num_threads);
+    printf("Compare %s\n\n", (1 == res) ? "OK" : "MISMATCH");
+    g_TotalFailures += (1 != res);
+  }
+
+  // cleanup memory
+  free(h_idata);
+  free(h_odata);
+  free(reference);
+  HIPCHECK(hipFree(d_idata));
+  HIPCHECK(hipFree(d_odata));
+}
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2017.vcxproj
index 9cc5050..96cca98 100755
--- a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleTemplates.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2019.vcxproj
index ab198d9..9396903 100755
--- a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleTemplates.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2022.vcxproj
index f8bedb8..90b222b 100755
--- a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleTemplates.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/README.md b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/README.md
index 5138303..31c588e 100755
--- a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/README.md
+++ b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/README.md
@@ -10,7 +10,7 @@ C++ Templates, Runtime Compilation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cuMemcpyDtoH, cuLaunchKernel, cuMemcpyHtoD, cuCtxSynchronize, cuMemAlloc, cuMemF
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_hipified.cpp b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_hipified.cpp
index d4004b8..8a71a4d 100755
--- a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_hipified.cpp
+++ b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_hipified.cpp
@@ -43,7 +43,7 @@
 // helper functions and utilities to work with CUDA
 #include "helper_functions.h"
 #include <nvrtc_helper.h>
-
+#include "HIPCHECK.h"
 #ifndef MAX
 #define MAX(a, b) (a > b ? a : b)
 #endif
@@ -153,7 +153,7 @@ hipFunction_t getKernel(hipModule_t in);
 template <>
 hipFunction_t getKernel<int>(hipModule_t in) {
   hipFunction_t kernel_addr;
-  checkCudaErrors(hipModuleGetFunction(&kernel_addr, in, "testInt"));
+  HIPCHECK(hipModuleGetFunction(&kernel_addr, in, "testInt"));
 
   return kernel_addr;
 }
@@ -161,7 +161,7 @@ hipFunction_t getKernel<int>(hipModule_t in) {
 template <>
 hipFunction_t getKernel<float>(hipModule_t in) {
   hipFunction_t kernel_addr;
-  checkCudaErrors(hipModuleGetFunction(&kernel_addr, in, "testFloat"));
+  HIPCHECK(hipModuleGetFunction(&kernel_addr, in, "testFloat"));
 
   return kernel_addr;
 }
@@ -204,14 +204,14 @@ void runTest(int argc, char **argv, int len) {
 
   // allocate device memory
   hipDeviceptr_t d_idata;
-  checkCudaErrors(hipMalloc(&d_idata, mem_size));
+  HIPCHECK(hipMalloc(&d_idata, mem_size));
 
   // copy host memory to device
-  checkCudaErrors(hipMemcpyHtoD(d_idata, h_idata, mem_size));
+  HIPCHECK(hipMemcpyHtoD(d_idata, h_idata, mem_size));
 
   // allocate device memory for result
   hipDeviceptr_t d_odata;
-  checkCudaErrors(hipMalloc(&d_odata, mem_size));
+  HIPCHECK(hipMalloc(&d_odata, mem_size));
 
   // setup execution parameters
   dim3 grid(1, 1, 1);
@@ -221,7 +221,7 @@ void runTest(int argc, char **argv, int len) {
   hipFunction_t kernel_addr = getKernel<T>(module);
 
   void *arr[] = {(void *)&d_idata, (void *)&d_odata};
-  checkCudaErrors(
+  HIPCHECK(
       hipModuleLaunchKernel(kernel_addr, grid.x, grid.y, grid.z, /* grid dim */
                      threads.x, threads.y, threads.z,     /* block dim */
                      mem_size, 0, /* shared mem, stream */
@@ -229,13 +229,13 @@ void runTest(int argc, char **argv, int len) {
                      0));
 
   // check if kernel execution generated and error
-  checkCudaErrors(hipCtxSynchronize());
+  HIPCHECK(hipCtxSynchronize());
 
   // allocate mem for the result on host side
   T *h_odata = (T *)malloc(mem_size);
 
   // copy result from device to host
-  checkCudaErrors(hipMemcpyDtoH(h_odata, d_odata, sizeof(T) * num_threads));
+  HIPCHECK(hipMemcpyDtoH(h_odata, d_odata, sizeof(T) * num_threads));
 
   sdkStopTimer(&timer);
   printf("Processing time: %f (ms)\n", sdkGetTimerValue(&timer));
@@ -267,6 +267,6 @@ void runTest(int argc, char **argv, int len) {
   free(h_idata);
   free(h_odata);
   free(reference);
-  checkCudaErrors(hipFree(d_idata));
-  checkCudaErrors(hipFree(d_odata));
+  HIPCHECK(hipFree(d_idata));
+  HIPCHECK(hipFree(d_odata));
 }
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_kernel.cu.hip b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_kernel.cu.hip
index e69de29..89eed5d 100755
--- a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_kernel.cu.hip
@@ -0,0 +1,71 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+// includes, kernels
+#include "sharedmem.cuh"
+
+////////////////////////////////////////////////////////////////////////////////
+//! Simple test kernel for device functionality
+//! @param g_idata  input data in global memory
+//! @param g_odata  output data in global memory
+////////////////////////////////////////////////////////////////////////////////
+
+template <class T>
+__device__ void testKernel(T *g_idata, T *g_odata) {
+  // Shared mem size is determined by the host app at run time
+  SharedMemory<T> smem;
+
+  T *sdata = smem.getPointer();
+
+  // access thread id
+  const unsigned int tid = threadIdx.x;
+
+  // access number of threads in this block
+  const unsigned int num_threads = blockDim.x;
+
+  // read in input data from global memory
+  sdata[tid] = g_idata[tid];
+
+  __syncthreads();
+
+  // perform some computations
+  sdata[tid] = (T)num_threads * sdata[tid];
+
+  __syncthreads();
+
+  // write data to global memory
+  g_odata[tid] = sdata[tid];
+}
+
+extern "C" __global__ void testFloat(float *p1, float *p2) {
+  testKernel<float>(p1, p2);
+}
+
+extern "C" __global__ void testInt(int *p1, int *p2) {
+  testKernel<int>(p1, p2);
+}
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2017.vcxproj
index 1de18c4..1655b53 100755
--- a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2019.vcxproj
index d2c223e..6d28d7a 100755
--- a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2022.vcxproj
index 45df91a..0c8ae96 100755
--- a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/Makefile b/src/samples/Samples/0_Introduction/simpleTexture/Makefile
index e3bb901..e705cef 100755
--- a/src/samples/Samples/0_Introduction/simpleTexture/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleTexture/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleTexture/NsightEclipse.xml
index 4cdf5ff..0f029ae 100755
--- a/src/samples/Samples/0_Introduction/simpleTexture/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleTexture/NsightEclipse.xml
@@ -46,6 +46,8 @@
     <scope>2:Texture</scope>
     <scope>2:Image Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/README.md b/src/samples/Samples/0_Introduction/simpleTexture/README.md
index 5cf5cce..834d4ee 100755
--- a/src/samples/Samples/0_Introduction/simpleTexture/README.md
+++ b/src/samples/Samples/0_Introduction/simpleTexture/README.md
@@ -10,7 +10,7 @@ CUDA Runtime API, Texture, Image Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaCreateChannelDesc, cudaMallocArray, cudaFreeArray, cudaFree, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/data/teapot512_out.pgm b/src/samples/Samples/0_Introduction/simpleTexture/data/teapot512_out.pgm
index 75c2bd9..29bd5ee 100755
Binary files a/src/samples/Samples/0_Introduction/simpleTexture/data/teapot512_out.pgm and b/src/samples/Samples/0_Introduction/simpleTexture/data/teapot512_out.pgm differ
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture.cu.hip b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture.cu.hip
index 04999af..8ecaad0 100755
--- a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture.cu.hip
@@ -37,8 +37,6 @@
 // Includes, system
 #include <stdlib.h>
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <string.h>
 #include <math.h>
 
@@ -52,11 +50,11 @@
 #include <hip/hip_runtime.h>
 
 // Utilities and timing functions
-#include "helper_functions.h"  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
+#include <helper_functions.h>  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
 
 // CUDA helper functions
-#include "helper_cuda_hipified.h"  // helper functions for CUDA error check
-#include "HIPCHECK.h"
+#include <helper_cuda.h>  // helper functions for CUDA error check
+
 #define MAX_EPSILON_ERROR 5e-3f
 
 // Define the files that are to be save and the reference images for validation
@@ -252,3 +250,7 @@ void runTest(int argc, char **argv) {
   free(imagePath);
   free(refPath);
 }
+aErrors(hipFreeArray(cuArray));
+  free(imagePath);
+  free(refPath);
+}
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture.out b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture.out
index 25c6794..ef1daeb 100755
Binary files a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture.out and b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture.out differ
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2017.vcxproj
index 6e84e6f..c12f6f1 100755
--- a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2019.vcxproj
index f039eb5..6c76b4a 100755
--- a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2022.vcxproj
index 4429380..5562ce0 100755
--- a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/Makefile b/src/samples/Samples/0_Introduction/simpleTexture3D/Makefile
index 18c4123..f232cff 100755
--- a/src/samples/Samples/0_Introduction/simpleTexture3D/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleTexture3D/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleTexture3D/NsightEclipse.xml
index 34a12f6..5684859 100755
--- a/src/samples/Samples/0_Introduction/simpleTexture3D/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleTexture3D/NsightEclipse.xml
@@ -66,6 +66,8 @@
     <scope>2:Texture</scope>
     <scope>2:Image Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/README.md b/src/samples/Samples/0_Introduction/simpleTexture3D/README.md
index 149c347..de889b8 100755
--- a/src/samples/Samples/0_Introduction/simpleTexture3D/README.md
+++ b/src/samples/Samples/0_Introduction/simpleTexture3D/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Image Processing, 3D Textures, Surface Writes
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaFreeArray, cudaFree, cudaPitchedPtr,
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2017.vcxproj
index b330bae..ed90a63 100755
--- a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleTexture3D.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -118,6 +118,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2019.vcxproj
index dbf707d..be0fa98 100755
--- a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleTexture3D.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2022.vcxproj
index b9f6ea0..1dd427b 100755
--- a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleTexture3D.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/Makefile b/src/samples/Samples/0_Introduction/simpleTextureDrv/Makefile
index b916f6d..95ff9ff 100755
--- a/src/samples/Samples/0_Introduction/simpleTextureDrv/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleTextureDrv/Makefile
@@ -285,7 +285,7 @@ FATBIN_FILE := simpleTexture_kernel${TARGET_SIZE}.fatbin
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(GENCODE_FLAGS),)
@@ -297,8 +297,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/README.md b/src/samples/Samples/0_Introduction/simpleTextureDrv/README.md
index 7cd53f0..ee28ee7 100755
--- a/src/samples/Samples/0_Introduction/simpleTextureDrv/README.md
+++ b/src/samples/Samples/0_Introduction/simpleTextureDrv/README.md
@@ -10,7 +10,7 @@ CUDA Driver API, Texture, Image Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cuMemcpyDtoH, cuLaunchKernel, cuModuleLoadData, cuDeviceGetName, cuDeviceGetAttr
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2017.vcxproj
index 5aeb9c8..66dc7b3 100755
--- a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleTextureDrv.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2019.vcxproj
index 960d5d2..e1c4371 100755
--- a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleTextureDrv.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2022.vcxproj
index ca277c6..21cf1f3 100755
--- a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleTextureDrv.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTexture_kernel.cu.hip b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTexture_kernel.cu.hip
index e69de29..d878b25 100755
--- a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTexture_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTexture_kernel.cu.hip
@@ -0,0 +1,56 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef _SIMPLETEXTURE_KERNEL_H_
+#define _SIMPLETEXTURE_KERNEL_H_
+#include <hip/hip_runtime.h>
+
+////////////////////////////////////////////////////////////////////////////////
+//! Transform an image using texture lookups
+//! @param g_odata  output data in global memory
+////////////////////////////////////////////////////////////////////////////////
+extern "C" __global__ void transformKernel(float *g_odata, int width,
+                                           int height, float theta,
+                                           hipTextureObject_t tex) {
+  // calculate normalized texture coordinates
+  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
+  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
+
+  float u = (float)x - (float)width / 2;
+  float v = (float)y - (float)height / 2;
+  float tu = u * cosf(theta) - v * sinf(theta);
+  float tv = v * cosf(theta) + u * sinf(theta);
+
+  tu /= (float)width;
+  tv /= (float)height;
+
+  // read from texture and write to global memory
+  g_odata[y * width + x] = tex2D<float>(tex, tu + 0.5f, tv + 0.5f);
+}
+
+#endif  // #ifndef _SIMPLETEXTURE_KERNEL_H_
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/Makefile b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/Makefile
index b7aef85..32edcf7 100755
--- a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/NsightEclipse.xml
index 2e70125..e91b971 100755
--- a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/NsightEclipse.xml
@@ -33,6 +33,8 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/README.md b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/README.md
index 0f20ab5..9c86c63 100755
--- a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/README.md
+++ b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/README.md
@@ -10,7 +10,7 @@ Vote Intrinsics
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaFree, cudaDeviceSynchronize, cudaMalloc, cudaGetDeviceProperties
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics.cu.hip b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics.cu.hip
index 750f0c1..7e6e57f 100755
--- a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics.cu.hip
@@ -35,7 +35,7 @@
 // helper functions and utilities to work with CUDA
 #include "helper_cuda_hipified.h"
 #include "helper_functions.h"
-//#include <hipify/__clang_cuda_intrinsics.h>
+
 #ifndef MAX
 #define MAX(a, b) (a > b ? a : b)
 #endif
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2017.vcxproj
index 67573c9..d9045a5 100755
--- a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleVoteIntrinsics.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2019.vcxproj
index 8f568d7..3bcc147 100755
--- a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleVoteIntrinsics.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2022.vcxproj
index 1b0352a..3af7fc2 100755
--- a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleVoteIntrinsics.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/README.md b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/README.md
index 23fcf2d..2f4cdeb 100755
--- a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/README.md
+++ b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/README.md
@@ -10,7 +10,7 @@ Vote Intrinsics, CUDA Driver API, Runtime Compilation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cuMemcpyDtoH, cuLaunchKernel, cuMemcpyHtoD, cuCtxSynchronize, cuMemAlloc, cuMemF
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2017.vcxproj
index 819ab5f..0d541d1 100755
--- a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2019.vcxproj
index d915564..2c334e5 100755
--- a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2022.vcxproj
index 4d3d8cc..69dbd96 100755
--- a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/Makefile b/src/samples/Samples/0_Introduction/simpleZeroCopy/Makefile
index 2aed966..3161f90 100755
--- a/src/samples/Samples/0_Introduction/simpleZeroCopy/Makefile
+++ b/src/samples/Samples/0_Introduction/simpleZeroCopy/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleZeroCopy/NsightEclipse.xml
index e69efda..a5776e5 100755
--- a/src/samples/Samples/0_Introduction/simpleZeroCopy/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/simpleZeroCopy/NsightEclipse.xml
@@ -38,6 +38,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/README.md b/src/samples/Samples/0_Introduction/simpleZeroCopy/README.md
index 52d22d2..a2f5acc 100755
--- a/src/samples/Samples/0_Introduction/simpleZeroCopy/README.md
+++ b/src/samples/Samples/0_Introduction/simpleZeroCopy/README.md
@@ -10,7 +10,7 @@ Performance Strategies, Pinned System Paged Memory, Vector Addition
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaHostAlloc, cudaSetDeviceFlags, cudaHostRegister, cudaSetDevice, cudaGetDevic
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.cu.hip b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.cu.hip
index a59ca37..e6ad156 100755
--- a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.cu.hip
@@ -36,7 +36,7 @@
 // helper functions and utilities to work with CUDA
 #include "helper_cuda_hipified.h"
 #include "helper_functions.h"
-
+#define CUDART_VERSION 3020
 #ifndef MAX
 #define MAX(a, b) (a > b ? a : b)
 #endif
@@ -243,7 +243,3 @@ int main(int argc, char **argv) {
 
   exit(errorNorm / refNorm < 1.e-6f ? EXIT_SUCCESS : EXIT_FAILURE);
 }
-HostFree(b));
-    checkCudaErrors(hipHostFree(c));
-#endif
-  }
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.out b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.out
index 1d02889..ad500c7 100755
Binary files a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.out and b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.out differ
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2017.vcxproj
index a3ad4b8..b7e0b9c 100755
--- a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleZeroCopy.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2019.vcxproj
index 4f274b9..c7a9dae 100755
--- a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleZeroCopy.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2022.vcxproj
index 26af7cf..2970958 100755
--- a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleZeroCopy.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/systemWideAtomics/README.md b/src/samples/Samples/0_Introduction/systemWideAtomics/README.md
index cdd3d2c..98f2a06 100755
--- a/src/samples/Samples/0_Introduction/systemWideAtomics/README.md
+++ b/src/samples/Samples/0_Introduction/systemWideAtomics/README.md
@@ -30,7 +30,7 @@ cudaDeviceSynchronize, cudaMallocManaged, cudaGetDeviceProperties, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/systemWideAtomics/systemWideAtomics.cu.hip b/src/samples/Samples/0_Introduction/systemWideAtomics/systemWideAtomics.cu.hip
index d226320..0f3196d 100755
--- a/src/samples/Samples/0_Introduction/systemWideAtomics/systemWideAtomics.cu.hip
+++ b/src/samples/Samples/0_Introduction/systemWideAtomics/systemWideAtomics.cu.hip
@@ -36,7 +36,7 @@
 #include <stdint.h>
 #include <cstdio>
 #include <ctime>
-#include "HIPCHECK.h"
+
 #define min(a, b) (a) < (b) ? (a) : (b)
 #define max(a, b) (a) > (b) ? (a) : (b)
 
@@ -59,13 +59,10 @@ __global__ void atomicKernel(int *atom_arr) {
     atomicMin_system(&atom_arr[3], tid);
 
     // Atomic increment (modulo 17+1)
-    //atomicInc_system((unsigned int *)&atom_arr[4], 17);
-    atomicInc((unsigned int *)&atom_arr[4], 17);
-
+    atomicInc_system((unsigned int *)&atom_arr[4], 17);
 
     // Atomic decrement
-    //atomicDec_system((unsigned int *)&atom_arr[5], 137);
-    atomicDec((unsigned int *)&atom_arr[4], 17);
+    atomicDec_system((unsigned int *)&atom_arr[5], 137);
 
     // Atomic compare-and-swap
     atomicCAS_system(&atom_arr[6], tid - 1, tid);
@@ -283,7 +280,7 @@ int main(int argc, char **argv) {
   // set device
   hipDeviceProp_t device_prop;
   int dev_id = findCudaDevice(argc, (const char **)argv);
-  checkCudaErrors(hipGetDeviceProperties(&device_prop, dev_id));
+  HIPCHECK(hipGetDeviceProperties(&device_prop, dev_id));
 
   if (!device_prop.managedMemory) {
     // This samples requires being run on a device that supports Unified Memory
@@ -318,7 +315,7 @@ int main(int argc, char **argv) {
     atom_arr = (int *)malloc(sizeof(int) * numData);
   } else {
     printf("CANNOT access pageable memory\n");
-    checkCudaErrors(hipMallocManaged(&atom_arr, sizeof(int) * numData));
+    HIPCHECK(hipMallocManaged(&atom_arr, sizeof(int) * numData));
   }
 
   for (unsigned int i = 0; i < numData; i++) atom_arr[i] = 0;
@@ -329,7 +326,7 @@ int main(int argc, char **argv) {
   atomicKernel<<<numBlocks, numThreads>>>(atom_arr);
   atomicKernel_CPU(atom_arr, numBlocks * numThreads);
 
-  checkCudaErrors(hipDeviceSynchronize());
+  HIPCHECK(hipDeviceSynchronize());
 
   // Compute & verify reference solution
   int testResult = verify(atom_arr, 2 * numThreads * numBlocks);
diff --git a/src/samples/Samples/0_Introduction/template/Makefile b/src/samples/Samples/0_Introduction/template/Makefile
index 9ba665a..47f3796 100755
--- a/src/samples/Samples/0_Introduction/template/Makefile
+++ b/src/samples/Samples/0_Introduction/template/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/template/NsightEclipse.xml b/src/samples/Samples/0_Introduction/template/NsightEclipse.xml
index bae8123..21fe74f 100755
--- a/src/samples/Samples/0_Introduction/template/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/template/NsightEclipse.xml
@@ -28,6 +28,8 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/template/README.md b/src/samples/Samples/0_Introduction/template/README.md
index 4536081..f224456 100755
--- a/src/samples/Samples/0_Introduction/template/README.md
+++ b/src/samples/Samples/0_Introduction/template/README.md
@@ -10,7 +10,7 @@ Device Memory Allocation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMalloc, cudaMemcpy, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/template/template.cu.hip b/src/samples/Samples/0_Introduction/template/template.cu.hip
index 366a3a8..c929826 100755
--- a/src/samples/Samples/0_Introduction/template/template.cu.hip
+++ b/src/samples/Samples/0_Introduction/template/template.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -44,7 +43,7 @@
 
 // includes, project
 #include "helper_cuda_hipified.h"
-#include <helper_functions.h> // helper functions for SDK examples
+#include "helper_functions.h" // helper functions for SDK examples
 
 ////////////////////////////////////////////////////////////////////////////////
 // declaration, forward
diff --git a/src/samples/Samples/0_Introduction/template/template.out b/src/samples/Samples/0_Introduction/template/template.out
index 5cb4f8a..0006e7b 100755
Binary files a/src/samples/Samples/0_Introduction/template/template.out and b/src/samples/Samples/0_Introduction/template/template.out differ
diff --git a/src/samples/Samples/0_Introduction/template/template_cpu.cpp b/src/samples/Samples/0_Introduction/template/template_cpu.cpp
index 1e7c9f1..2140a9c 100755
--- a/src/samples/Samples/0_Introduction/template/template_cpu.cpp
+++ b/src/samples/Samples/0_Introduction/template/template_cpu.cpp
@@ -1,45 +1,45 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// export C interface
-extern "C" void computeGold(float *reference, float *idata,
-                            const unsigned int len);
-
-////////////////////////////////////////////////////////////////////////////////
-//! Compute reference data set
-//! Each element is multiplied with the number of threads / array length
-//! @param reference  reference data, computed but preallocated
-//! @param idata      input data as provided to device
-//! @param len        number of elements in reference / idata
-////////////////////////////////////////////////////////////////////////////////
-void computeGold(float *reference, float *idata, const unsigned int len) {
-  const float f_len = static_cast<float>(len);
-
-  for (unsigned int i = 0; i < len; ++i) {
-    reference[i] = idata[i] * f_len;
-  }
-}
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+// export C interface
+extern "C" void computeGold(float *reference, float *idata,
+                            const unsigned int len);
+
+////////////////////////////////////////////////////////////////////////////////
+//! Compute reference data set
+//! Each element is multiplied with the number of threads / array length
+//! @param reference  reference data, computed but preallocated
+//! @param idata      input data as provided to device
+//! @param len        number of elements in reference / idata
+////////////////////////////////////////////////////////////////////////////////
+void computeGold(float *reference, float *idata, const unsigned int len) {
+  const float f_len = static_cast<float>(len);
+
+  for (unsigned int i = 0; i < len; ++i) {
+    reference[i] = idata[i] * f_len;
+  }
+}
diff --git a/src/samples/Samples/0_Introduction/template/template_vs2017.vcxproj b/src/samples/Samples/0_Introduction/template/template_vs2017.vcxproj
index 4664e43..5e43678 100755
--- a/src/samples/Samples/0_Introduction/template/template_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/template/template_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/template.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/template/template_vs2019.vcxproj b/src/samples/Samples/0_Introduction/template/template_vs2019.vcxproj
index 88aff51..f736fc2 100755
--- a/src/samples/Samples/0_Introduction/template/template_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/template/template_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/template.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/template/template_vs2022.vcxproj b/src/samples/Samples/0_Introduction/template/template_vs2022.vcxproj
index 2180293..6a6d874 100755
--- a/src/samples/Samples/0_Introduction/template/template_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/template/template_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/template.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/Makefile b/src/samples/Samples/0_Introduction/vectorAdd/Makefile
index e687cbc..62be149 100755
--- a/src/samples/Samples/0_Introduction/vectorAdd/Makefile
+++ b/src/samples/Samples/0_Introduction/vectorAdd/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/NsightEclipse.xml b/src/samples/Samples/0_Introduction/vectorAdd/NsightEclipse.xml
index 19d9a3b..353acee 100755
--- a/src/samples/Samples/0_Introduction/vectorAdd/NsightEclipse.xml
+++ b/src/samples/Samples/0_Introduction/vectorAdd/NsightEclipse.xml
@@ -33,6 +33,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/README.md b/src/samples/Samples/0_Introduction/vectorAdd/README.md
index ea0d4f5..9952316 100755
--- a/src/samples/Samples/0_Introduction/vectorAdd/README.md
+++ b/src/samples/Samples/0_Introduction/vectorAdd/README.md
@@ -10,7 +10,7 @@ CUDA Runtime API, Vector Addition
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaGetErrorString, cudaFree, cudaGetLastError, cudaMalloc
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd.cu.hip b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd.cu.hip
index e69de29..7d24050 100755
--- a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd.cu.hip
+++ b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd.cu.hip
@@ -0,0 +1,212 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/**
+ * Vector addition: C = A + B.
+ *
+ * This sample is a very basic sample that implements element by element
+ * vector addition. It is the same as the sample illustrating Chapter 2
+ * of the programming guide with some additions like error checking.
+ */
+
+#include <stdio.h>
+#include "rocprofiler.h"
+#include "HIPCHECK.h"
+
+// For the CUDA runtime routines (prefixed with "cuda_")
+#include <hip/hip_runtime.h>
+
+#include <helper_cuda.h>
+/**
+ * CUDA Kernel Device code
+ *
+ * Computes the vector addition of A and B into C. The 3 vectors have the same
+ * number of elements numElements.
+ */
+__global__ void vectorAdd(const float *A, const float *B, float *C,
+                          int numElements) {
+  int i = blockDim.x * blockIdx.x + threadIdx.x;
+
+  if (i < numElements) {
+    C[i] = A[i] + B[i] + 0.0f;
+  }
+}
+
+/**
+ * Host main routine
+ */
+int main(void) {
+  // Error code to check return values for CUDA calls
+  hipError_t err = hipSuccess;
+
+  // Print the vector length to be used, and compute its size
+  int numElements = 50000;
+  size_t size = numElements * sizeof(float);
+  printf("[Vector addition of %d elements]\n", numElements);
+
+  // Allocate the host input vector A
+  float *h_A = (float *)malloc(size);
+
+  // Allocate the host input vector B
+  float *h_B = (float *)malloc(size);
+
+  // Allocate the host output vector C
+  float *h_C = (float *)malloc(size);
+
+  // Verify that allocations succeeded
+  if (h_A == NULL || h_B == NULL || h_C == NULL) {
+    fprintf(stderr, "Failed to allocate host vectors!\n");
+    exit(EXIT_FAILURE);
+  }
+
+  // Initialize the host input vectors
+  for (int i = 0; i < numElements; ++i) {
+    h_A[i] = rand() / (float)RAND_MAX;
+    h_B[i] = rand() / (float)RAND_MAX;
+  }
+
+  // Allocate the device input vector A
+  float *d_A = NULL;
+  err = hipMalloc((void **)&d_A, size);
+
+  if (err != hipSuccess) {
+    fprintf(stderr, "Failed to allocate device vector A (error code %s)!\n",
+            hipGetErrorString(err));
+    exit(EXIT_FAILURE);
+  }
+
+  // Allocate the device input vector B
+  float *d_B = NULL;
+  err = hipMalloc((void **)&d_B, size);
+
+  if (err != hipSuccess) {
+    fprintf(stderr, "Failed to allocate device vector B (error code %s)!\n",
+            hipGetErrorString(err));
+    exit(EXIT_FAILURE);
+  }
+
+  // Allocate the device output vector C
+  float *d_C = NULL;
+  err = hipMalloc((void **)&d_C, size);
+
+  if (err != hipSuccess) {
+    fprintf(stderr, "Failed to allocate device vector C (error code %s)!\n",
+            hipGetErrorString(err));
+    exit(EXIT_FAILURE);
+  }
+
+  // Copy the host input vectors A and B in host memory to the device input
+  // vectors in
+  // device memory
+  printf("Copy input data from the host memory to the CUDA device\n");
+  err = hipMemcpy(d_A, h_A, size, hipMemcpyHostToDevice);
+
+  if (err != hipSuccess) {
+    fprintf(stderr,
+            "Failed to copy vector A from host to device (error code %s)!\n",
+            hipGetErrorString(err));
+    exit(EXIT_FAILURE);
+  }
+
+  err = hipMemcpy(d_B, h_B, size, hipMemcpyHostToDevice);
+
+  if (err != hipSuccess) {
+    fprintf(stderr,
+            "Failed to copy vector B from host to device (error code %s)!\n",
+            hipGetErrorString(err));
+    exit(EXIT_FAILURE);
+  }
+
+  // Launch the Vector Add CUDA Kernel
+  int threadsPerBlock = 256;
+  int blocksPerGrid = (numElements + threadsPerBlock - 1) / threadsPerBlock;
+  printf("CUDA kernel launch with %d blocks of %d threads\n", blocksPerGrid,
+         threadsPerBlock);
+  vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, numElements);
+  err = hipGetLastError();
+
+  if (err != hipSuccess) {
+    fprintf(stderr, "Failed to launch vectorAdd kernel (error code %s)!\n",
+            hipGetErrorString(err));
+    exit(EXIT_FAILURE);
+  }
+
+  // Copy the device result vector in device memory to the host result vector
+  // in host memory.
+  printf("Copy output data from the CUDA device to the host memory\n");
+  err = hipMemcpy(h_C, d_C, size, hipMemcpyDeviceToHost);
+
+  if (err != hipSuccess) {
+    fprintf(stderr,
+            "Failed to copy vector C from device to host (error code %s)!\n",
+            hipGetErrorString(err));
+    exit(EXIT_FAILURE);
+  }
+
+  // Verify that the result vector is correct
+  for (int i = 0; i < numElements; ++i) {
+    if (fabs(h_A[i] + h_B[i] - h_C[i]) > 1e-5) {
+      fprintf(stderr, "Result verification failed at element %d!\n", i);
+      exit(EXIT_FAILURE);
+    }
+  }
+
+  printf("Test PASSED\n");
+
+  // Free device global memory
+  err = hipFree(d_A);
+
+  if (err != hipSuccess) {
+    fprintf(stderr, "Failed to free device vector A (error code %s)!\n",
+            hipGetErrorString(err));
+    exit(EXIT_FAILURE);
+  }
+
+  err = hipFree(d_B);
+
+  if (err != hipSuccess) {
+    fprintf(stderr, "Failed to free device vector B (error code %s)!\n",
+            hipGetErrorString(err));
+    exit(EXIT_FAILURE);
+  }
+
+  err = hipFree(d_C);
+
+  if (err != hipSuccess) {
+    fprintf(stderr, "Failed to free device vector C (error code %s)!\n",
+            hipGetErrorString(err));
+    exit(EXIT_FAILURE);
+  }
+
+  // Free host memory
+  free(h_A);
+  free(h_B);
+  free(h_C);
+
+  printf("Done\n");
+  return 0;
+}
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2017.vcxproj b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2017.vcxproj
index d357fdc..e8af314 100755
--- a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/vectorAdd.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2019.vcxproj b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2019.vcxproj
index ca54985..a25492e 100755
--- a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/vectorAdd.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2022.vcxproj b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2022.vcxproj
index 9163923..c983b88 100755
--- a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/vectorAdd.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/Makefile b/src/samples/Samples/0_Introduction/vectorAddDrv/Makefile
index 9288498..472417b 100755
--- a/src/samples/Samples/0_Introduction/vectorAddDrv/Makefile
+++ b/src/samples/Samples/0_Introduction/vectorAddDrv/Makefile
@@ -285,7 +285,7 @@ FATBIN_FILE := vectorAdd_kernel${TARGET_SIZE}.fatbin
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(GENCODE_FLAGS),)
@@ -297,8 +297,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/README.md b/src/samples/Samples/0_Introduction/vectorAddDrv/README.md
index 2d52221..ac26085 100755
--- a/src/samples/Samples/0_Introduction/vectorAddDrv/README.md
+++ b/src/samples/Samples/0_Introduction/vectorAddDrv/README.md
@@ -10,7 +10,7 @@ CUDA Driver API, Vector Addition
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cuMemcpyDtoH, cuLaunchKernel, cuMemcpyHtoD, cuModuleLoadData, cuCtxSynchronize,
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_hipified.cpp b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_hipified.cpp
index bb9bb71..21a9a29 100755
--- a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_hipified.cpp
+++ b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_hipified.cpp
@@ -43,7 +43,8 @@
 // includes, project
 #include <helper_cuda_drvapi.h>
 #include "helper_functions.h"
-
+#include "helper_cuda_hipified.h"
+#include "HIPCHECK.h"
 // includes, CUDA
 #include <builtin_types.h>
 
@@ -78,11 +79,11 @@ int main(int argc, char **argv) {
   size_t size = N * sizeof(float);
 
   // Initialize
-  checkCudaErrors(hipInit(0));
+  HIPCHECK(hipInit(0));
 
   cuDevice = findCudaDeviceDRV(argc, (const char **)argv);
   // Create context
-  checkCudaErrors(hipCtxCreate(&cuContext, 0, cuDevice));
+  HIPCHECK(hipCtxCreate(&cuContext, 0, cuDevice));
 
   // first search for the module path before we load the results
   string module_path;
@@ -101,10 +102,10 @@ int main(int argc, char **argv) {
   }
 
   // Create module from binary file (FATBIN)
-  checkCudaErrors(hipModuleLoadData(&cuModule, fatbin.str().c_str()));
+  HIPCHECK(hipModuleLoadData(&cuModule, fatbin.str().c_str()));
 
   // Get function handle from module
-  checkCudaErrors(
+  HIPCHECK(
       hipModuleGetFunction(&vecAdd_kernel, cuModule, "VecAdd_kernel"));
 
   // Allocate input vectors h_A and h_B in host memory
@@ -117,16 +118,16 @@ int main(int argc, char **argv) {
   RandomInit(h_B, N);
 
   // Allocate vectors in device memory
-  checkCudaErrors(hipMalloc(&d_A, size));
+  HIPCHECK(hipMalloc(&d_A, size));
 
-  checkCudaErrors(hipMalloc(&d_B, size));
+  HIPCHECK(hipMalloc(&d_B, size));
 
-  checkCudaErrors(hipMalloc(&d_C, size));
+  HIPCHECK(hipMalloc(&d_C, size));
 
   // Copy vectors from host memory to device memory
-  checkCudaErrors(hipMemcpyHtoD(d_A, h_A, size));
+  HIPCHECK(hipMemcpyHtoD(d_A, h_A, size));
 
-  checkCudaErrors(hipMemcpyHtoD(d_B, h_B, size));
+  HIPCHECK(hipMemcpyHtoD(d_B, h_B, size));
 
   if (1) {
     // This is the new CUDA 4.0 API for Kernel Parameter Passing and Kernel
@@ -139,7 +140,7 @@ int main(int argc, char **argv) {
     void *args[] = {&d_A, &d_B, &d_C, &N};
 
     // Launch the CUDA kernel
-    checkCudaErrors(hipModuleLaunchKernel(vecAdd_kernel, blocksPerGrid, 1, 1,
+    HIPCHECK(hipModuleLaunchKernel(vecAdd_kernel, blocksPerGrid, 1, 1,
                                    threadsPerBlock, 1, 1, 0, NULL, args, NULL));
   } else {
     // This is the new CUDA 4.0 API for Kernel Parameter Passing and Kernel
@@ -160,18 +161,18 @@ int main(int argc, char **argv) {
     int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;
 
     // Launch the CUDA kernel
-    checkCudaErrors(hipModuleLaunchKernel(vecAdd_kernel, blocksPerGrid, 1, 1,
+    HIPCHECK(hipModuleLaunchKernel(vecAdd_kernel, blocksPerGrid, 1, 1,
                                    threadsPerBlock, 1, 1, 0, NULL, NULL,
                                    argBuffer));
   }
 
 #ifdef _DEBUG
-  checkCudaErrors(hipCtxSynchronize());
+  HIPCHECK(hipCtxSynchronize());
 #endif
 
   // Copy result from device memory to host memory
   // h_C contains the result in host memory
-  checkCudaErrors(hipMemcpyDtoH(h_C, d_C, size));
+  HIPCHECK(hipMemcpyDtoH(h_C, d_C, size));
 
   // Verify result
   int i;
@@ -192,9 +193,9 @@ int main(int argc, char **argv) {
 
 int CleanupNoFailure() {
   // Free device memory
-  checkCudaErrors(hipFree(d_A));
-  checkCudaErrors(hipFree(d_B));
-  checkCudaErrors(hipFree(d_C));
+  HIPCHECK(hipFree(d_A));
+  HIPCHECK(hipFree(d_B));
+  HIPCHECK(hipFree(d_C));
 
   // Free host memory
   if (h_A) {
@@ -209,7 +210,7 @@ int CleanupNoFailure() {
     free(h_C);
   }
 
-  checkCudaErrors(hipCtxDestroy(cuContext));
+  HIPCHECK(hipCtxDestroy(cuContext));
 
   return EXIT_SUCCESS;
 }
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2017.vcxproj b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2017.vcxproj
index 556f1c3..57b0669 100755
--- a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/vectorAddDrv.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2019.vcxproj b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2019.vcxproj
index e8dfdd3..c48b9e1 100755
--- a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/vectorAddDrv.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2022.vcxproj b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2022.vcxproj
index def3596..4f04109 100755
--- a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/vectorAddDrv.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAdd_kernel.cu.hip b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAdd_kernel.cu.hip
index e69de29..8c2afb9 100755
--- a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAdd_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAdd_kernel.cu.hip
@@ -0,0 +1,42 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+/* Vector addition: C = A + B.
+ *
+ * This sample is a very basic sample that implements element by element
+ * vector addition. It is the same as the sample illustrating Chapter 3
+ * of the programming guide with some additions like error checking.
+ *
+ */
+
+// Device code
+extern "C" __global__ void VecAdd_kernel(const float *A, const float *B,
+                                         float *C, int N) {
+  int i = blockDim.x * blockIdx.x + threadIdx.x;
+
+  if (i < N) C[i] = A[i] + B[i];
+}
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/Makefile b/src/samples/Samples/0_Introduction/vectorAddMMAP/Makefile
index 9e81293..743d2bd 100755
--- a/src/samples/Samples/0_Introduction/vectorAddMMAP/Makefile
+++ b/src/samples/Samples/0_Introduction/vectorAddMMAP/Makefile
@@ -309,7 +309,7 @@ FATBIN_FILE := vectorAdd_kernel${TARGET_SIZE}.fatbin
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(GENCODE_FLAGS),)
@@ -321,8 +321,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/README.md b/src/samples/Samples/0_Introduction/vectorAddMMAP/README.md
index 62a7aa4..6dbbcae 100755
--- a/src/samples/Samples/0_Introduction/vectorAddMMAP/README.md
+++ b/src/samples/Samples/0_Introduction/vectorAddMMAP/README.md
@@ -10,7 +10,7 @@ CUDA Driver API, Vector Addition, MMAP
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cuMemcpyDtoH, cuDeviceCanAccessPeer, cuModuleGetFunction, cuMemSetAccess, cuMemR
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2017.vcxproj b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2017.vcxproj
index 7adcfb4..00641d9 100755
--- a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/vectorAddMMAP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -112,6 +112,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2019.vcxproj b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2019.vcxproj
index 23ee1d4..a488508 100755
--- a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/vectorAddMMAP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2022.vcxproj b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2022.vcxproj
index 236de35..59ad3c8 100755
--- a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/vectorAddMMAP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAdd_kernel.cu.hip b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAdd_kernel.cu.hip
index e69de29..72e20f6 100755
--- a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAdd_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAdd_kernel.cu.hip
@@ -0,0 +1,43 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/* Vector addition: C = A + B.
+ *
+ * This sample is a very basic sample that implements element by element
+ * vector addition. It is the same as the sample illustrating Chapter 3
+ * of the programming guide with some additions like error checking.
+ *
+ */
+
+// Device code
+extern "C" __global__ void VecAdd_kernel(const float *A, const float *B,
+                                         float *C, int N) {
+  int i = blockDim.x * blockIdx.x + threadIdx.x;
+
+  if (i < N) C[i] = A[i] + B[i];
+}
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/README.md b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/README.md
index 26b3ca3..03ed2a7 100755
--- a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/README.md
+++ b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/README.md
@@ -10,7 +10,7 @@ CUDA Driver API, Vector Addition, Runtime Compilation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaBlockSize, cudaGridSize
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_kernel.cu.hip b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_kernel.cu.hip
index e69de29..bb459dd 100755
--- a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_kernel.cu.hip
@@ -0,0 +1,43 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/**
+ * CUDA Kernel Device code
+ *
+ * Computes the vector addition of A and B into C. The 3 vectors have the same
+ * number of elements numElements.
+ */
+
+extern "C" __global__ void vectorAdd(const float *A, const float *B, float *C,
+                                     int numElements) {
+  int i = blockDim.x * blockIdx.x + threadIdx.x;
+
+  if (i < numElements) {
+    C[i] = A[i] + B[i];
+  }
+}
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2017.vcxproj b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2017.vcxproj
index 60994e4..1ad04a6 100755
--- a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2017.vcxproj
+++ b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2019.vcxproj b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2019.vcxproj
index 08515aa..e140f5e 100755
--- a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2019.vcxproj
+++ b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2022.vcxproj b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2022.vcxproj
index 57bccff..a575fb8 100755
--- a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2022.vcxproj
+++ b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/Makefile b/src/samples/Samples/1_Utilities/bandwidthTest/Makefile
index ffaecea..8699a8b 100755
--- a/src/samples/Samples/1_Utilities/bandwidthTest/Makefile
+++ b/src/samples/Samples/1_Utilities/bandwidthTest/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/NsightEclipse.xml b/src/samples/Samples/1_Utilities/bandwidthTest/NsightEclipse.xml
index 9025af0..6078a76 100755
--- a/src/samples/Samples/1_Utilities/bandwidthTest/NsightEclipse.xml
+++ b/src/samples/Samples/1_Utilities/bandwidthTest/NsightEclipse.xml
@@ -45,6 +45,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/README.md b/src/samples/Samples/1_Utilities/bandwidthTest/README.md
index 8a2f0da..2cf0bad 100755
--- a/src/samples/Samples/1_Utilities/bandwidthTest/README.md
+++ b/src/samples/Samples/1_Utilities/bandwidthTest/README.md
@@ -10,7 +10,7 @@ CUDA Streams and Events, Performance Strategies
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaHostAlloc, cudaMemcpy, cudaMalloc, cudaMemcpyAsync, cudaFree, cudaGetErrorSt
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.cu.hip b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.cu.hip
index c8bfb2f..a80025b 100755
--- a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.cu.hip
+++ b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.cu.hip
@@ -42,7 +42,7 @@
 #include <helper_cuda.h>  // helper functions for CUDA error checking and initialization
 #include <helper_functions.h>  // helper for shared functions common to CUDA Samples
 
-#include <hip/hip_runtime.h>
+
 
 #include <cassert>
 #include <iostream>
@@ -245,7 +245,7 @@ int runTest(const int argc, const char **argv) {
       if (deviceProp.computeMode == hipComputeModeProhibited) {
         fprintf(stderr,
                 "Error: device is running in <Compute Mode Prohibited>, no "
-                "threads can use ::hipSetDevice().\n");
+                "threads can use ::cudaSetDevice().\n");
         HIPCHECK(hipSetDevice(currentDevice));
 
         exit(EXIT_FAILURE);
@@ -829,7 +829,7 @@ float testDeviceToDeviceTransfer(unsigned int memSize) {
   HIPCHECK(hipEventRecord(stop, 0));
 
   // Since device to device memory copies are non-blocking,
-  // hipDeviceSynchronize() is required in order to get
+  // cudaDeviceSynchronize() is required in order to get
   // proper timing.
   HIPCHECK(hipDeviceSynchronize());
 
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.out b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.out
index 4e838ee..cf38a24 100755
Binary files a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.out and b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.out differ
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2017.vcxproj b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2017.vcxproj
index 5be6093..ad862bf 100755
--- a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2017.vcxproj
+++ b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/bandwidthTest.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2019.vcxproj b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2019.vcxproj
index f1e9ea7..e6f5f30 100755
--- a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2019.vcxproj
+++ b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/bandwidthTest.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2022.vcxproj b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2022.vcxproj
index 50c4a54..676302b 100755
--- a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2022.vcxproj
+++ b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/bandwidthTest.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/Makefile b/src/samples/Samples/1_Utilities/deviceQuery/Makefile
index 51cd96a..44dd2fb 100755
--- a/src/samples/Samples/1_Utilities/deviceQuery/Makefile
+++ b/src/samples/Samples/1_Utilities/deviceQuery/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/NsightEclipse.xml b/src/samples/Samples/1_Utilities/deviceQuery/NsightEclipse.xml
index 015fe88..dda30eb 100755
--- a/src/samples/Samples/1_Utilities/deviceQuery/NsightEclipse.xml
+++ b/src/samples/Samples/1_Utilities/deviceQuery/NsightEclipse.xml
@@ -35,6 +35,8 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/README.md b/src/samples/Samples/1_Utilities/deviceQuery/README.md
index 1f0750f..4f4a647 100755
--- a/src/samples/Samples/1_Utilities/deviceQuery/README.md
+++ b/src/samples/Samples/1_Utilities/deviceQuery/README.md
@@ -10,7 +10,7 @@ CUDA Runtime API, Device Query
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaRuntimeGetVersion, cudaGetErrorString, cudaDeviceCanAccessPeer, cudaSetDevic
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2017.vcxproj b/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2017.vcxproj
index f5cff5f..87cca12 100755
--- a/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2017.vcxproj
+++ b/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/deviceQuery.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2019.vcxproj b/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2019.vcxproj
index c13bf8d..41b5beb 100755
--- a/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2019.vcxproj
+++ b/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/deviceQuery.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2022.vcxproj b/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2022.vcxproj
index 4cac2ee..4ba036e 100755
--- a/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2022.vcxproj
+++ b/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/deviceQuery.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/Makefile b/src/samples/Samples/1_Utilities/deviceQueryDrv/Makefile
index 93fa494..f9d77f6 100755
--- a/src/samples/Samples/1_Utilities/deviceQueryDrv/Makefile
+++ b/src/samples/Samples/1_Utilities/deviceQueryDrv/Makefile
@@ -291,8 +291,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/NsightEclipse.xml b/src/samples/Samples/1_Utilities/deviceQueryDrv/NsightEclipse.xml
index 4d65197..7a56e69 100755
--- a/src/samples/Samples/1_Utilities/deviceQueryDrv/NsightEclipse.xml
+++ b/src/samples/Samples/1_Utilities/deviceQueryDrv/NsightEclipse.xml
@@ -37,6 +37,8 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/README.md b/src/samples/Samples/1_Utilities/deviceQueryDrv/README.md
index a7d854f..92d0235 100755
--- a/src/samples/Samples/1_Utilities/deviceQueryDrv/README.md
+++ b/src/samples/Samples/1_Utilities/deviceQueryDrv/README.md
@@ -10,7 +10,7 @@ CUDA Driver API, Device Query
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaSetDevice
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2017.vcxproj b/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2017.vcxproj
index 5641fc0..59f77b9 100755
--- a/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2017.vcxproj
+++ b/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/deviceQueryDrv.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2019.vcxproj b/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2019.vcxproj
index 5e097c5..629a2e6 100755
--- a/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2019.vcxproj
+++ b/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/deviceQueryDrv.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2022.vcxproj b/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2022.vcxproj
index f75aee5..5c8aab7 100755
--- a/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2022.vcxproj
+++ b/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/deviceQueryDrv.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/Makefile b/src/samples/Samples/1_Utilities/topologyQuery/Makefile
index 50f315a..9a48838 100755
--- a/src/samples/Samples/1_Utilities/topologyQuery/Makefile
+++ b/src/samples/Samples/1_Utilities/topologyQuery/Makefile
@@ -299,7 +299,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/NsightEclipse.xml b/src/samples/Samples/1_Utilities/topologyQuery/NsightEclipse.xml
index f7f5f35..8bfd757 100755
--- a/src/samples/Samples/1_Utilities/topologyQuery/NsightEclipse.xml
+++ b/src/samples/Samples/1_Utilities/topologyQuery/NsightEclipse.xml
@@ -33,6 +33,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/README.md b/src/samples/Samples/1_Utilities/topologyQuery/README.md
index 2eaf958..e08fa33 100755
--- a/src/samples/Samples/1_Utilities/topologyQuery/README.md
+++ b/src/samples/Samples/1_Utilities/topologyQuery/README.md
@@ -10,7 +10,7 @@ Performance Strategies, Multi-GPU
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaGetDeviceCount, cudaDeviceGetAttribute
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.cu.hip b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.cu.hip
index 21c1a8d..cd315f0 100755
--- a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.cu.hip
+++ b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.cu.hip
@@ -34,7 +34,7 @@
 #include <hip/hip_runtime.h>
 
 // includes, project
-#include "helper_cuda_hipified.h"
+#include <helper_cuda.h>
 #include <helper_functions.h>  // helper for shared that are common to CUDA Samples
 #include "HIPCHECK.h"
 int main(int argc, char **argv) {
@@ -80,5 +80,3 @@ int main(int argc, char **argv) {
 
   return 0;
 }
-  << std::endl;
-  }
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.out b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.out
index 2445b1d..0561caa 100755
Binary files a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.out and b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.out differ
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2017.vcxproj b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2017.vcxproj
index b36bae0..feecd32 100755
--- a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2017.vcxproj
+++ b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/topologyQuery.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2019.vcxproj b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2019.vcxproj
index b6e85fe..245f929 100755
--- a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2019.vcxproj
+++ b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/topologyQuery.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2022.vcxproj b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2022.vcxproj
index 361f4e3..1d81b93 100755
--- a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2022.vcxproj
+++ b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/topologyQuery.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/Makefile
index f620725..dabf051 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/Makefile
@@ -303,7 +303,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/NsightEclipse.xml
index 57a5b0c..6df81e0 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/NsightEclipse.xml
@@ -68,6 +68,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>2:Graphics Interop</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/README.md b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/README.md
index e8a0e98..b559583 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/README.md
@@ -10,7 +10,7 @@ EGLStreams Interop
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaMemcpy, cudaMalloc, cudaProducerPresentFrame, cudaFree, cudaGetErrorString,
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/NsightEclipse.xml
index d775b75..ce22364 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/NsightEclipse.xml
@@ -62,6 +62,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>2:Graphics Interop</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/README.md b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/README.md
index bb56de6..5cee12b 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/README.md
@@ -10,7 +10,7 @@ EGLStreams Interop
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaProducerReadYUVFrame, cudaProducerTest, cudaProducerDeinit, cudaDeviceCreate
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/Makefile
index ffa17c9..86cfb92 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/Makefile
@@ -323,7 +323,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/NsightEclipse.xml
index 0053962..6399552 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/NsightEclipse.xml
@@ -59,6 +59,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>2:Graphics Interop</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/README.md b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/README.md
index af8103e..8c980b5 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/README.md
@@ -10,7 +10,7 @@ EGLSync-CUDAEvent Interop, EGLImage-CUDA Interop
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaMemcpy, cudaGetErrorString, cudaFree, cudaDeviceSynchronize, cudaGetValueMis
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_kernels.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_kernels.cu.hip
index eb0288c..cc9e695 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_kernels.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_kernels.cu.hip
@@ -404,12 +404,4 @@ extern "C" void sobelFilter(Pixel *odata, int iw, int ih,
    iw, ih, fScale, blockOperation, pPointOp, tex);
     } break;
   }
-}
-   iw, ih, fScale, blockOperation, pPointOp, tex);
-    } break;
-  }
-}
-   iw, ih, fScale, blockOperation, pPointOp, tex);
-    } break;
-  }
 }
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2017.vcxproj
index 30f72d2..e80efd5 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/FunctionPointers.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -118,6 +118,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2019.vcxproj
index a1720de..d5cbccd 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/FunctionPointers.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2022.vcxproj
index 5058ff4..ca5eb33 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/FunctionPointers.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/Makefile
index 89ae95c..651a4f8 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/NsightEclipse.xml
index 96cc889..f90f7b3 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/NsightEclipse.xml
@@ -75,6 +75,8 @@
     <scope>2:Graphics Interop</scope>
     <scope>2:Image Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/README.md b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/README.md
index e1c1c80..83e1641 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Image Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaMallocArray, cudaFreeArray, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2017.vcxproj
index 0283f9a..9b6616f 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/MC_EstimatePiInlineP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2019.vcxproj
index 4c30b0b..fd17c3e 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/MC_EstimatePiInlineP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2022.vcxproj
index a833ecc..9d5110d 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/MC_EstimatePiInlineP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/Makefile
index 1bc9b32..c4a3fa5 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/NsightEclipse.xml
index bb516fe..bf9c24d 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/NsightEclipse.xml
@@ -47,6 +47,8 @@
   <scopes>
     <scope>1:CUDA Advanced Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/README.md b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/README.md
index cce39c2..a7d4067 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/README.md
@@ -10,7 +10,7 @@ Random Number Generator, Computational Finance, CURAND Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMemcpy, cudaGetErrorString, cudaFree, cudaSetDevice, cudaGetDeviceCount, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/piestimator.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/piestimator.cu.hip
index e69de29..c56c703 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/piestimator.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/piestimator.cu.hip
@@ -0,0 +1,284 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "../inc/piestimator.h"
+
+#include <string>
+#include <vector>
+#include <numeric>
+#include <stdexcept>
+#include <typeinfo>
+#include <hip/hip_runtime.h>
+#include <hip/hip_cooperative_groups.h>
+
+namespace cg = cooperative_groups;
+#include <hiprand_kernel.h>
+
+using std::string;
+using std::vector;
+
+// RNG init kernel
+__global__ void initRNG(hiprandState *const rngStates, const unsigned int seed) {
+  // Determine thread ID
+  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
+
+  // Initialise the RNG
+  hiprand_init(seed, tid, 0, &rngStates[tid]);
+}
+
+__device__ unsigned int reduce_sum(unsigned int in, cg::thread_block cta) {
+  extern __shared__ unsigned int sdata[];
+
+  // Perform first level of reduction:
+  // - Write to shared memory
+  unsigned int ltid = threadIdx.x;
+
+  sdata[ltid] = in;
+  cg::sync(cta);
+
+  // Do reduction in shared mem
+  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
+    if (ltid < s) {
+      sdata[ltid] += sdata[ltid + s];
+    }
+
+    cg::sync(cta);
+  }
+
+  return sdata[0];
+}
+
+__device__ inline void getPoint(float &x, float &y, hiprandState &state) {
+  x = hiprand_uniform(&state);
+  y = hiprand_uniform(&state);
+}
+__device__ inline void getPoint(double &x, double &y, hiprandState &state) {
+  x = hiprand_uniform_double(&state);
+  y = hiprand_uniform_double(&state);
+}
+
+// Estimator kernel
+template <typename Real>
+__global__ void computeValue(unsigned int *const results,
+                             hiprandState *const rngStates,
+                             const unsigned int numSims) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  // Determine thread ID
+  unsigned int bid = blockIdx.x;
+  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
+  unsigned int step = gridDim.x * blockDim.x;
+
+  // Initialise the RNG
+  hiprandState localState = rngStates[tid];
+
+  // Count the number of points which lie inside the unit quarter-circle
+  unsigned int pointsInside = 0;
+
+  for (unsigned int i = tid; i < numSims; i += step) {
+    Real x;
+    Real y;
+    getPoint(x, y, localState);
+    Real l2norm2 = x * x + y * y;
+
+    if (l2norm2 < static_cast<Real>(1)) {
+      pointsInside++;
+    }
+  }
+
+  // Reduce within the block
+  pointsInside = reduce_sum(pointsInside, cta);
+
+  // Store the result
+  if (threadIdx.x == 0) {
+    results[bid] = pointsInside;
+  }
+}
+
+template <typename Real>
+PiEstimator<Real>::PiEstimator(unsigned int numSims, unsigned int device,
+                               unsigned int threadBlockSize, unsigned int seed)
+    : m_numSims(numSims),
+      m_device(device),
+      m_threadBlockSize(threadBlockSize),
+      m_seed(seed) {}
+
+template <typename Real>
+Real PiEstimator<Real>::operator()() {
+  hipError_t cudaResult = hipSuccess;
+  struct hipDeviceProp_t deviceProperties;
+  struct hipFuncAttributes funcAttributes;
+
+  // Get device properties
+  cudaResult = hipGetDeviceProperties(&deviceProperties, m_device);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not get device properties: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Check precision is valid
+  if (typeid(Real) == typeid(double) &&
+      (deviceProperties.major < 1 ||
+       (deviceProperties.major == 1 && deviceProperties.minor < 3))) {
+    throw std::runtime_error("Device does not have double precision support");
+  }
+
+  // Attach to GPU
+  cudaResult = hipSetDevice(m_device);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not set CUDA device: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Determine how to divide the work between cores
+  dim3 block;
+  dim3 grid;
+  block.x = m_threadBlockSize;
+  grid.x = (m_numSims + m_threadBlockSize - 1) / m_threadBlockSize;
+
+  // Aim to launch around ten or more times as many blocks as there
+  // are multiprocessors on the target device.
+  unsigned int blocksPerSM = 10;
+  unsigned int numSMs = deviceProperties.multiProcessorCount;
+
+  while (grid.x > 2 * blocksPerSM * numSMs) {
+    grid.x >>= 1;
+  }
+
+  // Get initRNG function properties and check the maximum block size
+  cudaResult = hipFuncGetAttributes(&funcAttributes, initRNG);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not get function attributes: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
+    throw std::runtime_error(
+        "Block X dimension is too large for initRNG kernel");
+  }
+
+  // Get computeValue function properties and check the maximum block size
+  cudaResult = hipFuncGetAttributes(&funcAttributes, computeValue<Real>);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not get function attributes: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
+    throw std::runtime_error(
+        "Block X dimension is too large for computeValue kernel");
+  }
+
+  // Check the dimensions are valid
+  if (block.x > (unsigned int)deviceProperties.maxThreadsDim[0]) {
+    throw std::runtime_error("Block X dimension is too large for device");
+  }
+
+  if (grid.x > (unsigned int)deviceProperties.maxGridSize[0]) {
+    throw std::runtime_error("Grid X dimension is too large for device");
+  }
+
+  // Allocate memory for RNG states
+  hiprandState *d_rngStates = 0;
+  cudaResult =
+      hipMalloc((void **)&d_rngStates, grid.x * block.x * sizeof(hiprandState));
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not allocate memory on device for RNG states: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Allocate memory for result
+  // Each thread block will produce one result
+  unsigned int *d_results = 0;
+  cudaResult = hipMalloc((void **)&d_results, grid.x * sizeof(unsigned int));
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not allocate memory on device for partial results: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Initialise RNG
+  initRNG<<<grid, block>>>(d_rngStates, m_seed);
+
+  // Count the points inside unit quarter-circle
+  computeValue<Real><<<grid, block, block.x * sizeof(unsigned int)>>>(
+      d_results, d_rngStates, m_numSims);
+
+  // Copy partial results back
+  vector<unsigned int> results(grid.x);
+  cudaResult = hipMemcpy(&results[0], d_results, grid.x * sizeof(unsigned int),
+                          hipMemcpyDeviceToHost);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not copy partial results to host: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Complete sum-reduction on host
+  Real value =
+      static_cast<Real>(std::accumulate(results.begin(), results.end(), 0));
+
+  // Determine the proportion of points inside the quarter-circle,
+  // i.e. the area of the unit quarter-circle
+  value /= m_numSims;
+
+  // Value is currently an estimate of the area of a unit quarter-circle, so we
+  // can scale to a full circle by multiplying by four. Now since the area of a
+  // circle is pi * r^2, and r is one, the value will be an estimate for the
+  // value of pi.
+  value *= 4;
+
+  // Cleanup
+  if (d_rngStates) {
+    hipFree(d_rngStates);
+    d_rngStates = 0;
+  }
+
+  if (d_results) {
+    hipFree(d_results);
+    d_results = 0;
+  }
+
+  return value;
+}
+
+// Explicit template instantiation
+template class PiEstimator<float>;
+template class PiEstimator<double>;
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2017.vcxproj
index 56e1fc8..9ac2184 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/MC_EstimatePiInlineQ.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2019.vcxproj
index b2215f5..b8246a1 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/MC_EstimatePiInlineQ.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2022.vcxproj
index b7bbf54..da748e1 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/MC_EstimatePiInlineQ.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/Makefile
index 19dea4b..5d8b086 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/NsightEclipse.xml
index 1c739b6..f087e82 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/NsightEclipse.xml
@@ -47,6 +47,8 @@
   <scopes>
     <scope>1:CUDA Advanced Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/README.md b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/README.md
index a0ed8ff..485c16a 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/README.md
@@ -10,7 +10,7 @@ Random Number Generator, Computational Finance, CURAND Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMemcpy, cudaGetErrorString, cudaFree, cudaSetDevice, cudaGetDeviceCount, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/piestimator.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/piestimator.cu.hip
index e69de29..7b35647 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/piestimator.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/piestimator.cu.hip
@@ -0,0 +1,393 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+
+#include "../inc/piestimator.h"
+
+#include <string>
+#include <vector>
+#include <numeric>
+#include <stdexcept>
+#include <typeinfo>
+#include <hip/hip_runtime.h>
+ #include <hip/hip_cooperative_groups.h>
+
+namespace cg = cooperative_groups;
+#include <hiprand.h>
+#include <hiprand_kernel.h>
+
+#include "../inc/cudasharedmem.h"
+
+using std::string;
+using std::vector;
+
+// Helper templates to support float and double in same code
+template <typename L, typename R>
+struct TYPE_IS {
+  static const bool test = false;
+};
+template <typename L>
+struct TYPE_IS<L, L> {
+  static const bool test = true;
+};
+template <bool, class L, class R>
+struct IF {
+  typedef R type;
+};
+template <class L, class R>
+struct IF<true, L, R> {
+  typedef L type;
+};
+
+// RNG init kernel
+template <typename rngState_t, typename rngDirectionVectors_t>
+__global__ void initRNG(rngState_t *const rngStates,
+                        rngDirectionVectors_t *const rngDirections,
+                        unsigned int numDrawsPerDirection) {
+  // Determine thread ID
+  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
+  unsigned int step = gridDim.x * blockDim.x;
+
+  // Determine offset to avoid overlapping sub-sequences
+  unsigned int offset = tid * ((numDrawsPerDirection + step - 1) / step);
+
+  // Initialise the RNG
+  hiprand_init(rngDirections[0], offset, &rngStates[tid]);
+  hiprand_init(rngDirections[1], offset, &rngStates[tid + step]);
+}
+
+__device__ unsigned int reduce_sum(unsigned int in, cg::thread_block cta) {
+  extern __shared__ unsigned int sdata[];
+
+  // Perform first level of reduction:
+  // - Write to shared memory
+  unsigned int ltid = threadIdx.x;
+
+  sdata[ltid] = in;
+  cg::sync(cta);
+
+  // Do reduction in shared mem
+  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
+    if (ltid < s) {
+      sdata[ltid] += sdata[ltid + s];
+    }
+
+    cg::sync(cta);
+  }
+
+  return sdata[0];
+}
+
+__device__ inline void getPoint(float &x, float &y, hiprandStateSobol32 &state1,
+                                hiprandStateSobol32 &state2) {
+  x = hiprand_uniform(&state1);
+  y = hiprand_uniform(&state2);
+}
+__device__ inline void getPoint(double &x, double &y,
+                                curandStateSobol64 &state1,
+                                curandStateSobol64 &state2) {
+  x = hiprand_uniform_double(&state1);
+  y = hiprand_uniform_double(&state2);
+}
+
+// Estimator kernel
+template <typename Real, typename rngState_t>
+__global__ void computeValue(unsigned int *const results,
+                             rngState_t *const rngStates,
+                             const unsigned int numSims) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  // Determine thread ID
+  unsigned int bid = blockIdx.x;
+  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
+  unsigned int step = gridDim.x * blockDim.x;
+
+  // Initialise the RNG
+  rngState_t localState1 = rngStates[tid];
+  rngState_t localState2 = rngStates[tid + step];
+
+  // Count the number of points which lie inside the unit quarter-circle
+  unsigned int pointsInside = 0;
+
+  for (unsigned int i = tid; i < numSims; i += step) {
+    Real x;
+    Real y;
+    getPoint(x, y, localState1, localState2);
+    Real l2norm2 = x * x + y * y;
+
+    if (l2norm2 < static_cast<Real>(1)) {
+      pointsInside++;
+    }
+  }
+
+  // Reduce within the block
+  pointsInside = reduce_sum(pointsInside, cta);
+
+  // Store the result
+  if (threadIdx.x == 0) {
+    results[bid] = pointsInside;
+  }
+}
+
+template <typename Real>
+PiEstimator<Real>::PiEstimator(unsigned int numSims, unsigned int device,
+                               unsigned int threadBlockSize)
+    : m_numSims(numSims),
+      m_device(device),
+      m_threadBlockSize(threadBlockSize) {}
+
+template <typename Real>
+Real PiEstimator<Real>::operator()() {
+  hipError_t cudaResult = hipSuccess;
+  struct hipDeviceProp_t deviceProperties;
+  struct hipFuncAttributes funcAttributes;
+
+  // Determine type of generator to use (32- or 64-bit)
+  typedef typename IF<TYPE_IS<Real, double>::test, curandStateSobol64_t,
+                      hiprandStateSobol32_t>::type curandStateSobol_sz;
+  typedef
+      typename IF<TYPE_IS<Real, double>::test, curandDirectionVectors64_t,
+                  hiprandDirectionVectors32_t>::type curandDirectionVectors_sz;
+
+  // Get device properties
+  cudaResult = hipGetDeviceProperties(&deviceProperties, m_device);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not get device properties: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Check precision is valid
+  if (typeid(Real) == typeid(double) &&
+      (deviceProperties.major < 1 ||
+       (deviceProperties.major == 1 && deviceProperties.minor < 3))) {
+    throw std::runtime_error("Device does not have double precision support");
+  }
+
+  // Attach to GPU
+  cudaResult = hipSetDevice(m_device);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not set CUDA device: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Determine how to divide the work between cores
+  dim3 block;
+  dim3 grid;
+  block.x = m_threadBlockSize;
+  grid.x = (m_numSims + m_threadBlockSize - 1) / m_threadBlockSize;
+
+  // Aim to launch around ten or more times as many blocks as there
+  // are multiprocessors on the target device.
+  unsigned int blocksPerSM = 10;
+  unsigned int numSMs = deviceProperties.multiProcessorCount;
+
+  while (grid.x > 2 * blocksPerSM * numSMs) {
+    grid.x >>= 1;
+  }
+
+  // Get initRNG function properties and check the maximum block size
+  cudaResult = hipFuncGetAttributes(
+      &funcAttributes, initRNG<curandStateSobol_sz, curandDirectionVectors_sz>);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not get function attributes: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
+    throw std::runtime_error(
+        "Block X dimension is too large for initRNG kernel");
+  }
+
+  // Get computeValue function properties and check the maximum block size
+  cudaResult = hipFuncGetAttributes(&funcAttributes,
+                                     computeValue<Real, curandStateSobol_sz>);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not get function attributes: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
+    throw std::runtime_error(
+        "Block X dimension is too large for computeValue kernel");
+  }
+
+  // Check the dimensions are valid
+  if (block.x > (unsigned int)deviceProperties.maxThreadsDim[0]) {
+    throw std::runtime_error("Block X dimension is too large for device");
+  }
+
+  if (grid.x > (unsigned int)deviceProperties.maxGridSize[0]) {
+    throw std::runtime_error("Grid X dimension is too large for device");
+  }
+
+  // Allocate memory for RNG states and direction vectors
+  curandStateSobol_sz *d_rngStates = 0;
+  curandDirectionVectors_sz *d_rngDirections = 0;
+  cudaResult = hipMalloc((void **)&d_rngStates,
+                          2 * grid.x * block.x * sizeof(curandStateSobol_sz));
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not allocate memory on device for RNG states: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  cudaResult = hipMalloc((void **)&d_rngDirections,
+                          2 * sizeof(curandDirectionVectors_sz));
+
+  if (cudaResult != hipSuccess) {
+    string msg(
+        "Could not allocate memory on device for RNG direction vectors: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Allocate memory for result
+  // Each thread block will produce one result
+  unsigned int *d_results = 0;
+  cudaResult = hipMalloc((void **)&d_results, grid.x * sizeof(unsigned int));
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not allocate memory on device for partial results: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Generate direction vectors on the host and copy to the device
+  if (typeid(Real) == typeid(float)) {
+    hiprandDirectionVectors32_t *rngDirections;
+    hiprandStatus_t curandResult = curandGetDirectionVectors32(
+        &rngDirections, CURAND_DIRECTION_VECTORS_32_JOEKUO6);
+
+    if (curandResult != HIPRAND_STATUS_SUCCESS) {
+      string msg(
+          "Could not get direction vectors for quasi-random number "
+          "generator: ");
+      msg += curandResult;
+      throw std::runtime_error(msg);
+    }
+
+    cudaResult = hipMemcpy(d_rngDirections, rngDirections,
+                            2 * sizeof(hiprandDirectionVectors32_t),
+                            hipMemcpyHostToDevice);
+
+    if (cudaResult != hipSuccess) {
+      string msg("Could not copy direction vectors to device: ");
+      msg += hipGetErrorString(cudaResult);
+      throw std::runtime_error(msg);
+    }
+  } else if (typeid(Real) == typeid(double)) {
+    curandDirectionVectors64_t *rngDirections;
+    hiprandStatus_t curandResult = curandGetDirectionVectors64(
+        &rngDirections, CURAND_DIRECTION_VECTORS_64_JOEKUO6);
+
+    if (curandResult != HIPRAND_STATUS_SUCCESS) {
+      string msg(
+          "Could not get direction vectors for quasi-random number "
+          "generator: ");
+      msg += curandResult;
+      throw std::runtime_error(msg);
+    }
+
+    cudaResult = hipMemcpy(d_rngDirections, rngDirections,
+                            2 * sizeof(curandDirectionVectors64_t),
+                            hipMemcpyHostToDevice);
+
+    if (cudaResult != hipSuccess) {
+      string msg("Could not copy direction vectors to device: ");
+      msg += hipGetErrorString(cudaResult);
+      throw std::runtime_error(msg);
+    }
+  } else {
+    string msg(
+        "Could not get direction vectors for random number generator of "
+        "specified type");
+    throw std::runtime_error(msg);
+  }
+
+  // Initialise RNG
+  initRNG<<<grid, block>>>(d_rngStates, d_rngDirections, m_numSims);
+
+  // Count the points inside unit quarter-circle
+  computeValue<Real><<<grid, block, block.x * sizeof(unsigned int)>>>(
+      d_results, d_rngStates, m_numSims);
+
+  // Copy partial results back
+  vector<unsigned int> results(grid.x);
+  cudaResult = hipMemcpy(&results[0], d_results, grid.x * sizeof(unsigned int),
+                          hipMemcpyDeviceToHost);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not copy partial results to host: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Complete sum-reduction on host
+  Real value =
+      static_cast<Real>(std::accumulate(results.begin(), results.end(), 0));
+
+  // Determine the proportion of points inside the quarter-circle,
+  // i.e. the area of the unit quarter-circle
+  value /= m_numSims;
+
+  // Value is currently an estimate of the area of a unit quarter-circle, so we
+  // can scale to a full circle by multiplying by four. Now since the area of a
+  // circle is pi * r^2, and r is one, the value will be an estimate for the
+  // value of pi.
+  value *= 4;
+
+  // Cleanup
+  if (d_rngStates) {
+    hipFree(d_rngStates);
+    d_rngStates = 0;
+  }
+
+  if (d_rngDirections) {
+    hipFree(d_rngDirections);
+    d_rngDirections = 0;
+  }
+
+  if (d_results) {
+    hipFree(d_results);
+    d_results = 0;
+  }
+
+  return value;
+}
+
+// Explicit template instantiation
+template class PiEstimator<float>;
+template class PiEstimator<double>;
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2017.vcxproj
index a1847cf..c641887 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/MC_EstimatePiP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2019.vcxproj
index e71a90a..c188ae7 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/MC_EstimatePiP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2022.vcxproj
index 9dc53c3..c9893f3 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/MC_EstimatePiP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/Makefile
index 18f1e3e..0e5b423 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/NsightEclipse.xml
index 6ed1b76..56a07de 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/NsightEclipse.xml
@@ -47,6 +47,8 @@
   <scopes>
     <scope>1:CUDA Advanced Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/README.md b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/README.md
index 1bfba3f..4390385 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/README.md
@@ -10,7 +10,7 @@ Random Number Generator, Computational Finance, CURAND Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMemcpy, cudaGetErrorString, cudaFree, cudaSetDevice, cudaGetDeviceCount, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/piestimator.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/piestimator.cu.hip
index e69de29..5b9a22c 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/piestimator.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/piestimator.cu.hip
@@ -0,0 +1,293 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "../inc/piestimator.h"
+
+#include <string>
+#include <vector>
+#include <numeric>
+#include <stdexcept>
+#include <typeinfo>
+#include <hip/hip_runtime.h>
+ #include <hip/hip_cooperative_groups.h>
+
+namespace cg = cooperative_groups;
+#include <hiprand.h>
+
+using std::string;
+using std::vector;
+
+__device__ unsigned int reduce_sum(unsigned int in, cg::thread_block cta) {
+  extern __shared__ unsigned int sdata[];
+
+  // Perform first level of reduction:
+  // - Write to shared memory
+  unsigned int ltid = threadIdx.x;
+
+  sdata[ltid] = in;
+  cg::sync(cta);
+
+  // Do reduction in shared mem
+  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
+    if (ltid < s) {
+      sdata[ltid] += sdata[ltid + s];
+    }
+
+    cg::sync(cta);
+  }
+
+  return sdata[0];
+}
+
+// Estimator kernel
+template <typename Real>
+__global__ void computeValue(unsigned int *const results,
+                             const Real *const points,
+                             const unsigned int numSims) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  // Determine thread ID
+  unsigned int bid = blockIdx.x;
+  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
+  unsigned int step = gridDim.x * blockDim.x;
+
+  // Shift the input/output pointers
+  const Real *pointx = points + tid;
+  const Real *pointy = pointx + numSims;
+
+  // Count the number of points which lie inside the unit quarter-circle
+  unsigned int pointsInside = 0;
+
+  for (unsigned int i = tid; i < numSims;
+       i += step, pointx += step, pointy += step) {
+    Real x = *pointx;
+    Real y = *pointy;
+    Real l2norm2 = x * x + y * y;
+
+    if (l2norm2 < static_cast<Real>(1)) {
+      pointsInside++;
+    }
+  }
+
+  // Reduce within the block
+  pointsInside = reduce_sum(pointsInside, cta);
+
+  // Store the result
+  if (threadIdx.x == 0) {
+    results[bid] = pointsInside;
+  }
+}
+
+template <typename Real>
+PiEstimator<Real>::PiEstimator(unsigned int numSims, unsigned int device,
+                               unsigned int threadBlockSize, unsigned int seed)
+    : m_numSims(numSims),
+      m_device(device),
+      m_threadBlockSize(threadBlockSize),
+      m_seed(seed) {}
+
+template <typename Real>
+Real PiEstimator<Real>::operator()() {
+  hipError_t cudaResult = hipSuccess;
+  struct hipDeviceProp_t deviceProperties;
+  struct hipFuncAttributes funcAttributes;
+
+  // Get device properties
+  cudaResult = hipGetDeviceProperties(&deviceProperties, m_device);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not get device properties: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Check precision is valid
+  if (typeid(Real) == typeid(double) &&
+      (deviceProperties.major < 1 ||
+       (deviceProperties.major == 1 && deviceProperties.minor < 3))) {
+    throw std::runtime_error("Device does not have double precision support");
+  }
+
+  // Attach to GPU
+  cudaResult = hipSetDevice(m_device);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not set CUDA device: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Determine how to divide the work between cores
+  dim3 block;
+  dim3 grid;
+  block.x = m_threadBlockSize;
+  grid.x = (m_numSims + m_threadBlockSize - 1) / m_threadBlockSize;
+
+  // Aim to launch around ten or more times as many blocks as there
+  // are multiprocessors on the target device.
+  unsigned int blocksPerSM = 10;
+  unsigned int numSMs = deviceProperties.multiProcessorCount;
+
+  while (grid.x > 2 * blocksPerSM * numSMs) {
+    grid.x >>= 1;
+  }
+
+  // Get computeValue function properties and check the maximum block size
+  cudaResult = hipFuncGetAttributes(&funcAttributes, computeValue<Real>);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not get function attributes: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
+    throw std::runtime_error(
+        "Block X dimension is too large for computeValue kernel");
+  }
+
+  // Check the dimensions are valid
+  if (block.x > (unsigned int)deviceProperties.maxThreadsDim[0]) {
+    throw std::runtime_error("Block X dimension is too large for device");
+  }
+
+  if (grid.x > (unsigned int)deviceProperties.maxGridSize[0]) {
+    throw std::runtime_error("Grid X dimension is too large for device");
+  }
+
+  // Allocate memory for points
+  // Each simulation has two random numbers to give X and Y coordinate
+  Real *d_points = 0;
+  cudaResult = hipMalloc((void **)&d_points, 2 * m_numSims * sizeof(Real));
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not allocate memory on device for random numbers: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Allocate memory for result
+  // Each thread block will produce one result
+  unsigned int *d_results = 0;
+  cudaResult = hipMalloc((void **)&d_results, grid.x * sizeof(unsigned int));
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not allocate memory on device for partial results: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Generate random points in unit square
+  hiprandStatus_t curandResult;
+  hiprandGenerator_t prng;
+  curandResult = hiprandCreateGenerator(&prng, HIPRAND_RNG_PSEUDO_DEFAULT);
+
+  if (curandResult != HIPRAND_STATUS_SUCCESS) {
+    string msg("Could not create pseudo-random number generator: ");
+    msg += curandResult;
+    throw std::runtime_error(msg);
+  }
+
+  curandResult = hiprandSetPseudoRandomGeneratorSeed(prng, m_seed);
+
+  if (curandResult != HIPRAND_STATUS_SUCCESS) {
+    string msg("Could not set seed for pseudo-random number generator: ");
+    msg += curandResult;
+    throw std::runtime_error(msg);
+  }
+
+  if (typeid(Real) == typeid(float)) {
+    curandResult =
+        hiprandGenerateUniform(prng, (float *)d_points, 2 * m_numSims);
+  } else if (typeid(Real) == typeid(double)) {
+    curandResult =
+        hiprandGenerateUniformDouble(prng, (double *)d_points, 2 * m_numSims);
+  } else {
+    string msg("Could not generate random numbers of specified type");
+    throw std::runtime_error(msg);
+  }
+
+  if (curandResult != HIPRAND_STATUS_SUCCESS) {
+    string msg("Could not generate pseudo-random numbers: ");
+    msg += curandResult;
+    throw std::runtime_error(msg);
+  }
+
+  curandResult = hiprandDestroyGenerator(prng);
+
+  if (curandResult != HIPRAND_STATUS_SUCCESS) {
+    string msg("Could not destroy pseudo-random number generator: ");
+    msg += curandResult;
+    throw std::runtime_error(msg);
+  }
+
+  // Count the points inside unit quarter-circle
+  computeValue<Real><<<grid, block, block.x * sizeof(unsigned int)>>>(
+      d_results, d_points, m_numSims);
+
+  // Copy partial results back
+  vector<unsigned int> results(grid.x);
+  cudaResult = hipMemcpy(&results[0], d_results, grid.x * sizeof(unsigned int),
+                          hipMemcpyDeviceToHost);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not copy partial results to host: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Complete sum-reduction on host
+  Real value =
+      static_cast<Real>(std::accumulate(results.begin(), results.end(), 0));
+
+  // Determine the proportion of points inside the quarter-circle,
+  // i.e. the area of the unit quarter-circle
+  value /= m_numSims;
+
+  // Value is currently an estimate of the area of a unit quarter-circle, so we
+  // can scale to a full circle by multiplying by four. Now since the area of a
+  // circle is pi * r^2, and r is one, the value will be an estimate for the
+  // value of pi.
+  value *= 4;
+
+  // Cleanup
+  if (d_points) {
+    hipFree(d_points);
+    d_points = 0;
+  }
+
+  if (d_results) {
+    hipFree(d_results);
+    d_results = 0;
+  }
+
+  return value;
+}
+
+// Explicit template instantiation
+template class PiEstimator<float>;
+template class PiEstimator<double>;
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2017.vcxproj
index 833f425..95b72fe 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/MC_EstimatePiQ.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2019.vcxproj
index 1db25e7..ff93163 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/MC_EstimatePiQ.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2022.vcxproj
index c97c135..5714f94 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/MC_EstimatePiQ.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/Makefile
index 7c27cc5..61ae97d 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/NsightEclipse.xml
index 7660c37..71f9c10 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/NsightEclipse.xml
@@ -47,6 +47,8 @@
   <scopes>
     <scope>1:CUDA Advanced Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/README.md b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/README.md
index 48b48de..c6bac7b 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/README.md
@@ -10,7 +10,7 @@ Random Number Generator, Computational Finance, CURAND Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMemcpy, cudaGetErrorString, cudaFree, cudaSetDevice, cudaGetDeviceCount, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/piestimator.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/piestimator.cu.hip
index e69de29..581aa2c 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/piestimator.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/piestimator.cu.hip
@@ -0,0 +1,312 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "../inc/piestimator.h"
+
+#include <string>
+#include <vector>
+#include <numeric>
+#include <stdexcept>
+#include <typeinfo>
+#include <hip/hip_runtime.h>
+#include <hip/hip_cooperative_groups.h>
+
+namespace cg = cooperative_groups;
+#include <hiprand.h>
+
+using std::string;
+using std::vector;
+
+__device__ unsigned int reduce_sum(unsigned int in, cg::thread_block cta) {
+  extern __shared__ unsigned int sdata[];
+
+  // Perform first level of reduction:
+  // - Write to shared memory
+  unsigned int ltid = threadIdx.x;
+
+  sdata[ltid] = in;
+  cg::sync(cta);
+
+  // Do reduction in shared mem
+  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
+    if (ltid < s) {
+      sdata[ltid] += sdata[ltid + s];
+    }
+
+    cg::sync(cta);
+  }
+
+  return sdata[0];
+}
+
+// Estimator kernel
+template <typename Real>
+__global__ void computeValue(unsigned int *const results,
+                             const Real *const points,
+                             const unsigned int numSims) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  // Determine thread ID
+  unsigned int bid = blockIdx.x;
+  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
+  unsigned int step = gridDim.x * blockDim.x;
+
+  // Shift the input/output pointers
+  const Real *pointx = points + tid;
+  const Real *pointy = pointx + numSims;
+
+  // Count the number of points which lie inside the unit quarter-circle
+  unsigned int pointsInside = 0;
+
+  for (unsigned int i = tid; i < numSims;
+       i += step, pointx += step, pointy += step) {
+    Real x = *pointx;
+    Real y = *pointy;
+    Real l2norm2 = x * x + y * y;
+
+    if (l2norm2 < static_cast<Real>(1)) {
+      pointsInside++;
+    }
+  }
+
+  // Reduce within the block
+  pointsInside = reduce_sum(pointsInside, cta);
+
+  // Store the result
+  if (threadIdx.x == 0) {
+    results[bid] = pointsInside;
+  }
+}
+
+template <typename Real>
+PiEstimator<Real>::PiEstimator(unsigned int numSims, unsigned int device,
+                               unsigned int threadBlockSize)
+    : m_numSims(numSims),
+      m_device(device),
+      m_threadBlockSize(threadBlockSize) {}
+
+template <typename Real>
+Real PiEstimator<Real>::operator()() {
+  hipError_t cudaResult = hipSuccess;
+  struct hipDeviceProp_t deviceProperties;
+  struct hipFuncAttributes funcAttributes;
+
+  // Get device properties
+  cudaResult = hipGetDeviceProperties(&deviceProperties, m_device);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not get device properties: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Check precision is valid
+  if (typeid(Real) == typeid(double) &&
+      (deviceProperties.major < 1 ||
+       (deviceProperties.major == 1 && deviceProperties.minor < 3))) {
+    throw std::runtime_error("Device does not have double precision support");
+  }
+
+  // Attach to GPU
+  cudaResult = hipSetDevice(m_device);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not set CUDA device: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Determine how to divide the work between cores
+  dim3 block;
+  dim3 grid;
+  block.x = m_threadBlockSize;
+  grid.x = (m_numSims + m_threadBlockSize - 1) / m_threadBlockSize;
+
+  // Aim to launch around ten or more times as many blocks as there
+  // are multiprocessors on the target device.
+  unsigned int blocksPerSM = 10;
+  unsigned int numSMs = deviceProperties.multiProcessorCount;
+
+  while (grid.x > 2 * blocksPerSM * numSMs) {
+    grid.x >>= 1;
+  }
+
+  // Get computeValue function properties and check the maximum block size
+  cudaResult = hipFuncGetAttributes(&funcAttributes, computeValue<Real>);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not get function attributes: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
+    throw std::runtime_error(
+        "Block X dimension is too large for computeValue kernel");
+  }
+
+  // Check the dimensions are valid
+  if (block.x > (unsigned int)deviceProperties.maxThreadsDim[0]) {
+    throw std::runtime_error("Block X dimension is too large for device");
+  }
+
+  if (grid.x > (unsigned int)deviceProperties.maxGridSize[0]) {
+    throw std::runtime_error("Grid X dimension is too large for device");
+  }
+
+  // Allocate memory for points
+  // Each simulation has two random numbers to give X and Y coordinate
+  Real *d_points = 0;
+  cudaResult = hipMalloc((void **)&d_points, 2 * m_numSims * sizeof(Real));
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not allocate memory on device for random numbers: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Allocate memory for result
+  // Each thread block will produce one result
+  unsigned int *d_results = 0;
+  cudaResult = hipMalloc((void **)&d_results, grid.x * sizeof(unsigned int));
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not allocate memory on device for partial results: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Generate random points in unit square
+  hiprandStatus_t curandResult;
+  hiprandGenerator_t qrng;
+
+  if (typeid(Real) == typeid(float)) {
+    curandResult = hiprandCreateGenerator(&qrng, HIPRAND_RNG_QUASI_SOBOL32);
+  } else if (typeid(Real) == typeid(double)) {
+    curandResult = hiprandCreateGenerator(&qrng, HIPRAND_RNG_QUASI_SOBOL64);
+  } else {
+    string msg("Could not create random number generator of specified type");
+    throw std::runtime_error(msg);
+  }
+
+  if (curandResult != HIPRAND_STATUS_SUCCESS) {
+    string msg("Could not create quasi-random number generator: ");
+    msg += curandResult;
+    throw std::runtime_error(msg);
+  }
+
+  curandResult = hiprandSetQuasiRandomGeneratorDimensions(qrng, 2);
+
+  if (curandResult != HIPRAND_STATUS_SUCCESS) {
+    string msg(
+        "Could not set number of dimensions for quasi-random number "
+        "generator: ");
+    msg += curandResult;
+    throw std::runtime_error(msg);
+  }
+
+  curandResult =
+      curandSetGeneratorOrdering(qrng, CURAND_ORDERING_QUASI_DEFAULT);
+
+  if (curandResult != HIPRAND_STATUS_SUCCESS) {
+    string msg("Could not set order for quasi-random number generator: ");
+    msg += curandResult;
+    throw std::runtime_error(msg);
+  }
+
+  if (typeid(Real) == typeid(float)) {
+    curandResult =
+        hiprandGenerateUniform(qrng, (float *)d_points, 2 * m_numSims);
+  } else if (typeid(Real) == typeid(double)) {
+    curandResult =
+        hiprandGenerateUniformDouble(qrng, (double *)d_points, 2 * m_numSims);
+  } else {
+    string msg("Could not generate random numbers of specified type");
+    throw std::runtime_error(msg);
+  }
+
+  if (curandResult != HIPRAND_STATUS_SUCCESS) {
+    string msg("Could not generate quasi-random numbers: ");
+    msg += curandResult;
+    throw std::runtime_error(msg);
+  }
+
+  curandResult = hiprandDestroyGenerator(qrng);
+
+  if (curandResult != HIPRAND_STATUS_SUCCESS) {
+    string msg("Could not destroy quasi-random number generator: ");
+    msg += curandResult;
+    throw std::runtime_error(msg);
+  }
+
+  // Count the points inside unit quarter-circle
+  computeValue<Real><<<grid, block, block.x * sizeof(unsigned int)>>>(
+      d_results, d_points, m_numSims);
+
+  // Copy partial results back
+  vector<unsigned int> results(grid.x);
+  cudaResult = hipMemcpy(&results[0], d_results, grid.x * sizeof(unsigned int),
+                          hipMemcpyDeviceToHost);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not copy partial results to host: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Complete sum-reduction on host
+  Real value =
+      static_cast<Real>(std::accumulate(results.begin(), results.end(), 0));
+
+  // Determine the proportion of points inside the quarter-circle,
+  // i.e. the area of the unit quarter-circle
+  value /= m_numSims;
+
+  // Value is currently an estimate of the area of a unit quarter-circle, so we
+  // can scale to a full circle by multiplying by four. Now since the area of a
+  // circle is pi * r^2, and r is one, the value will be an estimate for the
+  // value of pi.
+  value *= 4;
+
+  // Cleanup
+  if (d_points) {
+    hipFree(d_points);
+    d_points = 0;
+  }
+
+  if (d_results) {
+    hipFree(d_results);
+    d_results = 0;
+  }
+
+  return value;
+}
+
+// Explicit template instantiation
+template class PiEstimator<float>;
+template class PiEstimator<double>;
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2017.vcxproj
index 1bf1fea..c9d46e4 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/MC_SingleAsianOptionP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -112,6 +112,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2019.vcxproj
index fd00734..1a31f28 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/MC_SingleAsianOptionP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2022.vcxproj
index 22d8c6d..a97d1d4 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/MC_SingleAsianOptionP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/Makefile
index fc6ef98..97baec6 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/NsightEclipse.xml
index 326f993..e11b104 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/NsightEclipse.xml
@@ -48,6 +48,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>3:Computational Finance</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/README.md b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/README.md
index b7e1821..f6f6cd1 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/README.md
@@ -10,7 +10,7 @@ Random Number Generator, Computational Finance, CURAND Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMemcpy, cudaGetErrorString, cudaFree, cudaSetDevice, cudaGetDeviceCount, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/pricingengine.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/pricingengine.cu.hip
index e69de29..e5857fd 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/pricingengine.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/pricingengine.cu.hip
@@ -0,0 +1,374 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "../inc/pricingengine.h"
+
+#include <string>
+#include <vector>
+#include <numeric>
+#include <stdexcept>
+#include <typeinfo>
+#include <hip/hip_runtime.h>
+#include <hip/hip_cooperative_groups.h>
+
+namespace cg = cooperative_groups;
+#include <hiprand_kernel.h>
+
+#include "../inc/asianoption.h"
+#include "../inc/cudasharedmem.h"
+
+using std::string;
+using std::vector;
+
+// RNG init kernel
+__global__ void initRNG(hiprandState *const rngStates, const unsigned int seed) {
+  // Determine thread ID
+  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
+
+  // Initialise the RNG
+  hiprand_init(seed, tid, 0, &rngStates[tid]);
+}
+
+__device__ inline float getPathStep(float &drift, float &diffusion,
+                                    hiprandState &state) {
+  return expf(drift + diffusion * hiprand_normal(&state));
+}
+__device__ inline double getPathStep(double &drift, double &diffusion,
+                                     hiprandState &state) {
+  return exp(drift + diffusion * hiprand_normal_double(&state));
+}
+
+// Path generation kernel
+template <typename Real>
+__global__ void generatePaths(Real *const paths, hiprandState *const rngStates,
+                              const AsianOption<Real> *const option,
+                              const unsigned int numSims,
+                              const unsigned int numTimesteps) {
+  // Determine thread ID
+  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
+  unsigned int step = gridDim.x * blockDim.x;
+
+  // Compute parameters
+  Real drift =
+      (option->r - static_cast<Real>(0.5) * option->sigma * option->sigma) *
+      option->dt;
+  Real diffusion = option->sigma * sqrt(option->dt);
+
+  // Initialise the RNG
+  hiprandState localState = rngStates[tid];
+
+  for (unsigned int i = tid; i < numSims; i += step) {
+    // Shift the output pointer
+    Real *output = paths + i;
+
+    // Simulate the path
+    Real s = static_cast<Real>(1);
+
+    for (unsigned int t = 0; t < numTimesteps; t++, output += numSims) {
+      s *= getPathStep(drift, diffusion, localState);
+      *output = s;
+    }
+  }
+}
+
+template <typename Real>
+__device__ Real reduce_sum(Real in, cg::thread_block cta) {
+  SharedMemory<Real> sdata;
+
+  // Perform first level of reduction:
+  // - Write to shared memory
+  unsigned int ltid = threadIdx.x;
+
+  sdata[ltid] = in;
+  cg::sync(cta);
+
+  // Do reduction in shared mem
+  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
+    if (ltid < s) {
+      sdata[ltid] += sdata[ltid + s];
+    }
+
+    cg::sync(cta);
+  }
+
+  return sdata[0];
+}
+
+// Valuation kernel
+template <typename Real>
+__global__ void computeValue(Real *const values, const Real *const paths,
+                             const AsianOption<Real> *const option,
+                             const unsigned int numSims,
+                             const unsigned int numTimesteps) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  // Determine thread ID
+  unsigned int bid = blockIdx.x;
+  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
+  unsigned int step = gridDim.x * blockDim.x;
+
+  Real sumPayoffs = static_cast<Real>(0);
+
+  for (unsigned int i = tid; i < numSims; i += step) {
+    // Shift the input pointer
+    const Real *path = paths + i;
+    // Compute the arithmetic average
+    Real avg = static_cast<Real>(0);
+
+    for (unsigned int t = 0; t < numTimesteps; t++, path += numSims) {
+      avg += *path;
+    }
+
+    avg = avg * option->spot / numTimesteps;
+    // Compute the payoff
+    Real payoff = avg - option->strike;
+
+    if (option->type == AsianOption<Real>::Put) {
+      payoff = -payoff;
+    }
+
+    payoff = max(static_cast<Real>(0), payoff);
+    // Accumulate payoff locally
+    sumPayoffs += payoff;
+  }
+
+  // Reduce within the block
+  sumPayoffs = reduce_sum<Real>(sumPayoffs, cta);
+
+  // Store the result
+  if (threadIdx.x == 0) {
+    values[bid] = sumPayoffs;
+  }
+}
+
+template <typename Real>
+PricingEngine<Real>::PricingEngine(unsigned int numSims, unsigned int device,
+                                   unsigned int threadBlockSize,
+                                   unsigned int seed)
+    : m_numSims(numSims),
+      m_device(device),
+      m_threadBlockSize(threadBlockSize),
+      m_seed(seed) {}
+
+template <typename Real>
+void PricingEngine<Real>::operator()(AsianOption<Real> &option) {
+  hipError_t cudaResult = hipSuccess;
+  struct hipDeviceProp_t deviceProperties;
+  struct hipFuncAttributes funcAttributes;
+
+  // Get device properties
+  cudaResult = hipGetDeviceProperties(&deviceProperties, m_device);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not get device properties: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Check precision is valid
+  unsigned int deviceVersion =
+      deviceProperties.major * 10 + deviceProperties.minor;
+
+  if (typeid(Real) == typeid(double) && deviceVersion < 13) {
+    throw std::runtime_error("Device does not have double precision support");
+  }
+
+  // Attach to GPU
+  cudaResult = hipSetDevice(m_device);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not set CUDA device: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Determine how to divide the work between cores
+  dim3 block;
+  dim3 grid;
+  block.x = m_threadBlockSize;
+  grid.x = (m_numSims + m_threadBlockSize - 1) / m_threadBlockSize;
+
+  // Aim to launch around ten or more times as many blocks as there
+  // are multiprocessors on the target device.
+  unsigned int blocksPerSM = 10;
+  unsigned int numSMs = deviceProperties.multiProcessorCount;
+
+  while (grid.x > 2 * blocksPerSM * numSMs) {
+    grid.x >>= 1;
+  }
+
+  // Get initRNG function properties and check the maximum block size
+  cudaResult = hipFuncGetAttributes(&funcAttributes,(const void*) initRNG);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not get function attributes: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
+    throw std::runtime_error(
+        "Block X dimension is too large for initRNG kernel");
+  }
+
+  // Get generatePaths function properties and check the maximum block size
+  cudaResult = hipFuncGetAttributes(&funcAttributes, (const void*)generatePaths<Real>);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not get function attributes: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
+    throw std::runtime_error(
+        "Block X dimension is too large for generatePaths kernel");
+  }
+
+  // Get computeValue function properties and check the maximum block size
+  cudaResult = hipFuncGetAttributes(&funcAttributes,(const void*) computeValue<Real>);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not get function attributes: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
+    throw std::runtime_error(
+        "Block X dimension is too large for computeValue kernel");
+  }
+
+  // Setup problem on GPU
+  AsianOption<Real> *d_option = 0;
+  cudaResult = hipMalloc((void **)&d_option, sizeof(AsianOption<Real>));
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not allocate memory on device for option data: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  cudaResult = hipMemcpy(d_option, &option, sizeof(AsianOption<Real>),
+                          hipMemcpyHostToDevice);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not copy data to device: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Allocate memory for paths
+  Real *d_paths = 0;
+  int numTimesteps = static_cast<int>(option.tenor / option.dt);
+  cudaResult =
+      hipMalloc((void **)&d_paths, m_numSims * numTimesteps * sizeof(Real));
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not allocate memory on device for paths: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Allocate memory for RNG states
+  hiprandState *d_rngStates = 0;
+  cudaResult =
+      hipMalloc((void **)&d_rngStates, grid.x * block.x * sizeof(hiprandState));
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not allocate memory on device for RNG state: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Allocate memory for result
+  Real *d_values = 0;
+  cudaResult = hipMalloc((void **)&d_values, grid.x * sizeof(Real));
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not allocate memory on device for partial results: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Initialise RNG
+  initRNG<<<grid, block>>>(d_rngStates, m_seed);
+
+  // Generate paths
+  generatePaths<Real><<<grid, block>>>(d_paths, d_rngStates, d_option,
+                                       m_numSims, numTimesteps);
+
+  // Compute value
+  computeValue<<<grid, block, block.x * sizeof(Real)>>>(
+      d_values, d_paths, d_option, m_numSims, numTimesteps);
+
+  // Copy partial results back
+  vector<Real> values(grid.x);
+  cudaResult = hipMemcpy(&values[0], d_values, grid.x * sizeof(Real),
+                          hipMemcpyDeviceToHost);
+
+  if (cudaResult != hipSuccess) {
+    string msg("Could not copy partial results to host: ");
+    msg += hipGetErrorString(cudaResult);
+    throw std::runtime_error(msg);
+  }
+
+  // Complete sum-reduction on host
+  option.value =
+      std::accumulate(values.begin(), values.end(), static_cast<Real>(0));
+
+  // Compute the mean
+  option.value /= m_numSims;
+
+  // Discount to present value
+  option.value *= exp(-option.r * option.tenor);
+
+  // Cleanup
+  if (d_option) {
+    hipFree(d_option);
+    d_option = 0;
+  }
+
+  if (d_paths) {
+    hipFree(d_paths);
+    d_paths = 0;
+  }
+
+  if (d_rngStates) {
+    hipFree(d_rngStates);
+    d_rngStates = 0;
+  }
+
+  if (d_values) {
+    hipFree(d_values);
+    d_values = 0;
+  }
+}
+
+// Explicit template instantiation
+template class PricingEngine<float>;
+template class PricingEngine<double>;
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/Makefile
index 10e6bd2..ef50006 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/NsightEclipse.xml
index a65448b..5dc2779 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/NsightEclipse.xml
@@ -71,6 +71,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/README.md b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/README.md
index 64233ea..5be86ce 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Image Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaCreateChannelDesc, cudaMallocArray, cudaFreeArra
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2017.vcxproj
index cc3b4f2..e37e536 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/boxFilter.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -119,6 +119,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2019.vcxproj
index 1ea4cef..0857361 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/boxFilter.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -115,6 +115,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2022.vcxproj
index 9861e9b..113b623 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/boxFilter.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -115,6 +115,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/Makefile
index 28f11d5..dd13e54 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/NsightEclipse.xml
index 2ed2585..6471a44 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/NsightEclipse.xml
@@ -40,6 +40,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/README.md b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/README.md
index efa6b52..8afcf17 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/README.md
@@ -10,7 +10,7 @@ Image Processing, Data Parallel Algorithms
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaFree, cudaDeviceSynchronize, cudaMemcpyToSymbol, cudaMalloc
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable.cu.hip
index e69de29..4180aa8 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable.cu.hip
@@ -0,0 +1,216 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+
+#include <hip/hip_runtime.h>
+#include <assert.h>
+#include "helper_cuda_hipified.h"
+#include <hip/hip_cooperative_groups.h>
+
+namespace cg = cooperative_groups;
+#include "convolutionSeparable_common.h"
+
+////////////////////////////////////////////////////////////////////////////////
+// Convolution kernel storage
+////////////////////////////////////////////////////////////////////////////////
+__constant__ float c_Kernel[KERNEL_LENGTH];
+
+extern "C" void setConvolutionKernel(float *h_Kernel) {
+  hipMemcpyToSymbol(HIP_SYMBOL(c_Kernel), h_Kernel, KERNEL_LENGTH * sizeof(float));
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Row convolution filter
+////////////////////////////////////////////////////////////////////////////////
+#define ROWS_BLOCKDIM_X 16
+#define ROWS_BLOCKDIM_Y 4
+#define ROWS_RESULT_STEPS 8
+#define ROWS_HALO_STEPS 1
+
+__global__ void convolutionRowsKernel(float *d_Dst, float *d_Src, int imageW,
+                                      int imageH, int pitch) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  __shared__ float
+      s_Data[ROWS_BLOCKDIM_Y][(ROWS_RESULT_STEPS + 2 * ROWS_HALO_STEPS) *
+                              ROWS_BLOCKDIM_X];
+
+  // Offset to the left halo edge
+  const int baseX =
+      (blockIdx.x * ROWS_RESULT_STEPS - ROWS_HALO_STEPS) * ROWS_BLOCKDIM_X +
+      threadIdx.x;
+  const int baseY = blockIdx.y * ROWS_BLOCKDIM_Y + threadIdx.y;
+
+  d_Src += baseY * pitch + baseX;
+  d_Dst += baseY * pitch + baseX;
+
+// Load main data
+#pragma unroll
+
+  for (int i = ROWS_HALO_STEPS; i < ROWS_HALO_STEPS + ROWS_RESULT_STEPS; i++) {
+    s_Data[threadIdx.y][threadIdx.x + i * ROWS_BLOCKDIM_X] =
+        d_Src[i * ROWS_BLOCKDIM_X];
+  }
+
+// Load left halo
+#pragma unroll
+
+  for (int i = 0; i < ROWS_HALO_STEPS; i++) {
+    s_Data[threadIdx.y][threadIdx.x + i * ROWS_BLOCKDIM_X] =
+        (baseX >= -i * ROWS_BLOCKDIM_X) ? d_Src[i * ROWS_BLOCKDIM_X] : 0;
+  }
+
+// Load right halo
+#pragma unroll
+
+  for (int i = ROWS_HALO_STEPS + ROWS_RESULT_STEPS;
+       i < ROWS_HALO_STEPS + ROWS_RESULT_STEPS + ROWS_HALO_STEPS; i++) {
+    s_Data[threadIdx.y][threadIdx.x + i * ROWS_BLOCKDIM_X] =
+        (imageW - baseX > i * ROWS_BLOCKDIM_X) ? d_Src[i * ROWS_BLOCKDIM_X] : 0;
+  }
+
+  // Compute and store results
+  cg::sync(cta);
+#pragma unroll
+
+  for (int i = ROWS_HALO_STEPS; i < ROWS_HALO_STEPS + ROWS_RESULT_STEPS; i++) {
+    float sum = 0;
+
+#pragma unroll
+
+    for (int j = -KERNEL_RADIUS; j <= KERNEL_RADIUS; j++) {
+      sum += c_Kernel[KERNEL_RADIUS - j] *
+             s_Data[threadIdx.y][threadIdx.x + i * ROWS_BLOCKDIM_X + j];
+    }
+
+    d_Dst[i * ROWS_BLOCKDIM_X] = sum;
+  }
+}
+
+extern "C" void convolutionRowsGPU(float *d_Dst, float *d_Src, int imageW,
+                                   int imageH) {
+  assert(ROWS_BLOCKDIM_X * ROWS_HALO_STEPS >= KERNEL_RADIUS);
+  assert(imageW % (ROWS_RESULT_STEPS * ROWS_BLOCKDIM_X) == 0);
+  assert(imageH % ROWS_BLOCKDIM_Y == 0);
+
+  dim3 blocks(imageW / (ROWS_RESULT_STEPS * ROWS_BLOCKDIM_X),
+              imageH / ROWS_BLOCKDIM_Y);
+  dim3 threads(ROWS_BLOCKDIM_X, ROWS_BLOCKDIM_Y);
+
+  convolutionRowsKernel<<<blocks, threads>>>(d_Dst, d_Src, imageW, imageH,
+                                             imageW);
+  getLastCudaError("convolutionRowsKernel() execution failed\n");
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Column convolution filter
+////////////////////////////////////////////////////////////////////////////////
+#define COLUMNS_BLOCKDIM_X 16
+#define COLUMNS_BLOCKDIM_Y 8
+#define COLUMNS_RESULT_STEPS 8
+#define COLUMNS_HALO_STEPS 1
+
+__global__ void convolutionColumnsKernel(float *d_Dst, float *d_Src, int imageW,
+                                         int imageH, int pitch) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  __shared__ float s_Data[COLUMNS_BLOCKDIM_X][(COLUMNS_RESULT_STEPS +
+                                               2 * COLUMNS_HALO_STEPS) *
+                                                  COLUMNS_BLOCKDIM_Y +
+                                              1];
+
+  // Offset to the upper halo edge
+  const int baseX = blockIdx.x * COLUMNS_BLOCKDIM_X + threadIdx.x;
+  const int baseY = (blockIdx.y * COLUMNS_RESULT_STEPS - COLUMNS_HALO_STEPS) *
+                        COLUMNS_BLOCKDIM_Y +
+                    threadIdx.y;
+  d_Src += baseY * pitch + baseX;
+  d_Dst += baseY * pitch + baseX;
+
+// Main data
+#pragma unroll
+
+  for (int i = COLUMNS_HALO_STEPS;
+       i < COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS; i++) {
+    s_Data[threadIdx.x][threadIdx.y + i * COLUMNS_BLOCKDIM_Y] =
+        d_Src[i * COLUMNS_BLOCKDIM_Y * pitch];
+  }
+
+// Upper halo
+#pragma unroll
+
+  for (int i = 0; i < COLUMNS_HALO_STEPS; i++) {
+    s_Data[threadIdx.x][threadIdx.y + i * COLUMNS_BLOCKDIM_Y] =
+        (baseY >= -i * COLUMNS_BLOCKDIM_Y)
+            ? d_Src[i * COLUMNS_BLOCKDIM_Y * pitch]
+            : 0;
+  }
+
+// Lower halo
+#pragma unroll
+
+  for (int i = COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS;
+       i < COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS + COLUMNS_HALO_STEPS;
+       i++) {
+    s_Data[threadIdx.x][threadIdx.y + i * COLUMNS_BLOCKDIM_Y] =
+        (imageH - baseY > i * COLUMNS_BLOCKDIM_Y)
+            ? d_Src[i * COLUMNS_BLOCKDIM_Y * pitch]
+            : 0;
+  }
+
+  // Compute and store results
+  cg::sync(cta);
+#pragma unroll
+
+  for (int i = COLUMNS_HALO_STEPS;
+       i < COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS; i++) {
+    float sum = 0;
+#pragma unroll
+
+    for (int j = -KERNEL_RADIUS; j <= KERNEL_RADIUS; j++) {
+      sum += c_Kernel[KERNEL_RADIUS - j] *
+             s_Data[threadIdx.x][threadIdx.y + i * COLUMNS_BLOCKDIM_Y + j];
+    }
+
+    d_Dst[i * COLUMNS_BLOCKDIM_Y * pitch] = sum;
+  }
+}
+
+extern "C" void convolutionColumnsGPU(float *d_Dst, float *d_Src, int imageW,
+                                      int imageH) {
+  assert(COLUMNS_BLOCKDIM_Y * COLUMNS_HALO_STEPS >= KERNEL_RADIUS);
+  assert(imageW % COLUMNS_BLOCKDIM_X == 0);
+  assert(imageH % (COLUMNS_RESULT_STEPS * COLUMNS_BLOCKDIM_Y) == 0);
+
+  dim3 blocks(imageW / COLUMNS_BLOCKDIM_X,
+              imageH / (COLUMNS_RESULT_STEPS * COLUMNS_BLOCKDIM_Y));
+  dim3 threads(COLUMNS_BLOCKDIM_X, COLUMNS_BLOCKDIM_Y);
+
+  convolutionColumnsKernel<<<blocks, threads>>>(d_Dst, d_Src, imageW, imageH,
+                                                imageW);
+  getLastCudaError("convolutionColumnsKernel() execution failed\n");
+}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2017.vcxproj
index e397b7d..12140d6 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/convolutionSeparable.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2019.vcxproj
index ade5ab4..882b180 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/convolutionSeparable.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2022.vcxproj
index 9f9ba15..0bfe92a 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/convolutionSeparable.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/Makefile
index ea2f310..e063121 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/NsightEclipse.xml
index c1296a7..c2a9e14 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/NsightEclipse.xml
@@ -46,6 +46,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/README.md b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/README.md
index 9a09f43..b54a396 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/README.md
@@ -10,7 +10,7 @@ Image Processing, Texture, Data Parallel Algorithms
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaMallocArray, cudaFreeArray, cudaFree, cudaMemcpyToArray, cudaDev
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2017.vcxproj
index 6a5dcfb..1769a59 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/convolutionTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2019.vcxproj
index f645e1b..1a367ce 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/convolutionTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2022.vcxproj
index c31ac81..d9ff12c 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/convolutionTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/Makefile
index ad38d72..5986c7b 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/Makefile
@@ -331,7 +331,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/README.md b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/README.md
index bfe2f0c..39ec1cb 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/README.md
@@ -12,7 +12,7 @@ Debugging
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -32,7 +32,7 @@ cudaDeviceReset, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/Makefile
index 5f86ef1..0540bc0 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/NsightEclipse.xml
index 9af1eb1..adb0675 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/NsightEclipse.xml
@@ -44,6 +44,8 @@
     <scope>2:Video Codecs</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/README.md b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/README.md
index 9db35c1..7e0e24f 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/README.md
@@ -10,7 +10,7 @@ Image Processing, Video Compression
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMallocArray, cudaFreeArray, cudaFree, cudaMallocPitch, cudaDestroyTextureObj
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2017.vcxproj
index f714265..5044890 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/dct8x8.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -115,6 +115,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2019.vcxproj
index f82223c..8452c9d 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/dct8x8.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2022.vcxproj
index 28a848f..b0fd737 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/dct8x8.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/Makefile
index 2b5624a..54c371e 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/NsightEclipse.xml
index 0055997..74a1351 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/NsightEclipse.xml
@@ -39,6 +39,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/README.md b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/README.md
index 15e0799..bef2e95 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/README.md
@@ -10,7 +10,7 @@ Linear Algebra
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMalloc, cudaDeviceSynchronize, cudaMemcpy, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_large.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_large.cu.hip
index e69de29..0d8ff2f 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_large.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_large.cu.hip
@@ -0,0 +1,372 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/* Computation of eigenvalues of a large symmetric, tridiagonal matrix */
+
+// includes, system
+
+#include <hip/hip_runtime.h>
+#include <stdlib.h>
+#include <stdio.h>
+#include "rocprofiler.h"
+#include "HIPCHECK.h"
+#include <string.h>
+#include <math.h>
+#include <float.h>
+
+// includes, project
+#include "helper_functions.h"
+#include "helper_cuda_hipified.h"
+#include "config.h"
+#include "structs.h"
+#include "util.h"
+#include "matlab.h"
+
+#include "bisect_large.cuh"
+
+// includes, kernels
+#include "bisect_kernel_large.cuh"
+#include "bisect_kernel_large_onei.cuh"
+#include "bisect_kernel_large_multi.cuh"
+
+////////////////////////////////////////////////////////////////////////////////
+//! Initialize variables and memory for result
+//! @param  result handles to memory
+//! @param  matrix_size  size of the matrix
+////////////////////////////////////////////////////////////////////////////////
+void initResultDataLargeMatrix(ResultDataLarge &result,
+                               const unsigned int mat_size) {
+  // helper variables to initialize memory
+  unsigned int zero = 0;
+  unsigned int mat_size_f = sizeof(float) * mat_size;
+  unsigned int mat_size_ui = sizeof(unsigned int) * mat_size;
+
+  float *tempf = (float *)malloc(mat_size_f);
+  unsigned int *tempui = (unsigned int *)malloc(mat_size_ui);
+
+  for (unsigned int i = 0; i < mat_size; ++i) {
+    tempf[i] = 0.0f;
+    tempui[i] = 0;
+  }
+
+  // number of intervals containing only one eigenvalue after the first step
+  HIPCHECK(hipMalloc((void **)&result.g_num_one, sizeof(unsigned int)));
+  HIPCHECK(hipMemcpy(result.g_num_one, &zero, sizeof(unsigned int),
+                             hipMemcpyHostToDevice));
+
+  // number of (thread) blocks of intervals with multiple eigenvalues after
+  // the first iteration
+  HIPCHECK(
+      hipMalloc((void **)&result.g_num_blocks_mult, sizeof(unsigned int)));
+  HIPCHECK(hipMemcpy(result.g_num_blocks_mult, &zero,
+                             sizeof(unsigned int), hipMemcpyHostToDevice));
+
+  HIPCHECK(hipMalloc((void **)&result.g_left_one, mat_size_f));
+  HIPCHECK(hipMalloc((void **)&result.g_right_one, mat_size_f));
+  HIPCHECK(hipMalloc((void **)&result.g_pos_one, mat_size_ui));
+
+  HIPCHECK(hipMalloc((void **)&result.g_left_mult, mat_size_f));
+  HIPCHECK(hipMalloc((void **)&result.g_right_mult, mat_size_f));
+  HIPCHECK(hipMalloc((void **)&result.g_left_count_mult, mat_size_ui));
+  HIPCHECK(hipMalloc((void **)&result.g_right_count_mult, mat_size_ui));
+
+  HIPCHECK(
+      hipMemcpy(result.g_left_one, tempf, mat_size_f, hipMemcpyHostToDevice));
+  HIPCHECK(hipMemcpy(result.g_right_one, tempf, mat_size_f,
+                             hipMemcpyHostToDevice));
+  HIPCHECK(hipMemcpy(result.g_pos_one, tempui, mat_size_ui,
+                             hipMemcpyHostToDevice));
+
+  HIPCHECK(hipMemcpy(result.g_left_mult, tempf, mat_size_f,
+                             hipMemcpyHostToDevice));
+  HIPCHECK(hipMemcpy(result.g_right_mult, tempf, mat_size_f,
+                             hipMemcpyHostToDevice));
+  HIPCHECK(hipMemcpy(result.g_left_count_mult, tempui, mat_size_ui,
+                             hipMemcpyHostToDevice));
+  HIPCHECK(hipMemcpy(result.g_right_count_mult, tempui, mat_size_ui,
+                             hipMemcpyHostToDevice));
+
+  HIPCHECK(hipMalloc((void **)&result.g_blocks_mult, mat_size_ui));
+  HIPCHECK(hipMemcpy(result.g_blocks_mult, tempui, mat_size_ui,
+                             hipMemcpyHostToDevice));
+  HIPCHECK(hipMalloc((void **)&result.g_blocks_mult_sum, mat_size_ui));
+  HIPCHECK(hipMemcpy(result.g_blocks_mult_sum, tempui, mat_size_ui,
+                             hipMemcpyHostToDevice));
+
+  HIPCHECK(hipMalloc((void **)&result.g_lambda_mult, mat_size_f));
+  HIPCHECK(hipMemcpy(result.g_lambda_mult, tempf, mat_size_f,
+                             hipMemcpyHostToDevice));
+  HIPCHECK(hipMalloc((void **)&result.g_pos_mult, mat_size_ui));
+  HIPCHECK(hipMemcpy(result.g_pos_mult, tempf, mat_size_ui,
+                             hipMemcpyHostToDevice));
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Cleanup result memory
+//! @param result  handles to memory
+////////////////////////////////////////////////////////////////////////////////
+void cleanupResultDataLargeMatrix(ResultDataLarge &result) {
+  HIPCHECK(hipFree(result.g_num_one));
+  HIPCHECK(hipFree(result.g_num_blocks_mult));
+  HIPCHECK(hipFree(result.g_left_one));
+  HIPCHECK(hipFree(result.g_right_one));
+  HIPCHECK(hipFree(result.g_pos_one));
+  HIPCHECK(hipFree(result.g_left_mult));
+  HIPCHECK(hipFree(result.g_right_mult));
+  HIPCHECK(hipFree(result.g_left_count_mult));
+  HIPCHECK(hipFree(result.g_right_count_mult));
+  HIPCHECK(hipFree(result.g_blocks_mult));
+  HIPCHECK(hipFree(result.g_blocks_mult_sum));
+  HIPCHECK(hipFree(result.g_lambda_mult));
+  HIPCHECK(hipFree(result.g_pos_mult));
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Run the kernels to compute the eigenvalues for large matrices
+//! @param  input   handles to input data
+//! @param  result  handles to result data
+//! @param  mat_size  matrix size
+//! @param  precision  desired precision of eigenvalues
+//! @param  lg  lower limit of Gerschgorin interval
+//! @param  ug  upper limit of Gerschgorin interval
+//! @param  iterations  number of iterations (for timing)
+////////////////////////////////////////////////////////////////////////////////
+void computeEigenvaluesLargeMatrix(const InputData &input,
+                                   const ResultDataLarge &result,
+                                   const unsigned int mat_size,
+                                   const float precision, const float lg,
+                                   const float ug,
+                                   const unsigned int iterations) {
+  dim3 blocks(1, 1, 1);
+  dim3 threads(MAX_THREADS_BLOCK, 1, 1);
+
+  StopWatchInterface *timer_step1 = NULL;
+  StopWatchInterface *timer_step2_one = NULL;
+  StopWatchInterface *timer_step2_mult = NULL;
+  StopWatchInterface *timer_total = NULL;
+  sdkCreateTimer(&timer_step1);
+  sdkCreateTimer(&timer_step2_one);
+  sdkCreateTimer(&timer_step2_mult);
+  sdkCreateTimer(&timer_total);
+
+  sdkStartTimer(&timer_total);
+
+  // do for multiple iterations to improve timing accuracy
+  for (unsigned int iter = 0; iter < iterations; ++iter) {
+    sdkStartTimer(&timer_step1);
+    bisectKernelLarge<<<blocks, threads>>>(
+        input.g_a, input.g_b, mat_size, lg, ug, 0, mat_size, precision,
+        result.g_num_one, result.g_num_blocks_mult, result.g_left_one,
+        result.g_right_one, result.g_pos_one, result.g_left_mult,
+        result.g_right_mult, result.g_left_count_mult,
+        result.g_right_count_mult, result.g_blocks_mult,
+        result.g_blocks_mult_sum);
+
+    getLastCudaError("Kernel launch failed.");
+    HIPCHECK(hipDeviceSynchronize());
+    sdkStopTimer(&timer_step1);
+
+    // get the number of intervals containing one eigenvalue after the first
+    // processing step
+    unsigned int num_one_intervals;
+    HIPCHECK(hipMemcpy(&num_one_intervals, result.g_num_one,
+                               sizeof(unsigned int), hipMemcpyDeviceToHost));
+
+    dim3 grid_onei;
+    grid_onei.x = getNumBlocksLinear(num_one_intervals, MAX_THREADS_BLOCK);
+    dim3 threads_onei;
+    // use always max number of available threads to better balance load times
+    // for matrix data
+    threads_onei.x = MAX_THREADS_BLOCK;
+
+    // compute eigenvalues for intervals that contained only one eigenvalue
+    // after the first processing step
+    sdkStartTimer(&timer_step2_one);
+
+    bisectKernelLarge_OneIntervals<<<grid_onei, threads_onei>>>(
+        input.g_a, input.g_b, mat_size, num_one_intervals, result.g_left_one,
+        result.g_right_one, result.g_pos_one, precision);
+
+    getLastCudaError("bisectKernelLarge_OneIntervals() FAILED.");
+    HIPCHECK(hipDeviceSynchronize());
+    sdkStopTimer(&timer_step2_one);
+
+    // process intervals that contained more than one eigenvalue after
+    // the first processing step
+
+    // get the number of blocks of intervals that contain, in total when
+    // each interval contains only one eigenvalue, not more than
+    // MAX_THREADS_BLOCK threads
+    unsigned int num_blocks_mult = 0;
+    HIPCHECK(hipMemcpy(&num_blocks_mult, result.g_num_blocks_mult,
+                               sizeof(unsigned int), hipMemcpyDeviceToHost));
+
+    // setup the execution environment
+    dim3 grid_mult(num_blocks_mult, 1, 1);
+    dim3 threads_mult(MAX_THREADS_BLOCK, 1, 1);
+
+    sdkStartTimer(&timer_step2_mult);
+
+    bisectKernelLarge_MultIntervals<<<grid_mult, threads_mult>>>(
+        input.g_a, input.g_b, mat_size, result.g_blocks_mult,
+        result.g_blocks_mult_sum, result.g_left_mult, result.g_right_mult,
+        result.g_left_count_mult, result.g_right_count_mult,
+        result.g_lambda_mult, result.g_pos_mult, precision);
+
+    getLastCudaError("bisectKernelLarge_MultIntervals() FAILED.");
+    HIPCHECK(hipDeviceSynchronize());
+    sdkStopTimer(&timer_step2_mult);
+  }
+
+  sdkStopTimer(&timer_total);
+
+  printf("Average time step 1: %f ms\n",
+         sdkGetTimerValue(&timer_step1) / (float)iterations);
+  printf("Average time step 2, one intervals: %f ms\n",
+         sdkGetTimerValue(&timer_step2_one) / (float)iterations);
+  printf("Average time step 2, mult intervals: %f ms\n",
+         sdkGetTimerValue(&timer_step2_mult) / (float)iterations);
+
+  printf("Average time TOTAL: %f ms\n",
+         sdkGetTimerValue(&timer_total) / (float)iterations);
+
+  sdkDeleteTimer(&timer_step1);
+  sdkDeleteTimer(&timer_step2_one);
+  sdkDeleteTimer(&timer_step2_mult);
+  sdkDeleteTimer(&timer_total);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Process the result, that is obtain result from device and do simple sanity
+//! checking
+//! @param  input   handles to input data
+//! @param  result  handles to result data
+//! @param  mat_size  matrix size
+//! @param  filename  output filename
+////////////////////////////////////////////////////////////////////////////////
+bool processResultDataLargeMatrix(const InputData &input,
+                                  const ResultDataLarge &result,
+                                  const unsigned int mat_size,
+                                  const char *filename,
+                                  const unsigned int user_defined,
+                                  char *exec_path) {
+  bool bCompareResult = false;
+  const unsigned int mat_size_ui = sizeof(unsigned int) * mat_size;
+  const unsigned int mat_size_f = sizeof(float) * mat_size;
+
+  // copy data from intervals that contained more than one eigenvalue after
+  // the first processing step
+  float *lambda_mult = (float *)malloc(sizeof(float) * mat_size);
+  HIPCHECK(hipMemcpy(lambda_mult, result.g_lambda_mult,
+                             sizeof(float) * mat_size, hipMemcpyDeviceToHost));
+  unsigned int *pos_mult =
+      (unsigned int *)malloc(sizeof(unsigned int) * mat_size);
+  HIPCHECK(hipMemcpy(pos_mult, result.g_pos_mult,
+                             sizeof(unsigned int) * mat_size,
+                             hipMemcpyDeviceToHost));
+
+  unsigned int *blocks_mult_sum =
+      (unsigned int *)malloc(sizeof(unsigned int) * mat_size);
+  HIPCHECK(hipMemcpy(blocks_mult_sum, result.g_blocks_mult_sum,
+                             sizeof(unsigned int) * mat_size,
+                             hipMemcpyDeviceToHost));
+
+  unsigned int num_one_intervals;
+  HIPCHECK(hipMemcpy(&num_one_intervals, result.g_num_one,
+                             sizeof(unsigned int), hipMemcpyDeviceToHost));
+
+  unsigned int sum_blocks_mult = mat_size - num_one_intervals;
+
+  // copy data for intervals that contained one eigenvalue after the first
+  // processing step
+  float *left_one = (float *)malloc(mat_size_f);
+  float *right_one = (float *)malloc(mat_size_f);
+  unsigned int *pos_one = (unsigned int *)malloc(mat_size_ui);
+  HIPCHECK(hipMemcpy(left_one, result.g_left_one, mat_size_f,
+                             hipMemcpyDeviceToHost));
+  HIPCHECK(hipMemcpy(right_one, result.g_right_one, mat_size_f,
+                             hipMemcpyDeviceToHost));
+  HIPCHECK(hipMemcpy(pos_one, result.g_pos_one, mat_size_ui,
+                             hipMemcpyDeviceToHost));
+
+  // extract eigenvalues
+  float *eigenvals = (float *)malloc(mat_size_f);
+
+  // singleton intervals generated in the second step
+  for (unsigned int i = 0; i < sum_blocks_mult; ++i) {
+    eigenvals[pos_mult[i] - 1] = lambda_mult[i];
+  }
+
+  // singleton intervals generated in the first step
+  unsigned int index = 0;
+
+  for (unsigned int i = 0; i < num_one_intervals; ++i, ++index) {
+    eigenvals[pos_one[i] - 1] = left_one[i];
+  }
+
+  if (1 == user_defined) {
+    // store result
+    writeTridiagSymMatlab(filename, input.a, input.b + 1, eigenvals, mat_size);
+    // getLastCudaError( sdkWriteFilef( filename, eigenvals, mat_size, 0.0f));
+
+    printf("User requests non-default argument(s), skipping self-check!\n");
+    bCompareResult = true;
+  } else {
+    // compare with reference solution
+
+    float *reference = NULL;
+    unsigned int input_data_size = 0;
+
+    char *ref_path = sdkFindFilePath("reference.dat", exec_path);
+    assert(NULL != ref_path);
+    sdkReadFile(ref_path, &reference, &input_data_size, false);
+    assert(input_data_size == mat_size);
+
+    // there's an imprecision of Sturm count computation which makes an
+    // additional offset necessary
+    float tolerance = 1.0e-5f + 5.0e-6f;
+
+    if (sdkCompareL2fe(reference, eigenvals, mat_size, tolerance) == true) {
+      bCompareResult = true;
+    } else {
+      bCompareResult = false;
+    }
+
+    free(ref_path);
+    free(reference);
+  }
+
+  freePtr(eigenvals);
+  freePtr(lambda_mult);
+  freePtr(pos_mult);
+  freePtr(blocks_mult_sum);
+  freePtr(left_one);
+  freePtr(right_one);
+  freePtr(pos_one);
+
+  return bCompareResult;
+}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_small.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_small.cu.hip
index e69de29..aa1f8a5 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_small.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_small.cu.hip
@@ -0,0 +1,186 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/* Computation of eigenvalues of a small symmetric, tridiagonal matrix */
+
+// includes, system
+
+#include <hip/hip_runtime.h>
+#include <stdlib.h>
+#include <stdio.h>
+#include "rocprofiler.h"
+#include "HIPCHECK.h"
+#include <string.h>
+#include <math.h>
+#include <float.h>
+
+// includes, project
+#include "helper_functions.h"
+#include "helper_cuda_hipified.h"
+#include "config.h"
+#include "structs.h"
+#include "matlab.h"
+
+// includes, kernels
+#include "bisect_kernel_small.cuh"
+
+// includes, file
+#include "bisect_small.cuh"
+
+////////////////////////////////////////////////////////////////////////////////
+//! Determine eigenvalues for matrices smaller than MAX_SMALL_MATRIX
+//! @param TimingIterations  number of iterations for timing
+//! @param  input  handles to input data of kernel
+//! @param  result handles to result of kernel
+//! @param  mat_size  matrix size
+//! @param  lg  lower limit of Gerschgorin interval
+//! @param  ug  upper limit of Gerschgorin interval
+//! @param  precision  desired precision of eigenvalues
+//! @param  iterations  number of iterations for timing
+////////////////////////////////////////////////////////////////////////////////
+void computeEigenvaluesSmallMatrix(const InputData &input,
+                                   ResultDataSmall &result,
+                                   const unsigned int mat_size, const float lg,
+                                   const float ug, const float precision,
+                                   const unsigned int iterations) {
+  StopWatchInterface *timer = NULL;
+  sdkCreateTimer(&timer);
+  sdkStartTimer(&timer);
+
+  for (unsigned int i = 0; i < iterations; ++i) {
+    dim3 blocks(1, 1, 1);
+    dim3 threads(MAX_THREADS_BLOCK_SMALL_MATRIX, 1, 1);
+
+    bisectKernel<<<blocks, threads>>>(input.g_a, input.g_b, mat_size,
+                                      result.g_left, result.g_right,
+                                      result.g_left_count, result.g_right_count,
+                                      lg, ug, 0, mat_size, precision);
+  }
+
+  HIPCHECK(hipDeviceSynchronize());
+  sdkStopTimer(&timer);
+  getLastCudaError("Kernel launch failed");
+  printf("Average time: %f ms (%i iterations)\n",
+         sdkGetTimerValue(&timer) / (float)iterations, iterations);
+
+  sdkDeleteTimer(&timer);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Initialize variables and memory for the result for small matrices
+//! @param result  handles to the necessary memory
+//! @param  mat_size  matrix_size
+////////////////////////////////////////////////////////////////////////////////
+void initResultSmallMatrix(ResultDataSmall &result,
+                           const unsigned int mat_size) {
+  result.mat_size_f = sizeof(float) * mat_size;
+  result.mat_size_ui = sizeof(unsigned int) * mat_size;
+
+  result.eigenvalues = (float *)malloc(result.mat_size_f);
+
+  // helper variables
+  result.zero_f = (float *)malloc(result.mat_size_f);
+  result.zero_ui = (unsigned int *)malloc(result.mat_size_ui);
+
+  for (unsigned int i = 0; i < mat_size; ++i) {
+    result.zero_f[i] = 0.0f;
+    result.zero_ui[i] = 0;
+
+    result.eigenvalues[i] = 0.0f;
+  }
+
+  HIPCHECK(hipMalloc((void **)&result.g_left, result.mat_size_f));
+  HIPCHECK(hipMalloc((void **)&result.g_right, result.mat_size_f));
+
+  HIPCHECK(
+      hipMalloc((void **)&result.g_left_count, result.mat_size_ui));
+  HIPCHECK(
+      hipMalloc((void **)&result.g_right_count, result.mat_size_ui));
+
+  // initialize result memory
+  HIPCHECK(hipMemcpy(result.g_left, result.zero_f, result.mat_size_f,
+                             hipMemcpyHostToDevice));
+  HIPCHECK(hipMemcpy(result.g_right, result.zero_f, result.mat_size_f,
+                             hipMemcpyHostToDevice));
+  HIPCHECK(hipMemcpy(result.g_right_count, result.zero_ui,
+                             result.mat_size_ui, hipMemcpyHostToDevice));
+  HIPCHECK(hipMemcpy(result.g_left_count, result.zero_ui,
+                             result.mat_size_ui, hipMemcpyHostToDevice));
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Cleanup memory and variables for result for small matrices
+//! @param  result  handle to variables
+////////////////////////////////////////////////////////////////////////////////
+void cleanupResultSmallMatrix(ResultDataSmall &result) {
+  freePtr(result.eigenvalues);
+  freePtr(result.zero_f);
+  freePtr(result.zero_ui);
+
+  HIPCHECK(hipFree(result.g_left));
+  HIPCHECK(hipFree(result.g_right));
+  HIPCHECK(hipFree(result.g_left_count));
+  HIPCHECK(hipFree(result.g_right_count));
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Process the result obtained on the device, that is transfer to host and
+//! perform basic sanity checking
+//! @param  input  handles to input data
+//! @param  result  handles to result data
+//! @param  mat_size   matrix size
+//! @param  filename  output filename
+////////////////////////////////////////////////////////////////////////////////
+void processResultSmallMatrix(const InputData &input,
+                              const ResultDataSmall &result,
+                              const unsigned int mat_size,
+                              const char *filename) {
+  const unsigned int mat_size_f = sizeof(float) * mat_size;
+  const unsigned int mat_size_ui = sizeof(unsigned int) * mat_size;
+
+  // copy data back to host
+  float *left = (float *)malloc(mat_size_f);
+  unsigned int *left_count = (unsigned int *)malloc(mat_size_ui);
+
+  HIPCHECK(
+      hipMemcpy(left, result.g_left, mat_size_f, hipMemcpyDeviceToHost));
+  HIPCHECK(hipMemcpy(left_count, result.g_left_count, mat_size_ui,
+                             hipMemcpyDeviceToHost));
+
+  float *eigenvalues = (float *)malloc(mat_size_f);
+
+  for (unsigned int i = 0; i < mat_size; ++i) {
+    eigenvalues[left_count[i]] = left[i];
+  }
+
+  // save result in matlab format
+  writeTridiagSymMatlab(filename, input.a, input.b + 1, eigenvalues, mat_size);
+
+  freePtr(left);
+  freePtr(left_count);
+  freePtr(eigenvalues);
+}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_util.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_util.cu.hip
index e69de29..1061c2a 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_util.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_util.cu.hip
@@ -0,0 +1,530 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/* Utility / shared functionality for bisection kernels */
+
+#ifndef _BISECT_UTIL_H_
+#define _BISECT_UTIL_H_
+
+#include <hip/hip_runtime.h>
+#include <hip/hip_cooperative_groups.h>
+
+namespace cg = cooperative_groups;
+
+// includes, project
+#include "config.h"
+#include "util.h"
+
+////////////////////////////////////////////////////////////////////////////////
+//! Compute the next lower power of two of n
+//! @param  n  number for which next higher power of two is sought
+////////////////////////////////////////////////////////////////////////////////
+__device__ inline int floorPow2(int n) {
+  // early out if already power of two
+  if (0 == (n & (n - 1))) {
+    return n;
+  }
+
+  int exp;
+  frexp((float)n, &exp);
+  return (1 << (exp - 1));
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Compute the next higher power of two of n
+//! @param  n  number for which next higher power of two is sought
+////////////////////////////////////////////////////////////////////////////////
+__device__ inline int ceilPow2(int n) {
+  // early out if already power of two
+  if (0 == (n & (n - 1))) {
+    return n;
+  }
+
+  int exp;
+  frexp((float)n, &exp);
+  return (1 << exp);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Compute midpoint of interval [\a left, \a right] avoiding overflow if
+//! possible
+//! @param left   left / lower limit of interval
+//! @param right  right / upper limit of interval
+////////////////////////////////////////////////////////////////////////////////
+__device__ inline float computeMidpoint(const float left, const float right) {
+  float mid;
+
+  if (sign_f(left) == sign_f(right)) {
+    mid = left + (right - left) * 0.5f;
+  } else {
+    mid = (left + right) * 0.5f;
+  }
+
+  return mid;
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Check if interval converged and store appropriately
+//! @param  addr    address where to store the information of the interval
+//! @param  s_left  shared memory storage for left interval limits
+//! @param  s_right  shared memory storage for right interval limits
+//! @param  s_left_count  shared memory storage for number of eigenvalues less
+//!                       than left interval limits
+//! @param  s_right_count  shared memory storage for number of eigenvalues less
+//!                       than right interval limits
+//! @param  left   lower limit of interval
+//! @param  right  upper limit of interval
+//! @param  left_count  eigenvalues less than \a left
+//! @param  right_count  eigenvalues less than \a right
+//! @param  precision  desired precision for eigenvalues
+////////////////////////////////////////////////////////////////////////////////
+template <class S, class T>
+__device__ void storeInterval(unsigned int addr, float *s_left, float *s_right,
+                              T *s_left_count, T *s_right_count, float left,
+                              float right, S left_count, S right_count,
+                              float precision) {
+  s_left_count[addr] = left_count;
+  s_right_count[addr] = right_count;
+
+  // check if interval converged
+  float t0 = abs(right - left);
+  float t1 = max(abs(left), abs(right)) * precision;
+
+  if (t0 <= max(MIN_ABS_INTERVAL, t1)) {
+    // compute mid point
+    float lambda = computeMidpoint(left, right);
+
+    // mark as converged
+    s_left[addr] = lambda;
+    s_right[addr] = lambda;
+  } else {
+    // store current limits
+    s_left[addr] = left;
+    s_right[addr] = right;
+  }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Compute number of eigenvalues that are smaller than x given a symmetric,
+//! real, and tridiagonal matrix
+//! @param  g_d  diagonal elements stored in global memory
+//! @param  g_s  superdiagonal elements stored in global memory
+//! @param  n    size of matrix
+//! @param  x    value for which the number of eigenvalues that are smaller is
+//!              seeked
+//! @param  tid  thread identified (e.g. threadIdx.x or gtid)
+//! @param  num_intervals_active  number of active intervals / threads that
+//!                               currently process an interval
+//! @param  s_d  scratch space to store diagonal entries of the tridiagonal
+//!              matrix in shared memory
+//! @param  s_s  scratch space to store superdiagonal entries of the tridiagonal
+//!              matrix in shared memory
+//! @param  converged  flag if the current thread is already converged (that
+//!         is count does not have to be computed)
+////////////////////////////////////////////////////////////////////////////////
+__device__ inline unsigned int computeNumSmallerEigenvals(
+    float *g_d, float *g_s, const unsigned int n, const float x,
+    const unsigned int tid, const unsigned int num_intervals_active, float *s_d,
+    float *s_s, unsigned int converged, cg::thread_block cta) {
+  float delta = 1.0f;
+  unsigned int count = 0;
+
+  cg::sync(cta);
+
+  // read data into shared memory
+  if (threadIdx.x < n) {
+    s_d[threadIdx.x] = *(g_d + threadIdx.x);
+    s_s[threadIdx.x] = *(g_s + threadIdx.x - 1);
+  }
+
+  cg::sync(cta);
+
+  // perform loop only for active threads
+  if ((tid < num_intervals_active) && (0 == converged)) {
+    // perform (optimized) Gaussian elimination to determine the number
+    // of eigenvalues that are smaller than n
+    for (unsigned int k = 0; k < n; ++k) {
+      delta = s_d[k] - x - (s_s[k] * s_s[k]) / delta;
+      count += (delta < 0) ? 1 : 0;
+    }
+
+  }  // end if thread currently processing an interval
+
+  return count;
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Compute number of eigenvalues that are smaller than x given a symmetric,
+//! real, and tridiagonal matrix
+//! @param  g_d  diagonal elements stored in global memory
+//! @param  g_s  superdiagonal elements stored in global memory
+//! @param  n    size of matrix
+//! @param  x    value for which the number of eigenvalues that are smaller is
+//!              seeked
+//! @param  tid  thread identified (e.g. threadIdx.x or gtid)
+//! @param  num_intervals_active  number of active intervals / threads that
+//!                               currently process an interval
+//! @param  s_d  scratch space to store diagonal entries of the tridiagonal
+//!              matrix in shared memory
+//! @param  s_s  scratch space to store superdiagonal entries of the tridiagonal
+//!              matrix in shared memory
+//! @param  converged  flag if the current thread is already converged (that
+//!         is count does not have to be computed)
+////////////////////////////////////////////////////////////////////////////////
+__device__ inline unsigned int computeNumSmallerEigenvalsLarge(
+    float *g_d, float *g_s, const unsigned int n, const float x,
+    const unsigned int tid, const unsigned int num_intervals_active, float *s_d,
+    float *s_s, unsigned int converged, cg::thread_block cta) {
+  float delta = 1.0f;
+  unsigned int count = 0;
+
+  unsigned int rem = n;
+
+  // do until whole diagonal and superdiagonal has been loaded and processed
+  for (unsigned int i = 0; i < n; i += blockDim.x) {
+    cg::sync(cta);
+
+    // read new chunk of data into shared memory
+    if ((i + threadIdx.x) < n) {
+      s_d[threadIdx.x] = *(g_d + i + threadIdx.x);
+      s_s[threadIdx.x] = *(g_s + i + threadIdx.x - 1);
+    }
+
+    cg::sync(cta);
+
+    if (tid < num_intervals_active) {
+      // perform (optimized) Gaussian elimination to determine the number
+      // of eigenvalues that are smaller than n
+      for (unsigned int k = 0; k < min((int)rem, (int)blockDim.x); ++k) {
+        delta = s_d[k] - x - (s_s[k] * s_s[k]) / delta;
+        // delta = (abs( delta) < (1.0e-10)) ? -(1.0e-10) : delta;
+        count += (delta < 0) ? 1 : 0;
+      }
+
+    }  // end if thread currently processing an interval
+
+    rem -= blockDim.x;
+  }
+
+  return count;
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Store all non-empty intervals resulting from the subdivision of the interval
+//! currently processed by the thread
+//! @param  addr  base address for storing intervals
+//! @param  num_threads_active  number of threads / intervals in current sweep
+//! @param  s_left  shared memory storage for left interval limits
+//! @param  s_right  shared memory storage for right interval limits
+//! @param  s_left_count  shared memory storage for number of eigenvalues less
+//!                       than left interval limits
+//! @param  s_right_count  shared memory storage for number of eigenvalues less
+//!                       than right interval limits
+//! @param  left   lower limit of interval
+//! @param  mid    midpoint of interval
+//! @param  right  upper limit of interval
+//! @param  left_count  eigenvalues less than \a left
+//! @param  mid_count  eigenvalues less than \a mid
+//! @param  right_count  eigenvalues less than \a right
+//! @param  precision  desired precision for eigenvalues
+//! @param  compact_second_chunk  shared mem flag if second chunk is used and
+//!                               ergo requires compaction
+//! @param  s_compaction_list_exc  helper array for stream compaction,
+//!                                s_compaction_list_exc[tid] = 1 when the
+//!                                thread generated two child intervals
+//! @is_active_interval  mark is thread has a second non-empty child interval
+////////////////////////////////////////////////////////////////////////////////
+template <class S, class T>
+__device__ void storeNonEmptyIntervals(
+    unsigned int addr, const unsigned int num_threads_active, float *s_left,
+    float *s_right, T *s_left_count, T *s_right_count, float left, float mid,
+    float right, const S left_count, const S mid_count, const S right_count,
+    float precision, unsigned int &compact_second_chunk,
+    T *s_compaction_list_exc, unsigned int &is_active_second) {
+  // check if both child intervals are valid
+  if ((left_count != mid_count) && (mid_count != right_count)) {
+    // store the left interval
+    storeInterval(addr, s_left, s_right, s_left_count, s_right_count, left, mid,
+                  left_count, mid_count, precision);
+
+    // mark that a second interval has been generated, only stored after
+    // stream compaction of second chunk
+    is_active_second = 1;
+    s_compaction_list_exc[threadIdx.x] = 1;
+    atomicExch(&compact_second_chunk, 1);
+  } else {
+    // only one non-empty child interval
+
+    // mark that no second child
+    is_active_second = 0;
+    s_compaction_list_exc[threadIdx.x] = 0;
+
+    // store the one valid child interval
+    if (left_count != mid_count) {
+      storeInterval(addr, s_left, s_right, s_left_count, s_right_count, left,
+                    mid, left_count, mid_count, precision);
+    } else {
+      storeInterval(addr, s_left, s_right, s_left_count, s_right_count, mid,
+                    right, mid_count, right_count, precision);
+    }
+  }
+}
+////////////////////////////////////////////////////////////////////////////////
+//! Create indices for compaction, that is process \a s_compaction_list_exc
+//! which is 1 for intervals that generated a second child and 0 otherwise
+//! and create for each of the non-zero elements the index where the new
+//! interval belongs to in a compact representation of all generated second
+//! childs
+//! @param   s_compaction_list_exc  list containing the flags which threads
+//!                                 generated two children
+//! @param   num_threads_compaction number of threads to employ for compaction
+////////////////////////////////////////////////////////////////////////////////
+template <class T>
+__device__ void createIndicesCompaction(T *s_compaction_list_exc,
+                                        unsigned int num_threads_compaction,
+                                        cg::thread_block cta) {
+  unsigned int offset = 1;
+  const unsigned int tid = threadIdx.x;
+
+  // higher levels of scan tree
+  for (int d = (num_threads_compaction >> 1); d > 0; d >>= 1) {
+    cg::sync(cta);
+
+    if (tid < d) {
+      unsigned int ai = offset * (2 * tid + 1) - 1;
+      unsigned int bi = offset * (2 * tid + 2) - 1;
+
+      s_compaction_list_exc[bi] =
+          s_compaction_list_exc[bi] + s_compaction_list_exc[ai];
+    }
+
+    offset <<= 1;
+  }
+
+  // traverse down tree: first down to level 2 across
+  for (int d = 2; d < num_threads_compaction; d <<= 1) {
+    offset >>= 1;
+    cg::sync(cta);
+
+    if (tid < (d - 1)) {
+      unsigned int ai = offset * (tid + 1) - 1;
+      unsigned int bi = ai + (offset >> 1);
+
+      s_compaction_list_exc[bi] =
+          s_compaction_list_exc[bi] + s_compaction_list_exc[ai];
+    }
+  }
+
+  cg::sync(cta);
+}
+
+///////////////////////////////////////////////////////////////////////////////
+//! Perform stream compaction for second child intervals
+//! @param  s_left  shared
+//! @param  s_left  shared memory storage for left interval limits
+//! @param  s_right  shared memory storage for right interval limits
+//! @param  s_left_count  shared memory storage for number of eigenvalues less
+//!                       than left interval limits
+//! @param  s_right_count  shared memory storage for number of eigenvalues less
+//!                       than right interval limits
+//! @param  mid    midpoint of current interval (left of new interval)
+//! @param  right  upper limit of interval
+//! @param  mid_count  eigenvalues less than \a mid
+//! @param  s_compaction_list  list containing the indices where the data has
+//!         to be stored
+//! @param  num_threads_active  number of active threads / intervals
+//! @is_active_interval  mark is thread has a second non-empty child interval
+///////////////////////////////////////////////////////////////////////////////
+template <class T>
+__device__ void compactIntervals(float *s_left, float *s_right, T *s_left_count,
+                                 T *s_right_count, float mid, float right,
+                                 unsigned int mid_count,
+                                 unsigned int right_count, T *s_compaction_list,
+                                 unsigned int num_threads_active,
+                                 unsigned int is_active_second) {
+  const unsigned int tid = threadIdx.x;
+
+  // perform compaction / copy data for all threads where the second
+  // child is not dead
+  if ((tid < num_threads_active) && (1 == is_active_second)) {
+    unsigned int addr_w = num_threads_active + s_compaction_list[tid];
+
+    s_left[addr_w] = mid;
+    s_right[addr_w] = right;
+    s_left_count[addr_w] = mid_count;
+    s_right_count[addr_w] = right_count;
+  }
+}
+
+///////////////////////////////////////////////////////////////////////////////
+//! Store intervals that have already converged (w.r.t. the desired precision),
+//! duplicating intervals that contain multiple eigenvalues
+//! @param  s_left  shared memory storage for left interval limits
+//! @param  s_right  shared memory storage for right interval limits
+//! @param  s_left_count  shared memory storage for number of eigenvalues less
+//!                       than left interval limits
+//! @param  s_right_count  shared memory storage for number of eigenvalues less
+//!                       than right interval limits
+//! @param  left   lower limit of interval
+//! @param  mid    midpoint of interval (updated if split is necessary)
+//! @param  right  upper limit of interval
+//! @param  left_count  eigenvalues less than \a left
+//! @param  mid_count  eigenvalues less than \a mid
+//! @param  right_count  eigenvalues less than \a right
+//! @param  s_compaction_list_exc  helper array for stream compaction, updated
+//!                                at tid if split is necessary
+//! @param  compact_second_chunk  shared mem flag if second chunk is used and
+//!                               ergo requires compaction
+//! @param  num_threads_active  number of active threads / intervals
+///////////////////////////////////////////////////////////////////////////////
+template <class T, class S>
+__device__ void storeIntervalConverged(float *s_left, float *s_right,
+                                       T *s_left_count, T *s_right_count,
+                                       float &left, float &mid, float &right,
+                                       S &left_count, S &mid_count,
+                                       S &right_count, T *s_compaction_list_exc,
+                                       unsigned int &compact_second_chunk,
+                                       const unsigned int num_threads_active) {
+  const unsigned int tid = threadIdx.x;
+  const unsigned int multiplicity = right_count - left_count;
+
+  // check multiplicity of eigenvalue
+  if (1 == multiplicity) {
+    // just re-store intervals, simple eigenvalue
+    s_left[tid] = left;
+    s_right[tid] = right;
+    s_left_count[tid] = left_count;
+    s_right_count[tid] = right_count;
+
+    // mark that no second child / clear
+    s_right_count[tid + num_threads_active] = 0;
+    s_compaction_list_exc[tid] = 0;
+  } else {
+    // number of eigenvalues after the split less than mid
+    mid_count = left_count + (multiplicity >> 1);
+
+    // store left interval
+    s_left[tid] = left;
+    s_right[tid] = right;
+    s_left_count[tid] = left_count;
+    s_right_count[tid] = mid_count;
+
+    mid = left;
+
+    // mark that second child interval exists
+    s_right_count[tid + num_threads_active] = right_count;
+    s_compaction_list_exc[tid] = 1;
+    compact_second_chunk = 1;
+  }
+}
+
+template <class T, class S>
+__device__ void storeIntervalConverged(float *s_left, float *s_right,
+                                       T *s_left_count, T *s_right_count,
+                                       float &left, float &mid, float &right,
+                                       S &left_count, S &mid_count,
+                                       S &right_count, T *s_compaction_list_exc,
+                                       unsigned int &compact_second_chunk,
+                                       const unsigned int num_threads_active,
+                                       unsigned int &is_active_second) {
+  const unsigned int tid = threadIdx.x;
+  const unsigned int multiplicity = right_count - left_count;
+
+  // check multiplicity of eigenvalue
+  if (1 == multiplicity) {
+    // just re-store intervals, simple eigenvalue
+    s_left[tid] = left;
+    s_right[tid] = right;
+    s_left_count[tid] = left_count;
+    s_right_count[tid] = right_count;
+
+    // mark that no second child / clear
+    is_active_second = 0;
+    s_compaction_list_exc[tid] = 0;
+  } else {
+    // number of eigenvalues after the split less than mid
+    mid_count = left_count + (multiplicity >> 1);
+
+    // store left interval
+    s_left[tid] = left;
+    s_right[tid] = right;
+    s_left_count[tid] = left_count;
+    s_right_count[tid] = mid_count;
+
+    mid = left;
+
+    // mark that second child interval exists
+    is_active_second = 1;
+    s_compaction_list_exc[tid] = 1;
+    compact_second_chunk = 1;
+  }
+}
+
+///////////////////////////////////////////////////////////////////////////////
+//! Subdivide interval if active and not already converged
+//! @param tid  id of thread
+//! @param  s_left  shared memory storage for left interval limits
+//! @param  s_right  shared memory storage for right interval limits
+//! @param  s_left_count  shared memory storage for number of eigenvalues less
+//!                       than left interval limits
+//! @param  s_right_count  shared memory storage for number of eigenvalues less
+//!                       than right interval limits
+//! @param  num_threads_active  number of active threads in warp
+//! @param  left   lower limit of interval
+//! @param  right  upper limit of interval
+//! @param  left_count  eigenvalues less than \a left
+//! @param  right_count  eigenvalues less than \a right
+//! @param  all_threads_converged  shared memory flag if all threads are
+//!                                 converged
+///////////////////////////////////////////////////////////////////////////////
+template <class T>
+__device__ void subdivideActiveInterval(
+    const unsigned int tid, float *s_left, float *s_right, T *s_left_count,
+    T *s_right_count, const unsigned int num_threads_active, float &left,
+    float &right, unsigned int &left_count, unsigned int &right_count,
+    float &mid, unsigned int &all_threads_converged) {
+  // for all active threads
+  if (tid < num_threads_active) {
+    left = s_left[tid];
+    right = s_right[tid];
+    left_count = s_left_count[tid];
+    right_count = s_right_count[tid];
+
+    // check if thread already converged
+    if (left != right) {
+      mid = computeMidpoint(left, right);
+      atomicExch(&all_threads_converged, 0);
+    } else if ((right_count - left_count) > 1) {
+      // mark as not converged if multiple eigenvalues enclosed
+      // duplicate interval in storeIntervalsConverged()
+      atomicExch(&all_threads_converged, 0);
+    }
+
+  }  // end for all active threads
+}
+
+#endif  // #ifndef _BISECT_UTIL_H_
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2017.vcxproj
index 217c3f2..e5a3127 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/eigenvalues.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -122,6 +122,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2019.vcxproj
index 92f7f21..8f84683 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/eigenvalues.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -118,6 +118,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2022.vcxproj
index 92d8f38..32faad5 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/eigenvalues.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -118,6 +118,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/main.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/main.cu.hip
index e69de29..304911e 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/main.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/main.cu.hip
@@ -0,0 +1,331 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/* Computation of eigenvalues of symmetric, tridiagonal matrix using
+ * bisection.
+ */
+
+// includes, system
+
+#include <hip/hip_runtime.h>
+#include <stdlib.h>
+#include <stdio.h>
+//#include "rocprofiler.h"
+#include <string.h>
+#include <math.h>
+#include <float.h>
+#include <assert.h>
+
+// includes, project
+#include "HIPCHECK.h"
+#include "helper_cuda_hipified.h"
+#include "helper_functions.h"
+//#include <helper_functions.h>
+//#include <helper_cuda.h>
+#include "config.h"
+#include "structs.h"
+#include "matlab.h"
+#include "util.h"
+#include "gerschgorin.h"
+
+#include "bisect_small.cuh"
+#include "bisect_large.cuh"
+
+////////////////////////////////////////////////////////////////////////////////
+// declaration, forward
+bool runTest(int argc, char **argv);
+
+////////////////////////////////////////////////////////////////////////////////
+// Program main
+////////////////////////////////////////////////////////////////////////////////
+int main(int argc, char **argv) {
+  bool bQAResults = false;
+
+  printf("Starting eigenvalues\n");
+
+  bQAResults = runTest(argc, argv);
+  printf("Test %s\n", bQAResults ? "Succeeded!" : "Failed!");
+
+  exit(bQAResults ? EXIT_SUCCESS : EXIT_FAILURE);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Initialize the input data to the algorithm
+//! @param input  handles to the input data
+//! @param exec_path  path where executable is run (argv[0])
+//! @param mat_size  size of the matrix
+//! @param user_defined  1 if the matrix size has been requested by the user,
+//!                      0 if the default size
+////////////////////////////////////////////////////////////////////////////////
+void initInputData(InputData &input, char *exec_path,
+                   const unsigned int mat_size,
+                   const unsigned int user_defined) {
+  // allocate memory
+  input.a = (float *)malloc(sizeof(float) * mat_size);
+  input.b = (float *)malloc(sizeof(float) * mat_size);
+
+  if (1 == user_defined) {
+    // initialize diagonal and superdiagonal entries with random values
+    srand(278217421);
+
+    // srand( clock());
+    for (unsigned int i = 0; i < mat_size; ++i) {
+      input.a[i] = (float)(2.0 * (((double)rand() / (double)RAND_MAX) - 0.5));
+      input.b[i] = (float)(2.0 * (((double)rand() / (double)RAND_MAX) - 0.5));
+    }
+
+    // the first element of s is used as padding on the device (thus the
+    // whole vector is copied to the device but the kernels are launched
+    // with (s+1) as start address
+    input.b[0] = 0.0f;
+  } else {
+    // read default matrix
+    unsigned int input_data_size = mat_size;
+    char *diag_path = sdkFindFilePath("diagonal.dat", exec_path);
+    assert(NULL != diag_path);
+    sdkReadFile(diag_path, &(input.a), &input_data_size, false);
+
+    char *sdiag_path = sdkFindFilePath("superdiagonal.dat", exec_path);
+    assert(NULL != sdiag_path);
+    sdkReadFile(sdiag_path, &(input.b), &input_data_size, false);
+
+    free(diag_path);
+    free(sdiag_path);
+  }
+
+  // allocate device memory for input
+  HIPCHECK(hipMalloc((void **)&(input.g_a), sizeof(float) * mat_size));
+  HIPCHECK(
+      hipMalloc((void **)&(input.g_b_raw), sizeof(float) * mat_size));
+
+  // copy data to device
+  HIPCHECK(hipMemcpy(input.g_a, input.a, sizeof(float) * mat_size,
+                             hipMemcpyHostToDevice));
+  HIPCHECK(hipMemcpy(input.g_b_raw, input.b, sizeof(float) * mat_size,
+                             hipMemcpyHostToDevice));
+
+  input.g_b = input.g_b_raw + 1;
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Clean up input data, in particular allocated memory
+//! @param input  handles to the input data
+////////////////////////////////////////////////////////////////////////////////
+void cleanupInputData(InputData &input) {
+  freePtr(input.a);
+  freePtr(input.b);
+
+  HIPCHECK(hipFree(input.g_a));
+  input.g_a = NULL;
+  HIPCHECK(hipFree(input.g_b_raw));
+  input.g_b_raw = NULL;
+  input.g_b = NULL;
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Check if a specific matrix size has to be used
+//! @param argc  number of command line arguments (from main(argc, argv)
+//! @param argv  pointers to command line arguments (from main(argc, argv)
+//! @param matrix_size  size of matrix, updated if specific size specified on
+//!                     command line
+////////////////////////////////////////////////////////////////////////////////
+void getMatrixSize(int argc, char **argv, unsigned int &mat_size,
+                   unsigned int &user_defined) {
+  int temp = -1;
+
+  if (checkCmdLineFlag(argc, (const char **)argv, "matrix-size")) {
+    temp = getCmdLineArgumentInt(argc, (const char **)argv, "matrix-size");
+  }
+
+  if (temp > 0) {
+    mat_size = (unsigned int)temp;
+    // data type short is used in the kernel
+    assert(mat_size < (1 << 16));
+
+    // mat_size should be large than 2
+    assert(mat_size >= 2);
+
+    user_defined = 1;
+  }
+
+  printf("Matrix size: %i x %i\n", mat_size, mat_size);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Check if a specific precision of the eigenvalue has to be obtained
+//! @param argc  number of command line arguments (from main(argc, argv)
+//! @param argv  pointers to command line arguments (from main(argc, argv)
+//! @param iters_timing  numbers of iterations for timing, updated if a
+//!                      specific number is specified on the command line
+//! @param user_defined  1 if the precision has been requested by the user,
+//!                      0 if the default size
+////////////////////////////////////////////////////////////////////////////////
+void getPrecision(int argc, char **argv, float &precision,
+                  unsigned int &user_defined) {
+  float temp = -1.0f;
+
+  if (checkCmdLineFlag(argc, (const char **)argv, "precision")) {
+    temp = getCmdLineArgumentFloat(argc, (const char **)argv, "precision");
+    printf("Precision is between [0.001, 0.000001]\n");
+  }
+
+  if (temp > 1e-6 && temp <= 0.001) {
+    precision = temp;
+    user_defined = 1;
+  }
+
+  printf("Precision: %f\n", precision);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Check if a particular number of iterations for timings has to be used
+//! @param argc  number of command line arguments (from main(argc, argv)
+//! @param argv  pointers to command line arguments (from main(argc, argv)
+//! @param  iters_timing  number of timing iterations, updated if user
+//!                       specific value
+////////////////////////////////////////////////////////////////////////////////
+void getItersTiming(int argc, char **argv, unsigned int &iters_timing) {
+  int temp = -1;
+
+  if (checkCmdLineFlag(argc, (const char **)argv, "iters-timing")) {
+    temp = getCmdLineArgumentInt(argc, (const char **)argv, "iters-timing");
+  }
+
+  if (temp > 0) {
+    iters_timing = temp;
+  }
+
+  printf("Iterations to be timed: %i\n", iters_timing);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Check if a particular filename has to be used for the file where the result
+//! is stored
+//! @param argc  number of command line arguments (from main(argc, argv)
+//! @param argv  pointers to command line arguments (from main(argc, argv)
+//! @param  filename  filename of result file, updated if user specified
+//!                   filename
+////////////////////////////////////////////////////////////////////////////////
+void getResultFilename(int argc, char **argv, char *&filename) {
+  char *temp = NULL;
+  getCmdLineArgumentString(argc, (const char **)argv, "filename-result", &temp);
+
+  if (NULL != temp) {
+    filename = (char *)malloc(sizeof(char) * strlen(temp));
+    strcpy(filename, temp);
+
+    free(temp);
+  }
+
+  printf("Result filename: '%s'\n", filename);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Run a simple test for CUDA
+////////////////////////////////////////////////////////////////////////////////
+bool runTest(int argc, char **argv) {
+  bool bCompareResult = false;
+
+  findCudaDevice(argc, (const char **)argv);
+
+  StopWatchInterface *timer = NULL;
+  StopWatchInterface *timer_total = NULL;
+  sdkCreateTimer(&timer);
+  sdkCreateTimer(&timer_total);
+
+  // default
+  unsigned int mat_size = 2048;
+  // flag if the matrix size is due to explicit user request
+  unsigned int user_defined = 0;
+  // desired precision of eigenvalues
+  float precision = 0.00001f;
+  unsigned int iters_timing = 100;
+  char *result_file = (char *)"eigenvalues.dat";
+
+  // check if there is a command line request for the matrix size
+  getMatrixSize(argc, argv, mat_size, user_defined);
+
+  // check if user requested specific precision
+  getPrecision(argc, argv, precision, user_defined);
+
+  // check if user requested specific number of iterations for timing
+  getItersTiming(argc, argv, iters_timing);
+
+  // file name for result file
+  getResultFilename(argc, argv, result_file);
+
+  // set up input
+  InputData input;
+  initInputData(input, argv[0], mat_size, user_defined);
+
+  // compute Gerschgorin interval
+  float lg = FLT_MAX;
+  float ug = -FLT_MAX;
+  computeGerschgorin(input.a, input.b + 1, mat_size, lg, ug);
+  printf("Gerschgorin interval: %f / %f\n", lg, ug);
+
+  // two kernels, for small matrices a lot of overhead can be avoided
+  if (mat_size <= MAX_SMALL_MATRIX) {
+    // initialize memory for result
+    ResultDataSmall result;
+    initResultSmallMatrix(result, mat_size);
+
+    // run the kernel
+    computeEigenvaluesSmallMatrix(input, result, mat_size, lg, ug, precision,
+                                  iters_timing);
+
+    // get the result from the device and do some sanity checks,
+    // save the result
+    processResultSmallMatrix(input, result, mat_size, result_file);
+
+    // clean up
+    cleanupResultSmallMatrix(result);
+
+    printf("User requests non-default argument(s), skipping self-check!\n");
+    bCompareResult = true;
+  } else {
+    // initialize memory for result
+    ResultDataLarge result;
+    initResultDataLargeMatrix(result, mat_size);
+
+    // run the kernel
+    computeEigenvaluesLargeMatrix(input, result, mat_size, precision, lg, ug,
+                                  iters_timing);
+
+    // get the result from the device and do some sanity checks
+    // save the result if user specified matrix size
+    bCompareResult = processResultDataLargeMatrix(
+        input, result, mat_size, result_file, user_defined, argv[0]);
+
+    // cleanup
+    cleanupResultDataLargeMatrix(result);
+  }
+
+  cleanupInputData(input);
+
+  return bCompareResult;
+}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/histogram/Makefile
index e629d6e..c73f8a9 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/histogram/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/histogram/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/histogram/NsightEclipse.xml
index bcb2152..72e7c05 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/histogram/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/histogram/NsightEclipse.xml
@@ -39,6 +39,8 @@
     <scope>2:Data Compression</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/README.md b/src/samples/Samples/2_Concepts_and_Techniques/histogram/README.md
index 5af85cb..8ddf8e5 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/histogram/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/histogram/README.md
@@ -10,7 +10,7 @@ Image Processing, Data Parallel Algorithms
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaFree, cudaDeviceSynchronize, cudaMalloc, cudaGetDeviceProperties
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram256.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram256.cu.hip
index e69de29..1649e73 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram256.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram256.cu.hip
@@ -0,0 +1,168 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+
+#include <hip/hip_runtime.h>
+#include <assert.h>
+#include <stdio.h>
+//#include "rocprofiler.h"
+#include "HIPCHECK.h"
+#include <stdlib.h>
+#include <string.h>
+#include <hip/hip_cooperative_groups.h>
+
+namespace cg = cooperative_groups;
+#include "helper_cuda_hipified.h"
+#include "helper_functions.h"
+#include "histogram_common.h"
+
+////////////////////////////////////////////////////////////////////////////////
+// Shortcut shared memory atomic addition functions
+////////////////////////////////////////////////////////////////////////////////
+
+#define TAG_MASK 0xFFFFFFFFU
+inline __device__ void addByte(uint *s_WarpHist, uint data, uint threadTag) {
+  atomicAdd(s_WarpHist + data, 1);
+}
+
+inline __device__ void addWord(uint *s_WarpHist, uint data, uint tag) {
+  addByte(s_WarpHist, (data >> 0) & 0xFFU, tag);
+  addByte(s_WarpHist, (data >> 8) & 0xFFU, tag);
+  addByte(s_WarpHist, (data >> 16) & 0xFFU, tag);
+  addByte(s_WarpHist, (data >> 24) & 0xFFU, tag);
+}
+
+__global__ void histogram256Kernel(uint *d_PartialHistograms, uint *d_Data,
+                                   uint dataCount) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  // Per-warp subhistogram storage
+  __shared__ uint s_Hist[HISTOGRAM256_THREADBLOCK_MEMORY];
+  uint *s_WarpHist =
+      s_Hist + (threadIdx.x >> LOG2_WARP_SIZE) * HISTOGRAM256_BIN_COUNT;
+
+// Clear shared memory storage for current threadblock before processing
+#pragma unroll
+
+  for (uint i = 0;
+       i < (HISTOGRAM256_THREADBLOCK_MEMORY / HISTOGRAM256_THREADBLOCK_SIZE);
+       i++) {
+    s_Hist[threadIdx.x + i * HISTOGRAM256_THREADBLOCK_SIZE] = 0;
+  }
+
+  // Cycle through the entire data set, update subhistograms for each warp
+  const uint tag = threadIdx.x << (UINT_BITS - LOG2_WARP_SIZE);
+
+  cg::sync(cta);
+
+  for (uint pos = UMAD(blockIdx.x, blockDim.x, threadIdx.x); pos < dataCount;
+       pos += UMUL(blockDim.x, gridDim.x)) {
+    uint data = d_Data[pos];
+    addWord(s_WarpHist, data, tag);
+  }
+
+  // Merge per-warp histograms into per-block and write to global memory
+  cg::sync(cta);
+
+  for (uint bin = threadIdx.x; bin < HISTOGRAM256_BIN_COUNT;
+       bin += HISTOGRAM256_THREADBLOCK_SIZE) {
+    uint sum = 0;
+
+    for (uint i = 0; i < WARP_COUNT; i++) {
+      sum += s_Hist[bin + i * HISTOGRAM256_BIN_COUNT] & TAG_MASK;
+    }
+
+    d_PartialHistograms[blockIdx.x * HISTOGRAM256_BIN_COUNT + bin] = sum;
+  }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Merge histogram256() output
+// Run one threadblock per bin; each threadblock adds up the same bin counter
+// from every partial histogram. Reads are uncoalesced, but mergeHistogram256
+// takes only a fraction of total processing time
+////////////////////////////////////////////////////////////////////////////////
+#define MERGE_THREADBLOCK_SIZE 256
+
+__global__ void mergeHistogram256Kernel(uint *d_Histogram,
+                                        uint *d_PartialHistograms,
+                                        uint histogramCount) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+
+  uint sum = 0;
+
+  for (uint i = threadIdx.x; i < histogramCount; i += MERGE_THREADBLOCK_SIZE) {
+    sum += d_PartialHistograms[blockIdx.x + i * HISTOGRAM256_BIN_COUNT];
+  }
+
+  __shared__ uint data[MERGE_THREADBLOCK_SIZE];
+  data[threadIdx.x] = sum;
+
+  for (uint stride = MERGE_THREADBLOCK_SIZE / 2; stride > 0; stride >>= 1) {
+    cg::sync(cta);
+
+    if (threadIdx.x < stride) {
+      data[threadIdx.x] += data[threadIdx.x + stride];
+    }
+  }
+
+  if (threadIdx.x == 0) {
+    d_Histogram[blockIdx.x] = data[0];
+  }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Host interface to GPU histogram
+////////////////////////////////////////////////////////////////////////////////
+// histogram256kernel() intermediate results buffer
+static const uint PARTIAL_HISTOGRAM256_COUNT = 240;
+static uint *d_PartialHistograms;
+
+// Internal memory allocation
+extern "C" void initHistogram256(void) {
+  HIPCHECK(hipMalloc(
+      (void **)&d_PartialHistograms,
+      PARTIAL_HISTOGRAM256_COUNT * HISTOGRAM256_BIN_COUNT * sizeof(uint)));
+}
+
+// Internal memory deallocation
+extern "C" void closeHistogram256(void) {
+  HIPCHECK(hipFree(d_PartialHistograms));
+}
+
+extern "C" void histogram256(uint *d_Histogram, void *d_Data, uint byteCount) {
+  assert(byteCount % sizeof(uint) == 0);
+  histogram256Kernel<<<PARTIAL_HISTOGRAM256_COUNT,
+                       HISTOGRAM256_THREADBLOCK_SIZE>>>(
+      d_PartialHistograms, (uint *)d_Data, byteCount / sizeof(uint));
+  getLastCudaError("histogram256Kernel() execution failed\n");
+
+  mergeHistogram256Kernel<<<HISTOGRAM256_BIN_COUNT, MERGE_THREADBLOCK_SIZE>>>(
+      d_Histogram, d_PartialHistograms, PARTIAL_HISTOGRAM256_COUNT);
+  getLastCudaError("mergeHistogram256Kernel() execution failed\n");
+}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram64.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram64.cu.hip
index e69de29..1e19257 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram64.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram64.cu.hip
@@ -0,0 +1,210 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+
+#include <hip/hip_runtime.h>
+#include <assert.h>
+#include <stdio.h>
+//#include "rocprofiler.h"
+#include "HIPCHECK.h"
+#include <stdlib.h>
+#include <string.h>
+#include <hip/hip_cooperative_groups.h>
+
+namespace cg = cooperative_groups;
+#include "helper_cuda_hipified.h"
+#include "helper_functions.h"
+#include "histogram_common.h"
+
+////////////////////////////////////////////////////////////////////////////////
+// GPU-specific common definitions
+////////////////////////////////////////////////////////////////////////////////
+// Data type used for input data fetches
+typedef uint4 data_t;
+
+// May change on future hardware, so better parametrize the code
+#define SHARED_MEMORY_BANKS 16
+
+////////////////////////////////////////////////////////////////////////////////
+// Main computation pass: compute gridDim.x partial histograms
+////////////////////////////////////////////////////////////////////////////////
+// Count a byte into shared-memory storage
+inline __device__ void addByte(uchar *s_ThreadBase, uint data) {
+  s_ThreadBase[UMUL(data, HISTOGRAM64_THREADBLOCK_SIZE)]++;
+}
+
+// Count four bytes of a word
+inline __device__ void addWord(uchar *s_ThreadBase, uint data) {
+  // Only higher 6 bits of each byte matter, as this is a 64-bin histogram
+  addByte(s_ThreadBase, (data >> 2) & 0x3FU);
+  addByte(s_ThreadBase, (data >> 10) & 0x3FU);
+  addByte(s_ThreadBase, (data >> 18) & 0x3FU);
+  addByte(s_ThreadBase, (data >> 26) & 0x3FU);
+}
+
+__global__ void histogram64Kernel(uint *d_PartialHistograms, data_t *d_Data,
+                                  uint dataCount) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  // Encode thread index in order to avoid bank conflicts in s_Hist[] access:
+  // each group of SHARED_MEMORY_BANKS threads accesses consecutive shared
+  // memory banks
+  // and the same bytes [0..3] within the banks
+  // Because of this permutation block size should be a multiple of 4 *
+  // SHARED_MEMORY_BANKS
+  const uint threadPos = ((threadIdx.x & ~(SHARED_MEMORY_BANKS * 4 - 1)) << 0) |
+                         ((threadIdx.x & (SHARED_MEMORY_BANKS - 1)) << 2) |
+                         ((threadIdx.x & (SHARED_MEMORY_BANKS * 3)) >> 4);
+
+  // Per-thread histogram storage
+  __shared__ uchar s_Hist[HISTOGRAM64_THREADBLOCK_SIZE * HISTOGRAM64_BIN_COUNT];
+  uchar *s_ThreadBase = s_Hist + threadPos;
+
+// Initialize shared memory (writing 32-bit words)
+#pragma unroll
+
+  for (uint i = 0; i < (HISTOGRAM64_BIN_COUNT / 4); i++) {
+    ((uint *)s_Hist)[threadIdx.x + i * HISTOGRAM64_THREADBLOCK_SIZE] = 0;
+  }
+
+  // Read data from global memory and submit to the shared-memory histogram
+  // Since histogram counters are byte-sized, every single thread can't do more
+  // than 255 submission
+  cg::sync(cta);
+
+  for (uint pos = UMAD(blockIdx.x, blockDim.x, threadIdx.x); pos < dataCount;
+       pos += UMUL(blockDim.x, gridDim.x)) {
+    data_t data = d_Data[pos];
+    addWord(s_ThreadBase, data.x);
+    addWord(s_ThreadBase, data.y);
+    addWord(s_ThreadBase, data.z);
+    addWord(s_ThreadBase, data.w);
+  }
+
+  // Accumulate per-thread histograms into per-block and write to global memory
+  cg::sync(cta);
+
+  if (threadIdx.x < HISTOGRAM64_BIN_COUNT) {
+    uchar *s_HistBase =
+        s_Hist + UMUL(threadIdx.x, HISTOGRAM64_THREADBLOCK_SIZE);
+
+    uint sum = 0;
+    uint pos = 4 * (threadIdx.x & (SHARED_MEMORY_BANKS - 1));
+
+#pragma unroll
+
+    for (uint i = 0; i < (HISTOGRAM64_THREADBLOCK_SIZE / 4); i++) {
+      sum += s_HistBase[pos + 0] + s_HistBase[pos + 1] + s_HistBase[pos + 2] +
+             s_HistBase[pos + 3];
+      pos = (pos + 4) & (HISTOGRAM64_THREADBLOCK_SIZE - 1);
+    }
+
+    d_PartialHistograms[blockIdx.x * HISTOGRAM64_BIN_COUNT + threadIdx.x] = sum;
+  }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Merge histogram64() output
+// Run one threadblock per bin; each threadbock adds up the same bin counter
+// from every partial histogram. Reads are uncoalesced, but mergeHistogram64
+// takes only a fraction of total processing time
+////////////////////////////////////////////////////////////////////////////////
+#define MERGE_THREADBLOCK_SIZE 256
+
+__global__ void mergeHistogram64Kernel(uint *d_Histogram,
+                                       uint *d_PartialHistograms,
+                                       uint histogramCount) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  __shared__ uint data[MERGE_THREADBLOCK_SIZE];
+
+  uint sum = 0;
+
+  for (uint i = threadIdx.x; i < histogramCount; i += MERGE_THREADBLOCK_SIZE) {
+    sum += d_PartialHistograms[blockIdx.x + i * HISTOGRAM64_BIN_COUNT];
+  }
+
+  data[threadIdx.x] = sum;
+
+  for (uint stride = MERGE_THREADBLOCK_SIZE / 2; stride > 0; stride >>= 1) {
+    cg::sync(cta);
+
+    if (threadIdx.x < stride) {
+      data[threadIdx.x] += data[threadIdx.x + stride];
+    }
+  }
+
+  if (threadIdx.x == 0) {
+    d_Histogram[blockIdx.x] = data[0];
+  }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// CPU interface to GPU histogram calculator
+////////////////////////////////////////////////////////////////////////////////
+// histogram64kernel() intermediate results buffer
+// MAX_PARTIAL_HISTOGRAM64_COUNT == 32768 and HISTOGRAM64_THREADBLOCK_SIZE == 64
+// amounts to max. 480MB of input data
+static const uint MAX_PARTIAL_HISTOGRAM64_COUNT = 32768;
+static uint *d_PartialHistograms;
+
+// Internal memory allocation
+extern "C" void initHistogram64(void) {
+  assert(HISTOGRAM64_THREADBLOCK_SIZE % (4 * SHARED_MEMORY_BANKS) == 0);
+  HIPCHECK(hipMalloc(
+      (void **)&d_PartialHistograms,
+      MAX_PARTIAL_HISTOGRAM64_COUNT * HISTOGRAM64_BIN_COUNT * sizeof(uint)));
+}
+
+// Internal memory deallocation
+extern "C" void closeHistogram64(void) {
+  HIPCHECK(hipFree(d_PartialHistograms));
+}
+
+// Round a / b to nearest higher integer value
+inline uint iDivUp(uint a, uint b) {
+  return (a % b != 0) ? (a / b + 1) : (a / b);
+}
+
+// Snap a to nearest lower multiple of b
+inline uint iSnapDown(uint a, uint b) { return a - a % b; }
+
+extern "C" void histogram64(uint *d_Histogram, void *d_Data, uint byteCount) {
+  const uint histogramCount = iDivUp(
+      byteCount, HISTOGRAM64_THREADBLOCK_SIZE * iSnapDown(255, sizeof(data_t)));
+
+  assert(byteCount % sizeof(data_t) == 0);
+  assert(histogramCount <= MAX_PARTIAL_HISTOGRAM64_COUNT);
+
+  histogram64Kernel<<<histogramCount, HISTOGRAM64_THREADBLOCK_SIZE>>>(
+      d_PartialHistograms, (data_t *)d_Data, byteCount / sizeof(data_t));
+  getLastCudaError("histogram64Kernel() execution failed\n");
+
+  mergeHistogram64Kernel<<<HISTOGRAM64_BIN_COUNT, MERGE_THREADBLOCK_SIZE>>>(
+      d_Histogram, d_PartialHistograms, histogramCount);
+  getLastCudaError("mergeHistogram64() execution failed\n");
+}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2017.vcxproj
index e4308b2..39dd837 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/histogram.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -110,6 +110,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2019.vcxproj
index b6db8eb..5bde10f 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/histogram.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -106,6 +106,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2022.vcxproj
index e2b3a65..a3e05c1 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/histogram.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -106,6 +106,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/Makefile
index 5b30bb7..3789508 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/NsightEclipse.xml
index 736c059..bef8876 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/NsightEclipse.xml
@@ -70,6 +70,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/README.md b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/README.md
index e452beb..d5741a7 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/README.md
@@ -10,7 +10,7 @@ Image Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaMallocArray, cudaFreeArray, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2017.vcxproj
index 6d5ec8e..bf03ff5 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/imageDenoising.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -123,6 +123,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2019.vcxproj
index 079b850..facb985 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/imageDenoising.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -119,6 +119,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2022.vcxproj
index 710fab1..ec0b7c6 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/imageDenoising.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -119,6 +119,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/Makefile
index 0861d28..6b06a65 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/NsightEclipse.xml
index 2ca5148..b329810 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/NsightEclipse.xml
@@ -38,6 +38,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/README.md b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/README.md
index d402a4a..60d100d 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/README.md
@@ -10,7 +10,7 @@ Performance Strategies, PTX Assembly, CUDA Driver API
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaFree, cudaMallocHost, cudaGetLastError, cudaGridSize, cudaBlockS
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2017.vcxproj
index f704776..b54f0ec 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/inlinePTX.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2019.vcxproj
index 36c9228..59b6d33 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/inlinePTX.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2022.vcxproj
index ff645ba..955dd6c 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/inlinePTX.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/README.md b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/README.md
index 4caabc1..3d99e87 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/README.md
@@ -10,7 +10,7 @@ Performance Strategies, PTX Assembly, CUDA Driver API, Runtime Compilation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaBlockSize, cudaGridSize
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_kernel.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_kernel.cu.hip
index e69de29..9c714f1 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_kernel.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_kernel.cu.hip
@@ -0,0 +1,40 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+extern "C" __global__ void sequence_gpu(int *d_ptr, int length) {
+  int elemID = blockIdx.x * blockDim.x + threadIdx.x;
+
+  if (elemID < length) {
+    unsigned int laneid;
+
+    // This command gets the lane ID within the current warp
+    asm("mov.u32 %0, %%laneid;" : "=r"(laneid));
+
+    d_ptr[elemID] = laneid;
+  }
+}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2017.vcxproj
index 6f78ad5..3d8dcc9 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2019.vcxproj
index 110fbc2..be53ad4 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2022.vcxproj
index f8bf654..87de14f 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/interval/Makefile
index 0cc67ef..69cf0f0 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/interval/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/interval/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/interval/NsightEclipse.xml
index 04f49ea..33d957a 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/interval/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/interval/NsightEclipse.xml
@@ -42,6 +42,8 @@
   <scopes>
     <scope>1:CUDA Advanced Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/README.md b/src/samples/Samples/2_Concepts_and_Techniques/interval/README.md
index bd12329..d13b6e9 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/interval/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/interval/README.md
@@ -10,7 +10,7 @@ Recursion, Templates
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaFuncSetCacheConfig, cudaMalloc, cudaFree, cudaGetLastError, cuda
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval_rounded_arith_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval_rounded_arith_hipified.h
index c6e0b1f..386f051 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval_rounded_arith_hipified.h
+++ b/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval_rounded_arith_hipified.h
@@ -59,44 +59,44 @@ struct rounded_arith {
 template <>
 struct rounded_arith<float> {
   __device__ float add_down(const float &x, const float &y) {
-    return __fadd_rd(x, y);
+    return __fadd_rn(x, y);
   }
 
   __device__ float add_up(const float &x, const float &y) {
-    return __fadd_ru(x, y);
+    return __fadd_rn(x, y);
   }
 
   __device__ float sub_down(const float &x, const float &y) {
-    return __fadd_rd(x, -y);
+    return __fadd_rn(x, -y);
   }
 
   __device__ float sub_up(const float &x, const float &y) {
-    return __fadd_ru(x, -y);
+    return __fadd_rn(x, -y);
   }
 
   __device__ float mul_down(const float &x, const float &y) {
-    return __fmul_rd(x, y);
+    return __fmul_rn(x, y);
   }
 
   __device__ float mul_up(const float &x, const float &y) {
-    return __fmul_ru(x, y);
+    return __fmul_rn(x, y);
   }
 
   __device__ float div_down(const float &x, const float &y) {
-    return __fdiv_rd(x, y);
+    return __fdiv_rn(x, y);
   }
 
   __device__ float div_up(const float &x, const float &y) {
-    return __fdiv_ru(x, y);
+    return __fdiv_rn(x, y);
   }
 
   __device__ float median(const float &x, const float &y) {
     return (x + y) * .5f;
   }
 
-  __device__ float sqrt_down(const float &x) { return __fsqrt_rd(x); }
+  __device__ float sqrt_down(const float &x) { return __fsqrt_rn(x); }
 
-  __device__ float sqrt_up(const float &x) { return __fsqrt_ru(x); }
+  __device__ float sqrt_up(const float &x) { return __fsqrt_rn(x); }
 
   __device__ float int_down(const float &x) { return floorf(x); }
 
@@ -117,43 +117,43 @@ struct rounded_arith<float> {
 template <>
 struct rounded_arith<double> {
   __device__ double add_down(const double &x, const double &y) {
-    return __dadd_rd(x, y);
+    return __dadd_rn(x, y);
   }
 
   __device__ double add_up(const double &x, const double &y) {
-    return __dadd_ru(x, y);
+    return __dadd_rn(x, y);
   }
 
   __device__ double sub_down(const double &x, const double &y) {
-    return __dadd_rd(x, -y);
+    return __dadd_rn(x, -y);
   }
 
   __device__ double sub_up(const double &x, const double &y) {
-    return __dadd_ru(x, -y);
+    return __dadd_rn(x, -y);
   }
 
   __device__ double mul_down(const double &x, const double &y) {
-    return __dmul_rd(x, y);
+    return __dmul_rn(x, y);
   }
 
   __device__ double mul_up(const double &x, const double &y) {
-    return __dmul_ru(x, y);
+    return __dmul_rn(x, y);
   }
 
   __device__ double div_down(const double &x, const double &y) {
-    return __ddiv_rd(x, y);
+    return __ddiv_rn(x, y);
   }
 
   __device__ double div_up(const double &x, const double &y) {
-    return __ddiv_ru(x, y);
+    return __ddiv_rn(x, y);
   }
   __device__ double median(const double &x, const double &y) {
     return (x + y) * .5;
   }
 
-  __device__ double sqrt_down(const double &x) { return __dsqrt_rd(x); }
+  __device__ double sqrt_down(const double &x) { return __dsqrt_rn(x); }
 
-  __device__ double sqrt_up(const double &x) { return __dsqrt_ru(x); }
+  __device__ double sqrt_up(const double &x) { return __dsqrt_rn(x); }
 
   __device__ double int_down(const double &x) { return floor(x); }
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval.cu.hip
index e69de29..e2c7460 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval.cu.hip
@@ -0,0 +1,163 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/* Example of program using the interval_gpu<T> template class and operators:
+ * Search for roots of a function using an interval Newton method.
+  *
+ * Use the command-line argument "--n=<N>" to select which GPU implementation to
+ * use,
+ * otherwise the naive implementation will be used by default.
+ * 0: the naive implementation
+ * 1: the optimized implementation
+ * 2: the recursive implementation
+ *
+ */
+
+const static char *sSDKsample = "Interval Computing";
+#include "hip/hip_runtime.h"
+#include <iostream>
+#include <stdio.h>
+#include "helper_cuda_hipified.h"
+#include "interval_hipified.h"
+#include "cuda_interval_hipified.h"
+#include "cpu_interval_hipified.h"
+
+int main(int argc, char *argv[]) {
+  int implementation_choice = 0;
+
+  printf("[%s]  starting ...\n\n", sSDKsample);
+
+  if (checkCmdLineFlag(argc, (const char **)argv, "n")) {
+    implementation_choice =
+        getCmdLineArgumentInt(argc, (const char **)argv, "n");
+  }
+
+  // Pick the best GPU available, or if the developer selects one at the command
+  // line
+  int devID = findCudaDevice(argc, (const char **)argv);
+  hipDeviceProp_t deviceProp;
+  hipGetDeviceProperties(&deviceProp, devID);
+  printf("> GPU Device has Compute Capabilities SM %d.%d\n\n", deviceProp.major,
+         deviceProp.minor);
+
+  switch (implementation_choice) {
+    case 0:
+      printf("GPU naive implementation\n");
+      break;
+
+    case 1:
+      printf("GPU optimized implementation\n");
+      break;
+
+    case 2:
+      printf("GPU recursive implementation (requires Compute SM 2.0+)\n");
+      break;
+
+    default:
+      printf("GPU naive implementation\n");
+  }
+
+  interval_gpu<T> *d_result;
+  int *d_nresults;
+  int *h_nresults = new int[THREADS];
+  hipEvent_t start, stop;
+
+  CHECKED_CALL(hipSetDevice(devID));
+  CHECKED_CALL(hipMalloc((void **)&d_result,
+                          THREADS * DEPTH_RESULT * sizeof(*d_result)));
+  CHECKED_CALL(hipMalloc((void **)&d_nresults, THREADS * sizeof(*d_nresults)));
+  CHECKED_CALL(hipEventCreate(&start));
+  CHECKED_CALL(hipEventCreate(&stop));
+
+  // We need L1 cache to store the stack (only applicable to sm_20 and higher)
+  CHECKED_CALL(
+      hipFuncSetCacheConfig((const void*)test_interval_newton<T>, hipFuncCachePreferL1));
+
+  // Increase the stack size large enough for the non-inlined and recursive
+  // function calls (only applicable to sm_20 and higher)
+  CHECKED_CALL(hipDeviceSetLimit(hipLimitStackSize, 8192));
+
+  interval_gpu<T> i(0.01f, 4.0f);
+  std::cout << "Searching for roots in [" << i.lower() << ", " << i.upper()
+            << "]...\n";
+
+  CHECKED_CALL(hipEventRecord(start, 0));
+
+  for (int it = 0; it < NUM_RUNS; ++it) {
+    test_interval_newton<T><<<GRID_SIZE, BLOCK_SIZE>>>(d_result, d_nresults, i,
+                                                       implementation_choice);
+    CHECKED_CALL(hipGetLastError());
+  }
+
+  CHECKED_CALL(hipEventRecord(stop, 0));
+  CHECKED_CALL(hipDeviceSynchronize());
+
+  I_CPU *h_result = new I_CPU[THREADS * DEPTH_RESULT];
+  CHECKED_CALL(hipMemcpy(h_result, d_result,
+                          THREADS * DEPTH_RESULT * sizeof(*d_result),
+                          hipMemcpyDeviceToHost));
+  CHECKED_CALL(hipMemcpy(h_nresults, d_nresults, THREADS * sizeof(*d_nresults),
+                          hipMemcpyDeviceToHost));
+
+  std::cout << "Found " << h_nresults[0]
+            << " intervals that may contain the root(s)\n";
+  std::cout.precision(15);
+
+  for (int i = 0; i != h_nresults[0]; ++i) {
+    std::cout << " i[" << i << "] ="
+              << " [" << h_result[THREADS * i + 0].lower() << ", "
+              << h_result[THREADS * i + 0].upper() << "]\n";
+  }
+
+  float time;
+  CHECKED_CALL(hipEventElapsedTime(&time, start, stop));
+  std::cout << "Number of equations solved: " << THREADS << "\n";
+  std::cout << "Time per equation: "
+            << 1000000.0f * (time / (float)(THREADS)) / NUM_RUNS << " us\n";
+
+  CHECKED_CALL(hipEventDestroy(start));
+  CHECKED_CALL(hipEventDestroy(stop));
+  CHECKED_CALL(hipFree(d_result));
+  CHECKED_CALL(hipFree(d_nresults));
+
+  // Compute the results using a CPU implementation based on the Boost library
+  I_CPU i_cpu(0.01f, 4.0f);
+  I_CPU *h_result_cpu = new I_CPU[THREADS * DEPTH_RESULT];
+  int *h_nresults_cpu = new int[THREADS];
+  test_interval_newton_cpu<I_CPU>(h_result_cpu, h_nresults_cpu, i_cpu);
+
+  // Compare the CPU and GPU results
+  bool bTestResult =
+      checkAgainstHost(h_nresults, h_nresults_cpu, h_result, h_result_cpu);
+
+  delete[] h_result_cpu;
+  delete[] h_nresults_cpu;
+  delete[] h_result;
+  delete[] h_nresults;
+
+  exit(bTestResult ? EXIT_SUCCESS : EXIT_FAILURE);
+}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2017.vcxproj
index a5e9a68..2c71346 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/interval.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -213,6 +213,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2019.vcxproj
index 507674d..43bea23 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/interval.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -209,6 +209,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2022.vcxproj
index d5091bb..ff04d5b 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/interval.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -209,6 +209,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/particles/Makefile
index 42a9267..62b19bf 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/particles/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/particles/Makefile
@@ -326,7 +326,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/particles/NsightEclipse.xml
index bbda212..b3fcd5a 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/particles/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/particles/NsightEclipse.xml
@@ -70,6 +70,8 @@
     <scope>2:Graphics Interop</scope>
     <scope>3:Physically-Based Simulation</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/README.md b/src/samples/Samples/2_Concepts_and_Techniques/particles/README.md
index a7b5eaf..3b1a697 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/particles/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/particles/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Data Parallel Algorithms, Physically-Based Simulation, Perform
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaFree, cudaGraphicsResourceGetMappedP
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2017.vcxproj
index fbb9510..d2c2a6f 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/particles.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -129,6 +129,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2019.vcxproj
index 1ff5340..c739cc7 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/particles.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -125,6 +125,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2022.vcxproj
index d3c770d..77b78a2 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/particles.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -125,6 +125,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/Makefile
index a0cc572..459e9a2 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/Makefile
@@ -306,7 +306,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/NsightEclipse.xml
index 73daf5f..62fd4d5 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/NsightEclipse.xml
@@ -45,6 +45,8 @@
     <scope>1:Data-Parallel Algorithms</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/README.md b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/README.md
index b53fb45..4914b5d 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/README.md
@@ -10,7 +10,7 @@ Data-Parallel Algorithms, Performance Strategies
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaEventSynchronize, cudaEventRecord, cudaGetDevice, cudaEventDestroy, cudaEven
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust.cu.hip
index 42fc161..9da52d3 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust.cu.hip
@@ -24,7 +24,7 @@
  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
-#include "HIPCHECK.h"
+
 #include <thrust/host_vector.h>
 #include <thrust/device_vector.h>
 #include <thrust/sort.h>
@@ -34,7 +34,7 @@
 #include <thrust/generate.h>
 #include <thrust/detail/type_traits.h>
 
-#include <helper_cuda.h>
+#include "helper_cuda_hipified.h"
 
 #include <algorithm>
 #include <time.h>
@@ -142,8 +142,8 @@ bool testSort(int argc, char **argv) {
 
   // run multiple iterations to compute an average sort time
   hipEvent_t start_event, stop_event;
-  checkCudaErrors(hipEventCreate(&start_event));
-  checkCudaErrors(hipEventCreate(&stop_event));
+  HIPCHECK(hipEventCreate(&start_event));
+  HIPCHECK(hipEventCreate(&stop_event));
 
   float totalTime = 0;
 
@@ -153,18 +153,18 @@ bool testSort(int argc, char **argv) {
 
     if (!keysOnly) d_values = h_values;
 
-    checkCudaErrors(hipEventRecord(start_event, 0));
+    HIPCHECK(hipEventRecord(start_event, 0));
 
     if (keysOnly)
       thrust::sort(d_keys.begin(), d_keys.end());
     else
       thrust::sort_by_key(d_keys.begin(), d_keys.end(), d_values.begin());
 
-    checkCudaErrors(hipEventRecord(stop_event, 0));
-    checkCudaErrors(hipEventSynchronize(stop_event));
+    HIPCHECK(hipEventRecord(stop_event, 0));
+    HIPCHECK(hipEventSynchronize(stop_event));
 
     float time = 0;
-    checkCudaErrors(hipEventElapsedTime(&time, start_event, stop_event));
+    HIPCHECK(hipEventElapsedTime(&time, start_event, stop_event));
     totalTime += time;
   }
 
@@ -188,8 +188,8 @@ bool testSort(int argc, char **argv) {
   bool bTestResult =
       thrust::is_sorted(h_keysSorted.begin(), h_keysSorted.end());
 
-  checkCudaErrors(hipEventDestroy(start_event));
-  checkCudaErrors(hipEventDestroy(stop_event));
+  HIPCHECK(hipEventDestroy(start_event));
+  HIPCHECK(hipEventDestroy(stop_event));
 
   if (!bTestResult && !quiet) {
     return false;
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2017.vcxproj
index e31f41c..a9c39d2 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/radixSortThrust.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2019.vcxproj
index 9ab5880..9ac46af 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/radixSortThrust.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2022.vcxproj
index 44daadd..30b2d9b 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/radixSortThrust.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/reduction/Makefile
index b8f19f7..eed9f80 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/reduction/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/reduction/Makefile
@@ -312,7 +312,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/reduction/NsightEclipse.xml
index cab3999..629ec3f 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/reduction/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/reduction/NsightEclipse.xml
@@ -54,6 +54,8 @@
     <scope>1:Data-Parallel Algorithms</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/README.md b/src/samples/Samples/2_Concepts_and_Techniques/reduction/README.md
index 1814228..65024c6 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/reduction/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/reduction/README.md
@@ -10,7 +10,7 @@ Data-Parallel Algorithms, Performance Strategies
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMemcpy, cudaFree, cudaSetDevice, cudaDeviceSynchronize, cudaGetDevice, cudaM
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_kernel.cu b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_kernel.cu
index 5be1676..44d231d 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_kernel.cu
+++ b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_kernel.cu
@@ -32,6 +32,7 @@
 #ifndef _REDUCE_KERNEL_H_
 #define _REDUCE_KERNEL_H_
 
+#define _CG_ABI_EXPERIMENTAL
 #include <cooperative_groups.h>
 #include <cooperative_groups/reduce.h>
 #include <stdio.h>
@@ -554,12 +555,12 @@ template <class T, size_t BlockSize, size_t MultiWarpGroupSize>
 __global__ void multi_warp_cg_reduce(T *g_idata, T *g_odata, unsigned int n) {
   // Shared memory for intermediate steps
   T *sdata = SharedMemory<T>();
-  __shared__ cg::block_tile_memory<BlockSize> scratch;
+  __shared__ cg::experimental::block_tile_memory<sizeof(T), BlockSize> scratch;
 
   // Handle to thread block group
-  auto cta = cg::this_thread_block(scratch);
+  auto cta = cg::experimental::this_thread_block(scratch);
   // Handle to multiWarpTile in thread block
-  auto multiWarpTile = cg::tiled_partition<MultiWarpGroupSize>(cta);
+  auto multiWarpTile = cg::experimental::tiled_partition<MultiWarpGroupSize>(cta);
 
   unsigned int gridSize = BlockSize * gridDim.x;
   T threadVal = 0;
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_kernel.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_kernel.cu.hip
index e69de29..84cd0b2 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_kernel.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_kernel.cu.hip
@@ -0,0 +1,1039 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+    Parallel reduction kernels
+*/
+
+#ifndef _REDUCE_KERNEL_H_
+#define _REDUCE_KERNEL_H_
+
+#define _CG_ABI_EXPERIMENTAL
+#include <hip/hip_cooperative_groups.h>
+#include "cooperative_groups/reduce.h"
+#include <stdio.h>
+
+namespace cg = cooperative_groups;
+
+// Utility class used to avoid linker errors with extern
+// unsized shared memory arrays with templated type
+template <class T>
+struct SharedMemory {
+  __device__ inline operator T *() {
+    extern __shared__ int __smem[];
+    return (T *)__smem;
+  }
+
+  __device__ inline operator const T *() const {
+    extern __shared__ int __smem[];
+    return (T *)__smem;
+  }
+};
+
+// specialize for double to avoid unaligned memory
+// access compile errors
+template <>
+struct SharedMemory<double> {
+  __device__ inline operator double *() {
+    extern __shared__ double __smem_d[];
+    return (double *)__smem_d;
+  }
+
+  __device__ inline operator const double *() const {
+    extern __shared__ double __smem_d[];
+    return (double *)__smem_d;
+  }
+};
+
+template <class T>
+__device__ __forceinline__ T warpReduceSum(unsigned int mask, T mySum) {
+  for (int offset = warpSize / 2; offset > 0; offset /= 2) {
+    mySum += __shfl_down_sync(mask, mySum, offset);
+  }
+  return mySum;
+}
+
+#if __CUDA_ARCH__ >= 800
+// Specialize warpReduceFunc for int inputs to use __reduce_add_sync intrinsic
+// when on SM 8.0 or higher
+template <>
+__device__ __forceinline__ int warpReduceSum<int>(unsigned int mask,
+                                                  int mySum) {
+  mySum = __reduce_add_sync(mask, mySum);
+  return mySum;
+}
+#endif
+
+/*
+    Parallel sum reduction using shared memory
+    - takes log(n) steps for n input elements
+    - uses n threads
+    - only works for power-of-2 arrays
+*/
+
+/* This reduction interleaves which threads are active by using the modulo
+   operator.  This operator is very expensive on GPUs, and the interleaved
+   inactivity means that no whole warps are active, which is also very
+   inefficient */
+template <class T>
+__global__ void reduce0(T *g_idata, T *g_odata, unsigned int n) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  T *sdata = SharedMemory<T>();
+
+  // load shared mem
+  unsigned int tid = threadIdx.x;
+  unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
+
+  sdata[tid] = (i < n) ? g_idata[i] : 0;
+
+  cg::sync(cta);
+
+  // do reduction in shared mem
+  for (unsigned int s = 1; s < blockDim.x; s *= 2) {
+    // modulo arithmetic is slow!
+    if ((tid % (2 * s)) == 0) {
+      sdata[tid] += sdata[tid + s];
+    }
+
+    cg::sync(cta);
+  }
+
+  // write result for this block to global mem
+  if (tid == 0) g_odata[blockIdx.x] = sdata[0];
+}
+
+/* This version uses contiguous threads, but its interleaved
+   addressing results in many shared memory bank conflicts.
+*/
+template <class T>
+__global__ void reduce1(T *g_idata, T *g_odata, unsigned int n) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  T *sdata = SharedMemory<T>();
+
+  // load shared mem
+  unsigned int tid = threadIdx.x;
+  unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
+
+  sdata[tid] = (i < n) ? g_idata[i] : 0;
+
+  cg::sync(cta);
+
+  // do reduction in shared mem
+  for (unsigned int s = 1; s < blockDim.x; s *= 2) {
+    int index = 2 * s * tid;
+
+    if (index < blockDim.x) {
+      sdata[index] += sdata[index + s];
+    }
+
+    cg::sync(cta);
+  }
+
+  // write result for this block to global mem
+  if (tid == 0) g_odata[blockIdx.x] = sdata[0];
+}
+
+/*
+    This version uses sequential addressing -- no divergence or bank conflicts.
+*/
+template <class T>
+__global__ void reduce2(T *g_idata, T *g_odata, unsigned int n) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  T *sdata = SharedMemory<T>();
+
+  // load shared mem
+  unsigned int tid = threadIdx.x;
+  unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
+
+  sdata[tid] = (i < n) ? g_idata[i] : 0;
+
+  cg::sync(cta);
+
+  // do reduction in shared mem
+  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
+    if (tid < s) {
+      sdata[tid] += sdata[tid + s];
+    }
+
+    cg::sync(cta);
+  }
+
+  // write result for this block to global mem
+  if (tid == 0) g_odata[blockIdx.x] = sdata[0];
+}
+
+/*
+    This version uses n/2 threads --
+    it performs the first level of reduction when reading from global memory.
+*/
+template <class T>
+__global__ void reduce3(T *g_idata, T *g_odata, unsigned int n) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  T *sdata = SharedMemory<T>();
+
+  // perform first level of reduction,
+  // reading from global memory, writing to shared memory
+  unsigned int tid = threadIdx.x;
+  unsigned int i = blockIdx.x * (blockDim.x * 2) + threadIdx.x;
+
+  T mySum = (i < n) ? g_idata[i] : 0;
+
+  if (i + blockDim.x < n) mySum += g_idata[i + blockDim.x];
+
+  sdata[tid] = mySum;
+  cg::sync(cta);
+
+  // do reduction in shared mem
+  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
+    if (tid < s) {
+      sdata[tid] = mySum = mySum + sdata[tid + s];
+    }
+
+    cg::sync(cta);
+  }
+
+  // write result for this block to global mem
+  if (tid == 0) g_odata[blockIdx.x] = mySum;
+}
+
+/*
+    This version uses the warp shuffle operation if available to reduce
+    warp synchronization. When shuffle is not available the final warp's
+    worth of work is unrolled to reduce looping overhead.
+
+    See
+   http://devblogs.nvidia.com/parallelforall/faster-parallel-reductions-kepler/
+    for additional information about using shuffle to perform a reduction
+    within a warp.
+
+    Note, this kernel needs a minimum of 64*sizeof(T) bytes of shared memory.
+    In other words if blockSize <= 32, allocate 64*sizeof(T) bytes.
+    If blockSize > 32, allocate blockSize*sizeof(T) bytes.
+*/
+template <class T, unsigned int blockSize>
+__global__ void reduce4(T *g_idata, T *g_odata, unsigned int n) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  T *sdata = SharedMemory<T>();
+
+  // perform first level of reduction,
+  // reading from global memory, writing to shared memory
+  unsigned int tid = threadIdx.x;
+  unsigned int i = blockIdx.x * (blockDim.x * 2) + threadIdx.x;
+
+  T mySum = (i < n) ? g_idata[i] : 0;
+
+  if (i + blockSize < n) mySum += g_idata[i + blockSize];
+
+  sdata[tid] = mySum;
+  cg::sync(cta);
+
+  // do reduction in shared mem
+  for (unsigned int s = blockDim.x / 2; s > 32; s >>= 1) {
+    if (tid < s) {
+      sdata[tid] = mySum = mySum + sdata[tid + s];
+    }
+
+    cg::sync(cta);
+  }
+
+  cg::thread_block_tile<32> tile32 = cg::tiled_partition<32>(cta);
+
+  if (cta.thread_rank() < 32) {
+    // Fetch final intermediate sum from 2nd warp
+    if (blockSize >= 64) mySum += sdata[tid + 32];
+    // Reduce final warp using shuffle
+    for (int offset = tile32.size() / 2; offset > 0; offset /= 2) {
+      mySum += tile32.shfl_down(mySum, offset);
+    }
+  }
+
+  // write result for this block to global mem
+  if (cta.thread_rank() == 0) g_odata[blockIdx.x] = mySum;
+}
+
+/*
+    This version is completely unrolled, unless warp shuffle is available, then
+    shuffle is used within a loop.  It uses a template parameter to achieve
+    optimal code for any (power of 2) number of threads.  This requires a switch
+    statement in the host code to handle all the different thread block sizes at
+    compile time. When shuffle is available, it is used to reduce warp
+   synchronization.
+
+    Note, this kernel needs a minimum of 64*sizeof(T) bytes of shared memory.
+    In other words if blockSize <= 32, allocate 64*sizeof(T) bytes.
+    If blockSize > 32, allocate blockSize*sizeof(T) bytes.
+*/
+template <class T, unsigned int blockSize>
+__global__ void reduce5(T *g_idata, T *g_odata, unsigned int n) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  T *sdata = SharedMemory<T>();
+
+  // perform first level of reduction,
+  // reading from global memory, writing to shared memory
+  unsigned int tid = threadIdx.x;
+  unsigned int i = blockIdx.x * (blockSize * 2) + threadIdx.x;
+
+  T mySum = (i < n) ? g_idata[i] : 0;
+
+  if (i + blockSize < n) mySum += g_idata[i + blockSize];
+
+  sdata[tid] = mySum;
+  cg::sync(cta);
+
+  // do reduction in shared mem
+  if ((blockSize >= 512) && (tid < 256)) {
+    sdata[tid] = mySum = mySum + sdata[tid + 256];
+  }
+
+  cg::sync(cta);
+
+  if ((blockSize >= 256) && (tid < 128)) {
+    sdata[tid] = mySum = mySum + sdata[tid + 128];
+  }
+
+  cg::sync(cta);
+
+  if ((blockSize >= 128) && (tid < 64)) {
+    sdata[tid] = mySum = mySum + sdata[tid + 64];
+  }
+
+  cg::sync(cta);
+
+  cg::thread_block_tile<32> tile32 = cg::tiled_partition<32>(cta);
+
+  if (cta.thread_rank() < 32) {
+    // Fetch final intermediate sum from 2nd warp
+    if (blockSize >= 64) mySum += sdata[tid + 32];
+    // Reduce final warp using shuffle
+    for (int offset = tile32.size() / 2; offset > 0; offset /= 2) {
+      mySum += tile32.shfl_down(mySum, offset);
+    }
+  }
+
+  // write result for this block to global mem
+  if (cta.thread_rank() == 0) g_odata[blockIdx.x] = mySum;
+}
+
+/*
+    This version adds multiple elements per thread sequentially.  This reduces
+   the overall cost of the algorithm while keeping the work complexity O(n) and
+   the step complexity O(log n). (Brent's Theorem optimization)
+
+    Note, this kernel needs a minimum of 64*sizeof(T) bytes of shared memory.
+    In other words if blockSize <= 32, allocate 64*sizeof(T) bytes.
+    If blockSize > 32, allocate blockSize*sizeof(T) bytes.
+*/
+template <class T, unsigned int blockSize, bool nIsPow2>
+__global__ void reduce6(T *g_idata, T *g_odata, unsigned int n) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  T *sdata = SharedMemory<T>();
+
+  // perform first level of reduction,
+  // reading from global memory, writing to shared memory
+  unsigned int tid = threadIdx.x;
+  unsigned int gridSize = blockSize * gridDim.x;
+
+  T mySum = 0;
+
+  // we reduce multiple elements per thread.  The number is determined by the
+  // number of active thread blocks (via gridDim).  More blocks will result
+  // in a larger gridSize and therefore fewer elements per thread
+  if (nIsPow2) {
+    unsigned int i = blockIdx.x * blockSize * 2 + threadIdx.x;
+    gridSize = gridSize << 1;
+
+    while (i < n) {
+      mySum += g_idata[i];
+      // ensure we don't read out of bounds -- this is optimized away for
+      // powerOf2 sized arrays
+      if ((i + blockSize) < n) {
+        mySum += g_idata[i + blockSize];
+      }
+      i += gridSize;
+    }
+  } else {
+    unsigned int i = blockIdx.x * blockSize + threadIdx.x;
+    while (i < n) {
+      mySum += g_idata[i];
+      i += gridSize;
+    }
+  }
+
+  // each thread puts its local sum into shared memory
+  sdata[tid] = mySum;
+  cg::sync(cta);
+
+  // do reduction in shared mem
+  if ((blockSize >= 512) && (tid < 256)) {
+    sdata[tid] = mySum = mySum + sdata[tid + 256];
+  }
+
+  cg::sync(cta);
+
+  if ((blockSize >= 256) && (tid < 128)) {
+    sdata[tid] = mySum = mySum + sdata[tid + 128];
+  }
+
+  cg::sync(cta);
+
+  if ((blockSize >= 128) && (tid < 64)) {
+    sdata[tid] = mySum = mySum + sdata[tid + 64];
+  }
+
+  cg::sync(cta);
+
+  cg::thread_block_tile<32> tile32 = cg::tiled_partition<32>(cta);
+
+  if (cta.thread_rank() < 32) {
+    // Fetch final intermediate sum from 2nd warp
+    if (blockSize >= 64) mySum += sdata[tid + 32];
+    // Reduce final warp using shuffle
+    for (int offset = tile32.size() / 2; offset > 0; offset /= 2) {
+      mySum += tile32.shfl_down(mySum, offset);
+    }
+  }
+
+  // write result for this block to global mem
+  if (cta.thread_rank() == 0) g_odata[blockIdx.x] = mySum;
+}
+
+template <typename T, unsigned int blockSize, bool nIsPow2>
+__global__ void reduce7(const T *__restrict__ g_idata, T *__restrict__ g_odata,
+                        unsigned int n) {
+  T *sdata = SharedMemory<T>();
+
+  // perform first level of reduction,
+  // reading from global memory, writing to shared memory
+  unsigned int tid = threadIdx.x;
+  unsigned int gridSize = blockSize * gridDim.x;
+  unsigned int maskLength = (blockSize & 31);  // 31 = warpSize-1
+  maskLength = (maskLength > 0) ? (32 - maskLength) : maskLength;
+  const unsigned int mask = (0xffffffff) >> maskLength;
+
+  T mySum = 0;
+
+  // we reduce multiple elements per thread.  The number is determined by the
+  // number of active thread blocks (via gridDim).  More blocks will result
+  // in a larger gridSize and therefore fewer elements per thread
+  if (nIsPow2) {
+    unsigned int i = blockIdx.x * blockSize * 2 + threadIdx.x;
+    gridSize = gridSize << 1;
+
+    while (i < n) {
+      mySum += g_idata[i];
+      // ensure we don't read out of bounds -- this is optimized away for
+      // powerOf2 sized arrays
+      if ((i + blockSize) < n) {
+        mySum += g_idata[i + blockSize];
+      }
+      i += gridSize;
+    }
+  } else {
+    unsigned int i = blockIdx.x * blockSize + threadIdx.x;
+    while (i < n) {
+      mySum += g_idata[i];
+      i += gridSize;
+    }
+  }
+
+  // Reduce within warp using shuffle or reduce_add if T==int & CUDA_ARCH ==
+  // SM 8.0
+  mySum = warpReduceSum<T>(mask, mySum);
+
+  // each thread puts its local sum into shared memory
+  if ((tid % warpSize) == 0) {
+    sdata[tid / warpSize] = mySum;
+  }
+
+  __syncthreads();
+
+  const unsigned int shmem_extent =
+      (blockSize / warpSize) > 0 ? (blockSize / warpSize) : 1;
+  const unsigned int ballot_result = __ballot_sync(mask, tid < shmem_extent);
+  if (tid < shmem_extent) {
+    mySum = sdata[tid];
+    // Reduce final warp using shuffle or reduce_add if T==int & CUDA_ARCH ==
+    // SM 8.0
+    mySum = warpReduceSum<T>(ballot_result, mySum);
+  }
+
+  // write result for this block to global mem
+  if (tid == 0) {
+    g_odata[blockIdx.x] = mySum;
+  }
+}
+
+// Performs a reduction step and updates numTotal with how many are remaining
+template <typename T, typename Group>
+__device__ T cg_reduce_n(T in, Group &threads) {
+  return cg::reduce(threads, in, cg::plus<T>());
+}
+
+template <class T>
+__global__ void cg_reduce(T *g_idata, T *g_odata, unsigned int n) {
+  // Shared memory for intermediate steps
+  T *sdata = SharedMemory<T>();
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  // Handle to tile in thread block
+  cg::thread_block_tile<32> tile = cg::tiled_partition<32>(cta);
+
+  unsigned int ctaSize = cta.size();
+  unsigned int numCtas = gridDim.x;
+  unsigned int threadRank = cta.thread_rank();
+  unsigned int threadIndex = (blockIdx.x * ctaSize) + threadRank;
+
+  T threadVal = 0;
+  {
+    unsigned int i = threadIndex;
+    unsigned int indexStride = (numCtas * ctaSize);
+    while (i < n) {
+      threadVal += g_idata[i];
+      i += indexStride;
+    }
+    sdata[threadRank] = threadVal;
+  }
+
+  // Wait for all tiles to finish and reduce within CTA
+  {
+    unsigned int ctaSteps = tile.meta_group_size();
+    unsigned int ctaIndex = ctaSize >> 1;
+    while (ctaIndex >= 32) {
+      cta.sync();
+      if (threadRank < ctaIndex) {
+        threadVal += sdata[threadRank + ctaIndex];
+        sdata[threadRank] = threadVal;
+      }
+      ctaSteps >>= 1;
+      ctaIndex >>= 1;
+    }
+  }
+
+  // Shuffle redux instead of smem redux
+  {
+    cta.sync();
+    if (tile.meta_group_rank() == 0) {
+      threadVal = cg_reduce_n(threadVal, tile);
+    }
+  }
+
+  if (threadRank == 0) g_odata[blockIdx.x] = threadVal;
+}
+
+template <class T, size_t BlockSize, size_t MultiWarpGroupSize>
+__global__ void multi_warp_cg_reduce(T *g_idata, T *g_odata, unsigned int n) {
+  // Shared memory for intermediate steps
+  T *sdata = SharedMemory<T>();
+  __shared__ cg::experimental::block_tile_memory<sizeof(T), BlockSize> scratch;
+
+  // Handle to thread block group
+  auto cta = cg::experimental::this_thread_block(scratch);
+  // Handle to multiWarpTile in thread block
+  auto multiWarpTile = cg::experimental::tiled_partition<MultiWarpGroupSize>(cta);
+
+  unsigned int gridSize = BlockSize * gridDim.x;
+  T threadVal = 0;
+
+  // we reduce multiple elements per thread.  The number is determined by the
+  // number of active thread blocks (via gridDim).  More blocks will result
+  // in a larger gridSize and therefore fewer elements per thread
+  int nIsPow2 = !(n & n-1);
+  if (nIsPow2) {
+    unsigned int i = blockIdx.x * BlockSize * 2 + threadIdx.x;
+    gridSize = gridSize << 1;
+
+    while (i < n) {
+      threadVal += g_idata[i];
+      // ensure we don't read out of bounds -- this is optimized away for
+      // powerOf2 sized arrays
+      if ((i + BlockSize) < n) {
+        threadVal += g_idata[i + blockDim.x];
+      }
+      i += gridSize;
+    }
+  } else {
+    unsigned int i = blockIdx.x * BlockSize + threadIdx.x;
+    while (i < n) {
+      threadVal += g_idata[i];
+      i += gridSize;
+    }
+  }
+
+  threadVal = cg_reduce_n(threadVal, multiWarpTile);
+
+  if (multiWarpTile.thread_rank() == 0) {
+    sdata[multiWarpTile.meta_group_rank()] = threadVal;
+  }
+  cg::sync(cta);
+
+  if (threadIdx.x == 0) {
+    threadVal = 0;
+    for (int i=0; i < multiWarpTile.meta_group_size(); i++) {
+      threadVal += sdata[i];
+    }
+    g_odata[blockIdx.x] = threadVal;
+  }
+}
+
+extern "C" bool isPow2(unsigned int x);
+
+////////////////////////////////////////////////////////////////////////////////
+// Wrapper function for kernel launch
+////////////////////////////////////////////////////////////////////////////////
+template <class T>
+void reduce(int size, int threads, int blocks, int whichKernel, T *d_idata,
+            T *d_odata) {
+  dim3 dimBlock(threads, 1, 1);
+  dim3 dimGrid(blocks, 1, 1);
+
+  // when there is only one warp per block, we need to allocate two warps
+  // worth of shared memory so that we don't index shared memory out of bounds
+  int smemSize =
+      (threads <= 32) ? 2 * threads * sizeof(T) : threads * sizeof(T);
+
+  // as kernel 9 - multi_warp_cg_reduce cannot work for more than 64 threads
+  // we choose to set kernel 7 for this purpose.
+  if (threads < 64 && whichKernel == 9)
+  {
+    whichKernel = 7;
+  }
+
+  // choose which of the optimized versions of reduction to launch
+  switch (whichKernel) {
+    case 0:
+      reduce0<T><<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+      break;
+
+    case 1:
+      reduce1<T><<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+      break;
+
+    case 2:
+      reduce2<T><<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+      break;
+
+    case 3:
+      reduce3<T><<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+      break;
+
+    case 4:
+      switch (threads) {
+        case 512:
+          reduce4<T, 512>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 256:
+          reduce4<T, 256>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 128:
+          reduce4<T, 128>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 64:
+          reduce4<T, 64>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 32:
+          reduce4<T, 32>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 16:
+          reduce4<T, 16>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 8:
+          reduce4<T, 8>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 4:
+          reduce4<T, 4>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 2:
+          reduce4<T, 2>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 1:
+          reduce4<T, 1>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+      }
+
+      break;
+
+    case 5:
+      switch (threads) {
+        case 512:
+          reduce5<T, 512>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 256:
+          reduce5<T, 256>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 128:
+          reduce5<T, 128>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 64:
+          reduce5<T, 64>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 32:
+          reduce5<T, 32>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 16:
+          reduce5<T, 16>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 8:
+          reduce5<T, 8>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 4:
+          reduce5<T, 4>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 2:
+          reduce5<T, 2>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 1:
+          reduce5<T, 1>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+      }
+
+      break;
+
+    case 6:
+      if (isPow2(size)) {
+        switch (threads) {
+          case 512:
+            reduce6<T, 512, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 256:
+            reduce6<T, 256, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 128:
+            reduce6<T, 128, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 64:
+            reduce6<T, 64, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 32:
+            reduce6<T, 32, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 16:
+            reduce6<T, 16, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 8:
+            reduce6<T, 8, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 4:
+            reduce6<T, 4, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 2:
+            reduce6<T, 2, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 1:
+            reduce6<T, 1, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+        }
+      } else {
+        switch (threads) {
+          case 512:
+            reduce6<T, 512, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 256:
+            reduce6<T, 256, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 128:
+            reduce6<T, 128, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 64:
+            reduce6<T, 64, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 32:
+            reduce6<T, 32, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 16:
+            reduce6<T, 16, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 8:
+            reduce6<T, 8, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 4:
+            reduce6<T, 4, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 2:
+            reduce6<T, 2, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 1:
+            reduce6<T, 1, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+        }
+      }
+
+      break;
+
+    case 7:
+      // For reduce7 kernel we require only blockSize/warpSize
+      // number of elements in shared memory
+      smemSize = ((threads / 32) + 1) * sizeof(T);
+      if (isPow2(size)) {
+        switch (threads) {
+          case 1024:
+            reduce7<T, 1024, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+          case 512:
+            reduce7<T, 512, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 256:
+            reduce7<T, 256, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 128:
+            reduce7<T, 128, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 64:
+            reduce7<T, 64, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 32:
+            reduce7<T, 32, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 16:
+            reduce7<T, 16, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 8:
+            reduce7<T, 8, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 4:
+            reduce7<T, 4, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 2:
+            reduce7<T, 2, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 1:
+            reduce7<T, 1, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+        }
+      } else {
+        switch (threads) {
+          case 1024:
+            reduce7<T, 1024, true>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+          case 512:
+            reduce7<T, 512, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 256:
+            reduce7<T, 256, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 128:
+            reduce7<T, 128, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 64:
+            reduce7<T, 64, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 32:
+            reduce7<T, 32, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 16:
+            reduce7<T, 16, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 8:
+            reduce7<T, 8, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 4:
+            reduce7<T, 4, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 2:
+            reduce7<T, 2, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+
+          case 1:
+            reduce7<T, 1, false>
+                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+            break;
+        }
+      }
+
+      break;
+    case 8:
+      cg_reduce<T><<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+      break;
+    case 9:
+      constexpr int numOfMultiWarpGroups = 2;
+      smemSize = numOfMultiWarpGroups * sizeof(T);
+      switch (threads) {
+        case 1024:
+          multi_warp_cg_reduce<T, 1024, 1024/numOfMultiWarpGroups>
+            <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 512:
+          multi_warp_cg_reduce<T, 512, 512/numOfMultiWarpGroups>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 256:
+          multi_warp_cg_reduce<T, 256, 256/numOfMultiWarpGroups>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 128:
+          multi_warp_cg_reduce<T, 128, 128/numOfMultiWarpGroups>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        case 64:
+          multi_warp_cg_reduce<T, 64, 64/numOfMultiWarpGroups>
+              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
+          break;
+
+        default:
+          printf("thread block size of < 64 is not supported for this kernel\n");
+          break;
+      }
+      break;
+  }
+}
+
+// Instantiate the reduction function for 3 types
+template void reduce<int>(int size, int threads, int blocks, int whichKernel,
+                          int *d_idata, int *d_odata);
+
+template void reduce<float>(int size, int threads, int blocks, int whichKernel,
+                            float *d_idata, float *d_odata);
+
+template void reduce<double>(int size, int threads, int blocks, int whichKernel,
+                             double *d_idata, double *d_odata);
+
+#endif  // #ifndef _REDUCE_KERNEL_H_
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2017.vcxproj
index d486bc9..f80b176 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/reduction.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2019.vcxproj
index 7da9b36..dea43ea 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/reduction.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2022.vcxproj
index 0f15232..bbc6826 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/reduction.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/README.md b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/README.md
index 9b1ecc0..7473bae 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/README.md
@@ -30,7 +30,7 @@ cudaMemcpy, cudaFree, cudaSetDevice, cudaDeviceSynchronize, cudaLaunchCooperativ
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG.cu.hip
index 82853ad..75ad1e8 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG.cu.hip
@@ -61,8 +61,8 @@
 #include <math.h>
 
 // includes, project
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
+#include <helper_functions.h>
+#include <helper_cuda.h>
 
 #include <hip/hip_runtime.h>
 
@@ -385,21 +385,3 @@ bool runTest(int argc, char **argv, int device) {
 
   return bTestPassed;
 }
-ta);
-  hipFree(d_idata);
-  hipFree(d_odata);
-
-  return bTestPassed;
-}
-ta);
-  hipFree(d_idata);
-  hipFree(d_odata);
-
-  return bTestPassed;
-}
-ta);
-  hipFree(d_idata);
-  hipFree(d_odata);
-
-  return bTestPassed;
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2017.vcxproj
index 9b5d1fb..c467625 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2019.vcxproj
index b1fbf9c..306b8c6 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2022.vcxproj
index 057f252..a7261ba 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/Makefile
index 0979306..9cacc53 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/NsightEclipse.xml
index fb34c8e..79a458f 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/NsightEclipse.xml
@@ -33,6 +33,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/README.md b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/README.md
index ce9a91c..47ff8e5 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/README.md
@@ -10,7 +10,7 @@ Linear Algebra
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMalloc, cudaDeviceSynchronize, cudaMemcpy, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd.cu.hip
index e69de29..7318b87 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd.cu.hip
@@ -0,0 +1,172 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * This sample calculates scalar products of a
+ * given set of input vector pairs
+ */
+
+
+#include <hip/hip_runtime.h>
+#include <stdio.h>
+#include "rocprofiler.h"
+#include "HIPCHECK.h"
+#include <stdlib.h>
+#include <time.h>
+#include <string.h>
+
+#include "helper_functions.h"
+#include "helper_cuda_hipified.h"
+
+///////////////////////////////////////////////////////////////////////////////
+// Calculate scalar products of VectorN vectors of ElementN elements on CPU
+///////////////////////////////////////////////////////////////////////////////
+extern "C" void scalarProdCPU(float *h_C, float *h_A, float *h_B, int vectorN,
+                              int elementN);
+
+///////////////////////////////////////////////////////////////////////////////
+// Calculate scalar products of VectorN vectors of ElementN elements on GPU
+///////////////////////////////////////////////////////////////////////////////
+#include "scalarProd_kernel.cuh"
+
+////////////////////////////////////////////////////////////////////////////////
+// Helper function, returning uniformly distributed
+// random float in [low, high] range
+////////////////////////////////////////////////////////////////////////////////
+float RandFloat(float low, float high) {
+  float t = (float)rand() / (float)RAND_MAX;
+  return (1.0f - t) * low + t * high;
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// Data configuration
+///////////////////////////////////////////////////////////////////////////////
+
+// Total number of input vector pairs; arbitrary
+const int VECTOR_N = 256;
+// Number of elements per vector; arbitrary,
+// but strongly preferred to be a multiple of warp size
+// to meet memory coalescing constraints
+const int ELEMENT_N = 4096;
+// Total number of data elements
+const int DATA_N = VECTOR_N * ELEMENT_N;
+
+const int DATA_SZ = DATA_N * sizeof(float);
+const int RESULT_SZ = VECTOR_N * sizeof(float);
+
+///////////////////////////////////////////////////////////////////////////////
+// Main program
+///////////////////////////////////////////////////////////////////////////////
+int main(int argc, char **argv) {
+  float *h_A, *h_B, *h_C_CPU, *h_C_GPU;
+  float *d_A, *d_B, *d_C;
+  double delta, ref, sum_delta, sum_ref, L1norm;
+  StopWatchInterface *hTimer = NULL;
+  int i;
+
+  printf("%s Starting...\n\n", argv[0]);
+
+  // use command-line specified CUDA device, otherwise use device with highest
+  // Gflops/s
+  findCudaDevice(argc, (const char **)argv);
+
+  sdkCreateTimer(&hTimer);
+
+  printf("Initializing data...\n");
+  printf("...allocating CPU memory.\n");
+  h_A = (float *)malloc(DATA_SZ);
+  h_B = (float *)malloc(DATA_SZ);
+  h_C_CPU = (float *)malloc(RESULT_SZ);
+  h_C_GPU = (float *)malloc(RESULT_SZ);
+
+  printf("...allocating GPU memory.\n");
+  HIPCHECK(hipMalloc((void **)&d_A, DATA_SZ));
+  HIPCHECK(hipMalloc((void **)&d_B, DATA_SZ));
+  HIPCHECK(hipMalloc((void **)&d_C, RESULT_SZ));
+
+  printf("...generating input data in CPU mem.\n");
+  srand(123);
+
+  // Generating input data on CPU
+  for (i = 0; i < DATA_N; i++) {
+    h_A[i] = RandFloat(0.0f, 1.0f);
+    h_B[i] = RandFloat(0.0f, 1.0f);
+  }
+
+  printf("...copying input data to GPU mem.\n");
+  // Copy options data to GPU memory for further processing
+  HIPCHECK(hipMemcpy(d_A, h_A, DATA_SZ, hipMemcpyHostToDevice));
+  HIPCHECK(hipMemcpy(d_B, h_B, DATA_SZ, hipMemcpyHostToDevice));
+  printf("Data init done.\n");
+
+  printf("Executing GPU kernel...\n");
+  HIPCHECK(hipDeviceSynchronize());
+  sdkResetTimer(&hTimer);
+  sdkStartTimer(&hTimer);
+  scalarProdGPU<<<128, 256>>>(d_C, d_A, d_B, VECTOR_N, ELEMENT_N);
+  getLastCudaError("scalarProdGPU() execution failed\n");
+  HIPCHECK(hipDeviceSynchronize());
+  sdkStopTimer(&hTimer);
+  printf("GPU time: %f msecs.\n", sdkGetTimerValue(&hTimer));
+
+  printf("Reading back GPU result...\n");
+  // Read back GPU results to compare them to CPU results
+  HIPCHECK(hipMemcpy(h_C_GPU, d_C, RESULT_SZ, hipMemcpyDeviceToHost));
+
+  printf("Checking GPU results...\n");
+  printf("..running CPU scalar product calculation\n");
+  scalarProdCPU(h_C_CPU, h_A, h_B, VECTOR_N, ELEMENT_N);
+
+  printf("...comparing the results\n");
+  // Calculate max absolute difference and L1 distance
+  // between CPU and GPU results
+  sum_delta = 0;
+  sum_ref = 0;
+
+  for (i = 0; i < VECTOR_N; i++) {
+    delta = fabs(h_C_GPU[i] - h_C_CPU[i]);
+    ref = h_C_CPU[i];
+    sum_delta += delta;
+    sum_ref += ref;
+  }
+
+  L1norm = sum_delta / sum_ref;
+
+  printf("Shutting down...\n");
+  HIPCHECK(hipFree(d_C));
+  HIPCHECK(hipFree(d_B));
+  HIPCHECK(hipFree(d_A));
+  free(h_C_GPU);
+  free(h_C_CPU);
+  free(h_B);
+  free(h_A);
+  sdkDeleteTimer(&hTimer);
+
+  printf("L1 error: %E\n", L1norm);
+  printf((L1norm < 1e-6) ? "Test passed\n" : "Test failed!\n");
+  exit(L1norm < 1e-6 ? EXIT_SUCCESS : EXIT_FAILURE);
+}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2017.vcxproj
index 9dfca3b..d404cd6 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/scalarProd.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2019.vcxproj
index 9509637..72e9579 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/scalarProd.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2022.vcxproj
index 531700a..cb130ea 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/scalarProd.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/scan/Makefile
index 79cf29f..8ce4ab7 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scan/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scan/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/scan/NsightEclipse.xml
index 3862941..11e6c2f 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scan/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scan/NsightEclipse.xml
@@ -37,6 +37,8 @@
     <scope>1:Data-Parallel Algorithms</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/README.md b/src/samples/Samples/2_Concepts_and_Techniques/scan/README.md
index 2697dbc..e10d0a3 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scan/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scan/README.md
@@ -10,7 +10,7 @@ Data-Parallel Algorithms, Performance Strategies
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMalloc, cudaDeviceSynchronize, cudaMemcpy, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.cu.hip
index 2dbdf6a..07204ea 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -26,6 +25,8 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
+
+#include <hip/hip_runtime.h>
 #include <assert.h>
 #include <hip/hip_cooperative_groups.h>
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.out b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.out
index 25fe114..d29fd14 100755
Binary files a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.out and b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.out differ
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_gold.cpp b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_gold.cpp
index 4d07998..8ebca66 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_gold.cpp
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_gold.cpp
@@ -35,3 +35,4 @@ extern "C" void scanExclusiveHost(uint *dst, uint *src, uint batchSize,
     for (uint j = 1; j < arrayLength; j++) dst[j] = src[j - 1] + dst[j - 1];
   }
 }
+
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_gold_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_gold_hipified.cpp
index 4d07998..8ebca66 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_gold_hipified.cpp
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_gold_hipified.cpp
@@ -35,3 +35,4 @@ extern "C" void scanExclusiveHost(uint *dst, uint *src, uint batchSize,
     for (uint j = 1; j < arrayLength; j++) dst[j] = src[j - 1] + dst[j - 1];
   }
 }
+
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2017.vcxproj
index bcbe701..ac2bd4b 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/scan.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2019.vcxproj
index 5b29c2e..fddb849 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/scan.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2022.vcxproj
index f8b686c..4f23893 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/scan.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/Makefile
index e25a33c..fe1a04e 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/Makefile
@@ -306,7 +306,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/NsightEclipse.xml
index bdac6af..bfabb71 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/NsightEclipse.xml
@@ -47,6 +47,8 @@
     <scope>1:Data-Parallel Algorithms</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/README.md b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/README.md
index 79b65b7..b629235 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/README.md
@@ -10,7 +10,7 @@ Data-Parallel Algorithms, Performance Strategies
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaMemGetInfo, cudaEventSynchronize, cudaEventRecord, cudaMemset, c
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2017.vcxproj
index da640d6..d72fc3b 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/segmentationTreeThrust.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 1 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2019.vcxproj
index 83cd990..96fd376 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/segmentationTreeThrust.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 1 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2022.vcxproj
index 4f1a84a..18e37f1 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/segmentationTreeThrust.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 1 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/Makefile
index c87e133..4f210b3 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/Makefile
@@ -312,7 +312,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/NsightEclipse.xml
index 854ef6c..d606006 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/NsightEclipse.xml
@@ -53,6 +53,20 @@
     <scope>1:Data-Parallel Algorithms</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/README.md b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/README.md
index 39e1dbe..5afaefe 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/README.md
@@ -10,6 +10,8 @@ Data-Parallel Algorithms, Performance Strategies
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux, Windows
@@ -28,7 +30,7 @@ cudaMemcpy, cudaFree, cudaMallocHost, cudaEventSynchronize, cudaEventRecord, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan.cu.hip
index 05c1860..ba26509 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan.cu.hip
@@ -213,9 +213,9 @@ bool shuffle_simple_test(int argc, char **argv) {
   cuda_device = findCudaDevice(argc, (const char **)argv);
 
   hipDeviceProp_t deviceProp;
-  checkCudaErrors(hipGetDevice(&cuda_device));
+  HIPCHECK(hipGetDevice(&cuda_device));
 
-  checkCudaErrors(hipGetDeviceProperties(&deviceProp, cuda_device));
+  HIPCHECK(hipGetDeviceProperties(&deviceProp, cuda_device));
 
   printf("> Detected Compute SM %d.%d hardware with %d multi-processors\n",
          deviceProp.major, deviceProp.minor, deviceProp.multiProcessorCount);
@@ -227,9 +227,9 @@ bool shuffle_simple_test(int argc, char **argv) {
     exit(EXIT_WAIVED);
   }
 
-  checkCudaErrors(hipHostMalloc(reinterpret_cast<void **>(&h_data),
+  HIPCHECK(hipHostMalloc(reinterpret_cast<void **>(&h_data),
                                  sizeof(int) * n_elements));
-  checkCudaErrors(hipHostMalloc(reinterpret_cast<void **>(&h_result),
+  HIPCHECK(hipHostMalloc(reinterpret_cast<void **>(&h_result),
                                  sizeof(int) * n_elements));
 
   // initialize data:
@@ -259,32 +259,32 @@ bool shuffle_simple_test(int argc, char **argv) {
 
   // initialize a timer
   hipEvent_t start, stop;
-  checkCudaErrors(hipEventCreate(&start));
-  checkCudaErrors(hipEventCreate(&stop));
+  HIPCHECK(hipEventCreate(&start));
+  HIPCHECK(hipEventCreate(&stop));
   float et = 0;
   float inc = 0;
 
-  checkCudaErrors(hipMalloc(reinterpret_cast<void **>(&d_data), sz));
-  checkCudaErrors(
+  HIPCHECK(hipMalloc(reinterpret_cast<void **>(&d_data), sz));
+  HIPCHECK(
       hipMalloc(reinterpret_cast<void **>(&d_partial_sums), partial_sz));
-  checkCudaErrors(hipMemset(d_partial_sums, 0, partial_sz));
+  HIPCHECK(hipMemset(d_partial_sums, 0, partial_sz));
 
-  checkCudaErrors(
+  HIPCHECK(
       hipHostMalloc(reinterpret_cast<void **>(&h_partial_sums), partial_sz));
-  checkCudaErrors(hipMemcpy(d_data, h_data, sz, hipMemcpyHostToDevice));
+  HIPCHECK(hipMemcpy(d_data, h_data, sz, hipMemcpyHostToDevice));
 
-  checkCudaErrors(hipEventRecord(start, 0));
+  HIPCHECK(hipEventRecord(start, 0));
   shfl_scan_test<<<gridSize, blockSize, shmem_sz>>>(d_data, 32, d_partial_sums);
   shfl_scan_test<<<p_gridSize, p_blockSize, shmem_sz>>>(d_partial_sums, 32);
   uniform_add<<<gridSize - 1, blockSize>>>(d_data + blockSize, d_partial_sums,
                                            n_elements);
-  checkCudaErrors(hipEventRecord(stop, 0));
-  checkCudaErrors(hipEventSynchronize(stop));
-  checkCudaErrors(hipEventElapsedTime(&inc, start, stop));
+  HIPCHECK(hipEventRecord(stop, 0));
+  HIPCHECK(hipEventSynchronize(stop));
+  HIPCHECK(hipEventElapsedTime(&inc, start, stop));
   et += inc;
 
-  checkCudaErrors(hipMemcpy(h_result, d_data, sz, hipMemcpyDeviceToHost));
-  checkCudaErrors(hipMemcpy(h_partial_sums, d_partial_sums, partial_sz,
+  HIPCHECK(hipMemcpy(h_result, d_data, sz, hipMemcpyDeviceToHost));
+  HIPCHECK(hipMemcpy(h_partial_sums, d_partial_sums, partial_sz,
                              hipMemcpyDeviceToHost));
 
   printf("Test Sum: %d\n", h_partial_sums[n_partialSums - 1]);
@@ -294,11 +294,11 @@ bool shuffle_simple_test(int argc, char **argv) {
 
   bool bTestResult = CPUverify(h_data, h_result, n_elements);
 
-  checkCudaErrors(hipHostFree(h_data));
-  checkCudaErrors(hipHostFree(h_result));
-  checkCudaErrors(hipHostFree(h_partial_sums));
-  checkCudaErrors(hipFree(d_data));
-  checkCudaErrors(hipFree(d_partial_sums));
+  HIPCHECK(hipHostFree(h_data));
+  HIPCHECK(hipHostFree(h_result));
+  HIPCHECK(hipHostFree(h_partial_sums));
+  HIPCHECK(hipFree(d_data));
+  HIPCHECK(hipFree(d_partial_sums));
 
   return bTestResult;
 }
@@ -317,7 +317,7 @@ bool shuffle_integral_image_test() {
   printf("\nComputing Integral Image Test on size %d x %d synthetic data\n", w,
          h);
   printf("---------------------------------------------------\n");
-  checkCudaErrors(hipHostMalloc(reinterpret_cast<void **>(&h_image), sz));
+  HIPCHECK(hipHostMalloc(reinterpret_cast<void **>(&h_image), sz));
   // fill test "image" with synthetic 1's data
   memset(h_image, 0, sz);
 
@@ -327,11 +327,11 @@ bool shuffle_integral_image_test() {
   int gridSize = h;
 
   // Create a synthetic image for testing
-  checkCudaErrors(hipMalloc(reinterpret_cast<void **>(&d_data), sz));
-  checkCudaErrors(hipMalloc(reinterpret_cast<void **>(&d_integral_image),
+  HIPCHECK(hipMalloc(reinterpret_cast<void **>(&d_data), sz));
+  HIPCHECK(hipMalloc(reinterpret_cast<void **>(&d_integral_image),
                              n_elements * sizeof(int) * 4));
-  checkCudaErrors(hipMemset(d_data, 1, sz));
-  checkCudaErrors(hipMemset(d_integral_image, 0, sz));
+  HIPCHECK(hipMemset(d_data, 1, sz));
+  HIPCHECK(hipMemset(d_integral_image, 0, sz));
 
   hipEvent_t start, stop;
   hipEventCreate(&start);
@@ -345,12 +345,12 @@ bool shuffle_integral_image_test() {
       reinterpret_cast<uint4 *>(d_data),
       reinterpret_cast<uint4 *>(d_integral_image));
   hipEventRecord(stop);
-  checkCudaErrors(hipEventSynchronize(stop));
-  checkCudaErrors(hipEventElapsedTime(&et, start, stop));
+  HIPCHECK(hipEventSynchronize(stop));
+  HIPCHECK(hipEventElapsedTime(&et, start, stop));
   printf("Method: Fast  Time (GPU Timer): %f ms ", et);
 
   // verify the scan line results
-  checkCudaErrors(
+  HIPCHECK(
       hipMemcpy(h_image, d_integral_image, sz, hipMemcpyDeviceToHost));
   err = verifyDataRowSums(h_image, w, h);
   printf("Diff = %d\n", err);
@@ -363,21 +363,21 @@ bool shuffle_integral_image_test() {
   shfl_vertical_shfl<<<testGrid, blockSz>>>((unsigned int *)d_integral_image, w,
                                             h);
   hipEventRecord(stop);
-  checkCudaErrors(hipEventSynchronize(stop));
-  checkCudaErrors(hipEventElapsedTime(&et, start, stop));
+  HIPCHECK(hipEventSynchronize(stop));
+  HIPCHECK(hipEventElapsedTime(&et, start, stop));
   printf("Method: Vertical Scan  Time (GPU Timer): %f ms ", et);
 
   // Verify the column results
-  checkCudaErrors(
+  HIPCHECK(
       hipMemcpy(h_image, d_integral_image, sz, hipMemcpyDeviceToHost));
   printf("\n");
 
   int finalSum = h_image[w * h - 1];
   printf("CheckSum: %d, (expect %dx%d=%d)\n", finalSum, w, h, w * h);
 
-  checkCudaErrors(hipFree(d_data));
-  checkCudaErrors(hipFree(d_integral_image));
-  checkCudaErrors(hipHostFree(h_image));
+  HIPCHECK(hipFree(d_data));
+  HIPCHECK(hipFree(d_integral_image));
+  HIPCHECK(hipHostFree(h_image));
   // verify final sum: if the final value in the corner is the same as the size
   // of the buffer (all 1's) then the integral image was generated successfully
   return (finalSum == w * h) ? true : false;
@@ -395,9 +395,9 @@ int main(int argc, char *argv[]) {
   cuda_device = findCudaDevice(argc, (const char **)argv);
 
   hipDeviceProp_t deviceProp;
-  checkCudaErrors(hipGetDevice(&cuda_device));
+  HIPCHECK(hipGetDevice(&cuda_device));
 
-  checkCudaErrors(hipGetDeviceProperties(&deviceProp, cuda_device));
+  HIPCHECK(hipGetDeviceProperties(&deviceProp, cuda_device));
 
   printf("> Detected Compute SM %d.%d hardware with %d multi-processors\n",
          deviceProp.major, deviceProp.minor, deviceProp.multiProcessorCount);
@@ -429,51 +429,3 @@ ing test.\n");
 
   exit((bTestResult) ? EXIT_SUCCESS : EXIT_FAILURE);
 }
-ing test.\n");
-    exit(EXIT_WAIVED);
-  }
-
-  bool bTestResult = true;
-  bool simpleTest = shuffle_simple_test(argc, argv);
-  bool intTest = shuffle_integral_image_test();
-
-  bTestResult = simpleTest & intTest;
-
-  exit((bTestResult) ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-ing test.\n");
-    exit(EXIT_WAIVED);
-  }
-
-  bool bTestResult = true;
-  bool simpleTest = shuffle_simple_test(argc, argv);
-  bool intTest = shuffle_integral_image_test();
-
-  bTestResult = simpleTest & intTest;
-
-  exit((bTestResult) ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-ing test.\n");
-    exit(EXIT_WAIVED);
-  }
-
-  bool bTestResult = true;
-  bool simpleTest = shuffle_simple_test(argc, argv);
-  bool intTest = shuffle_integral_image_test();
-
-  bTestResult = simpleTest & intTest;
-
-  exit((bTestResult) ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-ing test.\n");
-    exit(EXIT_WAIVED);
-  }
-
-  bool bTestResult = true;
-  bool simpleTest = shuffle_simple_test(argc, argv);
-  bool intTest = shuffle_integral_image_test();
-
-  bTestResult = simpleTest & intTest;
-
-  exit((bTestResult) ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2017.vcxproj
index 3a3de30..9e80171 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/shfl_scan.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2019.vcxproj
index 34477cb..72076c4 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/shfl_scan.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2022.vcxproj
index 6f5c744..3ad9db4 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/shfl_scan.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/Makefile
index 7a0404d..7d715f2 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/NsightEclipse.xml
index dabd01e..3ef6272 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/NsightEclipse.xml
@@ -33,6 +33,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>1:Data-Parallel Algorithms</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/README.md b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/README.md
index 1c0c4ee..707ed30 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/README.md
@@ -10,7 +10,7 @@ Data-Parallel Algorithms
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMalloc, cudaDeviceSynchronize, cudaMemcpy, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/bitonicSort.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/bitonicSort.cu.hip
index e69de29..9c9aa43 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/bitonicSort.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/bitonicSort.cu.hip
@@ -0,0 +1,278 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+//Based on http://www.iti.fh-flensburg.de/lang/algorithmen/sortieren/bitonic/bitonicen.htm
+
+
+#include <hip/hip_runtime.h>
+#include <assert.h>
+#include <hip/hip_cooperative_groups.h>
+
+namespace cg = cooperative_groups;
+#include <helper_cuda.h>
+#include "sortingNetworks_common.h"
+#include "sortingNetworks_common.cuh"
+
+////////////////////////////////////////////////////////////////////////////////
+// Monolithic bitonic sort kernel for short arrays fitting into shared memory
+////////////////////////////////////////////////////////////////////////////////
+__global__ void bitonicSortShared(uint *d_DstKey, uint *d_DstVal,
+                                  uint *d_SrcKey, uint *d_SrcVal,
+                                  uint arrayLength, uint dir) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  // Shared memory storage for one or more short vectors
+  __shared__ uint s_key[SHARED_SIZE_LIMIT];
+  __shared__ uint s_val[SHARED_SIZE_LIMIT];
+
+  // Offset to the beginning of subbatch and load data
+  d_SrcKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  d_SrcVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  d_DstKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  d_DstVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  s_key[threadIdx.x + 0] = d_SrcKey[0];
+  s_val[threadIdx.x + 0] = d_SrcVal[0];
+  s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
+      d_SrcKey[(SHARED_SIZE_LIMIT / 2)];
+  s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
+      d_SrcVal[(SHARED_SIZE_LIMIT / 2)];
+
+  for (uint size = 2; size < arrayLength; size <<= 1) {
+    // Bitonic merge
+    uint ddd = dir ^ ((threadIdx.x & (size / 2)) != 0);
+
+    for (uint stride = size / 2; stride > 0; stride >>= 1) {
+      cg::sync(cta);
+      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
+      Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
+                 s_val[pos + stride], ddd);
+    }
+  }
+
+  // ddd == dir for the last bitonic merge step
+  {
+    for (uint stride = arrayLength / 2; stride > 0; stride >>= 1) {
+      cg::sync(cta);
+      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
+      Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
+                 s_val[pos + stride], dir);
+    }
+  }
+
+  cg::sync(cta);
+  d_DstKey[0] = s_key[threadIdx.x + 0];
+  d_DstVal[0] = s_val[threadIdx.x + 0];
+  d_DstKey[(SHARED_SIZE_LIMIT / 2)] =
+      s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
+  d_DstVal[(SHARED_SIZE_LIMIT / 2)] =
+      s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Bitonic sort kernel for large arrays (not fitting into shared memory)
+////////////////////////////////////////////////////////////////////////////////
+// Bottom-level bitonic sort
+// Almost the same as bitonicSortShared with the exception of
+// even / odd subarrays being sorted in opposite directions
+// Bitonic merge accepts both
+// Ascending | descending or descending | ascending sorted pairs
+__global__ void bitonicSortShared1(uint *d_DstKey, uint *d_DstVal,
+                                   uint *d_SrcKey, uint *d_SrcVal) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  // Shared memory storage for current subarray
+  __shared__ uint s_key[SHARED_SIZE_LIMIT];
+  __shared__ uint s_val[SHARED_SIZE_LIMIT];
+
+  // Offset to the beginning of subarray and load data
+  d_SrcKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  d_SrcVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  d_DstKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  d_DstVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  s_key[threadIdx.x + 0] = d_SrcKey[0];
+  s_val[threadIdx.x + 0] = d_SrcVal[0];
+  s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
+      d_SrcKey[(SHARED_SIZE_LIMIT / 2)];
+  s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
+      d_SrcVal[(SHARED_SIZE_LIMIT / 2)];
+
+  for (uint size = 2; size < SHARED_SIZE_LIMIT; size <<= 1) {
+    // Bitonic merge
+    uint ddd = (threadIdx.x & (size / 2)) != 0;
+
+    for (uint stride = size / 2; stride > 0; stride >>= 1) {
+      cg::sync(cta);
+      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
+      Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
+                 s_val[pos + stride], ddd);
+    }
+  }
+
+  // Odd / even arrays of SHARED_SIZE_LIMIT elements
+  // sorted in opposite directions
+  uint ddd = blockIdx.x & 1;
+  {
+    for (uint stride = SHARED_SIZE_LIMIT / 2; stride > 0; stride >>= 1) {
+      cg::sync(cta);
+      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
+      Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
+                 s_val[pos + stride], ddd);
+    }
+  }
+
+  cg::sync(cta);
+  d_DstKey[0] = s_key[threadIdx.x + 0];
+  d_DstVal[0] = s_val[threadIdx.x + 0];
+  d_DstKey[(SHARED_SIZE_LIMIT / 2)] =
+      s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
+  d_DstVal[(SHARED_SIZE_LIMIT / 2)] =
+      s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
+}
+
+// Bitonic merge iteration for stride >= SHARED_SIZE_LIMIT
+__global__ void bitonicMergeGlobal(uint *d_DstKey, uint *d_DstVal,
+                                   uint *d_SrcKey, uint *d_SrcVal,
+                                   uint arrayLength, uint size, uint stride,
+                                   uint dir) {
+  uint global_comparatorI = blockIdx.x * blockDim.x + threadIdx.x;
+  uint comparatorI = global_comparatorI & (arrayLength / 2 - 1);
+
+  // Bitonic merge
+  uint ddd = dir ^ ((comparatorI & (size / 2)) != 0);
+  uint pos = 2 * global_comparatorI - (global_comparatorI & (stride - 1));
+
+  uint keyA = d_SrcKey[pos + 0];
+  uint valA = d_SrcVal[pos + 0];
+  uint keyB = d_SrcKey[pos + stride];
+  uint valB = d_SrcVal[pos + stride];
+
+  Comparator(keyA, valA, keyB, valB, ddd);
+
+  d_DstKey[pos + 0] = keyA;
+  d_DstVal[pos + 0] = valA;
+  d_DstKey[pos + stride] = keyB;
+  d_DstVal[pos + stride] = valB;
+}
+
+// Combined bitonic merge steps for
+// size > SHARED_SIZE_LIMIT and stride = [1 .. SHARED_SIZE_LIMIT / 2]
+__global__ void bitonicMergeShared(uint *d_DstKey, uint *d_DstVal,
+                                   uint *d_SrcKey, uint *d_SrcVal,
+                                   uint arrayLength, uint size, uint dir) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  // Shared memory storage for current subarray
+  __shared__ uint s_key[SHARED_SIZE_LIMIT];
+  __shared__ uint s_val[SHARED_SIZE_LIMIT];
+
+  d_SrcKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  d_SrcVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  d_DstKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  d_DstVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  s_key[threadIdx.x + 0] = d_SrcKey[0];
+  s_val[threadIdx.x + 0] = d_SrcVal[0];
+  s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
+      d_SrcKey[(SHARED_SIZE_LIMIT / 2)];
+  s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
+      d_SrcVal[(SHARED_SIZE_LIMIT / 2)];
+
+  // Bitonic merge
+  uint comparatorI =
+      UMAD(blockIdx.x, blockDim.x, threadIdx.x) & ((arrayLength / 2) - 1);
+  uint ddd = dir ^ ((comparatorI & (size / 2)) != 0);
+
+  for (uint stride = SHARED_SIZE_LIMIT / 2; stride > 0; stride >>= 1) {
+    cg::sync(cta);
+    uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
+    Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
+               s_val[pos + stride], ddd);
+  }
+
+  cg::sync(cta);
+  d_DstKey[0] = s_key[threadIdx.x + 0];
+  d_DstVal[0] = s_val[threadIdx.x + 0];
+  d_DstKey[(SHARED_SIZE_LIMIT / 2)] =
+      s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
+  d_DstVal[(SHARED_SIZE_LIMIT / 2)] =
+      s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Interface function
+////////////////////////////////////////////////////////////////////////////////
+// Helper function (also used by odd-even merge sort)
+extern "C" uint factorRadix2(uint *log2L, uint L) {
+  if (!L) {
+    *log2L = 0;
+    return 0;
+  } else {
+    for (*log2L = 0; (L & 1) == 0; L >>= 1, *log2L++)
+      ;
+
+    return L;
+  }
+}
+
+extern "C" uint bitonicSort(uint *d_DstKey, uint *d_DstVal, uint *d_SrcKey,
+                            uint *d_SrcVal, uint batchSize, uint arrayLength,
+                            uint dir) {
+  // Nothing to sort
+  if (arrayLength < 2) return 0;
+
+  // Only power-of-two array lengths are supported by this implementation
+  uint log2L;
+  uint factorizationRemainder = factorRadix2(&log2L, arrayLength);
+  assert(factorizationRemainder == 1);
+
+  dir = (dir != 0);
+
+  uint blockCount = batchSize * arrayLength / SHARED_SIZE_LIMIT;
+  uint threadCount = SHARED_SIZE_LIMIT / 2;
+
+  if (arrayLength <= SHARED_SIZE_LIMIT) {
+    assert((batchSize * arrayLength) % SHARED_SIZE_LIMIT == 0);
+    bitonicSortShared<<<blockCount, threadCount>>>(d_DstKey, d_DstVal, d_SrcKey,
+                                                   d_SrcVal, arrayLength, dir);
+  } else {
+    bitonicSortShared1<<<blockCount, threadCount>>>(d_DstKey, d_DstVal,
+                                                    d_SrcKey, d_SrcVal);
+
+    for (uint size = 2 * SHARED_SIZE_LIMIT; size <= arrayLength; size <<= 1)
+      for (unsigned stride = size / 2; stride > 0; stride >>= 1)
+        if (stride >= SHARED_SIZE_LIMIT) {
+          bitonicMergeGlobal<<<(batchSize * arrayLength) / 512, 256>>>(
+              d_DstKey, d_DstVal, d_DstKey, d_DstVal, arrayLength, size, stride,
+              dir);
+        } else {
+          bitonicMergeShared<<<blockCount, threadCount>>>(
+              d_DstKey, d_DstVal, d_DstKey, d_DstVal, arrayLength, size, dir);
+          break;
+        }
+  }
+
+  return threadCount;
+}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/oddEvenMergeSort.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/oddEvenMergeSort.cu.hip
index e69de29..05791f4 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/oddEvenMergeSort.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/oddEvenMergeSort.cu.hip
@@ -0,0 +1,182 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+//Based on http://www.iti.fh-flensburg.de/lang/algorithmen/sortieren/networks/oemen.htm
+
+
+
+#include <hip/hip_runtime.h>
+#include <assert.h>
+#include <hip/hip_cooperative_groups.h>
+
+namespace cg = cooperative_groups;
+
+#include "helper_cuda_hipified.h"
+#include "sortingNetworks_common.h"
+#include "sortingNetworks_common.cuh"
+
+////////////////////////////////////////////////////////////////////////////////
+// Monolithic Bacther's sort kernel for short arrays fitting into shared memory
+////////////////////////////////////////////////////////////////////////////////
+__global__ void oddEvenMergeSortShared(uint *d_DstKey, uint *d_DstVal,
+                                       uint *d_SrcKey, uint *d_SrcVal,
+                                       uint arrayLength, uint dir) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  // Shared memory storage for one or more small vectors
+  __shared__ uint s_key[SHARED_SIZE_LIMIT];
+  __shared__ uint s_val[SHARED_SIZE_LIMIT];
+
+  // Offset to the beginning of subbatch and load data
+  d_SrcKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  d_SrcVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  d_DstKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  d_DstVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
+  s_key[threadIdx.x + 0] = d_SrcKey[0];
+  s_val[threadIdx.x + 0] = d_SrcVal[0];
+  s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
+      d_SrcKey[(SHARED_SIZE_LIMIT / 2)];
+  s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
+      d_SrcVal[(SHARED_SIZE_LIMIT / 2)];
+
+  for (uint size = 2; size <= arrayLength; size <<= 1) {
+    uint stride = size / 2;
+    uint offset = threadIdx.x & (stride - 1);
+
+    {
+      cg::sync(cta);
+      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
+      Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
+                 s_val[pos + stride], dir);
+      stride >>= 1;
+    }
+
+    for (; stride > 0; stride >>= 1) {
+      cg::sync(cta);
+      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
+
+      if (offset >= stride)
+        Comparator(s_key[pos - stride], s_val[pos - stride], s_key[pos + 0],
+                   s_val[pos + 0], dir);
+    }
+  }
+
+  cg::sync(cta);
+  d_DstKey[0] = s_key[threadIdx.x + 0];
+  d_DstVal[0] = s_val[threadIdx.x + 0];
+  d_DstKey[(SHARED_SIZE_LIMIT / 2)] =
+      s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
+  d_DstVal[(SHARED_SIZE_LIMIT / 2)] =
+      s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Odd-even merge sort iteration kernel
+// for large arrays (not fitting into shared memory)
+////////////////////////////////////////////////////////////////////////////////
+__global__ void oddEvenMergeGlobal(uint *d_DstKey, uint *d_DstVal,
+                                   uint *d_SrcKey, uint *d_SrcVal,
+                                   uint arrayLength, uint size, uint stride,
+                                   uint dir) {
+  uint global_comparatorI = blockIdx.x * blockDim.x + threadIdx.x;
+
+  // Odd-even merge
+  uint pos = 2 * global_comparatorI - (global_comparatorI & (stride - 1));
+
+  if (stride < size / 2) {
+    uint offset = global_comparatorI & ((size / 2) - 1);
+
+    if (offset >= stride) {
+      uint keyA = d_SrcKey[pos - stride];
+      uint valA = d_SrcVal[pos - stride];
+      uint keyB = d_SrcKey[pos + 0];
+      uint valB = d_SrcVal[pos + 0];
+
+      Comparator(keyA, valA, keyB, valB, dir);
+
+      d_DstKey[pos - stride] = keyA;
+      d_DstVal[pos - stride] = valA;
+      d_DstKey[pos + 0] = keyB;
+      d_DstVal[pos + 0] = valB;
+    }
+  } else {
+    uint keyA = d_SrcKey[pos + 0];
+    uint valA = d_SrcVal[pos + 0];
+    uint keyB = d_SrcKey[pos + stride];
+    uint valB = d_SrcVal[pos + stride];
+
+    Comparator(keyA, valA, keyB, valB, dir);
+
+    d_DstKey[pos + 0] = keyA;
+    d_DstVal[pos + 0] = valA;
+    d_DstKey[pos + stride] = keyB;
+    d_DstVal[pos + stride] = valB;
+  }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Interface function
+////////////////////////////////////////////////////////////////////////////////
+// Helper function
+extern "C" uint factorRadix2(uint *log2L, uint L);
+
+extern "C" void oddEvenMergeSort(uint *d_DstKey, uint *d_DstVal, uint *d_SrcKey,
+                                 uint *d_SrcVal, uint batchSize,
+                                 uint arrayLength, uint dir) {
+  // Nothing to sort
+  if (arrayLength < 2) return;
+
+  // Only power-of-two array lengths are supported by this implementation
+  uint log2L;
+  uint factorizationRemainder = factorRadix2(&log2L, arrayLength);
+  assert(factorizationRemainder == 1);
+
+  dir = (dir != 0);
+
+  uint blockCount = (batchSize * arrayLength) / SHARED_SIZE_LIMIT;
+  uint threadCount = SHARED_SIZE_LIMIT / 2;
+
+  if (arrayLength <= SHARED_SIZE_LIMIT) {
+    assert(SHARED_SIZE_LIMIT % arrayLength == 0);
+    oddEvenMergeSortShared<<<blockCount, threadCount>>>(
+        d_DstKey, d_DstVal, d_SrcKey, d_SrcVal, arrayLength, dir);
+  } else {
+    oddEvenMergeSortShared<<<blockCount, threadCount>>>(
+        d_DstKey, d_DstVal, d_SrcKey, d_SrcVal, SHARED_SIZE_LIMIT, dir);
+
+    for (uint size = 2 * SHARED_SIZE_LIMIT; size <= arrayLength; size <<= 1)
+      for (unsigned stride = size / 2; stride > 0; stride >>= 1) {
+        // Unlike with bitonic sort, combining bitonic merge steps with
+        // stride = [SHARED_SIZE_LIMIT / 2 .. 1] seems to be impossible as there
+        // are dependencies between data elements crossing the SHARED_SIZE_LIMIT
+        // borders
+        oddEvenMergeGlobal<<<(batchSize * arrayLength) / 512, 256>>>(
+            d_DstKey, d_DstVal, d_DstKey, d_DstVal, arrayLength, size, stride,
+            dir);
+      }
+  }
+}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2017.vcxproj
index 80ab809..7c018ef 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/sortingNetworks.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2019.vcxproj
index 9fbd5a0..3181de7 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/sortingNetworks.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2022.vcxproj
index ca3c1f1..dc83a7b 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/sortingNetworks.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/Makefile
index ff6c36b..c672f70 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/Makefile
@@ -287,7 +287,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/README.md b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/README.md
index 5ab1cb7..4af372e 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/README.md
@@ -27,7 +27,7 @@ cudaDeviceGetDefaultMemPool, cudaFreeAsync, cudaStreamCreateWithFlags, cudaStrea
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation.cu.hip
index e69de29..c905e5b 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation.cu.hip
@@ -0,0 +1,245 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * This sample demonstrates stream ordered memory allocation on a GPU using
+ * cudaMallocAsync and cudaMemPool family of APIs.
+ *
+ * basicStreamOrderedAllocation(): demonstrates stream ordered allocation using
+ * cudaMallocAsync/cudaFreeAsync APIs with default settings.
+ *
+ * streamOrderedAllocationPostSync(): demonstrates if there's a synchronization
+ * in between allocations, then setting the release threshold on the pool will
+ * make sure the synchronize will not free memory back to the OS.
+ */
+
+// System includes
+#include <assert.h>
+#include <stdio.h>
+//#include "rocprofiler.h"
+#include <climits>
+
+// CUDA runtime
+#include <hip/hip_runtime.h>
+
+// helper functions and utilities to work with CUDA
+#include "HIPCHECK.h"
+#include "helper_cuda_hipified.h"
+#include "helper_functions.h"
+
+#define MAX_ITER 20
+
+/* Add two vectors on the GPU */
+__global__ void vectorAddGPU(const float *a, const float *b, float *c, int N) {
+  int idx = blockIdx.x * blockDim.x + threadIdx.x;
+
+  if (idx < N) {
+    c[idx] = a[idx] + b[idx];
+  }
+}
+
+int basicStreamOrderedAllocation(const int dev, const int nelem, const float *a,
+                                 const float *b, float *c) {
+  float *d_a, *d_b, *d_c;  // Device buffers
+  float errorNorm, refNorm, ref, diff;
+  size_t bytes = nelem * sizeof(float);
+
+  hipStream_t stream;
+  printf("Starting basicStreamOrderedAllocation()\n");
+  HIPCHECK(hipSetDevice(dev));
+  HIPCHECK(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
+
+  HIPCHECK(hipMallocAsync(&d_a, bytes, stream));
+  HIPCHECK(hipMallocAsync(&d_b, bytes, stream));
+  HIPCHECK(hipMallocAsync(&d_c, bytes, stream));
+  HIPCHECK(
+      hipMemcpyAsync(d_a, a, bytes, hipMemcpyHostToDevice, stream));
+  HIPCHECK(
+      hipMemcpyAsync(d_b, b, bytes, hipMemcpyHostToDevice, stream));
+
+  dim3 block(256);
+  dim3 grid((unsigned int)ceil(nelem / (float)block.x));
+  vectorAddGPU<<<grid, block, 0, stream>>>(d_a, d_b, d_c, nelem);
+
+  HIPCHECK(hipFreeAsync(d_a, stream));
+  HIPCHECK(hipFreeAsync(d_b, stream));
+  HIPCHECK(
+      hipMemcpyAsync(c, d_c, bytes, hipMemcpyDeviceToHost, stream));
+  HIPCHECK(hipFreeAsync(d_c, stream));
+  HIPCHECK(hipStreamSynchronize(stream));
+
+  /* Compare the results */
+  printf("> Checking the results from vectorAddGPU() ...\n");
+  errorNorm = 0.f;
+  refNorm = 0.f;
+
+  for (int n = 0; n < nelem; n++) {
+    ref = a[n] + b[n];
+    diff = c[n] - ref;
+    errorNorm += diff * diff;
+    refNorm += ref * ref;
+  }
+
+  errorNorm = (float)sqrt((double)errorNorm);
+  refNorm = (float)sqrt((double)refNorm);
+  if (errorNorm / refNorm < 1.e-6f)
+    printf("basicStreamOrderedAllocation PASSED\n");
+
+  HIPCHECK(hipStreamDestroy(stream));
+
+  return errorNorm / refNorm < 1.e-6f ? EXIT_SUCCESS : EXIT_FAILURE;
+}
+
+// streamOrderedAllocationPostSync(): demonstrates If the application wants the
+// memory to persist in the pool beyond synchronization, then it sets the
+// release threshold on the pool. This way, when the application reaches the
+// "steady state", it is no longer allocating/freeing memory from the OS.
+int streamOrderedAllocationPostSync(const int dev, const int nelem,
+                                    const float *a, const float *b, float *c) {
+  float *d_a, *d_b, *d_c;  // Device buffers
+  float errorNorm, refNorm, ref, diff;
+  size_t bytes = nelem * sizeof(float);
+
+  hipStream_t stream;
+  hipMemPool_t memPool;
+  hipEvent_t start, end;
+  printf("Starting streamOrderedAllocationPostSync()\n");
+  HIPCHECK(hipSetDevice(dev));
+  HIPCHECK(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
+  HIPCHECK(hipEventCreate(&start));
+  HIPCHECK(hipEventCreate(&end));
+
+  HIPCHECK(hipDeviceGetDefaultMemPool(&memPool, dev));
+  uint64_t thresholdVal = ULONG_MAX;
+  // set high release threshold on the default pool so that cudaFreeAsync will
+  // not actually release memory to the system. By default, the release
+  // threshold for a memory pool is set to zero. This implies that the CUDA
+  // driver is allowed to release a memory chunk back to the system as long as
+  // it does not contain any active suballocations.
+  HIPCHECK(hipMemPoolSetAttribute(
+      memPool, hipMemPoolAttrReleaseThreshold, (void *)&thresholdVal));
+
+  // Record the start event
+  HIPCHECK(hipEventRecord(start, stream));
+  for (int i = 0; i < MAX_ITER; i++) {
+    HIPCHECK(hipMallocAsync(&d_a, bytes, stream));
+    HIPCHECK(hipMallocAsync(&d_b, bytes, stream));
+    HIPCHECK(hipMallocAsync(&d_c, bytes, stream));
+    HIPCHECK(
+        hipMemcpyAsync(d_a, a, bytes, hipMemcpyHostToDevice, stream));
+    HIPCHECK(
+        hipMemcpyAsync(d_b, b, bytes, hipMemcpyHostToDevice, stream));
+
+    dim3 block(256);
+    dim3 grid((unsigned int)ceil(nelem / (float)block.x));
+    vectorAddGPU<<<grid, block, 0, stream>>>(d_a, d_b, d_c, nelem);
+
+    HIPCHECK(hipFreeAsync(d_a, stream));
+    HIPCHECK(hipFreeAsync(d_b, stream));
+    HIPCHECK(
+        hipMemcpyAsync(c, d_c, bytes, hipMemcpyDeviceToHost, stream));
+    HIPCHECK(hipFreeAsync(d_c, stream));
+    HIPCHECK(hipStreamSynchronize(stream));
+  }
+  HIPCHECK(hipEventRecord(end, stream));
+  // Wait for the end event to complete
+  HIPCHECK(hipEventSynchronize(end));
+
+  float msecTotal = 0.0f;
+  HIPCHECK(hipEventElapsedTime(&msecTotal, start, end));
+  printf("Total elapsed time = %f ms over %d iterations\n", msecTotal,
+         MAX_ITER);
+
+  /* Compare the results */
+  printf("> Checking the results from vectorAddGPU() ...\n");
+  errorNorm = 0.f;
+  refNorm = 0.f;
+
+  for (int n = 0; n < nelem; n++) {
+    ref = a[n] + b[n];
+    diff = c[n] - ref;
+    errorNorm += diff * diff;
+    refNorm += ref * ref;
+  }
+
+  errorNorm = (float)sqrt((double)errorNorm);
+  refNorm = (float)sqrt((double)refNorm);
+  if (errorNorm / refNorm < 1.e-6f)
+    printf("streamOrderedAllocationPostSync PASSED\n");
+
+  HIPCHECK(hipStreamDestroy(stream));
+
+  return errorNorm / refNorm < 1.e-6f ? EXIT_SUCCESS : EXIT_FAILURE;
+}
+
+int main(int argc, char **argv) {
+  int nelem;
+  int dev = 0;  // use default device 0
+  size_t bytes;
+  float *a, *b, *c;  // Host
+
+  if (checkCmdLineFlag(argc, (const char **)argv, "help")) {
+    printf("Usage:  streamOrderedAllocation [OPTION]\n\n");
+    printf("Options:\n");
+    printf("  --device=[device #]  Specify the device to be used\n");
+    return EXIT_SUCCESS;
+  }
+
+  dev = findCudaDevice(argc, (const char **)argv);
+
+  int isMemPoolSupported = 0;
+  HIPCHECK(hipDeviceGetAttribute(&isMemPoolSupported,
+                                         hipDeviceAttributeMemoryPoolsSupported, dev));
+  if (!isMemPoolSupported) {
+    printf("Waiving execution as device does not support Memory Pools\n");
+    exit(EXIT_WAIVED);
+  }
+
+  // Allocate CPU memory.
+  nelem = 1048576;
+  bytes = nelem * sizeof(float);
+
+  a = (float *)malloc(bytes);
+  b = (float *)malloc(bytes);
+  c = (float *)malloc(bytes);
+  /* Initialize the vectors. */
+  for (int n = 0; n < nelem; n++) {
+    a[n] = rand() / (float)RAND_MAX;
+    b[n] = rand() / (float)RAND_MAX;
+  }
+
+  int ret1 = basicStreamOrderedAllocation(dev, nelem, a, b, c);
+  int ret2 = streamOrderedAllocationPostSync(dev, nelem, a, b, c);
+
+  /* Memory clean up */
+  free(a);
+  free(b);
+  free(c);
+
+  return ((ret1 == EXIT_SUCCESS && ret2 == EXIT_SUCCESS) ? EXIT_SUCCESS
+                                                         : EXIT_FAILURE);
+}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2017.vcxproj
index 517cd0d..8f4dc7c 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/streamOrderedAllocation.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2019.vcxproj
index a69c83f..9cd3baa 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/streamOrderedAllocation.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2022.vcxproj
index f992b1a..6f2d504 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/streamOrderedAllocation.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/Makefile
index 7e719fa..4184516 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/Makefile
@@ -307,7 +307,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/README.md b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/README.md
index 929ee4d..b3eff96 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/README.md
@@ -30,7 +30,7 @@ cudaDeviceGetAttribute, cudaMemPoolImportFromShareableHandle, cudaSetDevice, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/streamOrderedAllocationIPC.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/streamOrderedAllocationIPC.cu.hip
index f549e15..268b3af 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/streamOrderedAllocationIPC.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/streamOrderedAllocationIPC.cu.hip
@@ -451,27 +451,3 @@ d(_WIN32) || defined(WIN64) || defined(_WIN64)
   return EXIT_SUCCESS;
 #endif
 }
-d(_WIN32) || defined(WIN64) || defined(_WIN64)
-  printf("Not supported on ARM\n");
-  return EXIT_WAIVED;
-#else
-  if (argc == 1) {
-    parentProcess(argv[0]);
-  } else {
-    childProcess(atoi(argv[1]));
-  }
-  return EXIT_SUCCESS;
-#endif
-}
-d(_WIN32) || defined(WIN64) || defined(_WIN64)
-  printf("Not supported on ARM\n");
-  return EXIT_WAIVED;
-#else
-  if (argc == 1) {
-    parentProcess(argv[0]);
-  } else {
-    childProcess(atoi(argv[1]));
-  }
-  return EXIT_SUCCESS;
-#endif
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/Makefile
index 40d3a43..75bf638 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/Makefile
@@ -287,7 +287,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/README.md b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/README.md
index b4f77f8..0b2a83d 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/README.md
@@ -27,7 +27,7 @@ cudaDeviceGetDefaultMemPool, cudaFreeAsync, cudaStreamCreateWithFlags, cudaMemPo
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.cu.hip
index e69de29..f94ec7b 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.cu.hip
@@ -0,0 +1,253 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * This sample demonstrates peer-to-peer access of stream ordered memory
+ * allocated with cudaMallocAsync and cudaMemPool family of APIs through simple
+ * kernel which does peer-to-peer to access & scales vector elements.
+ */
+
+// System includes
+#include <assert.h>
+#include <stdio.h>
+#include "rocprofiler.h"
+#include "HIPCHECK.h"
+#include <iostream>
+#include <map>
+#include <set>
+#include <utility>
+// CUDA runtime
+#include <hip/hip_runtime.h>
+
+// helper functions and utilities to work with CUDA
+#include "helper_cuda_hipified.h"
+#include "helper_functions.h"
+
+// Simple kernel to demonstrate copying cudaMallocAsync memory via P2P to peer
+// device
+__global__ void copyP2PAndScale(const int *src, int *dst, int N) {
+  int idx = blockIdx.x * blockDim.x + threadIdx.x;
+
+  if (idx < N) {
+    // scale & store src vector.
+    dst[idx] = 2 * src[idx];
+  }
+}
+
+// Map of device version to device number
+std::multimap<std::pair<int, int>, int> getIdenticalGPUs() {
+  int numGpus = 0;
+  HIPCHECK(hipGetDeviceCount(&numGpus));
+
+  std::multimap<std::pair<int, int>, int> identicalGpus;
+
+  for (int i = 0; i < numGpus; i++) {
+    int isMemPoolSupported = 0;
+    HIPCHECK(hipDeviceGetAttribute(&isMemPoolSupported,
+                                           hipDeviceAttributeMemoryPoolsSupported, i));
+
+    // Filter unsupported devices
+    if (isMemPoolSupported) {
+      int major = 0, minor = 0;
+      HIPCHECK(
+          hipDeviceGetAttribute(&major, hipDeviceAttributeComputeCapabilityMajor, i));
+      HIPCHECK(
+          hipDeviceGetAttribute(&minor, hipDeviceAttributeComputeCapabilityMinor, i));
+      identicalGpus.emplace(std::make_pair(major, minor), i);
+    }
+  }
+
+  return identicalGpus;
+}
+
+std::pair<int, int> getP2PCapableGpuPair() {
+  constexpr size_t kNumGpusRequired = 2;
+
+  auto gpusByArch = getIdenticalGPUs();
+
+  auto it = gpusByArch.begin();
+  auto end = gpusByArch.end();
+
+  auto bestFit = std::make_pair(it, it);
+  // use std::distance to find the largest number of GPUs amongst architectures
+  auto distance = [](decltype(bestFit) p) {
+    return std::distance(p.first, p.second);
+  };
+
+  // Read each unique key/pair element in order
+  for (; it != end; it = gpusByArch.upper_bound(it->first)) {
+    // first and second are iterators bounded within the architecture group
+    auto testFit = gpusByArch.equal_range(it->first);
+    // Always use devices with highest architecture version or whichever has the
+    // most devices available
+    if (distance(bestFit) <= distance(testFit)) bestFit = testFit;
+  }
+
+  if (distance(bestFit) < kNumGpusRequired) {
+    printf(
+        "No Two or more GPUs with same architecture capable of cuda Memory "
+        "Pools found."
+        "\nWaiving the sample\n");
+    exit(EXIT_WAIVED);
+  }
+
+  std::set<int> bestFitDeviceIds;
+
+  // check & select peer-to-peer access capable GPU devices.
+  int devIds[2];
+  for (auto itr = bestFit.first; itr != bestFit.second; itr++) {
+    int deviceId = itr->second;
+    HIPCHECK(hipSetDevice(deviceId));
+
+    std::for_each(itr, bestFit.second, [&deviceId, &bestFitDeviceIds,
+                                        &kNumGpusRequired](
+                                           decltype(*itr) mapPair) {
+      if (deviceId != mapPair.second) {
+        int access = 0;
+        HIPCHECK(
+            hipDeviceCanAccessPeer(&access, deviceId, mapPair.second));
+        printf("Device=%d %s Access Peer Device=%d\n", deviceId,
+               access ? "CAN" : "CANNOT", mapPair.second);
+        if (access && bestFitDeviceIds.size() < kNumGpusRequired) {
+          bestFitDeviceIds.emplace(deviceId);
+          bestFitDeviceIds.emplace(mapPair.second);
+        } else {
+          printf("Ignoring device %i (max devices exceeded)\n", mapPair.second);
+        }
+      }
+    });
+
+    if (bestFitDeviceIds.size() >= kNumGpusRequired) {
+      printf("Selected p2p capable devices - ");
+      int i = 0;
+      for (auto devicesItr = bestFitDeviceIds.begin();
+           devicesItr != bestFitDeviceIds.end(); devicesItr++) {
+        devIds[i++] = *devicesItr;
+        printf("deviceId = %d  ", *devicesItr);
+      }
+      printf("\n");
+      break;
+    }
+  }
+
+  // if bestFitDeviceIds.size() == 0 it means the GPUs in system are not p2p
+  // capable, hence we add it without p2p capability check.
+  if (!bestFitDeviceIds.size()) {
+    printf("No Two or more Devices p2p capable found.. exiting..\n");
+    exit(EXIT_WAIVED);
+  }
+
+  auto p2pGpuPair = std::make_pair(devIds[0], devIds[1]);
+
+  return p2pGpuPair;
+}
+
+int memPoolP2PCopy() {
+  int *dev0_srcVec, *dev1_dstVec;  // Device buffers
+  hipStream_t stream1, stream2;
+  hipMemPool_t memPool;
+  hipEvent_t waitOnStream1;
+
+  // Allocate CPU memory.
+  size_t nelem = 1048576;
+  size_t bytes = nelem * sizeof(int);
+
+  int *a = (int *)malloc(bytes);
+  int *output = (int *)malloc(bytes);
+
+  /* Initialize the vectors. */
+  for (int n = 0; n < nelem; n++) {
+    a[n] = rand() / (int)RAND_MAX;
+  }
+
+  auto p2pDevices = getP2PCapableGpuPair();
+  printf("selected devices = %d & %d\n", p2pDevices.first, p2pDevices.second);
+  HIPCHECK(hipSetDevice(p2pDevices.first));
+  HIPCHECK(hipEventCreate(&waitOnStream1));
+
+  HIPCHECK(hipStreamCreateWithFlags(&stream1, hipStreamNonBlocking));
+
+  // Get the default mempool for device p2pDevices.first from the pair
+  HIPCHECK(hipDeviceGetDefaultMemPool(&memPool, p2pDevices.first));
+
+  // Allocate memory in a stream from the pool set above.
+  HIPCHECK(hipMallocAsync(&dev0_srcVec, bytes, stream1));
+
+  HIPCHECK(
+      hipMemcpyAsync(dev0_srcVec, a, bytes, hipMemcpyHostToDevice, stream1));
+  HIPCHECK(hipEventRecord(waitOnStream1, stream1));
+
+  HIPCHECK(hipSetDevice(p2pDevices.second));
+  HIPCHECK(hipStreamCreateWithFlags(&stream2, hipStreamNonBlocking));
+
+  // Allocate memory in p2pDevices.second device
+  HIPCHECK(hipMallocAsync(&dev1_dstVec, bytes, stream2));
+
+  // Setup peer mappings for p2pDevices.second device
+  hipMemAccessDesc desc;
+  memset(&desc, 0, sizeof(hipMemAccessDesc));
+  desc.location.type = hipMemLocationTypeDevice;
+  desc.location.id = p2pDevices.second;
+  desc.flags = hipMemAccessFlagsProtReadWrite;
+  HIPCHECK(hipMemPoolSetAccess(memPool, &desc, 1));
+
+  printf("> copyP2PAndScale kernel running ...\n");
+  dim3 block(256);
+  dim3 grid((unsigned int)ceil(nelem / (int)block.x));
+  HIPCHECK(hipStreamWaitEvent(stream2, waitOnStream1,3));
+  copyP2PAndScale<<<grid, block, 0, stream2>>>(dev0_srcVec, dev1_dstVec, nelem);
+
+  HIPCHECK(hipMemcpyAsync(output, dev1_dstVec, bytes,
+                                  hipMemcpyDeviceToHost, stream2));
+  HIPCHECK(hipFreeAsync(dev0_srcVec, stream2));
+  HIPCHECK(hipFreeAsync(dev1_dstVec, stream2));
+  HIPCHECK(hipStreamSynchronize(stream2));
+
+  /* Compare the results */
+  printf("> Checking the results from copyP2PAndScale() ...\n");
+
+  for (int n = 0; n < nelem; n++) {
+    if ((2 * a[n]) != output[n]) {
+      printf("mismatch i = %d expected = %d val = %d\n", n, 2 * a[n],
+             output[n]);
+      return EXIT_FAILURE;
+    }
+  }
+
+  free(a);
+  free(output);
+  HIPCHECK(hipStreamDestroy(stream1));
+  HIPCHECK(hipStreamDestroy(stream2));
+  printf("PASSED\n");
+
+  return EXIT_SUCCESS;
+}
+
+int main(int argc, char **argv) {
+  int ret = memPoolP2PCopy();
+  return ret;
+}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.out b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.out
index a14f0e8..fc9e176 100755
Binary files a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.out and b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.out differ
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2017.vcxproj
index d0c09b3..5ad486f 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/streamOrderedAllocationP2P.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2019.vcxproj
index 603d556..a7248a6 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/streamOrderedAllocationP2P.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2022.vcxproj
index 893e795..0ea7214 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/streamOrderedAllocationP2P.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/Makefile
index e6dd4ab..37b8a9b 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/NsightEclipse.xml
index 8b5d318..8436fef 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/NsightEclipse.xml
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/NsightEclipse.xml
@@ -35,6 +35,8 @@
     <scope>1:Data-Parallel Algorithms</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/README.md b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/README.md
index 33ccd4b..0156a5f 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/README.md
@@ -10,7 +10,7 @@ Cooperative Groups, Data-Parallel Algorithms, Performance Strategies
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaFree, cudaDeviceSynchronize, cudaMalloc, cudaGetDeviceProperties
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.cu.hip
index 51bfcfd..5dc70aa 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.cu.hip
@@ -64,22 +64,20 @@
 // includes, system
 #include <stdlib.h>
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <string.h>
 #include <math.h>
-
+#include "HIPCHECK.h"
 // includes, project
-#include "helper_functions.h"
+#include "hip/hip_runtime.h"
 #include "helper_cuda_hipified.h"
-
+#include "helper_functions.h"
 #define VERSION_MAJOR (CUDART_VERSION / 1000)
 #define VERSION_MINOR (CUDART_VERSION % 100) / 10
-
 const char *sSDKsample = "threadFenceReduction";
 
 #if CUDART_VERSION >= 2020
-#include "threadFenceReduction_kernel.cuh"
+#include "threadFenceReduction_kernel_hipified.cuh"
+#include "threadFenceReduction_hipified.h"
 #else
 #pragma comment(user, "CUDA 2.2 is required to build for threadFenceReduction")
 #endif
@@ -128,7 +126,7 @@ int main(int argc, char **argv) {
 #if CUDART_VERSION >= 2020
   bTestResult = runTest(argc, argv);
 #else
-  print_NVCC_min_spec(sSDKsample, "2.2", "Version 185");
+  //print_NVCC_min_spec(sSDKsample, "2.2", "Version 185");
   exit(EXIT_SUCCESS);
 #endif
 
@@ -201,7 +199,7 @@ float benchmarkReduce(int n, int numThreads, int numBlocks, int maxThreads,
   for (int i = 0; i < testIterations; ++i) {
     gpu_result = 0;
     unsigned int retCnt = 0;
-    error = setRetirementCount(retCnt);
+    //error = setRetirementCount(retCnt);
     HIPCHECK(error);
 
     hipDeviceSynchronize();
@@ -465,7 +463,3 @@ bool runTest(int argc, char **argv) {
 
   return bTestResult;
 }
-   free(h_odata);
-    hipFree(d_idata);
-    hipFree(d_odata);
-  }
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.out b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.out
index 498ed08..d4e124e 100755
Binary files a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.out and b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.out differ
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2017.vcxproj
index f017829..0d54705 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/threadFenceReduction.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2019.vcxproj
index 9689845..ca4df79 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/threadFenceReduction.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2022.vcxproj
index 4660e57..2e5fa2f 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/threadFenceReduction.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/Makefile
index 163b5f5..6c4d542 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/Makefile
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/Makefile
@@ -285,7 +285,7 @@ FATBIN_FILE := threadMigration_kernel${TARGET_SIZE}.fatbin
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(GENCODE_FLAGS),)
@@ -297,8 +297,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/README.md b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/README.md
index 044ee5b..801305c 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/README.md
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/README.md
@@ -10,7 +10,7 @@ CUDA Driver API
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cuMemcpyDtoH, cuLaunchKernel, cuModuleLoadData, cuDeviceGetName, cuDeviceGet, cu
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration.out b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration.out
deleted file mode 100755
index 12b9aed..0000000
Binary files a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration.out and /dev/null differ
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_hipified.cpp
index 29c237c..1d1a4b8 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_hipified.cpp
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_hipified.cpp
@@ -41,7 +41,7 @@
 
 #define MAXTHREADS 256
 #define NUM_INTS 32
-#include "HIPCHECK.h"
+
 #if defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64)
 // Windows threads use different data structures
 #include <windows.h>
@@ -73,7 +73,7 @@ pthread_mutex_t g_mutex;
 
 #include <iostream>
 #include <cstring>
-
+#include "HIPCHECK.h"
 using namespace std;
 
 int NumThreads;
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_kernel.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_kernel.cu.hip
index e69de29..42cc050 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_kernel.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_kernel.cu.hip
@@ -0,0 +1,31 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+extern "C" __global__ void kernelFunction(int *input) {
+  input[threadIdx.x] = 32 - threadIdx.x;
+}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2017.vcxproj
index 3e11c99..ba53a46 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2017.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/threadMigration.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2019.vcxproj
index a7cc75e..6f0f8a9 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2019.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/threadMigration.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2022.vcxproj
index 2717a46..b81a2b0 100755
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2022.vcxproj
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/threadMigration.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/StreamPriorities/Makefile b/src/samples/Samples/3_CUDA_Features/StreamPriorities/Makefile
index 6a4f786..6faeb19 100755
--- a/src/samples/Samples/3_CUDA_Features/StreamPriorities/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/StreamPriorities/Makefile
@@ -299,7 +299,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/3_CUDA_Features/StreamPriorities/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/StreamPriorities/NsightEclipse.xml
index af5d526..0cb59d5 100755
--- a/src/samples/Samples/3_CUDA_Features/StreamPriorities/NsightEclipse.xml
+++ b/src/samples/Samples/3_CUDA_Features/StreamPriorities/NsightEclipse.xml
@@ -41,6 +41,20 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>1:Streams</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/3_CUDA_Features/StreamPriorities/README.md b/src/samples/Samples/3_CUDA_Features/StreamPriorities/README.md
index c162a2b..0b616b4 100755
--- a/src/samples/Samples/3_CUDA_Features/StreamPriorities/README.md
+++ b/src/samples/Samples/3_CUDA_Features/StreamPriorities/README.md
@@ -10,6 +10,8 @@ CUDA Streams and Events
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux
@@ -28,7 +30,7 @@ cudaMemcpy, cudaStreamCreateWithPriority, cudaDeviceGetStreamPriorityRange, cuda
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.cu.hip b/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.cu.hip
index 2736b81..b5d40ee 100755
--- a/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -28,11 +27,11 @@
 
 // std::system includes
 #include <cstdio>
-#include "HIPCHECK.h"
+
 // CUDA-C includes
 #include <hip/hip_runtime.h>
 
-#include "helper_cuda_hipified.h"
+
 
 #define TOTAL_SIZE 256 * 1024 * 1024
 #define EACH_SIZE 128 * 1024 * 1024
@@ -40,7 +39,9 @@
 // # threadblocks
 #define TBLOCKS 1024
 #define THREADS 512
-
+#include "HIPCHECK.h"
+#include "helper_cuda_hipified.h"
+#include "helper_functions.h"
 // throw error on equality
 #define ERR_EQ(X, Y)                                                           \
   do {                                                                         \
diff --git a/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.out b/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.out
index fdb4ce8..985bcf1 100755
Binary files a/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.out and b/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.out differ
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/README.md b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/README.md
index d798998..30f4eec 100755
--- a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/README.md
+++ b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/README.md
@@ -30,7 +30,7 @@ cudaMemcpy, cudaFree, cudaGetErrorString, cudaGetLastError, cudaEventSynchronize
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm.cu.hip b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm.cu.hip
index 5719083..51910f1 100755
--- a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm.cu.hip
@@ -171,12 +171,12 @@
 
 enum kernels
 {
-    bf16mma_shmem_gemm_async_copy  = 0, // __nv_bfloat16 MMA shmem using kernel with async_copy
+    bf16mma_shmem_gemm_async_copy  = 0, // __nv_bfloat16 MMA shmem using kernel with async_copy 
     bf16mma_shmem_gemm             = 1, // __nv_bfloat16 MMA shmem using kernel normal copy (without async_copy).
     simple_bf16mma_gemm            = 2  // __nv_bfloat16 MMA non-shmem using simple kernel.
 };
 
-const char* kernelNames[] = {"compute_bf16gemm_async_copy", "compute_bf16gemm",
+const char* kernelNames[] = {"compute_bf16gemm_async_copy", "compute_bf16gemm", 
                             "simple_wmma_bf16gemm"};
 
 using namespace nvcuda;
@@ -242,7 +242,7 @@ __global__ void compute_bf16gemm(const __nv_bfloat16 *A, const __nv_bfloat16 *B,
         // Stream multiple C tiles to shared memory.
 #pragma unroll
         for (int i = 0; i < N; i++) {
-            *((int4*)(shmem_warp_stream_ptr + SHMEM_STRIDE * i) + laneId) =
+            *((int4*)(shmem_warp_stream_ptr + SHMEM_STRIDE * i) + laneId) = 
                 *((int4*)(src_gmem_warp_stream_ptr + GLOBAL_MEM_STRIDE * i) + laneId);
         }
 
@@ -287,7 +287,7 @@ __global__ void compute_bf16gemm(const __nv_bfloat16 *A, const __nv_bfloat16 *B,
         for (int tile_k = 0; tile_k < K_TILES; tile_k += CHUNK_K) {
             // Copy slices of the A and B matrices to shared memory.
             // The first half of the warps in the CTA copy the A matrix, the rest copy the B matrix.
-            size_t shmem_idx = warpId < (WARPS_PER_BLOCK/2) ? (M * (warpId % (WARPS_PER_BLOCK/2)) * 2) :
+            size_t shmem_idx = warpId < (WARPS_PER_BLOCK/2) ? (M * (warpId % (WARPS_PER_BLOCK/2)) * 2) : 
                                                               (N * (warpId % (WARPS_PER_BLOCK/2)) * 2 + shmem_idx_b_off);
 
             // First half of the warp copies the first row / column of the matrix,
@@ -563,7 +563,7 @@ __global__ void compute_bf16gemm_async_copy(const __nv_bfloat16 *A, const __nv_b
 
 // Performs an MxNxK bf16 GEMM (C=alpha*A*B + beta*C) assuming:
 //  1) Matrices are packed in memory.
-//  2) M, N and K are multiples of 16, 16 and 16 respectively.
+//  2) M, N and K are multiples of 16, 16 and 16 respectively. 
 //  3) A is row major, B is column major matrix.
 // Note: This is a less performant version of the compute_bf16gemm kernel. It is designed for
 //       demonstration purposes only to show the CUDA WMMA API use without relying on
@@ -579,7 +579,7 @@ __global__ void simple_wmma_bf16gemm(__nv_bfloat16 *a, __nv_bfloat16 *b, float *
    // Tile using a 2D grid
    int warpM = (blockIdx.x * blockDim.x + threadIdx.x) / warpSize;
    int warpN = (blockIdx.y * blockDim.y + threadIdx.y);
-
+ 
    // Declare the fragments
    wmma::fragment<wmma::matrix_a, M, N, K, __nv_bfloat16, wmma::row_major> a_frag;
    wmma::fragment<wmma::matrix_b, M, N, K, __nv_bfloat16, wmma::col_major> b_frag;
@@ -590,7 +590,7 @@ __global__ void simple_wmma_bf16gemm(__nv_bfloat16 *a, __nv_bfloat16 *b, float *
 
    // Loop over k
    for (int i = 0; i < k_ld; i += K) {
-      int aCol = i;
+      int aCol = i; 
       int aRow = warpM * M;
 
       int bCol = i;
@@ -601,7 +601,7 @@ __global__ void simple_wmma_bf16gemm(__nv_bfloat16 *a, __nv_bfloat16 *b, float *
          // Load the inputs
          wmma::load_matrix_sync(a_frag, a + aCol + aRow * lda, lda);
          wmma::load_matrix_sync(b_frag, b + bRow + bCol * ldb, ldb);
-
+ 
          // Perform the matrix multiplication
          wmma::mma_sync(acc_frag, a_frag, b_frag, acc_frag);
 
@@ -651,7 +651,7 @@ int main(int argc, char **argv)
     int dev = findCudaDevice(argc, (const char **)argv);
 
     hipDeviceProp_t deviceProp;
-    checkCudaErrors(hipGetDeviceProperties(&deviceProp, dev));
+    HIPCHECK(hipGetDeviceProperties(&deviceProp, dev));
 
     // Tensor cores require a GPU of Volta (SM8X) architecture or higher.
     if (deviceProp.major < 8) {
@@ -684,10 +684,10 @@ int main(int argc, char **argv)
     float *C = NULL;
     float *D = NULL;
 
-    checkCudaErrors(hipMalloc((void**)&A, sizeof(__nv_bfloat16) * M_GLOBAL * K_GLOBAL));
-    checkCudaErrors(hipMalloc((void**)&B, sizeof(__nv_bfloat16) * N_GLOBAL * K_GLOBAL));
-    checkCudaErrors(hipMalloc((void**)&C, sizeof(float) * M_GLOBAL * N_GLOBAL));
-    checkCudaErrors(hipMalloc((void**)&D, sizeof(float) * M_GLOBAL * N_GLOBAL));
+    HIPCHECK(hipMalloc((void**)&A, sizeof(__nv_bfloat16) * M_GLOBAL * K_GLOBAL));
+    HIPCHECK(hipMalloc((void**)&B, sizeof(__nv_bfloat16) * N_GLOBAL * K_GLOBAL));
+    HIPCHECK(hipMalloc((void**)&C, sizeof(float) * M_GLOBAL * N_GLOBAL));
+    HIPCHECK(hipMalloc((void**)&D, sizeof(float) * M_GLOBAL * N_GLOBAL));
 
     assert(((unsigned long long)A) % 128 == 0);
     assert(((unsigned long long)B) % 128 == 0);
@@ -698,10 +698,10 @@ int main(int argc, char **argv)
 
     printf("Preparing data for GPU...\n");
 
-    checkCudaErrors(hipMemcpy(A, A_h, sizeof(__nv_bfloat16) * M_GLOBAL * K_GLOBAL, hipMemcpyHostToDevice));
-    checkCudaErrors(hipMemcpy(B, B_h, sizeof(__nv_bfloat16) * N_GLOBAL * K_GLOBAL, hipMemcpyHostToDevice));
-    checkCudaErrors(hipMemcpy(C, C_h, sizeof(float) * M_GLOBAL * N_GLOBAL, hipMemcpyHostToDevice));
-    checkCudaErrors(hipMemset(D, 0, sizeof(float) * M_GLOBAL * N_GLOBAL));
+    HIPCHECK(hipMemcpy(A, A_h, sizeof(__nv_bfloat16) * M_GLOBAL * K_GLOBAL, hipMemcpyHostToDevice));
+    HIPCHECK(hipMemcpy(B, B_h, sizeof(__nv_bfloat16) * N_GLOBAL * K_GLOBAL, hipMemcpyHostToDevice));
+    HIPCHECK(hipMemcpy(C, C_h, sizeof(float) * M_GLOBAL * N_GLOBAL, hipMemcpyHostToDevice));
+    HIPCHECK(hipMemset(D, 0, sizeof(float) * M_GLOBAL * N_GLOBAL));
 
     enum {
         // Compute the right amount of shared memory to request.
@@ -719,9 +719,9 @@ int main(int argc, char **argv)
 
     hipEvent_t start, stop;
 
-    checkCudaErrors(hipEventCreate(&start));
-    checkCudaErrors(hipEventCreate(&stop));
-    checkCudaErrors(hipEventRecord(start));
+    HIPCHECK(hipEventCreate(&start));    
+    HIPCHECK(hipEventCreate(&stop));
+    HIPCHECK(hipEventRecord(start));
 
     // kernel to run - default (b16mma_shmem_gemm_async_copy == 0)
     kernels selected_kernel = bf16mma_shmem_gemm_async_copy;
@@ -745,22 +745,22 @@ int main(int argc, char **argv)
         {
             case bf16mma_shmem_gemm_async_copy :
             default:
-                checkCudaErrors(hipFuncSetAttribute(compute_bf16gemm_async_copy, hipFuncAttributeMaxDynamicSharedMemorySize, SHMEM_SZ));
+                HIPCHECK(hipFuncSetAttribute((const void *)compute_bf16gemm_async_copy, hipFuncAttributeMaxDynamicSharedMemorySize, SHMEM_SZ));
                 checkKernelErrors((compute_bf16gemm_async_copy<<<deviceProp.multiProcessorCount*2, THREADS_PER_BLOCK, SHMEM_SZ>>>(A, B, C, D, alpha, beta)));
                 break;
             case bf16mma_shmem_gemm :
-                checkCudaErrors(hipFuncSetAttribute(compute_bf16gemm, hipFuncAttributeMaxDynamicSharedMemorySize, SHMEM_SZ));
+                HIPCHECK(hipFuncSetAttribute((const void *)compute_bf16gemm, hipFuncAttributeMaxDynamicSharedMemorySize, SHMEM_SZ));
                 checkKernelErrors((compute_bf16gemm<<<deviceProp.multiProcessorCount*2, THREADS_PER_BLOCK, SHMEM_SZ>>>(A, B, C, D, alpha, beta)));
                 break;
         }
 #if CPU_DEBUG
-        checkCudaErrors(hipMemcpy(result_hD, D, sizeof(float)*M_GLOBAL*N_GLOBAL, hipMemcpyDeviceToHost));
+        HIPCHECK(hipMemcpy(result_hD, D, sizeof(float)*M_GLOBAL*N_GLOBAL, hipMemcpyDeviceToHost));
 #endif
     }
     else {
         dim3 gridDim;
         dim3 blockDim;
-
+     
         // blockDim.x must be a multple of warpSize
         // 128x4 means we have 16 warps and a block computes a 64x64 output tile
         blockDim.x = 128;
@@ -772,12 +772,12 @@ int main(int argc, char **argv)
         printf("Computing... using simple_wmma_gemm kernel\n");
         simple_wmma_bf16gemm<<<gridDim, blockDim>>>(A, B, C, D, M_GLOBAL, N_GLOBAL, K_GLOBAL, alpha, beta);
 #if CPU_DEBUG
-        checkCudaErrors(hipMemcpy(result_hD, D, sizeof(float) * M_GLOBAL * N_GLOBAL, hipMemcpyDeviceToHost));
+        HIPCHECK(hipMemcpy(result_hD, D, sizeof(float) * M_GLOBAL * N_GLOBAL, hipMemcpyDeviceToHost));
 #endif
     }
 
-    checkCudaErrors(hipEventRecord(stop));
-    checkCudaErrors(hipEventSynchronize(stop));
+    HIPCHECK(hipEventRecord(stop));
+    HIPCHECK(hipEventSynchronize(stop));
 
 #if CPU_DEBUG
     printf("Verifying correctness of the computations...\n");
@@ -801,7 +801,7 @@ int main(int argc, char **argv)
 
     float milliseconds = 0;
 
-    checkCudaErrors(hipEventElapsedTime(&milliseconds, start, stop));
+    HIPCHECK(hipEventElapsedTime(&milliseconds, start, stop));
 
     printf("Time: %f ms\n", milliseconds);
     printf("TFLOPS: %.2f\n", (((double)M_GLOBAL * N_GLOBAL * K_GLOBAL * 2)/(milliseconds/1000.)) / 1e12);
@@ -816,11 +816,4 @@ int main(int argc, char **argv)
 
     return 0;
 }
-ors(hipFree((void*)A));
-    checkCudaErrors(hipFree((void*)B));
-    checkCudaErrors(hipFree((void*)C));
-    checkCudaErrors(hipFree((void*)D));
-
-    return 0;
-}
 
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2017.vcxproj
index d40d204..b8cb9fb 100755
--- a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2019.vcxproj
index c723186..c2c1f92 100755
--- a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2022.vcxproj
index b331b74..774b45b 100755
--- a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/Makefile b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/Makefile
index b0c7912..ace0b3a 100755
--- a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/Makefile
@@ -312,7 +312,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/NsightEclipse.xml
index 6e571d9..9698221 100755
--- a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/NsightEclipse.xml
+++ b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/NsightEclipse.xml
@@ -41,6 +41,8 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/README.md b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/README.md
index b7e3ec8..d2c2968 100755
--- a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/README.md
+++ b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/README.md
@@ -10,7 +10,7 @@ Cooperative Groups
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaStreamCreateWithFlags, cudaFree, cudaMallocHost, cudaFreeHost, cudaStreamSyn
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2017.vcxproj
index 90b179d..be9569b 100755
--- a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/binaryPartitionCG.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2019.vcxproj
index 88b21d9..c3c2836 100755
--- a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/binaryPartitionCG.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2022.vcxproj
index b1b4007..594d4bd 100755
--- a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/binaryPartitionCG.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/Makefile b/src/samples/Samples/3_CUDA_Features/bindlessTexture/Makefile
index 6b64dcb..9e9c336 100755
--- a/src/samples/Samples/3_CUDA_Features/bindlessTexture/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/bindlessTexture/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/bindlessTexture/NsightEclipse.xml
index 5cd8348..25b63ad 100755
--- a/src/samples/Samples/3_CUDA_Features/bindlessTexture/NsightEclipse.xml
+++ b/src/samples/Samples/3_CUDA_Features/bindlessTexture/NsightEclipse.xml
@@ -72,6 +72,20 @@
     <scope>2:Graphics Interop</scope>
     <scope>2:Texture</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/README.md b/src/samples/Samples/3_CUDA_Features/bindlessTexture/README.md
index 322ca66..cf14ba1 100755
--- a/src/samples/Samples/3_CUDA_Features/bindlessTexture/README.md
+++ b/src/samples/Samples/3_CUDA_Features/bindlessTexture/README.md
@@ -10,6 +10,8 @@ Graphics Interop, Texture
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux, Windows
@@ -28,7 +30,7 @@ cudaMemcpy, cudaGetMipmappedArrayLevel, cudaGraphicsMapResources, cudaDestroySur
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2017.vcxproj
index abf59d3..bcc1990 100755
--- a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/bindlessTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -118,6 +118,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2019.vcxproj
index bb3da57..110d990 100755
--- a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/bindlessTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2022.vcxproj
index dc1e65b..f9bcc8a 100755
--- a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/bindlessTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/Makefile b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/Makefile
index 5325b39..5eab141 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/Makefile
@@ -312,7 +312,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 61 70 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/NsightEclipse.xml
index acd97e2..383410d 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/NsightEclipse.xml
+++ b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/NsightEclipse.xml
@@ -50,6 +50,20 @@
   <scopes>
     <scope>1:CUDA Advanced Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/README.md b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/README.md
index 0851241..1314b89 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/README.md
+++ b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/README.md
@@ -10,6 +10,8 @@ Cooperative Groups, CUDA Dynamic Parallelism
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux, Windows
@@ -28,7 +30,7 @@ cudaStreamCreateWithFlags, cudaMemcpy, cudaMemcpyAsync, cudaFree, cudaGetErrorSt
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2017.vcxproj
index 3c3c778..5c76d1c 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/cdpAdvancedQuicksort.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2019.vcxproj
index f59db33..4779bb5 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cdpAdvancedQuicksort.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2022.vcxproj
index c10b191..39da540 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cdpAdvancedQuicksort.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/BezierLineCDP.cu.hip b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/BezierLineCDP.cu.hip
index e69de29..295d9d4 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/BezierLineCDP.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/BezierLineCDP.cu.hip
@@ -0,0 +1,208 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <stdio.h>
+#include <hip/hip_runtime_api.h>
+#include <helper_cuda.h>
+#include <string.h>
+#include "HIPCHECK.h"
+__forceinline__ __device__ float2 operator+(float2 a, float2 b) {
+  float2 c;
+  c.x = a.x + b.x;
+  c.y = a.y + b.y;
+  return c;
+}
+
+__forceinline__ __device__ float2 operator-(float2 a, float2 b) {
+  float2 c;
+  c.x = a.x - b.x;
+  c.y = a.y - b.y;
+  return c;
+}
+
+__forceinline__ __device__ float2 operator*(float a, float2 b) {
+  float2 c;
+  c.x = a * b.x;
+  c.y = a * b.y;
+  return c;
+}
+
+__forceinline__ __device__ float length(float2 a) {
+  return sqrtf(a.x * a.x + a.y * a.y);
+}
+
+#define MAX_TESSELLATION 32
+struct BezierLine {
+  float2 CP[3];
+  float2 *vertexPos;
+  int nVertices;
+};
+
+__global__ void computeBezierLinePositions(int lidx, BezierLine *bLines,
+                                           int nTessPoints) {
+  int idx = threadIdx.x + blockDim.x * blockIdx.x;
+
+  if (idx < nTessPoints) {
+    float u = (float)idx / (float)(nTessPoints - 1);
+    float omu = 1.0f - u;
+
+    float B3u[3];
+
+    B3u[0] = omu * omu;
+    B3u[1] = 2.0f * u * omu;
+    B3u[2] = u * u;
+
+    float2 position = {0, 0};
+
+    for (int i = 0; i < 3; i++) {
+      position = position + B3u[i] * bLines[lidx].CP[i];
+    }
+
+    bLines[lidx].vertexPos[idx] = position;
+  }
+}
+
+__global__ void computeBezierLinesCDP(BezierLine *bLines, int nLines) {
+  int lidx = threadIdx.x + blockDim.x * blockIdx.x;
+
+  if (lidx < nLines) {
+    float curvature = length(bLines[lidx].CP[1] -
+                             0.5f * (bLines[lidx].CP[0] + bLines[lidx].CP[2])) /
+                      length(bLines[lidx].CP[2] - bLines[lidx].CP[0]);
+    int nTessPoints = min(max((int)(curvature * 16.0f), 4), MAX_TESSELLATION);
+
+    if (bLines[lidx].vertexPos == NULL) {
+      bLines[lidx].nVertices = nTessPoints;
+      hipMalloc((void **)&bLines[lidx].vertexPos,
+                 nTessPoints * sizeof(float2));
+    }
+
+    computeBezierLinePositions<<<ceilf((float)bLines[lidx].nVertices / 32.0f),
+                                 32>>>(lidx, bLines, bLines[lidx].nVertices);
+  }
+}
+
+__global__ void freeVertexMem(BezierLine *bLines, int nLines) {
+  int lidx = threadIdx.x + blockDim.x * blockIdx.x;
+
+  if (lidx < nLines) hipFree(bLines[lidx].vertexPos);
+}
+
+unsigned int checkCapableSM35Device(int argc, char **argv) {
+  // Get device properties
+  hipDeviceProp_t properties;
+  int device_count = 0, device = -1;
+
+  if (checkCmdLineFlag(argc, (const char **)argv, "device")) {
+    device = getCmdLineArgumentInt(argc, (const char **)argv, "device");
+
+    hipDeviceProp_t properties;
+    HIPCHECK(hipGetDeviceProperties(&properties, device));
+
+    if (properties.major > 3 ||
+        (properties.major == 3 && properties.minor >= 5)) {
+      printf("Running on GPU  %d (%s)\n", device, properties.name);
+    } else {
+      printf(
+          "cdpBezierTessellation requires GPU devices with compute SM 3.5 or "
+          "higher.");
+      printf("Current GPU device has compute SM %d.%d. Exiting...\n",
+             properties.major, properties.minor);
+      return EXIT_FAILURE;
+    }
+
+  } else {
+    HIPCHECK(hipGetDeviceCount(&device_count));
+
+    for (int i = 0; i < device_count; ++i) {
+      HIPCHECK(hipGetDeviceProperties(&properties, i));
+
+      if (properties.major > 3 ||
+          (properties.major == 3 && properties.minor >= 5)) {
+        device = i;
+        printf("Running on GPU %d (%s)\n", i, properties.name);
+        break;
+      }
+
+      printf("GPU %d %s does not support CUDA Dynamic Parallelism\n", i,
+             properties.name);
+    }
+  }
+  if (device == -1) {
+    fprintf(stderr,
+            "cdpBezierTessellation requires GPU devices with compute SM 3.5 or "
+            "higher.  Exiting...\n");
+    return EXIT_WAIVED;
+  }
+
+  return EXIT_SUCCESS;
+}
+
+#define N_LINES 256
+#define BLOCK_DIM 64
+int main(int argc, char **argv) {
+  BezierLine *bLines_h = new BezierLine[N_LINES];
+
+  float2 last = {0, 0};
+
+  for (int i = 0; i < N_LINES; i++) {
+    bLines_h[i].CP[0] = last;
+
+    for (int j = 1; j < 3; j++) {
+      bLines_h[i].CP[j].x = (float)rand() / (float)RAND_MAX;
+      bLines_h[i].CP[j].y = (float)rand() / (float)RAND_MAX;
+    }
+
+    last = bLines_h[i].CP[2];
+    bLines_h[i].vertexPos = NULL;
+    bLines_h[i].nVertices = 0;
+  }
+
+  unsigned int sm35Ret = checkCapableSM35Device(argc, argv);
+  if (sm35Ret != EXIT_SUCCESS) {
+    exit(sm35Ret);
+  }
+
+  BezierLine *bLines_d;
+  HIPCHECK(hipMalloc((void **)&bLines_d, N_LINES * sizeof(BezierLine)));
+  HIPCHECK(hipMemcpy(bLines_d, bLines_h, N_LINES * sizeof(BezierLine),
+                             hipMemcpyHostToDevice));
+  printf("Computing Bezier Lines (CUDA Dynamic Parallelism Version) ... ");
+  computeBezierLinesCDP<<<(unsigned int)ceil((float)N_LINES / (float)BLOCK_DIM),
+                          BLOCK_DIM>>>(bLines_d, N_LINES);
+  printf("Done!\n");
+
+  // Do something to draw the lines here
+
+  freeVertexMem<<<(unsigned int)ceil((float)N_LINES / (float)BLOCK_DIM),
+                  BLOCK_DIM>>>(bLines_d, N_LINES);
+  HIPCHECK(hipFree(bLines_d));
+  delete[] bLines_h;
+
+  exit(EXIT_SUCCESS);
+}
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/Makefile b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/Makefile
index af3659e..23ef29e 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/Makefile
@@ -287,7 +287,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 61 70 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/NsightEclipse.xml
index 2984dbf..26392f7 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/NsightEclipse.xml
+++ b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/NsightEclipse.xml
@@ -37,6 +37,20 @@
   <scopes>
     <scope>1:CUDA Advanced Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/README.md b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/README.md
index 785510b..bb2d6e6 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/README.md
+++ b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/README.md
@@ -10,6 +10,8 @@ CUDA Dynamic Parallelism
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux, Windows
@@ -28,7 +30,7 @@ cudaMemcpy, cudaFree, cudaGetDeviceCount, cudaMalloc, cudaGetDeviceProperties
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2017.vcxproj
index 1f4b957..e7733bf 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/cdpBezierTessellation.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2019.vcxproj
index 1aa4266..aa2fefe 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cdpBezierTessellation.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2022.vcxproj
index 8e28315..577c5e1 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cdpBezierTessellation.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/Makefile b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/Makefile
index ea0a7b4..9b4e08f 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/Makefile
@@ -312,7 +312,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 61 70 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/NsightEclipse.xml
index f041b46..6d867f7 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/NsightEclipse.xml
+++ b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/NsightEclipse.xml
@@ -41,6 +41,20 @@
   <scopes>
     <scope>1:CUDA Advanced Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/README.md b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/README.md
index 6bcc0f3..dc96c3c 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/README.md
+++ b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/README.md
@@ -10,6 +10,8 @@ Cooperative Groups, CUDA Dynamic Parallelism
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux, Windows
@@ -28,7 +30,7 @@ cudaMemcpy, cudaFree, cudaGetLastError, cudaDeviceSetLimit, cudaMalloc, cudaGetD
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu
index 06fbddb..60018a8 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu
+++ b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu
@@ -673,6 +673,9 @@ bool cdpQuadtree(int warp_size) {
   checkCudaErrors(
       cudaMemcpy(nodes, &root, sizeof(Quadtree_node), cudaMemcpyHostToDevice));
 
+  // We set the recursion limit for CDP to max_depth.
+  cudaDeviceSetLimit(cudaLimitDevRuntimeSyncDepth, max_depth);
+
   // Build the quadtree.
   Parameters params(max_depth, min_points_per_node);
   std::cout << "Launching CDP kernel to build the quadtree" << std::endl;
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu.hip b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu.hip
index a4ffd7e..f83b6d2 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu.hip
@@ -32,7 +32,7 @@
 #include <hip/hip_cooperative_groups.h>
 
 namespace cg = cooperative_groups;
-#include <helper_cuda.h>
+#include "helper_cuda_hipified.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 // A structure of 2D points (structure of arrays).
@@ -654,8 +654,8 @@ bool cdpQuadtree(int warp_size) {
 
   // Allocate memory to store points.
   Points *points;
-  checkCudaErrors(hipMalloc((void **)&points, 2 * sizeof(Points)));
-  checkCudaErrors(hipMemcpy(points, points_init, 2 * sizeof(Points),
+  HIPCHECK(hipMalloc((void **)&points, 2 * sizeof(Points)));
+  HIPCHECK(hipMemcpy(points, points_init, 2 * sizeof(Points),
                              hipMemcpyHostToDevice));
 
   // We could use a close form...
@@ -669,9 +669,9 @@ bool cdpQuadtree(int warp_size) {
   Quadtree_node root;
   root.set_range(0, num_points);
   Quadtree_node *nodes;
-  checkCudaErrors(
+  HIPCHECK(
       hipMalloc((void **)&nodes, max_nodes * sizeof(Quadtree_node)));
-  checkCudaErrors(
+  HIPCHECK(
       hipMemcpy(nodes, &root, sizeof(Quadtree_node), hipMemcpyHostToDevice));
 
   // We set the recursion limit for CDP to max_depth.
@@ -686,7 +686,7 @@ bool cdpQuadtree(int warp_size) {
   build_quadtree_kernel<
       NUM_THREADS_PER_BLOCK><<<1, NUM_THREADS_PER_BLOCK, smem_size>>>(
       nodes, points, params);
-  checkCudaErrors(hipGetLastError());
+  HIPCHECK(hipGetLastError());
 
   // Copy points to CPU.
   thrust::host_vector<float> x_h(x_d0);
@@ -697,7 +697,7 @@ bool cdpQuadtree(int warp_size) {
 
   // Copy nodes to CPU.
   Quadtree_node *host_nodes = new Quadtree_node[max_nodes];
-  checkCudaErrors(hipMemcpy(host_nodes, nodes,
+  HIPCHECK(hipMemcpy(host_nodes, nodes,
                              max_nodes * sizeof(Quadtree_node),
                              hipMemcpyDeviceToHost));
 
@@ -709,8 +709,8 @@ bool cdpQuadtree(int warp_size) {
   delete[] host_nodes;
 
   // Free memory.
-  checkCudaErrors(hipFree(nodes));
-  checkCudaErrors(hipFree(points));
+  HIPCHECK(hipFree(nodes));
+  HIPCHECK(hipFree(points));
 
   return ok;
 }
@@ -723,7 +723,7 @@ int main(int argc, char **argv) {
   // The test requires an architecture SM35 or greater (CDP capable).
   int cuda_device = findCudaDevice(argc, (const char **)argv);
   hipDeviceProp_t deviceProps;
-  checkCudaErrors(hipGetDeviceProperties(&deviceProps, cuda_device));
+  HIPCHECK(hipGetDeviceProperties(&deviceProps, cuda_device));
   int cdpCapable = (deviceProps.major == 3 && deviceProps.minor >= 5) ||
                    deviceProps.major >= 4;
 
@@ -745,11 +745,3 @@ ops.warpSize);
 
   return (ok ? EXIT_SUCCESS : EXIT_FAILURE);
 }
-ops.warpSize);
-
-  return (ok ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-ops.warpSize);
-
-  return (ok ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2017.vcxproj
index 85dd77f..15110cd 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/cdpQuadtree.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2019.vcxproj
index b5c6aae..3ec1b13 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cdpQuadtree.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2022.vcxproj
index e23bc84..181408c 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cdpQuadtree.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/Makefile b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/Makefile
index 22f105e..1ea6442 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/Makefile
@@ -287,7 +287,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 61 70 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/NsightEclipse.xml
index 3a6c271..cfe32d1 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/NsightEclipse.xml
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/NsightEclipse.xml
@@ -38,6 +38,20 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/README.md b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/README.md
index 839776a..c872f4b 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/README.md
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/README.md
@@ -10,6 +10,8 @@ CUDA Dynamic Parallelism
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux, Windows
@@ -28,7 +30,7 @@ cudaDeviceSynchronize, cudaGetLastError, cudaGetDeviceProperties, cudaDeviceSetL
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu
index 3f401d1..f4acf13 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu
@@ -157,6 +157,9 @@ int main(int argc, char **argv) {
       "************************************************************************"
       "***\n\n");
 
+  // We set the recursion limit for CDP to max_depth.
+  cudaDeviceSetLimit(cudaLimitDevRuntimeSyncDepth, max_depth);
+
   // Launch the kernel from the CPU.
   printf("Launching cdp_kernel() with CUDA Dynamic Parallelism:\n\n");
   cdp_kernel<<<2, 2>>>(max_depth, 0, 0, -1);
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu.hip b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu.hip
index 249d861..b0e6e0f 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu.hip
@@ -124,7 +124,7 @@ int main(int argc, char **argv) {
   int device = -1;
   hipDeviceProp_t deviceProp;
   device = findCudaDevice(argc, (const char **)argv);
-  checkCudaErrors(hipGetDeviceProperties(&deviceProp, device));
+  HIPCHECK(hipGetDeviceProperties(&deviceProp, device));
 
   if (!(deviceProp.major > 3 ||
         (deviceProp.major == 3 && deviceProp.minor >= 5))) {
@@ -158,6 +158,9 @@ int main(int argc, char **argv) {
       "************************************************************************"
       "***\n\n");
 
+  // We set the recursion limit for CDP to max_depth.
+  hipDeviceSetLimit(cudaLimitDevRuntimeSyncDepth, max_depth);
+
   // Launch the kernel from the CPU.
   printf("Launching cdp_kernel() with CUDA Dynamic Parallelism:\n\n");
   cdp_kernel<<<2, 2>>>(max_depth, 0, 0, -1);
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2017.vcxproj
index 7a6d9b8..b261348 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/cdpSimplePrint.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2019.vcxproj
index 4d84301..ae105c0 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cdpSimplePrint.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2022.vcxproj
index 1dcb5cd..7f1b73f 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cdpSimplePrint.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/Makefile b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/Makefile
index 330faa0..1bf519d 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/Makefile
@@ -287,7 +287,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 61 70 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/NsightEclipse.xml
index 4dea0b9..9c19608 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/NsightEclipse.xml
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/NsightEclipse.xml
@@ -42,6 +42,20 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/README.md b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/README.md
index 452eee2..5a765c0 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/README.md
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/README.md
@@ -10,6 +10,8 @@ CUDA Dynamic Parallelism
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux, Windows
@@ -28,7 +30,7 @@ cudaStreamCreateWithFlags, cudaMemcpy, cudaStreamDestroy, cudaFree, cudaDeviceSy
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu
index 0334c0f..baac871 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu
@@ -129,6 +129,7 @@ __global__ void cdp_simple_quicksort(unsigned int *data, int left, int right,
 ////////////////////////////////////////////////////////////////////////////////
 void run_qsort(unsigned int *data, unsigned int nitems) {
   // Prepare CDP for the max depth 'MAX_DEPTH'.
+  checkCudaErrors(cudaDeviceSetLimit(cudaLimitDevRuntimeSyncDepth, MAX_DEPTH));
 
   // Launch on device
   int left = 0;
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu.hip b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu.hip
index e11adb9..22268b9 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu.hip
@@ -130,6 +130,7 @@ __global__ void cdp_simple_quicksort(unsigned int *data, int left, int right,
 ////////////////////////////////////////////////////////////////////////////////
 void run_qsort(unsigned int *data, unsigned int nitems) {
   // Prepare CDP for the max depth 'MAX_DEPTH'.
+  HIPCHECK(hipDeviceSetLimit(cudaLimitDevRuntimeSyncDepth, MAX_DEPTH));
 
   // Launch on device
   int left = 0;
@@ -244,7 +245,7 @@ int main(int argc, char **argv) {
 
   exit(EXIT_SUCCESS);
 }
-ipFree(d_data));
+rrors(hipFree(d_data));
 
   exit(EXIT_SUCCESS);
 }
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2017.vcxproj
index 54a149d..701ef7d 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/cdpSimpleQuicksort.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2019.vcxproj
index 1e78222..be79af0 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cdpSimpleQuicksort.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2022.vcxproj
index 31d1edb..601d665 100755
--- a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cdpSimpleQuicksort.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/Makefile b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/Makefile
index fa93fe5..9d7f9ad 100755
--- a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/Makefile
@@ -295,7 +295,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/README.md b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/README.md
index cfb8644..cd28b6f 100755
--- a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/README.md
+++ b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/README.md
@@ -10,7 +10,7 @@ CUDA Driver API, Compressible Memory, MMAP
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMemcpy, cudaEventSynchronize, cudaEventRecord, cudaEventElapsedTime, cudaOcc
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/compMalloc_hipified.cpp b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/compMalloc_hipified.cpp
index 1025437..cc0ad29 100755
--- a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/compMalloc_hipified.cpp
+++ b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/compMalloc_hipified.cpp
@@ -43,7 +43,7 @@ hipError_t setProp(hipMemAllocationProp *prop, bool UseCompressibleMemory)
     prop->location.id = currentDevice;
 
     if (UseCompressibleMemory)
-       // prop->allocFlags.compressionType = CU_MEM_ALLOCATION_COMP_GENERIC;
+        prop->allocFlags.compressionType = CU_MEM_ALLOCATION_COMP_GENERIC;
 
     return hipSuccess;
 }
@@ -72,10 +72,10 @@ hipError_t allocateCompressible(void **adr, size_t size, bool UseCompressibleMem
     if (UseCompressibleMemory) {
         hipMemAllocationProp allocationProp = {};
         hipMemGetAllocationPropertiesFromHandle(&allocationProp, allocationHandle);
-       // if (allocationProp.allocFlags.compressionType != CU_MEM_ALLOCATION_COMP_GENERIC) {
-       //     printf("Could not allocate compressible memory... so waiving execution\n");
-       //     exit(EXIT_WAIVED);
-       // }
+        if (allocationProp.allocFlags.compressionType != CU_MEM_ALLOCATION_COMP_GENERIC) {
+            printf("Could not allocate compressible memory... so waiving execution\n");
+            exit(EXIT_WAIVED);
+        }
     }
 
     if (hipMemMap(dptr, size, 0, allocationHandle, 0) != hipSuccess)
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2017.vcxproj
index f9b2be9..5fd82a2 100755
--- a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/cudaCompressibleMemory.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2019.vcxproj
index e3883b2..f013827 100755
--- a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cudaCompressibleMemory.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2022.vcxproj
index 136d919..5c5b989 100755
--- a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cudaCompressibleMemory.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/saxpy.cu.hip b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/saxpy.cu.hip
index d2da2fc..bba346f 100755
--- a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/saxpy.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/saxpy.cu.hip
@@ -1,4 +1,4 @@
-
+#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -33,8 +33,6 @@
 // compression.
 
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <hip/hip_runtime.h>
 #define CUDA_DRIVER_API
 #include "helper_cuda.h"
@@ -161,7 +159,7 @@ int main(int argc, char **argv)
     bool compressibleZbuf = 0;
     if ((major == 8 && minor == 0) || (major == 8 && minor == 6))
     {
-        // On SM 8.0 and 8.6 GPUs compressible buffer can only be initialized
+        // On SM 8.0 and 8.6 GPUs compressible buffer can only be initialized 
         // through hipMemcpy.
         printf("allocating non-compressible Z buffer\n");
         checkCudaErrors(allocateCompressible((void **)&z, size, false));
@@ -173,3 +171,29 @@ int main(int argc, char **argv)
         compressibleZbuf = 1;
     }
 
+    printf("Running saxpy on %zu bytes of Compressible memory\n", size);
+
+    const float a = 1.0f;
+    const float init_val = 1.0f;
+    launchSaxpy(a, x, y, z, n, init_val, compressibleZbuf);
+ 
+    checkCudaErrors(freeCompressible(x, size, true));
+    checkCudaErrors(freeCompressible(y, size, true));
+    checkCudaErrors(freeCompressible(z, size, true));
+
+    printf("Running saxpy on %zu bytes of Non-Compressible memory\n", size);
+    // Allocating non-compressible memory
+    checkCudaErrors(allocateCompressible((void **)&x, size, false));
+    checkCudaErrors(allocateCompressible((void **)&y, size, false));
+    checkCudaErrors(allocateCompressible((void **)&z, size, false));
+
+    launchSaxpy(a, x, y, z, n, init_val, compressibleZbuf);
+
+    checkCudaErrors(freeCompressible(x, size, false));
+    checkCudaErrors(freeCompressible(y, size, false));
+    checkCudaErrors(freeCompressible(z, size, false));
+
+    printf("\nNOTE: The CUDA Samples are not meant for performance measurements. "
+      "Results may vary when GPU Boost is enabled.\n");
+    return EXIT_SUCCESS;
+}
\ No newline at end of file
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/README.md b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/README.md
index 853c8f3..ed9ca03 100755
--- a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/README.md
+++ b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/README.md
@@ -31,7 +31,7 @@ cudaMemcpy, cudaFree, cudaGetErrorString, cudaGetLastError, cudaEventSynchronize
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm.cu.hip b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm.cu.hip
index 7eebfb0..345ac83 100755
--- a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm.cu.hip
@@ -63,13 +63,12 @@
 
 #include <assert.h>
 #include <hip/hip_runtime.h>
-//#include <mma.h>
-#include "rocwmma.hpp"
+#include <mma.h>
 #include <stdio.h>
 
 // helper functions and utilities to work with CUDA
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"
+#include <helper_cuda.h>
+#include <helper_functions.h>
 
 // Externally configurable parameters.
 
@@ -176,8 +175,8 @@
     }                                                       \
   } while (0)
 
-//using namespace nvcuda;
-using namespace rocwmma;
+using namespace nvcuda;
+
 __host__ void init_host_matrices(half *a, half *b, float *c) {
   for (int i = 0; i < M_GLOBAL; i++) {
     for (int j = 0; j < K_GLOBAL; j++) {
@@ -648,15 +647,3 @@ int main(int argc, char **argv) {
 
   return 0;
 }
-rpret_cast<void *>(B)));
-  checkCudaErrors(hipFree(reinterpret_cast<void *>(C)));
-  checkCudaErrors(hipFree(reinterpret_cast<void *>(D)));
-
-  return 0;
-}
-rpret_cast<void *>(B)));
-  checkCudaErrors(hipFree(reinterpret_cast<void *>(C)));
-  checkCudaErrors(hipFree(reinterpret_cast<void *>(D)));
-
-  return 0;
-}
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2017.vcxproj
index 034081e..a585470 100755
--- a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2019.vcxproj
index d787fbc..5a7700b 100755
--- a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2022.vcxproj
index 5275a19..3a4f102 100755
--- a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/README.md b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/README.md
index ba02ef9..8699aa2 100755
--- a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/README.md
+++ b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/README.md
@@ -30,7 +30,7 @@ cudaMemcpy, cudaFree, cudaGetErrorString, cudaGetLastError, cudaEventSynchronize
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm.cu.hip b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm.cu.hip
index 2cb5cc2..5895df3 100755
--- a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm.cu.hip
@@ -70,8 +70,8 @@
 #include <cuda/pipeline>
 
 // helper functions and utilities to work with CUDA
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
+#include <helper_functions.h>
+#include <helper_cuda.h>
 
 // Externally configurable parameters.
 
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2017.vcxproj
index d976c18..1dbcff5 100755
--- a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2019.vcxproj
index 9683627..0f024a2 100755
--- a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2022.vcxproj
index 9087b28..6dcc023 100755
--- a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/README.md b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/README.md
index a155870..a2d7d6a 100755
--- a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/README.md
+++ b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/README.md
@@ -30,7 +30,7 @@ cudaStreamCreateWithFlags, cudaMalloc, cudaDeviceGetAttribute, cudaFree, cudaMal
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy.cu.hip b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy.cu.hip
index e50044a..bfc7c82 100755
--- a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy.cu.hip
@@ -1070,17 +1070,3 @@ int main(int argc, char **argv) {
 
   exit(matrix_result);
 }
-rintf("MatrixA(%d,%d), MatrixB(%d,%d)\n", dimsA.x, dimsA.y, dimsB.x,
-         dimsB.y);
-
-  int matrix_result = MatrixMultiply(argc, argv, dimsA, dimsB, selected_kernel);
-
-  exit(matrix_result);
-}
-rintf("MatrixA(%d,%d), MatrixB(%d,%d)\n", dimsA.x, dimsA.y, dimsB.x,
-         dimsB.y);
-
-  int matrix_result = MatrixMultiply(argc, argv, dimsA, dimsB, selected_kernel);
-
-  exit(matrix_result);
-}
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2017.vcxproj
index 79e70a4..41bedad 100755
--- a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2019.vcxproj
index 119f0c2..7db3f23 100755
--- a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2022.vcxproj
index 265defc..5351130 100755
--- a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/Makefile b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/Makefile
index 7929526..0233718 100755
--- a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/Makefile
@@ -287,7 +287,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/README.md b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/README.md
index 14a4239..6286fa0 100755
--- a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/README.md
+++ b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/README.md
@@ -27,7 +27,7 @@ cudaGraphAddMemAllocNode, cudaStreamCreateWithFlags, cudaGraphInstantiate, cudaS
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2017.vcxproj
index 5ec7c79..e65d0b6 100755
--- a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/graphMemoryFootprint.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2019.vcxproj
index 848a81b..82b9814 100755
--- a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/graphMemoryFootprint.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2022.vcxproj
index 71c7e26..cbf3dd3 100755
--- a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/graphMemoryFootprint.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/Makefile b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/Makefile
index ee36847..b760fc4 100755
--- a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/Makefile
@@ -287,7 +287,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/README.md b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/README.md
index 0b28a34..7bf467a 100755
--- a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/README.md
+++ b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/README.md
@@ -27,7 +27,7 @@ cudaMemcpy, cudaDeviceGetAttribute, cudaDriverGetVersion, cudaGraphLaunch, cudaE
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes.cu.hip b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes.cu.hip
index e69de29..e1d90f4 100755
--- a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes.cu.hip
@@ -0,0 +1,555 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+// System includes
+#include <assert.h>
+#include <stdio.h>
+
+#include <climits>
+#include <vector>
+
+// CUDA runtime
+#include <hip/hip_runtime.h>
+
+// helper functions and utilities to work with CUDA
+#include <helper_cuda.h>
+#include <helper_functions.h>
+
+#define THREADS_PER_BLOCK 512
+#define ALLOWABLE_VARIANCE 1.e-6f
+#define NUM_ELEMENTS 8000000
+
+// Stores the square of each input element in output array
+__global__ void squareArray(const float *input, float *output,
+                            int numElements) {
+  int idx = blockIdx.x * blockDim.x + threadIdx.x;
+
+  if (idx < numElements) {
+    output[idx] = input[idx] * input[idx];
+  }
+}
+
+// Stores the negative of each input element in output array
+__global__ void negateArray(const float *input, float *output,
+                            int numElements) {
+  int idx = blockIdx.x * blockDim.x + threadIdx.x;
+
+  if (idx < numElements) {
+    output[idx] = input[idx] * -1;
+  }
+}
+
+struct negSquareArrays {
+  float *input;
+  float *square;
+  float *negSquare;
+  int numElements;
+  size_t bytes;
+  size_t numBlocks;
+};
+
+void fillRandomly(float *array, int numElements) {
+  for (int n = 0; n < numElements; n++) {
+    array[n] = rand() / (float)RAND_MAX;
+  }
+}
+
+void resetOutputArrays(negSquareArrays *hostArrays) {
+  fillRandomly(hostArrays->square, hostArrays->numElements);
+  fillRandomly(hostArrays->negSquare, hostArrays->numElements);
+}
+
+void prepareHostArrays(negSquareArrays *hostArrays) {
+  hostArrays->numElements = NUM_ELEMENTS;
+  size_t bytes = hostArrays->numElements * sizeof(float);
+
+  size_t numBlocks = hostArrays->numElements / (size_t)THREADS_PER_BLOCK;
+  if ((numBlocks % (size_t)THREADS_PER_BLOCK) != 0) {
+    numBlocks++;
+  }
+
+  hostArrays->input = (float *)malloc(bytes);
+  hostArrays->square = (float *)malloc(bytes);
+  hostArrays->negSquare = (float *)malloc(bytes);
+  hostArrays->bytes = bytes;
+  hostArrays->numBlocks = numBlocks;
+
+  fillRandomly(hostArrays->input, hostArrays->numElements);
+  fillRandomly(hostArrays->square, hostArrays->numElements);
+  fillRandomly(hostArrays->negSquare, hostArrays->numElements);
+}
+
+void createFreeGraph(hipGraphExec_t *graphExec, float *dPtr) {
+  hipGraph_t graph;
+  hipGraphNode_t freeNode;
+
+  checkCudaErrors(hipGraphCreate(&graph, 0));
+
+  checkCudaErrors(
+      cudaGraphAddMemFreeNode(&freeNode, graph, NULL, 0, (void *)dPtr));
+
+  checkCudaErrors(hipGraphInstantiate(graphExec, graph, NULL, NULL, 0));
+  checkCudaErrors(hipGraphDestroy(graph));
+}
+
+/**
+ * Demonstrates explicitly creating a CUDA graph including memory nodes.
+ * createNegateSquaresGraphWithStreamCapture constructs an equivalent graph
+ * using stream capture.
+ *
+ * If d_negSquare_out is non null, then:
+ * 1) d_negSquare will not be freed;
+ * 2) the value of d_negSquare_out will be set to d_negSquare.
+ *
+ * Diagram of the graph constructed by createNegateSquaresGraphExplicitly:
+ *
+ * alloc d_input
+ *       |
+ * alloc d_square
+ *       |
+ * Memcpy a to device
+ *       |
+ * launch kernel squareArray ------->---- Memcpy d_square to host
+ *       |                                      |
+ * free d_input                                 |
+ *       |                                      |
+ * allocate d_negSquare                         |
+ *       |                                      |
+ * launch kernel negateArray -------->--- free d_square
+ *       |
+ * Memcpy d_negSquare to host
+ *       |
+ * free d_negSquare
+ */
+void createNegateSquaresGraphExplicitly(hipGraphExec_t *graphExec, int device,
+                                        negSquareArrays *hostArrays,
+                                        float **d_negSquare_out = NULL) {
+  // Array buffers on device
+  float *d_input, *d_square, *d_negSquare;
+
+  // Memory allocation parameters
+  cudaMemAllocNodeParams allocParams;
+  memset(&allocParams, 0, sizeof(allocParams));
+  allocParams.bytesize = hostArrays->bytes;
+  allocParams.poolProps.allocType = hipMemAllocationTypePinned;
+  allocParams.poolProps.location.id = device;
+  allocParams.poolProps.location.type = hipMemLocationTypeDevice;
+
+  // Kernel launch parameters
+  hipKernelNodeParams kernelNodeParams = {0};
+  kernelNodeParams.gridDim = dim3(hostArrays->numBlocks, 1, 1);
+  kernelNodeParams.blockDim = dim3(THREADS_PER_BLOCK, 1, 1);
+  kernelNodeParams.sharedMemBytes = 0;
+  kernelNodeParams.extra = NULL;
+
+  hipGraph_t graph;
+  hipGraphNode_t allocNodeInput, allocNodeSquare, allocNodeNegSquare;
+  hipGraphNode_t copyNodeInput, copyNodeSquare, copyNodeNegSquare;
+  hipGraphNode_t squareKernelNode, negateKernelNode;
+  hipGraphNode_t freeNodeInput, freeNodeSquare;
+
+  // Buffer for storing graph node dependencies
+  std::vector<hipGraphNode_t> nodeDependencies;
+
+  checkCudaErrors(hipGraphCreate(&graph, 0));
+
+  checkCudaErrors(
+      cudaGraphAddMemAllocNode(&allocNodeInput, graph, NULL, 0, &allocParams));
+  d_input = (float *)allocParams.dptr;
+
+  // To keep the graph structure simple (fewer branching dependencies),
+  // allocNodeSquare should depend on allocNodeInput
+  checkCudaErrors(cudaGraphAddMemAllocNode(&allocNodeSquare, graph,
+                                           &allocNodeInput, 1, &allocParams));
+  d_square = (float *)allocParams.dptr;
+
+  // copyNodeInput needs to depend on allocNodeInput because copyNodeInput
+  // writes to d_input. It does so here indirectly through allocNodeSquare.
+  checkCudaErrors(hipGraphAddMemcpyNode1D(
+      &copyNodeInput, graph, &allocNodeSquare, 1, d_input, hostArrays->input,
+      hostArrays->bytes, hipMemcpyHostToDevice));
+
+  void *squareKernelArgs[3] = {(void *)&d_input, (void *)&d_square,
+                               (void *)&(hostArrays->numElements)};
+  kernelNodeParams.func = (void *)squareArray;
+  kernelNodeParams.kernelParams = (void **)squareKernelArgs;
+
+  // Square kernel depends on copyNodeInput to ensure all data is on the device
+  // before kernel launch.
+  checkCudaErrors(hipGraphAddKernelNode(&squareKernelNode, graph,
+                                         &copyNodeInput, 1, &kernelNodeParams));
+
+  checkCudaErrors(hipGraphAddMemcpyNode1D(
+      &copyNodeSquare, graph, &squareKernelNode, 1, hostArrays->square,
+      d_square, hostArrays->bytes, hipMemcpyDeviceToHost));
+
+  // Free of d_input depends on the square kernel to ensure that d_input is not
+  // freed while being read by the kernel. It also depends on the alloc of
+  // d_input via squareKernelNode > copyNodeInput > allocNodeSquare >
+  // allocNodeInput.
+  checkCudaErrors(cudaGraphAddMemFreeNode(&freeNodeInput, graph,
+                                          &squareKernelNode, 1, d_input));
+
+  // Allocation of C depends on free of A so CUDA can reuse the virtual address.
+  checkCudaErrors(cudaGraphAddMemAllocNode(&allocNodeNegSquare, graph,
+                                           &freeNodeInput, 1, &allocParams));
+  d_negSquare = (float *)allocParams.dptr;
+
+  if (d_negSquare == d_input) {
+    printf(
+        "Check verified that d_negSquare and d_input share a virtual "
+        "address.\n");
+  }
+
+  void *negateKernelArgs[3] = {(void *)&d_square, (void *)&d_negSquare,
+                               (void *)&(hostArrays->numElements)};
+  kernelNodeParams.func = (void *)negateArray;
+  kernelNodeParams.kernelParams = (void **)negateKernelArgs;
+
+  checkCudaErrors(hipGraphAddKernelNode(
+      &negateKernelNode, graph, &allocNodeNegSquare, 1, &kernelNodeParams));
+
+  nodeDependencies.push_back(copyNodeSquare);
+  nodeDependencies.push_back(negateKernelNode);
+  checkCudaErrors(cudaGraphAddMemFreeNode(&freeNodeSquare, graph,
+                                          nodeDependencies.data(),
+                                          nodeDependencies.size(), d_square));
+  nodeDependencies.clear();
+
+  checkCudaErrors(hipGraphAddMemcpyNode1D(
+      &copyNodeNegSquare, graph, &negateKernelNode, 1, hostArrays->negSquare,
+      d_negSquare, hostArrays->bytes, hipMemcpyDeviceToHost));
+
+  if (d_negSquare_out == NULL) {
+    hipGraphNode_t freeNodeNegSquare;
+    checkCudaErrors(cudaGraphAddMemFreeNode(
+        &freeNodeNegSquare, graph, &copyNodeNegSquare, 1, d_negSquare));
+  } else {
+    *d_negSquare_out = d_negSquare;
+  }
+
+  checkCudaErrors(hipGraphInstantiate(graphExec, graph, NULL, NULL, 0));
+  checkCudaErrors(hipGraphDestroy(graph));
+}
+
+/**
+ * Adds work to a CUDA stream which negates the square of values in the input
+ * array.
+ *
+ * If d_negSquare_out is non null, then:
+ * 1) d_negSquare will not be freed;
+ * 2) the value of d_negSquare_out will be set to d_negSquare.
+ *
+ * Diagram of the stream operations in doNegateSquaresInStream
+ * ---------------------------------------------------------------------
+ * | STREAM                             | STREAM2                      |
+ * ---------------------------------------------------------------------
+ *
+ * alloc d_input
+ *       |
+ * alloc d_square
+ *       |
+ * Memcpy a to device
+ *       |
+ * launch kernel squareArray
+ *       |
+ * record squareKernelCompleteEvent -->-- wait squareKernelCompleteEvent
+ *       |                                      |
+ * free d_input                                 |
+ *       |                                      |
+ * allocate d_negSquare                   Memcpy d_square to host
+ *       |                                      |
+ * launch kernel negateArray                    |
+ *       |                                      |
+ * record negateKernelCompleteEvent -->-- wait negateKernelCompleteEvent
+ *       |                                      |
+ * Memcpy d_negSquare to host                   |
+ *       |                                free d_square
+ * free d_negSquare                             |
+ *       |                                      |
+ * wait squareFreeEvent --------------<---- record squareFreeEvent
+ */
+void doNegateSquaresInStream(hipStream_t stream1, negSquareArrays *hostArrays,
+                             float **d_negSquare_out = NULL) {
+  float *d_input, *d_square, *d_negSquare;
+  hipStream_t stream2;
+  hipEvent_t squareKernelCompleteEvent, negateKernelCompleteEvent,
+      squareFreeEvent;
+
+  checkCudaErrors(hipStreamCreateWithFlags(&stream2, hipStreamNonBlocking));
+
+  checkCudaErrors(hipEventCreate(&squareKernelCompleteEvent));
+  checkCudaErrors(hipEventCreate(&negateKernelCompleteEvent));
+  checkCudaErrors(hipEventCreate(&squareFreeEvent));
+
+  // Virtual addresses are assigned synchronously when hipMallocAsync is
+  // called, thus there is no performace benefit gained by separating the
+  // allocations into two streams.
+  checkCudaErrors(hipMallocAsync(&d_input, hostArrays->bytes, stream1));
+  checkCudaErrors(hipMallocAsync(&d_square, hostArrays->bytes, stream1));
+
+  checkCudaErrors(hipMemcpyAsync(d_input, hostArrays->input, hostArrays->bytes,
+                                  hipMemcpyHostToDevice, stream1));
+  squareArray<<<hostArrays->numBlocks, THREADS_PER_BLOCK, 0, stream1>>>(
+      d_input, d_square, hostArrays->numElements);
+  checkCudaErrors(hipEventRecord(squareKernelCompleteEvent, stream1));
+
+  checkCudaErrors(hipStreamWaitEvent(stream2, squareKernelCompleteEvent, 0));
+  checkCudaErrors(hipMemcpyAsync(hostArrays->square, d_square,
+                                  hostArrays->bytes, hipMemcpyDeviceToHost,
+                                  stream2));
+
+  checkCudaErrors(hipFreeAsync(d_input, stream1));
+  checkCudaErrors(hipMallocAsync(&d_negSquare, hostArrays->bytes, stream1));
+  negateArray<<<hostArrays->numBlocks, THREADS_PER_BLOCK, 0, stream1>>>(
+      d_square, d_negSquare, hostArrays->numElements);
+  checkCudaErrors(hipEventRecord(negateKernelCompleteEvent, stream1));
+  checkCudaErrors(hipMemcpyAsync(hostArrays->negSquare, d_negSquare,
+                                  hostArrays->bytes, hipMemcpyDeviceToHost,
+                                  stream1));
+  if (d_negSquare_out == NULL) {
+    checkCudaErrors(hipFreeAsync(d_negSquare, stream1));
+  } else {
+    *d_negSquare_out = d_negSquare;
+  }
+
+  checkCudaErrors(hipStreamWaitEvent(stream2, negateKernelCompleteEvent, 0));
+  checkCudaErrors(hipFreeAsync(d_square, stream2));
+  checkCudaErrors(hipEventRecord(squareFreeEvent, stream2));
+
+  checkCudaErrors(hipStreamWaitEvent(stream1, squareFreeEvent, 0));
+
+  checkCudaErrors(hipStreamDestroy(stream2));
+  checkCudaErrors(hipEventDestroy(squareKernelCompleteEvent));
+  checkCudaErrors(hipEventDestroy(negateKernelCompleteEvent));
+  checkCudaErrors(hipEventDestroy(squareFreeEvent));
+}
+
+/**
+ * Demonstrates creating a CUDA graph including memory nodes using stream
+ * capture. createNegateSquaresGraphExplicitly constructs an equivalent graph
+ * without stream capture.
+ */
+void createNegateSquaresGraphWithStreamCapture(hipGraphExec_t *graphExec,
+                                               negSquareArrays *hostArrays,
+                                               float **d_negSquare_out = NULL) {
+  hipGraph_t graph;
+  hipStream_t stream;
+
+  checkCudaErrors(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
+
+  checkCudaErrors(hipStreamBeginCapture(stream, hipStreamCaptureModeGlobal));
+  doNegateSquaresInStream(stream, hostArrays, d_negSquare_out);
+  checkCudaErrors(hipStreamEndCapture(stream, &graph));
+
+  checkCudaErrors(hipGraphInstantiate(graphExec, graph, NULL, NULL, 0));
+  checkCudaErrors(hipStreamDestroy(stream));
+  checkCudaErrors(hipGraphDestroy(graph));
+}
+
+void prepareRefArrays(negSquareArrays *hostArrays,
+                      negSquareArrays *deviceRefArrays,
+                      bool **foundValidationFailure) {
+  deviceRefArrays->bytes = hostArrays->bytes;
+  deviceRefArrays->numElements = hostArrays->numElements;
+
+  for (int i = 0; i < hostArrays->numElements; i++) {
+    hostArrays->square[i] = hostArrays->input[i] * hostArrays->input[i];
+    hostArrays->negSquare[i] = hostArrays->square[i] * -1;
+  }
+
+  checkCudaErrors(
+      hipMalloc((void **)&deviceRefArrays->negSquare, deviceRefArrays->bytes));
+  checkCudaErrors(hipMemcpy(deviceRefArrays->negSquare, hostArrays->negSquare,
+                             hostArrays->bytes, hipMemcpyHostToDevice));
+
+  checkCudaErrors(
+      hipMallocManaged((void **)foundValidationFailure, sizeof(bool)));
+}
+
+int checkValidationFailure(bool *foundValidationFailure) {
+  if (*foundValidationFailure) {
+    printf("Validation FAILURE!\n\n");
+    *foundValidationFailure = false;
+    return EXIT_FAILURE;
+  } else {
+    printf("Validation PASSED!\n\n");
+    return EXIT_SUCCESS;
+  }
+}
+
+__global__ void validateGPU(float *d_negSquare, negSquareArrays devRefArrays,
+                            bool *foundValidationFailure) {
+  int idx = blockIdx.x * blockDim.x + threadIdx.x;
+  float ref, diff;
+
+  if (idx < devRefArrays.numElements) {
+    ref = devRefArrays.negSquare[idx];
+    diff = d_negSquare[idx] - ref;
+    diff *= diff;
+    ref *= ref;
+    if (diff / ref > ALLOWABLE_VARIANCE) {
+      *foundValidationFailure = true;
+    }
+  }
+}
+
+void validateHost(negSquareArrays *hostArrays, bool *foundValidationFailure) {
+  float ref, diff;
+
+  for (int i = 0; i < hostArrays->numElements; i++) {
+    ref = hostArrays->input[i] * hostArrays->input[i] * -1;
+    diff = hostArrays->negSquare[i] - ref;
+    diff *= diff;
+    ref *= ref;
+    if (diff / ref > ALLOWABLE_VARIANCE) {
+      *foundValidationFailure = true;
+    }
+  }
+}
+
+int main(int argc, char **argv) {
+  negSquareArrays hostArrays, deviceRefArrays;
+  hipStream_t stream;
+  hipGraphExec_t graphExec, graphExecFreeC;
+
+  // Declare pointers for GPU buffers
+  float *d_negSquare = NULL;
+  bool *foundValidationFailure = NULL;
+
+  srand(time(0));
+  int device = findCudaDevice(argc, (const char **)argv);
+
+  int driverVersion = 0;
+  int deviceSupportsMemoryPools = 0;
+
+  hipDriverGetVersion(&driverVersion);
+  printf("Driver version is: %d.%d\n", driverVersion / 1000,
+         (driverVersion % 100) / 10);
+
+  if (driverVersion < 11040) {
+    printf("Waiving execution as driver does not support Graph Memory Nodes\n");
+    exit(EXIT_WAIVED);
+  }
+
+  hipDeviceGetAttribute(&deviceSupportsMemoryPools,
+                         hipDeviceAttributeMemoryPoolsSupported, device);
+  if (!deviceSupportsMemoryPools) {
+    printf("Waiving execution as device does not support Memory Pools\n");
+    exit(EXIT_WAIVED);
+  } else {
+    printf("Setting up sample.\n");
+  }
+
+  prepareHostArrays(&hostArrays);
+  prepareRefArrays(&hostArrays, &deviceRefArrays, &foundValidationFailure);
+  checkCudaErrors(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
+  printf("Setup complete.\n\n");
+
+  printf("Running negateSquares in a stream.\n");
+  doNegateSquaresInStream(stream, &hostArrays);
+  checkCudaErrors(hipStreamSynchronize(stream));
+  printf("Validating negateSquares in a stream...\n");
+  validateHost(&hostArrays, foundValidationFailure);
+  checkValidationFailure(foundValidationFailure);
+  resetOutputArrays(&hostArrays);
+
+  printf("Running negateSquares in a stream-captured graph.\n");
+  createNegateSquaresGraphWithStreamCapture(&graphExec, &hostArrays);
+  checkCudaErrors(hipGraphLaunch(graphExec, stream));
+  checkCudaErrors(hipStreamSynchronize(stream));
+  printf("Validating negateSquares in a stream-captured graph...\n");
+  validateHost(&hostArrays, foundValidationFailure);
+  checkValidationFailure(foundValidationFailure);
+  resetOutputArrays(&hostArrays);
+
+  printf("Running negateSquares in an explicitly constructed graph.\n");
+  createNegateSquaresGraphExplicitly(&graphExec, device, &hostArrays);
+  checkCudaErrors(hipGraphLaunch(graphExec, stream));
+  checkCudaErrors(hipStreamSynchronize(stream));
+  printf("Validating negateSquares in an explicitly constructed graph...\n");
+  validateHost(&hostArrays, foundValidationFailure);
+  checkValidationFailure(foundValidationFailure);
+  resetOutputArrays(&hostArrays);
+
+  // Each of the three examples below free d_negSquare outside the graph. As
+  // demonstrated by validateGPU, d_negSquare can be accessed by outside the
+  // graph before d_negSquare is freed.
+
+  printf("Running negateSquares with d_negSquare freed outside the stream.\n");
+  createNegateSquaresGraphExplicitly(&graphExec, device, &hostArrays,
+                                     &d_negSquare);
+  checkCudaErrors(hipGraphLaunch(graphExec, stream));
+  validateGPU<<<hostArrays.numBlocks, THREADS_PER_BLOCK, 0, stream>>>(
+      d_negSquare, deviceRefArrays, foundValidationFailure);
+  // Since hipFree is synchronous, the stream must synchronize before freeing
+  // d_negSquare to ensure d_negSquare no longer being accessed.
+  checkCudaErrors(hipStreamSynchronize(stream));
+  checkCudaErrors(hipFree(d_negSquare));
+  printf(
+      "Validating negateSquares with d_negSquare freed outside the "
+      "stream...\n");
+  validateHost(&hostArrays, foundValidationFailure);
+  checkValidationFailure(foundValidationFailure);
+  resetOutputArrays(&hostArrays);
+
+  printf("Running negateSquares with d_negSquare freed outside the graph.\n");
+  checkCudaErrors(hipGraphLaunch(graphExec, stream));
+  validateGPU<<<hostArrays.numBlocks, THREADS_PER_BLOCK, 0, stream>>>(
+      d_negSquare, deviceRefArrays, foundValidationFailure);
+  checkCudaErrors(hipFreeAsync(d_negSquare, stream));
+  checkCudaErrors(hipStreamSynchronize(stream));
+  printf(
+      "Validating negateSquares with d_negSquare freed outside the graph...\n");
+  checkValidationFailure(foundValidationFailure);
+  resetOutputArrays(&hostArrays);
+
+  printf(
+      "Running negateSquares with d_negSquare freed in a different graph.\n");
+  createFreeGraph(&graphExecFreeC, d_negSquare);
+  checkCudaErrors(hipGraphLaunch(graphExec, stream));
+  validateGPU<<<hostArrays.numBlocks, THREADS_PER_BLOCK, 0, stream>>>(
+      d_negSquare, deviceRefArrays, foundValidationFailure);
+  checkCudaErrors(hipGraphLaunch(graphExecFreeC, stream));
+  checkCudaErrors(hipStreamSynchronize(stream));
+  printf(
+      "Validating negateSquares with d_negSquare freed in a different "
+      "graph...\n");
+  checkValidationFailure(foundValidationFailure);
+
+  printf("Cleaning up sample.\n");
+  checkCudaErrors(hipGraphExecDestroy(graphExec));
+  checkCudaErrors(hipGraphExecDestroy(graphExecFreeC));
+  checkCudaErrors(hipStreamDestroy(stream));
+  checkCudaErrors(hipFree(foundValidationFailure));
+  checkCudaErrors(hipFree(deviceRefArrays.negSquare));
+  free(hostArrays.input);
+  free(hostArrays.square);
+  free(hostArrays.negSquare);
+  printf("Cleanup complete. Exiting sample.\n");
+}
\ No newline at end of file
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2017.vcxproj
index 12812f5..f025d77 100755
--- a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/graphMemoryNodes.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2019.vcxproj
index b0e8dd3..df29858 100755
--- a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/graphMemoryNodes.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2022.vcxproj
index a42ac1c..5f123dc 100755
--- a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/graphMemoryNodes.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/README.md b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/README.md
index 8796c99..db9d480 100755
--- a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/README.md
+++ b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/README.md
@@ -27,7 +27,7 @@ cudaMemcpy, cudaFree, cudaGetErrorString, cudaGetLastError, cudaEventSynchronize
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2017.vcxproj
index d56dd80..b48ad38 100755
--- a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2019.vcxproj
index 7f7651a..b5931f5 100755
--- a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2022.vcxproj
index ec7cb72..90ae339 100755
--- a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/Makefile b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/Makefile
index 74a124f..fa42ed8 100755
--- a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/NsightEclipse.xml
index d689be0..e1572b4 100755
--- a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/NsightEclipse.xml
+++ b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/NsightEclipse.xml
@@ -53,6 +53,20 @@
   <scopes>
     <scope>1:CUDA</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/README.md b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/README.md
index 71d8ddc..6872218 100755
--- a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/README.md
+++ b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/README.md
@@ -10,6 +10,8 @@ CUDA Graphs, Stream Capture, Instantiated CUDA Graph Update, Cooperative Groups
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux, Windows
@@ -25,7 +27,7 @@ cudaExtent, cudaGraphLaunch, cudaGraphAddMemcpyNode, cudaMallocHost, cudaPitched
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobi.cu.hip b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobi.cu.hip
index 35a8da9..7cc0867 100755
--- a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobi.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobi.cu.hip
@@ -28,11 +28,10 @@
 
 #include <hip/hip_cooperative_groups.h>
 #include <hip/hip_runtime.h>
-#include "helper_cuda_hipified.h"
-#include "HIPCHECK.h"
+#include <helper_cuda.h>
 #include <vector>
 #include "jacobi.h"
-
+#include "HIPCHECK.h"
 namespace cg = cooperative_groups;
 
 // 8 Rows of square-matrix A processed by each CTA.
@@ -393,10 +392,3 @@ double JacobiMethodGpu(const float *A, const double *b,
   HIPCHECK(hipFree(d_sum));
   return sum;
 }
-    hipMemcpyDeviceToHost, stream));
-      checkCudaErrors(hipStreamSynchronize(stream));
-      printf("GPU iterations : %d\n", k + 1);
-      printf("GPU error : %.3e\n", sum);
-      break;
-    }
-  }
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs.out b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs.out
index a911056..c24e40f 100755
Binary files a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs.out and b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs.out differ
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2017.vcxproj
index 447cc89..489735b 100755
--- a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/jacobiCudaGraphs.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2019.vcxproj
index 68cea2b..b6440eb 100755
--- a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/jacobiCudaGraphs.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2022.vcxproj
index 7655f0e..2d37b08 100755
--- a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/jacobiCudaGraphs.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/Makefile b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/Makefile
index 5d9a55a..ae7b17d 100755
--- a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/Makefile
@@ -299,8 +299,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/README.md b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/README.md
index 6477cff..bace5c4 100755
--- a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/README.md
+++ b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/README.md
@@ -10,7 +10,7 @@ CUDA Driver API, cuMemMap IPC, MMAP
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cuDeviceCanAccessPeer, cuMemImportFromShareableHandle, cuModuleLoadDataEx, cuMod
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2017.vcxproj
index f72cfee..4d7d058 100755
--- a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/memMapIPCDrv.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -112,6 +112,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2019.vcxproj
index 4791514..287fbc9 100755
--- a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/memMapIPCDrv.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2022.vcxproj
index 754ffa8..d6bc39c 100755
--- a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/memMapIPCDrv.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_hipified.cpp b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_hipified.cpp
index 173355b..6238c81 100755
--- a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_hipified.cpp
+++ b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_hipified.cpp
@@ -278,15 +278,15 @@ static void memMapGetDeviceFunction(char **argv) {
     hipJitOption *jitOptions = new hipJitOption[jitNumOptions];
     void **jitOptVals = new void *[jitNumOptions];
     // set up size of compilation log buffer
-    jitOptions[0] = HIPRTC_JIT_INFO_LOG_BUFFER_SIZE_BYTES;
+    jitOptions[0] = hipJitOptionInfoLogBufferSizeBytes;
     int jitLogBufferSize = 1024;
     jitOptVals[0] = (void *)(size_t)jitLogBufferSize;
     // set up pointer to the compilation log buffer
-    jitOptions[1] = HIPRTC_JIT_INFO_LOG_BUFFER;
+    jitOptions[1] = hipJitOptionInfoLogBuffer;
     char *jitLogBuffer = new char[jitLogBufferSize];
     jitOptVals[1] = jitLogBuffer;
     // set up pointer to set the Maximum # of registers for a particular kernel
-    jitOptions[2] = HIPRTC_JIT_MAX_REGISTERS;
+    jitOptions[2] = hipJitOptionMaxRegisters;
     int jitRegCount = 32;
     jitOptVals[2] = (void *)(size_t)jitRegCount;
     checkCudaErrors(hipModuleLoadDataEx(&cuModule, ptx_source.c_str(),
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_kernel.cu.hip b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_kernel.cu.hip
index e69de29..41b1784 100755
--- a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_kernel.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_kernel.cu.hip
@@ -0,0 +1,38 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+
+// Device code
+extern "C" __global__ void memMapIpc_kernel(char *ptr, int sz, char val)
+{
+    // Dummy kernel
+    int idx = blockIdx.x * blockDim.x + threadIdx.x;
+    for (; idx < sz; idx += (gridDim.x * blockDim.x)) {
+        ptr[idx] = val;
+    }
+}
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/Makefile b/src/samples/Samples/3_CUDA_Features/newdelete/Makefile
index 3c0a41d..48c352f 100755
--- a/src/samples/Samples/3_CUDA_Features/newdelete/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/newdelete/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/newdelete/NsightEclipse.xml
index 397b3ee..ae7639e 100755
--- a/src/samples/Samples/3_CUDA_Features/newdelete/NsightEclipse.xml
+++ b/src/samples/Samples/3_CUDA_Features/newdelete/NsightEclipse.xml
@@ -33,6 +33,8 @@
   <scopes>
     <scope>1:CUDA Advanced Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/README.md b/src/samples/Samples/3_CUDA_Features/newdelete/README.md
index 87b1e97..1df54ae 100755
--- a/src/samples/Samples/3_CUDA_Features/newdelete/README.md
+++ b/src/samples/Samples/3_CUDA_Features/newdelete/README.md
@@ -10,7 +10,7 @@ Device Memory Allocation, C++ Templates
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaFree, cudaDeviceSynchronize, cudaDeviceSetLimit, cudaMalloc
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete.out b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete.out
index 2a5db23..46374e6 100755
Binary files a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete.out and b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete.out differ
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2017.vcxproj
index 8db0679..f5546f2 100755
--- a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/newdelete.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2019.vcxproj
index c0f396a..4f6a09f 100755
--- a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/newdelete.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2022.vcxproj
index f1bdb5d..cec331d 100755
--- a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/newdelete.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/Makefile b/src/samples/Samples/3_CUDA_Features/ptxjit/Makefile
index f36c928..414a761 100755
--- a/src/samples/Samples/3_CUDA_Features/ptxjit/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/ptxjit/Makefile
@@ -293,8 +293,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/ptxjit/NsightEclipse.xml
index 4ad69bc..2beac11 100755
--- a/src/samples/Samples/3_CUDA_Features/ptxjit/NsightEclipse.xml
+++ b/src/samples/Samples/3_CUDA_Features/ptxjit/NsightEclipse.xml
@@ -44,6 +44,8 @@
   <scopes>
     <scope>1:CUDA Advanced Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/README.md b/src/samples/Samples/3_CUDA_Features/ptxjit/README.md
index 701ad40..314c628 100755
--- a/src/samples/Samples/3_CUDA_Features/ptxjit/README.md
+++ b/src/samples/Samples/3_CUDA_Features/ptxjit/README.md
@@ -10,7 +10,7 @@ CUDA Driver API
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMalloc, cudaDriverGetVersion, cudaMemcpy, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_hipified.cpp b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_hipified.cpp
index 8ad89b6..fdbe2d7 100755
--- a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_hipified.cpp
+++ b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_hipified.cpp
@@ -48,7 +48,7 @@
 #include "helper_cuda_hipified.h"
 #include <helper_cuda_drvapi.h>
 #include "helper_functions.h"  // helper for shared that are common to CUDA Samples
-#include "hip/hiprtc.h"
+
 #if defined(_WIN64) || defined(__LP64__)
 #define PTX_FILE "ptxjit_kernel64.ptx"
 #else
@@ -105,26 +105,26 @@ void ptxJIT(int argc, char **argv, hipModule_t *phModule, hipFunction_t *phKerne
 
   // Setup linker options
   // Return walltime from JIT compilation
-  options[0] = HIPRTC_JIT_WALL_TIME;
+  options[0] = hipJitOptionWallTime;
   optionVals[0] = (void *)&walltime;
   // Pass a buffer for info messages
-  options[1] = HIPRTC_JIT_INFO_LOG_BUFFER;
+  options[1] = hipJitOptionInfoLogBuffer;
   optionVals[1] = (void *)info_log;
   // Pass the size of the info buffer
-  options[2] = HIPRTC_JIT_INFO_LOG_BUFFER_SIZE_BYTES;
+  options[2] = hipJitOptionInfoLogBufferSizeBytes;
   optionVals[2] = (void *)(long)logSize;
   // Pass a buffer for error message
-  options[3] = HIPRTC_JIT_ERROR_LOG_BUFFER;
+  options[3] = hipJitOptionErrorLogBuffer;
   optionVals[3] = (void *)error_log;
   // Pass the size of the error buffer
-  options[4] = HIPRTC_JIT_ERROR_LOG_BUFFER_SIZE_BYTES;
+  options[4] = hipJitOptionErrorLogBufferSizeBytes;
   optionVals[4] = (void *)(long)logSize;
   // Make the linker verbose
-  options[5] = HIPRTC_JIT_LOG_VERBOSE;
+  options[5] = hipJitOptionLogVerbose;
   optionVals[5] = (void *)1;
 
   // Create a pending linker invocation
-  checkCudaErrors(hiprtcLinkCreate(6, options, optionVals, lState));
+  checkCudaErrors(cuLinkCreate(6, options, optionVals, lState));
 
   // first search for the module path before we load the results
   if (!findModulePath(PTX_FILE, module_path, argv, ptx_source)) {
@@ -136,17 +136,17 @@ void ptxJIT(int argc, char **argv, hipModule_t *phModule, hipFunction_t *phKerne
 
   // Load the PTX from the ptx file
   printf("Loading ptxjit_kernel[] program\n");
-  myErr = hiprtcLinkAddData(*lState, HIPRTC_JIT_INPUT_PTX, (void *)ptx_source.c_str(),
+  myErr = cuLinkAddData(*lState, CU_JIT_INPUT_PTX, (void *)ptx_source.c_str(),
                         strlen(ptx_source.c_str()) + 1, 0, 0, 0, 0);
 
   if (myErr != hipSuccess) {
-    // Errors will be put in error_log, per HIPRTC_JIT_ERROR_LOG_BUFFER option
+    // Errors will be put in error_log, per hipJitOptionErrorLogBuffer option
     // above.
     fprintf(stderr, "PTX Linker Error:\n%s\n", error_log);
   }
 
   // Complete the linker step
-  checkCudaErrors(hiprtcLinkComplete(*lState, &cuOut, &outSize));
+  checkCudaErrors(cuLinkComplete(*lState, &cuOut, &outSize));
 
   // Linker walltime and info_log were requested in options above.
   printf("CUDA Link Completed in %fms. Linker Output:\n%s\n", walltime,
@@ -159,7 +159,7 @@ void ptxJIT(int argc, char **argv, hipModule_t *phModule, hipFunction_t *phKerne
   checkCudaErrors(hipModuleGetFunction(phKernel, *phModule, "myKernel"));
 
   // Destroy the linker invocation
-  checkCudaErrors(hiprtcLinkDestroy(*lState));
+  checkCudaErrors(cuLinkDestroy(*lState));
 }
 
 int main(int argc, char **argv) {
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2017.vcxproj
index 64ddab2..8544a38 100755
--- a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/ptxjit.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2019.vcxproj
index 48a4290..d0c152c 100755
--- a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/ptxjit.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2022.vcxproj
index 8396aaf..c4dbf91 100755
--- a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/ptxjit.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/Makefile b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/Makefile
index aa41b46..d956e9b 100755
--- a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/NsightEclipse.xml
index 40b8336..56db08f 100755
--- a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/NsightEclipse.xml
+++ b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/NsightEclipse.xml
@@ -60,6 +60,20 @@
   <scopes>
     <scope>1:CUDA</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/README.md b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/README.md
index 73c830e..b421b2f 100755
--- a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/README.md
+++ b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/README.md
@@ -10,6 +10,8 @@ CUDA Graphs, Stream Capture
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux, Windows
@@ -25,7 +27,7 @@ cudaGraphClone, cudaExtent, cudaGraphLaunch, cudaStreamCreate, cudaLaunchHostFun
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.cu.hip b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.cu.hip
index 3e3ef3b..8f88d3d 100755
--- a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -27,7 +26,7 @@
  */
 
 #include <hip/hip_runtime.h>
-#include <hip/hip_cooperative_groups.h>
+#include <hip/hip_cooperative_groups.h>	
 #include "helper_cuda_hipified.h"
 #include <vector>
 #include "HIPCHECK.h"
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.out b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.out
index ba74a4b..74b721c 100755
Binary files a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.out and b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.out differ
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2017.vcxproj
index e484070..a9525b0 100755
--- a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleCudaGraphs.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2019.vcxproj
index 5344218..168b88a 100755
--- a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCudaGraphs.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2022.vcxproj
index 2bea3b3..58840c8 100755
--- a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCudaGraphs.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/README.md b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/README.md
index 13b68b9..d7f41f6 100755
--- a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/README.md
+++ b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/README.md
@@ -30,7 +30,7 @@ cudaMemcpy, cudaFree, cudaGetErrorString, cudaGetLastError, cudaEventSynchronize
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2017.vcxproj
index a437748..2948b39 100755
--- a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2019.vcxproj
index 6ee7313..7a06218 100755
--- a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2022.vcxproj
index 5b37dbc..f7b1d1a 100755
--- a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/Makefile b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/Makefile
index efa3bd0..aa25f15 100755
--- a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/Makefile
+++ b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/Makefile
@@ -306,7 +306,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/NsightEclipse.xml
index f6eb813..f0457b1 100755
--- a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/NsightEclipse.xml
+++ b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/NsightEclipse.xml
@@ -37,6 +37,20 @@
   <scopes>
     <scope>1:CUDA Advanced Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/README.md b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/README.md
index 562686b..f40b05e 100755
--- a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/README.md
+++ b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/README.md
@@ -10,6 +10,8 @@ Cooperative Groups, Atomic Intrinsics
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux, Windows
@@ -25,7 +27,7 @@ cudaMemcpy, cudaFree, cudaDeviceGetAttribute, cudaMemset, cudaMalloc
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG.cu.hip b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG.cu.hip
index c3ab431..e0fec53 100755
--- a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG.cu.hip
@@ -197,7 +197,7 @@ int calculateMaxInBuckets(int *h_srcArr, int *d_srcArr, int numOfBuckets)
 
   memset(cpuBucketsMax, 0, sizeof(int) * numOfBuckets);
 
-  // Here we create values which is assumed to correspond to each
+  // Here we create values which is assumed to correspond to each 
   // buckets of srcArr at same array index.
   for (int i=0; i < NUM_ELEMS; i++)
   {
@@ -238,7 +238,7 @@ int calculateMaxInBuckets(int *h_srcArr, int *d_srcArr, int numOfBuckets)
   }
   if (allMatch)
   {
-    printf("CPU max matches GPU max\n");
+    printf("CPU max matches GPU max\n"); 
   }
 
   delete[] h_valueInBuckets;
@@ -316,7 +316,7 @@ int main(int argc, char **argv) {
   }
 
   printf("\nWarp Aggregated Atomics %s \n",
-         (host_flt_count == nres) && (mapIndicesToBucketsStatus == EXIT_SUCCESS) &&
+         (host_flt_count == nres) && (mapIndicesToBucketsStatus == EXIT_SUCCESS) && 
          (calculateMaxInBucketsStatus == EXIT_SUCCESS) ? "PASSED" : "FAILED");
 
   checkCudaErrors(hipFree(d_data_to_filter));
@@ -326,9 +326,3 @@ int main(int argc, char **argv) {
   free(filtered_data);
   free(host_filtered_data);
 }
-eckCudaErrors(hipFree(d_filtered_data));
-  checkCudaErrors(hipFree(d_nres));
-  free(data_to_filter);
-  free(filtered_data);
-  free(host_filtered_data);
-}
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2017.vcxproj
index 93d8d3a..0e2d597 100755
--- a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2017.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/warpAggregatedAtomicsCG.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2019.vcxproj
index 21f7ba7..a15057b 100755
--- a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2019.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/warpAggregatedAtomicsCG.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2022.vcxproj
index a169926..8567bb3 100755
--- a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2022.vcxproj
+++ b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/warpAggregatedAtomicsCG.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2017.vcxproj
index 75fe964..61a190a 100755
--- a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/FilterBorderControlNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -117,6 +117,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2019.vcxproj
index 9df4a2d..438dd31 100755
--- a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/FilterBorderControlNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2022.vcxproj
index db146d3..8678084 100755
--- a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/FilterBorderControlNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/Makefile b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/Makefile
index 9dfe95d..7efec15 100755
--- a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/Makefile
@@ -295,8 +295,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/NsightEclipse.xml
index 3e2dd0f..60bd7e9 100755
--- a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/NsightEclipse.xml
@@ -55,6 +55,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/README.md b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/README.md
index 9e5f692..54a652a 100755
--- a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/README.md
@@ -10,7 +10,7 @@ Performance Strategies, Image Processing, NPP Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaRuntimeGetVersion, cudaDeviceReset, cudaSetDevice, cudaGetDeviceCount, cudaD
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/Makefile b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/Makefile
index 9def65c..1460d98 100755
--- a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/Makefile
@@ -287,8 +287,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2017.vcxproj
index 2726844..17822bc 100755
--- a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/MersenneTwisterGP11213.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2019.vcxproj
index 24a30ef..7532260 100755
--- a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/MersenneTwisterGP11213.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2022.vcxproj
index f549fb4..a40090f 100755
--- a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/MersenneTwisterGP11213.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/NsightEclipse.xml
index 5de9a76..34ed799 100755
--- a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/NsightEclipse.xml
@@ -45,6 +45,8 @@
   <scopes>
     <scope>1:CUDA Advanced Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/README.md b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/README.md
index 6597909..6244164 100755
--- a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/README.md
@@ -10,7 +10,7 @@ CURAND Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaStreamCreateWithFlags, cudaStreamDestroy, cudaFree, cudaMallocHost, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/Makefile b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/Makefile
index ba14106..f21c6df 100755
--- a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/Makefile
@@ -287,8 +287,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/NsightEclipse.xml
index dbf0c6d..44f306e 100755
--- a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/NsightEclipse.xml
@@ -45,6 +45,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/README.md b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/README.md
index e0445d2..6357502 100755
--- a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/README.md
@@ -10,7 +10,7 @@ Linear Algebra, CUBLAS Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaMemcpy, cudaGetErrorString, cudaFree, cudaGetLastError, cudaDeviceSynchroniz
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2017.vcxproj
index 82f0bfc..2c41bea 100755
--- a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/batchCUBLAS.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2019.vcxproj
index cd92e43..1bd17ba 100755
--- a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/batchCUBLAS.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2022.vcxproj
index ba62a73..dba07df 100755
--- a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/batchCUBLAS.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/Makefile b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/Makefile
index e6ee70d..d571295 100755
--- a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/Makefile
@@ -301,8 +301,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/NsightEclipse.xml
index 86c70ec..9cd72dd 100755
--- a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/NsightEclipse.xml
@@ -55,6 +55,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/README.md b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/README.md
index fafb0fd..ddc106f 100755
--- a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/README.md
@@ -10,7 +10,7 @@ Performance Strategies, Image Processing, NPP Library, Using NPP Batch Functions
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaRuntimeGetVersion, cudaMallocPitch, cudaFree, cudaDeviceGetAttribute, cudaMa
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2017.vcxproj
index 685e35d..da25b50 100755
--- a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/batchedLabelMarkersAndLabelCompressionNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2019.vcxproj
index 2ee2fde..928dc41 100755
--- a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/batchedLabelMarkersAndLabelCompressionNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2022.vcxproj
index 0b0bb30..5b9408a 100755
--- a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/batchedLabelMarkersAndLabelCompressionNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/Makefile b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/Makefile
index 946fbb0..59fb6aa 100755
--- a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/Makefile
@@ -295,8 +295,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/NsightEclipse.xml
index 7c02003..da9c0d5 100755
--- a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/NsightEclipse.xml
@@ -51,6 +51,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/README.md b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/README.md
index 9770ef3..f647397 100755
--- a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/README.md
@@ -10,7 +10,7 @@ Performance Strategies, Image Processing, NPP Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaRuntimeGetVersion, cudaDriverGetVersion
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2017.vcxproj
index 2d8bc63..bf2a30a 100755
--- a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/boxFilterNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -117,6 +117,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2019.vcxproj
index 0b6fbb7..a7ab43b 100755
--- a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/boxFilterNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2022.vcxproj
index a922b28..5b3e3fb 100755
--- a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/boxFilterNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/Makefile b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/Makefile
index 7618723..0e613ac 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/Makefile
@@ -295,8 +295,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/NsightEclipse.xml
index 8caedf3..26b3f45 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/NsightEclipse.xml
@@ -53,6 +53,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/README.md b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/README.md
index 1daba12..01493d7 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/README.md
@@ -10,7 +10,7 @@ Performance Strategies, Image Processing, NPP Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaRuntimeGetVersion, cudaFree, cudaSetDevice, cudaGetDeviceCount, cudaDeviceIn
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2017.vcxproj
index e45d19a..338a498 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/cannyEdgeDetectorNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -117,6 +117,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2019.vcxproj
index ae21d2c..9116415 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cannyEdgeDetectorNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2022.vcxproj
index d4b80c0..31270ca 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/cannyEdgeDetectorNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/Makefile b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/Makefile
index dcf16b3..11d8a24 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/Makefile
@@ -287,8 +287,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/NsightEclipse.xml
index 717b37f..99a85b3 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/NsightEclipse.xml
@@ -46,6 +46,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/README.md b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/README.md
index 1244508..9f66478 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/README.md
@@ -10,7 +10,7 @@ Linear Algebra, CUBLAS Library, CUSPARSE Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMemcpy, cudaFree, cudaDeviceSynchronize, cudaMalloc, cudaGetDeviceProperties
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2017.vcxproj
index 4cf6195..42096e5 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/conjugateGradient.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2019.vcxproj
index 9132bc3..44cdb92 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/conjugateGradient.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2022.vcxproj
index a63fac3..afb56e1 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/conjugateGradient.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/Makefile b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/Makefile
index edd098c..4c4c95d 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/NsightEclipse.xml
index 2323c1a..0a76680 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/NsightEclipse.xml
@@ -58,6 +58,8 @@
     <scope>3:Linear Algebra</scope>
     <scope>1:CUDA Graphs</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/README.md b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/README.md
index cfeb9f0..787c89a 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/README.md
@@ -10,7 +10,7 @@ Linear Algebra, CUBLAS Library, CUSPARSE Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphInstantiate, cudaStreamDestroy, cudaStreamBeginCapture, cudaFree, cudaM
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs.cu.hip b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs.cu.hip
index a006706..167dd92 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs.cu.hip
@@ -43,8 +43,8 @@
 #include <hipsparse.h>
 
 // Utilities and system includes
-#include "helper_cuda_hipified.h"  // helper function CUDA error checking and initialization
-#include "helper_functions.h"  // helper for shared functions common to CUDA Samples
+#include <helper_cuda.h>  // helper function CUDA error checking and initialization
+#include <helper_functions.h>  // helper for shared functions common to CUDA Samples
 
 const char *sSDKname = "conjugateGradientCudaGraphs";
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2017.vcxproj
index 2af89ce..2a1e00e 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/conjugateGradientCudaGraphs.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2019.vcxproj
index 91958e7..c1e3676 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/conjugateGradientCudaGraphs.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2022.vcxproj
index b339fdb..f641b21 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/conjugateGradientCudaGraphs.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/README.md b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/README.md
index 732d89d..e8c0643 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/README.md
@@ -30,7 +30,7 @@ cudaFree, cudaMallocManaged, cudaDeviceSynchronize, cudaEventRecord, cudaLaunchC
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG.cu.hip b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG.cu.hip
index 925c2a5..a4b41a0 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG.cu.hip
@@ -343,7 +343,7 @@ int main(int argc, char **argv) {
   // This will pick the best possible CUDA capable device
   hipDeviceProp_t deviceProp;
   int devID = findCudaDevice(argc, (const char **)argv);
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, devID));
+  checkCudaErrors(hipGetDeviceProperties(&deviceProp, devID));
 
   if (!deviceProp.managedMemory) {
     // This sample requires being run on a device that supports Unified Memory
@@ -386,17 +386,17 @@ int main(int argc, char **argv) {
   *dot_result = 0.0;
 
   // temp memory for CG
-  HIPCHECK(
+  checkCudaErrors(
       hipMallocManaged(reinterpret_cast<void **>(&r), N * sizeof(float)));
-  HIPCHECK(
+  checkCudaErrors(
       hipMallocManaged(reinterpret_cast<void **>(&p), N * sizeof(float)));
-  HIPCHECK(
+  checkCudaErrors(
       hipMallocManaged(reinterpret_cast<void **>(&Ax), N * sizeof(float)));
 
   hipDeviceSynchronize();
 
-  HIPCHECK(hipEventCreate(&start));
-  HIPCHECK(hipEventCreate(&stop));
+  checkCudaErrors(hipEventCreate(&start));
+  checkCudaErrors(hipEventCreate(&stop));
 
 #if ENABLE_CPU_DEBUG_CODE
   float *Ax_cpu = reinterpret_cast<float *>(malloc(sizeof(float) * N));
@@ -426,21 +426,21 @@ int main(int argc, char **argv) {
   int numBlocksPerSm = 0;
   int numThreads = THREADS_PER_BLOCK;
 
-  HIPCHECK(hipOccupancyMaxActiveBlocksPerMultiprocessor(
+  checkCudaErrors(hipOccupancyMaxActiveBlocksPerMultiprocessor(
       &numBlocksPerSm, gpuConjugateGradient, numThreads, sMemSize));
 
   int numSms = deviceProp.multiProcessorCount;
   dim3 dimGrid(numSms * numBlocksPerSm, 1, 1),
       dimBlock(THREADS_PER_BLOCK, 1, 1);
-  HIPCHECK(hipEventRecord(start, 0));
-  HIPCHECK(hipLaunchCooperativeKernel((void *)gpuConjugateGradient,
+  checkCudaErrors(hipEventRecord(start, 0));
+  checkCudaErrors(hipLaunchCooperativeKernel((void *)gpuConjugateGradient,
                                               dimGrid, dimBlock, kernelArgs,
                                               sMemSize, NULL));
-  HIPCHECK(hipEventRecord(stop, 0));
-  HIPCHECK(hipDeviceSynchronize());
+  checkCudaErrors(hipEventRecord(stop, 0));
+  checkCudaErrors(hipDeviceSynchronize());
 
   float time;
-  HIPCHECK(hipEventElapsedTime(&time, start, stop));
+  checkCudaErrors(hipEventElapsedTime(&time, start, stop));
 
   r1 = *dot_result;
 
@@ -467,17 +467,17 @@ int main(int argc, char **argv) {
     }
   }
 
-  HIPCHECK(hipFree(I));
-  HIPCHECK(hipFree(J));
-  HIPCHECK(hipFree(val));
-  HIPCHECK(hipFree(x));
-  HIPCHECK(hipFree(rhs));
-  HIPCHECK(hipFree(r));
-  HIPCHECK(hipFree(p));
-  HIPCHECK(hipFree(Ax));
-  HIPCHECK(hipFree(dot_result));
-  HIPCHECK(hipEventDestroy(start));
-  HIPCHECK(hipEventDestroy(stop));
+  checkCudaErrors(hipFree(I));
+  checkCudaErrors(hipFree(J));
+  checkCudaErrors(hipFree(val));
+  checkCudaErrors(hipFree(x));
+  checkCudaErrors(hipFree(rhs));
+  checkCudaErrors(hipFree(r));
+  checkCudaErrors(hipFree(p));
+  checkCudaErrors(hipFree(Ax));
+  checkCudaErrors(hipFree(dot_result));
+  checkCudaErrors(hipEventDestroy(start));
+  checkCudaErrors(hipEventDestroy(stop));
 
 #if ENABLE_CPU_DEBUG_CODE
   free(Ax_cpu);
@@ -491,7 +491,3 @@ int main(int argc, char **argv) {
           (sqrt(r1) < tol) ? "PASSED" : "FAILED");
   exit((sqrt(r1) < tol) ? EXIT_SUCCESS : EXIT_FAILURE);
 }
-(stdout, "&&&& conjugateGradientMultiBlockCG %s\n",
-          (sqrt(r1) < tol) ? "PASSED" : "FAILED");
-  exit((sqrt(r1) < tol) ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2017.vcxproj
index 0586e71..d3fc2fd 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2019.vcxproj
index 061959b..6c064a9 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2022.vcxproj
index 75f5138..0e4d81b 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/README.md b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/README.md
index ece80f5..9d77bf3 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/README.md
@@ -30,7 +30,7 @@ cudaHostAlloc, cudaMemPrefetchAsync, cudaFree, cudaLaunchCooperativeKernel, cuda
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG.cu.hip b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG.cu.hip
index 2751c9b..94deed1 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG.cu.hip
@@ -792,39 +792,3 @@ int main(int argc, char **argv) {
           (sqrt(r1) < tol) ? "PASSED" : "FAILED");
   exit((sqrt(r1) < tol) ? EXIT_SUCCESS : EXIT_FAILURE);
 }
-G_CODE
-  free(Ax_cpu);
-  free(r_cpu);
-  free(p_cpu);
-  free(x_cpu);
-#endif
-
-  printf("Test Summary:  Error amount = %f \n", err);
-  fprintf(stdout, "&&&& conjugateGradientMultiDeviceCG %s\n",
-          (sqrt(r1) < tol) ? "PASSED" : "FAILED");
-  exit((sqrt(r1) < tol) ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-G_CODE
-  free(Ax_cpu);
-  free(r_cpu);
-  free(p_cpu);
-  free(x_cpu);
-#endif
-
-  printf("Test Summary:  Error amount = %f \n", err);
-  fprintf(stdout, "&&&& conjugateGradientMultiDeviceCG %s\n",
-          (sqrt(r1) < tol) ? "PASSED" : "FAILED");
-  exit((sqrt(r1) < tol) ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-G_CODE
-  free(Ax_cpu);
-  free(r_cpu);
-  free(p_cpu);
-  free(x_cpu);
-#endif
-
-  printf("Test Summary:  Error amount = %f \n", err);
-  fprintf(stdout, "&&&& conjugateGradientMultiDeviceCG %s\n",
-          (sqrt(r1) < tol) ? "PASSED" : "FAILED");
-  exit((sqrt(r1) < tol) ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2017.vcxproj
index 3c90656..b58051c 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2019.vcxproj
index 7a2c3f9..b422370 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2022.vcxproj
index e50c51d..41caff0 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/Makefile b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/Makefile
index c691293..df55e2f 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/Makefile
@@ -287,8 +287,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/NsightEclipse.xml
index eff44f2..760d5de 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/NsightEclipse.xml
@@ -44,6 +44,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/README.md b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/README.md
index 9504252..bded981 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/README.md
@@ -10,7 +10,7 @@ Linear Algebra, CUBLAS Library, CUSPARSE Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMemcpy, cudaFree, cudaMemset, cudaMalloc, cudaGetDeviceProperties
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2017.vcxproj
index 6ae930b..3af1df6 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/conjugateGradientPrecond.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2019.vcxproj
index 78c62c2..0721d9e 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/conjugateGradientPrecond.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2022.vcxproj
index 42cb117..e601f5f 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/conjugateGradientPrecond.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/main.cpp b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/main.cpp
index f8d1d29..d481ccc 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/main.cpp
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/main.cpp
@@ -42,101 +42,87 @@
  * benchmarking purposes.
  */
 
-
 // includes, system
-#include <stdlib.h>
+#include <math.h>
 #include <stdio.h>
+#include <stdlib.h>
 #include <string.h>
-#include <math.h>
 
 // CUDA Runtime
 #include <cuda_runtime.h>
 
 // Using updated (v2) interfaces for CUBLAS and CUSPARSE
-#include <cusparse.h>
 #include <cublas_v2.h>
+#include <cusparse.h>
 
 // Utilities and system includes
-#include <helper_functions.h>  // shared functions common to CUDA Samples
 #include <helper_cuda.h>       // CUDA error checking
+#include <helper_functions.h>  // shared functions common to CUDA Samples
 
-const char *sSDKname     = "conjugateGradientPrecond";
+const char *sSDKname = "conjugateGradientPrecond";
 
 /*
  * Generate a matrix representing a second order regular Laplacian operator
  * on a 2D domain in Compressed Sparse Row format.
  */
 void genLaplace(int *row_ptr, int *col_ind, float *val, int M, int N, int nz,
-                float *rhs)
-{
-    assert(M==N);
-    int n=(int)sqrt((double)N);
-    assert(n*n==N);
-    printf("laplace dimension = %d\n", n);
-    int idx = 0;
-
-    // loop over degrees of freedom
-    for (int i = 0; i < N; i++)
-    {
-        int ix = i % n;
-        int iy = i / n;
-
-        row_ptr[i] = idx;
-
-        // up
-        if (iy > 0)
-        {
-            val[idx] = 1.0;
-            col_ind[idx] = i - n;
-            idx++;
-        }
-        else
-        {
-            rhs[i] -= 1.0;
-        }
-
-        // left
-        if (ix > 0) {
-            val[idx] = 1.0;
-            col_ind[idx] = i - 1;
-            idx++;
-        } else {
-            rhs[i] -= 0.0;
-        }
-
-        // center
-        val[idx] = -4.0;
-        col_ind[idx] = i;
-        idx++;
-
-        //right
-        if (ix  < n - 1)
-        {
-            val[idx] = 1.0;
-            col_ind[idx] = i + 1;
-            idx++;
-        }
-        else
-        {
-            rhs[i] -= 0.0;
-        }
-
-        // down
-        if (iy  < n - 1)
-        {
-            val[idx] = 1.0;
-            col_ind[idx] = i + n;
-            idx++;
-        }
-        else
-        {
-            rhs[i] -= 0.0;
-        }
+                float *rhs) {
+  assert(M == N);
+  int n = (int)sqrt((double)N);
+  assert(n * n == N);
+  printf("laplace dimension = %d\n", n);
+  int idx = 0;
+
+  // loop over degrees of freedom
+  for (int i = 0; i < N; i++) {
+    int ix = i % n;
+    int iy = i / n;
+
+    row_ptr[i] = idx;
+
+    // up
+    if (iy > 0) {
+      val[idx] = 1.0;
+      col_ind[idx] = i - n;
+      idx++;
+    } else {
+      rhs[i] -= 1.0;
+    }
 
+    // left
+    if (ix > 0) {
+      val[idx] = 1.0;
+      col_ind[idx] = i - 1;
+      idx++;
+    } else {
+      rhs[i] -= 0.0;
     }
 
-    row_ptr[N] = idx;
+    // center
+    val[idx] = -4.0;
+    col_ind[idx] = i;
+    idx++;
+
+    // right
+    if (ix < n - 1) {
+      val[idx] = 1.0;
+      col_ind[idx] = i + 1;
+      idx++;
+    } else {
+      rhs[i] -= 0.0;
+    }
 
+    // down
+    if (iy < n - 1) {
+      val[idx] = 1.0;
+      col_ind[idx] = i + n;
+      idx++;
+    } else {
+      rhs[i] -= 0.0;
+    }
+  }
+
+  row_ptr[N] = idx;
 }
 
 /*
@@ -145,464 +131,401 @@ void genLaplace(int *row_ptr, int *col_ind, float *val, int M, int N, int nz,
  * b) using an Incomplete Cholesky preconditioner, and
  * c) using an ILU0 preconditioner.
  */
-int main(int argc, char **argv){
-    const int max_iter = 1000;
-    int k, M = 0, N = 0, nz = 0, *I = NULL, *J = NULL;
-    int *d_col, *d_row;
-    int qatest = 0;
-    const float tol = 1e-12f;
-    float *x, *rhs;
-    float r0, r1, alpha, beta;
-    float *d_val, *d_x;
-    float *d_zm1, *d_zm2, *d_rm2;
-    float *d_r, *d_p, *d_omega, *d_y;
-    float *val = NULL;
-    float *d_valsILU0;
-    float rsum, diff, err = 0.0;
-    float qaerr1, qaerr2 = 0.0;
-    float dot, numerator, denominator, nalpha;
-    const float floatone = 1.0;
-    const float floatzero = 0.0;
-
-    int nErrors = 0;
-
-    printf("conjugateGradientPrecond starting...\n");
-
-      /* QA testing mode */
+int main(int argc, char **argv) {
+  const int max_iter = 1000;
+  int k, M = 0, N = 0, nz = 0, *I = NULL, *J = NULL;
+  int *d_col, *d_row;
+  int qatest = 0;
+  const float tol = 1e-12f;
+  float *x, *rhs;
+  float r0, r1, alpha, beta;
+  float *d_val, *d_x;
+  float *d_zm1, *d_zm2, *d_rm2;
+  float *d_r, *d_p, *d_omega, *d_y;
+  float *val = NULL;
+  float *d_valsILU0;
+  void *buffer = NULL;
+  float rsum, diff, err = 0.0;
+  float qaerr1, qaerr2 = 0.0;
+  float dot, numerator, denominator, nalpha;
+  const float floatone = 1.0;
+  const float floatzero = 0.0;
+
+  int nErrors = 0;
+
+  printf("conjugateGradientPrecond starting...\n");
+
+  /* QA testing mode */
   if (checkCmdLineFlag(argc, (const char **)argv, "qatest")) {
     qatest = 1;
   }
 
-    /* This will pick the best possible CUDA capable device */
-    cudaDeviceProp deviceProp;
-    int devID = findCudaDevice(argc, (const char **)argv);
-    printf("GPU selected Device ID = %d \n", devID);
+  /* This will pick the best possible CUDA capable device */
+  cudaDeviceProp deviceProp;
+  int devID = findCudaDevice(argc, (const char **)argv);
+  printf("GPU selected Device ID = %d \n", devID);
 
-    if (devID < 0)
-    {
-        printf("Invalid GPU device %d selected,  exiting...\n", devID);
-        exit(EXIT_SUCCESS);
-    }
+  if (devID < 0) {
+    printf("Invalid GPU device %d selected,  exiting...\n", devID);
+    exit(EXIT_SUCCESS);
+  }
 
-    checkCudaErrors(cudaGetDeviceProperties(&deviceProp, devID));
-
-    /* Statistics about the GPU device */
-    printf("> GPU device has %d Multi-Processors, SM %d.%d compute capabilities\n\n",
-           deviceProp.multiProcessorCount, deviceProp.major, deviceProp.minor);
-
-    /* Generate a Laplace matrix in CSR (Compressed Sparse Row) format */
-    M = N = 16384;
-    nz = 5 * N - 4 * (int)sqrt((double)N);
-    I = (int *)malloc(sizeof(int) * (N + 1));   // csr row pointers for matrix A
-    J = (int *)malloc(sizeof(int) * nz);       // csr column indices for matrix A
-    val = (float *)malloc(sizeof(float) * nz); // csr values for matrix A
-    x = (float *)malloc(sizeof(float) * N);
-    rhs = (float *)malloc(sizeof(float) * N);
-
-    for (int i = 0; i < N; i++)
-    {
-        rhs[i] = 0.0;  // Initialize RHS
-        x[i] = 0.0;    // Initial solution approximation
-    }
+  checkCudaErrors(cudaGetDeviceProperties(&deviceProp, devID));
+
+  /* Statistics about the GPU device */
+  printf(
+      "> GPU device has %d Multi-Processors, "
+      "SM %d.%d compute capabilities\n\n",
+      deviceProp.multiProcessorCount, deviceProp.major, deviceProp.minor);
+
+  /* Generate a Laplace matrix in CSR (Compressed Sparse Row) format */
+  M = N = 16384;
+  nz = 5 * N - 4 * (int)sqrt((double)N);
+  I = (int *)malloc(sizeof(int) * (N + 1));   // csr row pointers for matrix A
+  J = (int *)malloc(sizeof(int) * nz);        // csr column indices for matrix A
+  val = (float *)malloc(sizeof(float) * nz);  // csr values for matrix A
+  x = (float *)malloc(sizeof(float) * N);
+  rhs = (float *)malloc(sizeof(float) * N);
+
+  for (int i = 0; i < N; i++) {
+    rhs[i] = 0.0;  // Initialize RHS
+    x[i] = 0.0;    // Initial solution approximation
+  }
 
-    genLaplace(I, J, val, M, N, nz, rhs);
-
-    /* Create CUBLAS context */
-    cublasHandle_t cublasHandle = NULL;
-    checkCudaErrors(cublasCreate(&cublasHandle));
-
-    /* Create CUSPARSE context */
-    cusparseHandle_t cusparseHandle = NULL;
-    checkCudaErrors(cusparseCreate(&cusparseHandle));
-
-    /* Description of the A matrix */
-    cusparseMatDescr_t descr = 0;
-    checkCudaErrors(cusparseCreateMatDescr(&descr));
-    checkCudaErrors(cusparseSetMatType(descr, CUSPARSE_MATRIX_TYPE_GENERAL));
-    checkCudaErrors(cusparseSetMatIndexBase(descr, CUSPARSE_INDEX_BASE_ZERO));
-
-    /* Allocate required memory */
-    checkCudaErrors(cudaMalloc((void **)&d_col, nz * sizeof(int)));
-    checkCudaErrors(cudaMalloc((void **)&d_row, (N + 1) * sizeof(int)));
-    checkCudaErrors(cudaMalloc((void **)&d_val, nz * sizeof(float)));
-    checkCudaErrors(cudaMalloc((void **)&d_x, N * sizeof(float)));
-    checkCudaErrors(cudaMalloc((void **)&d_y, N * sizeof(float)));
-    checkCudaErrors(cudaMalloc((void **)&d_r, N * sizeof(float)));
-    checkCudaErrors(cudaMalloc((void **)&d_p, N * sizeof(float)));
-    checkCudaErrors(cudaMalloc((void **)&d_omega, N * sizeof(float)));
-    checkCudaErrors(cudaMalloc((void **)&d_valsILU0, nz * sizeof(float)));
-    checkCudaErrors(cudaMalloc((void **)&d_zm1, (N) * sizeof(float)));
-    checkCudaErrors(cudaMalloc((void **)&d_zm2, (N) * sizeof(float)));
-    checkCudaErrors(cudaMalloc((void **)&d_rm2, (N) * sizeof(float)));
-
-    /* Wrap raw data into cuSPARSE generic API objects */
-    cusparseDnVecDescr_t vecp = NULL, vecX=NULL, vecY = NULL, vecR = NULL, vecZM1=NULL;
-    checkCudaErrors(cusparseCreateDnVec(&vecp, N, d_p, CUDA_R_32F));
-    checkCudaErrors(cusparseCreateDnVec(&vecX, N, d_x, CUDA_R_32F));
-    checkCudaErrors(cusparseCreateDnVec(&vecY, N, d_y, CUDA_R_32F));
-    checkCudaErrors(cusparseCreateDnVec(&vecR, N, d_r, CUDA_R_32F));
-    checkCudaErrors(cusparseCreateDnVec(&vecZM1, N, d_zm1, CUDA_R_32F));
-    cusparseDnVecDescr_t vecomega = NULL;
-    checkCudaErrors(cusparseCreateDnVec(&vecomega, N, d_omega, CUDA_R_32F));
-
-    /* Initialize problem data */
-    checkCudaErrors(cudaMemcpy(
-        d_col, J, nz * sizeof(int), cudaMemcpyHostToDevice));
-    checkCudaErrors(cudaMemcpy(
-        d_row, I, (N + 1) * sizeof(int), cudaMemcpyHostToDevice));
-    checkCudaErrors(cudaMemcpy(
-        d_val, val, nz * sizeof(float), cudaMemcpyHostToDevice));
-    checkCudaErrors(cudaMemcpy(
-        d_val, val, nz * sizeof(float), cudaMemcpyHostToDevice));
-    checkCudaErrors(cudaMemcpy(
-        d_x, x, N*sizeof(float), cudaMemcpyHostToDevice));
-    checkCudaErrors(cudaMemcpy(
-        d_r, rhs, N * sizeof(float), cudaMemcpyHostToDevice));
-
-    cusparseSpMatDescr_t matA = NULL;
-    cusparseSpMatDescr_t matM_lower, matM_upper;
-    cusparseFillMode_t   fill_lower    = CUSPARSE_FILL_MODE_LOWER;
-    cusparseDiagType_t   diag_unit     = CUSPARSE_DIAG_TYPE_UNIT;
-    cusparseFillMode_t   fill_upper    = CUSPARSE_FILL_MODE_UPPER;
-    cusparseDiagType_t   diag_non_unit = CUSPARSE_DIAG_TYPE_NON_UNIT;
-
-    checkCudaErrors(cusparseCreateCsr(
-        &matA, N, N, nz, d_row, d_col, d_val, CUSPARSE_INDEX_32I,
-        CUSPARSE_INDEX_32I, CUSPARSE_INDEX_BASE_ZERO, CUDA_R_32F));
-
-    /* Copy A data to ILU(0) vals as input*/
-    checkCudaErrors(cudaMemcpy(
-        d_valsILU0, d_val, nz*sizeof(float), cudaMemcpyDeviceToDevice));
-    
-    //Lower Part 
-     checkCudaErrors( cusparseCreateCsr(&matM_lower, N, N, nz, d_row, d_col, d_valsILU0,
-                                      CUSPARSE_INDEX_32I, CUSPARSE_INDEX_32I,
-                                      CUSPARSE_INDEX_BASE_ZERO, CUDA_R_32F) );
-
-    checkCudaErrors( cusparseSpMatSetAttribute(matM_lower,
-                                              CUSPARSE_SPMAT_FILL_MODE,
-                                              &fill_lower, sizeof(fill_lower)) );
-    checkCudaErrors( cusparseSpMatSetAttribute(matM_lower,
-                                              CUSPARSE_SPMAT_DIAG_TYPE,
-                                              &diag_unit, sizeof(diag_unit)) );
-    // M_upper
-    checkCudaErrors( cusparseCreateCsr(&matM_upper, N, N, nz, d_row, d_col, d_valsILU0,
-                                      CUSPARSE_INDEX_32I, CUSPARSE_INDEX_32I,
-                                      CUSPARSE_INDEX_BASE_ZERO, CUDA_R_32F) );
-    checkCudaErrors( cusparseSpMatSetAttribute(matM_upper,
-                                              CUSPARSE_SPMAT_FILL_MODE,
-                                              &fill_upper, sizeof(fill_upper)) );
-    checkCudaErrors( cusparseSpMatSetAttribute(matM_upper,
-                                              CUSPARSE_SPMAT_DIAG_TYPE,
-                                              &diag_non_unit,
-                                              sizeof(diag_non_unit)) );
-
-
-    /* Create ILU(0) info object */
-    int                 bufferSizeLU = 0;
-    size_t              bufferSizeMV, bufferSizeL, bufferSizeU;
-    void*               d_bufferLU, *d_bufferMV,  *d_bufferL, *d_bufferU;
-    cusparseSpSVDescr_t spsvDescrL, spsvDescrU;
-    cusparseMatDescr_t   matLU;
-    csrilu02Info_t      infoILU = NULL;
-
-    checkCudaErrors(cusparseCreateCsrilu02Info(&infoILU));
-    checkCudaErrors( cusparseCreateMatDescr(&matLU) );
-    checkCudaErrors( cusparseSetMatType(matLU, CUSPARSE_MATRIX_TYPE_GENERAL) );
-    checkCudaErrors( cusparseSetMatIndexBase(matLU, CUSPARSE_INDEX_BASE_ZERO) );
-
-    /* Allocate workspace for cuSPARSE */
-    checkCudaErrors(cusparseSpMV_bufferSize(
-        cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matA,
-        vecp, &floatzero, vecomega, CUDA_R_32F, CUSPARSE_SPMV_ALG_DEFAULT,
-        &bufferSizeMV));
-    checkCudaErrors( cudaMalloc(&d_bufferMV, bufferSizeMV) );
-
-    checkCudaErrors(cusparseScsrilu02_bufferSize(
-        cusparseHandle, N, nz, matLU, d_val, d_row, d_col, infoILU, &bufferSizeLU));
-    checkCudaErrors( cudaMalloc(&d_bufferLU, bufferSizeLU) );
-
-    checkCudaErrors( cusparseSpSV_createDescr(&spsvDescrL) );
-    checkCudaErrors(cusparseSpSV_bufferSize(
-        cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matM_lower, vecR, vecX, CUDA_R_32F,
-        CUSPARSE_SPSV_ALG_DEFAULT, spsvDescrL, &bufferSizeL));
-    checkCudaErrors( cudaMalloc(&d_bufferL, bufferSizeL) );
-
-    checkCudaErrors( cusparseSpSV_createDescr(&spsvDescrU) );
-    checkCudaErrors( cusparseSpSV_bufferSize(
-        cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matM_upper, vecR, vecX, CUDA_R_32F,
-        CUSPARSE_SPSV_ALG_DEFAULT, spsvDescrU, &bufferSizeU));
-    checkCudaErrors( cudaMalloc(&d_bufferU, bufferSizeU) );
-
-    /* Conjugate gradient without preconditioning.
-       ------------------------------------------
-
-       Follows the description by Golub & Van Loan,
-       "Matrix Computations 3rd ed.", Section 10.2.6  */
-
-    printf("Convergence of CG without preconditioning: \n");
-    k = 0;
-    r0 = 0;
-    checkCudaErrors(cublasSdot(cublasHandle, N, d_r, 1, d_r, 1, &r1));
+  genLaplace(I, J, val, M, N, nz, rhs);
+
+  /* Create CUBLAS context */
+  cublasHandle_t cublasHandle = NULL;
+  checkCudaErrors(cublasCreate(&cublasHandle));
+
+  /* Create CUSPARSE context */
+  cusparseHandle_t cusparseHandle = NULL;
+  checkCudaErrors(cusparseCreate(&cusparseHandle));
+
+  /* Description of the A matrix */
+  cusparseMatDescr_t descr = 0;
+  checkCudaErrors(cusparseCreateMatDescr(&descr));
+  checkCudaErrors(cusparseSetMatType(descr, CUSPARSE_MATRIX_TYPE_GENERAL));
+  checkCudaErrors(cusparseSetMatIndexBase(descr, CUSPARSE_INDEX_BASE_ZERO));
+
+  /* Allocate required memory */
+  checkCudaErrors(cudaMalloc((void **)&d_col, nz * sizeof(int)));
+  checkCudaErrors(cudaMalloc((void **)&d_row, (N + 1) * sizeof(int)));
+  checkCudaErrors(cudaMalloc((void **)&d_val, nz * sizeof(float)));
+  checkCudaErrors(cudaMalloc((void **)&d_x, N * sizeof(float)));
+  checkCudaErrors(cudaMalloc((void **)&d_y, N * sizeof(float)));
+  checkCudaErrors(cudaMalloc((void **)&d_r, N * sizeof(float)));
+  checkCudaErrors(cudaMalloc((void **)&d_p, N * sizeof(float)));
+  checkCudaErrors(cudaMalloc((void **)&d_omega, N * sizeof(float)));
+  checkCudaErrors(cudaMalloc((void **)&d_valsILU0, nz * sizeof(float)));
+  checkCudaErrors(cudaMalloc((void **)&d_zm1, (N) * sizeof(float)));
+  checkCudaErrors(cudaMalloc((void **)&d_zm2, (N) * sizeof(float)));
+  checkCudaErrors(cudaMalloc((void **)&d_rm2, (N) * sizeof(float)));
+
+  /* Wrap raw data into cuSPARSE generic API objects */
+  cusparseSpMatDescr_t matA = NULL;
+  checkCudaErrors(cusparseCreateCsr(&matA, N, N, nz, d_row, d_col, d_val,
+                                    CUSPARSE_INDEX_32I, CUSPARSE_INDEX_32I,
+                                    CUSPARSE_INDEX_BASE_ZERO, CUDA_R_32F));
+  cusparseDnVecDescr_t vecp = NULL;
+  checkCudaErrors(cusparseCreateDnVec(&vecp, N, d_p, CUDA_R_32F));
+  cusparseDnVecDescr_t vecomega = NULL;
+  checkCudaErrors(cusparseCreateDnVec(&vecomega, N, d_omega, CUDA_R_32F));
+
+  /* Initialize problem data */
+  checkCudaErrors(
+      cudaMemcpy(d_col, J, nz * sizeof(int), cudaMemcpyHostToDevice));
+  checkCudaErrors(
+      cudaMemcpy(d_row, I, (N + 1) * sizeof(int), cudaMemcpyHostToDevice));
+  checkCudaErrors(
+      cudaMemcpy(d_val, val, nz * sizeof(float), cudaMemcpyHostToDevice));
+  checkCudaErrors(
+      cudaMemcpy(d_x, x, N * sizeof(float), cudaMemcpyHostToDevice));
+  checkCudaErrors(
+      cudaMemcpy(d_r, rhs, N * sizeof(float), cudaMemcpyHostToDevice));
+  checkCudaErrors(cudaMemset(d_y, 0, sizeof(float) * N));
+
+  /* Create ILU(0) info object */
+  csrilu02Info_t infoILU = NULL;
+  checkCudaErrors(cusparseCreateCsrilu02Info(&infoILU));
+
+  /* Create L factor descriptor and triangular solve info */
+  cusparseMatDescr_t descrL = NULL;
+  checkCudaErrors(cusparseCreateMatDescr(&descrL));
+  checkCudaErrors(cusparseSetMatType(descrL, CUSPARSE_MATRIX_TYPE_GENERAL));
+  checkCudaErrors(cusparseSetMatIndexBase(descrL, CUSPARSE_INDEX_BASE_ZERO));
+  checkCudaErrors(cusparseSetMatFillMode(descrL, CUSPARSE_FILL_MODE_LOWER));
+  checkCudaErrors(cusparseSetMatDiagType(descrL, CUSPARSE_DIAG_TYPE_UNIT));
+  csrsv2Info_t infoL = NULL;
+  checkCudaErrors(cusparseCreateCsrsv2Info(&infoL));
+
+  /* Create U factor descriptor and triangular solve info */
+  cusparseMatDescr_t descrU = NULL;
+  checkCudaErrors(cusparseCreateMatDescr(&descrU));
+  checkCudaErrors(cusparseSetMatType(descrU, CUSPARSE_MATRIX_TYPE_GENERAL));
+  checkCudaErrors(cusparseSetMatIndexBase(descrU, CUSPARSE_INDEX_BASE_ZERO));
+  checkCudaErrors(cusparseSetMatFillMode(descrU, CUSPARSE_FILL_MODE_UPPER));
+  checkCudaErrors(cusparseSetMatDiagType(descrU, CUSPARSE_DIAG_TYPE_NON_UNIT));
+  csrsv2Info_t infoU = NULL;
+  checkCudaErrors(cusparseCreateCsrsv2Info(&infoU));
+
+  /* Allocate workspace for cuSPARSE */
+  size_t bufferSize = 0;
+  size_t tmp = 0;
+  int stmp = 0;
+  checkCudaErrors(cusparseSpMV_bufferSize(
+      cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matA, vecp,
+      &floatzero, vecomega, CUDA_R_32F, CUSPARSE_SPMV_ALG_DEFAULT, &tmp));
+  if (tmp > bufferSize) {
+    bufferSize = stmp;
+  }
+  checkCudaErrors(cusparseScsrilu02_bufferSize(
+      cusparseHandle, N, nz, descr, d_val, d_row, d_col, infoILU, &stmp));
+  if (stmp > bufferSize) {
+    bufferSize = stmp;
+  }
+  checkCudaErrors(cusparseScsrsv2_bufferSize(
+      cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, N, nz, descrL, d_val,
+      d_row, d_col, infoL, &stmp));
+  if (stmp > bufferSize) {
+    bufferSize = stmp;
+  }
+  checkCudaErrors(cusparseScsrsv2_bufferSize(
+      cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, N, nz, descrU, d_val,
+      d_row, d_col, infoU, &stmp));
+  if (stmp > bufferSize) {
+    bufferSize = stmp;
+  }
+  checkCudaErrors(cudaMalloc(&buffer, bufferSize));
 
-    while (r1 > tol * tol && k <= max_iter)
-    {
-        k++;
-
-        if (k == 1)
-        {
-            checkCudaErrors(cublasScopy(cublasHandle, N, d_r, 1, d_p, 1));
-        }
-        else
-        {
-            beta = r1 / r0;
-            checkCudaErrors(cublasSscal(cublasHandle, N, &beta, d_p, 1));
-            checkCudaErrors(cublasSaxpy(
-                cublasHandle, N, &floatone, d_r, 1, d_p, 1));
-        }
-
-        checkCudaErrors(cusparseSpMV(
-            cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matA,
-            vecp, &floatzero, vecomega, CUDA_R_32F, CUSPARSE_SPMV_ALG_DEFAULT,
-            d_bufferMV));
-        checkCudaErrors(cublasSdot(cublasHandle, N, d_p, 1, d_omega, 1, &dot));
-        alpha = r1 / dot;
-        checkCudaErrors(cublasSaxpy(cublasHandle, N, &alpha, d_p, 1, d_x, 1));
-        nalpha = -alpha;
-        checkCudaErrors(cublasSaxpy(
-            cublasHandle, N, &nalpha, d_omega, 1, d_r, 1));
-        r0 = r1;
-        checkCudaErrors(cublasSdot(cublasHandle, N, d_r, 1, d_r, 1, &r1));
-    }
+  /* Conjugate gradient without preconditioning.
+     ------------------------------------------
+
+     Follows the description by Golub & Van Loan,
+     "Matrix Computations 3rd ed.", Section 10.2.6  */
+
+  printf("Convergence of CG without preconditioning: \n");
+  k = 0;
+  r0 = 0;
+  checkCudaErrors(cublasSdot(cublasHandle, N, d_r, 1, d_r, 1, &r1));
 
-    printf("  iteration = %3d, residual = %e \n", k, sqrt(r1));
+  while (r1 > tol * tol && k <= max_iter) {
+    k++;
 
-    checkCudaErrors(cudaMemcpy(
-        x, d_x, N * sizeof(float), cudaMemcpyDeviceToHost));
+    if (k == 1) {
+      checkCudaErrors(cublasScopy(cublasHandle, N, d_r, 1, d_p, 1));
+    } else {
+      beta = r1 / r0;
+      checkCudaErrors(cublasSscal(cublasHandle, N, &beta, d_p, 1));
+      checkCudaErrors(cublasSaxpy(cublasHandle, N, &floatone, d_r, 1, d_p, 1));
+    }
 
-    /* check result */
-    err = 0.0;
+    checkCudaErrors(cusparseSpMV(
+        cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matA, vecp,
+        &floatzero, vecomega, CUDA_R_32F, CUSPARSE_SPMV_ALG_DEFAULT, buffer));
+    checkCudaErrors(cublasSdot(cublasHandle, N, d_p, 1, d_omega, 1, &dot));
+    alpha = r1 / dot;
+    checkCudaErrors(cublasSaxpy(cublasHandle, N, &alpha, d_p, 1, d_x, 1));
+    nalpha = -alpha;
+    checkCudaErrors(cublasSaxpy(cublasHandle, N, &nalpha, d_omega, 1, d_r, 1));
+    r0 = r1;
+    checkCudaErrors(cublasSdot(cublasHandle, N, d_r, 1, d_r, 1, &r1));
+  }
 
-    for (int i = 0; i < N; i++)
-    {
-        rsum = 0.0;
+  printf("  iteration = %3d, residual = %e \n", k, sqrt(r1));
 
-        for (int j = I[i]; j < I[i + 1]; j++)
-        {
-            rsum += val[j] * x[J[j]];
-        }
+  checkCudaErrors(
+      cudaMemcpy(x, d_x, N * sizeof(float), cudaMemcpyDeviceToHost));
 
-        diff = fabs(rsum - rhs[i]);
+  /* check result */
+  err = 0.0;
 
-        if (diff > err)
-        {
-            err = diff;
-        }
-    }
+  for (int i = 0; i < N; i++) {
+    rsum = 0.0;
 
-    printf("  Convergence Test: %s \n", (k <= max_iter) ? "OK" : "FAIL");
-    nErrors += (k > max_iter) ? 1 : 0;
-    qaerr1 = err;
-
-    if (0)
-    {
-        // output result in matlab-style array
-        int n = (int)sqrt((double)N);
-        printf("a = [  ");
-
-        for (int iy = 0; iy < n; iy++)
-        {
-            for (int ix = 0; ix < n; ix++)
-            {
-                printf(" %f ", x[iy * n + ix]);
-            }
-
-            if (iy == n - 1)
-            {
-                printf(" ]");
-            }
-
-            printf("\n");
-        }
+    for (int j = I[i]; j < I[i + 1]; j++) {
+      rsum += val[j] * x[J[j]];
     }
 
+    diff = fabs(rsum - rhs[i]);
 
-    /* Preconditioned Conjugate Gradient using ILU.
-       --------------------------------------------
-       Follows the description by Golub & Van Loan,
-       "Matrix Computations 3rd ed.", Algorithm 10.3.1  */
+    if (diff > err) {
+      err = diff;
+    }
+  }
 
-    printf("\nConvergence of CG using ILU(0) preconditioning: \n");
+  printf("  Convergence Test: %s \n", (k <= max_iter) ? "OK" : "FAIL");
+  nErrors += (k > max_iter) ? 1 : 0;
+  qaerr1 = err;
 
-    /* Perform analysis for ILU(0) */
-    checkCudaErrors(cusparseScsrilu02_analysis(
-        cusparseHandle, N, nz, descr, d_valsILU0, d_row, d_col, infoILU,
-        CUSPARSE_SOLVE_POLICY_USE_LEVEL, d_bufferLU));
+  if (0) {
+    // output result in matlab-style array
+    int n = (int)sqrt((double)N);
+    printf("a = [  ");
 
-    /* generate the ILU(0) factors */
-    checkCudaErrors(cusparseScsrilu02(
-        cusparseHandle, N, nz, matLU, d_valsILU0, d_row, d_col, infoILU,
-        CUSPARSE_SOLVE_POLICY_USE_LEVEL, d_bufferLU));
+    for (int iy = 0; iy < n; iy++) {
+      for (int ix = 0; ix < n; ix++) {
+        printf(" %f ", x[iy * n + ix]);
+      }
 
-    /* perform triangular solve analysis */
-    checkCudaErrors(cusparseSpSV_analysis(
-        cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, &floatone,
-        matM_lower, vecR, vecX, CUDA_R_32F,
-        CUSPARSE_SPSV_ALG_DEFAULT, spsvDescrL, d_bufferL));
+      if (iy == n - 1) {
+        printf(" ]");
+      }
 
-    checkCudaErrors(cusparseSpSV_analysis(
-        cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, &floatone,
-        matM_upper, vecR, vecX, CUDA_R_32F,
-        CUSPARSE_SPSV_ALG_DEFAULT, spsvDescrU, d_bufferU));
+      printf("\n");
+    }
+  }
 
-    /* reset the initial guess of the solution to zero */
-    for (int i = 0; i < N; i++)
-    {
-        x[i] = 0.0;
+  /* Preconditioned Conjugate Gradient using ILU.
+     --------------------------------------------
+     Follows the description by Golub & Van Loan,
+     "Matrix Computations 3rd ed.", Algorithm 10.3.1  */
+
+  printf("\nConvergence of CG using ILU(0) preconditioning: \n");
+
+  /* Perform analysis for ILU(0) */
+  checkCudaErrors(cusparseScsrilu02_analysis(
+      cusparseHandle, N, nz, descr, d_val, d_row, d_col, infoILU,
+      CUSPARSE_SOLVE_POLICY_USE_LEVEL, buffer));
+
+  /* Copy A data to ILU(0) vals as input*/
+  checkCudaErrors(cudaMemcpy(d_valsILU0, d_val, nz * sizeof(float),
+                             cudaMemcpyDeviceToDevice));
+
+  /* generate the ILU(0) factors */
+  checkCudaErrors(cusparseScsrilu02(cusparseHandle, N, nz, descr, d_valsILU0,
+                                    d_row, d_col, infoILU,
+                                    CUSPARSE_SOLVE_POLICY_USE_LEVEL, buffer));
+
+  /* perform triangular solve analysis */
+  checkCudaErrors(
+      cusparseScsrsv2_analysis(cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE,
+                               N, nz, descrL, d_valsILU0, d_row, d_col, infoL,
+                               CUSPARSE_SOLVE_POLICY_USE_LEVEL, buffer));
+  checkCudaErrors(
+      cusparseScsrsv2_analysis(cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE,
+                               N, nz, descrU, d_valsILU0, d_row, d_col, infoU,
+                               CUSPARSE_SOLVE_POLICY_USE_LEVEL, buffer));
+
+  /* reset the initial guess of the solution to zero */
+  for (int i = 0; i < N; i++) {
+    x[i] = 0.0;
+  }
+  checkCudaErrors(
+      cudaMemcpy(d_r, rhs, N * sizeof(float), cudaMemcpyHostToDevice));
+  checkCudaErrors(
+      cudaMemcpy(d_x, x, N * sizeof(float), cudaMemcpyHostToDevice));
+
+  k = 0;
+  checkCudaErrors(cublasSdot(cublasHandle, N, d_r, 1, d_r, 1, &r1));
+
+  while (r1 > tol * tol && k <= max_iter) {
+    // preconditioner application: d_zm1 = U^-1 L^-1 d_r
+    checkCudaErrors(cusparseScsrsv2_solve(
+        cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, N, nz, &floatone,
+        descrL, d_valsILU0, d_row, d_col, infoL, d_r, d_y,
+        CUSPARSE_SOLVE_POLICY_USE_LEVEL, buffer));
+    checkCudaErrors(cusparseScsrsv2_solve(
+        cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, N, nz, &floatone,
+        descrU, d_valsILU0, d_row, d_col, infoU, d_y, d_zm1,
+        CUSPARSE_SOLVE_POLICY_USE_LEVEL, buffer));
+
+    k++;
+
+    if (k == 1) {
+      checkCudaErrors(cublasScopy(cublasHandle, N, d_zm1, 1, d_p, 1));
+    } else {
+      checkCudaErrors(
+          cublasSdot(cublasHandle, N, d_r, 1, d_zm1, 1, &numerator));
+      checkCudaErrors(
+          cublasSdot(cublasHandle, N, d_rm2, 1, d_zm2, 1, &denominator));
+      beta = numerator / denominator;
+      checkCudaErrors(cublasSscal(cublasHandle, N, &beta, d_p, 1));
+      checkCudaErrors(
+          cublasSaxpy(cublasHandle, N, &floatone, d_zm1, 1, d_p, 1));
     }
-    checkCudaErrors(cudaMemcpy(
-        d_r, rhs, N * sizeof(float), cudaMemcpyHostToDevice));
-    checkCudaErrors(cudaMemcpy(
-        d_x, x, N * sizeof(float), cudaMemcpyHostToDevice));
 
-    k = 0;
+    checkCudaErrors(cusparseSpMV(
+        cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matA, vecp,
+        &floatzero, vecomega, CUDA_R_32F, CUSPARSE_SPMV_ALG_DEFAULT, buffer));
+    checkCudaErrors(cublasSdot(cublasHandle, N, d_r, 1, d_zm1, 1, &numerator));
+    checkCudaErrors(
+        cublasSdot(cublasHandle, N, d_p, 1, d_omega, 1, &denominator));
+    alpha = numerator / denominator;
+    checkCudaErrors(cublasSaxpy(cublasHandle, N, &alpha, d_p, 1, d_x, 1));
+    checkCudaErrors(cublasScopy(cublasHandle, N, d_r, 1, d_rm2, 1));
+    checkCudaErrors(cublasScopy(cublasHandle, N, d_zm1, 1, d_zm2, 1));
+    nalpha = -alpha;
+    checkCudaErrors(cublasSaxpy(cublasHandle, N, &nalpha, d_omega, 1, d_r, 1));
     checkCudaErrors(cublasSdot(cublasHandle, N, d_r, 1, d_r, 1, &r1));
+  }
 
-    while (r1 > tol * tol && k <= max_iter)
-    {
-        // preconditioner application: d_zm1 = U^-1 L^-1 d_r
-        checkCudaErrors(cusparseSpSV_solve(cusparseHandle,
-            CUSPARSE_OPERATION_NON_TRANSPOSE, &floatone,
-            matM_lower, vecR, vecY, CUDA_R_32F,
-            CUSPARSE_SPSV_ALG_DEFAULT,
-            spsvDescrL) );
-            
-        checkCudaErrors(cusparseSpSV_solve(cusparseHandle,
-            CUSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matM_upper,
-            vecY, vecZM1,
-            CUDA_R_32F,
-            CUSPARSE_SPSV_ALG_DEFAULT,
-            spsvDescrU));
-        k++;
-
-        if (k == 1)
-        {
-            checkCudaErrors(cublasScopy(cublasHandle, N, d_zm1, 1, d_p, 1));
-        }
-        else
-        {
-            checkCudaErrors(cublasSdot(
-                cublasHandle, N, d_r, 1, d_zm1, 1, &numerator));
-            checkCudaErrors(cublasSdot(
-                cublasHandle, N, d_rm2, 1, d_zm2, 1, &denominator));
-            beta = numerator / denominator;
-            checkCudaErrors(cublasSscal(cublasHandle, N, &beta, d_p, 1));
-            checkCudaErrors(cublasSaxpy(
-                cublasHandle, N, &floatone, d_zm1, 1, d_p, 1));
-        }
-
-        checkCudaErrors(cusparseSpMV(
-            cusparseHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matA,
-            vecp, &floatzero, vecomega, CUDA_R_32F, CUSPARSE_SPMV_ALG_DEFAULT,
-            d_bufferMV));
-        checkCudaErrors(cublasSdot(
-            cublasHandle, N, d_r, 1, d_zm1, 1, &numerator));
-        checkCudaErrors(cublasSdot(
-            cublasHandle, N, d_p, 1, d_omega, 1, &denominator));
-        alpha = numerator / denominator;
-        checkCudaErrors(cublasSaxpy(cublasHandle, N, &alpha, d_p, 1, d_x, 1));
-        checkCudaErrors(cublasScopy(cublasHandle, N, d_r, 1, d_rm2, 1));
-        checkCudaErrors(cublasScopy(cublasHandle, N, d_zm1, 1, d_zm2, 1));
-        nalpha = -alpha;
-        checkCudaErrors(cublasSaxpy(
-            cublasHandle, N, &nalpha, d_omega, 1, d_r, 1));
-        checkCudaErrors(cublasSdot(cublasHandle, N, d_r, 1, d_r, 1, &r1));
-    }
-
-    printf("  iteration = %3d, residual = %e \n", k, sqrt(r1));
+  printf("  iteration = %3d, residual = %e \n", k, sqrt(r1));
 
-    checkCudaErrors(cudaMemcpy(
-        x, d_x, N * sizeof(float), cudaMemcpyDeviceToHost));
+  checkCudaErrors(
+      cudaMemcpy(x, d_x, N * sizeof(float), cudaMemcpyDeviceToHost));
 
-    /* check result */
-    err = 0.0;
+  /* check result */
+  err = 0.0;
 
-    for (int i = 0; i < N; i++)
-    {
-        rsum = 0.0;
+  for (int i = 0; i < N; i++) {
+    rsum = 0.0;
 
-        for (int j = I[i]; j < I[i + 1]; j++)
-        {
-            rsum += val[j] * x[J[j]];
-        }
+    for (int j = I[i]; j < I[i + 1]; j++) {
+      rsum += val[j] * x[J[j]];
+    }
 
-        diff = fabs(rsum - rhs[i]);
+    diff = fabs(rsum - rhs[i]);
 
-        if (diff > err)
-        {
-            err = diff;
-        }
+    if (diff > err) {
+      err = diff;
     }
+  }
 
-    printf("  Convergence Test: %s \n", (k <= max_iter) ? "OK" : "FAIL");
-    nErrors += (k > max_iter) ? 1 : 0;
-    qaerr2 = err;
-
-    /* Destroy descriptors */
-    checkCudaErrors(cusparseDestroyCsrilu02Info(infoILU));
-    checkCudaErrors(cusparseDestroyMatDescr(matLU));
-    checkCudaErrors(cusparseSpSV_destroyDescr(spsvDescrL));
-    checkCudaErrors(cusparseSpSV_destroyDescr(spsvDescrU));
-    checkCudaErrors(cusparseDestroySpMat(matM_lower));
-    checkCudaErrors(cusparseDestroySpMat(matM_upper));
-    checkCudaErrors(cusparseDestroySpMat(matA));
-    checkCudaErrors(cusparseDestroyDnVec(vecp));
-    checkCudaErrors(cusparseDestroyDnVec(vecomega));
-    checkCudaErrors(cusparseDestroyDnVec(vecR));
-    checkCudaErrors(cusparseDestroyDnVec(vecX));
-    checkCudaErrors(cusparseDestroyDnVec(vecY));
-    checkCudaErrors(cusparseDestroyDnVec(vecZM1));
-
-    /* Destroy contexts */
-    checkCudaErrors(cusparseDestroy(cusparseHandle));
-    checkCudaErrors(cublasDestroy(cublasHandle));
-
-    /* Free device memory */
-    free(I);
-    free(J);
-    free(val);
-    free(x);
-    free(rhs);
-    checkCudaErrors(cudaFree(d_bufferMV));
-    checkCudaErrors(cudaFree(d_bufferLU));
-    checkCudaErrors(cudaFree(d_bufferL));
-    checkCudaErrors(cudaFree(d_bufferU));
-    checkCudaErrors(cudaFree(d_col));
-    checkCudaErrors(cudaFree(d_row));
-    checkCudaErrors(cudaFree(d_val));
-    checkCudaErrors(cudaFree(d_x));
-    checkCudaErrors(cudaFree(d_y));
-    checkCudaErrors(cudaFree(d_r));
-    checkCudaErrors(cudaFree(d_p));
-    checkCudaErrors(cudaFree(d_omega));
-    checkCudaErrors(cudaFree(d_valsILU0));
-    checkCudaErrors(cudaFree(d_zm1));
-    checkCudaErrors(cudaFree(d_zm2));
-    checkCudaErrors(cudaFree(d_rm2));
-
-    // cudaDeviceReset causes the driver to clean up all state. While
-    // not mandatory in normal operation, it is good practice.  It is also
-    // needed to ensure correct operation when the application is being
-    // profiled. Calling cudaDeviceReset causes all profile data to be
-    // flushed before the application exits
-    cudaDeviceReset();
-
-    printf("\n");
-    printf("Test Summary:\n");
-    printf("   Counted total of %d errors\n", nErrors);
-    printf("   qaerr1 = %f qaerr2 = %f\n\n", fabs(qaerr1), fabs(qaerr2));
-    exit((nErrors == 0 &&fabs(qaerr1) < 1e-5 && fabs(qaerr2) < 1e-5
-        ? EXIT_SUCCESS
-        : EXIT_FAILURE));
+  printf("  Convergence Test: %s \n", (k <= max_iter) ? "OK" : "FAIL");
+  nErrors += (k > max_iter) ? 1 : 0;
+  qaerr2 = err;
+
+  /* Destroy descriptors */
+  checkCudaErrors(cusparseDestroyCsrsv2Info(infoU));
+  checkCudaErrors(cusparseDestroyCsrsv2Info(infoL));
+  checkCudaErrors(cusparseDestroyCsrilu02Info(infoILU));
+  checkCudaErrors(cusparseDestroyMatDescr(descrL));
+  checkCudaErrors(cusparseDestroyMatDescr(descrU));
+  checkCudaErrors(cusparseDestroyMatDescr(descr));
+  checkCudaErrors(cusparseDestroySpMat(matA));
+  checkCudaErrors(cusparseDestroyDnVec(vecp));
+  checkCudaErrors(cusparseDestroyDnVec(vecomega));
+
+  /* Destroy contexts */
+  checkCudaErrors(cusparseDestroy(cusparseHandle));
+  checkCudaErrors(cublasDestroy(cublasHandle));
+
+  /* Free device memory */
+  free(I);
+  free(J);
+  free(val);
+  free(x);
+  free(rhs);
+  checkCudaErrors(cudaFree(buffer));
+  checkCudaErrors(cudaFree(d_col));
+  checkCudaErrors(cudaFree(d_row));
+  checkCudaErrors(cudaFree(d_val));
+  checkCudaErrors(cudaFree(d_x));
+  checkCudaErrors(cudaFree(d_y));
+  checkCudaErrors(cudaFree(d_r));
+  checkCudaErrors(cudaFree(d_p));
+  checkCudaErrors(cudaFree(d_omega));
+  checkCudaErrors(cudaFree(d_valsILU0));
+  checkCudaErrors(cudaFree(d_zm1));
+  checkCudaErrors(cudaFree(d_zm2));
+  checkCudaErrors(cudaFree(d_rm2));
+
+  printf("\n");
+  printf("Test Summary:\n");
+  printf("   Counted total of %d errors\n", nErrors);
+  printf("   qaerr1 = %f qaerr2 = %f\n\n", fabs(qaerr1), fabs(qaerr2));
+  exit((nErrors == 0 && fabs(qaerr1) < 1e-5 && fabs(qaerr2) < 1e-5
+            ? EXIT_SUCCESS
+            : EXIT_FAILURE));
 }
-
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/main_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/main_hipified.cpp
index 74f97a2..bd63ca8 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/main_hipified.cpp
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/main_hipified.cpp
@@ -42,101 +42,87 @@
  * benchmarking purposes.
  */
 
-
 // includes, system
-#include <stdlib.h>
+#include <math.h>
 #include <stdio.h>
+#include <stdlib.h>
 #include <string.h>
-#include <math.h>
 
 // CUDA Runtime
 #include <hip/hip_runtime.h>
 
 // Using updated (v2) interfaces for CUBLAS and CUSPARSE
-#include <hipsparse.h>
 #include <hipblas.h>
+#include <hipsparse.h>
 
 // Utilities and system includes
-#include "helper_functions.h"  // shared functions common to CUDA Samples
 #include "helper_cuda_hipified.h"       // CUDA error checking
+#include "helper_functions.h"  // shared functions common to CUDA Samples
 
-const char *sSDKname     = "conjugateGradientPrecond";
+const char *sSDKname = "conjugateGradientPrecond";
 
 /*
  * Generate a matrix representing a second order regular Laplacian operator
  * on a 2D domain in Compressed Sparse Row format.
  */
 void genLaplace(int *row_ptr, int *col_ind, float *val, int M, int N, int nz,
-                float *rhs)
-{
-    assert(M==N);
-    int n=(int)sqrt((double)N);
-    assert(n*n==N);
-    printf("laplace dimension = %d\n", n);
-    int idx = 0;
-
-    // loop over degrees of freedom
-    for (int i = 0; i < N; i++)
-    {
-        int ix = i % n;
-        int iy = i / n;
-
-        row_ptr[i] = idx;
-
-        // up
-        if (iy > 0)
-        {
-            val[idx] = 1.0;
-            col_ind[idx] = i - n;
-            idx++;
-        }
-        else
-        {
-            rhs[i] -= 1.0;
-        }
-
-        // left
-        if (ix > 0) {
-            val[idx] = 1.0;
-            col_ind[idx] = i - 1;
-            idx++;
-        } else {
-            rhs[i] -= 0.0;
-        }
-
-        // center
-        val[idx] = -4.0;
-        col_ind[idx] = i;
-        idx++;
-
-        //right
-        if (ix  < n - 1)
-        {
-            val[idx] = 1.0;
-            col_ind[idx] = i + 1;
-            idx++;
-        }
-        else
-        {
-            rhs[i] -= 0.0;
-        }
-
-        // down
-        if (iy  < n - 1)
-        {
-            val[idx] = 1.0;
-            col_ind[idx] = i + n;
-            idx++;
-        }
-        else
-        {
-            rhs[i] -= 0.0;
-        }
+                float *rhs) {
+  assert(M == N);
+  int n = (int)sqrt((double)N);
+  assert(n * n == N);
+  printf("laplace dimension = %d\n", n);
+  int idx = 0;
+
+  // loop over degrees of freedom
+  for (int i = 0; i < N; i++) {
+    int ix = i % n;
+    int iy = i / n;
+
+    row_ptr[i] = idx;
+
+    // up
+    if (iy > 0) {
+      val[idx] = 1.0;
+      col_ind[idx] = i - n;
+      idx++;
+    } else {
+      rhs[i] -= 1.0;
+    }
 
+    // left
+    if (ix > 0) {
+      val[idx] = 1.0;
+      col_ind[idx] = i - 1;
+      idx++;
+    } else {
+      rhs[i] -= 0.0;
     }
 
-    row_ptr[N] = idx;
+    // center
+    val[idx] = -4.0;
+    col_ind[idx] = i;
+    idx++;
+
+    // right
+    if (ix < n - 1) {
+      val[idx] = 1.0;
+      col_ind[idx] = i + 1;
+      idx++;
+    } else {
+      rhs[i] -= 0.0;
+    }
 
+    // down
+    if (iy < n - 1) {
+      val[idx] = 1.0;
+      col_ind[idx] = i + n;
+      idx++;
+    } else {
+      rhs[i] -= 0.0;
+    }
+  }
+
+  row_ptr[N] = idx;
 }
 
 /*
@@ -145,464 +131,401 @@ void genLaplace(int *row_ptr, int *col_ind, float *val, int M, int N, int nz,
  * b) using an Incomplete Cholesky preconditioner, and
  * c) using an ILU0 preconditioner.
  */
-int main(int argc, char **argv){
-    const int max_iter = 1000;
-    int k, M = 0, N = 0, nz = 0, *I = NULL, *J = NULL;
-    int *d_col, *d_row;
-    int qatest = 0;
-    const float tol = 1e-12f;
-    float *x, *rhs;
-    float r0, r1, alpha, beta;
-    float *d_val, *d_x;
-    float *d_zm1, *d_zm2, *d_rm2;
-    float *d_r, *d_p, *d_omega, *d_y;
-    float *val = NULL;
-    float *d_valsILU0;
-    float rsum, diff, err = 0.0;
-    float qaerr1, qaerr2 = 0.0;
-    float dot, numerator, denominator, nalpha;
-    const float floatone = 1.0;
-    const float floatzero = 0.0;
-
-    int nErrors = 0;
-
-    printf("conjugateGradientPrecond starting...\n");
-
-      /* QA testing mode */
+int main(int argc, char **argv) {
+  const int max_iter = 1000;
+  int k, M = 0, N = 0, nz = 0, *I = NULL, *J = NULL;
+  int *d_col, *d_row;
+  int qatest = 0;
+  const float tol = 1e-12f;
+  float *x, *rhs;
+  float r0, r1, alpha, beta;
+  float *d_val, *d_x;
+  float *d_zm1, *d_zm2, *d_rm2;
+  float *d_r, *d_p, *d_omega, *d_y;
+  float *val = NULL;
+  float *d_valsILU0;
+  void *buffer = NULL;
+  float rsum, diff, err = 0.0;
+  float qaerr1, qaerr2 = 0.0;
+  float dot, numerator, denominator, nalpha;
+  const float floatone = 1.0;
+  const float floatzero = 0.0;
+
+  int nErrors = 0;
+
+  printf("conjugateGradientPrecond starting...\n");
+
+  /* QA testing mode */
   if (checkCmdLineFlag(argc, (const char **)argv, "qatest")) {
     qatest = 1;
   }
 
-    /* This will pick the best possible CUDA capable device */
-    hipDeviceProp_t deviceProp;
-    int devID = findCudaDevice(argc, (const char **)argv);
-    printf("GPU selected Device ID = %d \n", devID);
+  /* This will pick the best possible CUDA capable device */
+  hipDeviceProp_t deviceProp;
+  int devID = findCudaDevice(argc, (const char **)argv);
+  printf("GPU selected Device ID = %d \n", devID);
 
-    if (devID < 0)
-    {
-        printf("Invalid GPU device %d selected,  exiting...\n", devID);
-        exit(EXIT_SUCCESS);
-    }
+  if (devID < 0) {
+    printf("Invalid GPU device %d selected,  exiting...\n", devID);
+    exit(EXIT_SUCCESS);
+  }
 
-    checkCudaErrors(hipGetDeviceProperties(&deviceProp, devID));
-
-    /* Statistics about the GPU device */
-    printf("> GPU device has %d Multi-Processors, SM %d.%d compute capabilities\n\n",
-           deviceProp.multiProcessorCount, deviceProp.major, deviceProp.minor);
-
-    /* Generate a Laplace matrix in CSR (Compressed Sparse Row) format */
-    M = N = 16384;
-    nz = 5 * N - 4 * (int)sqrt((double)N);
-    I = (int *)malloc(sizeof(int) * (N + 1));   // csr row pointers for matrix A
-    J = (int *)malloc(sizeof(int) * nz);       // csr column indices for matrix A
-    val = (float *)malloc(sizeof(float) * nz); // csr values for matrix A
-    x = (float *)malloc(sizeof(float) * N);
-    rhs = (float *)malloc(sizeof(float) * N);
-
-    for (int i = 0; i < N; i++)
-    {
-        rhs[i] = 0.0;  // Initialize RHS
-        x[i] = 0.0;    // Initial solution approximation
-    }
+  checkCudaErrors(hipGetDeviceProperties(&deviceProp, devID));
+
+  /* Statistics about the GPU device */
+  printf(
+      "> GPU device has %d Multi-Processors, "
+      "SM %d.%d compute capabilities\n\n",
+      deviceProp.multiProcessorCount, deviceProp.major, deviceProp.minor);
+
+  /* Generate a Laplace matrix in CSR (Compressed Sparse Row) format */
+  M = N = 16384;
+  nz = 5 * N - 4 * (int)sqrt((double)N);
+  I = (int *)malloc(sizeof(int) * (N + 1));   // csr row pointers for matrix A
+  J = (int *)malloc(sizeof(int) * nz);        // csr column indices for matrix A
+  val = (float *)malloc(sizeof(float) * nz);  // csr values for matrix A
+  x = (float *)malloc(sizeof(float) * N);
+  rhs = (float *)malloc(sizeof(float) * N);
+
+  for (int i = 0; i < N; i++) {
+    rhs[i] = 0.0;  // Initialize RHS
+    x[i] = 0.0;    // Initial solution approximation
+  }
 
-    genLaplace(I, J, val, M, N, nz, rhs);
-
-    /* Create CUBLAS context */
-    hipblasHandle_t cublasHandle = NULL;
-    checkCudaErrors(hipblasCreate(&cublasHandle));
-
-    /* Create CUSPARSE context */
-    hipsparseHandle_t cusparseHandle = NULL;
-    checkCudaErrors(hipsparseCreate(&cusparseHandle));
-
-    /* Description of the A matrix */
-    hipsparseMatDescr_t descr = 0;
-    checkCudaErrors(hipsparseCreateMatDescr(&descr));
-    checkCudaErrors(hipsparseSetMatType(descr, HIPSPARSE_MATRIX_TYPE_GENERAL));
-    checkCudaErrors(hipsparseSetMatIndexBase(descr, HIPSPARSE_INDEX_BASE_ZERO));
-
-    /* Allocate required memory */
-    checkCudaErrors(hipMalloc((void **)&d_col, nz * sizeof(int)));
-    checkCudaErrors(hipMalloc((void **)&d_row, (N + 1) * sizeof(int)));
-    checkCudaErrors(hipMalloc((void **)&d_val, nz * sizeof(float)));
-    checkCudaErrors(hipMalloc((void **)&d_x, N * sizeof(float)));
-    checkCudaErrors(hipMalloc((void **)&d_y, N * sizeof(float)));
-    checkCudaErrors(hipMalloc((void **)&d_r, N * sizeof(float)));
-    checkCudaErrors(hipMalloc((void **)&d_p, N * sizeof(float)));
-    checkCudaErrors(hipMalloc((void **)&d_omega, N * sizeof(float)));
-    checkCudaErrors(hipMalloc((void **)&d_valsILU0, nz * sizeof(float)));
-    checkCudaErrors(hipMalloc((void **)&d_zm1, (N) * sizeof(float)));
-    checkCudaErrors(hipMalloc((void **)&d_zm2, (N) * sizeof(float)));
-    checkCudaErrors(hipMalloc((void **)&d_rm2, (N) * sizeof(float)));
-
-    /* Wrap raw data into cuSPARSE generic API objects */
-    hipsparseDnVecDescr_t vecp = NULL, vecX=NULL, vecY = NULL, vecR = NULL, vecZM1=NULL;
-    checkCudaErrors(hipsparseCreateDnVec(&vecp, N, d_p, HIPBLAS_R_32F));
-    checkCudaErrors(hipsparseCreateDnVec(&vecX, N, d_x, HIPBLAS_R_32F));
-    checkCudaErrors(hipsparseCreateDnVec(&vecY, N, d_y, HIPBLAS_R_32F));
-    checkCudaErrors(hipsparseCreateDnVec(&vecR, N, d_r, HIPBLAS_R_32F));
-    checkCudaErrors(hipsparseCreateDnVec(&vecZM1, N, d_zm1, HIPBLAS_R_32F));
-    hipsparseDnVecDescr_t vecomega = NULL;
-    checkCudaErrors(hipsparseCreateDnVec(&vecomega, N, d_omega, HIPBLAS_R_32F));
-
-    /* Initialize problem data */
-    checkCudaErrors(hipMemcpy(
-        d_col, J, nz * sizeof(int), hipMemcpyHostToDevice));
-    checkCudaErrors(hipMemcpy(
-        d_row, I, (N + 1) * sizeof(int), hipMemcpyHostToDevice));
-    checkCudaErrors(hipMemcpy(
-        d_val, val, nz * sizeof(float), hipMemcpyHostToDevice));
-    checkCudaErrors(hipMemcpy(
-        d_val, val, nz * sizeof(float), hipMemcpyHostToDevice));
-    checkCudaErrors(hipMemcpy(
-        d_x, x, N*sizeof(float), hipMemcpyHostToDevice));
-    checkCudaErrors(hipMemcpy(
-        d_r, rhs, N * sizeof(float), hipMemcpyHostToDevice));
-
-    hipsparseSpMatDescr_t matA = NULL;
-    hipsparseSpMatDescr_t matM_lower, matM_upper;
-    hipsparseFillMode_t   fill_lower    = HIPSPARSE_FILL_MODE_LOWER;
-    hipsparseDiagType_t   diag_unit     = HIPSPARSE_DIAG_TYPE_UNIT;
-    hipsparseFillMode_t   fill_upper    = HIPSPARSE_FILL_MODE_UPPER;
-    hipsparseDiagType_t   diag_non_unit = HIPSPARSE_DIAG_TYPE_NON_UNIT;
-
-    checkCudaErrors(hipsparseCreateCsr(
-        &matA, N, N, nz, d_row, d_col, d_val, HIPSPARSE_INDEX_32I,
-        HIPSPARSE_INDEX_32I, HIPSPARSE_INDEX_BASE_ZERO, HIPBLAS_R_32F));
-
-    /* Copy A data to ILU(0) vals as input*/
-    checkCudaErrors(hipMemcpy(
-        d_valsILU0, d_val, nz*sizeof(float), hipMemcpyDeviceToDevice));
-    
-    //Lower Part 
-     checkCudaErrors( hipsparseCreateCsr(&matM_lower, N, N, nz, d_row, d_col, d_valsILU0,
-                                      HIPSPARSE_INDEX_32I, HIPSPARSE_INDEX_32I,
-                                      HIPSPARSE_INDEX_BASE_ZERO, HIPBLAS_R_32F) );
-
-    checkCudaErrors( hipsparseSpMatSetAttribute(matM_lower,
-                                              HIPSPARSE_SPMAT_FILL_MODE,
-                                              &fill_lower, sizeof(fill_lower)) );
-    checkCudaErrors( hipsparseSpMatSetAttribute(matM_lower,
-                                              HIPSPARSE_SPMAT_DIAG_TYPE,
-                                              &diag_unit, sizeof(diag_unit)) );
-    // M_upper
-    checkCudaErrors( hipsparseCreateCsr(&matM_upper, N, N, nz, d_row, d_col, d_valsILU0,
-                                      HIPSPARSE_INDEX_32I, HIPSPARSE_INDEX_32I,
-                                      HIPSPARSE_INDEX_BASE_ZERO, HIPBLAS_R_32F) );
-    checkCudaErrors( hipsparseSpMatSetAttribute(matM_upper,
-                                              HIPSPARSE_SPMAT_FILL_MODE,
-                                              &fill_upper, sizeof(fill_upper)) );
-    checkCudaErrors( hipsparseSpMatSetAttribute(matM_upper,
-                                              HIPSPARSE_SPMAT_DIAG_TYPE,
-                                              &diag_non_unit,
-                                              sizeof(diag_non_unit)) );
-
-
-    /* Create ILU(0) info object */
-    int                 bufferSizeLU = 0;
-    size_t              bufferSizeMV, bufferSizeL, bufferSizeU;
-    void*               d_bufferLU, *d_bufferMV,  *d_bufferL, *d_bufferU;
-    hipsparseSpSVDescr_t spsvDescrL, spsvDescrU;
-    hipsparseMatDescr_t   matLU;
-    csrilu02Info_t      infoILU = NULL;
-
-    checkCudaErrors(hipsparseCreateCsrilu02Info(&infoILU));
-    checkCudaErrors( hipsparseCreateMatDescr(&matLU) );
-    checkCudaErrors( hipsparseSetMatType(matLU, HIPSPARSE_MATRIX_TYPE_GENERAL) );
-    checkCudaErrors( hipsparseSetMatIndexBase(matLU, HIPSPARSE_INDEX_BASE_ZERO) );
-
-    /* Allocate workspace for cuSPARSE */
-    checkCudaErrors(hipsparseSpMV_bufferSize(
-        cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matA,
-        vecp, &floatzero, vecomega, HIPBLAS_R_32F, HIPSPARSE_SPMV_ALG_DEFAULT,
-        &bufferSizeMV));
-    checkCudaErrors( hipMalloc(&d_bufferMV, bufferSizeMV) );
-
-    checkCudaErrors(hipsparseScsrilu02_bufferSize(
-        cusparseHandle, N, nz, matLU, d_val, d_row, d_col, infoILU, &bufferSizeLU));
-    checkCudaErrors( hipMalloc(&d_bufferLU, bufferSizeLU) );
-
-    checkCudaErrors( hipsparseSpSV_createDescr(&spsvDescrL) );
-    checkCudaErrors(hipsparseSpSV_bufferSize(
-        cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matM_lower, vecR, vecX, HIPBLAS_R_32F,
-        HIPSPARSE_SPSV_ALG_DEFAULT, spsvDescrL, &bufferSizeL));
-    checkCudaErrors( hipMalloc(&d_bufferL, bufferSizeL) );
-
-    checkCudaErrors( hipsparseSpSV_createDescr(&spsvDescrU) );
-    checkCudaErrors( hipsparseSpSV_bufferSize(
-        cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matM_upper, vecR, vecX, HIPBLAS_R_32F,
-        HIPSPARSE_SPSV_ALG_DEFAULT, spsvDescrU, &bufferSizeU));
-    checkCudaErrors( hipMalloc(&d_bufferU, bufferSizeU) );
-
-    /* Conjugate gradient without preconditioning.
-       ------------------------------------------
-
-       Follows the description by Golub & Van Loan,
-       "Matrix Computations 3rd ed.", Section 10.2.6  */
-
-    printf("Convergence of CG without preconditioning: \n");
-    k = 0;
-    r0 = 0;
-    checkCudaErrors(hipblasSdot(cublasHandle, N, d_r, 1, d_r, 1, &r1));
+  genLaplace(I, J, val, M, N, nz, rhs);
+
+  /* Create CUBLAS context */
+  hipblasHandle_t cublasHandle = NULL;
+  checkCudaErrors(hipblasCreate(&cublasHandle));
+
+  /* Create CUSPARSE context */
+  hipsparseHandle_t cusparseHandle = NULL;
+  checkCudaErrors(hipsparseCreate(&cusparseHandle));
+
+  /* Description of the A matrix */
+  hipsparseMatDescr_t descr = 0;
+  checkCudaErrors(hipsparseCreateMatDescr(&descr));
+  checkCudaErrors(hipsparseSetMatType(descr, HIPSPARSE_MATRIX_TYPE_GENERAL));
+  checkCudaErrors(hipsparseSetMatIndexBase(descr, HIPSPARSE_INDEX_BASE_ZERO));
+
+  /* Allocate required memory */
+  checkCudaErrors(hipMalloc((void **)&d_col, nz * sizeof(int)));
+  checkCudaErrors(hipMalloc((void **)&d_row, (N + 1) * sizeof(int)));
+  checkCudaErrors(hipMalloc((void **)&d_val, nz * sizeof(float)));
+  checkCudaErrors(hipMalloc((void **)&d_x, N * sizeof(float)));
+  checkCudaErrors(hipMalloc((void **)&d_y, N * sizeof(float)));
+  checkCudaErrors(hipMalloc((void **)&d_r, N * sizeof(float)));
+  checkCudaErrors(hipMalloc((void **)&d_p, N * sizeof(float)));
+  checkCudaErrors(hipMalloc((void **)&d_omega, N * sizeof(float)));
+  checkCudaErrors(hipMalloc((void **)&d_valsILU0, nz * sizeof(float)));
+  checkCudaErrors(hipMalloc((void **)&d_zm1, (N) * sizeof(float)));
+  checkCudaErrors(hipMalloc((void **)&d_zm2, (N) * sizeof(float)));
+  checkCudaErrors(hipMalloc((void **)&d_rm2, (N) * sizeof(float)));
+
+  /* Wrap raw data into cuSPARSE generic API objects */
+  hipsparseSpMatDescr_t matA = NULL;
+  checkCudaErrors(hipsparseCreateCsr(&matA, N, N, nz, d_row, d_col, d_val,
+                                    HIPSPARSE_INDEX_32I, HIPSPARSE_INDEX_32I,
+                                    HIPSPARSE_INDEX_BASE_ZERO, HIPBLAS_R_32F));
+  hipsparseDnVecDescr_t vecp = NULL;
+  checkCudaErrors(hipsparseCreateDnVec(&vecp, N, d_p, HIPBLAS_R_32F));
+  hipsparseDnVecDescr_t vecomega = NULL;
+  checkCudaErrors(hipsparseCreateDnVec(&vecomega, N, d_omega, HIPBLAS_R_32F));
+
+  /* Initialize problem data */
+  checkCudaErrors(
+      hipMemcpy(d_col, J, nz * sizeof(int), hipMemcpyHostToDevice));
+  checkCudaErrors(
+      hipMemcpy(d_row, I, (N + 1) * sizeof(int), hipMemcpyHostToDevice));
+  checkCudaErrors(
+      hipMemcpy(d_val, val, nz * sizeof(float), hipMemcpyHostToDevice));
+  checkCudaErrors(
+      hipMemcpy(d_x, x, N * sizeof(float), hipMemcpyHostToDevice));
+  checkCudaErrors(
+      hipMemcpy(d_r, rhs, N * sizeof(float), hipMemcpyHostToDevice));
+  checkCudaErrors(hipMemset(d_y, 0, sizeof(float) * N));
+
+  /* Create ILU(0) info object */
+  csrilu02Info_t infoILU = NULL;
+  checkCudaErrors(hipsparseCreateCsrilu02Info(&infoILU));
+
+  /* Create L factor descriptor and triangular solve info */
+  hipsparseMatDescr_t descrL = NULL;
+  checkCudaErrors(hipsparseCreateMatDescr(&descrL));
+  checkCudaErrors(hipsparseSetMatType(descrL, HIPSPARSE_MATRIX_TYPE_GENERAL));
+  checkCudaErrors(hipsparseSetMatIndexBase(descrL, HIPSPARSE_INDEX_BASE_ZERO));
+  checkCudaErrors(hipsparseSetMatFillMode(descrL, HIPSPARSE_FILL_MODE_LOWER));
+  checkCudaErrors(hipsparseSetMatDiagType(descrL, HIPSPARSE_DIAG_TYPE_UNIT));
+  csrsv2Info_t infoL = NULL;
+  checkCudaErrors(hipsparseCreateCsrsv2Info(&infoL));
+
+  /* Create U factor descriptor and triangular solve info */
+  hipsparseMatDescr_t descrU = NULL;
+  checkCudaErrors(hipsparseCreateMatDescr(&descrU));
+  checkCudaErrors(hipsparseSetMatType(descrU, HIPSPARSE_MATRIX_TYPE_GENERAL));
+  checkCudaErrors(hipsparseSetMatIndexBase(descrU, HIPSPARSE_INDEX_BASE_ZERO));
+  checkCudaErrors(hipsparseSetMatFillMode(descrU, HIPSPARSE_FILL_MODE_UPPER));
+  checkCudaErrors(hipsparseSetMatDiagType(descrU, HIPSPARSE_DIAG_TYPE_NON_UNIT));
+  csrsv2Info_t infoU = NULL;
+  checkCudaErrors(hipsparseCreateCsrsv2Info(&infoU));
+
+  /* Allocate workspace for cuSPARSE */
+  size_t bufferSize = 0;
+  size_t tmp = 0;
+  int stmp = 0;
+  checkCudaErrors(hipsparseSpMV_bufferSize(
+      cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matA, vecp,
+      &floatzero, vecomega, HIPBLAS_R_32F, HIPSPARSE_SPMV_ALG_DEFAULT, &tmp));
+  if (tmp > bufferSize) {
+    bufferSize = stmp;
+  }
+  checkCudaErrors(hipsparseScsrilu02_bufferSize(
+      cusparseHandle, N, nz, descr, d_val, d_row, d_col, infoILU, &stmp));
+  if (stmp > bufferSize) {
+    bufferSize = stmp;
+  }
+  checkCudaErrors(hipsparseScsrsv2_bufferSize(
+      cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, N, nz, descrL, d_val,
+      d_row, d_col, infoL, &stmp));
+  if (stmp > bufferSize) {
+    bufferSize = stmp;
+  }
+  checkCudaErrors(hipsparseScsrsv2_bufferSize(
+      cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, N, nz, descrU, d_val,
+      d_row, d_col, infoU, &stmp));
+  if (stmp > bufferSize) {
+    bufferSize = stmp;
+  }
+  checkCudaErrors(hipMalloc(&buffer, bufferSize));
 
-    while (r1 > tol * tol && k <= max_iter)
-    {
-        k++;
-
-        if (k == 1)
-        {
-            checkCudaErrors(hipblasScopy(cublasHandle, N, d_r, 1, d_p, 1));
-        }
-        else
-        {
-            beta = r1 / r0;
-            checkCudaErrors(hipblasSscal(cublasHandle, N, &beta, d_p, 1));
-            checkCudaErrors(hipblasSaxpy(
-                cublasHandle, N, &floatone, d_r, 1, d_p, 1));
-        }
-
-        checkCudaErrors(hipsparseSpMV(
-            cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matA,
-            vecp, &floatzero, vecomega, HIPBLAS_R_32F, HIPSPARSE_SPMV_ALG_DEFAULT,
-            d_bufferMV));
-        checkCudaErrors(hipblasSdot(cublasHandle, N, d_p, 1, d_omega, 1, &dot));
-        alpha = r1 / dot;
-        checkCudaErrors(hipblasSaxpy(cublasHandle, N, &alpha, d_p, 1, d_x, 1));
-        nalpha = -alpha;
-        checkCudaErrors(hipblasSaxpy(
-            cublasHandle, N, &nalpha, d_omega, 1, d_r, 1));
-        r0 = r1;
-        checkCudaErrors(hipblasSdot(cublasHandle, N, d_r, 1, d_r, 1, &r1));
-    }
+  /* Conjugate gradient without preconditioning.
+     ------------------------------------------
+
+     Follows the description by Golub & Van Loan,
+     "Matrix Computations 3rd ed.", Section 10.2.6  */
+
+  printf("Convergence of CG without preconditioning: \n");
+  k = 0;
+  r0 = 0;
+  checkCudaErrors(hipblasSdot(cublasHandle, N, d_r, 1, d_r, 1, &r1));
 
-    printf("  iteration = %3d, residual = %e \n", k, sqrt(r1));
+  while (r1 > tol * tol && k <= max_iter) {
+    k++;
 
-    checkCudaErrors(hipMemcpy(
-        x, d_x, N * sizeof(float), hipMemcpyDeviceToHost));
+    if (k == 1) {
+      checkCudaErrors(hipblasScopy(cublasHandle, N, d_r, 1, d_p, 1));
+    } else {
+      beta = r1 / r0;
+      checkCudaErrors(hipblasSscal(cublasHandle, N, &beta, d_p, 1));
+      checkCudaErrors(hipblasSaxpy(cublasHandle, N, &floatone, d_r, 1, d_p, 1));
+    }
 
-    /* check result */
-    err = 0.0;
+    checkCudaErrors(hipsparseSpMV(
+        cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matA, vecp,
+        &floatzero, vecomega, HIPBLAS_R_32F, HIPSPARSE_SPMV_ALG_DEFAULT, buffer));
+    checkCudaErrors(hipblasSdot(cublasHandle, N, d_p, 1, d_omega, 1, &dot));
+    alpha = r1 / dot;
+    checkCudaErrors(hipblasSaxpy(cublasHandle, N, &alpha, d_p, 1, d_x, 1));
+    nalpha = -alpha;
+    checkCudaErrors(hipblasSaxpy(cublasHandle, N, &nalpha, d_omega, 1, d_r, 1));
+    r0 = r1;
+    checkCudaErrors(hipblasSdot(cublasHandle, N, d_r, 1, d_r, 1, &r1));
+  }
 
-    for (int i = 0; i < N; i++)
-    {
-        rsum = 0.0;
+  printf("  iteration = %3d, residual = %e \n", k, sqrt(r1));
 
-        for (int j = I[i]; j < I[i + 1]; j++)
-        {
-            rsum += val[j] * x[J[j]];
-        }
+  checkCudaErrors(
+      hipMemcpy(x, d_x, N * sizeof(float), hipMemcpyDeviceToHost));
 
-        diff = fabs(rsum - rhs[i]);
+  /* check result */
+  err = 0.0;
 
-        if (diff > err)
-        {
-            err = diff;
-        }
-    }
+  for (int i = 0; i < N; i++) {
+    rsum = 0.0;
 
-    printf("  Convergence Test: %s \n", (k <= max_iter) ? "OK" : "FAIL");
-    nErrors += (k > max_iter) ? 1 : 0;
-    qaerr1 = err;
-
-    if (0)
-    {
-        // output result in matlab-style array
-        int n = (int)sqrt((double)N);
-        printf("a = [  ");
-
-        for (int iy = 0; iy < n; iy++)
-        {
-            for (int ix = 0; ix < n; ix++)
-            {
-                printf(" %f ", x[iy * n + ix]);
-            }
-
-            if (iy == n - 1)
-            {
-                printf(" ]");
-            }
-
-            printf("\n");
-        }
+    for (int j = I[i]; j < I[i + 1]; j++) {
+      rsum += val[j] * x[J[j]];
     }
 
+    diff = fabs(rsum - rhs[i]);
 
-    /* Preconditioned Conjugate Gradient using ILU.
-       --------------------------------------------
-       Follows the description by Golub & Van Loan,
-       "Matrix Computations 3rd ed.", Algorithm 10.3.1  */
+    if (diff > err) {
+      err = diff;
+    }
+  }
 
-    printf("\nConvergence of CG using ILU(0) preconditioning: \n");
+  printf("  Convergence Test: %s \n", (k <= max_iter) ? "OK" : "FAIL");
+  nErrors += (k > max_iter) ? 1 : 0;
+  qaerr1 = err;
 
-    /* Perform analysis for ILU(0) */
-    checkCudaErrors(hipsparseScsrilu02_analysis(
-        cusparseHandle, N, nz, descr, d_valsILU0, d_row, d_col, infoILU,
-        HIPSPARSE_SOLVE_POLICY_USE_LEVEL, d_bufferLU));
+  if (0) {
+    // output result in matlab-style array
+    int n = (int)sqrt((double)N);
+    printf("a = [  ");
 
-    /* generate the ILU(0) factors */
-    checkCudaErrors(hipsparseScsrilu02(
-        cusparseHandle, N, nz, matLU, d_valsILU0, d_row, d_col, infoILU,
-        HIPSPARSE_SOLVE_POLICY_USE_LEVEL, d_bufferLU));
+    for (int iy = 0; iy < n; iy++) {
+      for (int ix = 0; ix < n; ix++) {
+        printf(" %f ", x[iy * n + ix]);
+      }
 
-    /* perform triangular solve analysis */
-    checkCudaErrors(hipsparseSpSV_analysis(
-        cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, &floatone,
-        matM_lower, vecR, vecX, HIPBLAS_R_32F,
-        HIPSPARSE_SPSV_ALG_DEFAULT, spsvDescrL, d_bufferL));
+      if (iy == n - 1) {
+        printf(" ]");
+      }
 
-    checkCudaErrors(hipsparseSpSV_analysis(
-        cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, &floatone,
-        matM_upper, vecR, vecX, HIPBLAS_R_32F,
-        HIPSPARSE_SPSV_ALG_DEFAULT, spsvDescrU, d_bufferU));
+      printf("\n");
+    }
+  }
 
-    /* reset the initial guess of the solution to zero */
-    for (int i = 0; i < N; i++)
-    {
-        x[i] = 0.0;
+  /* Preconditioned Conjugate Gradient using ILU.
+     --------------------------------------------
+     Follows the description by Golub & Van Loan,
+     "Matrix Computations 3rd ed.", Algorithm 10.3.1  */
+
+  printf("\nConvergence of CG using ILU(0) preconditioning: \n");
+
+  /* Perform analysis for ILU(0) */
+  checkCudaErrors(hipsparseScsrilu02_analysis(
+      cusparseHandle, N, nz, descr, d_val, d_row, d_col, infoILU,
+      HIPSPARSE_SOLVE_POLICY_USE_LEVEL, buffer));
+
+  /* Copy A data to ILU(0) vals as input*/
+  checkCudaErrors(hipMemcpy(d_valsILU0, d_val, nz * sizeof(float),
+                             hipMemcpyDeviceToDevice));
+
+  /* generate the ILU(0) factors */
+  checkCudaErrors(hipsparseScsrilu02(cusparseHandle, N, nz, descr, d_valsILU0,
+                                    d_row, d_col, infoILU,
+                                    HIPSPARSE_SOLVE_POLICY_USE_LEVEL, buffer));
+
+  /* perform triangular solve analysis */
+  checkCudaErrors(
+      hipsparseScsrsv2_analysis(cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE,
+                               N, nz, descrL, d_valsILU0, d_row, d_col, infoL,
+                               HIPSPARSE_SOLVE_POLICY_USE_LEVEL, buffer));
+  checkCudaErrors(
+      hipsparseScsrsv2_analysis(cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE,
+                               N, nz, descrU, d_valsILU0, d_row, d_col, infoU,
+                               HIPSPARSE_SOLVE_POLICY_USE_LEVEL, buffer));
+
+  /* reset the initial guess of the solution to zero */
+  for (int i = 0; i < N; i++) {
+    x[i] = 0.0;
+  }
+  checkCudaErrors(
+      hipMemcpy(d_r, rhs, N * sizeof(float), hipMemcpyHostToDevice));
+  checkCudaErrors(
+      hipMemcpy(d_x, x, N * sizeof(float), hipMemcpyHostToDevice));
+
+  k = 0;
+  checkCudaErrors(hipblasSdot(cublasHandle, N, d_r, 1, d_r, 1, &r1));
+
+  while (r1 > tol * tol && k <= max_iter) {
+    // preconditioner application: d_zm1 = U^-1 L^-1 d_r
+    checkCudaErrors(hipsparseScsrsv2_solve(
+        cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, N, nz, &floatone,
+        descrL, d_valsILU0, d_row, d_col, infoL, d_r, d_y,
+        HIPSPARSE_SOLVE_POLICY_USE_LEVEL, buffer));
+    checkCudaErrors(hipsparseScsrsv2_solve(
+        cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, N, nz, &floatone,
+        descrU, d_valsILU0, d_row, d_col, infoU, d_y, d_zm1,
+        HIPSPARSE_SOLVE_POLICY_USE_LEVEL, buffer));
+
+    k++;
+
+    if (k == 1) {
+      checkCudaErrors(hipblasScopy(cublasHandle, N, d_zm1, 1, d_p, 1));
+    } else {
+      checkCudaErrors(
+          hipblasSdot(cublasHandle, N, d_r, 1, d_zm1, 1, &numerator));
+      checkCudaErrors(
+          hipblasSdot(cublasHandle, N, d_rm2, 1, d_zm2, 1, &denominator));
+      beta = numerator / denominator;
+      checkCudaErrors(hipblasSscal(cublasHandle, N, &beta, d_p, 1));
+      checkCudaErrors(
+          hipblasSaxpy(cublasHandle, N, &floatone, d_zm1, 1, d_p, 1));
     }
-    checkCudaErrors(hipMemcpy(
-        d_r, rhs, N * sizeof(float), hipMemcpyHostToDevice));
-    checkCudaErrors(hipMemcpy(
-        d_x, x, N * sizeof(float), hipMemcpyHostToDevice));
 
-    k = 0;
+    checkCudaErrors(hipsparseSpMV(
+        cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matA, vecp,
+        &floatzero, vecomega, HIPBLAS_R_32F, HIPSPARSE_SPMV_ALG_DEFAULT, buffer));
+    checkCudaErrors(hipblasSdot(cublasHandle, N, d_r, 1, d_zm1, 1, &numerator));
+    checkCudaErrors(
+        hipblasSdot(cublasHandle, N, d_p, 1, d_omega, 1, &denominator));
+    alpha = numerator / denominator;
+    checkCudaErrors(hipblasSaxpy(cublasHandle, N, &alpha, d_p, 1, d_x, 1));
+    checkCudaErrors(hipblasScopy(cublasHandle, N, d_r, 1, d_rm2, 1));
+    checkCudaErrors(hipblasScopy(cublasHandle, N, d_zm1, 1, d_zm2, 1));
+    nalpha = -alpha;
+    checkCudaErrors(hipblasSaxpy(cublasHandle, N, &nalpha, d_omega, 1, d_r, 1));
     checkCudaErrors(hipblasSdot(cublasHandle, N, d_r, 1, d_r, 1, &r1));
+  }
 
-    while (r1 > tol * tol && k <= max_iter)
-    {
-        // preconditioner application: d_zm1 = U^-1 L^-1 d_r
-        checkCudaErrors(hipsparseSpSV_solve(cusparseHandle,
-            HIPSPARSE_OPERATION_NON_TRANSPOSE, &floatone,
-            matM_lower, vecR, vecY, HIPBLAS_R_32F,
-            HIPSPARSE_SPSV_ALG_DEFAULT,
-            spsvDescrL) );
-            
-        checkCudaErrors(hipsparseSpSV_solve(cusparseHandle,
-            HIPSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matM_upper,
-            vecY, vecZM1,
-            HIPBLAS_R_32F,
-            HIPSPARSE_SPSV_ALG_DEFAULT,
-            spsvDescrU));
-        k++;
-
-        if (k == 1)
-        {
-            checkCudaErrors(hipblasScopy(cublasHandle, N, d_zm1, 1, d_p, 1));
-        }
-        else
-        {
-            checkCudaErrors(hipblasSdot(
-                cublasHandle, N, d_r, 1, d_zm1, 1, &numerator));
-            checkCudaErrors(hipblasSdot(
-                cublasHandle, N, d_rm2, 1, d_zm2, 1, &denominator));
-            beta = numerator / denominator;
-            checkCudaErrors(hipblasSscal(cublasHandle, N, &beta, d_p, 1));
-            checkCudaErrors(hipblasSaxpy(
-                cublasHandle, N, &floatone, d_zm1, 1, d_p, 1));
-        }
-
-        checkCudaErrors(hipsparseSpMV(
-            cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, &floatone, matA,
-            vecp, &floatzero, vecomega, HIPBLAS_R_32F, HIPSPARSE_SPMV_ALG_DEFAULT,
-            d_bufferMV));
-        checkCudaErrors(hipblasSdot(
-            cublasHandle, N, d_r, 1, d_zm1, 1, &numerator));
-        checkCudaErrors(hipblasSdot(
-            cublasHandle, N, d_p, 1, d_omega, 1, &denominator));
-        alpha = numerator / denominator;
-        checkCudaErrors(hipblasSaxpy(cublasHandle, N, &alpha, d_p, 1, d_x, 1));
-        checkCudaErrors(hipblasScopy(cublasHandle, N, d_r, 1, d_rm2, 1));
-        checkCudaErrors(hipblasScopy(cublasHandle, N, d_zm1, 1, d_zm2, 1));
-        nalpha = -alpha;
-        checkCudaErrors(hipblasSaxpy(
-            cublasHandle, N, &nalpha, d_omega, 1, d_r, 1));
-        checkCudaErrors(hipblasSdot(cublasHandle, N, d_r, 1, d_r, 1, &r1));
-    }
-
-    printf("  iteration = %3d, residual = %e \n", k, sqrt(r1));
+  printf("  iteration = %3d, residual = %e \n", k, sqrt(r1));
 
-    checkCudaErrors(hipMemcpy(
-        x, d_x, N * sizeof(float), hipMemcpyDeviceToHost));
+  checkCudaErrors(
+      hipMemcpy(x, d_x, N * sizeof(float), hipMemcpyDeviceToHost));
 
-    /* check result */
-    err = 0.0;
+  /* check result */
+  err = 0.0;
 
-    for (int i = 0; i < N; i++)
-    {
-        rsum = 0.0;
+  for (int i = 0; i < N; i++) {
+    rsum = 0.0;
 
-        for (int j = I[i]; j < I[i + 1]; j++)
-        {
-            rsum += val[j] * x[J[j]];
-        }
+    for (int j = I[i]; j < I[i + 1]; j++) {
+      rsum += val[j] * x[J[j]];
+    }
 
-        diff = fabs(rsum - rhs[i]);
+    diff = fabs(rsum - rhs[i]);
 
-        if (diff > err)
-        {
-            err = diff;
-        }
+    if (diff > err) {
+      err = diff;
     }
+  }
 
-    printf("  Convergence Test: %s \n", (k <= max_iter) ? "OK" : "FAIL");
-    nErrors += (k > max_iter) ? 1 : 0;
-    qaerr2 = err;
-
-    /* Destroy descriptors */
-    checkCudaErrors(hipsparseDestroyCsrilu02Info(infoILU));
-    checkCudaErrors(hipsparseDestroyMatDescr(matLU));
-    checkCudaErrors(hipsparseSpSV_destroyDescr(spsvDescrL));
-    checkCudaErrors(hipsparseSpSV_destroyDescr(spsvDescrU));
-    checkCudaErrors(hipsparseDestroySpMat(matM_lower));
-    checkCudaErrors(hipsparseDestroySpMat(matM_upper));
-    checkCudaErrors(hipsparseDestroySpMat(matA));
-    checkCudaErrors(hipsparseDestroyDnVec(vecp));
-    checkCudaErrors(hipsparseDestroyDnVec(vecomega));
-    checkCudaErrors(hipsparseDestroyDnVec(vecR));
-    checkCudaErrors(hipsparseDestroyDnVec(vecX));
-    checkCudaErrors(hipsparseDestroyDnVec(vecY));
-    checkCudaErrors(hipsparseDestroyDnVec(vecZM1));
-
-    /* Destroy contexts */
-    checkCudaErrors(hipsparseDestroy(cusparseHandle));
-    checkCudaErrors(hipblasDestroy(cublasHandle));
-
-    /* Free device memory */
-    free(I);
-    free(J);
-    free(val);
-    free(x);
-    free(rhs);
-    checkCudaErrors(hipFree(d_bufferMV));
-    checkCudaErrors(hipFree(d_bufferLU));
-    checkCudaErrors(hipFree(d_bufferL));
-    checkCudaErrors(hipFree(d_bufferU));
-    checkCudaErrors(hipFree(d_col));
-    checkCudaErrors(hipFree(d_row));
-    checkCudaErrors(hipFree(d_val));
-    checkCudaErrors(hipFree(d_x));
-    checkCudaErrors(hipFree(d_y));
-    checkCudaErrors(hipFree(d_r));
-    checkCudaErrors(hipFree(d_p));
-    checkCudaErrors(hipFree(d_omega));
-    checkCudaErrors(hipFree(d_valsILU0));
-    checkCudaErrors(hipFree(d_zm1));
-    checkCudaErrors(hipFree(d_zm2));
-    checkCudaErrors(hipFree(d_rm2));
-
-    // hipDeviceReset causes the driver to clean up all state. While
-    // not mandatory in normal operation, it is good practice.  It is also
-    // needed to ensure correct operation when the application is being
-    // profiled. Calling hipDeviceReset causes all profile data to be
-    // flushed before the application exits
-    hipDeviceReset();
-
-    printf("\n");
-    printf("Test Summary:\n");
-    printf("   Counted total of %d errors\n", nErrors);
-    printf("   qaerr1 = %f qaerr2 = %f\n\n", fabs(qaerr1), fabs(qaerr2));
-    exit((nErrors == 0 &&fabs(qaerr1) < 1e-5 && fabs(qaerr2) < 1e-5
-        ? EXIT_SUCCESS
-        : EXIT_FAILURE));
+  printf("  Convergence Test: %s \n", (k <= max_iter) ? "OK" : "FAIL");
+  nErrors += (k > max_iter) ? 1 : 0;
+  qaerr2 = err;
+
+  /* Destroy descriptors */
+  checkCudaErrors(hipsparseDestroyCsrsv2Info(infoU));
+  checkCudaErrors(hipsparseDestroyCsrsv2Info(infoL));
+  checkCudaErrors(hipsparseDestroyCsrilu02Info(infoILU));
+  checkCudaErrors(hipsparseDestroyMatDescr(descrL));
+  checkCudaErrors(hipsparseDestroyMatDescr(descrU));
+  checkCudaErrors(hipsparseDestroyMatDescr(descr));
+  checkCudaErrors(hipsparseDestroySpMat(matA));
+  checkCudaErrors(hipsparseDestroyDnVec(vecp));
+  checkCudaErrors(hipsparseDestroyDnVec(vecomega));
+
+  /* Destroy contexts */
+  checkCudaErrors(hipsparseDestroy(cusparseHandle));
+  checkCudaErrors(hipblasDestroy(cublasHandle));
+
+  /* Free device memory */
+  free(I);
+  free(J);
+  free(val);
+  free(x);
+  free(rhs);
+  checkCudaErrors(hipFree(buffer));
+  checkCudaErrors(hipFree(d_col));
+  checkCudaErrors(hipFree(d_row));
+  checkCudaErrors(hipFree(d_val));
+  checkCudaErrors(hipFree(d_x));
+  checkCudaErrors(hipFree(d_y));
+  checkCudaErrors(hipFree(d_r));
+  checkCudaErrors(hipFree(d_p));
+  checkCudaErrors(hipFree(d_omega));
+  checkCudaErrors(hipFree(d_valsILU0));
+  checkCudaErrors(hipFree(d_zm1));
+  checkCudaErrors(hipFree(d_zm2));
+  checkCudaErrors(hipFree(d_rm2));
+
+  printf("\n");
+  printf("Test Summary:\n");
+  printf("   Counted total of %d errors\n", nErrors);
+  printf("   qaerr1 = %f qaerr2 = %f\n\n", fabs(qaerr1), fabs(qaerr2));
+  exit((nErrors == 0 && fabs(qaerr1) < 1e-5 && fabs(qaerr2) < 1e-5
+            ? EXIT_SUCCESS
+            : EXIT_FAILURE));
 }
-
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/Makefile b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/Makefile
index ece04e2..8f72576 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/Makefile
@@ -287,7 +287,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/NsightEclipse.xml
index 0791f6b..ca7258c 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/NsightEclipse.xml
@@ -46,6 +46,20 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/README.md b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/README.md
index edd7a5a..ac9fd25 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/README.md
@@ -10,6 +10,8 @@ Unified Memory, Linear Algebra, CUBLAS Library, CUSPARSE Library
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux, Windows
@@ -28,7 +30,7 @@ cudaFree, cudaMallocManaged, cudaDeviceSynchronize, cudaMalloc, cudaGetDevicePro
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2017.vcxproj
index 37274a5..4a8f1f5 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/conjugateGradientUM.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2019.vcxproj
index d6c7abf..44fd5a5 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/conjugateGradientUM.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2022.vcxproj
index c676e1f..05b5205 100755
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/conjugateGradientUM.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/Makefile
index 4ebd50c..9c8f53f 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/Makefile
@@ -332,7 +332,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/README.md b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/README.md
index e2d2b4f..e18dc7d 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/README.md
@@ -27,7 +27,7 @@ cudaStreamCreateWithFlags, cudaStreamDestroy, cudaFree, cudaGetErrorName, cudaSe
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/main.cu.hip b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/main.cu.hip
index e69de29..c38223b 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/main.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/main.cu.hip
@@ -0,0 +1,431 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "cudla.h"
+#include "hip/hip_runtime.h"
+
+#include <cstdio>
+#include <cstdlib>
+#include <cstring>
+#include <sys/stat.h>
+#include <fstream>
+#include <sstream>
+
+#define DPRINTF(...) printf(__VA_ARGS__)
+
+static void printTensorDesc(cudlaModuleTensorDescriptor* tensorDesc) {
+  DPRINTF("\tTENSOR NAME : %s\n", tensorDesc->name);
+  DPRINTF("\tsize: %lu\n", tensorDesc->size);
+
+  DPRINTF("\tdims: [%lu, %lu, %lu, %lu]\n", tensorDesc->n, tensorDesc->c,
+          tensorDesc->h, tensorDesc->w);
+
+  DPRINTF("\tdata fmt: %d\n", tensorDesc->dataFormat);
+  DPRINTF("\tdata type: %d\n", tensorDesc->dataType);
+  DPRINTF("\tdata category: %d\n", tensorDesc->dataCategory);
+  DPRINTF("\tpixel fmt: %d\n", tensorDesc->pixelFormat);
+  DPRINTF("\tpixel mapping: %d\n", tensorDesc->pixelMapping);
+  DPRINTF("\tstride[0]: %d\n", tensorDesc->stride[0]);
+  DPRINTF("\tstride[1]: %d\n", tensorDesc->stride[1]);
+  DPRINTF("\tstride[2]: %d\n", tensorDesc->stride[2]);
+  DPRINTF("\tstride[3]: %d\n", tensorDesc->stride[3]);
+}
+
+typedef struct {
+  cudlaDevHandle devHandle;
+  cudlaModule moduleHandle;
+  unsigned char* loadableData;
+  hipStream_t stream;
+  unsigned char* inputBuffer;
+  unsigned char* outputBuffer;
+  void* inputBufferGPU;
+  void* outputBufferGPU;
+  cudlaModuleTensorDescriptor* inputTensorDesc;
+  cudlaModuleTensorDescriptor* outputTensorDesc;
+} ResourceList;
+
+void cleanUp(ResourceList* resourceList);
+
+void cleanUp(ResourceList* resourceList) {
+  if (resourceList->inputTensorDesc != NULL) {
+    free(resourceList->inputTensorDesc);
+    resourceList->inputTensorDesc = NULL;
+  }
+  if (resourceList->outputTensorDesc != NULL) {
+    free(resourceList->outputTensorDesc);
+    resourceList->outputTensorDesc = NULL;
+  }
+
+  if (resourceList->loadableData != NULL) {
+    free(resourceList->loadableData);
+    resourceList->loadableData = NULL;
+  }
+
+  if (resourceList->moduleHandle != NULL) {
+    cudlaModuleUnload(resourceList->moduleHandle, 0);
+    resourceList->moduleHandle = NULL;
+  }
+
+  if (resourceList->devHandle != NULL) {
+    cudlaDestroyDevice(resourceList->devHandle);
+    resourceList->devHandle = NULL;
+  }
+
+  if (resourceList->inputBufferGPU != 0) {
+    hipFree(resourceList->inputBufferGPU);
+    resourceList->inputBufferGPU = 0;
+  }
+  if (resourceList->outputBufferGPU != 0) {
+    hipFree(resourceList->outputBufferGPU);
+    resourceList->outputBufferGPU = 0;
+  }
+
+  if (resourceList->inputBuffer != NULL) {
+    free(resourceList->inputBuffer);
+    resourceList->inputBuffer = NULL;
+  }
+  if (resourceList->outputBuffer != NULL) {
+    free(resourceList->outputBuffer);
+    resourceList->outputBuffer = NULL;
+  }
+
+  if (resourceList->stream != NULL) {
+    hipStreamDestroy(resourceList->stream);
+    resourceList->stream = NULL;
+  }
+}
+
+int main(int argc, char** argv) {
+  cudlaDevHandle devHandle;
+  cudlaModule moduleHandle;
+  cudlaStatus err;
+  FILE* fp = NULL;
+  struct stat st;
+  size_t file_size;
+  size_t actually_read = 0;
+  unsigned char* loadableData = NULL;
+
+  hipStream_t stream;
+  hipError_t result;
+  const char* errPtr = NULL;
+
+  ResourceList resourceList;
+
+  memset(&resourceList, 0x00, sizeof(ResourceList));
+
+  if (argc != 2) {
+    DPRINTF("Usage : ./cuDLAErrorReporting <loadable>\n");
+    return 1;
+  }
+
+  // Read loadable into buffer.
+  fp = fopen(argv[1], "rb");
+  if (fp == NULL) {
+    DPRINTF("Cannot open file %s\n", argv[1]);
+    return 1;
+  }
+
+  if (stat(argv[1], &st) != 0) {
+    DPRINTF("Cannot stat file\n");
+    return 1;
+  }
+
+  file_size = st.st_size;
+  DPRINTF("The file size = %ld\n", file_size);
+
+  loadableData = (unsigned char*)malloc(file_size);
+  if (loadableData == NULL) {
+    DPRINTF("Cannot Allocate memory for loadable\n");
+    return 1;
+  }
+
+  actually_read = fread(loadableData, 1, file_size, fp);
+  if (actually_read != file_size) {
+    free(loadableData);
+    DPRINTF("Read wrong size\n");
+    return 1;
+  }
+  fclose(fp);
+
+  resourceList.loadableData = loadableData;
+
+  // Initialize CUDA.
+  result = hipFree(0);
+  if (result != hipSuccess) {
+    errPtr = hipGetErrorName(result);
+    DPRINTF("Error in creating hipFree = %s\n", errPtr);
+    cleanUp(&resourceList);
+    return 1;
+  }
+  result = hipSetDevice(0);
+  if (result != hipSuccess) {
+    errPtr = hipGetErrorName(result);
+    DPRINTF("Error in creating hipSetDevice = %s\n", errPtr);
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  err = cudlaCreateDevice(0, &devHandle, CUDLA_CUDA_DLA);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in cuDLA create device = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  DPRINTF("Device created successfully\n");
+  resourceList.devHandle = devHandle;
+
+  err = cudlaModuleLoadFromMemory(devHandle, loadableData, file_size,
+                                  &moduleHandle, 0);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in cudlaModuleLoadFromMemory = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  } else {
+    DPRINTF("Successfully loaded module\n");
+  }
+
+  resourceList.moduleHandle = moduleHandle;
+
+  // Create CUDA stream.
+  result = hipStreamCreateWithFlags(&stream, hipStreamNonBlocking);
+
+  if (result != hipSuccess) {
+    errPtr = hipGetErrorName(result);
+    DPRINTF("Error in creating cuda stream = %s\n", errPtr);
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  resourceList.stream = stream;
+
+  // Get tensor attributes.
+  uint32_t numInputTensors = 0;
+  uint32_t numOutputTensors = 0;
+  cudlaModuleAttribute attribute;
+
+  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_NUM_INPUT_TENSORS,
+                                 &attribute);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in getting numInputTensors = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+  numInputTensors = attribute.numInputTensors;
+  DPRINTF("numInputTensors = %d\n", numInputTensors);
+
+  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_NUM_OUTPUT_TENSORS,
+                                 &attribute);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in getting numOutputTensors = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+  numOutputTensors = attribute.numOutputTensors;
+  DPRINTF("numOutputTensors = %d\n", numOutputTensors);
+
+  cudlaModuleTensorDescriptor* inputTensorDesc =
+      (cudlaModuleTensorDescriptor*)malloc(sizeof(cudlaModuleTensorDescriptor) *
+                                           numInputTensors);
+  cudlaModuleTensorDescriptor* outputTensorDesc =
+      (cudlaModuleTensorDescriptor*)malloc(sizeof(cudlaModuleTensorDescriptor) *
+                                           numOutputTensors);
+
+  if ((inputTensorDesc == NULL) || (outputTensorDesc == NULL)) {
+    if (inputTensorDesc != NULL) {
+      free(inputTensorDesc);
+      inputTensorDesc = NULL;
+    }
+
+    if (outputTensorDesc != NULL) {
+      free(outputTensorDesc);
+      outputTensorDesc = NULL;
+    }
+
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  resourceList.inputTensorDesc = inputTensorDesc;
+  resourceList.outputTensorDesc = outputTensorDesc;
+
+  attribute.inputTensorDesc = inputTensorDesc;
+  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_INPUT_TENSOR_DESCRIPTORS,
+                                 &attribute);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in getting input tensor descriptor = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+  DPRINTF("Printing input tensor descriptor\n");
+  printTensorDesc(inputTensorDesc);
+
+  attribute.outputTensorDesc = outputTensorDesc;
+  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_OUTPUT_TENSOR_DESCRIPTORS,
+                                 &attribute);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in getting output tensor descriptor = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+  DPRINTF("Printing output tensor descriptor\n");
+  printTensorDesc(outputTensorDesc);
+
+  // Setup the input and output buffers which will be used as an input to CUDA.
+  unsigned char* inputBuffer = (unsigned char*)malloc(inputTensorDesc[0].size);
+  if (inputBuffer == NULL) {
+    DPRINTF("Error in allocating input memory\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  resourceList.inputBuffer = inputBuffer;
+
+  unsigned char* outputBuffer =
+      (unsigned char*)malloc(outputTensorDesc[0].size);
+  if (outputBuffer == NULL) {
+    DPRINTF("Error in allocating output memory\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  resourceList.outputBuffer = outputBuffer;
+
+  memset(inputBuffer, 0x01, inputTensorDesc[0].size);
+  memset(outputBuffer, 0x00, outputTensorDesc[0].size);
+
+  // Allocate memory on GPU.
+  void* inputBufferGPU;
+  void* outputBufferGPU;
+  result = hipMalloc(&inputBufferGPU, inputTensorDesc[0].size);
+  if (result != hipSuccess) {
+    DPRINTF("Error in allocating input memory on GPU\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  resourceList.inputBufferGPU = inputBufferGPU;
+
+  result = hipMalloc(&outputBufferGPU, outputTensorDesc[0].size);
+  if (result != hipSuccess) {
+    DPRINTF("Error in allocating output memory on GPU\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  resourceList.outputBufferGPU = outputBufferGPU;
+
+  // Register the CUDA-allocated buffers.
+  uint64_t* inputBufferRegisteredPtr = NULL;
+  uint64_t* outputBufferRegisteredPtr = NULL;
+
+  err = cudlaMemRegister(devHandle, (uint64_t*)inputBufferGPU,
+                         inputTensorDesc[0].size, &inputBufferRegisteredPtr, 0);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in registering input memory = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  err =
+      cudlaMemRegister(devHandle, (uint64_t*)outputBufferGPU,
+                       outputTensorDesc[0].size, &outputBufferRegisteredPtr, 0);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in registering output memory = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+  DPRINTF("ALL MEMORY REGISTERED SUCCESSFULLY\n");
+
+  // Copy data from CPU buffers to GPU buffers.
+  result = hipMemcpyAsync(inputBufferGPU, inputBuffer, inputTensorDesc[0].size,
+                           hipMemcpyHostToDevice, stream);
+  if (result != hipSuccess) {
+    DPRINTF("Error in enqueueing memcpy for input\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+  result =
+      hipMemsetAsync(outputBufferGPU, 0, outputTensorDesc[0].size, stream);
+  if (result != hipSuccess) {
+    DPRINTF("Error in enqueueing memset for output\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  // Enqueue a cuDLA task.
+  cudlaTask task;
+  task.moduleHandle = moduleHandle;
+  task.outputTensor = &outputBufferRegisteredPtr;
+  task.numOutputTensors = 1;
+  task.numInputTensors = 1;
+  task.inputTensor = &inputBufferRegisteredPtr;
+  task.waitEvents = NULL;
+  task.signalEvents = NULL;
+  err = cudlaSubmitTask(devHandle, &task, 1, stream, 0);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in submitting task\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+  DPRINTF("SUBMIT IS DONE !!!\n");
+
+  // Wait for stream operations to finish and bring output buffer to CPU.
+  result =
+      hipMemcpyAsync(outputBuffer, outputBufferGPU, outputTensorDesc[0].size,
+                      hipMemcpyDeviceToHost, stream);
+  if (result != hipSuccess) {
+    if (result != cudaErrorExternalDevice) {
+      DPRINTF("Error in bringing result back to CPU\n");
+      cleanUp(&resourceList);
+      return 1;
+    } else {
+      cudlaStatus hwStatus = cudlaGetLastError(devHandle);
+      if (hwStatus != cudlaSuccess) {
+        DPRINTF("Asynchronous error in HW = %u\n", hwStatus);
+      }
+    }
+  }
+
+  result = hipStreamSynchronize(stream);
+  if (result != hipSuccess) {
+    DPRINTF("Error in synchronizing stream = %s\n", hipGetErrorName(result));
+
+    if (result == cudaErrorExternalDevice) {
+      cudlaStatus hwStatus = cudlaGetLastError(devHandle);
+      if (hwStatus != cudlaSuccess) {
+        DPRINTF("Asynchronous error in HW = %u\n", hwStatus);
+      }
+    }
+  }
+
+  cleanUp(&resourceList);
+
+  DPRINTF("cuDLAErrorReporting DONE !!!\n");
+
+  return 0;
+}
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/Makefile
index 6bb7401..5cf7413 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/Makefile
@@ -332,7 +332,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/README.md b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/README.md
index 3600f49..12799c1 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/README.md
@@ -27,7 +27,7 @@ cudaStreamCreateWithFlags, cudaStreamDestroy, cudaFree, cudaGetErrorName, cudaSe
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/main.cu.hip b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/main.cu.hip
index e69de29..ecaf605 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/main.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/main.cu.hip
@@ -0,0 +1,496 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "cudla.h"
+#include "hip/hip_runtime.h"
+
+#include <cstdio>
+#include <cstdlib>
+#include <cstring>
+#include <sys/stat.h>
+#include <fstream>
+#include <sstream>
+
+#define DPRINTF(...) printf(__VA_ARGS__)
+
+static void printTensorDesc(cudlaModuleTensorDescriptor* tensorDesc) {
+  DPRINTF("\tTENSOR NAME : %s\n", tensorDesc->name);
+  DPRINTF("\tsize: %lu\n", tensorDesc->size);
+
+  DPRINTF("\tdims: [%lu, %lu, %lu, %lu]\n", tensorDesc->n, tensorDesc->c,
+          tensorDesc->h, tensorDesc->w);
+
+  DPRINTF("\tdata fmt: %d\n", tensorDesc->dataFormat);
+  DPRINTF("\tdata type: %d\n", tensorDesc->dataType);
+  DPRINTF("\tdata category: %d\n", tensorDesc->dataCategory);
+  DPRINTF("\tpixel fmt: %d\n", tensorDesc->pixelFormat);
+  DPRINTF("\tpixel mapping: %d\n", tensorDesc->pixelMapping);
+  DPRINTF("\tstride[0]: %d\n", tensorDesc->stride[0]);
+  DPRINTF("\tstride[1]: %d\n", tensorDesc->stride[1]);
+  DPRINTF("\tstride[2]: %d\n", tensorDesc->stride[2]);
+  DPRINTF("\tstride[3]: %d\n", tensorDesc->stride[3]);
+}
+
+static int initializeInputBuffers(char* filePath,
+                                  cudlaModuleTensorDescriptor* tensorDesc,
+                                  unsigned char* buf) {
+  // Read the file in filePath and fill up 'buf' according to format
+  // specified by the user.
+
+  return 0;
+}
+
+typedef struct {
+  cudlaDevHandle devHandle;
+  cudlaModule moduleHandle;
+  unsigned char* loadableData;
+  hipStream_t stream;
+  unsigned char* inputBuffer;
+  unsigned char* outputBuffer;
+  void* inputBufferGPU;
+  void* outputBufferGPU;
+  cudlaModuleTensorDescriptor* inputTensorDesc;
+  cudlaModuleTensorDescriptor* outputTensorDesc;
+} ResourceList;
+
+void cleanUp(ResourceList* resourceList);
+
+void cleanUp(ResourceList* resourceList) {
+  if (resourceList->inputTensorDesc != NULL) {
+    free(resourceList->inputTensorDesc);
+    resourceList->inputTensorDesc = NULL;
+  }
+  if (resourceList->outputTensorDesc != NULL) {
+    free(resourceList->outputTensorDesc);
+    resourceList->outputTensorDesc = NULL;
+  }
+
+  if (resourceList->loadableData != NULL) {
+    free(resourceList->loadableData);
+    resourceList->loadableData = NULL;
+  }
+
+  if (resourceList->moduleHandle != NULL) {
+    cudlaModuleUnload(resourceList->moduleHandle, 0);
+    resourceList->moduleHandle = NULL;
+  }
+
+  if (resourceList->devHandle != NULL) {
+    cudlaDestroyDevice(resourceList->devHandle);
+    resourceList->devHandle = NULL;
+  }
+
+  if (resourceList->inputBufferGPU != 0) {
+    hipFree(resourceList->inputBufferGPU);
+    resourceList->inputBufferGPU = 0;
+  }
+  if (resourceList->outputBufferGPU != 0) {
+    hipFree(resourceList->outputBufferGPU);
+    resourceList->outputBufferGPU = 0;
+  }
+
+  if (resourceList->inputBuffer != NULL) {
+    free(resourceList->inputBuffer);
+    resourceList->inputBuffer = NULL;
+  }
+  if (resourceList->outputBuffer != NULL) {
+    free(resourceList->outputBuffer);
+    resourceList->outputBuffer = NULL;
+  }
+
+  if (resourceList->stream != NULL) {
+    hipStreamDestroy(resourceList->stream);
+    resourceList->stream = NULL;
+  }
+}
+
+int main(int argc, char** argv) {
+  cudlaDevHandle devHandle;
+  cudlaModule moduleHandle;
+  cudlaStatus err;
+  FILE* fp = NULL;
+  struct stat st;
+  size_t file_size;
+  size_t actually_read = 0;
+  unsigned char* loadableData = NULL;
+
+  hipStream_t stream;
+  hipError_t result;
+  const char* errPtr = NULL;
+
+  ResourceList resourceList;
+
+  memset(&resourceList, 0x00, sizeof(ResourceList));
+
+  if (argc != 3) {
+    DPRINTF("Usage : ./cuDLAHybridMode <loadable> <imageFile>\n");
+    return 1;
+  }
+
+  // Read loadable into buffer.
+  fp = fopen(argv[1], "rb");
+  if (fp == NULL) {
+    DPRINTF("Cannot open file %s\n", argv[1]);
+    return 1;
+  }
+
+  if (stat(argv[1], &st) != 0) {
+    DPRINTF("Cannot stat file\n");
+    return 1;
+  }
+
+  file_size = st.st_size;
+  DPRINTF("The file size = %ld\n", file_size);
+
+  loadableData = (unsigned char*)malloc(file_size);
+  if (loadableData == NULL) {
+    DPRINTF("Cannot Allocate memory for loadable\n");
+    return 1;
+  }
+
+  actually_read = fread(loadableData, 1, file_size, fp);
+  if (actually_read != file_size) {
+    free(loadableData);
+    DPRINTF("Read wrong size\n");
+    return 1;
+  }
+  fclose(fp);
+
+  resourceList.loadableData = loadableData;
+
+  // Initialize CUDA.
+  result = hipFree(0);
+  if (result != hipSuccess) {
+    errPtr = hipGetErrorName(result);
+    DPRINTF("Error in creating hipFree = %s\n", errPtr);
+    cleanUp(&resourceList);
+    return 1;
+  }
+  result = hipSetDevice(0);
+  if (result != hipSuccess) {
+    errPtr = hipGetErrorName(result);
+    DPRINTF("Error in creating hipSetDevice = %s\n", errPtr);
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  err = cudlaCreateDevice(0, &devHandle, CUDLA_CUDA_DLA);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in cuDLA create device = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  DPRINTF("Device created successfully\n");
+  resourceList.devHandle = devHandle;
+
+  err = cudlaModuleLoadFromMemory(devHandle, loadableData, file_size,
+                                  &moduleHandle, 0);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in cudlaModuleLoadFromMemory = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  } else {
+    DPRINTF("Successfully loaded module\n");
+  }
+
+  resourceList.moduleHandle = moduleHandle;
+
+  // Create CUDA stream.
+  result = hipStreamCreateWithFlags(&stream, hipStreamNonBlocking);
+
+  if (result != hipSuccess) {
+    errPtr = hipGetErrorName(result);
+    DPRINTF("Error in creating cuda stream = %s\n", errPtr);
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  resourceList.stream = stream;
+
+  // Get tensor attributes.
+  uint32_t numInputTensors = 0;
+  uint32_t numOutputTensors = 0;
+  cudlaModuleAttribute attribute;
+
+  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_NUM_INPUT_TENSORS,
+                                 &attribute);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in getting numInputTensors = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+  numInputTensors = attribute.numInputTensors;
+  DPRINTF("numInputTensors = %d\n", numInputTensors);
+
+  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_NUM_OUTPUT_TENSORS,
+                                 &attribute);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in getting numOutputTensors = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+  numOutputTensors = attribute.numOutputTensors;
+  DPRINTF("numOutputTensors = %d\n", numOutputTensors);
+
+  cudlaModuleTensorDescriptor* inputTensorDesc =
+      (cudlaModuleTensorDescriptor*)malloc(sizeof(cudlaModuleTensorDescriptor) *
+                                           numInputTensors);
+  cudlaModuleTensorDescriptor* outputTensorDesc =
+      (cudlaModuleTensorDescriptor*)malloc(sizeof(cudlaModuleTensorDescriptor) *
+                                           numOutputTensors);
+
+  if ((inputTensorDesc == NULL) || (outputTensorDesc == NULL)) {
+    if (inputTensorDesc != NULL) {
+      free(inputTensorDesc);
+      inputTensorDesc = NULL;
+    }
+
+    if (outputTensorDesc != NULL) {
+      free(outputTensorDesc);
+      outputTensorDesc = NULL;
+    }
+
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  resourceList.inputTensorDesc = inputTensorDesc;
+  resourceList.outputTensorDesc = outputTensorDesc;
+
+  attribute.inputTensorDesc = inputTensorDesc;
+  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_INPUT_TENSOR_DESCRIPTORS,
+                                 &attribute);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in getting input tensor descriptor = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+  DPRINTF("Printing input tensor descriptor\n");
+  printTensorDesc(inputTensorDesc);
+
+  attribute.outputTensorDesc = outputTensorDesc;
+  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_OUTPUT_TENSOR_DESCRIPTORS,
+                                 &attribute);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in getting output tensor descriptor = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+  DPRINTF("Printing output tensor descriptor\n");
+  printTensorDesc(outputTensorDesc);
+
+  // Setup the input and output buffers which will be used as an input to CUDA.
+  unsigned char* inputBuffer = (unsigned char*)malloc(inputTensorDesc[0].size);
+  if (inputBuffer == NULL) {
+    DPRINTF("Error in allocating input memory\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  resourceList.inputBuffer = inputBuffer;
+
+  unsigned char* outputBuffer =
+      (unsigned char*)malloc(outputTensorDesc[0].size);
+  if (outputBuffer == NULL) {
+    DPRINTF("Error in allocating output memory\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  resourceList.outputBuffer = outputBuffer;
+
+  memset(inputBuffer, 0x00, inputTensorDesc[0].size);
+  memset(outputBuffer, 0x00, outputTensorDesc[0].size);
+
+  // Fill up the buffers with data.
+  if (initializeInputBuffers(argv[2], inputTensorDesc, inputBuffer) != 0) {
+    DPRINTF("Error in initializing input buffer\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  // Allocate memory on GPU.
+  void* inputBufferGPU;
+  void* outputBufferGPU;
+  result = hipMalloc(&inputBufferGPU, inputTensorDesc[0].size);
+  if (result != hipSuccess) {
+    DPRINTF("Error in allocating input memory on GPU\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  resourceList.inputBufferGPU = inputBufferGPU;
+
+  result = hipMalloc(&outputBufferGPU, outputTensorDesc[0].size);
+  if (result != hipSuccess) {
+    DPRINTF("Error in allocating output memory on GPU\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  resourceList.outputBufferGPU = outputBufferGPU;
+
+  // Register the CUDA-allocated buffers.
+  uint64_t* inputBufferRegisteredPtr = NULL;
+  uint64_t* outputBufferRegisteredPtr = NULL;
+
+  err = cudlaMemRegister(devHandle, (uint64_t*)inputBufferGPU,
+                         inputTensorDesc[0].size, &inputBufferRegisteredPtr, 0);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in registering input memory = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  err =
+      cudlaMemRegister(devHandle, (uint64_t*)outputBufferGPU,
+                       outputTensorDesc[0].size, &outputBufferRegisteredPtr, 0);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in registering output memory = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+  DPRINTF("ALL MEMORY REGISTERED SUCCESSFULLY\n");
+
+  // Copy data from CPU buffers to GPU buffers.
+  result = hipMemcpyAsync(inputBufferGPU, inputBuffer, inputTensorDesc[0].size,
+                           hipMemcpyHostToDevice, stream);
+  if (result != hipSuccess) {
+    DPRINTF("Error in enqueueing memcpy for input\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+  result =
+      hipMemsetAsync(outputBufferGPU, 0, outputTensorDesc[0].size, stream);
+  if (result != hipSuccess) {
+    DPRINTF("Error in enqueueing memset for output\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  // Enqueue a cuDLA task.
+  cudlaTask task;
+  task.moduleHandle = moduleHandle;
+  task.outputTensor = &outputBufferRegisteredPtr;
+  task.numOutputTensors = 1;
+  task.numInputTensors = 1;
+  task.inputTensor = &inputBufferRegisteredPtr;
+  task.waitEvents = NULL;
+  task.signalEvents = NULL;
+  err = cudlaSubmitTask(devHandle, &task, 1, stream, 0);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in submitting task\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+  DPRINTF("SUBMIT IS DONE !!!\n");
+
+  // Wait for stream operations to finish and bring output buffer to CPU.
+  result =
+      hipMemcpyAsync(outputBuffer, outputBufferGPU, outputTensorDesc[0].size,
+                      hipMemcpyDeviceToHost, stream);
+  if (result != hipSuccess) {
+    DPRINTF("Error in bringing result back to CPU\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+  result = hipStreamSynchronize(stream);
+  if (result != hipSuccess) {
+    DPRINTF("Error in synchronizing stream\n");
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  // Output is available in outputBuffer.
+
+  // Teardown.
+  err = cudlaMemUnregister(devHandle, inputBufferRegisteredPtr);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in unregistering input memory = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  err = cudlaMemUnregister(devHandle, outputBufferRegisteredPtr);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in registering output memory = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  }
+  DPRINTF("ALL MEMORY UNREGISTERED SUCCESSFULLY\n");
+
+  free(inputTensorDesc);
+  free(outputTensorDesc);
+  free(loadableData);
+  free(inputBuffer);
+  free(outputBuffer);
+  hipFree(inputBufferGPU);
+  hipFree(outputBufferGPU);
+
+  resourceList.inputTensorDesc = NULL;
+  resourceList.outputTensorDesc = NULL;
+  resourceList.loadableData = NULL;
+  resourceList.inputBuffer = NULL;
+  resourceList.outputBuffer = NULL;
+  resourceList.inputBufferGPU = 0;
+  resourceList.outputBufferGPU = 0;
+
+  result = hipStreamDestroy(stream);
+  if (result != hipSuccess) {
+    errPtr = hipGetErrorName(result);
+    DPRINTF("Error in destroying cuda stream = %s\n", errPtr);
+    cleanUp(&resourceList);
+    return 1;
+  }
+
+  resourceList.stream = NULL;
+
+  err = cudlaModuleUnload(moduleHandle, 0);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in cudlaModuleUnload = %d\n", err);
+    cleanUp(&resourceList);
+    return 1;
+  } else {
+    DPRINTF("Successfully unloaded module\n");
+  }
+
+  resourceList.moduleHandle = NULL;
+
+  err = cudlaDestroyDevice(devHandle);
+  if (err != cudlaSuccess) {
+    DPRINTF("Error in cuDLA destroy device = %d\n", err);
+    return 1;
+  }
+  DPRINTF("Device destroyed successfully\n");
+
+  resourceList.devHandle = NULL;
+
+  DPRINTF("cuDLAHybridMode DONE !!!\n");
+
+  return 0;
+}
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/Makefile
index 58e7ead..76bfe83 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/Makefile
@@ -335,7 +335,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/README.md b/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/README.md
index 51f206f..21cdfb8 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/README.md
@@ -27,7 +27,7 @@ aarch64
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/Makefile
index 34068b6..941be48 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/Makefile
@@ -289,7 +289,7 @@ LIBRARIES :=
 
 ALL_CCFLAGS += --threads 0 --std=c++11
 
-LIBRARIES += -lcusolver -lnvJitLink -lcublas -lcusparse
+LIBRARIES += -lcusolver -lcublas -lcusparse
 
 ifeq ($(SAMPLE_ENABLED),0)
 EXEC ?= @echo "[@]"
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/NsightEclipse.xml
index de707a6..9405b39 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/NsightEclipse.xml
@@ -34,7 +34,6 @@
   </keywords>
   <libraries>
     <library>cusolver</library>
-    <library>nvJitLink</library>
     <library>cublas</library>
     <library>cusparse</library>
   </libraries>
@@ -56,6 +55,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/README.md b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/README.md
index eb31309..0b31194 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/README.md
@@ -10,7 +10,7 @@ Linear Algebra, CUSOLVER Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaMemcpy, cudaStreamDestroy, cudaFree, cudaDeviceSynchronize, cudaMemset, cuda
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2017.vcxproj
index d70eea9..cd859b9 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -62,7 +62,7 @@
     </ClCompile>
     <Link>
       <SubSystem>Console</SubSystem>
-      <AdditionalDependencies>cusolver.lib;nvJitLink.lib;cublas.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
+      <AdditionalDependencies>cusolver.lib;cublas.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
       <AdditionalLibraryDirectories>$(CudaToolkitLibDir);</AdditionalLibraryDirectories>
       <OutputFile>$(OutDir)/cuSolverDn_LinearSolver.exe</OutputFile>
     </Link>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2019.vcxproj
index 3ab272b..6155be1 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -58,7 +58,7 @@
     </ClCompile>
     <Link>
       <SubSystem>Console</SubSystem>
-      <AdditionalDependencies>cusolver.lib;nvJitLink.lib;cublas.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
+      <AdditionalDependencies>cusolver.lib;cublas.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
       <AdditionalLibraryDirectories>$(CudaToolkitLibDir);</AdditionalLibraryDirectories>
       <OutputFile>$(OutDir)/cuSolverDn_LinearSolver.exe</OutputFile>
     </Link>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2022.vcxproj
index 5d10614..9844892 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -58,7 +58,7 @@
     </ClCompile>
     <Link>
       <SubSystem>Console</SubSystem>
-      <AdditionalDependencies>cusolver.lib;nvJitLink.lib;cublas.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
+      <AdditionalDependencies>cusolver.lib;cublas.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
       <AdditionalLibraryDirectories>$(CudaToolkitLibDir);</AdditionalLibraryDirectories>
       <OutputFile>$(OutDir)/cuSolverDn_LinearSolver.exe</OutputFile>
     </Link>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/Makefile
index 4931be4..92fdc98 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/Makefile
@@ -285,7 +285,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
@@ -306,7 +306,7 @@ endif
 
 ALL_CCFLAGS += --threads 0 --std=c++11
 
-LIBRARIES += -lcusolver -lnvJitLink -lcublas -lcusparse
+LIBRARIES += -lcusolver -lcublas -lcusparse
 
 ifeq ($(SAMPLE_ENABLED),0)
 EXEC ?= @echo "[@]"
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/NsightEclipse.xml
index f9da843..84c56c8 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/NsightEclipse.xml
@@ -34,7 +34,6 @@
   </keywords>
   <libraries>
     <library>cusolver</library>
-    <library>nvJitLink</library>
     <library>cublas</library>
     <library>cusparse</library>
   </libraries>
@@ -55,6 +54,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/README.md b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/README.md
index 59cac0d..c268cf0 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/README.md
@@ -10,7 +10,7 @@ Linear Algebra, CUSOLVER Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaMemcpy, cudaStreamDestroy, cudaFree, cudaDeviceSynchronize, cudaMalloc, cuda
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2017.vcxproj
index 8d8509b..bcc7a6a 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -62,12 +62,12 @@
     </ClCompile>
     <Link>
       <SubSystem>Console</SubSystem>
-      <AdditionalDependencies>cusolver.lib;nvJitLink.lib;cublas.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
+      <AdditionalDependencies>cusolver.lib;cublas.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
       <AdditionalLibraryDirectories>$(CudaToolkitLibDir);</AdditionalLibraryDirectories>
       <OutputFile>$(OutDir)/cuSolverRf.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2019.vcxproj
index c40846e..16948fc 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -58,12 +58,12 @@
     </ClCompile>
     <Link>
       <SubSystem>Console</SubSystem>
-      <AdditionalDependencies>cusolver.lib;nvJitLink.lib;cublas.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
+      <AdditionalDependencies>cusolver.lib;cublas.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
       <AdditionalLibraryDirectories>$(CudaToolkitLibDir);</AdditionalLibraryDirectories>
       <OutputFile>$(OutDir)/cuSolverRf.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2022.vcxproj
index ab149fd..6de3db9 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -58,12 +58,12 @@
     </ClCompile>
     <Link>
       <SubSystem>Console</SubSystem>
-      <AdditionalDependencies>cusolver.lib;nvJitLink.lib;cublas.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
+      <AdditionalDependencies>cusolver.lib;cublas.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
       <AdditionalLibraryDirectories>$(CudaToolkitLibDir);</AdditionalLibraryDirectories>
       <OutputFile>$(OutDir)/cuSolverRf.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/Makefile
index 1e33a6d..04cdc6e 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/Makefile
@@ -285,7 +285,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
@@ -306,7 +306,7 @@ endif
 
 ALL_CCFLAGS += --threads 0 --std=c++11
 
-LIBRARIES += -lcusolver -lnvJitLink -lcusparse
+LIBRARIES += -lcusolver -lcusparse
 
 ifeq ($(SAMPLE_ENABLED),0)
 EXEC ?= @echo "[@]"
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/NsightEclipse.xml
index 8c1931e..f6b92a5 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/NsightEclipse.xml
@@ -33,7 +33,6 @@
   </keywords>
   <libraries>
     <library>cusolver</library>
-    <library>nvJitLink</library>
     <library>cusparse</library>
   </libraries>
   <librarypaths>
@@ -56,6 +55,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/README.md b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/README.md
index 8dd94c7..25ce286 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/README.md
@@ -10,7 +10,7 @@ Linear Algebra, CUSOLVER Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaStreamDestroy, cudaFree, cudaDeviceSynchronize, cudaMalloc, cudaStreamCreate
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver.cpp
index d42ac64..9e53a0a 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver.cpp
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver.cpp
@@ -546,13 +546,8 @@ int main(int argc, char *argv[]) {
            singularity, tol);
   }
   /* Q*x = z */
-  cusparseSpVecDescr_t vecz = NULL;
-  checkCudaErrors(cusparseCreateSpVec(&vecz, colsA, rowsA, d_Q, d_z, CUSPARSE_INDEX_32I,
-      CUSPARSE_INDEX_BASE_ZERO, CUDA_R_64F));
-  checkCudaErrors(cusparseScatter(cusparseHandle, vecz, vecx));
-  checkCudaErrors(cusparseDestroySpVec(vecz));
-
-  
+  checkCudaErrors(cusparseDsctr(cusparseHandle, rowsA, d_z, d_Q, d_x,
+                                CUSPARSE_INDEX_BASE_ZERO));
   checkCudaErrors(cudaDeviceSynchronize());
 
   stop = second();
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_hipified.cpp
index 4a390bb..d38a1cb 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_hipified.cpp
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_hipified.cpp
@@ -546,13 +546,8 @@ int main(int argc, char *argv[]) {
            singularity, tol);
   }
   /* Q*x = z */
-  hipsparseSpVecDescr_t vecz = NULL;
-  checkCudaErrors(hipsparseCreateSpVec(&vecz, colsA, rowsA, d_Q, d_z, HIPSPARSE_INDEX_32I,
-      HIPSPARSE_INDEX_BASE_ZERO, HIPBLAS_R_64F));
-  checkCudaErrors(hipsparseScatter(cusparseHandle, vecz, vecx));
-  checkCudaErrors(hipsparseDestroySpVec(vecz));
-
-  
+  checkCudaErrors(hipsparseDsctr(cusparseHandle, rowsA, d_z, d_Q, d_x,
+                                HIPSPARSE_INDEX_BASE_ZERO));
   checkCudaErrors(hipDeviceSynchronize());
 
   stop = second();
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2017.vcxproj
index d4ddca9..9978ec3 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -62,12 +62,12 @@
     </ClCompile>
     <Link>
       <SubSystem>Console</SubSystem>
-      <AdditionalDependencies>cusolver.lib;nvJitLink.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
+      <AdditionalDependencies>cusolver.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
       <AdditionalLibraryDirectories>$(CudaToolkitLibDir);</AdditionalLibraryDirectories>
       <OutputFile>$(OutDir)/cuSolverSp_LinearSolver.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2019.vcxproj
index 936022f..a7aef7d 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -58,12 +58,12 @@
     </ClCompile>
     <Link>
       <SubSystem>Console</SubSystem>
-      <AdditionalDependencies>cusolver.lib;nvJitLink.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
+      <AdditionalDependencies>cusolver.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
       <AdditionalLibraryDirectories>$(CudaToolkitLibDir);</AdditionalLibraryDirectories>
       <OutputFile>$(OutDir)/cuSolverSp_LinearSolver.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2022.vcxproj
index b0ce633..d6a6ef4 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -58,12 +58,12 @@
     </ClCompile>
     <Link>
       <SubSystem>Console</SubSystem>
-      <AdditionalDependencies>cusolver.lib;nvJitLink.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
+      <AdditionalDependencies>cusolver.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
       <AdditionalLibraryDirectories>$(CudaToolkitLibDir);</AdditionalLibraryDirectories>
       <OutputFile>$(OutDir)/cuSolverSp_LinearSolver.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/Makefile
index 87bd4b4..649da6f 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/Makefile
@@ -285,7 +285,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
@@ -306,7 +306,7 @@ endif
 
 ALL_CCFLAGS += --threads 0 --std=c++11
 
-LIBRARIES += -lcusolver -lnvJitLink -lcusparse
+LIBRARIES += -lcusolver -lcusparse
 
 ifeq ($(SAMPLE_ENABLED),0)
 EXEC ?= @echo "[@]"
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/NsightEclipse.xml
index 663d47d..65fa855 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/NsightEclipse.xml
@@ -32,7 +32,6 @@
   </keywords>
   <libraries>
     <library>cusolver</library>
-    <library>nvJitLink</library>
     <library>cusparse</library>
   </libraries>
   <librarypaths>
@@ -47,6 +46,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/README.md b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/README.md
index b432aea..3cf4112 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/README.md
@@ -10,7 +10,7 @@ Linear Algebra, CUSOLVER Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaMemcpy, cudaStreamDestroy, cudaFree, cudaMalloc, cudaStreamCreate
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2017.vcxproj
index 799ea95..d2c8031 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -62,12 +62,12 @@
     </ClCompile>
     <Link>
       <SubSystem>Console</SubSystem>
-      <AdditionalDependencies>cusolver.lib;nvJitLink.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
+      <AdditionalDependencies>cusolver.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
       <AdditionalLibraryDirectories>$(CudaToolkitLibDir);</AdditionalLibraryDirectories>
       <OutputFile>$(OutDir)/cuSolverSp_LowlevelCholesky.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2019.vcxproj
index 96cb1d7..2703da3 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -58,12 +58,12 @@
     </ClCompile>
     <Link>
       <SubSystem>Console</SubSystem>
-      <AdditionalDependencies>cusolver.lib;nvJitLink.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
+      <AdditionalDependencies>cusolver.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
       <AdditionalLibraryDirectories>$(CudaToolkitLibDir);</AdditionalLibraryDirectories>
       <OutputFile>$(OutDir)/cuSolverSp_LowlevelCholesky.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2022.vcxproj
index 200c0ae..b85749b 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -58,12 +58,12 @@
     </ClCompile>
     <Link>
       <SubSystem>Console</SubSystem>
-      <AdditionalDependencies>cusolver.lib;nvJitLink.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
+      <AdditionalDependencies>cusolver.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
       <AdditionalLibraryDirectories>$(CudaToolkitLibDir);</AdditionalLibraryDirectories>
       <OutputFile>$(OutDir)/cuSolverSp_LowlevelCholesky.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/Makefile
index 2d44ee2..2e7d1c9 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/Makefile
@@ -285,7 +285,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
@@ -306,7 +306,7 @@ endif
 
 ALL_CCFLAGS += --threads 0 --std=c++11
 
-LIBRARIES += -lcusolver -lnvJitLink -lcusparse
+LIBRARIES += -lcusolver -lcusparse
 
 ifeq ($(SAMPLE_ENABLED),0)
 EXEC ?= @echo "[@]"
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/NsightEclipse.xml
index 6c12276..51bab24 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/NsightEclipse.xml
@@ -33,7 +33,6 @@
   </keywords>
   <libraries>
     <library>cusolver</library>
-    <library>nvJitLink</library>
     <library>cusparse</library>
   </libraries>
   <librarypaths>
@@ -48,6 +47,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/README.md b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/README.md
index 1af5759..df5f2a8 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/README.md
@@ -10,7 +10,7 @@ Linear Algebra, CUSOLVER Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaMemcpy, cudaStreamDestroy, cudaFree, cudaMalloc, cudaStreamCreate
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2017.vcxproj
index 3a9edfc..b25aa37 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -62,12 +62,12 @@
     </ClCompile>
     <Link>
       <SubSystem>Console</SubSystem>
-      <AdditionalDependencies>cusolver.lib;nvJitLink.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
+      <AdditionalDependencies>cusolver.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
       <AdditionalLibraryDirectories>$(CudaToolkitLibDir);</AdditionalLibraryDirectories>
       <OutputFile>$(OutDir)/cuSolverSp_LowlevelQR.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2019.vcxproj
index 6b1907f..af967c4 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -58,12 +58,12 @@
     </ClCompile>
     <Link>
       <SubSystem>Console</SubSystem>
-      <AdditionalDependencies>cusolver.lib;nvJitLink.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
+      <AdditionalDependencies>cusolver.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
       <AdditionalLibraryDirectories>$(CudaToolkitLibDir);</AdditionalLibraryDirectories>
       <OutputFile>$(OutDir)/cuSolverSp_LowlevelQR.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2022.vcxproj
index f1f2a95..bb98790 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -58,12 +58,12 @@
     </ClCompile>
     <Link>
       <SubSystem>Console</SubSystem>
-      <AdditionalDependencies>cusolver.lib;nvJitLink.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
+      <AdditionalDependencies>cusolver.lib;cusparse.lib;cudart_static.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;comdlg32.lib;advapi32.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;odbc32.lib;odbccp32.lib;%(AdditionalDependencies)</AdditionalDependencies>
       <AdditionalLibraryDirectories>$(CudaToolkitLibDir);</AdditionalLibraryDirectories>
       <OutputFile>$(OutDir)/cuSolverSp_LowlevelQR.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/Makefile b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/Makefile
index 2f44cab..f6561b1 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/Makefile
@@ -329,7 +329,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/README.md b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/README.md
index cf37bb3..2e12e22 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/README.md
@@ -33,7 +33,7 @@ cudaExternalMemoryGetMappedBuffer, cudaImportExternalSemaphore, cudaDeviceGetAtt
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/Makefile b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/Makefile
index 8da4909..f9a79cd 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/Makefile
@@ -340,7 +340,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/README.md b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/README.md
index 346141c..9d1cd13 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/README.md
@@ -33,7 +33,7 @@ cudaImportExternalSemaphore, cudaGetMipmappedArrayLevel, cudaSetDevice, cudaDest
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer.cu b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer.cu
index 1a9279b..215efe0 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer.cu
+++ b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer.cu
@@ -1,428 +1,428 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <iostream>
-
-#include <cuda_runtime.h>
-#include "cuda_consumer.h"
-#include <helper_image.h>
-#include "nvmedia_image_nvscibuf.h"
-#include "nvmedia_utils/cmdline.h"
-
-// Enable this to 1 if require cuda processed output to ppm file.
-#define WRITE_OUTPUT_IMAGE 0
-
-#define checkNvSciErrors(call)                              \
-  do {                                                      \
-    NvSciError _status = call;                              \
-    if (NvSciError_Success != _status) {                    \
-      printf(                                               \
-          "NVSCI call in file '%s' in line %i returned"     \
-          " %d, expected %d\n",                             \
-          __FILE__, __LINE__, _status, NvSciError_Success); \
-      fflush(stdout);                                       \
-      exit(EXIT_FAILURE);                                   \
-    }                                                       \
-  } while (0)
-
-__global__ static void yuvToGrayscale(cudaSurfaceObject_t surfaceObject,
-                                      unsigned int *dstImage,
-                                      int32_t imageWidth, int32_t imageHeight) {
-  size_t x = blockIdx.x * blockDim.x + threadIdx.x;
-  size_t y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  uchar4 *dstImageUchar4 = (uchar4 *)dstImage;
-  for (; x < imageWidth && y < imageHeight;
-       x += gridDim.x * blockDim.x, y += gridDim.y * blockDim.y) {
-    int colInBytes = x * sizeof(unsigned char);
-    unsigned char luma =
-        surf2Dread<unsigned char>(surfaceObject, colInBytes, y);
-    uchar4 grayscalePix = make_uchar4(luma, luma, luma, 0);
-
-    dstImageUchar4[y * imageWidth + x] = grayscalePix;
-  }
-}
-
-static void cudaImportNvSciSync(cudaExternalSemaphore_t &extSem,
-                                NvSciSyncObj &syncObj) {
-  cudaExternalSemaphoreHandleDesc extSemDesc;
-  memset(&extSemDesc, 0, sizeof(extSemDesc));
-  extSemDesc.type = cudaExternalSemaphoreHandleTypeNvSciSync;
-  extSemDesc.handle.nvSciSyncObj = (void *)syncObj;
-
-  checkCudaErrors(cudaImportExternalSemaphore(&extSem, &extSemDesc));
-}
-
-static void waitExternalSemaphore(cudaExternalSemaphore_t &waitSem,
-                                  NvSciSyncFence *fence, cudaStream_t stream) {
-  cudaExternalSemaphoreWaitParams waitParams;
-  memset(&waitParams, 0, sizeof(waitParams));
-  // For cross-process signaler-waiter applications need to use NvSciIpc
-  // and NvSciSync[Export|Import] utilities to share the NvSciSyncFence
-  // across process. This step is optional in single-process.
-  waitParams.params.nvSciSync.fence = (void *)fence;
-  waitParams.flags = 0;
-
-  checkCudaErrors(
-      cudaWaitExternalSemaphoresAsync(&waitSem, &waitParams, 1, stream));
-}
-
-static void signalExternalSemaphore(cudaExternalSemaphore_t &signalSem,
-                                    NvSciSyncFence *fence,
-                                    cudaStream_t stream) {
-  cudaExternalSemaphoreSignalParams signalParams;
-  memset(&signalParams, 0, sizeof(signalParams));
-  // For cross-process signaler-waiter applications need to use NvSciIpc
-  // and NvSciSync[Export|Import] utilities to share the NvSciSyncFence
-  // across process. This step is optional in single-process.
-  signalParams.params.nvSciSync.fence = (void *)fence;
-  signalParams.flags = 0;
-
-  checkCudaErrors(
-      cudaSignalExternalSemaphoresAsync(&signalSem, &signalParams, 1, stream));
-}
-
-static void yuvToGrayscaleCudaKernel(cudaExternalResInterop &cudaExtResObj,
-                                     int32_t imageWidth, int32_t imageHeight) {
-#if WRITE_OUTPUT_IMAGE
-  unsigned int *h_dstImage;
-  checkCudaErrors(cudaMallocHost(
-      &h_dstImage, sizeof(unsigned int) * imageHeight * imageWidth));
-#endif
-  dim3 block(16, 16, 1);
-  dim3 grid((imageWidth / block.x) + 1, (imageHeight / block.y) + 1, 1);
-
-  yuvToGrayscale<<<grid, block, 0, cudaExtResObj.stream>>>(
-      cudaExtResObj.cudaSurfaceNvmediaBuf[0], cudaExtResObj.d_outputImage,
-      imageWidth, imageHeight);
-
-#if WRITE_OUTPUT_IMAGE
-  checkCudaErrors(
-      cudaMemcpyAsync(h_dstImage, cudaExtResObj.d_outputImage,
-                      sizeof(unsigned int) * imageHeight * imageWidth,
-                      cudaMemcpyDeviceToHost, cudaExtResObj.stream));
-  checkCudaErrors(cudaStreamSynchronize(cudaExtResObj.stream));
-  char outputFilename[1024];
-  std::string image_filename = "Grayscale";
-  strcpy(outputFilename, image_filename.c_str());
-  strcpy(outputFilename + image_filename.length(), "_nvsci_out.ppm");
-  sdkSavePPM4ub(outputFilename, (unsigned char *)h_dstImage, imageWidth,
-                imageHeight);
-  printf("Wrote '%s'\n", outputFilename);
-  checkCudaErrors(cudaFreeHost(h_dstImage));
-#endif
-}
-
-static void cudaImportNvSciImage(cudaExternalResInterop &cudaExtResObj,
-                                 NvSciBufObj &inputBufObj) {
-  NvSciBufModule module = NULL;
-  NvSciBufAttrList attrlist = NULL;
-  NvSciBufAttrKeyValuePair pairArrayOut[10];
-
-  checkNvSciErrors(NvSciBufModuleOpen(&module));
-  checkNvSciErrors(NvSciBufAttrListCreate(module, &attrlist));
-  checkNvSciErrors(NvSciBufObjGetAttrList(inputBufObj, &attrlist));
-
-  memset(pairArrayOut, 0, sizeof(NvSciBufAttrKeyValuePair) * 10);
-
-  int numAttrs = 0;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_Size;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneChannelCount;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneCount;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneWidth;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneHeight;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_Layout;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneBitsPerPixel;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneOffset;
-
-  checkNvSciErrors(NvSciBufAttrListGetAttrs(attrlist, pairArrayOut, numAttrs));
-
-  uint64_t size = *(uint64_t *)pairArrayOut[0].value;
-  uint8_t channelCount = *(uint8_t *)pairArrayOut[1].value;
-  cudaExtResObj.planeCount = *(int32_t *)pairArrayOut[2].value;
-  cudaExtResObj.imageWidth =
-      (int32_t *)malloc(sizeof(int32_t) * cudaExtResObj.planeCount);
-  cudaExtResObj.imageHeight =
-      (int32_t *)malloc(sizeof(int32_t) * cudaExtResObj.planeCount);
-  cudaExtResObj.planeOffset =
-      (uint64_t *)malloc(sizeof(uint64_t) * cudaExtResObj.planeCount);
-
-  memcpy(cudaExtResObj.imageWidth, (int32_t *)pairArrayOut[3].value,
-         cudaExtResObj.planeCount * sizeof(int32_t));
-  memcpy(cudaExtResObj.imageHeight, (int32_t *)pairArrayOut[4].value,
-         cudaExtResObj.planeCount * sizeof(int32_t));
-  memcpy(cudaExtResObj.planeOffset, (uint64_t *)pairArrayOut[7].value,
-         cudaExtResObj.planeCount * sizeof(uint64_t));
-
-  NvSciBufAttrValImageLayoutType layout =
-      *(NvSciBufAttrValImageLayoutType *)pairArrayOut[5].value;
-  uint32_t bitsPerPixel = *(uint32_t *)pairArrayOut[6].value;
-
-  if (layout != NvSciBufImage_BlockLinearType) {
-    printf("Image layout is not block linear.. waiving execution\n");
-    exit(EXIT_WAIVED);
-  }
-
-  cudaExternalMemoryHandleDesc memHandleDesc;
-  memset(&memHandleDesc, 0, sizeof(memHandleDesc));
-  memHandleDesc.type = cudaExternalMemoryHandleTypeNvSciBuf;
-  memHandleDesc.handle.nvSciBufObject = inputBufObj;
-  memHandleDesc.size = size;
-  checkCudaErrors(
-      cudaImportExternalMemory(&cudaExtResObj.extMemImageBuf, &memHandleDesc));
-
-  cudaExtResObj.d_mipmapArray = (cudaMipmappedArray_t *)malloc(
-      sizeof(cudaMipmappedArray_t) * cudaExtResObj.planeCount);
-
-  for (int i = 0; i < cudaExtResObj.planeCount; i++) {
-    cudaExtent extent = {};
-    memset(&extent, 0, sizeof(extent));
-    extent.width = cudaExtResObj.imageWidth[i];
-    extent.height = cudaExtResObj.imageHeight[i];
-    extent.depth = 0;
-    cudaChannelFormatDesc desc;
-    switch (channelCount) {
-      case 1:
-      default:
-        desc = cudaCreateChannelDesc(bitsPerPixel, 0, 0, 0,
-                                     cudaChannelFormatKindUnsigned);
-        break;
-      case 2:
-        desc = cudaCreateChannelDesc(bitsPerPixel, bitsPerPixel, 0, 0,
-                                     cudaChannelFormatKindUnsigned);
-        break;
-      case 3:
-        desc = cudaCreateChannelDesc(bitsPerPixel, bitsPerPixel, bitsPerPixel,
-                                     0, cudaChannelFormatKindUnsigned);
-        break;
-      case 4:
-        desc =
-            cudaCreateChannelDesc(bitsPerPixel, bitsPerPixel, bitsPerPixel,
-                                  bitsPerPixel, cudaChannelFormatKindUnsigned);
-        break;
-    }
-
-    cudaExternalMemoryMipmappedArrayDesc mipmapDesc = {0};
-    mipmapDesc.offset = cudaExtResObj.planeOffset[i];
-    mipmapDesc.formatDesc = desc;
-    mipmapDesc.extent = extent;
-    mipmapDesc.flags = 0;
-    mipmapDesc.numLevels = 1;
-    checkCudaErrors(cudaExternalMemoryGetMappedMipmappedArray(
-        &cudaExtResObj.d_mipmapArray[i], cudaExtResObj.extMemImageBuf,
-        &mipmapDesc));
-  }
-}
-
-static cudaSurfaceObject_t createCudaSurface(cudaArray_t &d_mipLevelArray) {
-  cudaResourceDesc resourceDesc;
-  memset(&resourceDesc, 0, sizeof(resourceDesc));
-  resourceDesc.resType = cudaResourceTypeArray;
-  resourceDesc.res.array.array = d_mipLevelArray;
-
-  cudaSurfaceObject_t surfaceObject;
-  checkCudaErrors(cudaCreateSurfaceObject(&surfaceObject, &resourceDesc));
-  return surfaceObject;
-}
-
-static cudaStream_t createCudaStream(int deviceId) {
-  checkCudaErrors(cudaSetDevice(deviceId));
-  cudaStream_t stream;
-  checkCudaErrors(cudaStreamCreateWithFlags(&stream, cudaStreamNonBlocking));
-  return stream;
-}
-
-// CUDA setup buffers/synchronization objects for interop via NvSci API.
-void setupCuda(cudaExternalResInterop &cudaExtResObj, NvSciBufObj &inputBufObj,
-               NvSciSyncObj &syncObj, NvSciSyncObj &cudaSignalerSyncObj,
-               int deviceId) {
-  checkCudaErrors(cudaSetDevice(deviceId));
-  cudaImportNvSciSync(cudaExtResObj.waitSem, syncObj);
-  cudaImportNvSciSync(cudaExtResObj.signalSem, cudaSignalerSyncObj);
-
-  cudaImportNvSciImage(cudaExtResObj, inputBufObj);
-  cudaExtResObj.d_mipLevelArray =
-      (cudaArray_t *)malloc(sizeof(cudaArray_t) * cudaExtResObj.planeCount);
-  cudaExtResObj.cudaSurfaceNvmediaBuf = (cudaSurfaceObject_t *)malloc(
-      sizeof(cudaSurfaceObject_t) * cudaExtResObj.planeCount);
-
-  for (int i = 0; i < cudaExtResObj.planeCount; ++i) {
-    uint32_t mipLevelId = 0;
-    checkCudaErrors(
-        cudaGetMipmappedArrayLevel(&cudaExtResObj.d_mipLevelArray[i],
-                                   cudaExtResObj.d_mipmapArray[i], mipLevelId));
-    cudaExtResObj.cudaSurfaceNvmediaBuf[i] =
-        createCudaSurface(cudaExtResObj.d_mipLevelArray[i]);
-  }
-
-  cudaExtResObj.stream = createCudaStream(deviceId);
-  checkCudaErrors(cudaMalloc(&cudaExtResObj.d_outputImage,
-                             sizeof(unsigned int) *
-                                 cudaExtResObj.imageWidth[0] *
-                                 cudaExtResObj.imageHeight[0]));
-}
-
-// CUDA clean up buffers used **with** NvSci API.
-void cleanupCuda(cudaExternalResInterop &cudaExtResObj) {
-  for (int i = 0; i < cudaExtResObj.planeCount; i++) {
-    checkCudaErrors(
-        cudaDestroySurfaceObject(cudaExtResObj.cudaSurfaceNvmediaBuf[i]));
-    checkCudaErrors(cudaFreeMipmappedArray(cudaExtResObj.d_mipmapArray[i]));
-  }
-  free(cudaExtResObj.d_mipmapArray);
-  free(cudaExtResObj.d_mipLevelArray);
-  free(cudaExtResObj.cudaSurfaceNvmediaBuf);
-  free(cudaExtResObj.imageWidth);
-  free(cudaExtResObj.imageHeight);
-  checkCudaErrors(cudaDestroyExternalSemaphore(cudaExtResObj.waitSem));
-  checkCudaErrors(cudaDestroyExternalSemaphore(cudaExtResObj.signalSem));
-  checkCudaErrors(cudaDestroyExternalMemory(cudaExtResObj.extMemImageBuf));
-  checkCudaErrors(cudaStreamDestroy(cudaExtResObj.stream));
-  checkCudaErrors(cudaFree(cudaExtResObj.d_outputImage));
-}
-
-void runCudaOperation(cudaExternalResInterop &cudaExtResObj,
-                      NvSciSyncFence *cudaWaitFence,
-                      NvSciSyncFence *cudaSignalFence, int deviceId,
-                      int iterations) {
-  checkCudaErrors(cudaSetDevice(deviceId));
-  static int64_t launch = 0;
-
-  waitExternalSemaphore(cudaExtResObj.waitSem, cudaWaitFence,
-                        cudaExtResObj.stream);
-
-  // run cuda kernel over surface object of the LUMA surface part to extract
-  // grayscale.
-  yuvToGrayscaleCudaKernel(cudaExtResObj, cudaExtResObj.imageWidth[0],
-                           cudaExtResObj.imageHeight[0]);
-
-  // signal fence till the second last iterations for NvMedia2DBlit to wait for
-  // cuda signal and for final iteration as there is no corresponding NvMedia
-  // operation pending therefore we end with cudaStreamSynchronize()
-  if (launch < iterations - 1) {
-    signalExternalSemaphore(cudaExtResObj.signalSem, cudaSignalFence,
-                            cudaExtResObj.stream);
-  } else {
-    checkCudaErrors(cudaStreamSynchronize(cudaExtResObj.stream));
-  }
-  launch++;
-}
-
-// CUDA imports and operates on NvSci buffer/synchronization objects
-void setupCuda(Blit2DTest *ctx, cudaResources &cudaResObj, int deviceId) {
-  checkCudaErrors(cudaSetDevice(deviceId));
-  cudaResObj.d_yuvArray =
-      (cudaArray_t *)malloc(sizeof(cudaArray_t) * ctx->numSurfaces);
-  cudaResObj.cudaSurfaceNvmediaBuf = (cudaSurfaceObject_t *)malloc(
-      sizeof(cudaSurfaceObject_t) * ctx->numSurfaces);
-  cudaChannelFormatDesc channelDesc;
-  switch (ctx->bytesPerPixel) {
-    case 1:
-    default:
-      channelDesc =
-          cudaCreateChannelDesc(8, 0, 0, 0, cudaChannelFormatKindUnsigned);
-      break;
-  }
-
-  for (int k = 0; k < ctx->numSurfaces; k++) {
-    checkCudaErrors(cudaMallocArray(
-        &cudaResObj.d_yuvArray[k], &channelDesc,
-        ctx->widthSurface * ctx->xScalePtr[k] * ctx->bytesPerPixel,
-        ctx->heightSurface * ctx->yScalePtr[k]));
-    cudaResObj.cudaSurfaceNvmediaBuf[k] =
-        createCudaSurface(cudaResObj.d_yuvArray[k]);
-  }
-  checkCudaErrors(cudaMalloc(
-      &cudaResObj.d_outputImage,
-      sizeof(unsigned int) * ctx->widthSurface * ctx->heightSurface));
-
-  cudaResObj.stream = createCudaStream(deviceId);
-}
-
-// CUDA clean up buffers used **without** NvSci API.
-void cleanupCuda(Blit2DTest *ctx, cudaResources &cudaResObj) {
-  for (int k = 0; k < ctx->numSurfaces; k++) {
-    checkCudaErrors(
-        cudaDestroySurfaceObject(cudaResObj.cudaSurfaceNvmediaBuf[k]));
-    checkCudaErrors(cudaFreeArray(cudaResObj.d_yuvArray[k]));
-  }
-
-  free(cudaResObj.cudaSurfaceNvmediaBuf);
-
-  checkCudaErrors(cudaStreamDestroy(cudaResObj.stream));
-  checkCudaErrors(cudaFree(cudaResObj.d_outputImage));
-}
-
-static void yuvToGrayscaleCudaKernelNonNvSci(cudaResources &cudaResObj,
-                                             int deviceId, int32_t imageWidth,
-                                             int32_t imageHeight) {
-#if WRITE_OUTPUT_IMAGE
-  unsigned int *h_dstImage;
-  checkCudaErrors(cudaMallocHost(
-      &h_dstImage, sizeof(unsigned int) * imageHeight * imageWidth));
-#endif
-  dim3 block(16, 16, 1);
-  dim3 grid((imageWidth / block.x) + 1, (imageHeight / block.y) + 1, 1);
-
-  yuvToGrayscale<<<grid, block, 0, cudaResObj.stream>>>(
-      cudaResObj.cudaSurfaceNvmediaBuf[0], cudaResObj.d_outputImage, imageWidth,
-      imageHeight);
-
-#if WRITE_OUTPUT_IMAGE
-  checkCudaErrors(
-      cudaMemcpyAsync(h_dstImage, cudaResObj.d_outputImage,
-                      sizeof(unsigned int) * imageHeight * imageWidth,
-                      cudaMemcpyDeviceToHost, cudaResObj.stream));
-  checkCudaErrors(cudaStreamSynchronize(cudaResObj.stream));
-  char outputFilename[1024];
-  std::string image_filename = "Grayscale";
-  strcpy(outputFilename, image_filename.c_str());
-  strcpy(outputFilename + image_filename.length(), "_non-nvsci_out.ppm");
-  sdkSavePPM4ub(outputFilename, (unsigned char *)h_dstImage, imageWidth,
-                imageHeight);
-  printf("Wrote '%s'\n", outputFilename);
-  checkCudaErrors(cudaFreeHost(h_dstImage));
-#else
-  checkCudaErrors(cudaStreamSynchronize(cudaResObj.stream));
-#endif
-}
-
-// CUDA operates **without** NvSci APIs buffer/synchronization objects.
-void runCudaOperation(Blit2DTest *ctx, cudaResources &cudaResObj,
-                      int deviceId) {
-  for (int k = 0; k < ctx->numSurfaces; k++) {
-    checkCudaErrors(cudaMemcpy2DToArray(
-        cudaResObj.d_yuvArray[k], 0, 0, ctx->dstBuff[k],
-        ctx->widthSurface * ctx->xScalePtr[k] * ctx->bytesPerPixel,
-        ctx->widthSurface * ctx->xScalePtr[k] * ctx->bytesPerPixel,
-        ctx->heightSurface * ctx->yScalePtr[k], cudaMemcpyHostToDevice));
-  }
-  // run cuda kernel over surface object of the LUMA surface part to extract
-  // grayscale.
-  yuvToGrayscaleCudaKernelNonNvSci(cudaResObj, deviceId, ctx->widthSurface,
-                                   ctx->heightSurface);
-}
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <iostream>
+
+#include <cuda_runtime.h>
+#include "cuda_consumer.h"
+#include <helper_image.h>
+#include "nvmedia_image_nvscibuf.h"
+#include "nvmedia_utils/cmdline.h"
+
+// Enable this to 1 if require cuda processed output to ppm file.
+#define WRITE_OUTPUT_IMAGE 0
+
+#define checkNvSciErrors(call)                              \
+  do {                                                      \
+    NvSciError _status = call;                              \
+    if (NvSciError_Success != _status) {                    \
+      printf(                                               \
+          "NVSCI call in file '%s' in line %i returned"     \
+          " %d, expected %d\n",                             \
+          __FILE__, __LINE__, _status, NvSciError_Success); \
+      fflush(stdout);                                       \
+      exit(EXIT_FAILURE);                                   \
+    }                                                       \
+  } while (0)
+
+__global__ static void yuvToGrayscale(cudaSurfaceObject_t surfaceObject,
+                                      unsigned int *dstImage,
+                                      int32_t imageWidth, int32_t imageHeight) {
+  size_t x = blockIdx.x * blockDim.x + threadIdx.x;
+  size_t y = blockIdx.y * blockDim.y + threadIdx.y;
+
+  uchar4 *dstImageUchar4 = (uchar4 *)dstImage;
+  for (; x < imageWidth && y < imageHeight;
+       x += gridDim.x * blockDim.x, y += gridDim.y * blockDim.y) {
+    int colInBytes = x * sizeof(unsigned char);
+    unsigned char luma =
+        surf2Dread<unsigned char>(surfaceObject, colInBytes, y);
+    uchar4 grayscalePix = make_uchar4(luma, luma, luma, 0);
+
+    dstImageUchar4[y * imageWidth + x] = grayscalePix;
+  }
+}
+
+static void cudaImportNvSciSync(cudaExternalSemaphore_t &extSem,
+                                NvSciSyncObj &syncObj) {
+  cudaExternalSemaphoreHandleDesc extSemDesc;
+  memset(&extSemDesc, 0, sizeof(extSemDesc));
+  extSemDesc.type = cudaExternalSemaphoreHandleTypeNvSciSync;
+  extSemDesc.handle.nvSciSyncObj = (void *)syncObj;
+
+  checkCudaErrors(cudaImportExternalSemaphore(&extSem, &extSemDesc));
+}
+
+static void waitExternalSemaphore(cudaExternalSemaphore_t &waitSem,
+                                  NvSciSyncFence *fence, cudaStream_t stream) {
+  cudaExternalSemaphoreWaitParams waitParams;
+  memset(&waitParams, 0, sizeof(waitParams));
+  // For cross-process signaler-waiter applications need to use NvSciIpc
+  // and NvSciSync[Export|Import] utilities to share the NvSciSyncFence
+  // across process. This step is optional in single-process.
+  waitParams.params.nvSciSync.fence = (void *)fence;
+  waitParams.flags = 0;
+
+  checkCudaErrors(
+      cudaWaitExternalSemaphoresAsync(&waitSem, &waitParams, 1, stream));
+}
+
+static void signalExternalSemaphore(cudaExternalSemaphore_t &signalSem,
+                                    NvSciSyncFence *fence,
+                                    cudaStream_t stream) {
+  cudaExternalSemaphoreSignalParams signalParams;
+  memset(&signalParams, 0, sizeof(signalParams));
+  // For cross-process signaler-waiter applications need to use NvSciIpc
+  // and NvSciSync[Export|Import] utilities to share the NvSciSyncFence
+  // across process. This step is optional in single-process.
+  signalParams.params.nvSciSync.fence = (void *)fence;
+  signalParams.flags = 0;
+
+  checkCudaErrors(
+      cudaSignalExternalSemaphoresAsync(&signalSem, &signalParams, 1, stream));
+}
+
+static void yuvToGrayscaleCudaKernel(cudaExternalResInterop &cudaExtResObj,
+                                     int32_t imageWidth, int32_t imageHeight) {
+#if WRITE_OUTPUT_IMAGE
+  unsigned int *h_dstImage;
+  checkCudaErrors(cudaMallocHost(
+      &h_dstImage, sizeof(unsigned int) * imageHeight * imageWidth));
+#endif
+  dim3 block(16, 16, 1);
+  dim3 grid((imageWidth / block.x) + 1, (imageHeight / block.y) + 1, 1);
+
+  yuvToGrayscale<<<grid, block, 0, cudaExtResObj.stream>>>(
+      cudaExtResObj.cudaSurfaceNvmediaBuf[0], cudaExtResObj.d_outputImage,
+      imageWidth, imageHeight);
+
+#if WRITE_OUTPUT_IMAGE
+  checkCudaErrors(
+      cudaMemcpyAsync(h_dstImage, cudaExtResObj.d_outputImage,
+                      sizeof(unsigned int) * imageHeight * imageWidth,
+                      cudaMemcpyDeviceToHost, cudaExtResObj.stream));
+  checkCudaErrors(cudaStreamSynchronize(cudaExtResObj.stream));
+  char outputFilename[1024];
+  std::string image_filename = "Grayscale";
+  strcpy(outputFilename, image_filename.c_str());
+  strcpy(outputFilename + image_filename.length(), "_nvsci_out.ppm");
+  sdkSavePPM4ub(outputFilename, (unsigned char *)h_dstImage, imageWidth,
+                imageHeight);
+  printf("Wrote '%s'\n", outputFilename);
+  checkCudaErrors(cudaFreeHost(h_dstImage));
+#endif
+}
+
+static void cudaImportNvSciImage(cudaExternalResInterop &cudaExtResObj,
+                                 NvSciBufObj &inputBufObj) {
+  NvSciBufModule module = NULL;
+  NvSciBufAttrList attrlist = NULL;
+  NvSciBufAttrKeyValuePair pairArrayOut[10];
+
+  checkNvSciErrors(NvSciBufModuleOpen(&module));
+  checkNvSciErrors(NvSciBufAttrListCreate(module, &attrlist));
+  checkNvSciErrors(NvSciBufObjGetAttrList(inputBufObj, &attrlist));
+
+  memset(pairArrayOut, 0, sizeof(NvSciBufAttrKeyValuePair) * 10);
+
+  int numAttrs = 0;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_Size;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneChannelCount;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneCount;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneWidth;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneHeight;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_Layout;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneBitsPerPixel;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneOffset;
+
+  checkNvSciErrors(NvSciBufAttrListGetAttrs(attrlist, pairArrayOut, numAttrs));
+
+  uint64_t size = *(uint64_t *)pairArrayOut[0].value;
+  uint8_t channelCount = *(uint8_t *)pairArrayOut[1].value;
+  cudaExtResObj.planeCount = *(int32_t *)pairArrayOut[2].value;
+  cudaExtResObj.imageWidth =
+      (int32_t *)malloc(sizeof(int32_t) * cudaExtResObj.planeCount);
+  cudaExtResObj.imageHeight =
+      (int32_t *)malloc(sizeof(int32_t) * cudaExtResObj.planeCount);
+  cudaExtResObj.planeOffset =
+      (uint64_t *)malloc(sizeof(uint64_t) * cudaExtResObj.planeCount);
+
+  memcpy(cudaExtResObj.imageWidth, (int32_t *)pairArrayOut[3].value,
+         cudaExtResObj.planeCount * sizeof(int32_t));
+  memcpy(cudaExtResObj.imageHeight, (int32_t *)pairArrayOut[4].value,
+         cudaExtResObj.planeCount * sizeof(int32_t));
+  memcpy(cudaExtResObj.planeOffset, (uint64_t *)pairArrayOut[7].value,
+         cudaExtResObj.planeCount * sizeof(uint64_t));
+
+  NvSciBufAttrValImageLayoutType layout =
+      *(NvSciBufAttrValImageLayoutType *)pairArrayOut[5].value;
+  uint32_t bitsPerPixel = *(uint32_t *)pairArrayOut[6].value;
+
+  if (layout != NvSciBufImage_BlockLinearType) {
+    printf("Image layout is not block linear.. waiving execution\n");
+    exit(EXIT_WAIVED);
+  }
+
+  cudaExternalMemoryHandleDesc memHandleDesc;
+  memset(&memHandleDesc, 0, sizeof(memHandleDesc));
+  memHandleDesc.type = cudaExternalMemoryHandleTypeNvSciBuf;
+  memHandleDesc.handle.nvSciBufObject = inputBufObj;
+  memHandleDesc.size = size;
+  checkCudaErrors(
+      cudaImportExternalMemory(&cudaExtResObj.extMemImageBuf, &memHandleDesc));
+
+  cudaExtResObj.d_mipmapArray = (cudaMipmappedArray_t *)malloc(
+      sizeof(cudaMipmappedArray_t) * cudaExtResObj.planeCount);
+
+  for (int i = 0; i < cudaExtResObj.planeCount; i++) {
+    cudaExtent extent = {};
+    memset(&extent, 0, sizeof(extent));
+    extent.width = cudaExtResObj.imageWidth[i];
+    extent.height = cudaExtResObj.imageHeight[i];
+    extent.depth = 0;
+    cudaChannelFormatDesc desc;
+    switch (channelCount) {
+      case 1:
+      default:
+        desc = cudaCreateChannelDesc(bitsPerPixel, 0, 0, 0,
+                                     cudaChannelFormatKindUnsigned);
+        break;
+      case 2:
+        desc = cudaCreateChannelDesc(bitsPerPixel, bitsPerPixel, 0, 0,
+                                     cudaChannelFormatKindUnsigned);
+        break;
+      case 3:
+        desc = cudaCreateChannelDesc(bitsPerPixel, bitsPerPixel, bitsPerPixel,
+                                     0, cudaChannelFormatKindUnsigned);
+        break;
+      case 4:
+        desc =
+            cudaCreateChannelDesc(bitsPerPixel, bitsPerPixel, bitsPerPixel,
+                                  bitsPerPixel, cudaChannelFormatKindUnsigned);
+        break;
+    }
+
+    cudaExternalMemoryMipmappedArrayDesc mipmapDesc = {0};
+    mipmapDesc.offset = cudaExtResObj.planeOffset[i];
+    mipmapDesc.formatDesc = desc;
+    mipmapDesc.extent = extent;
+    mipmapDesc.flags = 0;
+    mipmapDesc.numLevels = 1;
+    checkCudaErrors(cudaExternalMemoryGetMappedMipmappedArray(
+        &cudaExtResObj.d_mipmapArray[i], cudaExtResObj.extMemImageBuf,
+        &mipmapDesc));
+  }
+}
+
+static cudaSurfaceObject_t createCudaSurface(cudaArray_t &d_mipLevelArray) {
+  cudaResourceDesc resourceDesc;
+  memset(&resourceDesc, 0, sizeof(resourceDesc));
+  resourceDesc.resType = cudaResourceTypeArray;
+  resourceDesc.res.array.array = d_mipLevelArray;
+
+  cudaSurfaceObject_t surfaceObject;
+  checkCudaErrors(cudaCreateSurfaceObject(&surfaceObject, &resourceDesc));
+  return surfaceObject;
+}
+
+static cudaStream_t createCudaStream(int deviceId) {
+  checkCudaErrors(cudaSetDevice(deviceId));
+  cudaStream_t stream;
+  checkCudaErrors(cudaStreamCreateWithFlags(&stream, cudaStreamNonBlocking));
+  return stream;
+}
+
+// CUDA setup buffers/synchronization objects for interop via NvSci API.
+void setupCuda(cudaExternalResInterop &cudaExtResObj, NvSciBufObj &inputBufObj,
+               NvSciSyncObj &syncObj, NvSciSyncObj &cudaSignalerSyncObj,
+               int deviceId) {
+  checkCudaErrors(cudaSetDevice(deviceId));
+  cudaImportNvSciSync(cudaExtResObj.waitSem, syncObj);
+  cudaImportNvSciSync(cudaExtResObj.signalSem, cudaSignalerSyncObj);
+
+  cudaImportNvSciImage(cudaExtResObj, inputBufObj);
+  cudaExtResObj.d_mipLevelArray =
+      (cudaArray_t *)malloc(sizeof(cudaArray_t) * cudaExtResObj.planeCount);
+  cudaExtResObj.cudaSurfaceNvmediaBuf = (cudaSurfaceObject_t *)malloc(
+      sizeof(cudaSurfaceObject_t) * cudaExtResObj.planeCount);
+
+  for (int i = 0; i < cudaExtResObj.planeCount; ++i) {
+    uint32_t mipLevelId = 0;
+    checkCudaErrors(
+        cudaGetMipmappedArrayLevel(&cudaExtResObj.d_mipLevelArray[i],
+                                   cudaExtResObj.d_mipmapArray[i], mipLevelId));
+    cudaExtResObj.cudaSurfaceNvmediaBuf[i] =
+        createCudaSurface(cudaExtResObj.d_mipLevelArray[i]);
+  }
+
+  cudaExtResObj.stream = createCudaStream(deviceId);
+  checkCudaErrors(cudaMalloc(&cudaExtResObj.d_outputImage,
+                             sizeof(unsigned int) *
+                                 cudaExtResObj.imageWidth[0] *
+                                 cudaExtResObj.imageHeight[0]));
+}
+
+// CUDA clean up buffers used **with** NvSci API.
+void cleanupCuda(cudaExternalResInterop &cudaExtResObj) {
+  for (int i = 0; i < cudaExtResObj.planeCount; i++) {
+    checkCudaErrors(
+        cudaDestroySurfaceObject(cudaExtResObj.cudaSurfaceNvmediaBuf[i]));
+    checkCudaErrors(cudaFreeMipmappedArray(cudaExtResObj.d_mipmapArray[i]));
+  }
+  free(cudaExtResObj.d_mipmapArray);
+  free(cudaExtResObj.d_mipLevelArray);
+  free(cudaExtResObj.cudaSurfaceNvmediaBuf);
+  free(cudaExtResObj.imageWidth);
+  free(cudaExtResObj.imageHeight);
+  checkCudaErrors(cudaDestroyExternalSemaphore(cudaExtResObj.waitSem));
+  checkCudaErrors(cudaDestroyExternalSemaphore(cudaExtResObj.signalSem));
+  checkCudaErrors(cudaDestroyExternalMemory(cudaExtResObj.extMemImageBuf));
+  checkCudaErrors(cudaStreamDestroy(cudaExtResObj.stream));
+  checkCudaErrors(cudaFree(cudaExtResObj.d_outputImage));
+}
+
+void runCudaOperation(cudaExternalResInterop &cudaExtResObj,
+                      NvSciSyncFence *cudaWaitFence,
+                      NvSciSyncFence *cudaSignalFence, int deviceId,
+                      int iterations) {
+  checkCudaErrors(cudaSetDevice(deviceId));
+  static int64_t launch = 0;
+
+  waitExternalSemaphore(cudaExtResObj.waitSem, cudaWaitFence,
+                        cudaExtResObj.stream);
+
+  // run cuda kernel over surface object of the LUMA surface part to extract
+  // grayscale.
+  yuvToGrayscaleCudaKernel(cudaExtResObj, cudaExtResObj.imageWidth[0],
+                           cudaExtResObj.imageHeight[0]);
+
+  // signal fence till the second last iterations for NvMedia2DBlit to wait for
+  // cuda signal and for final iteration as there is no corresponding NvMedia
+  // operation pending therefore we end with cudaStreamSynchronize()
+  if (launch < iterations - 1) {
+    signalExternalSemaphore(cudaExtResObj.signalSem, cudaSignalFence,
+                            cudaExtResObj.stream);
+  } else {
+    checkCudaErrors(cudaStreamSynchronize(cudaExtResObj.stream));
+  }
+  launch++;
+}
+
+// CUDA imports and operates on NvSci buffer/synchronization objects
+void setupCuda(Blit2DTest *ctx, cudaResources &cudaResObj, int deviceId) {
+  checkCudaErrors(cudaSetDevice(deviceId));
+  cudaResObj.d_yuvArray =
+      (cudaArray_t *)malloc(sizeof(cudaArray_t) * ctx->numSurfaces);
+  cudaResObj.cudaSurfaceNvmediaBuf = (cudaSurfaceObject_t *)malloc(
+      sizeof(cudaSurfaceObject_t) * ctx->numSurfaces);
+  cudaChannelFormatDesc channelDesc;
+  switch (ctx->bytesPerPixel) {
+    case 1:
+    default:
+      channelDesc =
+          cudaCreateChannelDesc(8, 0, 0, 0, cudaChannelFormatKindUnsigned);
+      break;
+  }
+
+  for (int k = 0; k < ctx->numSurfaces; k++) {
+    checkCudaErrors(cudaMallocArray(
+        &cudaResObj.d_yuvArray[k], &channelDesc,
+        ctx->widthSurface * ctx->xScalePtr[k] * ctx->bytesPerPixel,
+        ctx->heightSurface * ctx->yScalePtr[k]));
+    cudaResObj.cudaSurfaceNvmediaBuf[k] =
+        createCudaSurface(cudaResObj.d_yuvArray[k]);
+  }
+  checkCudaErrors(cudaMalloc(
+      &cudaResObj.d_outputImage,
+      sizeof(unsigned int) * ctx->widthSurface * ctx->heightSurface));
+
+  cudaResObj.stream = createCudaStream(deviceId);
+}
+
+// CUDA clean up buffers used **without** NvSci API.
+void cleanupCuda(Blit2DTest *ctx, cudaResources &cudaResObj) {
+  for (int k = 0; k < ctx->numSurfaces; k++) {
+    checkCudaErrors(
+        cudaDestroySurfaceObject(cudaResObj.cudaSurfaceNvmediaBuf[k]));
+    checkCudaErrors(cudaFreeArray(cudaResObj.d_yuvArray[k]));
+  }
+
+  free(cudaResObj.cudaSurfaceNvmediaBuf);
+
+  checkCudaErrors(cudaStreamDestroy(cudaResObj.stream));
+  checkCudaErrors(cudaFree(cudaResObj.d_outputImage));
+}
+
+static void yuvToGrayscaleCudaKernelNonNvSci(cudaResources &cudaResObj,
+                                             int deviceId, int32_t imageWidth,
+                                             int32_t imageHeight) {
+#if WRITE_OUTPUT_IMAGE
+  unsigned int *h_dstImage;
+  checkCudaErrors(cudaMallocHost(
+      &h_dstImage, sizeof(unsigned int) * imageHeight * imageWidth));
+#endif
+  dim3 block(16, 16, 1);
+  dim3 grid((imageWidth / block.x) + 1, (imageHeight / block.y) + 1, 1);
+
+  yuvToGrayscale<<<grid, block, 0, cudaResObj.stream>>>(
+      cudaResObj.cudaSurfaceNvmediaBuf[0], cudaResObj.d_outputImage, imageWidth,
+      imageHeight);
+
+#if WRITE_OUTPUT_IMAGE
+  checkCudaErrors(
+      cudaMemcpyAsync(h_dstImage, cudaResObj.d_outputImage,
+                      sizeof(unsigned int) * imageHeight * imageWidth,
+                      cudaMemcpyDeviceToHost, cudaResObj.stream));
+  checkCudaErrors(cudaStreamSynchronize(cudaResObj.stream));
+  char outputFilename[1024];
+  std::string image_filename = "Grayscale";
+  strcpy(outputFilename, image_filename.c_str());
+  strcpy(outputFilename + image_filename.length(), "_non-nvsci_out.ppm");
+  sdkSavePPM4ub(outputFilename, (unsigned char *)h_dstImage, imageWidth,
+                imageHeight);
+  printf("Wrote '%s'\n", outputFilename);
+  checkCudaErrors(cudaFreeHost(h_dstImage));
+#else
+  checkCudaErrors(cudaStreamSynchronize(cudaResObj.stream));
+#endif
+}
+
+// CUDA operates **without** NvSci APIs buffer/synchronization objects.
+void runCudaOperation(Blit2DTest *ctx, cudaResources &cudaResObj,
+                      int deviceId) {
+  for (int k = 0; k < ctx->numSurfaces; k++) {
+    checkCudaErrors(cudaMemcpy2DToArray(
+        cudaResObj.d_yuvArray[k], 0, 0, ctx->dstBuff[k],
+        ctx->widthSurface * ctx->xScalePtr[k] * ctx->bytesPerPixel,
+        ctx->widthSurface * ctx->xScalePtr[k] * ctx->bytesPerPixel,
+        ctx->heightSurface * ctx->yScalePtr[k], cudaMemcpyHostToDevice));
+  }
+  // run cuda kernel over surface object of the LUMA surface part to extract
+  // grayscale.
+  yuvToGrayscaleCudaKernelNonNvSci(cudaResObj, deviceId, ctx->widthSurface,
+                                   ctx->heightSurface);
+}
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer.cu.hip b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer.cu.hip
index f464b2a..08f8850 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer.cu.hip
@@ -1,436 +1,436 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <iostream>
-
-#include <hip/hip_runtime.h>
-#include "cuda_consumer.h"
-#include <helper_image.h>
-#include "nvmedia_image_nvscibuf.h"
-#include "nvmedia_utils/cmdline.h"
-
-// Enable this to 1 if require cuda processed output to ppm file.
-#define WRITE_OUTPUT_IMAGE 0
-
-#define checkNvSciErrors(call)                              \
-  do {                                                      \
-    NvSciError _status = call;                              \
-    if (NvSciError_Success != _status) {                    \
-      printf(                                               \
-          "NVSCI call in file '%s' in line %i returned"     \
-          " %d, expected %d\n",                             \
-          __FILE__, __LINE__, _status, NvSciError_Success); \
-      fflush(stdout);                                       \
-      exit(EXIT_FAILURE);                                   \
-    }                                                       \
-  } while (0)
-
-__global__ static void yuvToGrayscale(hipSurfaceObject_t surfaceObject,
-                                      unsigned int *dstImage,
-                                      int32_t imageWidth, int32_t imageHeight) {
-  size_t x = blockIdx.x * blockDim.x + threadIdx.x;
-  size_t y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  uchar4 *dstImageUchar4 = (uchar4 *)dstImage;
-  for (; x < imageWidth && y < imageHeight;
-       x += gridDim.x * blockDim.x, y += gridDim.y * blockDim.y) {
-    int colInBytes = x * sizeof(unsigned char);
-    unsigned char luma =
-        surf2Dread<unsigned char>(surfaceObject, colInBytes, y);
-    uchar4 grayscalePix = make_uchar4(luma, luma, luma, 0);
-
-    dstImageUchar4[y * imageWidth + x] = grayscalePix;
-  }
-}
-
-static void cudaImportNvSciSync(hipExternalSemaphore_t &extSem,
-                                NvSciSyncObj &syncObj) {
-  hipExternalSemaphoreHandleDesc extSemDesc;
-  memset(&extSemDesc, 0, sizeof(extSemDesc));
-  extSemDesc.type = cudaExternalSemaphoreHandleTypeNvSciSync;
-  extSemDesc.handle.nvSciSyncObj = (void *)syncObj;
-
-  HIPCHECK(hipImportExternalSemaphore(&extSem, &extSemDesc));
-}
-
-static void waitExternalSemaphore(hipExternalSemaphore_t &waitSem,
-                                  NvSciSyncFence *fence, hipStream_t stream) {
-  hipExternalSemaphoreWaitParams waitParams;
-  memset(&waitParams, 0, sizeof(waitParams));
-  // For cross-process signaler-waiter applications need to use NvSciIpc
-  // and NvSciSync[Export|Import] utilities to share the NvSciSyncFence
-  // across process. This step is optional in single-process.
-  waitParams.params.nvSciSync.fence = (void *)fence;
-  waitParams.flags = 0;
-
-  HIPCHECK(
-      hipWaitExternalSemaphoresAsync(&waitSem, &waitParams, 1, stream));
-}
-
-static void signalExternalSemaphore(hipExternalSemaphore_t &signalSem,
-                                    NvSciSyncFence *fence,
-                                    hipStream_t stream) {
-  hipExternalSemaphoreSignalParams signalParams;
-  memset(&signalParams, 0, sizeof(signalParams));
-  // For cross-process signaler-waiter applications need to use NvSciIpc
-  // and NvSciSync[Export|Import] utilities to share the NvSciSyncFence
-  // across process. This step is optional in single-process.
-  signalParams.params.nvSciSync.fence = (void *)fence;
-  signalParams.flags = 0;
-
-  HIPCHECK(
-      hipSignalExternalSemaphoresAsync(&signalSem, &signalParams, 1, stream));
-}
-
-static void yuvToGrayscaleCudaKernel(cudaExternalResInterop &cudaExtResObj,
-                                     int32_t imageWidth, int32_t imageHeight) {
-#if WRITE_OUTPUT_IMAGE
-  unsigned int *h_dstImage;
-  HIPCHECK(hipHostMalloc(
-      &h_dstImage, sizeof(unsigned int) * imageHeight * imageWidth));
-#endif
-  dim3 block(16, 16, 1);
-  dim3 grid((imageWidth / block.x) + 1, (imageHeight / block.y) + 1, 1);
-
-  yuvToGrayscale<<<grid, block, 0, cudaExtResObj.stream>>>(
-      cudaExtResObj.cudaSurfaceNvmediaBuf[0], cudaExtResObj.d_outputImage,
-      imageWidth, imageHeight);
-
-#if WRITE_OUTPUT_IMAGE
-  HIPCHECK(
-      hipMemcpyAsync(h_dstImage, cudaExtResObj.d_outputImage,
-                      sizeof(unsigned int) * imageHeight * imageWidth,
-                      hipMemcpyDeviceToHost, cudaExtResObj.stream));
-  HIPCHECK(hipStreamSynchronize(cudaExtResObj.stream));
-  char outputFilename[1024];
-  std::string image_filename = "Grayscale";
-  strcpy(outputFilename, image_filename.c_str());
-  strcpy(outputFilename + image_filename.length(), "_nvsci_out.ppm");
-  sdkSavePPM4ub(outputFilename, (unsigned char *)h_dstImage, imageWidth,
-                imageHeight);
-  printf("Wrote '%s'\n", outputFilename);
-  HIPCHECK(hipHostFree(h_dstImage));
-#endif
-}
-
-static void cudaImportNvSciImage(cudaExternalResInterop &cudaExtResObj,
-                                 NvSciBufObj &inputBufObj) {
-  NvSciBufModule module = NULL;
-  NvSciBufAttrList attrlist = NULL;
-  NvSciBufAttrKeyValuePair pairArrayOut[10];
-
-  checkNvSciErrors(NvSciBufModuleOpen(&module));
-  checkNvSciErrors(NvSciBufAttrListCreate(module, &attrlist));
-  checkNvSciErrors(NvSciBufObjGetAttrList(inputBufObj, &attrlist));
-
-  memset(pairArrayOut, 0, sizeof(NvSciBufAttrKeyValuePair) * 10);
-
-  int numAttrs = 0;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_Size;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneChannelCount;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneCount;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneWidth;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneHeight;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_Layout;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneBitsPerPixel;
-  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneOffset;
-
-  checkNvSciErrors(NvSciBufAttrListGetAttrs(attrlist, pairArrayOut, numAttrs));
-
-  uint64_t size = *(uint64_t *)pairArrayOut[0].value;
-  uint8_t channelCount = *(uint8_t *)pairArrayOut[1].value;
-  cudaExtResObj.planeCount = *(int32_t *)pairArrayOut[2].value;
-  cudaExtResObj.imageWidth =
-      (int32_t *)malloc(sizeof(int32_t) * cudaExtResObj.planeCount);
-  cudaExtResObj.imageHeight =
-      (int32_t *)malloc(sizeof(int32_t) * cudaExtResObj.planeCount);
-  cudaExtResObj.planeOffset =
-      (uint64_t *)malloc(sizeof(uint64_t) * cudaExtResObj.planeCount);
-
-  memcpy(cudaExtResObj.imageWidth, (int32_t *)pairArrayOut[3].value,
-         cudaExtResObj.planeCount * sizeof(int32_t));
-  memcpy(cudaExtResObj.imageHeight, (int32_t *)pairArrayOut[4].value,
-         cudaExtResObj.planeCount * sizeof(int32_t));
-  memcpy(cudaExtResObj.planeOffset, (uint64_t *)pairArrayOut[7].value,
-         cudaExtResObj.planeCount * sizeof(uint64_t));
-
-  NvSciBufAttrValImageLayoutType layout =
-      *(NvSciBufAttrValImageLayoutType *)pairArrayOut[5].value;
-  uint32_t bitsPerPixel = *(uint32_t *)pairArrayOut[6].value;
-
-  if (layout != NvSciBufImage_BlockLinearType) {
-    printf("Image layout is not block linear.. waiving execution\n");
-    exit(EXIT_WAIVED);
-  }
-
-  hipExternalMemoryHandleDesc memHandleDesc;
-  memset(&memHandleDesc, 0, sizeof(memHandleDesc));
-  memHandleDesc.type = cudaExternalMemoryHandleTypeNvSciBuf;
-  memHandleDesc.handle.nvSciBufObject = inputBufObj;
-  memHandleDesc.size = size;
-  HIPCHECK(
-      hipImportExternalMemory(&cudaExtResObj.extMemImageBuf, &memHandleDesc));
-
-  cudaExtResObj.d_mipmapArray = (hipMipmappedArray_t *)malloc(
-      sizeof(hipMipmappedArray_t) * cudaExtResObj.planeCount);
-
-  for (int i = 0; i < cudaExtResObj.planeCount; i++) {
-    hipExtent extent = {};
-    memset(&extent, 0, sizeof(extent));
-    extent.width = cudaExtResObj.imageWidth[i];
-    extent.height = cudaExtResObj.imageHeight[i];
-    extent.depth = 0;
-    hipChannelFormatDesc desc;
-    switch (channelCount) {
-      case 1:
-      default:
-        desc = hipCreateChannelDesc(bitsPerPixel, 0, 0, 0,
-                                     hipChannelFormatKindUnsigned);
-        break;
-      case 2:
-        desc = hipCreateChannelDesc(bitsPerPixel, bitsPerPixel, 0, 0,
-                                     hipChannelFormatKindUnsigned);
-        break;
-      case 3:
-        desc = hipCreateChannelDesc(bitsPerPixel, bitsPerPixel, bitsPerPixel,
-                                     0, hipChannelFormatKindUnsigned);
-        break;
-      case 4:
-        desc =
-            hipCreateChannelDesc(bitsPerPixel, bitsPerPixel, bitsPerPixel,
-                                  bitsPerPixel, hipChannelFormatKindUnsigned);
-        break;
-    }
-
-    cudaExternalMemoryMipmappedArrayDesc mipmapDesc = {0};
-    mipmapDesc.offset = cudaExtResObj.planeOffset[i];
-    mipmapDesc.formatDesc = desc;
-    mipmapDesc.extent = extent;
-    mipmapDesc.flags = 0;
-    mipmapDesc.numLevels = 1;
-    HIPCHECK(cudaExternalMemoryGetMappedMipmappedArray(
-        &cudaExtResObj.d_mipmapArray[i], cudaExtResObj.extMemImageBuf,
-        &mipmapDesc));
-  }
-}
-
-static hipSurfaceObject_t createCudaSurface(hipArray_t &d_mipLevelArray) {
-  hipResourceDesc resourceDesc;
-  memset(&resourceDesc, 0, sizeof(resourceDesc));
-  resourceDesc.resType = hipResourceTypeArray;
-  resourceDesc.res.array.array = d_mipLevelArray;
-
-  hipSurfaceObject_t surfaceObject;
-  HIPCHECK(hipCreateSurfaceObject(&surfaceObject, &resourceDesc));
-  return surfaceObject;
-}
-
-static hipStream_t createCudaStream(int deviceId) {
-  HIPCHECK(hipSetDevice(deviceId));
-  hipStream_t stream;
-  HIPCHECK(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
-  return stream;
-}
-
-// CUDA setup buffers/synchronization objects for interop via NvSci API.
-void setupCuda(cudaExternalResInterop &cudaExtResObj, NvSciBufObj &inputBufObj,
-               NvSciSyncObj &syncObj, NvSciSyncObj &cudaSignalerSyncObj,
-               int deviceId) {
-  HIPCHECK(hipSetDevice(deviceId));
-  cudaImportNvSciSync(cudaExtResObj.waitSem, syncObj);
-  cudaImportNvSciSync(cudaExtResObj.signalSem, cudaSignalerSyncObj);
-
-  cudaImportNvSciImage(cudaExtResObj, inputBufObj);
-  cudaExtResObj.d_mipLevelArray =
-      (hipArray_t *)malloc(sizeof(hipArray_t) * cudaExtResObj.planeCount);
-  cudaExtResObj.cudaSurfaceNvmediaBuf = (hipSurfaceObject_t *)malloc(
-      sizeof(hipSurfaceObject_t) * cudaExtResObj.planeCount);
-
-  for (int i = 0; i < cudaExtResObj.planeCount; ++i) {
-    uint32_t mipLevelId = 0;
-    HIPCHECK(
-        hipGetMipmappedArrayLevel(&cudaExtResObj.d_mipLevelArray[i],
-                                   cudaExtResObj.d_mipmapArray[i], mipLevelId));
-    cudaExtResObj.cudaSurfaceNvmediaBuf[i] =
-        createCudaSurface(cudaExtResObj.d_mipLevelArray[i]);
-  }
-
-  cudaExtResObj.stream = createCudaStream(deviceId);
-  HIPCHECK(hipMalloc(&cudaExtResObj.d_outputImage,
-                             sizeof(unsigned int) *
-                                 cudaExtResObj.imageWidth[0] *
-                                 cudaExtResObj.imageHeight[0]));
-}
-
-// CUDA clean up buffers used **with** NvSci API.
-void cleanupCuda(cudaExternalResInterop &cudaExtResObj) {
-  for (int i = 0; i < cudaExtResObj.planeCount; i++) {
-    HIPCHECK(
-        hipDestroySurfaceObject(cudaExtResObj.cudaSurfaceNvmediaBuf[i]));
-    HIPCHECK(hipFreeMipmappedArray(cudaExtResObj.d_mipmapArray[i]));
-  }
-  free(cudaExtResObj.d_mipmapArray);
-  free(cudaExtResObj.d_mipLevelArray);
-  free(cudaExtResObj.cudaSurfaceNvmediaBuf);
-  free(cudaExtResObj.imageWidth);
-  free(cudaExtResObj.imageHeight);
-  HIPCHECK(hipDestroyExternalSemaphore(cudaExtResObj.waitSem));
-  HIPCHECK(hipDestroyExternalSemaphore(cudaExtResObj.signalSem));
-  HIPCHECK(hipDestroyExternalMemory(cudaExtResObj.extMemImageBuf));
-  HIPCHECK(hipStreamDestroy(cudaExtResObj.stream));
-  HIPCHECK(hipFree(cudaExtResObj.d_outputImage));
-}
-
-void runCudaOperation(cudaExternalResInterop &cudaExtResObj,
-                      NvSciSyncFence *cudaWaitFence,
-                      NvSciSyncFence *cudaSignalFence, int deviceId,
-                      int iterations) {
-  HIPCHECK(hipSetDevice(deviceId));
-  static int64_t launch = 0;
-
-  waitExternalSemaphore(cudaExtResObj.waitSem, cudaWaitFence,
-                        cudaExtResObj.stream);
-
-  // run cuda kernel over surface object of the LUMA surface part to extract
-  // grayscale.
-  yuvToGrayscaleCudaKernel(cudaExtResObj, cudaExtResObj.imageWidth[0],
-                           cudaExtResObj.imageHeight[0]);
-
-  // signal fence till the second last iterations for NvMedia2DBlit to wait for
-  // cuda signal and for final iteration as there is no corresponding NvMedia
-  // operation pending therefore we end with hipStreamSynchronize()
-  if (launch < iterations - 1) {
-    signalExternalSemaphore(cudaExtResObj.signalSem, cudaSignalFence,
-                            cudaExtResObj.stream);
-  } else {
-    HIPCHECK(hipStreamSynchronize(cudaExtResObj.stream));
-  }
-  launch++;
-}
-
-// CUDA imports and operates on NvSci buffer/synchronization objects
-void setupCuda(Blit2DTest *ctx, cudaResources &cudaResObj, int deviceId) {
-  HIPCHECK(hipSetDevice(deviceId));
-  cudaResObj.d_yuvArray =
-      (hipArray_t *)malloc(sizeof(hipArray_t) * ctx->numSurfaces);
-  cudaResObj.cudaSurfaceNvmediaBuf = (hipSurfaceObject_t *)malloc(
-      sizeof(hipSurfaceObject_t) * ctx->numSurfaces);
-  hipChannelFormatDesc channelDesc;
-  switch (ctx->bytesPerPixel) {
-    case 1:
-    default:
-      channelDesc =
-          hipCreateChannelDesc(8, 0, 0, 0, hipChannelFormatKindUnsigned);
-      break;
-  }
-
-  for (int k = 0; k < ctx->numSurfaces; k++) {
-    HIPCHECK(hipMallocArray(
-        &cudaResObj.d_yuvArray[k], &channelDesc,
-        ctx->widthSurface * ctx->xScalePtr[k] * ctx->bytesPerPixel,
-        ctx->heightSurface * ctx->yScalePtr[k]));
-    cudaResObj.cudaSurfaceNvmediaBuf[k] =
-        createCudaSurface(cudaResObj.d_yuvArray[k]);
-  }
-  HIPCHECK(hipMalloc(
-      &cudaResObj.d_outputImage,
-      sizeof(unsigned int) * ctx->widthSurface * ctx->heightSurface));
-
-  cudaResObj.stream = createCudaStream(deviceId);
-}
-
-// CUDA clean up buffers used **without** NvSci API.
-void cleanupCuda(Blit2DTest *ctx, cudaResources &cudaResObj) {
-  for (int k = 0; k < ctx->numSurfaces; k++) {
-    HIPCHECK(
-        hipDestroySurfaceObject(cudaResObj.cudaSurfaceNvmediaBuf[k]));
-    HIPCHECK(hipFreeArray(cudaResObj.d_yuvArray[k]));
-  }
-
-  free(cudaResObj.cudaSurfaceNvmediaBuf);
-
-  HIPCHECK(hipStreamDestroy(cudaResObj.stream));
-  HIPCHECK(hipFree(cudaResObj.d_outputImage));
-}
-
-static void yuvToGrayscaleCudaKernelNonNvSci(cudaResources &cudaResObj,
-                                             int deviceId, int32_t imageWidth,
-                                             int32_t imageHeight) {
-#if WRITE_OUTPUT_IMAGE
-  unsigned int *h_dstImage;
-  HIPCHECK(hipHostMalloc(
-      &h_dstImage, sizeof(unsigned int) * imageHeight * imageWidth));
-#endif
-  dim3 block(16, 16, 1);
-  dim3 grid((imageWidth / block.x) + 1, (imageHeight / block.y) + 1, 1);
-
-  yuvToGrayscale<<<grid, block, 0, cudaResObj.stream>>>(
-      cudaResObj.cudaSurfaceNvmediaBuf[0], cudaResObj.d_outputImage, imageWidth,
-      imageHeight);
-
-#if WRITE_OUTPUT_IMAGE
-  HIPCHECK(
-      hipMemcpyAsync(h_dstImage, cudaResObj.d_outputImage,
-                      sizeof(unsigned int) * imageHeight * imageWidth,
-                      hipMemcpyDeviceToHost, cudaResObj.stream));
-  HIPCHECK(hipStreamSynchronize(cudaResObj.stream));
-  char outputFilename[1024];
-  std::string image_filename = "Grayscale";
-  strcpy(outputFilename, image_filename.c_str());
-  strcpy(outputFilename + image_filename.length(), "_non-nvsci_out.ppm");
-  sdkSavePPM4ub(outputFilename, (unsigned char *)h_dstImage, imageWidth,
-                imageHeight);
-  printf("Wrote '%s'\n", outputFilename);
-  HIPCHECK(hipHostFree(h_dstImage));
-#else
-  HIPCHECK(hipStreamSynchronize(cudaResObj.stream));
-#endif
-}
-
-// CUDA operates **without** NvSci APIs buffer/synchronization objects.
-void runCudaOperation(Blit2DTest *ctx, cudaResources &cudaResObj,
-                      int deviceId) {
-  for (int k = 0; k < ctx->numSurfaces; k++) {
-    HIPCHECK(hipMemcpy2DToArray(
-        cudaResObj.d_yuvArray[k], 0, 0, ctx->dstBuff[k],
-        ctx->widthSurface * ctx->xScalePtr[k] * ctx->bytesPerPixel,
-        ctx->widthSurface * ctx->xScalePtr[k] * ctx->bytesPerPixel,
-        ctx->heightSurface * ctx->yScalePtr[k], hipMemcpyHostToDevice));
-  }
-  // run cuda kernel over surface object of the LUMA surface part to extract
-  // grayscale.
-  yuvToGrayscaleCudaKernelNonNvSci(cudaResObj, deviceId, ctx->widthSurface,
-                                   ctx->heightSurface);
-}
-emcpyHostToDevice));
-  }
-  // run cuda kernel over surface object of the LUMA surface part to extract
-  // grayscale.
-  yuvToGrayscaleCudaKernelNonNvSci(cudaResObj, deviceId, ctx->widthSurface,
-                                   ctx->heightSurface);
-}
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <iostream>
+
+#include <hip/hip_runtime.h>
+#include "cuda_consumer.h"
+#include <helper_image.h>
+#include "nvmedia_image_nvscibuf.h"
+#include "nvmedia_utils/cmdline.h"
+
+// Enable this to 1 if require cuda processed output to ppm file.
+#define WRITE_OUTPUT_IMAGE 0
+
+#define checkNvSciErrors(call)                              \
+  do {                                                      \
+    NvSciError _status = call;                              \
+    if (NvSciError_Success != _status) {                    \
+      printf(                                               \
+          "NVSCI call in file '%s' in line %i returned"     \
+          " %d, expected %d\n",                             \
+          __FILE__, __LINE__, _status, NvSciError_Success); \
+      fflush(stdout);                                       \
+      exit(EXIT_FAILURE);                                   \
+    }                                                       \
+  } while (0)
+
+__global__ static void yuvToGrayscale(hipSurfaceObject_t surfaceObject,
+                                      unsigned int *dstImage,
+                                      int32_t imageWidth, int32_t imageHeight) {
+  size_t x = blockIdx.x * blockDim.x + threadIdx.x;
+  size_t y = blockIdx.y * blockDim.y + threadIdx.y;
+
+  uchar4 *dstImageUchar4 = (uchar4 *)dstImage;
+  for (; x < imageWidth && y < imageHeight;
+       x += gridDim.x * blockDim.x, y += gridDim.y * blockDim.y) {
+    int colInBytes = x * sizeof(unsigned char);
+    unsigned char luma =
+        surf2Dread<unsigned char>(surfaceObject, colInBytes, y);
+    uchar4 grayscalePix = make_uchar4(luma, luma, luma, 0);
+
+    dstImageUchar4[y * imageWidth + x] = grayscalePix;
+  }
+}
+
+static void cudaImportNvSciSync(hipExternalSemaphore_t &extSem,
+                                NvSciSyncObj &syncObj) {
+  hipExternalSemaphoreHandleDesc extSemDesc;
+  memset(&extSemDesc, 0, sizeof(extSemDesc));
+  extSemDesc.type = cudaExternalSemaphoreHandleTypeNvSciSync;
+  extSemDesc.handle.nvSciSyncObj = (void *)syncObj;
+
+  HIPCHECK(hipImportExternalSemaphore(&extSem, &extSemDesc));
+}
+
+static void waitExternalSemaphore(hipExternalSemaphore_t &waitSem,
+                                  NvSciSyncFence *fence, hipStream_t stream) {
+  hipExternalSemaphoreWaitParams waitParams;
+  memset(&waitParams, 0, sizeof(waitParams));
+  // For cross-process signaler-waiter applications need to use NvSciIpc
+  // and NvSciSync[Export|Import] utilities to share the NvSciSyncFence
+  // across process. This step is optional in single-process.
+  waitParams.params.nvSciSync.fence = (void *)fence;
+  waitParams.flags = 0;
+
+  HIPCHECK(
+      hipWaitExternalSemaphoresAsync(&waitSem, &waitParams, 1, stream));
+}
+
+static void signalExternalSemaphore(hipExternalSemaphore_t &signalSem,
+                                    NvSciSyncFence *fence,
+                                    hipStream_t stream) {
+  hipExternalSemaphoreSignalParams signalParams;
+  memset(&signalParams, 0, sizeof(signalParams));
+  // For cross-process signaler-waiter applications need to use NvSciIpc
+  // and NvSciSync[Export|Import] utilities to share the NvSciSyncFence
+  // across process. This step is optional in single-process.
+  signalParams.params.nvSciSync.fence = (void *)fence;
+  signalParams.flags = 0;
+
+  HIPCHECK(
+      hipSignalExternalSemaphoresAsync(&signalSem, &signalParams, 1, stream));
+}
+
+static void yuvToGrayscaleCudaKernel(cudaExternalResInterop &cudaExtResObj,
+                                     int32_t imageWidth, int32_t imageHeight) {
+#if WRITE_OUTPUT_IMAGE
+  unsigned int *h_dstImage;
+  HIPCHECK(hipHostMalloc(
+      &h_dstImage, sizeof(unsigned int) * imageHeight * imageWidth));
+#endif
+  dim3 block(16, 16, 1);
+  dim3 grid((imageWidth / block.x) + 1, (imageHeight / block.y) + 1, 1);
+
+  yuvToGrayscale<<<grid, block, 0, cudaExtResObj.stream>>>(
+      cudaExtResObj.cudaSurfaceNvmediaBuf[0], cudaExtResObj.d_outputImage,
+      imageWidth, imageHeight);
+
+#if WRITE_OUTPUT_IMAGE
+  HIPCHECK(
+      hipMemcpyAsync(h_dstImage, cudaExtResObj.d_outputImage,
+                      sizeof(unsigned int) * imageHeight * imageWidth,
+                      hipMemcpyDeviceToHost, cudaExtResObj.stream));
+  HIPCHECK(hipStreamSynchronize(cudaExtResObj.stream));
+  char outputFilename[1024];
+  std::string image_filename = "Grayscale";
+  strcpy(outputFilename, image_filename.c_str());
+  strcpy(outputFilename + image_filename.length(), "_nvsci_out.ppm");
+  sdkSavePPM4ub(outputFilename, (unsigned char *)h_dstImage, imageWidth,
+                imageHeight);
+  printf("Wrote '%s'\n", outputFilename);
+  HIPCHECK(hipHostFree(h_dstImage));
+#endif
+}
+
+static void cudaImportNvSciImage(cudaExternalResInterop &cudaExtResObj,
+                                 NvSciBufObj &inputBufObj) {
+  NvSciBufModule module = NULL;
+  NvSciBufAttrList attrlist = NULL;
+  NvSciBufAttrKeyValuePair pairArrayOut[10];
+
+  checkNvSciErrors(NvSciBufModuleOpen(&module));
+  checkNvSciErrors(NvSciBufAttrListCreate(module, &attrlist));
+  checkNvSciErrors(NvSciBufObjGetAttrList(inputBufObj, &attrlist));
+
+  memset(pairArrayOut, 0, sizeof(NvSciBufAttrKeyValuePair) * 10);
+
+  int numAttrs = 0;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_Size;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneChannelCount;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneCount;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneWidth;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneHeight;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_Layout;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneBitsPerPixel;
+  pairArrayOut[numAttrs++].key = NvSciBufImageAttrKey_PlaneOffset;
+
+  checkNvSciErrors(NvSciBufAttrListGetAttrs(attrlist, pairArrayOut, numAttrs));
+
+  uint64_t size = *(uint64_t *)pairArrayOut[0].value;
+  uint8_t channelCount = *(uint8_t *)pairArrayOut[1].value;
+  cudaExtResObj.planeCount = *(int32_t *)pairArrayOut[2].value;
+  cudaExtResObj.imageWidth =
+      (int32_t *)malloc(sizeof(int32_t) * cudaExtResObj.planeCount);
+  cudaExtResObj.imageHeight =
+      (int32_t *)malloc(sizeof(int32_t) * cudaExtResObj.planeCount);
+  cudaExtResObj.planeOffset =
+      (uint64_t *)malloc(sizeof(uint64_t) * cudaExtResObj.planeCount);
+
+  memcpy(cudaExtResObj.imageWidth, (int32_t *)pairArrayOut[3].value,
+         cudaExtResObj.planeCount * sizeof(int32_t));
+  memcpy(cudaExtResObj.imageHeight, (int32_t *)pairArrayOut[4].value,
+         cudaExtResObj.planeCount * sizeof(int32_t));
+  memcpy(cudaExtResObj.planeOffset, (uint64_t *)pairArrayOut[7].value,
+         cudaExtResObj.planeCount * sizeof(uint64_t));
+
+  NvSciBufAttrValImageLayoutType layout =
+      *(NvSciBufAttrValImageLayoutType *)pairArrayOut[5].value;
+  uint32_t bitsPerPixel = *(uint32_t *)pairArrayOut[6].value;
+
+  if (layout != NvSciBufImage_BlockLinearType) {
+    printf("Image layout is not block linear.. waiving execution\n");
+    exit(EXIT_WAIVED);
+  }
+
+  hipExternalMemoryHandleDesc memHandleDesc;
+  memset(&memHandleDesc, 0, sizeof(memHandleDesc));
+  memHandleDesc.type = cudaExternalMemoryHandleTypeNvSciBuf;
+  memHandleDesc.handle.nvSciBufObject = inputBufObj;
+  memHandleDesc.size = size;
+  HIPCHECK(
+      hipImportExternalMemory(&cudaExtResObj.extMemImageBuf, &memHandleDesc));
+
+  cudaExtResObj.d_mipmapArray = (hipMipmappedArray_t *)malloc(
+      sizeof(hipMipmappedArray_t) * cudaExtResObj.planeCount);
+
+  for (int i = 0; i < cudaExtResObj.planeCount; i++) {
+    hipExtent extent = {};
+    memset(&extent, 0, sizeof(extent));
+    extent.width = cudaExtResObj.imageWidth[i];
+    extent.height = cudaExtResObj.imageHeight[i];
+    extent.depth = 0;
+    hipChannelFormatDesc desc;
+    switch (channelCount) {
+      case 1:
+      default:
+        desc = hipCreateChannelDesc(bitsPerPixel, 0, 0, 0,
+                                     hipChannelFormatKindUnsigned);
+        break;
+      case 2:
+        desc = hipCreateChannelDesc(bitsPerPixel, bitsPerPixel, 0, 0,
+                                     hipChannelFormatKindUnsigned);
+        break;
+      case 3:
+        desc = hipCreateChannelDesc(bitsPerPixel, bitsPerPixel, bitsPerPixel,
+                                     0, hipChannelFormatKindUnsigned);
+        break;
+      case 4:
+        desc =
+            hipCreateChannelDesc(bitsPerPixel, bitsPerPixel, bitsPerPixel,
+                                  bitsPerPixel, hipChannelFormatKindUnsigned);
+        break;
+    }
+
+    cudaExternalMemoryMipmappedArrayDesc mipmapDesc = {0};
+    mipmapDesc.offset = cudaExtResObj.planeOffset[i];
+    mipmapDesc.formatDesc = desc;
+    mipmapDesc.extent = extent;
+    mipmapDesc.flags = 0;
+    mipmapDesc.numLevels = 1;
+    HIPCHECK(cudaExternalMemoryGetMappedMipmappedArray(
+        &cudaExtResObj.d_mipmapArray[i], cudaExtResObj.extMemImageBuf,
+        &mipmapDesc));
+  }
+}
+
+static hipSurfaceObject_t createCudaSurface(hipArray_t &d_mipLevelArray) {
+  hipResourceDesc resourceDesc;
+  memset(&resourceDesc, 0, sizeof(resourceDesc));
+  resourceDesc.resType = hipResourceTypeArray;
+  resourceDesc.res.array.array = d_mipLevelArray;
+
+  hipSurfaceObject_t surfaceObject;
+  HIPCHECK(hipCreateSurfaceObject(&surfaceObject, &resourceDesc));
+  return surfaceObject;
+}
+
+static hipStream_t createCudaStream(int deviceId) {
+  HIPCHECK(hipSetDevice(deviceId));
+  hipStream_t stream;
+  HIPCHECK(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
+  return stream;
+}
+
+// CUDA setup buffers/synchronization objects for interop via NvSci API.
+void setupCuda(cudaExternalResInterop &cudaExtResObj, NvSciBufObj &inputBufObj,
+               NvSciSyncObj &syncObj, NvSciSyncObj &cudaSignalerSyncObj,
+               int deviceId) {
+  HIPCHECK(hipSetDevice(deviceId));
+  cudaImportNvSciSync(cudaExtResObj.waitSem, syncObj);
+  cudaImportNvSciSync(cudaExtResObj.signalSem, cudaSignalerSyncObj);
+
+  cudaImportNvSciImage(cudaExtResObj, inputBufObj);
+  cudaExtResObj.d_mipLevelArray =
+      (hipArray_t *)malloc(sizeof(hipArray_t) * cudaExtResObj.planeCount);
+  cudaExtResObj.cudaSurfaceNvmediaBuf = (hipSurfaceObject_t *)malloc(
+      sizeof(hipSurfaceObject_t) * cudaExtResObj.planeCount);
+
+  for (int i = 0; i < cudaExtResObj.planeCount; ++i) {
+    uint32_t mipLevelId = 0;
+    HIPCHECK(
+        hipGetMipmappedArrayLevel(&cudaExtResObj.d_mipLevelArray[i],
+                                   cudaExtResObj.d_mipmapArray[i], mipLevelId));
+    cudaExtResObj.cudaSurfaceNvmediaBuf[i] =
+        createCudaSurface(cudaExtResObj.d_mipLevelArray[i]);
+  }
+
+  cudaExtResObj.stream = createCudaStream(deviceId);
+  HIPCHECK(hipMalloc(&cudaExtResObj.d_outputImage,
+                             sizeof(unsigned int) *
+                                 cudaExtResObj.imageWidth[0] *
+                                 cudaExtResObj.imageHeight[0]));
+}
+
+// CUDA clean up buffers used **with** NvSci API.
+void cleanupCuda(cudaExternalResInterop &cudaExtResObj) {
+  for (int i = 0; i < cudaExtResObj.planeCount; i++) {
+    HIPCHECK(
+        hipDestroySurfaceObject(cudaExtResObj.cudaSurfaceNvmediaBuf[i]));
+    HIPCHECK(hipFreeMipmappedArray(cudaExtResObj.d_mipmapArray[i]));
+  }
+  free(cudaExtResObj.d_mipmapArray);
+  free(cudaExtResObj.d_mipLevelArray);
+  free(cudaExtResObj.cudaSurfaceNvmediaBuf);
+  free(cudaExtResObj.imageWidth);
+  free(cudaExtResObj.imageHeight);
+  HIPCHECK(hipDestroyExternalSemaphore(cudaExtResObj.waitSem));
+  HIPCHECK(hipDestroyExternalSemaphore(cudaExtResObj.signalSem));
+  HIPCHECK(hipDestroyExternalMemory(cudaExtResObj.extMemImageBuf));
+  HIPCHECK(hipStreamDestroy(cudaExtResObj.stream));
+  HIPCHECK(hipFree(cudaExtResObj.d_outputImage));
+}
+
+void runCudaOperation(cudaExternalResInterop &cudaExtResObj,
+                      NvSciSyncFence *cudaWaitFence,
+                      NvSciSyncFence *cudaSignalFence, int deviceId,
+                      int iterations) {
+  HIPCHECK(hipSetDevice(deviceId));
+  static int64_t launch = 0;
+
+  waitExternalSemaphore(cudaExtResObj.waitSem, cudaWaitFence,
+                        cudaExtResObj.stream);
+
+  // run cuda kernel over surface object of the LUMA surface part to extract
+  // grayscale.
+  yuvToGrayscaleCudaKernel(cudaExtResObj, cudaExtResObj.imageWidth[0],
+                           cudaExtResObj.imageHeight[0]);
+
+  // signal fence till the second last iterations for NvMedia2DBlit to wait for
+  // cuda signal and for final iteration as there is no corresponding NvMedia
+  // operation pending therefore we end with hipStreamSynchronize()
+  if (launch < iterations - 1) {
+    signalExternalSemaphore(cudaExtResObj.signalSem, cudaSignalFence,
+                            cudaExtResObj.stream);
+  } else {
+    HIPCHECK(hipStreamSynchronize(cudaExtResObj.stream));
+  }
+  launch++;
+}
+
+// CUDA imports and operates on NvSci buffer/synchronization objects
+void setupCuda(Blit2DTest *ctx, cudaResources &cudaResObj, int deviceId) {
+  HIPCHECK(hipSetDevice(deviceId));
+  cudaResObj.d_yuvArray =
+      (hipArray_t *)malloc(sizeof(hipArray_t) * ctx->numSurfaces);
+  cudaResObj.cudaSurfaceNvmediaBuf = (hipSurfaceObject_t *)malloc(
+      sizeof(hipSurfaceObject_t) * ctx->numSurfaces);
+  hipChannelFormatDesc channelDesc;
+  switch (ctx->bytesPerPixel) {
+    case 1:
+    default:
+      channelDesc =
+          hipCreateChannelDesc(8, 0, 0, 0, hipChannelFormatKindUnsigned);
+      break;
+  }
+
+  for (int k = 0; k < ctx->numSurfaces; k++) {
+    HIPCHECK(hipMallocArray(
+        &cudaResObj.d_yuvArray[k], &channelDesc,
+        ctx->widthSurface * ctx->xScalePtr[k] * ctx->bytesPerPixel,
+        ctx->heightSurface * ctx->yScalePtr[k]));
+    cudaResObj.cudaSurfaceNvmediaBuf[k] =
+        createCudaSurface(cudaResObj.d_yuvArray[k]);
+  }
+  HIPCHECK(hipMalloc(
+      &cudaResObj.d_outputImage,
+      sizeof(unsigned int) * ctx->widthSurface * ctx->heightSurface));
+
+  cudaResObj.stream = createCudaStream(deviceId);
+}
+
+// CUDA clean up buffers used **without** NvSci API.
+void cleanupCuda(Blit2DTest *ctx, cudaResources &cudaResObj) {
+  for (int k = 0; k < ctx->numSurfaces; k++) {
+    HIPCHECK(
+        hipDestroySurfaceObject(cudaResObj.cudaSurfaceNvmediaBuf[k]));
+    HIPCHECK(hipFreeArray(cudaResObj.d_yuvArray[k]));
+  }
+
+  free(cudaResObj.cudaSurfaceNvmediaBuf);
+
+  HIPCHECK(hipStreamDestroy(cudaResObj.stream));
+  HIPCHECK(hipFree(cudaResObj.d_outputImage));
+}
+
+static void yuvToGrayscaleCudaKernelNonNvSci(cudaResources &cudaResObj,
+                                             int deviceId, int32_t imageWidth,
+                                             int32_t imageHeight) {
+#if WRITE_OUTPUT_IMAGE
+  unsigned int *h_dstImage;
+  HIPCHECK(hipHostMalloc(
+      &h_dstImage, sizeof(unsigned int) * imageHeight * imageWidth));
+#endif
+  dim3 block(16, 16, 1);
+  dim3 grid((imageWidth / block.x) + 1, (imageHeight / block.y) + 1, 1);
+
+  yuvToGrayscale<<<grid, block, 0, cudaResObj.stream>>>(
+      cudaResObj.cudaSurfaceNvmediaBuf[0], cudaResObj.d_outputImage, imageWidth,
+      imageHeight);
+
+#if WRITE_OUTPUT_IMAGE
+  HIPCHECK(
+      hipMemcpyAsync(h_dstImage, cudaResObj.d_outputImage,
+                      sizeof(unsigned int) * imageHeight * imageWidth,
+                      hipMemcpyDeviceToHost, cudaResObj.stream));
+  HIPCHECK(hipStreamSynchronize(cudaResObj.stream));
+  char outputFilename[1024];
+  std::string image_filename = "Grayscale";
+  strcpy(outputFilename, image_filename.c_str());
+  strcpy(outputFilename + image_filename.length(), "_non-nvsci_out.ppm");
+  sdkSavePPM4ub(outputFilename, (unsigned char *)h_dstImage, imageWidth,
+                imageHeight);
+  printf("Wrote '%s'\n", outputFilename);
+  HIPCHECK(hipHostFree(h_dstImage));
+#else
+  HIPCHECK(hipStreamSynchronize(cudaResObj.stream));
+#endif
+}
+
+// CUDA operates **without** NvSci APIs buffer/synchronization objects.
+void runCudaOperation(Blit2DTest *ctx, cudaResources &cudaResObj,
+                      int deviceId) {
+  for (int k = 0; k < ctx->numSurfaces; k++) {
+    HIPCHECK(hipMemcpy2DToArray(
+        cudaResObj.d_yuvArray[k], 0, 0, ctx->dstBuff[k],
+        ctx->widthSurface * ctx->xScalePtr[k] * ctx->bytesPerPixel,
+        ctx->widthSurface * ctx->xScalePtr[k] * ctx->bytesPerPixel,
+        ctx->heightSurface * ctx->yScalePtr[k], hipMemcpyHostToDevice));
+  }
+  // run cuda kernel over surface object of the LUMA surface part to extract
+  // grayscale.
+  yuvToGrayscaleCudaKernelNonNvSci(cudaResObj, deviceId, ctx->widthSurface,
+                                   ctx->heightSurface);
+}
+], hipMemcpyHostToDevice));
+  }
+  // run cuda kernel over surface object of the LUMA surface part to extract
+  // grayscale.
+  yuvToGrayscaleCudaKernelNonNvSci(cudaResObj, deviceId, ctx->widthSurface,
+                                   ctx->heightSurface);
+}
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer.cpp
index b6d9daf..8151947 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer.cpp
+++ b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer.cpp
@@ -1,471 +1,471 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <string.h>
-#include <iostream>
-/* Nvidia headers */
-#include "nvmedia_utils/cmdline.h"
-#include "nvmedia_image.h"
-#include "nvmedia_2d.h"
-#include "nvmedia_surface.h"
-#include "nvmedia_utils/image_utils.h"
-#include "nvmedia_image_nvscibuf.h"
-#include "nvmedia_producer.h"
-#include "nvmedia_2d_nvscisync.h"
-#include "nvsci_setup.h"
-
-NvMediaImage *NvMediaImageCreateUsingNvScibuf(NvMediaDevice *device,
-                                              NvMediaSurfaceType type,
-                                              const NvMediaSurfAllocAttr *attrs,
-                                              uint32_t numAttrs, uint32_t flags,
-                                              NvSciBufObj &bufobj,
-                                              int cudaDeviceId) {
-  NvSciBufModule module = NULL;
-  NvSciError err = NvSciError_Success;
-  NvMediaStatus status = NVMEDIA_STATUS_OK;
-  NvSciBufAttrList attrlist = NULL;
-  NvSciBufAttrList conflictlist = NULL;
-  NvSciBufAttrValAccessPerm access_perm = NvSciBufAccessPerm_ReadWrite;
-  NvSciBufAttrKeyValuePair attr_kvp = {NvSciBufGeneralAttrKey_RequiredPerm,
-                                       &access_perm, sizeof(access_perm)};
-  NvSciBufAttrKeyValuePair pairArrayOut[10];
-
-  NvMediaImage *image = NULL;
-
-  err = NvSciBufModuleOpen(&module);
-  if (err != NvSciError_Success) {
-    printf("%s: NvSciBuffModuleOpen failed. Error: %d \n", __func__, err);
-    goto fail_cleanup;
-  }
-
-  err = NvSciBufAttrListCreate(module, &attrlist);
-  if (err != NvSciError_Success) {
-    printf("%s: SciBufAttrListCreate failed. Error: %d \n", __func__, err);
-    goto fail_cleanup;
-  }
-
-  err = NvSciBufAttrListSetAttrs(attrlist, &attr_kvp, 1);
-  if (err != NvSciError_Success) {
-    printf("%s: AccessPermSetAttr failed. Error: %d \n", __func__, err);
-    goto fail_cleanup;
-  }
-
-  status =
-      NvMediaImageFillNvSciBufAttrs(device, type, attrs, numAttrs, 0, attrlist);
-
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: ImageFillSciBufAttrs failed. Error: %d \n", __func__, err);
-    goto fail_cleanup;
-  }
-
-  setupNvSciBuf(bufobj, attrlist, cudaDeviceId);
-
-  status = NvMediaImageCreateFromNvSciBuf(device, bufobj, &image);
-
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: ImageCreatefromSciBuf failed. Error: %d \n", __func__, err);
-    goto fail_cleanup;
-  }
-
-  NvSciBufAttrListFree(attrlist);
-
-  if (module != NULL) {
-    NvSciBufModuleClose(module);
-  }
-
-  return image;
-
-fail_cleanup:
-  if (attrlist != NULL) {
-    NvSciBufAttrListFree(attrlist);
-  }
-  if (bufobj != NULL) {
-    NvSciBufObjFree(bufobj);
-    bufobj = NULL;
-  }
-
-  if (module != NULL) {
-    NvSciBufModuleClose(module);
-  }
-  NvMediaImageDestroy(image);
-  return NULL;
-}
-
-/* Create NvMediaImage surface based on the input attributes.
- * Returns NVMEDIA_STATUS_OK on success
- */
-static NvMediaStatus createSurface(Blit2DTest *ctx,
-                                   NvMediaSurfFormatAttr *surfFormatAttrs,
-                                   NvMediaSurfAllocAttr *surfAllocAttrs,
-                                   uint32_t numSurfAllocAttrs,
-                                   NvMediaImage **image, NvSciBufObj &bufObj,
-                                   int cudaDeviceId) {
-  NvMediaSurfaceType surfType;
-
-  /* create source image */
-  surfType =
-      NvMediaSurfaceFormatGetType(surfFormatAttrs, NVM_SURF_FMT_ATTR_MAX);
-  *image = NvMediaImageCreateUsingNvScibuf(ctx->device, /* device */
-                                           surfType,    /* surface type */
-                                           surfAllocAttrs, numSurfAllocAttrs, 0,
-                                           bufObj, cudaDeviceId);
-
-  if (*image == NULL) {
-    printf("Unable to create image\n");
-    return NVMEDIA_STATUS_ERROR;
-  }
-  InitImage(*image, surfAllocAttrs[0].value, surfAllocAttrs[1].value);
-
-  /*    printf("%s: NvMediaImageCreate:: Image size: %ux%u Image type: %d\n",
-              __func__, surfAllocAttrs[0].value, surfAllocAttrs[1].value,
-     surfType);*/
-
-  return NVMEDIA_STATUS_OK;
-}
-
-/* Create NvMediaImage surface based on the input attributes.
- * Returns NVMEDIA_STATUS_OK on success
- */
-static NvMediaStatus createSurfaceNonNvSCI(
-    Blit2DTest *ctx, NvMediaSurfFormatAttr *surfFormatAttrs,
-    NvMediaSurfAllocAttr *surfAllocAttrs, uint32_t numSurfAllocAttrs,
-    NvMediaImage **image) {
-  NvMediaSurfaceType surfType;
-
-  /* create source image */
-  surfType =
-      NvMediaSurfaceFormatGetType(surfFormatAttrs, NVM_SURF_FMT_ATTR_MAX);
-
-  *image = NvMediaImageCreateNew(ctx->device, surfType, surfAllocAttrs,
-                                 numSurfAllocAttrs, 0);
-
-  if (*image == NULL) {
-    printf("Unable to create image\n");
-    return NVMEDIA_STATUS_ERROR;
-  }
-  InitImage(*image, surfAllocAttrs[0].value, surfAllocAttrs[1].value);
-
-  /*    printf("%s: NvMediaImageCreate:: Image size: %ux%u Image type: %d\n",
-              __func__, surfAllocAttrs[0].value, surfAllocAttrs[1].value,
-     surfType);*/
-
-  return NVMEDIA_STATUS_OK;
-}
-
-static void destroySurface(NvMediaImage *image) { NvMediaImageDestroy(image); }
-
-static NvMediaStatus blit2DImage(Blit2DTest *ctx, TestArgs *args,
-                                 NvSciSyncObj &nvMediaSignalerSyncObj,
-                                 NvSciSyncFence *preSyncFence,
-                                 NvSciSyncFence *fence) {
-  NvMediaStatus status;
-  NvMediaImageSurfaceMap surfaceMap;
-
-  status = ReadImage(args->inputFileName,              /* fileName */
-                     0,                                /* frameNum */
-                     args->srcSurfAllocAttrs[0].value, /* source image width */
-                     args->srcSurfAllocAttrs[1].value, /* source image height */
-                     ctx->srcImage,                    /* srcImage */
-                     NVMEDIA_TRUE,                     /* uvOrderFlag */
-                     1,                                /* bytesPerPixel */
-                     MSB_ALIGNED);                     /* pixelAlignment */
-
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: ReadImage failed for input buffer: %d\n", __func__, status);
-    return status;
-  }
-
-  if ((args->srcRect.x1 <= args->srcRect.x0) ||
-      (args->srcRect.y1 <= args->srcRect.y0)) {
-    ctx->srcRect = NULL;
-  } else {
-    ctx->srcRect = &(args->srcRect);
-  }
-
-  if ((args->dstRect.x1 <= args->dstRect.x0) ||
-      (args->dstRect.y1 <= args->dstRect.y0)) {
-    ctx->dstRect = NULL;
-  } else {
-    ctx->dstRect = &(args->dstRect);
-  }
-
-  static int64_t launch = 0;
-  // Start inserting pre-fence from second launch inorder to for NvMedia2Blit to
-  // wait
-  // for cuda signal on fence.
-  if (launch) {
-    status = NvMedia2DInsertPreNvSciSyncFence(ctx->i2d, preSyncFence);
-    if (status != NVMEDIA_STATUS_OK) {
-      printf("%s: NvMedia2DSetNvSciSyncObjforEOF   failed: %d\n", __func__,
-             status);
-      return status;
-    }
-    NvSciSyncFenceClear(preSyncFence);
-  }
-  launch++;
-
-  status = NvMedia2DSetNvSciSyncObjforEOF(ctx->i2d, nvMediaSignalerSyncObj);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: NvMedia2DSetNvSciSyncObjforEOF   failed: %d\n", __func__,
-           status);
-    return status;
-  }
-
-  /* 2DBlit processing on input image */
-  status = NvMedia2DBlitEx(ctx->i2d,          /* i2d */
-                           ctx->dstImage,     /* dstSurface */
-                           ctx->dstRect,      /* dstRect */
-                           ctx->srcImage,     /* srcSurface */
-                           ctx->srcRect,      /* srcRect */
-                           &args->blitParams, /* params */
-                           NULL);             /* paramsOut */
-
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: NvMedia2DBlitEx failed: %d\n", __func__, status);
-    return status;
-  }
-
-  status =
-      NvMedia2DGetEOFNvSciSyncFence(ctx->i2d, nvMediaSignalerSyncObj, fence);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: NvMedia2DGetEOFNvSciSyncFence failed: %d\n", __func__, status);
-    return status;
-  }
-
-  return NVMEDIA_STATUS_OK;
-}
-
-static NvMediaStatus blit2DImageNonNvSCI(Blit2DTest *ctx, TestArgs *args) {
-  NvMediaStatus status;
-  NvMediaImageSurfaceMap surfaceMap;
-
-  status = ReadImage(args->inputFileName,              /* fileName */
-                     0,                                /* frameNum */
-                     args->srcSurfAllocAttrs[0].value, /* source image width */
-                     args->srcSurfAllocAttrs[1].value, /* source image height */
-                     ctx->srcImage,                    /* srcImage */
-                     NVMEDIA_TRUE,                     /* uvOrderFlag */
-                     1,                                /* bytesPerPixel */
-                     MSB_ALIGNED);                     /* pixelAlignment */
-
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: ReadImage failed for input buffer: %d\n", __func__, status);
-    return status;
-  }
-
-  if ((args->srcRect.x1 <= args->srcRect.x0) ||
-      (args->srcRect.y1 <= args->srcRect.y0)) {
-    ctx->srcRect = NULL;
-  } else {
-    ctx->srcRect = &(args->srcRect);
-  }
-
-  if ((args->dstRect.x1 <= args->dstRect.x0) ||
-      (args->dstRect.y1 <= args->dstRect.y0)) {
-    ctx->dstRect = NULL;
-  } else {
-    ctx->dstRect = &(args->dstRect);
-  }
-
-  /* 2DBlit processing on input image */
-  status = NvMedia2DBlitEx(ctx->i2d,          /* i2d */
-                           ctx->dstImage,     /* dstSurface */
-                           ctx->dstRect,      /* dstRect */
-                           ctx->srcImage,     /* srcSurface */
-                           ctx->srcRect,      /* srcRect */
-                           &args->blitParams, /* params */
-                           NULL);             /* paramsOut */
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: NvMedia2DBlitEx failed: %d\n", __func__, status);
-    return status;
-  }
-
-  /* Write output image into buffer */
-  ctx->bytesPerPixel = 1;
-  WriteImageToAllocatedBuffer(ctx, ctx->dstImage, NVMEDIA_TRUE, NVMEDIA_FALSE,
-                              ctx->bytesPerPixel);
-
-  return NVMEDIA_STATUS_OK;
-}
-
-static void cleanup(Blit2DTest *ctx, NvMediaStatus status = NVMEDIA_STATUS_OK) {
-  if (ctx->srcImage != NULL) {
-    NvMedia2DImageUnRegister(ctx->i2d, ctx->srcImage);
-    destroySurface(ctx->srcImage);
-  }
-  if (ctx->dstImage != NULL) {
-    NvMedia2DImageUnRegister(ctx->i2d, ctx->dstImage);
-    destroySurface(ctx->dstImage);
-  }
-  if (status != NVMEDIA_STATUS_OK) {
-    exit(EXIT_FAILURE);
-  }
-}
-
-void cleanupNvMedia(Blit2DTest *ctx, NvSciSyncObj &syncObj,
-                    NvSciSyncObj &preSyncObj) {
-  NvMediaStatus status;
-  cleanup(ctx);
-  status = NvMedia2DUnregisterNvSciSyncObj(ctx->i2d, syncObj);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: NvMediaImageSciBufInit failed\n", __func__);
-    exit(EXIT_FAILURE);
-  }
-  status = NvMedia2DUnregisterNvSciSyncObj(ctx->i2d, preSyncObj);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: NvMediaImageSciBufInit failed\n", __func__);
-    exit(EXIT_FAILURE);
-  }
-  NvMediaImageNvSciBufDeinit();
-}
-
-void cleanupNvMedia(Blit2DTest *ctx) {
-  cleanup(ctx);
-  free(ctx->dstBuffPitches);
-  free(ctx->dstBuffer);
-  free(ctx->dstBuff);
-}
-
-void setupNvMedia(TestArgs *args, Blit2DTest *ctx, NvSciBufObj &srcNvSciBufobj,
-                  NvSciBufObj &dstNvSciBufobj, NvSciSyncObj &syncObj,
-                  NvSciSyncObj &preSyncObj, int cudaDeviceId) {
-  NvMediaStatus status;
-  status = NvMediaImageNvSciBufInit();
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: NvMediaImageSciBufInit failed\n", __func__);
-    cleanup(ctx, status);
-  }
-
-  // Create source surface
-  status = createSurface(ctx, args->srcSurfFormatAttrs, args->srcSurfAllocAttrs,
-                         args->numSurfAllocAttrs, &ctx->srcImage,
-                         srcNvSciBufobj, cudaDeviceId);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: Unable to create buffer pools\n", __func__);
-    cleanup(ctx, status);
-  }
-
-  // Create destination surface
-  status = createSurface(ctx, args->dstSurfFormatAttrs, args->dstSurfAllocAttrs,
-                         args->numSurfAllocAttrs, &ctx->dstImage,
-                         dstNvSciBufobj, cudaDeviceId);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: Unable to create buffer pools\n", __func__);
-    cleanup(ctx, status);
-  }
-
-  // Register source  Surface
-  status =
-      NvMedia2DImageRegister(ctx->i2d, ctx->srcImage, NVMEDIA_ACCESS_MODE_READ);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: Unable to register source surface\n", __func__);
-    cleanup(ctx, status);
-  }
-  // Register destination Surface
-  status = NvMedia2DImageRegister(ctx->i2d, ctx->dstImage,
-                                  NVMEDIA_ACCESS_MODE_READ_WRITE);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: Unable to register destination surface\n", __func__);
-    cleanup(ctx, status);
-  }
-
-  status = NvMedia2DRegisterNvSciSyncObj(ctx->i2d, NVMEDIA_EOFSYNCOBJ, syncObj);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: Unable to NvMedia2DRegisterNvSciSyncObj\n", __func__);
-  }
-
-  status =
-      NvMedia2DRegisterNvSciSyncObj(ctx->i2d, NVMEDIA_PRESYNCOBJ, preSyncObj);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: Unable to NvMedia2DRegisterNvSciSyncObj\n", __func__);
-  }
-}
-
-// Create NvMedia src & dst image without NvSciBuf
-void setupNvMedia(TestArgs *args, Blit2DTest *ctx) {
-  NvMediaStatus status;
-
-  // Create source surface
-  status = createSurfaceNonNvSCI(ctx, args->srcSurfFormatAttrs,
-                                 args->srcSurfAllocAttrs,
-                                 args->numSurfAllocAttrs, &ctx->srcImage);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: Unable to create buffer pools\n", __func__);
-    cleanup(ctx, status);
-  }
-
-  // Create destination surface
-  status = createSurfaceNonNvSCI(ctx, args->dstSurfFormatAttrs,
-                                 args->dstSurfAllocAttrs,
-                                 args->numSurfAllocAttrs, &ctx->dstImage);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: Unable to create buffer pools\n", __func__);
-    cleanup(ctx, status);
-  }
-
-  // Register source  Surface
-  status =
-      NvMedia2DImageRegister(ctx->i2d, ctx->srcImage, NVMEDIA_ACCESS_MODE_READ);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: Unable to register source surface\n", __func__);
-    cleanup(ctx, status);
-  }
-
-  // Register destination Surface
-  status = NvMedia2DImageRegister(ctx->i2d, ctx->dstImage,
-                                  NVMEDIA_ACCESS_MODE_READ_WRITE);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: Unable to register destination surface\n", __func__);
-    cleanup(ctx, status);
-  }
-
-  // Allocate buffer for writing image & set image parameters in Blit2DTest.
-  ctx->bytesPerPixel = 1;
-  AllocateBufferToWriteImage(ctx, ctx->dstImage, NVMEDIA_TRUE, /* uvOrderFlag */
-                             NVMEDIA_FALSE);                   /* appendFlag */
-}
-
-void runNvMediaBlit2D(TestArgs *args, Blit2DTest *ctx) {
-  // Blit2D function
-  NvMediaStatus status = blit2DImageNonNvSCI(ctx, args);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: Blit2D failed\n", __func__);
-    cleanup(ctx, status);
-  }
-}
-
-void runNvMediaBlit2D(TestArgs *args, Blit2DTest *ctx,
-                      NvSciSyncObj &nvMediaSignalerSyncObj,
-                      NvSciSyncFence *preSyncFence, NvSciSyncFence *fence) {
-  // Blit2D function
-  NvMediaStatus status =
-      blit2DImage(ctx, args, nvMediaSignalerSyncObj, preSyncFence, fence);
-  if (status != NVMEDIA_STATUS_OK) {
-    printf("%s: Blit2D failed\n", __func__);
-    cleanup(ctx, status);
-  }
-}
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <string.h>
+#include <iostream>
+/* Nvidia headers */
+#include "nvmedia_utils/cmdline.h"
+#include "nvmedia_image.h"
+#include "nvmedia_2d.h"
+#include "nvmedia_surface.h"
+#include "nvmedia_utils/image_utils.h"
+#include "nvmedia_image_nvscibuf.h"
+#include "nvmedia_producer.h"
+#include "nvmedia_2d_nvscisync.h"
+#include "nvsci_setup.h"
+
+NvMediaImage *NvMediaImageCreateUsingNvScibuf(NvMediaDevice *device,
+                                              NvMediaSurfaceType type,
+                                              const NvMediaSurfAllocAttr *attrs,
+                                              uint32_t numAttrs, uint32_t flags,
+                                              NvSciBufObj &bufobj,
+                                              int cudaDeviceId) {
+  NvSciBufModule module = NULL;
+  NvSciError err = NvSciError_Success;
+  NvMediaStatus status = NVMEDIA_STATUS_OK;
+  NvSciBufAttrList attrlist = NULL;
+  NvSciBufAttrList conflictlist = NULL;
+  NvSciBufAttrValAccessPerm access_perm = NvSciBufAccessPerm_ReadWrite;
+  NvSciBufAttrKeyValuePair attr_kvp = {NvSciBufGeneralAttrKey_RequiredPerm,
+                                       &access_perm, sizeof(access_perm)};
+  NvSciBufAttrKeyValuePair pairArrayOut[10];
+
+  NvMediaImage *image = NULL;
+
+  err = NvSciBufModuleOpen(&module);
+  if (err != NvSciError_Success) {
+    printf("%s: NvSciBuffModuleOpen failed. Error: %d \n", __func__, err);
+    goto fail_cleanup;
+  }
+
+  err = NvSciBufAttrListCreate(module, &attrlist);
+  if (err != NvSciError_Success) {
+    printf("%s: SciBufAttrListCreate failed. Error: %d \n", __func__, err);
+    goto fail_cleanup;
+  }
+
+  err = NvSciBufAttrListSetAttrs(attrlist, &attr_kvp, 1);
+  if (err != NvSciError_Success) {
+    printf("%s: AccessPermSetAttr failed. Error: %d \n", __func__, err);
+    goto fail_cleanup;
+  }
+
+  status =
+      NvMediaImageFillNvSciBufAttrs(device, type, attrs, numAttrs, 0, attrlist);
+
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: ImageFillSciBufAttrs failed. Error: %d \n", __func__, err);
+    goto fail_cleanup;
+  }
+
+  setupNvSciBuf(bufobj, attrlist, cudaDeviceId);
+
+  status = NvMediaImageCreateFromNvSciBuf(device, bufobj, &image);
+
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: ImageCreatefromSciBuf failed. Error: %d \n", __func__, err);
+    goto fail_cleanup;
+  }
+
+  NvSciBufAttrListFree(attrlist);
+
+  if (module != NULL) {
+    NvSciBufModuleClose(module);
+  }
+
+  return image;
+
+fail_cleanup:
+  if (attrlist != NULL) {
+    NvSciBufAttrListFree(attrlist);
+  }
+  if (bufobj != NULL) {
+    NvSciBufObjFree(bufobj);
+    bufobj = NULL;
+  }
+
+  if (module != NULL) {
+    NvSciBufModuleClose(module);
+  }
+  NvMediaImageDestroy(image);
+  return NULL;
+}
+
+/* Create NvMediaImage surface based on the input attributes.
+ * Returns NVMEDIA_STATUS_OK on success
+ */
+static NvMediaStatus createSurface(Blit2DTest *ctx,
+                                   NvMediaSurfFormatAttr *surfFormatAttrs,
+                                   NvMediaSurfAllocAttr *surfAllocAttrs,
+                                   uint32_t numSurfAllocAttrs,
+                                   NvMediaImage **image, NvSciBufObj &bufObj,
+                                   int cudaDeviceId) {
+  NvMediaSurfaceType surfType;
+
+  /* create source image */
+  surfType =
+      NvMediaSurfaceFormatGetType(surfFormatAttrs, NVM_SURF_FMT_ATTR_MAX);
+  *image = NvMediaImageCreateUsingNvScibuf(ctx->device, /* device */
+                                           surfType,    /* surface type */
+                                           surfAllocAttrs, numSurfAllocAttrs, 0,
+                                           bufObj, cudaDeviceId);
+
+  if (*image == NULL) {
+    printf("Unable to create image\n");
+    return NVMEDIA_STATUS_ERROR;
+  }
+  InitImage(*image, surfAllocAttrs[0].value, surfAllocAttrs[1].value);
+
+  /*    printf("%s: NvMediaImageCreate:: Image size: %ux%u Image type: %d\n",
+              __func__, surfAllocAttrs[0].value, surfAllocAttrs[1].value,
+     surfType);*/
+
+  return NVMEDIA_STATUS_OK;
+}
+
+/* Create NvMediaImage surface based on the input attributes.
+ * Returns NVMEDIA_STATUS_OK on success
+ */
+static NvMediaStatus createSurfaceNonNvSCI(
+    Blit2DTest *ctx, NvMediaSurfFormatAttr *surfFormatAttrs,
+    NvMediaSurfAllocAttr *surfAllocAttrs, uint32_t numSurfAllocAttrs,
+    NvMediaImage **image) {
+  NvMediaSurfaceType surfType;
+
+  /* create source image */
+  surfType =
+      NvMediaSurfaceFormatGetType(surfFormatAttrs, NVM_SURF_FMT_ATTR_MAX);
+
+  *image = NvMediaImageCreateNew(ctx->device, surfType, surfAllocAttrs,
+                                 numSurfAllocAttrs, 0);
+
+  if (*image == NULL) {
+    printf("Unable to create image\n");
+    return NVMEDIA_STATUS_ERROR;
+  }
+  InitImage(*image, surfAllocAttrs[0].value, surfAllocAttrs[1].value);
+
+  /*    printf("%s: NvMediaImageCreate:: Image size: %ux%u Image type: %d\n",
+              __func__, surfAllocAttrs[0].value, surfAllocAttrs[1].value,
+     surfType);*/
+
+  return NVMEDIA_STATUS_OK;
+}
+
+static void destroySurface(NvMediaImage *image) { NvMediaImageDestroy(image); }
+
+static NvMediaStatus blit2DImage(Blit2DTest *ctx, TestArgs *args,
+                                 NvSciSyncObj &nvMediaSignalerSyncObj,
+                                 NvSciSyncFence *preSyncFence,
+                                 NvSciSyncFence *fence) {
+  NvMediaStatus status;
+  NvMediaImageSurfaceMap surfaceMap;
+
+  status = ReadImage(args->inputFileName,              /* fileName */
+                     0,                                /* frameNum */
+                     args->srcSurfAllocAttrs[0].value, /* source image width */
+                     args->srcSurfAllocAttrs[1].value, /* source image height */
+                     ctx->srcImage,                    /* srcImage */
+                     NVMEDIA_TRUE,                     /* uvOrderFlag */
+                     1,                                /* bytesPerPixel */
+                     MSB_ALIGNED);                     /* pixelAlignment */
+
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: ReadImage failed for input buffer: %d\n", __func__, status);
+    return status;
+  }
+
+  if ((args->srcRect.x1 <= args->srcRect.x0) ||
+      (args->srcRect.y1 <= args->srcRect.y0)) {
+    ctx->srcRect = NULL;
+  } else {
+    ctx->srcRect = &(args->srcRect);
+  }
+
+  if ((args->dstRect.x1 <= args->dstRect.x0) ||
+      (args->dstRect.y1 <= args->dstRect.y0)) {
+    ctx->dstRect = NULL;
+  } else {
+    ctx->dstRect = &(args->dstRect);
+  }
+
+  static int64_t launch = 0;
+  // Start inserting pre-fence from second launch inorder to for NvMedia2Blit to
+  // wait
+  // for cuda signal on fence.
+  if (launch) {
+    status = NvMedia2DInsertPreNvSciSyncFence(ctx->i2d, preSyncFence);
+    if (status != NVMEDIA_STATUS_OK) {
+      printf("%s: NvMedia2DSetNvSciSyncObjforEOF   failed: %d\n", __func__,
+             status);
+      return status;
+    }
+    NvSciSyncFenceClear(preSyncFence);
+  }
+  launch++;
+
+  status = NvMedia2DSetNvSciSyncObjforEOF(ctx->i2d, nvMediaSignalerSyncObj);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: NvMedia2DSetNvSciSyncObjforEOF   failed: %d\n", __func__,
+           status);
+    return status;
+  }
+
+  /* 2DBlit processing on input image */
+  status = NvMedia2DBlitEx(ctx->i2d,          /* i2d */
+                           ctx->dstImage,     /* dstSurface */
+                           ctx->dstRect,      /* dstRect */
+                           ctx->srcImage,     /* srcSurface */
+                           ctx->srcRect,      /* srcRect */
+                           &args->blitParams, /* params */
+                           NULL);             /* paramsOut */
+
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: NvMedia2DBlitEx failed: %d\n", __func__, status);
+    return status;
+  }
+
+  status =
+      NvMedia2DGetEOFNvSciSyncFence(ctx->i2d, nvMediaSignalerSyncObj, fence);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: NvMedia2DGetEOFNvSciSyncFence failed: %d\n", __func__, status);
+    return status;
+  }
+
+  return NVMEDIA_STATUS_OK;
+}
+
+static NvMediaStatus blit2DImageNonNvSCI(Blit2DTest *ctx, TestArgs *args) {
+  NvMediaStatus status;
+  NvMediaImageSurfaceMap surfaceMap;
+
+  status = ReadImage(args->inputFileName,              /* fileName */
+                     0,                                /* frameNum */
+                     args->srcSurfAllocAttrs[0].value, /* source image width */
+                     args->srcSurfAllocAttrs[1].value, /* source image height */
+                     ctx->srcImage,                    /* srcImage */
+                     NVMEDIA_TRUE,                     /* uvOrderFlag */
+                     1,                                /* bytesPerPixel */
+                     MSB_ALIGNED);                     /* pixelAlignment */
+
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: ReadImage failed for input buffer: %d\n", __func__, status);
+    return status;
+  }
+
+  if ((args->srcRect.x1 <= args->srcRect.x0) ||
+      (args->srcRect.y1 <= args->srcRect.y0)) {
+    ctx->srcRect = NULL;
+  } else {
+    ctx->srcRect = &(args->srcRect);
+  }
+
+  if ((args->dstRect.x1 <= args->dstRect.x0) ||
+      (args->dstRect.y1 <= args->dstRect.y0)) {
+    ctx->dstRect = NULL;
+  } else {
+    ctx->dstRect = &(args->dstRect);
+  }
+
+  /* 2DBlit processing on input image */
+  status = NvMedia2DBlitEx(ctx->i2d,          /* i2d */
+                           ctx->dstImage,     /* dstSurface */
+                           ctx->dstRect,      /* dstRect */
+                           ctx->srcImage,     /* srcSurface */
+                           ctx->srcRect,      /* srcRect */
+                           &args->blitParams, /* params */
+                           NULL);             /* paramsOut */
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: NvMedia2DBlitEx failed: %d\n", __func__, status);
+    return status;
+  }
+
+  /* Write output image into buffer */
+  ctx->bytesPerPixel = 1;
+  WriteImageToAllocatedBuffer(ctx, ctx->dstImage, NVMEDIA_TRUE, NVMEDIA_FALSE,
+                              ctx->bytesPerPixel);
+
+  return NVMEDIA_STATUS_OK;
+}
+
+static void cleanup(Blit2DTest *ctx, NvMediaStatus status = NVMEDIA_STATUS_OK) {
+  if (ctx->srcImage != NULL) {
+    NvMedia2DImageUnRegister(ctx->i2d, ctx->srcImage);
+    destroySurface(ctx->srcImage);
+  }
+  if (ctx->dstImage != NULL) {
+    NvMedia2DImageUnRegister(ctx->i2d, ctx->dstImage);
+    destroySurface(ctx->dstImage);
+  }
+  if (status != NVMEDIA_STATUS_OK) {
+    exit(EXIT_FAILURE);
+  }
+}
+
+void cleanupNvMedia(Blit2DTest *ctx, NvSciSyncObj &syncObj,
+                    NvSciSyncObj &preSyncObj) {
+  NvMediaStatus status;
+  cleanup(ctx);
+  status = NvMedia2DUnregisterNvSciSyncObj(ctx->i2d, syncObj);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: NvMediaImageSciBufInit failed\n", __func__);
+    exit(EXIT_FAILURE);
+  }
+  status = NvMedia2DUnregisterNvSciSyncObj(ctx->i2d, preSyncObj);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: NvMediaImageSciBufInit failed\n", __func__);
+    exit(EXIT_FAILURE);
+  }
+  NvMediaImageNvSciBufDeinit();
+}
+
+void cleanupNvMedia(Blit2DTest *ctx) {
+  cleanup(ctx);
+  free(ctx->dstBuffPitches);
+  free(ctx->dstBuffer);
+  free(ctx->dstBuff);
+}
+
+void setupNvMedia(TestArgs *args, Blit2DTest *ctx, NvSciBufObj &srcNvSciBufobj,
+                  NvSciBufObj &dstNvSciBufobj, NvSciSyncObj &syncObj,
+                  NvSciSyncObj &preSyncObj, int cudaDeviceId) {
+  NvMediaStatus status;
+  status = NvMediaImageNvSciBufInit();
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: NvMediaImageSciBufInit failed\n", __func__);
+    cleanup(ctx, status);
+  }
+
+  // Create source surface
+  status = createSurface(ctx, args->srcSurfFormatAttrs, args->srcSurfAllocAttrs,
+                         args->numSurfAllocAttrs, &ctx->srcImage,
+                         srcNvSciBufobj, cudaDeviceId);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: Unable to create buffer pools\n", __func__);
+    cleanup(ctx, status);
+  }
+
+  // Create destination surface
+  status = createSurface(ctx, args->dstSurfFormatAttrs, args->dstSurfAllocAttrs,
+                         args->numSurfAllocAttrs, &ctx->dstImage,
+                         dstNvSciBufobj, cudaDeviceId);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: Unable to create buffer pools\n", __func__);
+    cleanup(ctx, status);
+  }
+
+  // Register source  Surface
+  status =
+      NvMedia2DImageRegister(ctx->i2d, ctx->srcImage, NVMEDIA_ACCESS_MODE_READ);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: Unable to register source surface\n", __func__);
+    cleanup(ctx, status);
+  }
+  // Register destination Surface
+  status = NvMedia2DImageRegister(ctx->i2d, ctx->dstImage,
+                                  NVMEDIA_ACCESS_MODE_READ_WRITE);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: Unable to register destination surface\n", __func__);
+    cleanup(ctx, status);
+  }
+
+  status = NvMedia2DRegisterNvSciSyncObj(ctx->i2d, NVMEDIA_EOFSYNCOBJ, syncObj);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: Unable to NvMedia2DRegisterNvSciSyncObj\n", __func__);
+  }
+
+  status =
+      NvMedia2DRegisterNvSciSyncObj(ctx->i2d, NVMEDIA_PRESYNCOBJ, preSyncObj);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: Unable to NvMedia2DRegisterNvSciSyncObj\n", __func__);
+  }
+}
+
+// Create NvMedia src & dst image without NvSciBuf
+void setupNvMedia(TestArgs *args, Blit2DTest *ctx) {
+  NvMediaStatus status;
+
+  // Create source surface
+  status = createSurfaceNonNvSCI(ctx, args->srcSurfFormatAttrs,
+                                 args->srcSurfAllocAttrs,
+                                 args->numSurfAllocAttrs, &ctx->srcImage);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: Unable to create buffer pools\n", __func__);
+    cleanup(ctx, status);
+  }
+
+  // Create destination surface
+  status = createSurfaceNonNvSCI(ctx, args->dstSurfFormatAttrs,
+                                 args->dstSurfAllocAttrs,
+                                 args->numSurfAllocAttrs, &ctx->dstImage);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: Unable to create buffer pools\n", __func__);
+    cleanup(ctx, status);
+  }
+
+  // Register source  Surface
+  status =
+      NvMedia2DImageRegister(ctx->i2d, ctx->srcImage, NVMEDIA_ACCESS_MODE_READ);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: Unable to register source surface\n", __func__);
+    cleanup(ctx, status);
+  }
+
+  // Register destination Surface
+  status = NvMedia2DImageRegister(ctx->i2d, ctx->dstImage,
+                                  NVMEDIA_ACCESS_MODE_READ_WRITE);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: Unable to register destination surface\n", __func__);
+    cleanup(ctx, status);
+  }
+
+  // Allocate buffer for writing image & set image parameters in Blit2DTest.
+  ctx->bytesPerPixel = 1;
+  AllocateBufferToWriteImage(ctx, ctx->dstImage, NVMEDIA_TRUE, /* uvOrderFlag */
+                             NVMEDIA_FALSE);                   /* appendFlag */
+}
+
+void runNvMediaBlit2D(TestArgs *args, Blit2DTest *ctx) {
+  // Blit2D function
+  NvMediaStatus status = blit2DImageNonNvSCI(ctx, args);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: Blit2D failed\n", __func__);
+    cleanup(ctx, status);
+  }
+}
+
+void runNvMediaBlit2D(TestArgs *args, Blit2DTest *ctx,
+                      NvSciSyncObj &nvMediaSignalerSyncObj,
+                      NvSciSyncFence *preSyncFence, NvSciSyncFence *fence) {
+  // Blit2D function
+  NvMediaStatus status =
+      blit2DImage(ctx, args, nvMediaSignalerSyncObj, preSyncFence, fence);
+  if (status != NVMEDIA_STATUS_OK) {
+    printf("%s: Blit2D failed\n", __func__);
+    cleanup(ctx, status);
+  }
+}
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer.h
index adee698..a4e234f 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer.h
+++ b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer.h
@@ -1,48 +1,48 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef __NVMEDIA_PRODUCER_H__
-#define __NVMEDIA_PRODUCER_H__
-#include "nvmedia_utils/cmdline.h"
-#include "nvmedia_image.h"
-#include "nvmedia_2d.h"
-#include "nvmedia_surface.h"
-#include "nvmedia_utils/image_utils.h"
-#include "nvmedia_image_nvscibuf.h"
-#include "nvscisync.h"
-
-void runNvMediaBlit2D(TestArgs* args, Blit2DTest* ctx, NvSciSyncObj& syncObj,
-                      NvSciSyncFence* preSyncFence, NvSciSyncFence* fence);
-void runNvMediaBlit2D(TestArgs* args, Blit2DTest* ctx);
-void setupNvMedia(TestArgs* args, Blit2DTest* ctx, NvSciBufObj& srcNvSciBufobj,
-                  NvSciBufObj& dstNvSciBufobj, NvSciSyncObj& syncObj,
-                  NvSciSyncObj& preSyncObj, int cudaDeviceId);
-void setupNvMedia(TestArgs* args, Blit2DTest* ctx);
-void cleanupNvMedia(Blit2DTest* ctx, NvSciSyncObj& syncObj,
-                    NvSciSyncObj& preSyncObj);
-void cleanupNvMedia(Blit2DTest* ctx);
-#endif
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef __NVMEDIA_PRODUCER_H__
+#define __NVMEDIA_PRODUCER_H__
+#include "nvmedia_utils/cmdline.h"
+#include "nvmedia_image.h"
+#include "nvmedia_2d.h"
+#include "nvmedia_surface.h"
+#include "nvmedia_utils/image_utils.h"
+#include "nvmedia_image_nvscibuf.h"
+#include "nvscisync.h"
+
+void runNvMediaBlit2D(TestArgs* args, Blit2DTest* ctx, NvSciSyncObj& syncObj,
+                      NvSciSyncFence* preSyncFence, NvSciSyncFence* fence);
+void runNvMediaBlit2D(TestArgs* args, Blit2DTest* ctx);
+void setupNvMedia(TestArgs* args, Blit2DTest* ctx, NvSciBufObj& srcNvSciBufobj,
+                  NvSciBufObj& dstNvSciBufobj, NvSciSyncObj& syncObj,
+                  NvSciSyncObj& preSyncObj, int cudaDeviceId);
+void setupNvMedia(TestArgs* args, Blit2DTest* ctx);
+void cleanupNvMedia(Blit2DTest* ctx, NvSciSyncObj& syncObj,
+                    NvSciSyncObj& preSyncObj);
+void cleanupNvMedia(Blit2DTest* ctx);
+#endif
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvsci_setup.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvsci_setup.h
index f2e1efa..23b26f7 100755
--- a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvsci_setup.h
+++ b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvsci_setup.h
@@ -1,42 +1,42 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef __NVSCI_SETUP_H__
-#define __NVSCI_SETUP_H__
-#include "nvmedia_utils/cmdline.h"
-#include <nvscibuf.h>
-#include <nvscisync.h>
-
-void setupNvMediaSignalerNvSciSync(Blit2DTest *ctx, NvSciSyncObj &syncObj,
-                                   int cudaDeviceId);
-void setupCudaSignalerNvSciSync(Blit2DTest *ctx, NvSciSyncObj &syncObj,
-                                int cudaDeviceId);
-void setupNvSciBuf(NvSciBufObj &bufobj, NvSciBufAttrList &nvmediaAttrlist,
-                   int cudaDeviceId);
-void cleanupNvSciBuf(NvSciBufObj &Bufobj);
-void cleanupNvSciSync(NvSciSyncObj &syncObj);
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef __NVSCI_SETUP_H__
+#define __NVSCI_SETUP_H__
+#include "nvmedia_utils/cmdline.h"
+#include <nvscibuf.h>
+#include <nvscisync.h>
+
+void setupNvMediaSignalerNvSciSync(Blit2DTest *ctx, NvSciSyncObj &syncObj,
+                                   int cudaDeviceId);
+void setupCudaSignalerNvSciSync(Blit2DTest *ctx, NvSciSyncObj &syncObj,
+                                int cudaDeviceId);
+void setupNvSciBuf(NvSciBufObj &bufobj, NvSciBufAttrList &nvmediaAttrlist,
+                   int cudaDeviceId);
+void cleanupNvSciBuf(NvSciBufObj &Bufobj);
+void cleanupNvSciSync(NvSciSyncObj &syncObj);
 #endif
\ No newline at end of file
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/Makefile b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/Makefile
index 06c77bc..55e712a 100755
--- a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/Makefile
@@ -295,8 +295,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/NsightEclipse.xml
index 8a6d87c..33f8075 100755
--- a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/NsightEclipse.xml
@@ -52,6 +52,8 @@
     <scope>1:Performance Strategies</scope>
     <scope>2:Image Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/README.md b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/README.md
index 77902c2..96e072b 100755
--- a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/README.md
@@ -10,7 +10,7 @@ Performance Strategies, Image Processing, NPP Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaRuntimeGetVersion, cudaSetDevice, cudaGetDeviceCount, cudaDeviceInit, cudaDr
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2017.vcxproj
index d3a5c0a..b81f5f2 100755
--- a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/freeImageInteropNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -117,6 +117,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2019.vcxproj
index b623830..0328959 100755
--- a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/freeImageInteropNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2022.vcxproj
index 81bbbc4..624cfaa 100755
--- a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/freeImageInteropNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/Makefile b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/Makefile
index a74c1ad..0930bc5 100755
--- a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/Makefile
@@ -295,8 +295,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/NsightEclipse.xml
index e6c9c2c..9b1554b 100755
--- a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/NsightEclipse.xml
@@ -58,6 +58,8 @@
     <scope>1:Performance Strategies</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/README.md b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/README.md
index b29aad8..ecf77bc 100755
--- a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/README.md
@@ -10,7 +10,7 @@ Image Processing, Performance Strategies, NPP Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaRuntimeGetVersion, cudaMemcpy, cudaFree, cudaSetDevice, cudaGetDeviceCount,
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2017.vcxproj
index 7c23e2f..6eb23e1 100755
--- a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/histEqualizationNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -117,6 +117,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2019.vcxproj
index d755930..6dd5705 100755
--- a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/histEqualizationNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2022.vcxproj
index ba6aa8e..3f16252 100755
--- a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/histEqualizationNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/Makefile b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/Makefile
index 1baccd0..21b842f 100755
--- a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/Makefile
@@ -306,7 +306,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/NsightEclipse.xml
index 785b6d8..e279a4f 100755
--- a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/NsightEclipse.xml
@@ -44,6 +44,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>1:Data-Parallel Algorithms</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/README.md b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/README.md
index d784404..e704d3e 100755
--- a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/README.md
@@ -10,7 +10,7 @@ Thrust Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaCreateChannelDesc, cudaMallocArray, cudaFreeArray, cudaDeviceSynchronize, cu
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight.cu.hip b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight.cu.hip
index c4dd461..7edb61c 100755
--- a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight.cu.hip
@@ -152,11 +152,11 @@ int runTest(int argc, char **argv) {
   hipChannelFormatDesc channelDesc =
       hipCreateChannelDesc(32, 0, 0, 0, hipChannelFormatKindFloat);
   hipArray *heightFieldArray;
-  checkCudaErrors(
+  HIPCHECK(
       hipMallocArray(&heightFieldArray, &channelDesc, dim.x, dim.y));
 
   // Initialize device memory
-  checkCudaErrors(hipMemcpy2DToArray(
+  HIPCHECK(hipMemcpy2DToArray(
       heightFieldArray, 0, 0, heightField.height, dim.x * sizeof(float),
       dim.x * sizeof(float), dim.y, hipMemcpyHostToDevice));
 
@@ -175,7 +175,7 @@ int runTest(int argc, char **argv) {
   texDescr.addressMode[1] = hipAddressModeClamp;
   texDescr.readMode = hipReadModeElementType;
 
-  checkCudaErrors(
+  HIPCHECK(
       hipCreateTextureObject(&heightFieldTex, &texRes, &texDescr, NULL));
 
   //////////////////////////////////////////////////////////////////////////////
@@ -256,7 +256,7 @@ int runTest(int argc, char **argv) {
   sdkResetTimer(&timer);
 
   // Cleanup memory
-  checkCudaErrors(hipFreeArray(heightFieldArray));
+  HIPCHECK(hipFreeArray(heightFieldArray));
   return res;
 }
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2017.vcxproj
index 771da18..14b93fa 100755
--- a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/lineOfSight.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2019.vcxproj
index afaa202..e2dc1bf 100755
--- a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/lineOfSight.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2022.vcxproj
index 7b629e5..2b15511 100755
--- a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/lineOfSight.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/Makefile b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/Makefile
index 1481877..dc4bc8d 100755
--- a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/NsightEclipse.xml
index d2197f2..8c19d35 100755
--- a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/NsightEclipse.xml
@@ -44,6 +44,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/README.md b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/README.md
index b3bab74..a5d6835 100755
--- a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/README.md
@@ -10,7 +10,7 @@ CUDA Runtime API, Performance Strategies, Linear Algebra, CUBLAS
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMemcpy, cudaFree, cudaEventSynchronize, cudaEventRecord, cudaMalloc, cudaEve
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2017.vcxproj
index e3abd4f..7cf90b0 100755
--- a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/matrixMulCUBLAS.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2019.vcxproj
index 603454e..1665d0f 100755
--- a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/matrixMulCUBLAS.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2022.vcxproj
index e79591b..e9257bf 100755
--- a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/matrixMulCUBLAS.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/NsightEclipse.xml
index 3875c29..baba3f9 100755
--- a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/NsightEclipse.xml
@@ -45,6 +45,20 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:JPEG Decoding</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/README.md b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/README.md
index d860396..a54a46c 100755
--- a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/README.md
@@ -10,6 +10,8 @@ Image Decoding, NVJPEG Library
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux, Windows, QNX
@@ -28,7 +30,7 @@ cudaHostAlloc, cudaStreamCreateWithFlags, cudaStreamDestroy, cudaFree, cudaEvent
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2017.vcxproj
index f360ac2..c5931b6 100755
--- a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2019.vcxproj
index 2d87c91..05906af 100755
--- a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2022.vcxproj
index 5cadf52..f861ff4 100755
--- a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/NsightEclipse.xml
index 6436c0b..fa59430 100755
--- a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/NsightEclipse.xml
@@ -42,6 +42,20 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>4:JPEG Encoding</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/README.md b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/README.md
index 7412d92..09e2227 100755
--- a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/README.md
@@ -10,6 +10,8 @@ Image Encoding, NVJPEG Library
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux, Windows, QNX
@@ -28,7 +30,7 @@ cudaFree, cudaGetErrorString, cudaEventSynchronize, cudaDeviceSynchronize, cudaE
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2017.vcxproj
index 77584a7..22a0937 100755
--- a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2019.vcxproj
index 9ec79b1..4e23250 100755
--- a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2022.vcxproj
index 68f69d5..735c989 100755
--- a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/Makefile b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/Makefile
index 3715f6b..eaa5717 100755
--- a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/NsightEclipse.xml
index d5ca682..8ac28a1 100755
--- a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/NsightEclipse.xml
@@ -72,6 +72,8 @@
     <scope>2:Graphics Interop</scope>
     <scope>3:Physically-Based Simulation</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/README.md b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/README.md
index 4037b2d..00f7aa5 100755
--- a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Image Processing, CUFFT Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaMalloc, cudaFree, cudaGraphicsResour
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_kernel.cu.hip b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_kernel.cu.hip
index e69de29..16d309d 100755
--- a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_kernel.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_kernel.cu.hip
@@ -0,0 +1,160 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+///////////////////////////////////////////////////////////////////////////////
+#include <hipfft.h>
+#include <math_constants.h>
+
+// Round a / b to nearest higher integer value
+int cuda_iDivUp(int a, int b) { return (a + (b - 1)) / b; }
+
+// complex math functions
+__device__ float2 conjugate(float2 arg) { return make_float2(arg.x, -arg.y); }
+
+__device__ float2 complex_exp(float arg) {
+  return make_float2(cosf(arg), sinf(arg));
+}
+
+__device__ float2 complex_add(float2 a, float2 b) {
+  return make_float2(a.x + b.x, a.y + b.y);
+}
+
+__device__ float2 complex_mult(float2 ab, float2 cd) {
+  return make_float2(ab.x * cd.x - ab.y * cd.y, ab.x * cd.y + ab.y * cd.x);
+}
+
+// generate wave heightfield at time t based on initial heightfield and
+// dispersion relationship
+__global__ void generateSpectrumKernel(float2 *h0, float2 *ht,
+                                       unsigned int in_width,
+                                       unsigned int out_width,
+                                       unsigned int out_height, float t,
+                                       float patchSize) {
+  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
+  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
+  unsigned int in_index = y * in_width + x;
+  unsigned int in_mindex =
+      (out_height - y) * in_width + (out_width - x);  // mirrored
+  unsigned int out_index = y * out_width + x;
+
+  // calculate wave vector
+  float2 k;
+  k.x = (-(int)out_width / 2.0f + x) * (2.0f * CUDART_PI_F / patchSize);
+  k.y = (-(int)out_width / 2.0f + y) * (2.0f * CUDART_PI_F / patchSize);
+
+  // calculate dispersion w(k)
+  float k_len = sqrtf(k.x * k.x + k.y * k.y);
+  float w = sqrtf(9.81f * k_len);
+
+  if ((x < out_width) && (y < out_height)) {
+    float2 h0_k = h0[in_index];
+    float2 h0_mk = h0[in_mindex];
+
+    // output frequency-space complex values
+    ht[out_index] =
+        complex_add(complex_mult(h0_k, complex_exp(w * t)),
+                    complex_mult(conjugate(h0_mk), complex_exp(-w * t)));
+    // ht[out_index] = h0_k;
+  }
+}
+
+// update height map values based on output of FFT
+__global__ void updateHeightmapKernel(float *heightMap, float2 *ht,
+                                      unsigned int width) {
+  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
+  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
+  unsigned int i = y * width + x;
+
+  // cos(pi * (m1 + m2))
+  float sign_correction = ((x + y) & 0x01) ? -1.0f : 1.0f;
+
+  heightMap[i] = ht[i].x * sign_correction;
+}
+
+// update height map values based on output of FFT
+__global__ void updateHeightmapKernel_y(float *heightMap, float2 *ht,
+                                        unsigned int width) {
+  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
+  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
+  unsigned int i = y * width + x;
+
+  // cos(pi * (m1 + m2))
+  float sign_correction = ((x + y) & 0x01) ? -1.0f : 1.0f;
+
+  heightMap[i] = ht[i].y * sign_correction;
+}
+
+// generate slope by partial differences in spatial domain
+__global__ void calculateSlopeKernel(float *h, float2 *slopeOut,
+                                     unsigned int width, unsigned int height) {
+  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
+  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
+  unsigned int i = y * width + x;
+
+  float2 slope = make_float2(0.0f, 0.0f);
+
+  if ((x > 0) && (y > 0) && (x < width - 1) && (y < height - 1)) {
+    slope.x = h[i + 1] - h[i - 1];
+    slope.y = h[i + width] - h[i - width];
+  }
+
+  slopeOut[i] = slope;
+}
+
+// wrapper functions
+extern "C" void cudaGenerateSpectrumKernel(float2 *d_h0, float2 *d_ht,
+                                           unsigned int in_width,
+                                           unsigned int out_width,
+                                           unsigned int out_height,
+                                           float animTime, float patchSize) {
+  dim3 block(8, 8, 1);
+  dim3 grid(cuda_iDivUp(out_width, block.x), cuda_iDivUp(out_height, block.y),
+            1);
+  generateSpectrumKernel<<<grid, block>>>(d_h0, d_ht, in_width, out_width,
+                                          out_height, animTime, patchSize);
+}
+
+extern "C" void cudaUpdateHeightmapKernel(float *d_heightMap, float2 *d_ht,
+                                          unsigned int width,
+                                          unsigned int height, bool autoTest) {
+  dim3 block(8, 8, 1);
+  dim3 grid(cuda_iDivUp(width, block.x), cuda_iDivUp(height, block.y), 1);
+  if (autoTest) {
+    updateHeightmapKernel_y<<<grid, block>>>(d_heightMap, d_ht, width);
+  } else {
+    updateHeightmapKernel<<<grid, block>>>(d_heightMap, d_ht, width);
+  }
+}
+
+extern "C" void cudaCalculateSlopeKernel(float *hptr, float2 *slopeOut,
+                                         unsigned int width,
+                                         unsigned int height) {
+  dim3 block(8, 8, 1);
+  dim3 grid2(cuda_iDivUp(width, block.x), cuda_iDivUp(height, block.y), 1);
+  calculateSlopeKernel<<<grid2, block>>>(hptr, slopeOut, width, height);
+}
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2017.vcxproj
index f6b4855..09d8130 100755
--- a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/oceanFFT.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -118,6 +118,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2019.vcxproj
index e121dc0..84a2172 100755
--- a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/oceanFFT.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2022.vcxproj
index eaeb8a0..9a86a33 100755
--- a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/oceanFFT.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/Makefile b/src/samples/Samples/4_CUDA_Libraries/randomFog/Makefile
index a36c55b..97220ec 100755
--- a/src/samples/Samples/4_CUDA_Libraries/randomFog/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/randomFog/Makefile
@@ -309,8 +309,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/randomFog/NsightEclipse.xml
index 24aeb66..467d2ef 100755
--- a/src/samples/Samples/4_CUDA_Libraries/randomFog/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/randomFog/NsightEclipse.xml
@@ -63,6 +63,8 @@
   <scopes>
     <scope>1:CUDA Basic Topics</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/README.md b/src/samples/Samples/4_CUDA_Libraries/randomFog/README.md
index efcd9db..e101b5b 100755
--- a/src/samples/Samples/4_CUDA_Libraries/randomFog/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/randomFog/README.md
@@ -10,7 +10,7 @@ This sample illustrates pseudo- and quasi- random numbers produced by CURAND.
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMalloc, cudaGetErrorString, cudaMemcpy, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2017.vcxproj
index e3b8b81..4e8773d 100755
--- a/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/randomFog.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -118,6 +118,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2019.vcxproj
index 2631374..52ae3ec 100755
--- a/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/randomFog.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2022.vcxproj
index def808a..126ba72 100755
--- a/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/randomFog.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/Makefile b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/Makefile
index 265cbf6..77c0d45 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/Makefile
@@ -287,8 +287,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/NsightEclipse.xml
index 49cf742..47e0657 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/NsightEclipse.xml
@@ -37,6 +37,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/README.md b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/README.md
index fba0329..dbb814b 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/README.md
@@ -10,7 +10,7 @@ Image Processing, CUBLAS Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMalloc, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2017.vcxproj
index 69d1607..181e913 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleCUBLAS.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2019.vcxproj
index 32f4859..f0994fd 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCUBLAS.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2022.vcxproj
index f687b6a..9640014 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCUBLAS.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/Makefile b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/Makefile
index 17861fd..c812e5d 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/Makefile
@@ -295,8 +295,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/NsightEclipse.xml
index 3ce1f4c..47bd44a 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/NsightEclipse.xml
@@ -37,6 +37,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/README.md b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/README.md
index d6d618e..0d8c969 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/README.md
@@ -10,7 +10,7 @@ CUBLAS-XT Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGetDeviceProperties, cudaGetDeviceCount, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2017.vcxproj
index 5c4784d..2970265 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleCUBLASXT.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2019.vcxproj
index 54e654d..32a4ace 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCUBLASXT.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2022.vcxproj
index 8f12098..c900da3 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCUBLASXT.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/Makefile b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/Makefile
index 06cda61..86638c5 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/Makefile
@@ -293,7 +293,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/NsightEclipse.xml
index 6b0b6eb..3dcea4e 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/NsightEclipse.xml
@@ -39,6 +39,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/README.md b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/README.md
index ee1b5af..2b1b93d 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/README.md
@@ -10,7 +10,7 @@ CUBLAS Library, LU decomposition
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGetErrorEnum, cudaMalloc, cudaMemcpy, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2017.vcxproj
index b01ffa5..bffe80d 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleCUBLAS_LU.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2019.vcxproj
index a657ee5..18c1b11 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCUBLAS_LU.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2022.vcxproj
index b07fe1f..2ff5187 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCUBLAS_LU.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/Makefile b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/Makefile
index feeb4a1..080c25d 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/NsightEclipse.xml
index 27e4bf8..6ba60d8 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/NsightEclipse.xml
@@ -36,6 +36,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>2:Image Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/README.md b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/README.md
index 7dc1de7..e91252b 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/README.md
@@ -10,7 +10,7 @@ Image Processing, CUFFT Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMalloc, cudaMemcpy, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2017.vcxproj
index 2d7ee5a..a6e80d8 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleCUFFT.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2019.vcxproj
index e399d82..5eb6489 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCUFFT.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2022.vcxproj
index 1522cb3..2c59837 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCUFFT.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/Makefile b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/Makefile
index 27b7e53..c21a0c6 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/NsightEclipse.xml
index 14553de..a22e53a 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/NsightEclipse.xml
@@ -44,6 +44,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>2:Image Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/README.md b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/README.md
index b2d56d3..9cd1ad5 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/README.md
@@ -10,7 +10,7 @@ Image Processing, CUFFT Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaXtFree, cudaMemcpy, cudaFree, cudaSetDevice, cudaGetDeviceCount, cudaDeviceS
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU.cu.hip b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU.cu.hip
index 2c1c5a5..1662a97 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU.cu.hip
@@ -52,8 +52,8 @@
 #include <hipfftXt.h>
 
 // helper functions and utilities to work with CUDA
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
+#include <helper_functions.h>
+#include <helper_cuda.h>
 
 // Complex data type
 typedef float2 Complex;
@@ -379,6 +379,3 @@ __global__ void solvePoisson(hipfftComplex *ft, hipfftComplex *ft_k, float *k,
     ft_k[index].y = -ft[index].y * 1 / k2;
   }
 }
-x].y * 1 / k2;
-  }
-}
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2017.vcxproj
index fab1df7..836ea06 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleCUFFT_2d_MGPU.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2019.vcxproj
index 3c0884a..86780b7 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCUFFT_2d_MGPU.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2022.vcxproj
index 8cd79e3..6e6b95b 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCUFFT_2d_MGPU.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/Makefile b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/Makefile
index 940706b..94cb18d 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/NsightEclipse.xml
index 4b5ff6c..f7274f8 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/NsightEclipse.xml
@@ -38,6 +38,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>2:Image Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/README.md b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/README.md
index 78d2930..bfb6e03 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/README.md
@@ -10,7 +10,7 @@ Image Processing, CUFFT Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaXtFree, cudaSetDevice, cudaGetDeviceCount, cudaDeviceSynchronize, cudaGetDev
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU.cu.hip b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU.cu.hip
index 9311d9e..8738cb3 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU.cu.hip
@@ -42,8 +42,8 @@
 #include <hipfftXt.h>
 
 // helper functions and utilities to work with CUDA
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
+#include <helper_functions.h>
+#include <helper_cuda.h>
 
 // Complex data type
 typedef float2 Complex;
@@ -153,7 +153,7 @@ int main(int argc, char **argv) {
   // hipfftCreate() - Create an empty plan
   hipfftResult result;
   hipfftHandle plan_input;
-  HIPCHECK(hipfftCreate(&plan_input));
+  checkCudaErrors(hipfftCreate(&plan_input));
 
   // cufftXtSetGPUs() - Define which GPUs to use
   result = cufftXtSetGPUs(plan_input, nGPUs, whichGPUs);
@@ -180,41 +180,41 @@ int main(int argc, char **argv) {
   worksize = (size_t *)malloc(sizeof(size_t) * nGPUs);
 
   // hipfftMakePlan1d() - Create the plan
-  HIPCHECK(
+  checkCudaErrors(
       hipfftMakePlan1d(plan_input, new_size, HIPFFT_C2C, 1, worksize));
 
   // cufftXtMalloc() - Malloc data on multiple GPUs
   cudaLibXtDesc *d_signal;
-  HIPCHECK(cufftXtMalloc(plan_input, (cudaLibXtDesc **)&d_signal,
+  checkCudaErrors(cufftXtMalloc(plan_input, (cudaLibXtDesc **)&d_signal,
                                 CUFFT_XT_FORMAT_INPLACE));
   cudaLibXtDesc *d_out_signal;
-  HIPCHECK(cufftXtMalloc(plan_input, (cudaLibXtDesc **)&d_out_signal,
+  checkCudaErrors(cufftXtMalloc(plan_input, (cudaLibXtDesc **)&d_out_signal,
                                 CUFFT_XT_FORMAT_INPLACE));
   cudaLibXtDesc *d_filter_kernel;
-  HIPCHECK(cufftXtMalloc(plan_input, (cudaLibXtDesc **)&d_filter_kernel,
+  checkCudaErrors(cufftXtMalloc(plan_input, (cudaLibXtDesc **)&d_filter_kernel,
                                 CUFFT_XT_FORMAT_INPLACE));
   cudaLibXtDesc *d_out_filter_kernel;
-  HIPCHECK(cufftXtMalloc(plan_input,
+  checkCudaErrors(cufftXtMalloc(plan_input,
                                 (cudaLibXtDesc **)&d_out_filter_kernel,
                                 CUFFT_XT_FORMAT_INPLACE));
 
   // cufftXtMemcpy() - Copy data from host to multiple GPUs
-  HIPCHECK(cufftXtMemcpy(plan_input, d_signal, h_padded_signal,
+  checkCudaErrors(cufftXtMemcpy(plan_input, d_signal, h_padded_signal,
                                 CUFFT_COPY_HOST_TO_DEVICE));
-  HIPCHECK(cufftXtMemcpy(plan_input, d_filter_kernel,
+  checkCudaErrors(cufftXtMemcpy(plan_input, d_filter_kernel,
                                 h_padded_filter_kernel,
                                 CUFFT_COPY_HOST_TO_DEVICE));
 
   // cufftXtExecDescriptorC2C() - Execute FFT on data on multiple GPUs
-  HIPCHECK(
+  checkCudaErrors(
       cufftXtExecDescriptorC2C(plan_input, d_signal, d_signal, HIPFFT_FORWARD));
-  HIPCHECK(cufftXtExecDescriptorC2C(plan_input, d_filter_kernel,
+  checkCudaErrors(cufftXtExecDescriptorC2C(plan_input, d_filter_kernel,
                                            d_filter_kernel, HIPFFT_FORWARD));
 
   // cufftXtMemcpy() - Copy the data to natural order on GPUs
-  HIPCHECK(cufftXtMemcpy(plan_input, d_out_signal, d_signal,
+  checkCudaErrors(cufftXtMemcpy(plan_input, d_out_signal, d_signal,
                                 CUFFT_COPY_DEVICE_TO_DEVICE));
-  HIPCHECK(cufftXtMemcpy(plan_input, d_out_filter_kernel,
+  checkCudaErrors(cufftXtMemcpy(plan_input, d_out_filter_kernel,
                                 d_filter_kernel, CUFFT_COPY_DEVICE_TO_DEVICE));
 
   printf("\n\nValue of Library Descriptor\n");
@@ -232,7 +232,7 @@ int main(int argc, char **argv) {
 
   // cufftXtExecDescriptorC2C() - Execute inverse  FFT on data on multiple GPUs
   printf("Transforming signal back hipfftExecC2C\n");
-  HIPCHECK(cufftXtExecDescriptorC2C(plan_input, d_out_signal,
+  checkCudaErrors(cufftXtExecDescriptorC2C(plan_input, d_out_signal,
                                            d_out_signal, HIPFFT_BACKWARD));
 
   // Create host pointer pointing to padded signal
@@ -266,13 +266,13 @@ int main(int argc, char **argv) {
   free(h_convolved_signal_ref);
 
   // cudaXtFree() - Free GPU memory
-  HIPCHECK(cufftXtFree(d_signal));
-  HIPCHECK(cufftXtFree(d_filter_kernel));
-  HIPCHECK(cufftXtFree(d_out_signal));
-  HIPCHECK(cufftXtFree(d_out_filter_kernel));
+  checkCudaErrors(cufftXtFree(d_signal));
+  checkCudaErrors(cufftXtFree(d_filter_kernel));
+  checkCudaErrors(cufftXtFree(d_out_signal));
+  checkCudaErrors(cufftXtFree(d_out_filter_kernel));
 
   // hipfftDestroy() - Destroy FFT plan
-  HIPCHECK(hipfftDestroy(plan_input));
+  checkCudaErrors(hipfftDestroy(plan_input));
 
   exit(bTestResult ? EXIT_SUCCESS : EXIT_FAILURE);
 }
@@ -399,8 +399,3 @@ static __global__ void ComplexPointwiseMulAndScale(hipfftComplex *a,
     a[i] = ComplexScale(ComplexMul(a[i], b[i]), scale);
   }
 }
-t threadID = blockIdx.x * blockDim.x + threadIdx.x;
-  for (int i = threadID; i < size; i += numThreads) {
-    a[i] = ComplexScale(ComplexMul(a[i], b[i]), scale);
-  }
-}
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2017.vcxproj
index ae5996e..c9da791 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleCUFFT_MGPU.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2019.vcxproj
index 14d3e0c..694fc4f 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCUFFT_MGPU.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2022.vcxproj
index 1cfda8b..a2f9ad9 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleCUFFT_MGPU.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/Makefile b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/Makefile
index f3d21a9..c5159be 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/Makefile
@@ -318,7 +318,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 70 72 75 80 86 87 90
 else
-SMS ?= 50 60 70 75 80 86 90
+SMS ?= 35 50 60 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/NsightEclipse.xml
index 81e8257..eaa551e 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/NsightEclipse.xml
@@ -49,6 +49,7 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>2:Image Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm53</sm-arch>
   <sm-arch>sm60</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/README.md b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/README.md
index 97c4320..71cd8ad 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/README.md
@@ -10,7 +10,7 @@ Image Processing, CUFFT Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMemcpy, cudaFree, cudaMemcpyFromSymbol, cudaGetDevice, cudaMalloc, cudaGetDe
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/simpleCUFFT_callback.cu.hip b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/simpleCUFFT_callback.cu.hip
index 85e1c9c..02c3077 100755
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/simpleCUFFT_callback.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/simpleCUFFT_callback.cu.hip
@@ -37,6 +37,8 @@
 // includes, system
 #include <stdlib.h>
 #include <stdio.h>
+#include "rocprofiler.h"
+#include "HIPCHECK.h"
 #include <string.h>
 #include <math.h>
 
@@ -188,7 +190,7 @@ int runTest(int argc, char **argv) {
   // The host needs to get a copy of the device pointer to the callback
   hipfftCallbackLoadC hostCopyOfCallbackPtr;
 
-  HIPCHECK(hipMemcpyFromSymbol(&hostCopyOfCallbackPtr, HIP_SYMBOL(myOwnCallbackPtr),
+  HIP_SYMBOL(myOwnCallbackPtr)(hipMemcpyFromSymbol(&hostCopyOfCallbackPtr, myOwnCallbackPtr,
                                        sizeof(hostCopyOfCallbackPtr)));
 
   // Now associate the load callback with the plan.
@@ -206,7 +208,7 @@ int runTest(int argc, char **argv) {
                                      HIPFFT_CB_LD_COMPLEX, (void **)&d_params));
 
   // Transform signal and kernel
-  printf("Transforming signal hipfftExecC2C\n");
+  printf("Transforming signal cufftExecC2C\n");
   HIPCHECK(hipfftExecC2C(plan, (hipfftComplex *)d_signal,
                                (hipfftComplex *)d_signal, HIPFFT_FORWARD));
   HIPCHECK(hipfftExecC2C(plan, (hipfftComplex *)d_filter_kernel,
@@ -214,7 +216,7 @@ int runTest(int argc, char **argv) {
 
   // Transform signal back, using the callback to do the pointwise multiply on
   // the way in.
-  printf("Transforming signal back hipfftExecC2C\n");
+  printf("Transforming signal back cufftExecC2C\n");
   HIPCHECK(hipfftExecC2C(cb_plan, (hipfftComplex *)d_signal,
                                (hipfftComplex *)d_signal, HIPFFT_BACKWARD));
 
@@ -334,7 +336,7 @@ static __device__ __host__ inline Complex ComplexMul(Complex a, Complex b) {
   c.y = a.x * b.y + a.y * b.x;
   return c;
 }
-c __device__ __host__ inline Complex ComplexMul(Complex a, Complex b) {
+ice__ __host__ inline Complex ComplexMul(Complex a, Complex b) {
   Complex c;
   c.x = a.x * b.x - a.y * b.y;
   c.y = a.x * b.y + a.y * b.x;
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/Makefile b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/Makefile
index 388c59b..57b0890 100755
--- a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/Makefile
+++ b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/Makefile
@@ -301,8 +301,8 @@ ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 # Generate PTX code from SM 53
 GENCODE_FLAGS += -gencode arch=compute_53,code=compute_53
 else
-# Generate PTX code from SM 50
-GENCODE_FLAGS += -gencode arch=compute_50,code=compute_50
+# Generate PTX code from SM 35
+GENCODE_FLAGS += -gencode arch=compute_35,code=compute_35
 endif
 endif
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/NsightEclipse.xml
index b0699ca..b16c392 100755
--- a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/NsightEclipse.xml
+++ b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/NsightEclipse.xml
@@ -49,6 +49,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/README.md b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/README.md
index 90aafdb..540e744 100755
--- a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/README.md
+++ b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/README.md
@@ -10,7 +10,7 @@ Performance Strategies, Image Processing, NPP Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaRuntimeGetVersion, cudaFree, cudaDeviceGetAttribute, cudaDriverGetVersion, c
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2017.vcxproj
index 9f33373..c752f13 100755
--- a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2017.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/watershedSegmentationNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2019.vcxproj
index 2d326ca..10f8fef 100755
--- a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2019.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/watershedSegmentationNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2022.vcxproj
index 2e259b1..d960f01 100755
--- a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2022.vcxproj
+++ b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/watershedSegmentationNPP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,compute_50;</CodeGeneration>
+      <CodeGeneration>compute_35,compute_35;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.cu.hip b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.cu.hip
index f145c7c..56e4423 100755
--- a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.cu.hip
@@ -31,9 +31,11 @@
  * See supplied whitepaper for more explanations.
  */
 
-#include <helper_functions.h>  // helper functions for string parsing
-#include <helper_cuda.h>  // helper functions CUDA error checking and initialization
 
+#include <hip/hip_runtime.h>
+#include "helper_functions.h"  // helper functions for string parsing
+#include "helper_cuda_hipified.h"  // helper functions CUDA error checking and initialization
+#include "HIPCHECK.h"
 ////////////////////////////////////////////////////////////////////////////////
 // Process an array of optN options on CPU
 ////////////////////////////////////////////////////////////////////////////////
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.out b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.out
index 4e671c1..6bc19ef 100755
Binary files a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.out and b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.out differ
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2017.vcxproj
index d05abc0..c63b2d7 100755
--- a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/BlackScholes.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2019.vcxproj
index b23a8c7..adf0db2 100755
--- a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/BlackScholes.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2022.vcxproj
index cf1222e..aa30ade 100755
--- a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/BlackScholes.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/Makefile b/src/samples/Samples/5_Domain_Specific/BlackScholes/Makefile
index cdf5aec..7935e54 100755
--- a/src/samples/Samples/5_Domain_Specific/BlackScholes/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/BlackScholes/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/BlackScholes/NsightEclipse.xml
index e7bd616..8af9aa6 100755
--- a/src/samples/Samples/5_Domain_Specific/BlackScholes/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/BlackScholes/NsightEclipse.xml
@@ -37,6 +37,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>3:Computational Finance</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/README.md b/src/samples/Samples/5_Domain_Specific/BlackScholes/README.md
index 499f492..2d53549 100755
--- a/src/samples/Samples/5_Domain_Specific/BlackScholes/README.md
+++ b/src/samples/Samples/5_Domain_Specific/BlackScholes/README.md
@@ -10,7 +10,7 @@ Computational Finance
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMalloc, cudaDeviceSynchronize, cudaMemcpy, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2017.vcxproj
index 8ec616b..0432f89 100755
--- a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2019.vcxproj
index a53d6f6..c97e0a3 100755
--- a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2022.vcxproj
index 789bf63..3796da0 100755
--- a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/README.md b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/README.md
index 0dc2ae4..a0e4aa6 100755
--- a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/README.md
+++ b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/README.md
@@ -10,7 +10,7 @@ Computational Finance, Runtime Compilation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaBlockSize, cudaGridSize
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2017.vcxproj
index d5d41b9..09368fc 100755
--- a/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/FDTD3d.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -112,6 +112,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2019.vcxproj
index b28538c..09c3400 100755
--- a/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/FDTD3d.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2022.vcxproj
index 70c1b71..6af53b8 100755
--- a/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/FDTD3d.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/Makefile b/src/samples/Samples/5_Domain_Specific/FDTD3d/Makefile
index 7e83643..bbbee3e 100755
--- a/src/samples/Samples/5_Domain_Specific/FDTD3d/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/FDTD3d/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/FDTD3d/NsightEclipse.xml
index a6e2ffa..7528550 100755
--- a/src/samples/Samples/5_Domain_Specific/FDTD3d/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/FDTD3d/NsightEclipse.xml
@@ -47,6 +47,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/README.md b/src/samples/Samples/5_Domain_Specific/FDTD3d/README.md
index bb19e8f..8077439 100755
--- a/src/samples/Samples/5_Domain_Specific/FDTD3d/README.md
+++ b/src/samples/Samples/5_Domain_Specific/FDTD3d/README.md
@@ -10,7 +10,7 @@ Performance Strategies
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaMalloc, cudaFree, cudaFuncGetAttributes, cudaSetDevice, cudaGetD
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow.out b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow.out
index cffdd4e..84ef648 100755
Binary files a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow.out and b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow.out differ
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Makefile b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Makefile
index 83d9fef..777aa73 100755
--- a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2017.vcxproj
index bb44fa9..4d84050 100755
--- a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/Mandelbrot.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -121,6 +121,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2019.vcxproj
index 666ee45..f577458 100755
--- a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/Mandelbrot.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -117,6 +117,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2022.vcxproj
index 06e7d9f..ce2b958 100755
--- a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/Mandelbrot.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -117,6 +117,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/Mandelbrot/NsightEclipse.xml
index 6db61e6..d74f3c4 100755
--- a/src/samples/Samples/5_Domain_Specific/Mandelbrot/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/Mandelbrot/NsightEclipse.xml
@@ -66,6 +66,8 @@
     <scope>2:Graphics Interop</scope>
     <scope>1:Data-Parallel Algorithms</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/README.md b/src/samples/Samples/5_Domain_Specific/Mandelbrot/README.md
index ed8ac47..a09cfee 100755
--- a/src/samples/Samples/5_Domain_Specific/Mandelbrot/README.md
+++ b/src/samples/Samples/5_Domain_Specific/Mandelbrot/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Data Parallel Algorithms
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGLUnmapBufferObject, cudaGraphicsUnmapResources, cudaMemcpy, cudaFree, cudaG
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/Makefile b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/Makefile
index fcd9f3a..c38f7e4 100755
--- a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2017.vcxproj
index 435bb82..3330def 100755
--- a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/MonteCarloMultiGPU.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2019.vcxproj
index 9454fdd..cf2d4ad 100755
--- a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/MonteCarloMultiGPU.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2022.vcxproj
index 63958c7..852394d 100755
--- a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/MonteCarloMultiGPU.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/NsightEclipse.xml
index 2de99af..bbe5593 100755
--- a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/NsightEclipse.xml
@@ -56,6 +56,8 @@
     <scope>1:Performance Strategies</scope>
     <scope>3:Computational Finance</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/README.md b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/README.md
index 9e73134..5eff98b 100755
--- a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/README.md
+++ b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/README.md
@@ -10,7 +10,7 @@ Random Number Generator, Computational Finance, CURAND Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaStreamDestroy, cudaMalloc, cudaFree, cudaMallocHost, cudaSetDevice, cudaEven
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/Makefile b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/Makefile
index b96ab74..f0ea1f7 100755
--- a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/Makefile
@@ -287,7 +287,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize.out b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize.out
index 9ccd139..8e94314 100755
Binary files a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize.out and b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize.out differ
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2017.vcxproj
index da890b7..845bded 100755
--- a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/NV12toBGRandResize.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -112,6 +112,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2019.vcxproj
index 099f58d..88c92e3 100755
--- a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/NV12toBGRandResize.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2022.vcxproj
index 0218e8f..09b89f9 100755
--- a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/NV12toBGRandResize.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NsightEclipse.xml
index 6b79327..cec2830 100755
--- a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NsightEclipse.xml
@@ -45,6 +45,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/README.md b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/README.md
index 14ed257..f789991 100755
--- a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/README.md
+++ b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Image Processing, Video Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaStreamDestroy, cudaMalloc, cudaFree, cudaMallocManaged, cudaStre
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/bgr_resize.cu.hip b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/bgr_resize.cu.hip
index a9d852c..62d0b6c 100755
--- a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/bgr_resize.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/bgr_resize.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -30,6 +29,7 @@
 // Implements BGR 3 progressive planars frames batch resize
 
 #include <hip/hip_runtime.h>
+
 #include "resize_convert_hipified.h"
 #include "HIPCHECK.h"
 __global__ void resizeBGRplanarBatchKernel(hipTextureObject_t texSrc,
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_resize.cu.hip b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_resize.cu.hip
index 05e5e91..c8e1400 100755
--- a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_resize.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_resize.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -29,6 +28,7 @@
 // Implements interlace NV12 frames batch resize
 
 #include <hip/hip_runtime.h>
+
 #include "resize_convert_hipified.h"
 #include "HIPCHECK.h"
 __global__ static void resizeNV12BatchKernel(hipTextureObject_t texSrcLuma,
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_to_bgr_planar.cu.hip b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_to_bgr_planar.cu.hip
index d64fbb4..4c21035 100755
--- a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_to_bgr_planar.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_to_bgr_planar.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -30,7 +29,7 @@
 // Implements NV12 to BGR batch conversion
 
 #include <hip/hip_runtime.h>
-#include <hip/hip_runtime.h>
+
 
 #include "resize_convert_hipified.h"
 
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/utils.cu.hip b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/utils.cu.hip
index a8ec643..4365271 100755
--- a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/utils.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/utils.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -31,12 +30,12 @@
 #include <sys/types.h>
 #include <fstream>
 #include <iostream>
-
-#include <hip/hip_runtime.h>
-#include <hip/hip_runtime.h>
 #include "HIPCHECK.h"
+#include <hip/hip_runtime.h>
+
+
 #include "resize_convert_hipified.h"
-#include "utils.h"
+#include "utils_hipified.h"
 
 __global__ void floatToChar(float *src, unsigned char *dst, int height,
                             int width, int batchSize) {
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/README.md b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/README.md
index c0f65dc..ddd18f0 100755
--- a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/README.md
+++ b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/README.md
@@ -10,7 +10,7 @@ Performance Strategies, Graphics Interop, Image Processing, 2D Textures
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaGraphicsUnmapResources, cudaMalloc, cudaMallocPitch, cudaGetErrorString, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2017.vcxproj
index 2457404..3b3d82c 100755
--- a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/SLID3D10Texture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2019.vcxproj
index d21332c..96c3165 100755
--- a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/SLID3D10Texture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2022.vcxproj
index 7f3837c..e26cc9a 100755
--- a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/SLID3D10Texture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/Makefile b/src/samples/Samples/5_Domain_Specific/SobelFilter/Makefile
index f7db836..16893f8 100755
--- a/src/samples/Samples/5_Domain_Specific/SobelFilter/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/SobelFilter/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/SobelFilter/NsightEclipse.xml
index 8eb4e42..1409139 100755
--- a/src/samples/Samples/5_Domain_Specific/SobelFilter/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/SobelFilter/NsightEclipse.xml
@@ -76,6 +76,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/README.md b/src/samples/Samples/5_Domain_Specific/SobelFilter/README.md
index 70addd4..f33e8df 100755
--- a/src/samples/Samples/5_Domain_Specific/SobelFilter/README.md
+++ b/src/samples/Samples/5_Domain_Specific/SobelFilter/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Image Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaMallocArray, cudaFreeArray, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_kernels.cu.hip b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_kernels.cu.hip
index 1a9e3b2..b0fcd54 100755
--- a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_kernels.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_kernels.cu.hip
@@ -295,10 +295,3 @@ extern "C" void sobelFilter(Pixel *odata, int iw, int ih,
     } break;
   }
 }
-         iw, ih, fScale, texObject);
-    } break;
-  }
-}
-         iw, ih, fScale, texObject);
-    } break;
-  }
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2017.vcxproj
index e9ef87f..bb26dfe 100755
--- a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/SobelFilter.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -118,6 +118,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2019.vcxproj
index eb4827f..8dcd7a8 100755
--- a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/SobelFilter.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2022.vcxproj
index e267380..d9f50ec 100755
--- a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/SobelFilter.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/Makefile b/src/samples/Samples/5_Domain_Specific/SobolQRNG/Makefile
index 70f0e3f..7d80c57 100755
--- a/src/samples/Samples/5_Domain_Specific/SobolQRNG/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/SobolQRNG/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/SobolQRNG/NsightEclipse.xml
index 1b9931c..cddf025 100755
--- a/src/samples/Samples/5_Domain_Specific/SobolQRNG/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/SobolQRNG/NsightEclipse.xml
@@ -37,6 +37,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>3:Computational Finance</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/README.md b/src/samples/Samples/5_Domain_Specific/SobolQRNG/README.md
index 5ab13c5..72bb3f8 100755
--- a/src/samples/Samples/5_Domain_Specific/SobolQRNG/README.md
+++ b/src/samples/Samples/5_Domain_Specific/SobolQRNG/README.md
@@ -10,7 +10,7 @@ Computational Finance
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaGetErrorString, cudaFree, cudaDeviceSynchronize, cudaGetDevice,
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG.out b/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG.out
index c0832b9..6621ed0 100755
Binary files a/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG.out and b/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG.out differ
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2017.vcxproj
index 85d69e4..2dc8daa 100755
--- a/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/SobolQRNG.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2019.vcxproj
index 6d02841..1f74108 100755
--- a/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/SobolQRNG.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2022.vcxproj
index ae0e92e..d54706b 100755
--- a/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/SobolQRNG.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gpu.cu.hip b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gpu.cu.hip
index e09b0e8..637f572 100755
--- a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gpu.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gpu.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -55,12 +54,14 @@
  *
  */
 
+
+#include <hip/hip_runtime.h>
 #include "sobol.h"
 #include "sobol_gpu.h"
 #include <hip/hip_cooperative_groups.h>
-
+#include "HIPCHECK.h"
 namespace cg = cooperative_groups;
-#include "helper_cuda_hipified.h"
+#include <helper_cuda.h>
 
 #define k_2powneg32 2.3283064E-10F
 
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/README.md b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/README.md
index 7ed2370..613b566 100755
--- a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/README.md
+++ b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Data Parallel Algorithms, Physically-Based Simulation, Perform
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaFree, cudaGetErrorString, cudaGraphi
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2017.vcxproj
index 26383b3..7744ff2 100755
--- a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/VFlockingD3D10.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -110,6 +110,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2019.vcxproj
index 9a9a766..3c776cc 100755
--- a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/VFlockingD3D10.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -106,6 +106,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2022.vcxproj
index b412c68..65635ec 100755
--- a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/VFlockingD3D10.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -106,6 +106,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/Makefile b/src/samples/Samples/5_Domain_Specific/bicubicTexture/Makefile
index 45b7871..cc6c268 100755
--- a/src/samples/Samples/5_Domain_Specific/bicubicTexture/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/bicubicTexture/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/bicubicTexture/NsightEclipse.xml
index d709aa5..bb42ff8 100755
--- a/src/samples/Samples/5_Domain_Specific/bicubicTexture/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/bicubicTexture/NsightEclipse.xml
@@ -73,6 +73,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/README.md b/src/samples/Samples/5_Domain_Specific/bicubicTexture/README.md
index 77d407d..c972ebd 100755
--- a/src/samples/Samples/5_Domain_Specific/bicubicTexture/README.md
+++ b/src/samples/Samples/5_Domain_Specific/bicubicTexture/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Image Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaCreateChannelDesc, cudaMallocArray, cudaFreeArra
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2017.vcxproj
index 9a373bc..11e527b 100755
--- a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/bicubicTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -118,6 +118,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2019.vcxproj
index c9ad6e7..dbb64ab 100755
--- a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/bicubicTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2022.vcxproj
index 6319b99..a54bf6b 100755
--- a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/bicubicTexture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/Makefile b/src/samples/Samples/5_Domain_Specific/bilateralFilter/Makefile
index 1fa49e2..2a4ee06 100755
--- a/src/samples/Samples/5_Domain_Specific/bilateralFilter/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/bilateralFilter/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/bilateralFilter/NsightEclipse.xml
index 4df7493..b9e13ff 100755
--- a/src/samples/Samples/5_Domain_Specific/bilateralFilter/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/bilateralFilter/NsightEclipse.xml
@@ -73,6 +73,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/README.md b/src/samples/Samples/5_Domain_Specific/bilateralFilter/README.md
index a28f747..b31f086 100755
--- a/src/samples/Samples/5_Domain_Specific/bilateralFilter/README.md
+++ b/src/samples/Samples/5_Domain_Specific/bilateralFilter/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Image Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaRuntimeGetVersion, cudaGraphicsUnmapResources, cudaMallocPitch, cudaFree, cu
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2017.vcxproj
index 8af1e7e..66d5cb1 100755
--- a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/bilateralFilter.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -120,6 +120,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2019.vcxproj
index 8f00b67..9081621 100755
--- a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/bilateralFilter.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -116,6 +116,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2022.vcxproj
index 50464d5..8f7f94a 100755
--- a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/bilateralFilter.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -116,6 +116,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/Makefile b/src/samples/Samples/5_Domain_Specific/binomialOptions/Makefile
index 34c301a..7d498db 100755
--- a/src/samples/Samples/5_Domain_Specific/binomialOptions/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/binomialOptions/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/binomialOptions/NsightEclipse.xml
index 08ff82b..f5273e4 100755
--- a/src/samples/Samples/5_Domain_Specific/binomialOptions/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/binomialOptions/NsightEclipse.xml
@@ -33,6 +33,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>3:Computational Finance</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/README.md b/src/samples/Samples/5_Domain_Specific/binomialOptions/README.md
index 7a0dff2..574d7e1 100755
--- a/src/samples/Samples/5_Domain_Specific/binomialOptions/README.md
+++ b/src/samples/Samples/5_Domain_Specific/binomialOptions/README.md
@@ -10,7 +10,7 @@ Computational Finance
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaDeviceSynchronize, cudaMemcpyToSymbol, cudaMemcpyFromSymbol
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions.out b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions.out
index ef6fb2b..11e5304 100755
Binary files a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions.out and b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions.out differ
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2017.vcxproj
index e3fd0a8..8416e03 100755
--- a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/binomialOptions.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -110,6 +110,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2019.vcxproj
index 1d911f2..806fed7 100755
--- a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/binomialOptions.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -106,6 +106,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2022.vcxproj
index 352a85a..616a1dc 100755
--- a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/binomialOptions.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -106,6 +106,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/README.md b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/README.md
index 27ae16c..0d96c7e 100755
--- a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/README.md
+++ b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/README.md
@@ -10,7 +10,7 @@ Computational Finance, Runtime Compilation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaBlockSize, cudaGridSize
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_kernel.cu.hip
index e69de29..24fd6b5 100755
--- a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_kernel.cu.hip
@@ -0,0 +1,108 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "common_gpu_header.h"
+#include "binomialOptions_common.h"
+#include "realtype.h"
+
+// Preprocessed input option data
+typedef struct {
+  real S;
+  real X;
+  real vDt;
+  real puByDf;
+  real pdByDf;
+} __TOptionData;
+static __constant__ __TOptionData d_OptionData[MAX_OPTIONS];
+__device__ real d_CallValue[MAX_OPTIONS];
+
+#define THREADBLOCK_SIZE 128
+#define ELEMS_PER_THREAD (NUM_STEPS / THREADBLOCK_SIZE)
+#if NUM_STEPS % THREADBLOCK_SIZE
+#error Bad constants
+#endif
+
+////////////////////////////////////////////////////////////////////////////////
+// Overloaded shortcut functions for different precision modes
+////////////////////////////////////////////////////////////////////////////////
+
+#ifndef DOUBLE_PRECISION
+__device__ inline float expiryCallValue(float S, float X, float vDt, int i) {
+  float d = S * __expf(vDt * (2.0f * i - NUM_STEPS)) - X;
+  return (d > 0.0F) ? d : 0.0F;
+}
+
+#else
+__device__ inline double expiryCallValue(double S, double X, double vDt,
+                                         int i) {
+  double d = S * exp(vDt * (2.0 * i - NUM_STEPS)) - X;
+  return (d > 0.0) ? d : 0.0;
+}
+#endif
+
+////////////////////////////////////////////////////////////////////////////////
+// GPU kernel
+////////////////////////////////////////////////////////////////////////////////
+extern "C" __global__ void binomialOptionsKernel() {
+  __shared__ real call_exchange[THREADBLOCK_SIZE + 1];
+
+  const int tid = threadIdx.x;
+  const real S = d_OptionData[blockIdx.x].S;
+  const real X = d_OptionData[blockIdx.x].X;
+  const real vDt = d_OptionData[blockIdx.x].vDt;
+  const real puByDf = d_OptionData[blockIdx.x].puByDf;
+  const real pdByDf = d_OptionData[blockIdx.x].pdByDf;
+
+  real call[ELEMS_PER_THREAD + 1];
+#pragma unroll
+  for (int i = 0; i < ELEMS_PER_THREAD; ++i)
+    call[i] = expiryCallValue(S, X, vDt, tid * ELEMS_PER_THREAD + i);
+
+  if (tid == 0)
+    call_exchange[THREADBLOCK_SIZE] = expiryCallValue(S, X, vDt, NUM_STEPS);
+
+  int final_it = max(0, tid * ELEMS_PER_THREAD - 1);
+
+#pragma unroll 16
+  for (int i = NUM_STEPS; i > 0; --i) {
+    call_exchange[tid] = call[0];
+    __syncthreads();
+    call[ELEMS_PER_THREAD] = call_exchange[tid + 1];
+    __syncthreads();
+
+    if (i > final_it) {
+#pragma unroll
+      for (int j = 0; j < ELEMS_PER_THREAD; ++j)
+        call[j] = puByDf * call[j + 1] + pdByDf * call[j];
+    }
+  }
+
+  if (tid == 0) {
+    d_CallValue[blockIdx.x] = call[0];
+  }
+}
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2017.vcxproj
index b1b2d99..4e02094 100755
--- a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -112,6 +112,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2019.vcxproj
index d9aa62b..153e2b1 100755
--- a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2022.vcxproj
index 16ff472..d2720c0 100755
--- a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/Makefile b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/Makefile
index 29de20a..0528320 100755
--- a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/NsightEclipse.xml
index cde834f..f813405 100755
--- a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/NsightEclipse.xml
@@ -45,6 +45,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/README.md b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/README.md
index 0921213..0f8d519 100755
--- a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/README.md
+++ b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/README.md
@@ -10,7 +10,7 @@ Image Processing, CUFFT Library
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMemcpy, cudaFree, cudaDestroyTextureObject, cudaDeviceSynchronize, cudaCreat
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D.cu.hip b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D.cu.hip
index e69de29..62c8fe6 100755
--- a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D.cu.hip
@@ -0,0 +1,319 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <assert.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <helper_cuda.h>
+#include "convolutionFFT2D_common_hipified.h"
+#include "convolutionFFT2D_hipified.cuh"
+
+////////////////////////////////////////////////////////////////////////////////
+/// Position convolution kernel center at (0, 0) in the image
+////////////////////////////////////////////////////////////////////////////////
+extern "C" void padKernel(float *d_Dst, float *d_Src, int fftH, int fftW,
+                          int kernelH, int kernelW, int kernelY, int kernelX) {
+  assert(d_Src != d_Dst);
+  dim3 threads(32, 8);
+  dim3 grid(iDivUp(kernelW, threads.x), iDivUp(kernelH, threads.y));
+
+  SET_FLOAT_BASE;
+#if (USE_TEXTURE)
+  hipTextureObject_t texFloat;
+  hipResourceDesc texRes;
+  memset(&texRes, 0, sizeof(hipResourceDesc));
+
+  texRes.resType = hipResourceTypeLinear;
+  texRes.res.linear.devPtr = d_Src;
+  texRes.res.linear.sizeInBytes = sizeof(float) * kernelH * kernelW;
+  texRes.res.linear.desc = hipCreateChannelDesc<float>();
+
+  hipTextureDesc texDescr;
+  memset(&texDescr, 0, sizeof(hipTextureDesc));
+
+  texDescr.normalizedCoords = false;
+  texDescr.filterMode = hipFilterModeLinear;
+  texDescr.addressMode[0] = hipAddressModeWrap;
+  texDescr.readMode = hipReadModeElementType;
+
+  checkCudaErrors(hipCreateTextureObject(&texFloat, &texRes, &texDescr, NULL));
+#endif
+
+  padKernel_kernel<<<grid, threads>>>(d_Dst, d_Src, fftH, fftW, kernelH,
+                                      kernelW, kernelY, kernelX
+#if (USE_TEXTURE)
+                                      ,
+                                      texFloat
+#endif
+                                      );
+  getLastCudaError("padKernel_kernel<<<>>> execution failed\n");
+
+#if (USE_TEXTURE)
+  checkCudaErrors(hipDestroyTextureObject(texFloat));
+#endif
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Prepare data for "pad to border" addressing mode
+////////////////////////////////////////////////////////////////////////////////
+extern "C" void padDataClampToBorder(float *d_Dst, float *d_Src, int fftH,
+                                     int fftW, int dataH, int dataW,
+                                     int kernelW, int kernelH, int kernelY,
+                                     int kernelX) {
+  assert(d_Src != d_Dst);
+  dim3 threads(32, 8);
+  dim3 grid(iDivUp(fftW, threads.x), iDivUp(fftH, threads.y));
+
+#if (USE_TEXTURE)
+  hipTextureObject_t texFloat;
+  hipResourceDesc texRes;
+  memset(&texRes, 0, sizeof(hipResourceDesc));
+
+  texRes.resType = hipResourceTypeLinear;
+  texRes.res.linear.devPtr = d_Src;
+  texRes.res.linear.sizeInBytes = sizeof(float) * dataH * dataW;
+  texRes.res.linear.desc = hipCreateChannelDesc<float>();
+
+  hipTextureDesc texDescr;
+  memset(&texDescr, 0, sizeof(hipTextureDesc));
+
+  texDescr.normalizedCoords = false;
+  texDescr.filterMode = hipFilterModeLinear;
+  texDescr.addressMode[0] = hipAddressModeWrap;
+  texDescr.readMode = hipReadModeElementType;
+
+  checkCudaErrors(hipCreateTextureObject(&texFloat, &texRes, &texDescr, NULL));
+#endif
+
+  padDataClampToBorder_kernel<<<grid, threads>>>(
+      d_Dst, d_Src, fftH, fftW, dataH, dataW, kernelH, kernelW, kernelY, kernelX
+#if (USE_TEXTURE)
+      ,
+      texFloat
+#endif
+      );
+  getLastCudaError("padDataClampToBorder_kernel<<<>>> execution failed\n");
+
+#if (USE_TEXTURE)
+  checkCudaErrors(hipDestroyTextureObject(texFloat));
+#endif
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Modulate Fourier image of padded data by Fourier image of padded kernel
+// and normalize by FFT size
+////////////////////////////////////////////////////////////////////////////////
+extern "C" void modulateAndNormalize(fComplex *d_Dst, fComplex *d_Src, int fftH,
+                                     int fftW, int padding) {
+  assert(fftW % 2 == 0);
+  const int dataSize = fftH * (fftW / 2 + padding);
+
+  modulateAndNormalize_kernel<<<iDivUp(dataSize, 256), 256>>>(
+      d_Dst, d_Src, dataSize, 1.0f / (float)(fftW * fftH));
+  getLastCudaError("modulateAndNormalize() execution failed\n");
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// 2D R2C / C2R post/preprocessing kernels
+////////////////////////////////////////////////////////////////////////////////
+static const double PI = 3.1415926535897932384626433832795;
+static const uint BLOCKDIM = 256;
+
+extern "C" void spPostprocess2D(void *d_Dst, void *d_Src, uint DY, uint DX,
+                                uint padding, int dir) {
+  assert(d_Src != d_Dst);
+  assert(DX % 2 == 0);
+
+#if (POWER_OF_TWO)
+  uint log2DX, log2DY;
+  uint factorizationRemX = factorRadix2(log2DX, DX);
+  uint factorizationRemY = factorRadix2(log2DY, DY);
+  assert(factorizationRemX == 1 && factorizationRemY == 1);
+#endif
+
+  const uint threadCount = DY * (DX / 2);
+  const double phaseBase = dir * PI / (double)DX;
+
+#if (USE_TEXTURE)
+  hipTextureObject_t texComplex;
+  hipResourceDesc texRes;
+  memset(&texRes, 0, sizeof(hipResourceDesc));
+
+  texRes.resType = hipResourceTypeLinear;
+  texRes.res.linear.devPtr = d_Src;
+  texRes.res.linear.sizeInBytes = sizeof(fComplex) * DY * (DX + padding);
+  texRes.res.linear.desc = hipCreateChannelDesc<fComplex>();
+
+  hipTextureDesc texDescr;
+  memset(&texDescr, 0, sizeof(hipTextureDesc));
+
+  texDescr.normalizedCoords = false;
+  texDescr.filterMode = hipFilterModeLinear;
+  texDescr.addressMode[0] = hipAddressModeWrap;
+  texDescr.readMode = hipReadModeElementType;
+
+  checkCudaErrors(
+      hipCreateTextureObject(&texComplex, &texRes, &texDescr, NULL));
+#endif
+
+  spPostprocess2D_kernel<<<iDivUp(threadCount, BLOCKDIM), BLOCKDIM>>>(
+      (fComplex *)d_Dst, (fComplex *)d_Src, DY, DX, threadCount, padding,
+      (float)phaseBase
+#if (USE_TEXTURE)
+      ,
+      texComplex
+#endif
+      );
+  getLastCudaError("spPostprocess2D_kernel<<<>>> execution failed\n");
+
+#if (USE_TEXTURE)
+  checkCudaErrors(hipDestroyTextureObject(texComplex));
+#endif
+}
+
+extern "C" void spPreprocess2D(void *d_Dst, void *d_Src, uint DY, uint DX,
+                               uint padding, int dir) {
+  assert(d_Src != d_Dst);
+  assert(DX % 2 == 0);
+
+#if (POWER_OF_TWO)
+  uint log2DX, log2DY;
+  uint factorizationRemX = factorRadix2(log2DX, DX);
+  uint factorizationRemY = factorRadix2(log2DY, DY);
+  assert(factorizationRemX == 1 && factorizationRemY == 1);
+#endif
+
+  const uint threadCount = DY * (DX / 2);
+  const double phaseBase = -dir * PI / (double)DX;
+
+#if (USE_TEXTURE)
+  hipTextureObject_t texComplex;
+  hipResourceDesc texRes;
+  memset(&texRes, 0, sizeof(hipResourceDesc));
+
+  texRes.resType = hipResourceTypeLinear;
+  texRes.res.linear.devPtr = d_Src;
+  texRes.res.linear.sizeInBytes = sizeof(fComplex) * DY * (DX + padding);
+  texRes.res.linear.desc = hipCreateChannelDesc<fComplex>();
+
+  hipTextureDesc texDescr;
+  memset(&texDescr, 0, sizeof(hipTextureDesc));
+
+  texDescr.normalizedCoords = false;
+  texDescr.filterMode = hipFilterModeLinear;
+  texDescr.addressMode[0] = hipAddressModeWrap;
+  texDescr.readMode = hipReadModeElementType;
+
+  checkCudaErrors(
+      hipCreateTextureObject(&texComplex, &texRes, &texDescr, NULL));
+#endif
+  spPreprocess2D_kernel<<<iDivUp(threadCount, BLOCKDIM), BLOCKDIM>>>(
+      (fComplex *)d_Dst, (fComplex *)d_Src, DY, DX, threadCount, padding,
+      (float)phaseBase
+#if (USE_TEXTURE)
+      ,
+      texComplex
+#endif
+      );
+  getLastCudaError("spPreprocess2D_kernel<<<>>> execution failed\n");
+
+#if (USE_TEXTURE)
+  checkCudaErrors(hipDestroyTextureObject(texComplex));
+#endif
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Combined spPostprocess2D + modulateAndNormalize + spPreprocess2D
+////////////////////////////////////////////////////////////////////////////////
+extern "C" void spProcess2D(void *d_Dst, void *d_SrcA, void *d_SrcB, uint DY,
+                            uint DX, int dir) {
+  assert(DY % 2 == 0);
+
+#if (POWER_OF_TWO)
+  uint log2DX, log2DY;
+  uint factorizationRemX = factorRadix2(log2DX, DX);
+  uint factorizationRemY = factorRadix2(log2DY, DY);
+  assert(factorizationRemX == 1 && factorizationRemY == 1);
+#endif
+
+  const uint threadCount = (DY / 2) * DX;
+  const double phaseBase = dir * PI / (double)DX;
+
+#if (USE_TEXTURE)
+  hipTextureObject_t texComplexA, texComplexB;
+  hipResourceDesc texRes;
+  memset(&texRes, 0, sizeof(hipResourceDesc));
+
+  texRes.resType = hipResourceTypeLinear;
+  texRes.res.linear.devPtr = d_SrcA;
+  texRes.res.linear.sizeInBytes = sizeof(fComplex) * DY * DX;
+  texRes.res.linear.desc = hipCreateChannelDesc<fComplex>();
+
+  hipTextureDesc texDescr;
+  memset(&texDescr, 0, sizeof(hipTextureDesc));
+
+  texDescr.normalizedCoords = false;
+  texDescr.filterMode = hipFilterModeLinear;
+  texDescr.addressMode[0] = hipAddressModeWrap;
+  texDescr.readMode = hipReadModeElementType;
+
+  checkCudaErrors(
+      hipCreateTextureObject(&texComplexA, &texRes, &texDescr, NULL));
+
+  memset(&texRes, 0, sizeof(hipResourceDesc));
+
+  texRes.resType = hipResourceTypeLinear;
+  texRes.res.linear.devPtr = d_SrcB;
+  texRes.res.linear.sizeInBytes = sizeof(fComplex) * DY * DX;
+  texRes.res.linear.desc = hipCreateChannelDesc<fComplex>();
+
+  memset(&texDescr, 0, sizeof(hipTextureDesc));
+
+  texDescr.normalizedCoords = false;
+  texDescr.filterMode = hipFilterModeLinear;
+  texDescr.addressMode[0] = hipAddressModeWrap;
+  texDescr.readMode = hipReadModeElementType;
+
+  checkCudaErrors(
+      hipCreateTextureObject(&texComplexB, &texRes, &texDescr, NULL));
+#endif
+  spProcess2D_kernel<<<iDivUp(threadCount, BLOCKDIM), BLOCKDIM>>>(
+      (fComplex *)d_Dst, (fComplex *)d_SrcA, (fComplex *)d_SrcB, DY, DX,
+      threadCount, (float)phaseBase, 0.5f / (float)(DY * DX)
+#if (USE_TEXTURE)
+                                         ,
+      texComplexA, texComplexB
+#endif
+      );
+  getLastCudaError("spProcess2D_kernel<<<>>> execution failed\n");
+
+#if (USE_TEXTURE)
+  checkCudaErrors(hipDestroyTextureObject(texComplexA));
+  checkCudaErrors(hipDestroyTextureObject(texComplexB));
+#endif
+}
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2017.vcxproj
index 834f65b..4fe20d8 100755
--- a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/convolutionFFT2D.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -110,6 +110,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2019.vcxproj
index 1c262cc..71bad45 100755
--- a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/convolutionFFT2D.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -106,6 +106,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2022.vcxproj
index 582f680..a73a0ce 100755
--- a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/convolutionFFT2D.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -106,6 +106,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/Makefile b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/Makefile
index 77fe127..abd407f 100755
--- a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/NsightEclipse.xml
index aa65af8..daa9612 100755
--- a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/NsightEclipse.xml
@@ -33,6 +33,8 @@
     <scope>2:Video Codecs</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/README.md b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/README.md
index 78eee3e..da368a4 100755
--- a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/README.md
+++ b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/README.md
@@ -10,7 +10,7 @@ Image Processing, Video Compression
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMalloc, cudaMemcpy, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.cu.hip b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.cu.hip
index e69de29..0c9302d 100755
--- a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.cu.hip
@@ -0,0 +1,393 @@
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+* 1D DWT for Haar wavelet and signals with a length which is a power of 2.
+* The code reduces bank conflicts and non-coalesced reads / writes as
+* appropriate but does not fully remove them because the computational
+* overhead to achieve this would outweighs the benefit (see inline comments
+* for more details).
+* Large signals are subdivided into sub-signals with 512 elements and the
+* wavelet transform for these is computed with one block over 10 decomposition
+* levels. The resulting signal consisting of the approximation coefficients at
+* level X is then processed in a subsequent step on the device. This requires
+* interblock synchronization which is only possible on host side.
+* Detail coefficients which have been computed are not further referenced
+* during the decomposition so that they can be stored directly in their final
+* position in global memory. The transform and its storing scheme preserve
+* locality in the coefficients so that these writes are coalesced.
+* Approximation coefficients are stored in shared memory because they are
+* needed to compute the subsequent decomposition step. The top most
+* approximation coefficient for a sub-signal processed by one block is stored
+* in a special global memory location to simplify the processing after the
+* interblock synchronization.
+* Most books on wavelets explain the Haar wavelet decomposition. A good freely
+* available resource is the Wavelet primer by Stollnitz et al.
+* http://grail.cs.washington.edu/projects/wavelets/article/wavelet1.pdf
+* http://grail.cs.washington.edu/projects/wavelets/article/wavelet2.pdf
+* The basic of all Wavelet transforms is to decompose a signal into
+* approximation (a) and detail (d) coefficients where the detail tends to be
+* small or zero which allows / simplifies compression. The following "graphs"
+* demonstrate the transform for a signal
+* of length eight. The index always describes the decomposition level where
+* a coefficient arises. The input signal is interpreted as approximation signal
+* at level 0. The coefficients computed on the device are stored in the same
+* scheme as in the example. This data structure is particularly well suited for
+* compression and also preserves the hierarchical structure of the
+decomposition.
+
+-------------------------------------------------
+| a_0 | a_0 | a_0 | a_0 | a_0 | a_0 | a_0 | a_0 |
+-------------------------------------------------
+
+-------------------------------------------------
+| a_1 | a_1 | a_1 | a_1 | d_1 | d_1 | d_1 | d_1 |
+-------------------------------------------------
+
+-------------------------------------------------
+| a_2 | a_2 | d_2 | d_2 | d_1 | d_1 | d_1 | d_1 |
+-------------------------------------------------
+
+-------------------------------------------------
+| a_3 | d_3 | d_2 | d_2 | d_1 | d_1 | d_1 | d_1 |
+-------------------------------------------------
+
+* Host code.
+*/
+
+#ifdef _WIN32
+#define NOMINMAX
+#endif
+
+// includes, system
+
+#include <hip/hip_runtime.h>
+#include <stdlib.h>
+#include <stdio.h>
+#include "rocprofiler.h"
+#include "HIPCHECK.h"
+#include <string.h>
+#include <math.h>
+#include <assert.h>
+
+// includes, project
+#include "helper_functions.h"
+#include "helper_cuda_hipified.h"
+
+// constants which are used in host and device code
+#define INV_SQRT_2 0.70710678118654752440f;
+const unsigned int LOG_NUM_BANKS = 4;
+const unsigned int NUM_BANKS = 16;
+
+////////////////////////////////////////////////////////////////////////////////
+// includes, kernels
+#include "dwtHaar1D_kernel.cuh"
+
+////////////////////////////////////////////////////////////////////////////////
+// declaration, forward
+void runTest(int argc, char **argv);
+bool getLevels(unsigned int len, unsigned int *levels);
+
+////////////////////////////////////////////////////////////////////////////////
+// Program main
+////////////////////////////////////////////////////////////////////////////////
+int main(int argc, char **argv) {
+  // run test
+  runTest(argc, argv);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Perform the wavelet decomposition
+////////////////////////////////////////////////////////////////////////////////
+void runTest(int argc, char **argv) {
+  bool bResult = false;  // flag for final validation of the results
+
+  char *s_fname = NULL, *r_gold_fname = NULL;
+  char r_fname[256];
+  const char usage[] = {
+      "\nUsage:\n"
+      "  dwtHaar1D --signal=<signal_file> --result=<result_file> "
+      "--gold=<gold_file>\n\n"
+      "  <signal_file> Input file containing the signal\n"
+      "  <result_file> Output file storing the result of the wavelet "
+      "decomposition\n"
+      "  <gold_file>   Input file containing the reference result of the "
+      "wavelet decomposition\n"
+      "\nExample:\n"
+      "  ./dwtHaar1D\n"
+      "       --signal=signal.dat\n"
+      "       --result=result.dat\n"
+      "       --gold=regression.gold.dat\n"};
+
+  printf("%s Starting...\n\n", argv[0]);
+
+  // use command-line specified CUDA device, otherwise use device with highest
+  // Gflops/s
+  findCudaDevice(argc, (const char **)argv);
+
+  // file names, either specified as cmd line args or use default
+  if (argc == 4) {
+    char *tmp_sfname, *tmp_rfname, *tmp_goldfname;
+
+    if ((getCmdLineArgumentString(argc, (const char **)argv, "signal",
+                                  &tmp_sfname) != true) ||
+        (getCmdLineArgumentString(argc, (const char **)argv, "result",
+                                  &tmp_rfname) != true) ||
+        (getCmdLineArgumentString(argc, (const char **)argv, "gold",
+                                  &tmp_goldfname) != true)) {
+      fprintf(stderr, "Invalid input syntax.\n%s", usage);
+      exit(EXIT_FAILURE);
+    }
+
+    s_fname = sdkFindFilePath(tmp_sfname, argv[0]);
+    r_gold_fname = sdkFindFilePath(tmp_goldfname, argv[0]);
+    strcpy(r_fname, tmp_rfname);
+  } else {
+    s_fname = sdkFindFilePath("signal.dat", argv[0]);
+    r_gold_fname = sdkFindFilePath("regression.gold.dat", argv[0]);
+    strcpy(r_fname, "result.dat");
+  }
+
+  printf("source file    = \"%s\"\n", s_fname);
+  printf("reference file = \"%s\"\n", r_fname);
+  printf("gold file      = \"%s\"\n", r_gold_fname);
+
+  // read in signal
+  unsigned int slength = 0;
+  float *signal = NULL;
+
+  if (s_fname == NULL) {
+    fprintf(stderr, "Cannot find the file containing the signal.\n%s", usage);
+
+    exit(EXIT_FAILURE);
+  }
+
+  if (sdkReadFile(s_fname, &signal, &slength, false) == true) {
+    printf("Reading signal from \"%s\"\n", s_fname);
+  } else {
+    exit(EXIT_FAILURE);
+  }
+
+  // get the number of decompositions necessary to perform a full decomposition
+  unsigned int dlevels_complete = 0;
+
+  if (true != getLevels(slength, &dlevels_complete)) {
+    // error message
+    fprintf(stderr, "Signal length not supported.\n");
+    // cleanup and abort
+    free(signal);
+    exit(EXIT_FAILURE);
+  }
+
+  // device in data
+  float *d_idata = NULL;
+  // device out data
+  float *d_odata = NULL;
+  // device approx_final data
+  float *approx_final = NULL;
+  // The very final approximation coefficient has to be written to the output
+  // data, all others are reused as input data in the next global step and
+  // therefore have to be written to the input data again.
+  // The following flag indicates where to copy approx_final data
+  //   - 0 is input, 1 is output
+  int approx_is_input;
+
+  // allocate device mem
+  const unsigned int smem_size = sizeof(float) * slength;
+  HIPCHECK(hipMalloc((void **)&d_idata, smem_size));
+  HIPCHECK(hipMalloc((void **)&d_odata, smem_size));
+  HIPCHECK(hipMalloc((void **)&approx_final, smem_size));
+  // copy input data to device
+  HIPCHECK(
+      hipMemcpy(d_idata, signal, smem_size, hipMemcpyHostToDevice));
+
+  // total number of threads
+  // in the first decomposition step always one thread computes the average and
+  // detail signal for one pair of adjacent values
+  unsigned int num_threads_total_left = slength / 2;
+  // decomposition levels performed in the current / next step
+  unsigned int dlevels_step = dlevels_complete;
+
+  // 1D signal so the arrangement of elements is also 1D
+  dim3 block_size;
+  dim3 grid_size;
+
+  // number of decomposition levels left after one iteration on the device
+  unsigned int dlevels_left = dlevels_complete;
+
+  // if less or equal 1k elements, then the data can be processed in one block,
+  // this avoids the Wait-For-Idle (WFI) on host side which is necessary if the
+  // computation is split across multiple SM's if enough input data
+  if (dlevels_complete <= 10) {
+    // decomposition can be performed at once
+    block_size.x = num_threads_total_left;
+    approx_is_input = 0;
+  } else {
+    // 512 threads per block
+    grid_size.x = (num_threads_total_left / 512);
+    block_size.x = 512;
+
+    // 512 threads corresponds to 10 decomposition steps
+    dlevels_step = 10;
+    dlevels_left -= 10;
+
+    approx_is_input = 1;
+  }
+
+  // Initialize d_odata to 0.0f
+  initValue<<<grid_size, block_size>>>(d_odata, 0.0f);
+
+  // do until full decomposition is accomplished
+  while (0 != num_threads_total_left) {
+    // double the number of threads as bytes
+    unsigned int mem_shared = (2 * block_size.x) * sizeof(float);
+    // extra memory requirements to avoid bank conflicts
+    mem_shared += ((2 * block_size.x) / NUM_BANKS) * sizeof(float);
+
+    // run kernel
+    dwtHaar1D<<<grid_size, block_size, mem_shared>>>(
+        d_idata, d_odata, approx_final, dlevels_step, num_threads_total_left,
+        block_size.x);
+
+    // Copy approx_final to appropriate location
+    if (approx_is_input) {
+      HIPCHECK(hipMemcpy(d_idata, approx_final, grid_size.x * 4,
+                                 hipMemcpyDeviceToDevice));
+    } else {
+      HIPCHECK(hipMemcpy(d_odata, approx_final, grid_size.x * 4,
+                                 hipMemcpyDeviceToDevice));
+    }
+
+    // update level variables
+    if (dlevels_left < 10) {
+      // approx_final = d_odata;
+      approx_is_input = 0;
+    }
+
+    // more global steps necessary
+    dlevels_step = (dlevels_left > 10) ? dlevels_left - 10 : dlevels_left;
+    dlevels_left -= 10;
+
+    // after each step only half the threads are used any longer
+    // therefore after 10 steps 2^10 less threads
+    num_threads_total_left = num_threads_total_left >> 10;
+
+    // update block and grid size
+    grid_size.x =
+        (num_threads_total_left / 512) + (0 != (num_threads_total_left % 512))
+            ? 1
+            : 0;
+
+    if (grid_size.x <= 1) {
+      block_size.x = num_threads_total_left;
+    }
+  }
+
+  // get the result back from the server
+  // allocate mem for the result
+  float *odata = (float *)malloc(smem_size);
+  HIPCHECK(
+      hipMemcpy(odata, d_odata, smem_size, hipMemcpyDeviceToHost));
+
+  // post processing
+  // write file for regression test
+  if (r_fname == NULL) {
+    fprintf(stderr,
+            "Cannot write the output file storing the result of the wavelet "
+            "decomposition.\n%s",
+            usage);
+    exit(EXIT_FAILURE);
+  }
+
+  if (sdkWriteFile(r_fname, odata, slength, 0.001f, false) == true) {
+    printf("Writing result to \"%s\"\n", r_fname);
+  } else {
+    exit(EXIT_FAILURE);
+  }
+
+  // load the reference solution
+  unsigned int len_reference = 0;
+  float *reference = NULL;
+
+  if (r_gold_fname == NULL) {
+    fprintf(stderr,
+            "Cannot read the file containing the reference result of the "
+            "wavelet decomposition.\n%s",
+            usage);
+
+    exit(EXIT_FAILURE);
+  }
+
+  if (sdkReadFile(r_gold_fname, &reference, &len_reference, false) == true) {
+    printf("Reading reference result from \"%s\"\n", r_gold_fname);
+  } else {
+    exit(EXIT_FAILURE);
+  }
+
+  assert(slength == len_reference);
+
+  // compare the computed solution and the reference
+  bResult = (bool)sdkCompareL2fe(reference, odata, slength, 0.001f);
+  free(reference);
+
+  // free allocated host and device memory
+  HIPCHECK(hipFree(d_odata));
+  HIPCHECK(hipFree(d_idata));
+  HIPCHECK(hipFree(approx_final));
+
+  free(signal);
+  free(odata);
+  free(s_fname);
+  free(r_gold_fname);
+
+  printf(bResult ? "Test success!\n" : "Test failure!\n");
+}
+
+////////////////////////////////////////////////////////////////////////////////
+//! Get number of decomposition levels to perform a full decomposition
+//! Also check if the input signal size is suitable
+//! @return  true if the number of decomposition levels could be determined
+//!          and the signal length is supported by the implementation,
+//!          otherwise false
+//! @param   len  length of input signal
+//! @param   levels  number of decomposition levels necessary to perform a full
+//!           decomposition
+////////////////////////////////////////////////////////////////////////////////
+bool getLevels(unsigned int len, unsigned int *levels) {
+  bool retval = false;
+
+  // currently signals up to a length of 2^20 supported
+  for (unsigned int i = 0; i < 20; ++i) {
+    if (len == (1 << i)) {
+      *levels = i;
+      retval = true;
+      break;
+    }
+  }
+
+  return retval;
+}
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.out b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.out
index e0b3ec8..1f0ecf7 100755
Binary files a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.out and b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.out differ
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2017.vcxproj
index 4e8abc5..6b69357 100755
--- a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/dwtHaar1D.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2019.vcxproj
index 4fd4505..c191c4f 100755
--- a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/dwtHaar1D.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2022.vcxproj
index f7c48fe..bba596d 100755
--- a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/dwtHaar1D.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/Makefile b/src/samples/Samples/5_Domain_Specific/dxtc/Makefile
index d03f9b9..b379d6c 100755
--- a/src/samples/Samples/5_Domain_Specific/dxtc/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/dxtc/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/dxtc/NsightEclipse.xml
index 3626a54..a31d16c 100755
--- a/src/samples/Samples/5_Domain_Specific/dxtc/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/dxtc/NsightEclipse.xml
@@ -48,6 +48,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Data Compression</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/README.md b/src/samples/Samples/5_Domain_Specific/dxtc/README.md
index ea513a5..3a80566 100755
--- a/src/samples/Samples/5_Domain_Specific/dxtc/README.md
+++ b/src/samples/Samples/5_Domain_Specific/dxtc/README.md
@@ -10,7 +10,7 @@ Cooperative Groups, Image Processing, Image Compression
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaFree, cudaDeviceSynchronize, cudaGetDevice, cudaMalloc, cudaGetD
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc.cu.hip b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc.cu.hip
index 662ba28..04d7bcf 100755
--- a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc.cu.hip
@@ -37,9 +37,9 @@ namespace cg = cooperative_groups;
 #include <helper_math.h>
 #include <float.h>  // for FLT_MAX
 
-#include "CudaMath_hipified.h"
-#include "dds_hipified.h"
-#include "permutations_hipified.h"
+#include "CudaMath.h"
+#include "dds.h"
+#include "permutations.h"
 
 // Definitions
 #define INPUT_IMAGE "teapot512_std.ppm"
@@ -611,12 +611,12 @@ int main(int argc, char **argv) {
 
   // copy into global mem
   uint *d_data = NULL;
-  checkCudaErrors(hipMalloc((void **)&d_data, memSize));
+  HIPCHECK(hipMalloc((void **)&d_data, memSize));
 
   // Result
   uint *d_result = NULL;
   const uint compressedSize = (w / 4) * (h / 4) * 8;
-  checkCudaErrors(hipMalloc((void **)&d_result, compressedSize));
+  HIPCHECK(hipMalloc((void **)&d_result, compressedSize));
   uint *h_result = (uint *)malloc(compressedSize);
 
   // Compute permutations.
@@ -625,8 +625,8 @@ int main(int argc, char **argv) {
 
   // Copy permutations host to devie.
   uint *d_permutations = NULL;
-  checkCudaErrors(hipMalloc((void **)&d_permutations, 1024 * sizeof(uint)));
-  checkCudaErrors(hipMemcpy(d_permutations, permutations, 1024 * sizeof(uint),
+  HIPCHECK(hipMalloc((void **)&d_permutations, 1024 * sizeof(uint)));
+  HIPCHECK(hipMemcpy(d_permutations, permutations, 1024 * sizeof(uint),
                              hipMemcpyHostToDevice));
 
   // create a timer
@@ -634,7 +634,7 @@ int main(int argc, char **argv) {
   sdkCreateTimer(&timer);
 
   // Copy image from host to device
-  checkCudaErrors(
+  HIPCHECK(
       hipMemcpy(d_data, block_image, memSize, hipMemcpyHostToDevice));
 
   // Determine launch configuration and run timed computation numIterations
@@ -646,8 +646,8 @@ int main(int argc, char **argv) {
   hipDeviceProp_t deviceProp;
 
   // get number of SMs on this GPU
-  checkCudaErrors(hipGetDevice(&devID));
-  checkCudaErrors(hipGetDeviceProperties(&deviceProp, devID));
+  HIPCHECK(hipGetDevice(&devID));
+  HIPCHECK(hipGetDeviceProperties(&deviceProp, devID));
 
   // Restrict the numbers of blocks to launch on low end GPUs to avoid kernel
   // timeout
@@ -660,7 +660,7 @@ int main(int argc, char **argv) {
 
   for (int i = -1; i < numIterations; ++i) {
     if (i == 0) {
-      checkCudaErrors(hipDeviceSynchronize());
+      HIPCHECK(hipDeviceSynchronize());
       sdkStartTimer(&timer);
     }
 
@@ -673,7 +673,7 @@ int main(int argc, char **argv) {
   getLastCudaError("compress");
 
   // sync to host, stop timer, record perf
-  checkCudaErrors(hipDeviceSynchronize());
+  HIPCHECK(hipDeviceSynchronize());
   sdkStopTimer(&timer);
   double dAvgTime = 1.0e-3 * sdkGetTimerValue(&timer) / (double)numIterations;
   printf(
@@ -682,7 +682,7 @@ int main(int argc, char **argv) {
       (1.0e-6 * (double)(W * H) / dAvgTime), dAvgTime, (W * H), 1, NUM_THREADS);
 
   // copy result data from device to host
-  checkCudaErrors(
+  HIPCHECK(
       hipMemcpy(h_result, d_result, compressedSize, hipMemcpyDeviceToHost));
 
   // Write out result data to DDS file
@@ -770,9 +770,9 @@ int main(int argc, char **argv) {
   rms /= w * h * 3;
 
   // Free allocated resources and exit
-  checkCudaErrors(hipFree(d_permutations));
-  checkCudaErrors(hipFree(d_data));
-  checkCudaErrors(hipFree(d_result));
+  HIPCHECK(hipFree(d_permutations));
+  HIPCHECK(hipFree(d_data));
+  HIPCHECK(hipFree(d_result));
   free(image_path);
   free(data);
   free(block_image);
@@ -789,11 +789,3 @@ int main(int argc, char **argv) {
   /* Return zero if test passed, one otherwise */
   return rms > ERROR_THRESHOLD;
 }
-!\n");
-  /* Return zero if test passed, one otherwise */
-  return rms > ERROR_THRESHOLD;
-}
-!\n");
-  /* Return zero if test passed, one otherwise */
-  return rms > ERROR_THRESHOLD;
-}
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2017.vcxproj
index 20e5c7e..e1d6843 100755
--- a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/dxtc.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2019.vcxproj
index 82eed56..c1b7f6d 100755
--- a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/dxtc.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2022.vcxproj
index bd9ab79..8609b64 100755
--- a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/dxtc.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/Makefile b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/Makefile
index a65915f..3cf3f54 100755
--- a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/NsightEclipse.xml
index 6bf4324..9e62735 100755
--- a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/NsightEclipse.xml
@@ -41,6 +41,8 @@
     <scope>2:Data Compression</scope>
     <scope>2:Video Codecs</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/README.md b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/README.md
index ffc9c78..473f4ce 100755
--- a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/README.md
+++ b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/README.md
@@ -10,7 +10,7 @@ Linear Algebra, Data-Parallel Algorithms, Video Compression
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaFree, cudaDeviceSynchronize, cudaMemset, cudaMalloc
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/_temp_0_gfx908_sramecc+_xnack-_linked.bc b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/_temp_0_gfx908_sramecc+_xnack-_linked.bc
index 57e2e5c..62d3800 100644
Binary files a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/_temp_0_gfx908_sramecc+_xnack-_linked.bc and b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/_temp_0_gfx908_sramecc+_xnack-_linked.bc differ
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.cu.hip b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.cu.hip
index 22e32a2..8e90506 100755
--- a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.cu.hip
@@ -38,12 +38,16 @@
  * Victor Podlozhnyuk (vpodlozhnyuk@nvidia.com)
  */
 
+
+#include <hip/hip_runtime.h>
 #include <stdio.h>
+#include "rocprofiler.h"
+#include "HIPCHECK.h"
 #include <stdlib.h>
 #include <string.h>
 #include "helper_functions.h"
 #include "helper_cuda_hipified.h"
-#include "HIPCHECK.h"
+
 ////////////////////////////////////////////////////////////////////////////////
 // Reference CPU FWT
 ////////////////////////////////////////////////////////////////////////////////
@@ -56,7 +60,7 @@ extern "C" void dyadicConvolutionCPU(float *h_Result, float *h_Data,
 ////////////////////////////////////////////////////////////////////////////////
 // GPU FWT
 ////////////////////////////////////////////////////////////////////////////////
-#include "fastWalshTransform_kernel_hipified.cuh"
+#include "fastWalshTransform_kernel.cuh"
 
 ////////////////////////////////////////////////////////////////////////////////
 // Data configuration
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.out b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.out
index a713fe2..d1e23f4 100755
Binary files a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.out and b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.out differ
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2017.vcxproj
index a8add5e..6ee445d 100755
--- a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/fastWalshTransform.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2019.vcxproj
index fafcf8c..71cafa0 100755
--- a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/fastWalshTransform.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2022.vcxproj
index 7d614d0..8e30886 100755
--- a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/fastWalshTransform.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -104,6 +104,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/README.md b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/README.md
index 0b142fd..912936d 100755
--- a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/README.md
+++ b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/README.md
@@ -10,7 +10,7 @@ Graphics Interop, CUFFT Library, Physically-Based Simulation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaMallocArray, cudaFreeArray, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2017.vcxproj
index 5295a42..4422168 100755
--- a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/fluidsD3D9.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -110,6 +110,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2019.vcxproj
index 236f689..3feb3a2 100755
--- a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/fluidsD3D9.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -106,6 +106,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2022.vcxproj
index 2ca333d..3dedaf0 100755
--- a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/fluidsD3D9.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -106,6 +106,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/Makefile b/src/samples/Samples/5_Domain_Specific/fluidsGL/Makefile
index 19ec8dd..1c98722 100755
--- a/src/samples/Samples/5_Domain_Specific/fluidsGL/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/fluidsGL/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/fluidsGL/NsightEclipse.xml
index c3f8715..96bb4ea 100755
--- a/src/samples/Samples/5_Domain_Specific/fluidsGL/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/fluidsGL/NsightEclipse.xml
@@ -70,6 +70,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>3:Physically-Based Simulation</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/README.md b/src/samples/Samples/5_Domain_Specific/fluidsGL/README.md
index 6de00d6..0d492eb 100755
--- a/src/samples/Samples/5_Domain_Specific/fluidsGL/README.md
+++ b/src/samples/Samples/5_Domain_Specific/fluidsGL/README.md
@@ -10,7 +10,7 @@ Graphics Interop, CUFFT Library, Physically-Based Simulation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaMallocArray, cudaFreeArray, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2017.vcxproj
index 022734e..8d2822e 100755
--- a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/fluidsGL.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -120,6 +120,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2019.vcxproj
index 182e71e..aa2839e 100755
--- a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/fluidsGL.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -116,6 +116,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2022.vcxproj
index 27ee457..eeae6a6 100755
--- a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/fluidsGL.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -116,6 +116,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/Makefile b/src/samples/Samples/5_Domain_Specific/fluidsGLES/Makefile
index fbae2c9..00b514c 100755
--- a/src/samples/Samples/5_Domain_Specific/fluidsGLES/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/fluidsGLES/Makefile
@@ -315,7 +315,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/fluidsGLES/NsightEclipse.xml
index 69a658f..afaeff7 100755
--- a/src/samples/Samples/5_Domain_Specific/fluidsGLES/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/fluidsGLES/NsightEclipse.xml
@@ -61,6 +61,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>3:Physically-Based Simulation</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/README.md b/src/samples/Samples/5_Domain_Specific/fluidsGLES/README.md
index 7a2049b..b2432dd 100755
--- a/src/samples/Samples/5_Domain_Specific/fluidsGLES/README.md
+++ b/src/samples/Samples/5_Domain_Specific/fluidsGLES/README.md
@@ -10,7 +10,7 @@ Graphics Interop, CUFFT Library, Physically-Based Simulation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaMallocArray, cudaFreeArray, cudaFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/Makefile b/src/samples/Samples/5_Domain_Specific/marchingCubes/Makefile
index 8ff5f5a..baf4f0f 100755
--- a/src/samples/Samples/5_Domain_Specific/marchingCubes/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/marchingCubes/Makefile
@@ -326,7 +326,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/marchingCubes/NsightEclipse.xml
index 2bddf98..0c23d02 100755
--- a/src/samples/Samples/5_Domain_Specific/marchingCubes/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/marchingCubes/NsightEclipse.xml
@@ -79,6 +79,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>3:Physically-Based Simulation</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/README.md b/src/samples/Samples/5_Domain_Specific/marchingCubes/README.md
index 668aeb2..0c2ed9e 100755
--- a/src/samples/Samples/5_Domain_Specific/marchingCubes/README.md
+++ b/src/samples/Samples/5_Domain_Specific/marchingCubes/README.md
@@ -10,7 +10,7 @@ OpenGL Graphics Interop, Vertex Buffers, 3D Graphics, Physically Based Simulatio
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGLUnmapBufferObject, cudaGraphicsUnmapResources, cudaCreateChannelDesc, cuda
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2017.vcxproj
index 30394a8..9d5e9d2 100755
--- a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/marchingCubes.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -119,6 +119,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2019.vcxproj
index fb5b699..9e370d0 100755
--- a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/marchingCubes.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -115,6 +115,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2022.vcxproj
index a13a0bc..ef1da88 100755
--- a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/marchingCubes.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -115,6 +115,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/Makefile b/src/samples/Samples/5_Domain_Specific/nbody/Makefile
index 0015e4e..f4e1df4 100755
--- a/src/samples/Samples/5_Domain_Specific/nbody/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/nbody/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/nbody/NsightEclipse.xml
index 952a3ac..213de22 100755
--- a/src/samples/Samples/5_Domain_Specific/nbody/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/nbody/NsightEclipse.xml
@@ -78,6 +78,8 @@
     <scope>1:Data-Parallel Algorithms</scope>
     <scope>3:Physically-Based Simulation</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/README.md b/src/samples/Samples/5_Domain_Specific/nbody/README.md
index 46a4353..837296c 100755
--- a/src/samples/Samples/5_Domain_Specific/nbody/README.md
+++ b/src/samples/Samples/5_Domain_Specific/nbody/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Data Parallel Algorithms, Physically-Based Simulation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaSetDeviceFlags, cudaGraphicsResourceSetMapFlags,
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda.cu.hip b/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda.cu.hip
index e69de29..8823fdd 100755
--- a/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda.cu.hip
@@ -0,0 +1,288 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "helper_cuda_hipified.h"
+#include <math.h>
+
+#if defined(__APPLE__) || defined(MACOSX)
+#pragma clang diagnostic ignored "-Wdeprecated-declarations"
+#include <GLUT/glut.h>
+#else
+#include <GL/freeglut.h>
+#endif
+
+// CUDA standard includes
+#include <hip/hip_runtime.h>
+#include <cuda_gl_interop.h>
+
+#include <hip/hip_cooperative_groups.h>
+
+namespace cg = cooperative_groups;
+
+#include "bodysystem.h"
+
+__constant__ float softeningSquared;
+__constant__ double softeningSquared_fp64;
+
+hipError_t setSofteningSquared(float softeningSq) {
+  return hipMemcpyToSymbol(HIP_SYMBOL(softeningSquared), &softeningSq, sizeof(float), 0,
+                            hipMemcpyHostToDevice);
+}
+
+hipError_t setSofteningSquared(double softeningSq) {
+  return hipMemcpyToSymbol(HIP_SYMBOL(softeningSquared_fp64), &softeningSq, sizeof(double),
+                            0, hipMemcpyHostToDevice);
+}
+
+template <class T>
+struct SharedMemory {
+  __device__ inline operator T *() {
+    extern __shared__ int __smem[];
+    return (T *)__smem;
+  }
+
+  __device__ inline operator const T *() const {
+    extern __shared__ int __smem[];
+    return (T *)__smem;
+  }
+};
+
+template <typename T>
+__device__ T rsqrt_T(T x) {
+  return rsqrt(x);
+}
+
+template <>
+__device__ float rsqrt_T<float>(float x) {
+  return rsqrtf(x);
+}
+
+template <>
+__device__ double rsqrt_T<double>(double x) {
+  return rsqrt(x);
+}
+
+// Macros to simplify shared memory addressing
+#define SX(i) sharedPos[i + blockDim.x * threadIdx.y]
+// This macro is only used when multithreadBodies is true (below)
+#define SX_SUM(i, j) sharedPos[i + blockDim.x * j]
+
+template <typename T>
+__device__ T getSofteningSquared() {
+  return softeningSquared;
+}
+template <>
+__device__ double getSofteningSquared<double>() {
+  return softeningSquared_fp64;
+}
+
+template <typename T>
+struct DeviceData {
+  T *dPos[2];  // mapped host pointers
+  T *dVel;
+  hipEvent_t event;
+  unsigned int offset;
+  unsigned int numBodies;
+};
+
+template <typename T>
+__device__ typename vec3<T>::Type bodyBodyInteraction(
+    typename vec3<T>::Type ai, typename vec4<T>::Type bi,
+    typename vec4<T>::Type bj) {
+  typename vec3<T>::Type r;
+
+  // r_ij  [3 FLOPS]
+  r.x = bj.x - bi.x;
+  r.y = bj.y - bi.y;
+  r.z = bj.z - bi.z;
+
+  // distSqr = dot(r_ij, r_ij) + EPS^2  [6 FLOPS]
+  T distSqr = r.x * r.x + r.y * r.y + r.z * r.z;
+  distSqr += getSofteningSquared<T>();
+
+  // invDistCube =1/distSqr^(3/2)  [4 FLOPS (2 mul, 1 sqrt, 1 inv)]
+  T invDist = rsqrt_T(distSqr);
+  T invDistCube = invDist * invDist * invDist;
+
+  // s = m_j * invDistCube [1 FLOP]
+  T s = bj.w * invDistCube;
+
+  // a_i =  a_i + s * r_ij [6 FLOPS]
+  ai.x += r.x * s;
+  ai.y += r.y * s;
+  ai.z += r.z * s;
+
+  return ai;
+}
+
+template <typename T>
+__device__ typename vec3<T>::Type computeBodyAccel(
+    typename vec4<T>::Type bodyPos, typename vec4<T>::Type *positions,
+    int numTiles, cg::thread_block cta) {
+  typename vec4<T>::Type *sharedPos = SharedMemory<typename vec4<T>::Type>();
+
+  typename vec3<T>::Type acc = {0.0f, 0.0f, 0.0f};
+
+  for (int tile = 0; tile < numTiles; tile++) {
+    sharedPos[threadIdx.x] = positions[tile * blockDim.x + threadIdx.x];
+
+    cg::sync(cta);
+
+// This is the "tile_calculation" from the GPUG3 article.
+#pragma unroll 128
+
+    for (unsigned int counter = 0; counter < blockDim.x; counter++) {
+      acc = bodyBodyInteraction<T>(acc, bodyPos, sharedPos[counter]);
+    }
+
+    cg::sync(cta);
+  }
+
+  return acc;
+}
+
+template <typename T>
+__global__ void integrateBodies(typename vec4<T>::Type *__restrict__ newPos,
+                                typename vec4<T>::Type *__restrict__ oldPos,
+                                typename vec4<T>::Type *vel,
+                                unsigned int deviceOffset,
+                                unsigned int deviceNumBodies, float deltaTime,
+                                float damping, int numTiles) {
+  // Handle to thread block group
+  cg::thread_block cta = cg::this_thread_block();
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+
+  if (index >= deviceNumBodies) {
+    return;
+  }
+
+  typename vec4<T>::Type position = oldPos[deviceOffset + index];
+
+  typename vec3<T>::Type accel =
+      computeBodyAccel<T>(position, oldPos, numTiles, cta);
+
+  // acceleration = force / mass;
+  // new velocity = old velocity + acceleration * deltaTime
+  // note we factor out the body's mass from the equation, here and in
+  // bodyBodyInteraction
+  // (because they cancel out).  Thus here force == acceleration
+  typename vec4<T>::Type velocity = vel[deviceOffset + index];
+
+  velocity.x += accel.x * deltaTime;
+  velocity.y += accel.y * deltaTime;
+  velocity.z += accel.z * deltaTime;
+
+  velocity.x *= damping;
+  velocity.y *= damping;
+  velocity.z *= damping;
+
+  // new position = old position + velocity * deltaTime
+  position.x += velocity.x * deltaTime;
+  position.y += velocity.y * deltaTime;
+  position.z += velocity.z * deltaTime;
+
+  // store new position and velocity
+  newPos[deviceOffset + index] = position;
+  vel[deviceOffset + index] = velocity;
+}
+
+template <typename T>
+void integrateNbodySystem(DeviceData<T> *deviceData,
+                          hipGraphicsResource **pgres,
+                          unsigned int currentRead, float deltaTime,
+                          float damping, unsigned int numBodies,
+                          unsigned int numDevices, int blockSize,
+                          bool bUsePBO) {
+  if (bUsePBO) {
+    HIPCHECK(cudaGraphicsResourceSetMapFlags(
+        pgres[currentRead], cudaGraphicsMapFlagsReadOnly));
+    HIPCHECK(cudaGraphicsResourceSetMapFlags(
+        pgres[1 - currentRead], cudaGraphicsMapFlagsWriteDiscard));
+    HIPCHECK(hipGraphicsMapResources(2, pgres, 0));
+    size_t bytes;
+    HIPCHECK(hipGraphicsResourceGetMappedPointer(
+        (void **)&(deviceData[0].dPos[currentRead]), &bytes,
+        pgres[currentRead]));
+    HIPCHECK(hipGraphicsResourceGetMappedPointer(
+        (void **)&(deviceData[0].dPos[1 - currentRead]), &bytes,
+        pgres[1 - currentRead]));
+  }
+
+  for (unsigned int dev = 0; dev != numDevices; dev++) {
+    if (numDevices > 1) {
+      hipSetDevice(dev);
+    }
+
+    int numBlocks = (deviceData[dev].numBodies + blockSize - 1) / blockSize;
+    int numTiles = (numBodies + blockSize - 1) / blockSize;
+    int sharedMemSize = blockSize * 4 * sizeof(T);  // 4 floats for pos
+
+    integrateBodies<T><<<numBlocks, blockSize, sharedMemSize>>>(
+        (typename vec4<T>::Type *)deviceData[dev].dPos[1 - currentRead],
+        (typename vec4<T>::Type *)deviceData[dev].dPos[currentRead],
+        (typename vec4<T>::Type *)deviceData[dev].dVel, deviceData[dev].offset,
+        deviceData[dev].numBodies, deltaTime, damping, numTiles);
+
+    if (numDevices > 1) {
+      HIPCHECK(hipEventRecord(deviceData[dev].event));
+      // MJH: Hack on older driver versions to force kernel launches to flush!
+      hipStreamQuery(0);
+    }
+
+    // check if kernel invocation generated an error
+    getLastCudaError("Kernel execution failed");
+  }
+
+  if (numDevices > 1) {
+    for (unsigned int dev = 0; dev < numDevices; dev++) {
+      HIPCHECK(hipEventSynchronize(deviceData[dev].event));
+    }
+  }
+
+  if (bUsePBO) {
+    HIPCHECK(hipGraphicsUnmapResources(2, pgres, 0));
+  }
+}
+
+// Explicit specializations needed to generate code
+template void integrateNbodySystem<float>(DeviceData<float> *deviceData,
+                                          hipGraphicsResource **pgres,
+                                          unsigned int currentRead,
+                                          float deltaTime, float damping,
+                                          unsigned int numBodies,
+                                          unsigned int numDevices,
+                                          int blockSize, bool bUsePBO);
+
+template void integrateNbodySystem<double>(DeviceData<double> *deviceData,
+                                           hipGraphicsResource **pgres,
+                                           unsigned int currentRead,
+                                           float deltaTime, float damping,
+                                           unsigned int numBodies,
+                                           unsigned int numDevices,
+                                           int blockSize, bool bUsePBO);
+                          int blockSize, bool bUsePBO);
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2017.vcxproj
index dfc6a1e..99e5a6b 100755
--- a/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/nbody.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -125,6 +125,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2019.vcxproj
index 63dd54b..7662e50 100755
--- a/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/nbody.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -121,6 +121,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2022.vcxproj
index 6bd14df..1c2c9ec 100755
--- a/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/nbody.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -121,6 +121,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/Makefile b/src/samples/Samples/5_Domain_Specific/nbody_opengles/Makefile
index a1e6585..ef0b753 100755
--- a/src/samples/Samples/5_Domain_Specific/nbody_opengles/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/nbody_opengles/Makefile
@@ -315,7 +315,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/nbody_opengles/NsightEclipse.xml
index 9421750..4ffba11 100755
--- a/src/samples/Samples/5_Domain_Specific/nbody_opengles/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/nbody_opengles/NsightEclipse.xml
@@ -68,6 +68,8 @@
     <scope>1:Data-Parallel Algorithms</scope>
     <scope>3:Physically-Based Simulation</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/README.md b/src/samples/Samples/5_Domain_Specific/nbody_opengles/README.md
index 52b8ce4..a7911e0 100755
--- a/src/samples/Samples/5_Domain_Specific/nbody_opengles/README.md
+++ b/src/samples/Samples/5_Domain_Specific/nbody_opengles/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Data Parallel Algorithms, Physically-Based Simulation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaSetDeviceFlags, cudaGraphicsResourceSetMapFlags,
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda.cu.hip b/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda.cu.hip
index e69de29..986ac9a 100755
--- a/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda.cu.hip
@@ -0,0 +1,278 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "helper_cuda_hipified.h"
+#include <math.h>
+
+//#include <GL/glew.h>
+//#include <GL/freeglut.h>
+
+// CUDA standard includes
+#include <hip/hip_runtime.h>
+//#include <cuda_gl_interop.h>
+
+#include "bodysystem.h"
+
+__constant__ float softeningSquared;
+__constant__ double softeningSquared_fp64;
+
+hipError_t setSofteningSquared(float softeningSq) {
+  return hipMemcpyToSymbol(HIP_SYMBOL(softeningSquared), &softeningSq, sizeof(float), 0,
+                            hipMemcpyHostToDevice);
+}
+
+hipError_t setSofteningSquared(double softeningSq) {
+  return hipMemcpyToSymbol(HIP_SYMBOL(softeningSquared_fp64), &softeningSq, sizeof(double),
+                            0, hipMemcpyHostToDevice);
+}
+
+template <class T>
+struct SharedMemory {
+  __device__ inline operator T *() {
+    extern __shared__ int __smem[];
+    return (T *)__smem;
+  }
+
+  __device__ inline operator const T *() const {
+    extern __shared__ int __smem[];
+    return (T *)__smem;
+  }
+};
+
+template <typename T>
+__device__ T rsqrt_T(T x) {
+  return rsqrt(x);
+}
+
+template <>
+__device__ float rsqrt_T<float>(float x) {
+  return rsqrtf(x);
+}
+
+template <>
+__device__ double rsqrt_T<double>(double x) {
+  return rsqrt(x);
+}
+
+// Macros to simplify shared memory addressing
+#define SX(i) sharedPos[i + blockDim.x * threadIdx.y]
+// This macro is only used when multithreadBodies is true (below)
+#define SX_SUM(i, j) sharedPos[i + blockDim.x * j]
+
+template <typename T>
+__device__ T getSofteningSquared() {
+  return softeningSquared;
+}
+template <>
+__device__ double getSofteningSquared<double>() {
+  return softeningSquared_fp64;
+}
+
+template <typename T>
+struct DeviceData {
+  T *dPos[2];  // mapped host pointers
+  T *dVel;
+  hipEvent_t event;
+  unsigned int offset;
+  unsigned int numBodies;
+};
+
+template <typename T>
+__device__ typename vec3<T>::Type bodyBodyInteraction(
+    typename vec3<T>::Type ai, typename vec4<T>::Type bi,
+    typename vec4<T>::Type bj) {
+  typename vec3<T>::Type r;
+
+  // r_ij  [3 FLOPS]
+  r.x = bj.x - bi.x;
+  r.y = bj.y - bi.y;
+  r.z = bj.z - bi.z;
+
+  // distSqr = dot(r_ij, r_ij) + EPS^2  [6 FLOPS]
+  T distSqr = r.x * r.x + r.y * r.y + r.z * r.z;
+  distSqr += getSofteningSquared<T>();
+
+  // invDistCube =1/distSqr^(3/2)  [4 FLOPS (2 mul, 1 sqrt, 1 inv)]
+  T invDist = rsqrt_T(distSqr);
+  T invDistCube = invDist * invDist * invDist;
+
+  // s = m_j * invDistCube [1 FLOP]
+  T s = bj.w * invDistCube;
+
+  // a_i =  a_i + s * r_ij [6 FLOPS]
+  ai.x += r.x * s;
+  ai.y += r.y * s;
+  ai.z += r.z * s;
+
+  return ai;
+}
+
+template <typename T>
+__device__ typename vec3<T>::Type computeBodyAccel(
+    typename vec4<T>::Type bodyPos, typename vec4<T>::Type *positions,
+    int numTiles) {
+  typename vec4<T>::Type *sharedPos = SharedMemory<typename vec4<T>::Type>();
+
+  typename vec3<T>::Type acc = {0.0f, 0.0f, 0.0f};
+
+  for (int tile = 0; tile < numTiles; tile++) {
+    sharedPos[threadIdx.x] = positions[tile * blockDim.x + threadIdx.x];
+
+    __syncthreads();
+
+    // This is the "tile_calculation" from the GPUG3 article.
+#pragma unroll 128
+
+    for (unsigned int counter = 0; counter < blockDim.x; counter++) {
+      acc = bodyBodyInteraction<T>(acc, bodyPos, sharedPos[counter]);
+    }
+
+    __syncthreads();
+  }
+
+  return acc;
+}
+
+template <typename T>
+__global__ void integrateBodies(typename vec4<T>::Type *__restrict__ newPos,
+                                typename vec4<T>::Type *__restrict__ oldPos,
+                                typename vec4<T>::Type *vel,
+                                unsigned int deviceOffset,
+                                unsigned int deviceNumBodies, float deltaTime,
+                                float damping, int numTiles) {
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+
+  if (index >= deviceNumBodies) {
+    return;
+  }
+
+  typename vec4<T>::Type position = oldPos[deviceOffset + index];
+
+  typename vec3<T>::Type accel =
+      computeBodyAccel<T>(position, oldPos, numTiles);
+
+  // acceleration = force / mass;
+  // new velocity = old velocity + acceleration * deltaTime
+  // note we factor out the body's mass from the equation, here and in
+  // bodyBodyInteraction (because they cancel out).  Thus here force ==
+  // acceleration
+  typename vec4<T>::Type velocity = vel[deviceOffset + index];
+
+  velocity.x += accel.x * deltaTime;
+  velocity.y += accel.y * deltaTime;
+  velocity.z += accel.z * deltaTime;
+
+  velocity.x *= damping;
+  velocity.y *= damping;
+  velocity.z *= damping;
+
+  // new position = old position + velocity * deltaTime
+  position.x += velocity.x * deltaTime;
+  position.y += velocity.y * deltaTime;
+  position.z += velocity.z * deltaTime;
+
+  // store new position and velocity
+  newPos[deviceOffset + index] = position;
+  vel[deviceOffset + index] = velocity;
+}
+
+template <typename T>
+void integrateNbodySystem(DeviceData<T> *deviceData,
+                          hipGraphicsResource **pgres,
+                          unsigned int currentRead, float deltaTime,
+                          float damping, unsigned int numBodies,
+                          unsigned int numDevices, int blockSize,
+                          bool bUsePBO) {
+  if (bUsePBO) {
+    HIPCHECK(cudaGraphicsResourceSetMapFlags(
+        pgres[currentRead], cudaGraphicsMapFlagsReadOnly));
+    HIPCHECK(cudaGraphicsResourceSetMapFlags(
+        pgres[1 - currentRead], cudaGraphicsMapFlagsWriteDiscard));
+    HIPCHECK(hipGraphicsMapResources(2, pgres, 0));
+    size_t bytes;
+    HIPCHECK(hipGraphicsResourceGetMappedPointer(
+        (void **)&(deviceData[0].dPos[currentRead]), &bytes,
+        pgres[currentRead]));
+    HIPCHECK(hipGraphicsResourceGetMappedPointer(
+        (void **)&(deviceData[0].dPos[1 - currentRead]), &bytes,
+        pgres[1 - currentRead]));
+  }
+
+  for (unsigned int dev = 0; dev != numDevices; dev++) {
+    if (numDevices > 1) {
+      hipSetDevice(dev);
+    }
+
+    int numBlocks = (deviceData[dev].numBodies + blockSize - 1) / blockSize;
+    int numTiles = (numBodies + blockSize - 1) / blockSize;
+    int sharedMemSize = blockSize * 4 * sizeof(T);  // 4 floats for pos
+
+    integrateBodies<T><<<numBlocks, blockSize, sharedMemSize>>>(
+        (typename vec4<T>::Type *)deviceData[dev].dPos[1 - currentRead],
+        (typename vec4<T>::Type *)deviceData[dev].dPos[currentRead],
+        (typename vec4<T>::Type *)deviceData[dev].dVel, deviceData[dev].offset,
+        deviceData[dev].numBodies, deltaTime, damping, numTiles);
+
+    if (numDevices > 1) {
+      HIPCHECK(hipEventRecord(deviceData[dev].event));
+      // MJH: Hack on older driver versions to force kernel launches to flush!
+      hipStreamQuery(0);
+    }
+
+    // check if kernel invocation generated an error
+    getLastCudaError("Kernel execution failed");
+  }
+
+  if (numDevices > 1) {
+    for (unsigned int dev = 0; dev < numDevices; dev++) {
+      HIPCHECK(hipEventSynchronize(deviceData[dev].event));
+    }
+  }
+
+  if (bUsePBO) {
+    HIPCHECK(hipGraphicsUnmapResources(2, pgres, 0));
+  }
+}
+
+// Explicit specializations needed to generate code
+template void integrateNbodySystem<float>(DeviceData<float> *deviceData,
+                                          hipGraphicsResource **pgres,
+                                          unsigned int currentRead,
+                                          float deltaTime, float damping,
+                                          unsigned int numBodies,
+                                          unsigned int numDevices,
+                                          int blockSize, bool bUsePBO);
+
+template void integrateNbodySystem<double>(DeviceData<double> *deviceData,
+                                           hipGraphicsResource **pgres,
+                                           unsigned int currentRead,
+                                           float deltaTime, float damping,
+                                           unsigned int numBodies,
+                                           unsigned int numDevices,
+                                           int blockSize, bool bUsePBO);
+                          int blockSize, bool bUsePBO);
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/Makefile b/src/samples/Samples/5_Domain_Specific/nbody_screen/Makefile
index e07e6f4..b54e179 100755
--- a/src/samples/Samples/5_Domain_Specific/nbody_screen/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/nbody_screen/Makefile
@@ -322,7 +322,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/nbody_screen/NsightEclipse.xml
index ee555f6..074a2e5 100755
--- a/src/samples/Samples/5_Domain_Specific/nbody_screen/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/nbody_screen/NsightEclipse.xml
@@ -66,6 +66,8 @@
     <scope>1:Data-Parallel Algorithms</scope>
     <scope>3:Physically-Based Simulation</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/README.md b/src/samples/Samples/5_Domain_Specific/nbody_screen/README.md
index 28c6cf6..54b9df1 100755
--- a/src/samples/Samples/5_Domain_Specific/nbody_screen/README.md
+++ b/src/samples/Samples/5_Domain_Specific/nbody_screen/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Data Parallel Algorithms, Physically-Based Simulation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaSetDeviceFlags, cudaGraphicsResourceSetMapFlags,
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda.cu.hip b/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda.cu.hip
index e69de29..986ac9a 100755
--- a/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda.cu.hip
@@ -0,0 +1,278 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "helper_cuda_hipified.h"
+#include <math.h>
+
+//#include <GL/glew.h>
+//#include <GL/freeglut.h>
+
+// CUDA standard includes
+#include <hip/hip_runtime.h>
+//#include <cuda_gl_interop.h>
+
+#include "bodysystem.h"
+
+__constant__ float softeningSquared;
+__constant__ double softeningSquared_fp64;
+
+hipError_t setSofteningSquared(float softeningSq) {
+  return hipMemcpyToSymbol(HIP_SYMBOL(softeningSquared), &softeningSq, sizeof(float), 0,
+                            hipMemcpyHostToDevice);
+}
+
+hipError_t setSofteningSquared(double softeningSq) {
+  return hipMemcpyToSymbol(HIP_SYMBOL(softeningSquared_fp64), &softeningSq, sizeof(double),
+                            0, hipMemcpyHostToDevice);
+}
+
+template <class T>
+struct SharedMemory {
+  __device__ inline operator T *() {
+    extern __shared__ int __smem[];
+    return (T *)__smem;
+  }
+
+  __device__ inline operator const T *() const {
+    extern __shared__ int __smem[];
+    return (T *)__smem;
+  }
+};
+
+template <typename T>
+__device__ T rsqrt_T(T x) {
+  return rsqrt(x);
+}
+
+template <>
+__device__ float rsqrt_T<float>(float x) {
+  return rsqrtf(x);
+}
+
+template <>
+__device__ double rsqrt_T<double>(double x) {
+  return rsqrt(x);
+}
+
+// Macros to simplify shared memory addressing
+#define SX(i) sharedPos[i + blockDim.x * threadIdx.y]
+// This macro is only used when multithreadBodies is true (below)
+#define SX_SUM(i, j) sharedPos[i + blockDim.x * j]
+
+template <typename T>
+__device__ T getSofteningSquared() {
+  return softeningSquared;
+}
+template <>
+__device__ double getSofteningSquared<double>() {
+  return softeningSquared_fp64;
+}
+
+template <typename T>
+struct DeviceData {
+  T *dPos[2];  // mapped host pointers
+  T *dVel;
+  hipEvent_t event;
+  unsigned int offset;
+  unsigned int numBodies;
+};
+
+template <typename T>
+__device__ typename vec3<T>::Type bodyBodyInteraction(
+    typename vec3<T>::Type ai, typename vec4<T>::Type bi,
+    typename vec4<T>::Type bj) {
+  typename vec3<T>::Type r;
+
+  // r_ij  [3 FLOPS]
+  r.x = bj.x - bi.x;
+  r.y = bj.y - bi.y;
+  r.z = bj.z - bi.z;
+
+  // distSqr = dot(r_ij, r_ij) + EPS^2  [6 FLOPS]
+  T distSqr = r.x * r.x + r.y * r.y + r.z * r.z;
+  distSqr += getSofteningSquared<T>();
+
+  // invDistCube =1/distSqr^(3/2)  [4 FLOPS (2 mul, 1 sqrt, 1 inv)]
+  T invDist = rsqrt_T(distSqr);
+  T invDistCube = invDist * invDist * invDist;
+
+  // s = m_j * invDistCube [1 FLOP]
+  T s = bj.w * invDistCube;
+
+  // a_i =  a_i + s * r_ij [6 FLOPS]
+  ai.x += r.x * s;
+  ai.y += r.y * s;
+  ai.z += r.z * s;
+
+  return ai;
+}
+
+template <typename T>
+__device__ typename vec3<T>::Type computeBodyAccel(
+    typename vec4<T>::Type bodyPos, typename vec4<T>::Type *positions,
+    int numTiles) {
+  typename vec4<T>::Type *sharedPos = SharedMemory<typename vec4<T>::Type>();
+
+  typename vec3<T>::Type acc = {0.0f, 0.0f, 0.0f};
+
+  for (int tile = 0; tile < numTiles; tile++) {
+    sharedPos[threadIdx.x] = positions[tile * blockDim.x + threadIdx.x];
+
+    __syncthreads();
+
+    // This is the "tile_calculation" from the GPUG3 article.
+#pragma unroll 128
+
+    for (unsigned int counter = 0; counter < blockDim.x; counter++) {
+      acc = bodyBodyInteraction<T>(acc, bodyPos, sharedPos[counter]);
+    }
+
+    __syncthreads();
+  }
+
+  return acc;
+}
+
+template <typename T>
+__global__ void integrateBodies(typename vec4<T>::Type *__restrict__ newPos,
+                                typename vec4<T>::Type *__restrict__ oldPos,
+                                typename vec4<T>::Type *vel,
+                                unsigned int deviceOffset,
+                                unsigned int deviceNumBodies, float deltaTime,
+                                float damping, int numTiles) {
+  int index = blockIdx.x * blockDim.x + threadIdx.x;
+
+  if (index >= deviceNumBodies) {
+    return;
+  }
+
+  typename vec4<T>::Type position = oldPos[deviceOffset + index];
+
+  typename vec3<T>::Type accel =
+      computeBodyAccel<T>(position, oldPos, numTiles);
+
+  // acceleration = force / mass;
+  // new velocity = old velocity + acceleration * deltaTime
+  // note we factor out the body's mass from the equation, here and in
+  // bodyBodyInteraction (because they cancel out).  Thus here force ==
+  // acceleration
+  typename vec4<T>::Type velocity = vel[deviceOffset + index];
+
+  velocity.x += accel.x * deltaTime;
+  velocity.y += accel.y * deltaTime;
+  velocity.z += accel.z * deltaTime;
+
+  velocity.x *= damping;
+  velocity.y *= damping;
+  velocity.z *= damping;
+
+  // new position = old position + velocity * deltaTime
+  position.x += velocity.x * deltaTime;
+  position.y += velocity.y * deltaTime;
+  position.z += velocity.z * deltaTime;
+
+  // store new position and velocity
+  newPos[deviceOffset + index] = position;
+  vel[deviceOffset + index] = velocity;
+}
+
+template <typename T>
+void integrateNbodySystem(DeviceData<T> *deviceData,
+                          hipGraphicsResource **pgres,
+                          unsigned int currentRead, float deltaTime,
+                          float damping, unsigned int numBodies,
+                          unsigned int numDevices, int blockSize,
+                          bool bUsePBO) {
+  if (bUsePBO) {
+    HIPCHECK(cudaGraphicsResourceSetMapFlags(
+        pgres[currentRead], cudaGraphicsMapFlagsReadOnly));
+    HIPCHECK(cudaGraphicsResourceSetMapFlags(
+        pgres[1 - currentRead], cudaGraphicsMapFlagsWriteDiscard));
+    HIPCHECK(hipGraphicsMapResources(2, pgres, 0));
+    size_t bytes;
+    HIPCHECK(hipGraphicsResourceGetMappedPointer(
+        (void **)&(deviceData[0].dPos[currentRead]), &bytes,
+        pgres[currentRead]));
+    HIPCHECK(hipGraphicsResourceGetMappedPointer(
+        (void **)&(deviceData[0].dPos[1 - currentRead]), &bytes,
+        pgres[1 - currentRead]));
+  }
+
+  for (unsigned int dev = 0; dev != numDevices; dev++) {
+    if (numDevices > 1) {
+      hipSetDevice(dev);
+    }
+
+    int numBlocks = (deviceData[dev].numBodies + blockSize - 1) / blockSize;
+    int numTiles = (numBodies + blockSize - 1) / blockSize;
+    int sharedMemSize = blockSize * 4 * sizeof(T);  // 4 floats for pos
+
+    integrateBodies<T><<<numBlocks, blockSize, sharedMemSize>>>(
+        (typename vec4<T>::Type *)deviceData[dev].dPos[1 - currentRead],
+        (typename vec4<T>::Type *)deviceData[dev].dPos[currentRead],
+        (typename vec4<T>::Type *)deviceData[dev].dVel, deviceData[dev].offset,
+        deviceData[dev].numBodies, deltaTime, damping, numTiles);
+
+    if (numDevices > 1) {
+      HIPCHECK(hipEventRecord(deviceData[dev].event));
+      // MJH: Hack on older driver versions to force kernel launches to flush!
+      hipStreamQuery(0);
+    }
+
+    // check if kernel invocation generated an error
+    getLastCudaError("Kernel execution failed");
+  }
+
+  if (numDevices > 1) {
+    for (unsigned int dev = 0; dev < numDevices; dev++) {
+      HIPCHECK(hipEventSynchronize(deviceData[dev].event));
+    }
+  }
+
+  if (bUsePBO) {
+    HIPCHECK(hipGraphicsUnmapResources(2, pgres, 0));
+  }
+}
+
+// Explicit specializations needed to generate code
+template void integrateNbodySystem<float>(DeviceData<float> *deviceData,
+                                          hipGraphicsResource **pgres,
+                                          unsigned int currentRead,
+                                          float deltaTime, float damping,
+                                          unsigned int numBodies,
+                                          unsigned int numDevices,
+                                          int blockSize, bool bUsePBO);
+
+template void integrateNbodySystem<double>(DeviceData<double> *deviceData,
+                                           hipGraphicsResource **pgres,
+                                           unsigned int currentRead,
+                                           float deltaTime, float damping,
+                                           unsigned int numBodies,
+                                           unsigned int numDevices,
+                                           int blockSize, bool bUsePBO);
+                          int blockSize, bool bUsePBO);
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/Makefile b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/Makefile
index 5aff491..37afba1 100755
--- a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/NsightEclipse.xml
index e456070..57679e4 100755
--- a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/NsightEclipse.xml
@@ -58,6 +58,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/README.md b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/README.md
index ba95304..1df07a6 100755
--- a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/README.md
+++ b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/README.md
@@ -10,7 +10,7 @@ Performance Strategies, Asynchronous Data Transfers, Unified Virtual Address Spa
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaSetDevice, cudaEventDestroy, cudaOccupancyMaxPotentialBlockSize, cudaCheckEr
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.cu.hip b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.cu.hip
index 8eafccd..d8bb742 100755
--- a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.cu.hip
@@ -1,4 +1,3 @@
-#include "hip/hip_runtime.h"
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -26,10 +25,12 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
+
+#include <hip/hip_runtime.h>
 #include <cstdio>
 #include <vector>
 
-#include "helper_cuda_hipified.h"
+#include <helper_cuda.h>
 #include <helper_timer.h>
 
 using namespace std;
@@ -201,7 +202,7 @@ void outputBandwidthMatrix(int numElems, int numGPUs, bool p2p, P2PDataTransfer
       cudaCheckError();
 
       // Block the stream until all the work is queued up
-      // DANGER! - hipMemcpy*Async may infinitely block waiting for
+      // DANGER! - cudaMemcpy*Async may infinitely block waiting for
       // room to push the operation, so keep the number of repeatitions
       // relatively low.  Higher repeatitions will cause the delay kernel
       // to timeout and lead to unstable results.
@@ -343,7 +344,7 @@ void outputBidirectionalBandwidthMatrix(int numElems, int numGPUs, bool p2p) {
       cudaCheckError();
 
       // Block the stream until all the work is queued up
-      // DANGER! - hipMemcpy*Async may infinitely block waiting for
+      // DANGER! - cudaMemcpy*Async may infinitely block waiting for
       // room to push the operation, so keep the number of repeatitions
       // relatively low.  Higher repeatitions will cause the delay kernel
       // to timeout and lead to unstable results.
@@ -502,7 +503,7 @@ void outputLatencyMatrix(int numGPUs, bool p2p, P2PDataTransfer p2p_method) {
       cudaCheckError();
 
       // Block the stream until all the work is queued up
-      // DANGER! - hipMemcpy*Async may infinitely block waiting for
+      // DANGER! - cudaMemcpy*Async may infinitely block waiting for
       // room to push the operation, so keep the number of repeatitions
       // relatively low.  Higher repeatitions will cause the delay kernel
       // to timeout and lead to unstable results.
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.out b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.out
index d81477f..af55ac4 100755
Binary files a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.out and b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.out differ
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2017.vcxproj
index 87d985b..cbed6fc 100755
--- a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/p2pBandwidthLatencyTest.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2019.vcxproj
index 1c97baa..43fbfc4 100755
--- a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/p2pBandwidthLatencyTest.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2022.vcxproj
index 7da205b..2848655 100755
--- a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/p2pBandwidthLatencyTest.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/Makefile b/src/samples/Samples/5_Domain_Specific/postProcessGL/Makefile
index 3f5148a..c6f18f8 100755
--- a/src/samples/Samples/5_Domain_Specific/postProcessGL/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/postProcessGL/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/postProcessGL/NsightEclipse.xml
index 345c7e0..756864f 100755
--- a/src/samples/Samples/5_Domain_Specific/postProcessGL/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/postProcessGL/NsightEclipse.xml
@@ -72,6 +72,8 @@
     <scope>2:Graphics Interop</scope>
     <scope>2:Image Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/README.md b/src/samples/Samples/5_Domain_Specific/postProcessGL/README.md
index 8e81df3..821e00f 100755
--- a/src/samples/Samples/5_Domain_Specific/postProcessGL/README.md
+++ b/src/samples/Samples/5_Domain_Specific/postProcessGL/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Image Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaHostAlloc, cudaGraphicsUnmapResources, cudaMalloc, cudaFree, cudaGetChannelD
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2017.vcxproj
index 4599bb2..23cf040 100755
--- a/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/postProcessGL.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -118,6 +118,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2019.vcxproj
index 4178a4a..08c28e4 100755
--- a/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/postProcessGL.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2022.vcxproj
index 6a4e923..b70819b 100755
--- a/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/postProcessGL.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/Makefile b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/Makefile
index aa7b450..04628cd 100755
--- a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/NsightEclipse.xml
index c73f776..c35eaa1 100755
--- a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/NsightEclipse.xml
@@ -36,6 +36,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>3:Computational Finance</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/README.md b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/README.md
index 868b670..54afdbb 100755
--- a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/README.md
+++ b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/README.md
@@ -10,7 +10,7 @@ Computational Finance
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaFree, cudaDeviceSynchronize, cudaMemset, cudaMemcpyToSymbol, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator.out b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator.out
index ecd4719..e12aae6 100755
Binary files a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator.out and b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator.out differ
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_kernel.cu.hip
index ae98b11..019f3f7 100755
--- a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_kernel.cu.hip
@@ -30,8 +30,6 @@
 #define QUASIRANDOMGENERATOR_KERNEL_CUH
 
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <stdlib.h>
 #include "helper_cuda_hipified.h"
 #include "quasirandomGenerator_common.h"
@@ -67,7 +65,7 @@ static __global__ void quasirandomGeneratorKernel(float *d_Output,
 // Table initialization routine
 extern "C" void initTableGPU(
     unsigned int tableCPU[QRNG_DIMENSIONS][QRNG_RESOLUTION]) {
-  HIPCHECK(hipMemcpyToSymbol(HIP_SYMBOL(
+  checkCudaErrors(hipMemcpyToSymbol(HIP_SYMBOL(
       c_Table), tableCPU,
       QRNG_DIMENSIONS * QRNG_RESOLUTION * sizeof(unsigned int)));
 }
@@ -179,4 +177,3 @@ extern "C" void inverseCNDgpu(float *d_Output, unsigned int *d_Input,
 }
 
 #endif
-#endif
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2017.vcxproj
index 97467a8..be6fcda 100755
--- a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/quasirandomGenerator.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2019.vcxproj
index 0d94c66..a708342 100755
--- a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/quasirandomGenerator.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2022.vcxproj
index fc06c10..0861b23 100755
--- a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/quasirandomGenerator.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/README.md b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/README.md
index ffd4841..c91d1a2 100755
--- a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/README.md
+++ b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/README.md
@@ -10,7 +10,7 @@ Computational Finance, Runtime Compilation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cuMemcpyDtoH, cuMemAlloc, cuMemFree
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_kernel.cu.hip
index e69de29..1e51076 100755
--- a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_kernel.cu.hip
@@ -0,0 +1,160 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef QUASIRANDOMGENERATOR_KERNEL_CUH
+#define QUASIRANDOMGENERATOR_KERNEL_CUH
+
+#include "quasirandomGenerator_common.h"
+
+// Fast integer multiplication
+#define MUL(a, b) __umul24(a, b)
+
+////////////////////////////////////////////////////////////////////////////////
+// Niederreiter quasirandom number generation kernel
+////////////////////////////////////////////////////////////////////////////////
+__constant__ unsigned int c_Table[QRNG_DIMENSIONS][QRNG_RESOLUTION];
+
+extern "C" __global__ void quasirandomGeneratorKernel(float *d_Output,
+                                                      unsigned int seed,
+                                                      unsigned int N) {
+  unsigned int *dimBase = &c_Table[threadIdx.y][0];
+  unsigned int tid = MUL(blockDim.x, blockIdx.x) + threadIdx.x;
+  unsigned int threadN = MUL(blockDim.x, gridDim.x);
+
+  for (unsigned int pos = tid; pos < N; pos += threadN) {
+    unsigned int result = 0;
+    unsigned int data = seed + pos;
+
+    for (int bit = 0; bit < QRNG_RESOLUTION; bit++, data >>= 1)
+      if (data & 1) {
+        result ^= dimBase[bit];
+      }
+
+    d_Output[MUL(threadIdx.y, N) + pos] = (float)(result + 1) * INT_SCALE;
+  }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Moro's Inverse Cumulative Normal Distribution function approximation
+////////////////////////////////////////////////////////////////////////////////
+__device__ inline float MoroInvCNDgpu(unsigned int x) {
+  const float a1 = 2.50662823884f;
+  const float a2 = -18.61500062529f;
+  const float a3 = 41.39119773534f;
+  const float a4 = -25.44106049637f;
+  const float b1 = -8.4735109309f;
+  const float b2 = 23.08336743743f;
+  const float b3 = -21.06224101826f;
+  const float b4 = 3.13082909833f;
+  const float c1 = 0.337475482272615f;
+  const float c2 = 0.976169019091719f;
+  const float c3 = 0.160797971491821f;
+  const float c4 = 2.76438810333863E-02f;
+  const float c5 = 3.8405729373609E-03f;
+  const float c6 = 3.951896511919E-04f;
+  const float c7 = 3.21767881768E-05f;
+  const float c8 = 2.888167364E-07f;
+  const float c9 = 3.960315187E-07f;
+
+  float z;
+
+  bool negate = false;
+
+  // Ensure the conversion to floating point will give a value in the
+  // range (0,0.5] by restricting the input to the bottom half of the
+  // input domain. We will later reflect the result if the input was
+  // originally in the top half of the input domain
+  if (x >= 0x80000000UL) {
+    x = 0xffffffffUL - x;
+    negate = true;
+  }
+
+  // x is now in the range [0,0x80000000) (i.e. [0,0x7fffffff])
+  // Convert to floating point in (0,0.5]
+  const float x1 = 1.0f / static_cast<float>(0xffffffffUL);
+  const float x2 = x1 / 2.0f;
+  float p1 = x * x1 + x2;
+  // Convert to floating point in (-0.5,0]
+  float p2 = p1 - 0.5f;
+
+  // The input to the Moro inversion is p2 which is in the range
+  // (-0.5,0]. This means that our output will be the negative side
+  // of the bell curve (which we will reflect if "negate" is true).
+
+  // Main body of the bell curve for |p| < 0.42
+  if (p2 > -0.42f) {
+    z = p2 * p2;
+    z = p2 * (((a4 * z + a3) * z + a2) * z + a1) /
+        ((((b4 * z + b3) * z + b2) * z + b1) * z + 1.0f);
+  }
+  // Special case (Chebychev) for tail
+  else {
+    z = __logf(-__logf(p1));
+    z = -(c1 + z * (c2 + z * (c3 + z * (c4 + z * (c5 + z * (c6 + z * 
+        (c7 + z * (c8 + z * c9))))))));
+  }
+
+  // If the original input (x) was in the top half of the range, reflect
+  // to get the positive side of the bell curve
+
+  return negate ? -z : z;
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Main kernel. Choose between transforming
+// input sequence and uniform ascending (0, 1) sequence
+////////////////////////////////////////////////////////////////////////////////
+
+extern "C" __global__ void inverseCNDKernel(float *d_Output,
+                                            unsigned int pathN) {
+  unsigned int distance = ((unsigned int)-1) / (pathN + 1);
+  unsigned int tid = MUL(blockDim.x, blockIdx.x) + threadIdx.x;
+  unsigned int threadN = MUL(blockDim.x, gridDim.x);
+
+  // Transform input number sequence if it's supplied
+  if (0)  // d_Input)
+  {
+    /*
+      for (unsigned int pos = tid; pos < pathN; pos += threadN)
+      {
+          unsigned int d = d_Input[pos];
+          d_Output[pos] = (float)MoroInvCNDgpu(d);
+      }
+      */
+  }
+  // Else generate input uniformly placed samples on the fly
+  // and write to destination
+  else {
+    for (unsigned int pos = tid; pos < pathN; pos += threadN) {
+      unsigned int d = (pos + 1) * distance;
+      d_Output[pos] = (float)MoroInvCNDgpu(d);
+    }
+  }
+}
+
+#endif
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2017.vcxproj
index 18e3b36..3faf855 100755
--- a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -110,6 +110,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2019.vcxproj
index 7eb041c..cb8893b 100755
--- a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -106,6 +106,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2022.vcxproj
index 62f9864..9dc93ac 100755
--- a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -106,6 +106,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/Makefile b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/Makefile
index f0d22a3..f228dea 100755
--- a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/NsightEclipse.xml
index 9405561..624f69c 100755
--- a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/NsightEclipse.xml
@@ -71,6 +71,8 @@
     <scope>2:Image Processing</scope>
     <scope>2:Computer Vision</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/README.md b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/README.md
index e92a946..9e1475c 100755
--- a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/README.md
+++ b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Image Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaFree, cudaGraphicsResourceGetMappedP
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2017.vcxproj
index 3155a89..f706030 100755
--- a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/recursiveGaussian.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -118,6 +118,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2019.vcxproj
index 37b3730..72663de 100755
--- a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/recursiveGaussian.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2022.vcxproj
index 059e221..947a471 100755
--- a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/recursiveGaussian.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D10/README.md
index 2fdc947..a9d7cde 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10/README.md
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10/README.md
@@ -10,7 +10,7 @@ Graphics Interop, 3D Graphics
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaGetErrorString, cudaGraphicsResourceGetMappedPoi
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2017.vcxproj
index 2f24a22..4dadd19 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleD3D10.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2019.vcxproj
index 794b860..1dca8e1 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleD3D10.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2022.vcxproj
index dcb8725..630c0ea 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleD3D10.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/README.md
index 84ea74c..49077dc 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/README.md
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Texture
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaMalloc, cudaUnbindTexture, cudaGetEr
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2017.vcxproj
index 1e71328..08ad0df 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleD3D10RenderTarget.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2019.vcxproj
index 22c9cba..5478db8 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleD3D10RenderTarget.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2022.vcxproj
index 12f8222..532e9d4 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleD3D10RenderTarget.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/README.md
index 80c3970..c8f1a2e 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/README.md
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Texture
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMalloc, cudaMallocPitch, cudaGetErrorString, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2017.vcxproj
index e73fd4f..f5f7322 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleD3D10Texture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2019.vcxproj
index bcf1940..d0c8131 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleD3D10Texture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2022.vcxproj
index 46bcabd..ebc2681 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleD3D10Texture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D11/README.md
index f561b35..fadf5bf 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D11/README.md
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D11/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Image Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaImportKeyedMutex, cudaExternalMemoryGetMappedBuffer, cudaStreamCreateWithFla
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2017.vcxproj
index 3313d5e..2a11df0 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleD3D11.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2019.vcxproj
index 7216908..f3dbb2e 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleD3D11.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2022.vcxproj
index 4fb28e0..7338f41 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleD3D11.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/README.md
index 110d90c..9c4cf95 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/README.md
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Image Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMalloc, cudaMallocPitch, cudaGetErrorString, cud
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2017.vcxproj
index 04ff2bc..025c68f 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleD3D11Texture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -112,6 +112,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2019.vcxproj
index 1fcebfa..67799b2 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleD3D11Texture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2022.vcxproj
index 7df7f46..6345c10 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleD3D11Texture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -108,6 +108,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/simpleD3D12/NsightEclipse.xml
index fcee920..0e142a5 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D12/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D12/NsightEclipse.xml
@@ -46,6 +46,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>2:Graphics Interop</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D12/README.md
index 62112a5..2e472bf 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D12/README.md
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D12/README.md
@@ -10,7 +10,7 @@ Graphics Interop, CUDA DX12 Interop, Image Processing
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaWaitExternalSemaphoresAsync, cudaExternalMemoryGetMappedBuffer, cudaImportEx
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2017.vcxproj
index a9bc3dd..3588238 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleD3D12.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -119,6 +119,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2019.vcxproj
index b2039fa..32c9763 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2019.vcxproj
@@ -39,7 +39,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -68,7 +68,7 @@
       <OutputFile>$(OutDir)/simpleD3D12.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -120,6 +120,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2022.vcxproj
index 5ac1d34..a746209 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2022.vcxproj
@@ -39,7 +39,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -68,7 +68,7 @@
       <OutputFile>$(OutDir)/simpleD3D12.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -120,6 +120,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/sinewave_cuda.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleD3D12/sinewave_cuda.cu.hip
index e69de29..7220a2e 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D12/sinewave_cuda.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D12/sinewave_cuda.cu.hip
@@ -0,0 +1,70 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "ShaderStructs.h"
+
+__global__ void sinewave_gen_kernel(Vertex *vertices, unsigned int width,
+                                    unsigned int height, float time) {
+  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
+  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
+
+  // calculate uv coordinates
+  float u = x / (float)width;
+  float v = y / (float)height;
+  u = u * 2.0f - 1.0f;
+  v = v * 2.0f - 1.0f;
+
+  // calculate simple sine wave pattern
+  float freq = 4.0f;
+  float w = sinf(u * freq + time) * cosf(v * freq + time) * 0.5f;
+
+  if (y < height && x < width) {
+    // write output vertex
+    vertices[y * width + x].position.x = u;
+    vertices[y * width + x].position.y = w;
+    vertices[y * width + x].position.z = v;
+    // vertices[y*width+x].position[3] = 1.0f;
+    vertices[y * width + x].color.x = 1.0f;
+    vertices[y * width + x].color.y = 0.0f;
+    vertices[y * width + x].color.z = 0.0f;
+    vertices[y * width + x].color.w = 0.0f;
+  }
+}
+
+// The host CPU Sinewave thread spawner
+void RunSineWaveKernel(size_t mesh_width, size_t mesh_height,
+                       Vertex *cudaDevVertptr, hipStream_t streamToRun,
+                       float AnimTime) {
+  dim3 block(16, 16, 1);
+  dim3 grid(mesh_width / 16, mesh_height / 16, 1);
+  Vertex *vertices = (Vertex *)cudaDevVertptr;
+  sinewave_gen_kernel<<<grid, block, 0, streamToRun>>>(vertices, mesh_width,
+                                                       mesh_height, AnimTime);
+
+  getLastCudaError("sinewave_gen_kernel execution failed.\n");
+}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D9/README.md
index d6cf615..708a6cf 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D9/README.md
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D9/README.md
@@ -10,7 +10,7 @@ Graphics Interop
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaGraphicsResourceGetMappedPointer, cudaGetLastErr
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2017.vcxproj
index b023418..513a7b2 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleD3D9.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -109,6 +109,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2019.vcxproj
index e057ef0..6c61823 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleD3D9.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2022.vcxproj
index 4d166a8..3389eb9 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleD3D9.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -105,6 +105,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/README.md
index 1e876e7..51bf5c0 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/README.md
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Texture
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMalloc, cudaMallocPitch, cudaFree, cudaGetLastEr
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2017.vcxproj
index 25d89d1..ab2a79d 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleD3D9Texture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -111,6 +111,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2019.vcxproj
index a51197e..53853db 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleD3D9Texture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2022.vcxproj
index 1a6ff77..de004fd 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleD3D9Texture.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/Makefile b/src/samples/Samples/5_Domain_Specific/simpleGL/Makefile
index 3e8281f..47d5ed8 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGL/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/simpleGL/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/simpleGL/NsightEclipse.xml
index b27ab00..0b73f33 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGL/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/simpleGL/NsightEclipse.xml
@@ -57,6 +57,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>2:Graphics Interop</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/README.md b/src/samples/Samples/5_Domain_Specific/simpleGL/README.md
index 0ad2c92..5fc0352 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGL/README.md
+++ b/src/samples/Samples/5_Domain_Specific/simpleGL/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Vertex Buffers, 3D Graphics
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaFree, cudaGraphicsResourceGetMappedP
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2017.vcxproj
index 3f55005..89aab5d 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleGL.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -117,6 +117,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2019.vcxproj
index ebbfb57..934fb11 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleGL.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2022.vcxproj
index 76b2442..e571db1 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleGL.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/Makefile b/src/samples/Samples/5_Domain_Specific/simpleGLES/Makefile
index 1bda9fe..6e0e516 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES/Makefile
@@ -315,7 +315,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/simpleGLES/NsightEclipse.xml
index 477e1d4..fc5a25b 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES/NsightEclipse.xml
@@ -53,6 +53,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>2:Graphics Interop</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/README.md b/src/samples/Samples/5_Domain_Specific/simpleGLES/README.md
index 94dd00c..50644d7 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES/README.md
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Vertex Buffers, 3D Graphics
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaFree, cudaGraphicsResourceGetMappedP
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/mesh.frag.glsl b/src/samples/Samples/5_Domain_Specific/simpleGLES/mesh.frag.glsl
index e5864be..78ba630 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES/mesh.frag.glsl
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES/mesh.frag.glsl
@@ -1,31 +1,31 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-void main()
-{
-    gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);
-}
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+void main()
+{
+    gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);
+}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/mesh.vert.glsl b/src/samples/Samples/5_Domain_Specific/simpleGLES/mesh.vert.glsl
index 1de61b1..e7f3b60 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES/mesh.vert.glsl
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES/mesh.vert.glsl
@@ -1,33 +1,33 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-attribute vec4 position;
-
-void main()
-{
-    gl_Position = position;
-}
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+attribute vec4 position;
+
+void main()
+{
+    gl_Position = position;
+}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/Makefile b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/Makefile
index 1645163..7debcfa 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/Makefile
@@ -315,7 +315,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/NsightEclipse.xml
index 0e0645d..a12a32e 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/NsightEclipse.xml
@@ -62,6 +62,8 @@ $ sudo modprobe nvidia-drm modeset=1
     <scope>1:CUDA Basic Topics</scope>
     <scope>2:Graphics Interop</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/README.md b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/README.md
index 3497072..f11b241 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/README.md
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/README.md
@@ -15,7 +15,7 @@ Graphics Interop, Vertex Buffers, 3D Graphics
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -35,7 +35,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaFree, cudaGraphicsResourceGetMappedP
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/mesh.frag.glsl b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/mesh.frag.glsl
index e5864be..78ba630 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/mesh.frag.glsl
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/mesh.frag.glsl
@@ -1,31 +1,31 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-void main()
-{
-    gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);
-}
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+void main()
+{
+    gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);
+}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/mesh.vert.glsl b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/mesh.vert.glsl
index 1de61b1..e7f3b60 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/mesh.vert.glsl
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/mesh.vert.glsl
@@ -1,33 +1,33 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-attribute vec4 position;
-
-void main()
-{
-    gl_Position = position;
-}
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+attribute vec4 position;
+
+void main()
+{
+    gl_Position = position;
+}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/Makefile b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/Makefile
index 5779d05..2629cc4 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/Makefile
@@ -322,7 +322,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/NsightEclipse.xml
index c8365f9..0b91191 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/NsightEclipse.xml
@@ -54,6 +54,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>2:Graphics Interop</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/README.md b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/README.md
index 1307cd4..78f96be 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/README.md
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Vertex Buffers, 3D Graphics
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaGraphicsUnmapResources, cudaMemcpy, cudaFree, cudaGraphicsResourceGetMappedP
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/mesh.frag.glsl b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/mesh.frag.glsl
index e5864be..78ba630 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/mesh.frag.glsl
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/mesh.frag.glsl
@@ -1,31 +1,31 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-void main()
-{
-    gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);
-}
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+void main()
+{
+    gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);
+}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/mesh.vert.glsl b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/mesh.vert.glsl
index 1de61b1..e7f3b60 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/mesh.vert.glsl
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/mesh.vert.glsl
@@ -1,33 +1,33 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-attribute vec4 position;
-
-void main()
-{
-    gl_Position = position;
-}
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+attribute vec4 position;
+
+void main()
+{
+    gl_Position = position;
+}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/Makefile b/src/samples/Samples/5_Domain_Specific/simpleVulkan/Makefile
index 24c0bec..8b5cfd4 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkan/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkan/Makefile
@@ -340,7 +340,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/simpleVulkan/NsightEclipse.xml
index f7dbf50..1d9449e 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkan/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkan/NsightEclipse.xml
@@ -62,6 +62,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>1:CUDA Vulkan Interop</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/README.md b/src/samples/Samples/5_Domain_Specific/simpleVulkan/README.md
index a1b32f9..fd28702 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkan/README.md
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkan/README.md
@@ -10,7 +10,7 @@ Graphics Interop, CUDA Vulkan Interop, Data Parallel Algorithms
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaStreamCreateWithFlags, cudaExternalMemoryGetMappedBuffer, cudaSignalSemaphor
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2017.vcxproj
index a96ea91..1ec49d0 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleVulkan.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -121,6 +121,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2019.vcxproj
index 1c0c45a..4a4e5a6 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleVulkan.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -117,6 +117,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2022.vcxproj
index 13a3257..81252a9 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleVulkan.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -117,6 +117,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/sinewave.frag b/src/samples/Samples/5_Domain_Specific/simpleVulkan/sinewave.frag
index 40cc9b3..a47d580 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkan/sinewave.frag
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkan/sinewave.frag
@@ -1,38 +1,38 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-
-#version 450
-#extension GL_ARB_separate_shader_objects : enable
-
-layout(location = 0) in vec3 fragColor;
-
-layout(location = 0) out vec4 outColor;
-
-void main() {
-    outColor = vec4(fragColor, 1.0);
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+
+#version 450
+#extension GL_ARB_separate_shader_objects : enable
+
+layout(location = 0) in vec3 fragColor;
+
+layout(location = 0) out vec4 outColor;
+
+void main() {
+    outColor = vec4(fragColor, 1.0);
 }
\ No newline at end of file
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/sinewave.vert b/src/samples/Samples/5_Domain_Specific/simpleVulkan/sinewave.vert
index 51c7c85..78b8616 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkan/sinewave.vert
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkan/sinewave.vert
@@ -1,43 +1,43 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#version 450
-#extension GL_ARB_separate_shader_objects : enable
-
-layout(binding = 0) uniform UniformBufferObject {
-	mat4 modelViewProj;
-} ubo;
-
-layout(location = 0) in float height;
-layout(location = 1) in vec2 xyPos;
-
-layout(location = 0) out vec3 fragColor;
-
-void main() {
-    gl_Position = ubo.modelViewProj * vec4(xyPos.xy, height, 1.0f);
-    fragColor = vec3(0.0f, (height + 0.5f), 0.0f);
-}
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#version 450
+#extension GL_ARB_separate_shader_objects : enable
+
+layout(binding = 0) uniform UniformBufferObject {
+	mat4 modelViewProj;
+} ubo;
+
+layout(location = 0) in float height;
+layout(location = 1) in vec2 xyPos;
+
+layout(location = 0) out vec3 fragColor;
+
+void main() {
+    gl_Position = ubo.modelViewProj * vec4(xyPos.xy, height, 1.0f);
+    fragColor = vec3(0.0f, (height + 0.5f), 0.0f);
+}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/Makefile b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/Makefile
index ec49cdc..42e9802 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/Makefile
@@ -342,7 +342,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/MonteCarloPi.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/MonteCarloPi.cu.hip
index 7cc9033..97c1700 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/MonteCarloPi.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/MonteCarloPi.cu.hip
@@ -307,16 +307,3 @@ void MonteCarloPiSimulation::cleanupSimulationAllocations() {
     m_pointsInsideCircle = nullptr;
   }
 }
-   checkCudaErrors(
-        hipMemAddressFree((hipDeviceptr_t)m_xyVector, m_totalAllocationSize));
-
-    m_xyVector = nullptr;
-    m_pointsInsideCircle = nullptr;
-  }
-}
-   checkCudaErrors(
-        hipMemAddressFree((hipDeviceptr_t)m_xyVector, m_totalAllocationSize));
-
-    m_xyVector = nullptr;
-    m_pointsInsideCircle = nullptr;
-  }
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/NsightEclipse.xml
index 51370fa..5f91fb6 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/NsightEclipse.xml
@@ -78,6 +78,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>1:CUDA Vulkan Interop</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/README.md b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/README.md
index 4531df1..3030b57 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/README.md
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/README.md
@@ -10,7 +10,7 @@ cuMemMap IPC, MMAP, Graphics Interop, CUDA Vulkan Interop, Data Parallel Algorit
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -33,7 +33,7 @@ cudaWaitExternalSemaphoresAsync, cudaImportExternalSemaphore, cudaDeviceGetAttri
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2017.vcxproj
index 223fc2c..2c6ebec 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/simpleVulkanMMAP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -123,6 +123,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2019.vcxproj
index db83ec4..1343dd0 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleVulkanMMAP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -119,6 +119,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2022.vcxproj
index 33fccf4..cf29fc5 100755
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/simpleVulkanMMAP.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -119,6 +119,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/Makefile b/src/samples/Samples/5_Domain_Specific/smokeParticles/Makefile
index 2ade201..f6afadb 100755
--- a/src/samples/Samples/5_Domain_Specific/smokeParticles/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/smokeParticles/Makefile
@@ -326,7 +326,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/smokeParticles/NsightEclipse.xml
index 56d80b2..581dba9 100755
--- a/src/samples/Samples/5_Domain_Specific/smokeParticles/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/smokeParticles/NsightEclipse.xml
@@ -66,6 +66,8 @@
     <scope>2:Texture</scope>
     <scope>3:Physically-Based Simulation</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/README.md b/src/samples/Samples/5_Domain_Specific/smokeParticles/README.md
index 4e0577f..3750d77 100755
--- a/src/samples/Samples/5_Domain_Specific/smokeParticles/README.md
+++ b/src/samples/Samples/5_Domain_Specific/smokeParticles/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Data Parallel Algorithms, Physically-Based Simulation
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaExtent, cudaPitchedPtr, cudaCreateTextureObject, cudaMemcpyToSymbol
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2017.vcxproj
index 9fd14f4..1807407 100755
--- a/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/smokeParticles.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -137,6 +137,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2019.vcxproj
index dc2b012..661e641 100755
--- a/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/smokeParticles.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -133,6 +133,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2022.vcxproj
index 0d71054..d6bb21a 100755
--- a/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/smokeParticles.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -133,6 +133,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/Makefile b/src/samples/Samples/5_Domain_Specific/stereoDisparity/Makefile
index 253ee3d..7608b56 100755
--- a/src/samples/Samples/5_Domain_Specific/stereoDisparity/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/stereoDisparity/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/stereoDisparity/NsightEclipse.xml
index ce10e54..a0249c7 100755
--- a/src/samples/Samples/5_Domain_Specific/stereoDisparity/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/stereoDisparity/NsightEclipse.xml
@@ -48,6 +48,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>2:Image Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/README.md b/src/samples/Samples/5_Domain_Specific/stereoDisparity/README.md
index bec5413..81b9eca 100755
--- a/src/samples/Samples/5_Domain_Specific/stereoDisparity/README.md
+++ b/src/samples/Samples/5_Domain_Specific/stereoDisparity/README.md
@@ -10,7 +10,7 @@ Image Processing, Video Intrinsics
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaFree, cudaEventSynchronize, cudaDeviceSynchronize, cudaCreateTex
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity.cu.hip b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity.cu.hip
index 9177090..44b3c7e 100755
--- a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity.cu.hip
@@ -41,9 +41,9 @@
 
 // includes, project
 #include <helper_functions.h>  // helper for shared that are common to CUDA Samples
-#include "helper_cuda_hipified.h"  // helper for checking cuda initialization and error checking
-#include "helper_string.h"  // helper functions for string parsing
-#include "HIPCHECK.h"
+#include <helper_cuda.h>  // helper for checking cuda initialization and error checking
+#include <helper_string.h>  // helper functions for string parsing
+
 static const char *sSDKsample = "[stereoDisparity]\0";
 
 int iDivUp(int a, int b) { return ((a % b) != 0) ? (a / b + 1) : (a / b); }
@@ -280,4 +280,9 @@ void runTest(int argc, char **argv) {
 
   exit((checkSum == cpuCheckSum) ? EXIT_SUCCESS : EXIT_FAILURE);
 }
+  if (dispOut != NULL) free(dispOut);
+
+  sdkDeleteTimer(&timer);
 
+  exit((checkSum == cpuCheckSum) ? EXIT_SUCCESS : EXIT_FAILURE);
+}
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2017.vcxproj
index c68e986..9305e49 100755
--- a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/stereoDisparity.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2019.vcxproj
index 142340b..bea60c0 100755
--- a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/stereoDisparity.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2022.vcxproj
index 48e768d..0b22b48 100755
--- a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/stereoDisparity.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/Makefile b/src/samples/Samples/5_Domain_Specific/volumeFiltering/Makefile
index ed2eb73..438c552 100755
--- a/src/samples/Samples/5_Domain_Specific/volumeFiltering/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/volumeFiltering/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/volumeFiltering/NsightEclipse.xml
index fc3e039..7b54f46 100755
--- a/src/samples/Samples/5_Domain_Specific/volumeFiltering/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/volumeFiltering/NsightEclipse.xml
@@ -73,6 +73,8 @@
     <scope>2:Image Processing</scope>
     <scope>3:Volume Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/README.md b/src/samples/Samples/5_Domain_Specific/volumeFiltering/README.md
index f0b4f49..a2bc76e 100755
--- a/src/samples/Samples/5_Domain_Specific/volumeFiltering/README.md
+++ b/src/samples/Samples/5_Domain_Specific/volumeFiltering/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Image Processing, 3D Textures, Surface Writes
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaMemcpy, cudaGraphicsMapResources, cudaDestroySurfaceObject, cudaExtent, cuda
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume.h b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume.h
index a9e60a1..6a6d7b9 100755
--- a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume.h
+++ b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume.h
@@ -60,7 +60,7 @@ template <>
 struct VolumeTypeInfo<unsigned char> {
   static const cudaTextureReadMode readMode = cudaReadModeNormalizedFloat;
   static __inline__ __device__ unsigned char convert(float sampled) {
-    return (unsigned char)(__saturatef(sampled) * 255.0);
+    return (unsigned char)(saturate(sampled) * 255.0);
   }
 };
 
@@ -68,7 +68,7 @@ template <>
 struct VolumeTypeInfo<unsigned short> {
   static const cudaTextureReadMode readMode = cudaReadModeNormalizedFloat;
   static __inline__ __device__ unsigned short convert(float sampled) {
-    return (unsigned short)(__saturatef(sampled) * 65535.0);
+    return (unsigned short)(saturate(sampled) * 65535.0);
   }
 };
 
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFilter_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFilter_kernel.cu.hip
index e69de29..c397a84 100755
--- a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFilter_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFilter_kernel.cu.hip
@@ -0,0 +1,117 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef _VOLUMEFILTER_KERNEL_CU_
+#define _VOLUMEFILTER_KERNEL_CU_
+
+#include "helper_cuda_hipified.h"
+#include <helper_math.h>
+#include "volumeFilter.h"
+
+typedef unsigned int uint;
+typedef unsigned char uchar;
+typedef unsigned short ushort;
+
+__constant__ float4 c_filterData[VOLUMEFILTER_MAXWEIGHTS];
+
+__global__ void d_filter_surface3d(int filterSize, float filter_offset,
+                                   hipExtent volumeSize,
+                                   hipTextureObject_t volumeTexIn,
+                                   hipSurfaceObject_t volumeTexOut) {
+  int x = blockIdx.x * blockDim.x + threadIdx.x;
+  int y = blockIdx.y * blockDim.y + threadIdx.y;
+  int z = blockIdx.z * blockDim.z + threadIdx.z;
+
+  if (x >= volumeSize.width || y >= volumeSize.height ||
+      z >= volumeSize.depth) {
+    return;
+  }
+
+  float filtered = 0;
+  float4 basecoord = make_float4(x, y, z, 0);
+
+  for (int i = 0; i < filterSize; i++) {
+    float4 coord = basecoord + c_filterData[i];
+    filtered += tex3D<float>(volumeTexIn, coord.x, coord.y, coord.z) *
+                c_filterData[i].w;
+  }
+
+  filtered += filter_offset;
+
+  VolumeType output = VolumeTypeInfo<VolumeType>::convert(filtered);
+
+  // surface writes need byte offsets for x!
+  surf3Dwrite(output, volumeTexOut, x * sizeof(VolumeType), y, z);
+}
+
+static unsigned int iDivUp(size_t a, size_t b) {
+  size_t val = (a % b != 0) ? (a / b + 1) : (a / b);
+  if (val > UINT_MAX) {
+    fprintf(stderr, "\nUINT_MAX limit exceeded in iDivUp() exiting.....\n");
+    exit(EXIT_FAILURE);  // val exceeds limit
+  }
+
+  return static_cast<unsigned int>(val);
+}
+
+extern "C" Volume *VolumeFilter_runFilter(Volume *input, Volume *output0,
+                                          Volume *output1, int iterations,
+                                          int numWeights, float4 *weights,
+                                          float postWeightOffset) {
+  Volume *swap = 0;
+  hipExtent size = input->size;
+  unsigned int dim = 32 / sizeof(VolumeType);
+  dim3 blockSize(dim, dim, 1);
+  dim3 gridSize(iDivUp(size.width, blockSize.x),
+                iDivUp(size.height, blockSize.y),
+                iDivUp(size.depth, blockSize.z));
+
+  // set weights
+  HIPCHECK(
+      hipMemcpyToSymbol(HIP_SYMBOL(c_filterData), weights, sizeof(float4) * numWeights));
+
+  for (int i = 0; i < iterations; i++) {
+    d_filter_surface3d<<<gridSize, blockSize>>>(numWeights, postWeightOffset,
+                                                size, input->volumeTex,
+                                                output0->volumeSurf);
+
+    getLastCudaError("filter kernel failed");
+
+    swap = input;
+    input = output0;
+    output0 = swap;
+
+    if (i == 0) {
+      output0 = output1;
+    }
+  }
+
+  return input;
+}
+#endif
+#endif
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2017.vcxproj
index 44a4393..6e06866 100755
--- a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/volumeFiltering.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -122,6 +122,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2019.vcxproj
index c1fc8a2..2a01aa1 100755
--- a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/volumeFiltering.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -118,6 +118,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2022.vcxproj
index ffadb6b..04608aa 100755
--- a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/volumeFiltering.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -118,6 +118,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume_hipified.h b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume_hipified.h
index 127cf62..589fb96 100755
--- a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume_hipified.h
+++ b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume_hipified.h
@@ -60,7 +60,7 @@ template <>
 struct VolumeTypeInfo<unsigned char> {
   static const hipTextureReadMode readMode = hipReadModeNormalizedFloat;
   static __inline__ __device__ unsigned char convert(float sampled) {
-    return (unsigned char)(__saturatef(sampled) * 255.0);
+    return (unsigned char)(saturate(sampled) * 255.0);
   }
 };
 
@@ -68,7 +68,7 @@ template <>
 struct VolumeTypeInfo<unsigned short> {
   static const hipTextureReadMode readMode = hipReadModeNormalizedFloat;
   static __inline__ __device__ unsigned short convert(float sampled) {
-    return (unsigned short)(__saturatef(sampled) * 65535.0);
+    return (unsigned short)(saturate(sampled) * 65535.0);
   }
 };
 
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/Makefile b/src/samples/Samples/5_Domain_Specific/volumeRender/Makefile
index 9d0643d..fdb5649 100755
--- a/src/samples/Samples/5_Domain_Specific/volumeRender/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/volumeRender/Makefile
@@ -301,7 +301,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/volumeRender/NsightEclipse.xml
index 63c705c..05b789d 100755
--- a/src/samples/Samples/5_Domain_Specific/volumeRender/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/volumeRender/NsightEclipse.xml
@@ -71,6 +71,8 @@
     <scope>2:Image Processing</scope>
     <scope>3:Volume Processing</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/README.md b/src/samples/Samples/5_Domain_Specific/volumeRender/README.md
index 71ead6b..d5d6ef5 100755
--- a/src/samples/Samples/5_Domain_Specific/volumeRender/README.md
+++ b/src/samples/Samples/5_Domain_Specific/volumeRender/README.md
@@ -10,7 +10,7 @@ Graphics Interop, Image Processing, 3D Textures
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaProfilerStop, cudaGraphicsUnmapResources, cudaMemcpy, cudaMallocArray, cudaF
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2017.vcxproj
index 402e56a..ab6037e 100755
--- a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/volumeRender.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -118,6 +118,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2019.vcxproj
index d1ff3ad..c752510 100755
--- a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/volumeRender.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2022.vcxproj
index 53b850d..7769819 100755
--- a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/volumeRender.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -114,6 +114,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/Makefile b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/Makefile
index 3b2dea4..56b3696 100755
--- a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/Makefile
+++ b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/Makefile
@@ -340,7 +340,7 @@ endif
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/NsightEclipse.xml
index be37264..4fa867e 100755
--- a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/NsightEclipse.xml
+++ b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/NsightEclipse.xml
@@ -67,6 +67,8 @@
     <scope>1:CUDA Advanced Topics</scope>
     <scope>1:CUDA Vulkan Interop</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/README.md b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/README.md
index 678d5d0..97f2de7 100755
--- a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/README.md
+++ b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/README.md
@@ -10,7 +10,7 @@ Graphics Interop, CUDA Vulkan Interop, Data Parallel Algorithms
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -30,7 +30,7 @@ cudaVkSemaphoreSignal, cudaWaitExternalSemaphoresAsync, cudaMemcpy, cudaVkImport
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2017.vcxproj
index 23444d8..424170a 100755
--- a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2017.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/vulkanImageCUDA.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -117,6 +117,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2019.vcxproj
index 03722f9..769231d 100755
--- a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2019.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/vulkanImageCUDA.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2022.vcxproj
index 4ba5c40..9972639 100755
--- a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2022.vcxproj
+++ b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/vulkanImageCUDA.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -113,6 +113,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/Makefile b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/Makefile
index 4b876ca..2f1a618 100755
--- a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/Makefile
+++ b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/Makefile
@@ -287,7 +287,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/NsightEclipse.xml b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/NsightEclipse.xml
index a3fb2ca..6217899 100755
--- a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/NsightEclipse.xml
+++ b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/NsightEclipse.xml
@@ -53,6 +53,20 @@
     <scope>1:CUDA Systems Integration</scope>
     <scope>1:Unified Memory</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
+  <sm-arch>sm50</sm-arch>
+  <sm-arch>sm52</sm-arch>
+  <sm-arch>sm53</sm-arch>
+  <sm-arch>sm60</sm-arch>
+  <sm-arch>sm61</sm-arch>
+  <sm-arch>sm70</sm-arch>
+  <sm-arch>sm72</sm-arch>
+  <sm-arch>sm75</sm-arch>
+  <sm-arch>sm80</sm-arch>
+  <sm-arch>sm86</sm-arch>
+  <sm-arch>sm87</sm-arch>
+  <sm-arch>sm90</sm-arch>
   <supported_envs>
     <env>
       <arch>x86_64</arch>
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/README.md b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/README.md
index a22bf2c..6c1ce62 100755
--- a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/README.md
+++ b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/README.md
@@ -10,6 +10,8 @@ CUDA Systems Integration, Unified Memory, CUDA Streams and Events, Pinned System
 
 ## Supported SM Architectures
 
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+
 ## Supported OSes
 
 Linux, Windows
@@ -28,7 +30,7 @@ cudaMemcpy, cudaStreamDestroy, cudaMemPrefetchAsync, cudaFree, cudaMallocHost, c
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 Make sure the dependencies mentioned in [Dependencies]() section above are installed.
 
 ## Build and Run
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2017.vcxproj b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2017.vcxproj
index 34fbaae..7d59c0a 100755
--- a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2017.vcxproj
+++ b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/UnifiedMemoryPerf.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -110,6 +110,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2019.vcxproj b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2019.vcxproj
index 401661e..9b5e365 100755
--- a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2019.vcxproj
+++ b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/UnifiedMemoryPerf.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -106,6 +106,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2022.vcxproj b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2022.vcxproj
index 8208bef..536d6d5 100755
--- a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2022.vcxproj
+++ b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/UnifiedMemoryPerf.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -106,6 +106,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/commonKernels.cu.hip b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/commonKernels.cu.hip
index e69de29..ed8cd7e 100755
--- a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/commonKernels.cu.hip
+++ b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/commonKernels.cu.hip
@@ -0,0 +1,34 @@
+#include "hip/hip_runtime.h"
+/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *  * Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ *  * Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *  * Neither the name of NVIDIA CORPORATION nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "commonKernels.hpp"
+
+__global__ void spinWhileLessThanOne(volatile unsigned int *latch) {
+  while (latch[0] < 1)
+    ;
+}
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/helperFunctions_hipified.cpp b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/helperFunctions_hipified.cpp
index d9483e0..b2c2c4f 100755
--- a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/helperFunctions_hipified.cpp
+++ b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/helperFunctions_hipified.cpp
@@ -27,7 +27,7 @@
 
 #include <stdio.h>
 #include <string.h>
-#include "commonDefs.hpp"
+#include "commonDefs_hipified.hpp"
 #define CU_INIT_UUID
 #include <cmath>
 
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/matrixMultiplyPerf.cu.hip b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/matrixMultiplyPerf.cu.hip
index 8bdd71e..28d90cc 100755
--- a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/matrixMultiplyPerf.cu.hip
+++ b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/matrixMultiplyPerf.cu.hip
@@ -125,7 +125,7 @@ void verifyMatrixData(float *expectedData, float *observedData,
 }
 
 #define BLOCK_SIZE 32
-__global__ void matrixMultiplyKernel(float *C,float *A,float *B,
+__global__ void matrixMultiplyKernel(float *C, float *A, float *B,
                                      unsigned int matrixDim) {
   // Block index
   int bx = blockIdx.x;
@@ -206,13 +206,9 @@ void runMatrixMultiplyKernel(unsigned int matrixDim, int allocType,
                              double *gpuLaunchTransferSyncTimes,
                              double *cpuAccessTimes, double *overallTimes,
                              int device_id) {
-  void *dptrA = NULL,  *hptrA = NULL;
-  void *dptrB = NULL,  *hptrB = NULL;
-  void *dptrC = NULL,  *hptrC = NULL;
-  //float *dptrA = NULL,  *hptrA = NULL;
-  //float *dptrB = NULL,  *hptrB = NULL;
-  //float *dptrC = NULL,  *hptrC = NULL;
-
+  float *dptrA = NULL, *hptrA = NULL;
+  float *dptrB = NULL, *hptrB = NULL;
+  float *dptrC = NULL, *hptrC = NULL;
   float *randValuesX = NULL, *randValuesY = NULL;
   float *randValuesVerifyXmulY = NULL, *randValuesVerifyYmulX = NULL;
   bool copyRequired = false, hintsRequired = false;
@@ -262,7 +258,7 @@ void runMatrixMultiplyKernel(unsigned int matrixDim, int allocType,
       hipMemcpyAsync(dptrA, randValuesX, size, hipMemcpyHostToDevice));
   HIPCHECK(
       hipMemcpyAsync(dptrB, randValuesY, size, hipMemcpyHostToDevice));
-matrixMultiplyKernel<<<grid, threads>>>(dptrC, dptrA, dptrB, matrixDim);
+  matrixMultiplyKernel<<<grid, threads>>>(dptrC, dptrA, dptrB, matrixDim);
   HIPCHECK(hipMemcpyAsync(randValuesVerifyXmulY, dptrC, size,
                                   hipMemcpyDeviceToHost));
   HIPCHECK(hipStreamSynchronize(NULL));
@@ -318,9 +314,9 @@ matrixMultiplyKernel<<<grid, threads>>>(dptrC, dptrA, dptrB, matrixDim);
       HIPCHECK(hipHostMalloc(&hptrA, size));
       HIPCHECK(hipHostMalloc(&hptrB, size));
       HIPCHECK(hipHostMalloc(&hptrC, size));
-      HIPCHECK(hipHostGetDevicePointer(&dptrA, hptrA, 0));
-      HIPCHECK(hipHostGetDevicePointer(&dptrB, hptrB, 0));
-      HIPCHECK(hipHostGetDevicePointer(&dptrC, hptrC, 0));
+      HIPCHECK(hipHostGetDevicePointer((void **)&dptrA, hptrA, 0));
+      HIPCHECK(hipHostGetDevicePointer((void **)&dptrB, hptrB, 0));
+      HIPCHECK(hipHostGetDevicePointer((void **)&dptrC, hptrC, 0));
       break;
 
     case USE_MANAGED_MEMORY:
@@ -700,11 +696,3 @@ int main(int argc, char **argv) {
       "Results may vary when GPU Boost is enabled.\n");
   exit(EXIT_SUCCESS);
 }
-{
-    numKernelRuns =
-        getCmdLineArgumentInt(argc, (const char **)argv, "kernel-iterations");
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "verbose")) {
-    verboseResults = 1;
-  }
diff --git a/src/samples/Samples/6_Performance/alignedTypes/Makefile b/src/samples/Samples/6_Performance/alignedTypes/Makefile
index 5158c30..492ad19 100755
--- a/src/samples/Samples/6_Performance/alignedTypes/Makefile
+++ b/src/samples/Samples/6_Performance/alignedTypes/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/6_Performance/alignedTypes/NsightEclipse.xml b/src/samples/Samples/6_Performance/alignedTypes/NsightEclipse.xml
index 21b86e7..0b1d16a 100755
--- a/src/samples/Samples/6_Performance/alignedTypes/NsightEclipse.xml
+++ b/src/samples/Samples/6_Performance/alignedTypes/NsightEclipse.xml
@@ -33,6 +33,8 @@
     <scope>1:CUDA Basic Topics</scope>
     <scope>1:Performance Strategies</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/6_Performance/alignedTypes/README.md b/src/samples/Samples/6_Performance/alignedTypes/README.md
index 2ff2597..56e5e26 100755
--- a/src/samples/Samples/6_Performance/alignedTypes/README.md
+++ b/src/samples/Samples/6_Performance/alignedTypes/README.md
@@ -10,7 +10,7 @@ Performance Strategies
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaFree, cudaDeviceSynchronize, cudaMemset, cudaMalloc, cudaGetDevi
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/6_Performance/alignedTypes/_temp_0_gfx908_sramecc+_xnack-_linked.bc b/src/samples/Samples/6_Performance/alignedTypes/_temp_0_gfx908_sramecc+_xnack-_linked.bc
index 57e2e5c..62d3800 100644
Binary files a/src/samples/Samples/6_Performance/alignedTypes/_temp_0_gfx908_sramecc+_xnack-_linked.bc and b/src/samples/Samples/6_Performance/alignedTypes/_temp_0_gfx908_sramecc+_xnack-_linked.bc differ
diff --git a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.cu.hip b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.cu.hip
index b3e70e1..7408fd2 100755
--- a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.cu.hip
+++ b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.cu.hip
@@ -40,11 +40,12 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <string.h>
-
+#include <hip/hip_runtime.h>
 // includes, project
 #include "helper_cuda_hipified.h"  // helper functions for CUDA error checking and initialization
-#include <helper_functions.h>  // helper utility functions
+#include "helper_functions.h"  // helper utility functions
 #include "HIPCHECK.h"
+#include <hip/hip_cooperative_groups.h>
 ////////////////////////////////////////////////////////////////////////////////
 // Misaligned types
 ////////////////////////////////////////////////////////////////////////////////
diff --git a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.out b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.out
index c506452..32574de 100755
Binary files a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.out and b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.out differ
diff --git a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2017.vcxproj b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2017.vcxproj
index 45175b9..7e3439f 100755
--- a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2017.vcxproj
+++ b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/alignedTypes.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2019.vcxproj b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2019.vcxproj
index 3ccac8e..833b531 100755
--- a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2019.vcxproj
+++ b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/alignedTypes.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2022.vcxproj b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2022.vcxproj
index 09c76db..ea91103 100755
--- a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2022.vcxproj
+++ b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/alignedTypes.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/6_Performance/transpose/Makefile b/src/samples/Samples/6_Performance/transpose/Makefile
index 0c744ee..83909bc 100755
--- a/src/samples/Samples/6_Performance/transpose/Makefile
+++ b/src/samples/Samples/6_Performance/transpose/Makefile
@@ -281,7 +281,7 @@ LIBRARIES :=
 ifeq ($(TARGET_ARCH),$(filter $(TARGET_ARCH),armv7l aarch64 sbsa))
 SMS ?= 53 61 70 72 75 80 86 87 90
 else
-SMS ?= 50 52 60 61 70 75 80 86 90
+SMS ?= 35 37 50 52 60 61 70 75 80 86 90
 endif
 
 ifeq ($(SMS),)
diff --git a/src/samples/Samples/6_Performance/transpose/NsightEclipse.xml b/src/samples/Samples/6_Performance/transpose/NsightEclipse.xml
index 8e2c6ee..58f448f 100755
--- a/src/samples/Samples/6_Performance/transpose/NsightEclipse.xml
+++ b/src/samples/Samples/6_Performance/transpose/NsightEclipse.xml
@@ -42,6 +42,8 @@
     <scope>1:Performance Strategies</scope>
     <scope>3:Linear Algebra</scope>
   </scopes>
+  <sm-arch>sm35</sm-arch>
+  <sm-arch>sm37</sm-arch>
   <sm-arch>sm50</sm-arch>
   <sm-arch>sm52</sm-arch>
   <sm-arch>sm53</sm-arch>
diff --git a/src/samples/Samples/6_Performance/transpose/README.md b/src/samples/Samples/6_Performance/transpose/README.md
index c8f030d..0693888 100755
--- a/src/samples/Samples/6_Performance/transpose/README.md
+++ b/src/samples/Samples/6_Performance/transpose/README.md
@@ -10,7 +10,7 @@ Performance Strategies, Linear Algebra
 
 ## Supported SM Architectures
 
-[SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
+[SM 3.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 3.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 5.3 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 6.1 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.2 ](https://developer.nvidia.com/cuda-gpus)  [SM 7.5 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.0 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.6 ](https://developer.nvidia.com/cuda-gpus)  [SM 8.7 ](https://developer.nvidia.com/cuda-gpus)  [SM 9.0 ](https://developer.nvidia.com/cuda-gpus)
 
 ## Supported OSes
 
@@ -27,7 +27,7 @@ cudaMemcpy, cudaMalloc, cudaFree, cudaGetLastError, cudaEventSynchronize, cudaEv
 
 ## Prerequisites
 
-Download and install the [CUDA Toolkit 12.0](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
+Download and install the [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.
 
 ## Build and Run
 
diff --git a/src/samples/Samples/6_Performance/transpose/transpose.cu.hip b/src/samples/Samples/6_Performance/transpose/transpose.cu.hip
index d707d4c..17d876e 100755
--- a/src/samples/Samples/6_Performance/transpose/transpose.cu.hip
+++ b/src/samples/Samples/6_Performance/transpose/transpose.cu.hip
@@ -45,7 +45,7 @@ namespace cg = cooperative_groups;
 // Utilities and system includes
 #include <helper_string.h>    // helper for string parsing
 #include <helper_image.h>     // helper for image and data comparison
-#include <helper_cuda_hipified.h>      // helper for cuda error checking functions
+#include "helper_cuda_hipified.h"      // helper for cuda error checking functions
 #include "HIPCHECK.h"
 const char *sSDKsample = "Transpose";
 
diff --git a/src/samples/Samples/6_Performance/transpose/transpose.out b/src/samples/Samples/6_Performance/transpose/transpose.out
index c0a5ce4..8ab954c 100755
Binary files a/src/samples/Samples/6_Performance/transpose/transpose.out and b/src/samples/Samples/6_Performance/transpose/transpose.out differ
diff --git a/src/samples/Samples/6_Performance/transpose/transpose_vs2017.vcxproj b/src/samples/Samples/6_Performance/transpose/transpose_vs2017.vcxproj
index 799c250..a9f215a 100755
--- a/src/samples/Samples/6_Performance/transpose/transpose_vs2017.vcxproj
+++ b/src/samples/Samples/6_Performance/transpose/transpose_vs2017.vcxproj
@@ -38,7 +38,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -67,7 +67,7 @@
       <OutputFile>$(OutDir)/transpose.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -107,6 +107,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/6_Performance/transpose/transpose_vs2019.vcxproj b/src/samples/Samples/6_Performance/transpose/transpose_vs2019.vcxproj
index aa0feba..e472187 100755
--- a/src/samples/Samples/6_Performance/transpose/transpose_vs2019.vcxproj
+++ b/src/samples/Samples/6_Performance/transpose/transpose_vs2019.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/transpose.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
diff --git a/src/samples/Samples/6_Performance/transpose/transpose_vs2022.vcxproj b/src/samples/Samples/6_Performance/transpose/transpose_vs2022.vcxproj
index b2fce58..1db2b8c 100755
--- a/src/samples/Samples/6_Performance/transpose/transpose_vs2022.vcxproj
+++ b/src/samples/Samples/6_Performance/transpose/transpose_vs2022.vcxproj
@@ -34,7 +34,7 @@
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.props" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.props" />
   </ImportGroup>
   <ImportGroup Label="PropertySheets">
     <Import Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" />
@@ -63,7 +63,7 @@
       <OutputFile>$(OutDir)/transpose.exe</OutputFile>
     </Link>
     <CudaCompile>
-      <CodeGeneration>compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
+      <CodeGeneration>compute_35,sm_35;compute_37,sm_37;compute_50,sm_50;compute_52,sm_52;compute_60,sm_60;compute_61,sm_61;compute_70,sm_70;compute_75,sm_75;compute_80,sm_80;compute_86,sm_86;compute_90,sm_90;</CodeGeneration>
       <AdditionalOptions>-Xcompiler "/wd 4819"  --threads 0 </AdditionalOptions>
       <Include>./;../../../Common</Include>
       <Defines>WIN32</Defines>
@@ -103,6 +103,6 @@
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
-    <Import Project="$(CUDAPropsPath)\CUDA 12.0.targets" />
+    <Import Project="$(CUDAPropsPath)\CUDA 11.8.targets" />
   </ImportGroup>
 </Project>
