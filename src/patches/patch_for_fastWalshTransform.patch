diff --git a/patch_gen.pyc b/patch_gen.pyc
index 25d41f4..d8cc456 100644
Binary files a/patch_gen.pyc and b/patch_gen.pyc differ
diff --git a/patch_gen2.pyc b/patch_gen2.pyc
index 57f9028..9899107 100644
Binary files a/patch_gen2.pyc and b/patch_gen2.pyc differ
diff --git a/patch_gen3.pyc b/patch_gen3.pyc
index 3e16c9e..8db8c43 100644
Binary files a/patch_gen3.pyc and b/patch_gen3.pyc differ
diff --git a/src/patches/extraneous_patches_v1.patch b/src/patches/extraneous_patches_v1.patch
old mode 100644
new mode 100755
diff --git a/src/patches/hipcheck_1_patch.patch b/src/patches/hipcheck_1_patch.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_BlackScholes.patch b/src/patches/patch_for_BlackScholes.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_MC_SingleAsianOption.patch b/src/patches/patch_for_MC_SingleAsianOption.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_NV12toBGRandResize.patch b/src/patches/patch_for_NV12toBGRandResize.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_SimpleSeperateCompilation_2.patch b/src/patches/patch_for_SimpleSeperateCompilation_2.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_SobelFilter_kernels.patch b/src/patches/patch_for_SobelFilter_kernels.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_UnifiedMemoryStreams.patch b/src/patches/patch_for_UnifiedMemoryStreams.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_UnifiedMemoryperf.patch b/src/patches/patch_for_UnifiedMemoryperf.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_alignedTypes.patch b/src/patches/patch_for_alignedTypes.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_asyncAPI_and_StreamProperties.patch b/src/patches/patch_for_asyncAPI_and_StreamProperties.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_baremetal_compilation.patch b/src/patches/patch_for_baremetal_compilation.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_binomialOptions.patch b/src/patches/patch_for_binomialOptions.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_clock.patch b/src/patches/patch_for_clock.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_concurrentKernels.patch b/src/patches/patch_for_concurrentKernels.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_concurrentKernels2.patch b/src/patches/patch_for_concurrentKernels2.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_cppIntegration.patch b/src/patches/patch_for_cppIntegration.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_dwtHaar1d.patch b/src/patches/patch_for_dwtHaar1d.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_eigenvalues.patch b/src/patches/patch_for_eigenvalues.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_fastWalshTransform.patch b/src/patches/patch_for_fastWalshTransform.patch
old mode 100644
new mode 100755
index 771a33f..e69de29
--- a/src/patches/patch_for_fastWalshTransform.patch
+++ b/src/patches/patch_for_fastWalshTransform.patch
@@ -1,30 +0,0 @@
-diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.cu.hip b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.cu.hip
-index c275ac0..8e90506 100644
---- a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.cu.hip
-+++ b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.cu.hip
-@@ -45,8 +45,8 @@
- #include "HIPCHECK.h"
- #include <stdlib.h>
- #include <string.h>
--#include <helper_functions.h>
--#include <helper_cuda.h>
-+#include "helper_functions.h"
-+#include "helper_cuda_hipified.h"
- 
- ////////////////////////////////////////////////////////////////////////////////
- // Reference CPU FWT
-diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_kernel.cuh b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_kernel.cuh
-index 4f64117..73f503e 100644
---- a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_kernel.cuh
-+++ b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_kernel.cuh
-@@ -30,8 +30,8 @@
- #ifndef fwt_kernel_cuh
- #define fwt_kernel_cuh
- 
--#include <cooperative_groups.h>
--
-+//#include <cooperative_groups.h>
-+#include <hip/hip_cooperative_groups.h>
- namespace cg = cooperative_groups;
- 
- ///////////////////////////////////////////////////////////////////////////////
diff --git a/src/patches/patch_for_fp16sp.patch b/src/patches/patch_for_fp16sp.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_hipcheck_2.patch b/src/patches/patch_for_hipcheck_2.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_histogram.patch b/src/patches/patch_for_histogram.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_initial_compilation.patch b/src/patches/patch_for_initial_compilation.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_interval.patch b/src/patches/patch_for_interval.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_jacobiCudaGraphs.patch b/src/patches/patch_for_jacobiCudaGraphs.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_mergesort.patch b/src/patches/patch_for_mergesort.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_printf.patch b/src/patches/patch_for_printf.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_quasirandomGenerator.patch b/src/patches/patch_for_quasirandomGenerator.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_scalarProd.patch b/src/patches/patch_for_scalarProd.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_scan.patch b/src/patches/patch_for_scan.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simpleAtomicIntrinsics.patch b/src/patches/patch_for_simpleAtomicIntrinsics.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simpleCallback.patch b/src/patches/patch_for_simpleCallback.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simpleCubemapTexture.patch b/src/patches/patch_for_simpleCubemapTexture.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simpleCudaGraphs.patch b/src/patches/patch_for_simpleCudaGraphs.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simpleCudaGraphs1.patch b/src/patches/patch_for_simpleCudaGraphs1.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simpleHyperQ.patch b/src/patches/patch_for_simpleHyperQ.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simpleLayeredTexture.patch b/src/patches/patch_for_simpleLayeredTexture.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simpleMultiCopy.patch b/src/patches/patch_for_simpleMultiCopy.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simpleMultiGPU.patch b/src/patches/patch_for_simpleMultiGPU.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simplePitchLinearTexture.patch b/src/patches/patch_for_simplePitchLinearTexture.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simpleSeperateCompilation.patch b/src/patches/patch_for_simpleSeperateCompilation.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simpleStreams.patch b/src/patches/patch_for_simpleStreams.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simpleSurfaceWrite.patch b/src/patches/patch_for_simpleSurfaceWrite.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simpleTemplates.patch b/src/patches/patch_for_simpleTemplates.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simpleTexture.patch b/src/patches/patch_for_simpleTexture.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_simpleZeroCopy.patch b/src/patches/patch_for_simpleZeroCopy.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_ssc.patch b/src/patches/patch_for_ssc.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_streamOrderedAllocation.patch b/src/patches/patch_for_streamOrderedAllocation.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_streamOrderedAllocationP2P.patch b/src/patches/patch_for_streamOrderedAllocationP2P.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_systemWideAtomics.patch b/src/patches/patch_for_systemWideAtomics.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_templates.patch b/src/patches/patch_for_templates.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_threadFenceReduction.patch b/src/patches/patch_for_threadFenceReduction.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_threadMigration.patch b/src/patches/patch_for_threadMigration.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patch_for_transpose.patch b/src/patches/patch_for_transpose.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patches_by_sir_2.patch b/src/patches/patches_by_sir_2.patch
old mode 100644
new mode 100755
diff --git a/src/patches/patchforBlackScholes.patch b/src/patches/patchforBlackScholes.patch
old mode 100644
new mode 100755
diff --git a/src/samples/Common/Brig.h b/src/samples/Common/Brig.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/GL/freeglut.h b/src/samples/Common/GL/freeglut.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/GL/freeglut_ext.h b/src/samples/Common/GL/freeglut_ext.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/GL/freeglut_std.h b/src/samples/Common/GL/freeglut_std.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/GL/glew.h b/src/samples/Common/GL/glew.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/GL/glext.h b/src/samples/Common/GL/glext.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/GL/glut.h b/src/samples/Common/GL/glut.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/GL/glxew.h b/src/samples/Common/GL/glxew.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/GL/glxext.h b/src/samples/Common/GL/glxext.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/GL/wglew.h b/src/samples/Common/GL/wglew.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/GL/wglext.h b/src/samples/Common/GL/wglext.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/HIPCHECK.h b/src/samples/Common/HIPCHECK.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/UtilNPP/Exceptions.h b/src/samples/Common/UtilNPP/Exceptions.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/UtilNPP/Image.h b/src/samples/Common/UtilNPP/Image.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/UtilNPP/ImageAllocatorsCPU.h b/src/samples/Common/UtilNPP/ImageAllocatorsCPU.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/UtilNPP/ImageAllocatorsNPP.h b/src/samples/Common/UtilNPP/ImageAllocatorsNPP.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/UtilNPP/ImageIO.h b/src/samples/Common/UtilNPP/ImageIO.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/UtilNPP/ImagePacked.h b/src/samples/Common/UtilNPP/ImagePacked.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/UtilNPP/ImagesCPU.h b/src/samples/Common/UtilNPP/ImagesCPU.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/UtilNPP/ImagesNPP.h b/src/samples/Common/UtilNPP/ImagesNPP.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/UtilNPP/Pixel.h b/src/samples/Common/UtilNPP/Pixel.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/UtilNPP/Signal.h b/src/samples/Common/UtilNPP/Signal.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/UtilNPP/SignalAllocatorsCPU.h b/src/samples/Common/UtilNPP/SignalAllocatorsCPU.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/UtilNPP/SignalAllocatorsNPP.h b/src/samples/Common/UtilNPP/SignalAllocatorsNPP.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/UtilNPP/SignalsCPU.h b/src/samples/Common/UtilNPP/SignalsCPU.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/UtilNPP/SignalsNPP.h b/src/samples/Common/UtilNPP/SignalsNPP.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/amd_hsa_common.h b/src/samples/Common/amd_hsa_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/amd_hsa_elf.h b/src/samples/Common/amd_hsa_elf.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/amd_hsa_kernel_code.h b/src/samples/Common/amd_hsa_kernel_code.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/amd_hsa_queue.h b/src/samples/Common/amd_hsa_queue.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/amd_hsa_signal.h b/src/samples/Common/amd_hsa_signal.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/data/CT_skull_512x512_8u.raw b/src/samples/Common/data/CT_skull_512x512_8u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Common/data/CT_skull_512x512_8u_Gray.raw b/src/samples/Common/data/CT_skull_512x512_8u_Gray.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Common/data/PCB2_1024x683_8u.raw b/src/samples/Common/data/PCB2_1024x683_8u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Common/data/PCB_1280x720_8u.raw b/src/samples/Common/data/PCB_1280x720_8u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Common/data/PCB_METAL_509x335_8u.raw b/src/samples/Common/data/PCB_METAL_509x335_8u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Common/data/Rocks_512x512_8u_Gray.raw b/src/samples/Common/data/Rocks_512x512_8u_Gray.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Common/data/teapot512.pgm b/src/samples/Common/data/teapot512.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Common/data/teapot_512x512_8u.raw b/src/samples/Common/data/teapot_512x512_8u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Common/data/teapot_512x512_8u_Gray.raw b/src/samples/Common/data/teapot_512x512_8u_Gray.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Common/drvapi_error_string.h b/src/samples/Common/drvapi_error_string.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/dynlink_d3d10.h b/src/samples/Common/dynlink_d3d10.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/dynlink_d3d11.h b/src/samples/Common/dynlink_d3d11.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/exception.h b/src/samples/Common/exception.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/helper_cuda-hipified.h b/src/samples/Common/helper_cuda-hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/helper_cuda.h b/src/samples/Common/helper_cuda.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/helper_cuda_drvapi.h b/src/samples/Common/helper_cuda_drvapi.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/helper_cuda_hipified.h b/src/samples/Common/helper_cuda_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/helper_cusolver.h b/src/samples/Common/helper_cusolver.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/helper_functions.h b/src/samples/Common/helper_functions.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/helper_gl.h b/src/samples/Common/helper_gl.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/helper_image.h b/src/samples/Common/helper_image.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/helper_math.h b/src/samples/Common/helper_math.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/helper_multiprocess.cpp b/src/samples/Common/helper_multiprocess.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Common/helper_multiprocess.h b/src/samples/Common/helper_multiprocess.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/helper_nvJPEG.hxx b/src/samples/Common/helper_nvJPEG.hxx
old mode 100644
new mode 100755
diff --git a/src/samples/Common/helper_string.h b/src/samples/Common/helper_string.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/helper_timer.h b/src/samples/Common/helper_timer.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/hsa.h b/src/samples/Common/hsa.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/hsa_api_trace.h b/src/samples/Common/hsa_api_trace.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/hsa_ext_amd.h b/src/samples/Common/hsa_ext_amd.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/hsa_ext_finalize.h b/src/samples/Common/hsa_ext_finalize.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/hsa_ext_image.h b/src/samples/Common/hsa_ext_image.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/hsa_ven_amd_aqlprofile.h b/src/samples/Common/hsa_ven_amd_aqlprofile.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/hsa_ven_amd_loader.h b/src/samples/Common/hsa_ven_amd_loader.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/lib/x64/freeglut.lib b/src/samples/Common/lib/x64/freeglut.lib
old mode 100644
new mode 100755
diff --git a/src/samples/Common/lib/x64/glew64.lib b/src/samples/Common/lib/x64/glew64.lib
old mode 100644
new mode 100755
diff --git a/src/samples/Common/multithreading.cpp b/src/samples/Common/multithreading.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Common/multithreading.h b/src/samples/Common/multithreading.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/nvMath.h b/src/samples/Common/nvMath.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/nvMatrix.h b/src/samples/Common/nvMatrix.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/nvQuaternion.h b/src/samples/Common/nvQuaternion.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/nvShaderUtils.h b/src/samples/Common/nvShaderUtils.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/nvVector.h b/src/samples/Common/nvVector.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/nvrtc_helper.h b/src/samples/Common/nvrtc_helper.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/param.h b/src/samples/Common/param.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/paramgl.h b/src/samples/Common/paramgl.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/rendercheck_d3d10.cpp b/src/samples/Common/rendercheck_d3d10.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Common/rendercheck_d3d10.h b/src/samples/Common/rendercheck_d3d10.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/rendercheck_d3d11.cpp b/src/samples/Common/rendercheck_d3d11.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Common/rendercheck_d3d11.h b/src/samples/Common/rendercheck_d3d11.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/rendercheck_d3d9.cpp b/src/samples/Common/rendercheck_d3d9.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Common/rendercheck_d3d9.h b/src/samples/Common/rendercheck_d3d9.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/rendercheck_gl.h b/src/samples/Common/rendercheck_gl.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/rendercheck_gles.h b/src/samples/Common/rendercheck_gles.h
old mode 100644
new mode 100755
diff --git a/src/samples/Common/rocprofiler.h b/src/samples/Common/rocprofiler.h
old mode 100644
new mode 100755
diff --git a/src/samples/Makefile b/src/samples/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/README.md b/src/samples/Samples/0_Introduction/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/.vscode/extensions.json b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/.vscode/launch.json b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/.vscode/tasks.json b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/Makefile b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/NsightEclipse.xml b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/README.md b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu.hip b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu.hip
old mode 100644
new mode 100755
index a6ee415..879287e
--- a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu.hip
+++ b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams.cu.hip
@@ -43,10 +43,13 @@
 #include <stdlib.h>
 
 // cuBLAS
-#include <hipblas.h>
+#include <hipblas/hipblas.h>
 
 // utilities
 #include "helper_cuda_hipified.h"
+#include "hip/hip_runtime.h"
+#include "hip/hip_runtime_api.h"
+#include "HIPCHECK.h"
 
 #if defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64)
 // SRAND48 and DRAND48 don't exist on windows, but these are the equivalent
@@ -210,7 +213,7 @@ void execute(Task<T> &t, hipblasHandle_t *handle, hipStream_t *stream,
     double zero = 0.0;
 
     // attach managed memory to my stream
-    HIPCHECK(hipblasSetStream(handle[tid + 1], stream[tid + 1]));
+    //HIPCHECK(hipblasSetStream(handle[tid + 1], stream[tid + 1]));
     HIPCHECK(hipStreamAttachMemAsync(stream[tid + 1], t.data, 0,
                                              hipMemAttachSingle));
     HIPCHECK(hipStreamAttachMemAsync(stream[tid + 1], t.vector, 0,
@@ -218,10 +221,11 @@ void execute(Task<T> &t, hipblasHandle_t *handle, hipStream_t *stream,
     HIPCHECK(hipStreamAttachMemAsync(stream[tid + 1], t.result, 0,
                                              hipMemAttachSingle));
     // call the device operation
-    HIPCHECK(hipblasDgemv(handle[tid + 1], HIPBLAS_OP_N, t.size, t.size,
+    /*HIPCHECK(hipblasDgemv(handle[tid + 1], HIPBLAS_OP_N, t.size, t.size,
                                 &one, t.data, t.size, t.vector, 1, &zero,
-                                t.result, 1));
+                                t.result, 1));*/
   }
+
 }
 #endif
 
@@ -271,7 +275,7 @@ int main(int argc, char **argv) {
 
   for (int i = 0; i < nthreads + 1; i++) {
     HIPCHECK(hipStreamCreate(&streams[i]));
-    HIPCHECK(hipblasCreate(&handles[i]));
+    //HIPCHECK(hipblasCreate(&handles[i]));
   }
 
   // create list of N tasks
@@ -330,7 +334,7 @@ int main(int argc, char **argv) {
   // Destroy CUDA Streams, cuBlas handles
   for (int i = 0; i < nthreads + 1; i++) {
     hipStreamDestroy(streams[i]);
-    hipblasDestroy(handles[i]);
+    //hipblasDestroy(handles[i]);
   }
 
   // Free TaskList
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2017.sln b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2017.vcxproj b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2019.sln b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2019.vcxproj b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2022.sln b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2022.vcxproj b/src/samples/Samples/0_Introduction/UnifiedMemoryStreams/UnifiedMemoryStreams_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/asyncAPI/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/.vscode/extensions.json b/src/samples/Samples/0_Introduction/asyncAPI/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/.vscode/launch.json b/src/samples/Samples/0_Introduction/asyncAPI/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/.vscode/tasks.json b/src/samples/Samples/0_Introduction/asyncAPI/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/Makefile b/src/samples/Samples/0_Introduction/asyncAPI/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/NsightEclipse.xml b/src/samples/Samples/0_Introduction/asyncAPI/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/README.md b/src/samples/Samples/0_Introduction/asyncAPI/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI.cu b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI.cu.hip b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI.cu.hip
old mode 100644
new mode 100755
index 961637b..e69de29
--- a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI.cu.hip
+++ b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI.cu.hip
@@ -1,145 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This sample illustrates the usage of CUDA events for both GPU timing and
- * overlapping CPU and GPU execution.  Events are inserted into a stream
- * of CUDA calls.  Since CUDA stream calls are asynchronous, the CPU can
- * perform computations while GPU is executing (including DMA memcopies
- * between the host and device).  CPU can query CUDA events to determine
- * whether GPU has completed tasks.
- */
-
-// includes, system
-#include <stdio.h>
-//#include "rocprofiler.h"
-#include "HIPCHECK.h"
-
-// includes CUDA Runtime
-#include <hip/hip_runtime.h>
-#include <hip/hip_runtime_api.h>
-
-// includes, project
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"  // helper utility functions
-
-__global__ void increment_kernel(int *g_data, int inc_value) {
-  int idx = blockIdx.x * blockDim.x + threadIdx.x;
-  g_data[idx] = g_data[idx] + inc_value;
-}
-
-bool correct_output(int *data, const int n, const int x) {
-  for (int i = 0; i < n; i++)
-    if (data[i] != x) {
-      printf("Error! data[%d] = %d, ref = %d\n", i, data[i], x);
-      return false;
-    }
-
-  return true;
-}
-
-int main(int argc, char *argv[]) {
-  int devID;
-  hipDeviceProp_t deviceProps;
-
-  printf("[%s] - Starting...\n", argv[0]);
-
-  // This will pick the best possible CUDA capable device
-  devID = findCudaDevice(argc, (const char **)argv);
-
-  // get device name
-  HIPCHECK(hipGetDeviceProperties(&deviceProps, devID));
-  printf("CUDA device [%s]\n", deviceProps.name);
-
-  int n = 16 * 1024 * 1024;
-  int nbytes = n * sizeof(int);
-  int value = 26;
-
-  // allocate host memory
-  int *a = 0;
-  HIPCHECK(hipHostMalloc((void **)&a, nbytes));
-  memset(a, 0, nbytes);
-
-  // allocate device memory
-  int *d_a = 0;
-  HIPCHECK(hipMalloc((void **)&d_a, nbytes));
-  HIPCHECK(hipMemset(d_a, 255, nbytes));
-
-  // set kernel launch configuration
-  dim3 threads = dim3(512, 1);
-  dim3 blocks = dim3(n / threads.x, 1);
-
-  // create cuda event handles
-  hipEvent_t start, stop;
-  HIPCHECK(hipEventCreate(&start));
-  HIPCHECK(hipEventCreate(&stop));
-
-  StopWatchInterface *timer = NULL;
-  sdkCreateTimer(&timer);
-  sdkResetTimer(&timer);
-
-  HIPCHECK(hipDeviceSynchronize());
-  float gpu_time = 0.0f;
-
-  // asynchronously issue work to the GPU (all to stream 0)
-  HIPCHECK(hipProfilerStart());
-  sdkStartTimer(&timer);
-  hipEventRecord(start, 0);
-  hipMemcpyAsync(d_a, a, nbytes, hipMemcpyHostToDevice, 0);
-  increment_kernel<<<blocks, threads, 0, 0>>>(d_a, value);
-  hipMemcpyAsync(a, d_a, nbytes, hipMemcpyDeviceToHost, 0);
-  hipEventRecord(stop, 0);
-  sdkStopTimer(&timer);
-  HIPCHECK(hipProfilerStop());
-
-  // have CPU do some work while waiting for stage 1 to finish
-  unsigned long int counter = 0;
-
-  while (hipEventQuery(stop) == hipErrorNotReady) {
-    counter++;
-  }
-
-  HIPCHECK(hipEventElapsedTime(&gpu_time, start, stop));
-
-  // print the cpu and gpu times
-  printf("time spent executing by the GPU: %.2f\n", gpu_time);
-  printf("time spent by CPU in CUDA calls: %.2f\n", sdkGetTimerValue(&timer));
-  printf("CPU executed %lu iterations while waiting for GPU to finish\n",
-         counter);
-
-  // check the output for correctness
-  bool bFinalResults = correct_output(a, n, value);
-
-  // release resources
-  HIPCHECK(hipEventDestroy(start));
-  HIPCHECK(hipEventDestroy(stop));
-  HIPCHECK(hipHostFree(a));
-  HIPCHECK(hipFree(d_a));
-
-  exit(bFinalResults ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI.out b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2017.sln b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2017.vcxproj b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2019.sln b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2019.vcxproj b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2022.sln b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2022.vcxproj b/src/samples/Samples/0_Introduction/asyncAPI/asyncAPI_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/c++11_cuda/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/.vscode/extensions.json b/src/samples/Samples/0_Introduction/c++11_cuda/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/.vscode/launch.json b/src/samples/Samples/0_Introduction/c++11_cuda/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/.vscode/tasks.json b/src/samples/Samples/0_Introduction/c++11_cuda/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/Makefile b/src/samples/Samples/0_Introduction/c++11_cuda/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/NsightEclipse.xml b/src/samples/Samples/0_Introduction/c++11_cuda/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/README.md b/src/samples/Samples/0_Introduction/c++11_cuda/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda.cu b/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda.cu.hip b/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda.cu.hip
old mode 100644
new mode 100755
index 4584896..e69de29
--- a/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda.cu.hip
+++ b/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda.cu.hip
@@ -1,141 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <thrust/device_ptr.h>
-#include <thrust/count.h>
-#include <thrust/execution_policy.h>
-
-#include <iostream>
-#include "helper_cuda_hipified.h"
-
-/////////////////////////////////////////////////////////////////
-// Some utility code to define grid_stride_range
-// Normally this would be in a header but it's here
-// for didactic purposes. Uses
-#include "range.hpp"
-using namespace util::lang;
-
-// type alias to simplify typing...
-template <typename T>
-using step_range = typename range_proxy<T>::step_range_proxy;
-
-template <typename T>
-__device__ step_range<T> grid_stride_range(T begin, T end) {
-  begin += blockDim.x * blockIdx.x + threadIdx.x;
-  return range(begin, end).step(gridDim.x * blockDim.x);
-}
-/////////////////////////////////////////////////////////////////
-
-template <typename T, typename Predicate>
-__device__ void count_if(int *count, T *data, int n, Predicate p) {
-  for (auto i : grid_stride_range(0, n)) {
-    if (p(data[i])) atomicAdd(count, 1);
-  }
-}
-
-// Use count_if with a lambda function that searches for x, y, z or w
-// Note the use of range-based for loop and initializer_list inside the functor
-// We use auto so we don't have to know the type of the functor or array
-__global__ void xyzw_frequency(int *count, char *text, int n) {
-  const char letters[]{'x', 'y', 'z', 'w'};
-
-  count_if(count, text, n, [&](char c) {
-    for (const auto x : letters)
-      if (c == x) return true;
-    return false;
-  });
-}
-
-__global__ void xyzw_frequency_thrust_device(int *count, char *text, int n) {
-  const char letters[]{'x', 'y', 'z', 'w'};
-  *count = thrust::count_if(thrust::device, text, text + n, [=](char c) {
-    for (const auto x : letters)
-      if (c == x) return true;
-    return false;
-  });
-}
-
-// a bug in Thrust 1.8 causes warnings when this is uncommented
-// so commented out by default -- fixed in Thrust master branch
-#if 0 
-void xyzw_frequency_thrust_host(int *count, char *text, int n)
-{
-  const char letters[] { 'x','y','z','w' };
-  *count = thrust::count_if(thrust::host, text, text+n, [&](char c) {
-    for (const auto x : letters) 
-      if (c == x) return true;
-    return false;
-  });
-}
-#endif
-
-int main(int argc, char **argv) {
-  const char *filename = sdkFindFilePath("warandpeace.txt", argv[0]);
-
-  int numBytes = 16 * 1048576;
-  char *h_text = (char *)malloc(numBytes);
-
-  // find first CUDA device
-  int devID = findCudaDevice(argc, (const char **)argv);
-
-  char *d_text;
-  HIPCHECK(hipMalloc((void **)&d_text, numBytes));
-
-  FILE *fp = fopen(filename, "r");
-  if (fp == NULL) {
-    printf("Cannot find the input text file\n. Exiting..\n");
-    return EXIT_FAILURE;
-  }
-  int len = (int)fread(h_text, sizeof(char), numBytes, fp);
-  fclose(fp);
-  std::cout << "Read " << len << " byte corpus from " << filename << std::endl;
-
-  HIPCHECK(hipMemcpy(d_text, h_text, len, hipMemcpyHostToDevice));
-
-  int count = 0;
-  int *d_count;
-  HIPCHECK(hipMalloc(&d_count, sizeof(int)));
-  HIPCHECK(hipMemset(d_count, 0, sizeof(int)));
-
-  // Try uncommenting one kernel call at a time
-  xyzw_frequency<<<8, 256>>>(d_count, d_text, len);
-  xyzw_frequency_thrust_device<<<1, 1>>>(d_count, d_text, len);
-  HIPCHECK(
-      hipMemcpy(&count, d_count, sizeof(int), hipMemcpyDeviceToHost));
-
-  // xyzw_frequency_thrust_host(&count, h_text, len);
-
-  std::cout << "counted " << count
-            << " instances of 'x', 'y', 'z', or 'w' in \"" << filename << "\""
-            << std::endl;
-
-  HIPCHECK(hipFree(d_count));
-  HIPCHECK(hipFree(d_text));
-
-  return EXIT_SUCCESS;
-}
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2017.sln b/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2017.vcxproj b/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2019.sln b/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2019.vcxproj b/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2022.sln b/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2022.vcxproj b/src/samples/Samples/0_Introduction/c++11_cuda/c++11_cuda_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/range.hpp b/src/samples/Samples/0_Introduction/c++11_cuda/range.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/c++11_cuda/warandpeace.txt b/src/samples/Samples/0_Introduction/c++11_cuda/warandpeace.txt
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/clock/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock/.vscode/extensions.json b/src/samples/Samples/0_Introduction/clock/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock/.vscode/launch.json b/src/samples/Samples/0_Introduction/clock/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock/.vscode/tasks.json b/src/samples/Samples/0_Introduction/clock/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock/Makefile b/src/samples/Samples/0_Introduction/clock/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock/NsightEclipse.xml b/src/samples/Samples/0_Introduction/clock/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock/README.md b/src/samples/Samples/0_Introduction/clock/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock/clock.cu b/src/samples/Samples/0_Introduction/clock/clock.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock/clock.cu.hip b/src/samples/Samples/0_Introduction/clock/clock.cu.hip
old mode 100644
new mode 100755
index d60759e..e69de29
--- a/src/samples/Samples/0_Introduction/clock/clock.cu.hip
+++ b/src/samples/Samples/0_Introduction/clock/clock.cu.hip
@@ -1,156 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This example shows how to use the clock function to measure the performance
- * of block of threads of a kernel accurately. Blocks are executed in parallel
- * and out of order. Since there's no synchronization mechanism between blocks,
- * we measure the clock once for each block. The clock samples are written to
- * device memory.
- */
-
-// System includes
-#include <assert.h>
-#include <stdint.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-
-// CUDA runtime
-#include <hip/hip_runtime.h>
-
-// helper functions and utilities to work with CUDA
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"
-
-// This kernel computes a standard parallel reduction and evaluates the
-// time it takes to do that for each block. The timing results are stored
-// in device memory.
-__global__ static void timedReduction(const float *input, float *output,
-                                      clock_t *timer) {
-  // __shared__ float shared[2 * blockDim.x];
-  extern __shared__ float shared[];
-
-  const int tid = threadIdx.x;
-  const int bid = blockIdx.x;
-
-  if (tid == 0) timer[bid] = clock();
-
-  // Copy input.
-  shared[tid] = input[tid];
-  shared[tid + blockDim.x] = input[tid + blockDim.x];
-
-  // Perform reduction to find minimum.
-  for (int d = blockDim.x; d > 0; d /= 2) {
-    __syncthreads();
-
-    if (tid < d) {
-      float f0 = shared[tid];
-      float f1 = shared[tid + d];
-
-      if (f1 < f0) {
-        shared[tid] = f1;
-      }
-    }
-  }
-
-  // Write result.
-  if (tid == 0) output[bid] = shared[0];
-
-  __syncthreads();
-
-  if (tid == 0) timer[bid + gridDim.x] = clock();
-}
-
-#define NUM_BLOCKS 64
-#define NUM_THREADS 256
-
-// It's interesting to change the number of blocks and the number of threads to
-// understand how to keep the hardware busy.
-//
-// Here are some numbers I get on my G80:
-//    blocks - clocks
-//    1 - 3096
-//    8 - 3232
-//    16 - 3364
-//    32 - 4615
-//    64 - 9981
-//
-// With less than 16 blocks some of the multiprocessors of the device are idle.
-// With more than 16 you are using all the multiprocessors, but there's only one
-// block per multiprocessor and that doesn't allow you to hide the latency of
-// the memory. With more than 32 the speed scales linearly.
-
-// Start the main CUDA Sample here
-int main(int argc, char **argv) {
-  printf("CUDA Clock sample\n");
-
-  // This will pick the best possible CUDA capable device
-  int dev = findCudaDevice(argc, (const char **)argv);
-
-  float *dinput = NULL;
-  float *doutput = NULL;
-  clock_t *dtimer = NULL;
-
-  clock_t timer[NUM_BLOCKS * 2];
-  float input[NUM_THREADS * 2];
-
-  for (int i = 0; i < NUM_THREADS * 2; i++) {
-    input[i] = (float)i;
-  }
-
-  HIPCHECK(
-      hipMalloc((void **)&dinput, sizeof(float) * NUM_THREADS * 2));
-  HIPCHECK(hipMalloc((void **)&doutput, sizeof(float) * NUM_BLOCKS));
-  HIPCHECK(
-      hipMalloc((void **)&dtimer, sizeof(clock_t) * NUM_BLOCKS * 2));
-
-  HIPCHECK(hipMemcpy(dinput, input, sizeof(float) * NUM_THREADS * 2,
-                             hipMemcpyHostToDevice));
-
-  timedReduction<<<NUM_BLOCKS, NUM_THREADS, sizeof(float) * 2 * NUM_THREADS>>>(
-      dinput, doutput, dtimer);
-
-  HIPCHECK(hipMemcpy(timer, dtimer, sizeof(clock_t) * NUM_BLOCKS * 2,
-                             hipMemcpyDeviceToHost));
-
-  HIPCHECK(hipFree(dinput));
-  HIPCHECK(hipFree(doutput));
-  HIPCHECK(hipFree(dtimer));
-
-  long double avgElapsedClocks = 0;
-
-  for (int i = 0; i < NUM_BLOCKS; i++) {
-    avgElapsedClocks += (long double)(timer[i + NUM_BLOCKS] - timer[i]);
-  }
-
-  avgElapsedClocks = avgElapsedClocks / NUM_BLOCKS;
-  printf("Average clocks/block = %Lf\n", avgElapsedClocks);
-
-  return EXIT_SUCCESS;
-}
diff --git a/src/samples/Samples/0_Introduction/clock/clock.out b/src/samples/Samples/0_Introduction/clock/clock.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock/clock_vs2017.sln b/src/samples/Samples/0_Introduction/clock/clock_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock/clock_vs2017.vcxproj b/src/samples/Samples/0_Introduction/clock/clock_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock/clock_vs2019.sln b/src/samples/Samples/0_Introduction/clock/clock_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock/clock_vs2019.vcxproj b/src/samples/Samples/0_Introduction/clock/clock_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock/clock_vs2022.sln b/src/samples/Samples/0_Introduction/clock/clock_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock/clock_vs2022.vcxproj b/src/samples/Samples/0_Introduction/clock/clock_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/clock_nvrtc/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/.vscode/extensions.json b/src/samples/Samples/0_Introduction/clock_nvrtc/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/.vscode/launch.json b/src/samples/Samples/0_Introduction/clock_nvrtc/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/.vscode/tasks.json b/src/samples/Samples/0_Introduction/clock_nvrtc/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/Makefile b/src/samples/Samples/0_Introduction/clock_nvrtc/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/README.md b/src/samples/Samples/0_Introduction/clock_nvrtc/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/clock.cpp b/src/samples/Samples/0_Introduction/clock_nvrtc/clock.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_hipified.cpp b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_kernel.cu b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_kernel.cu.hip b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_kernel.cu.hip
old mode 100644
new mode 100755
index 4ded7b0..e69de29
--- a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_kernel.cu.hip
@@ -1,75 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This example shows how to use the clock function to measure the performance
- * of block of threads of a kernel accurately. Blocks are executed in parallel
- * and out of order. Since there's no synchronization mechanism between blocks,
- * we measure the clock once for each block. The clock samples are written to
- * device memory.
- */
-
-// This kernel computes a standard parallel reduction and evaluates the
-// time it takes to do that for each block. The timing results are stored
-// in device memory.
-
-extern "C" __global__ void timedReduction(const float *input, float *output,
-                                          clock_t *timer) {
-  // __shared__ float shared[2 * blockDim.x];
-  extern __shared__ float shared[];
-
-  const int tid = threadIdx.x;
-  const int bid = blockIdx.x;
-
-  if (tid == 0) timer[bid] = clock();
-
-  // Copy input.
-  shared[tid] = input[tid];
-  shared[tid + blockDim.x] = input[tid + blockDim.x];
-
-  // Perform reduction to find minimum.
-  for (int d = blockDim.x; d > 0; d /= 2) {
-    __syncthreads();
-
-    if (tid < d) {
-      float f0 = shared[tid];
-      float f1 = shared[tid + d];
-
-      if (f1 < f0) {
-        shared[tid] = f1;
-      }
-    }
-  }
-
-  // Write result.
-  if (tid == 0) output[bid] = shared[0];
-
-  __syncthreads();
-
-  if (tid == 0) timer[bid + gridDim.x] = clock();
-}
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2017.sln b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2017.vcxproj b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2019.sln b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2019.vcxproj b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2022.sln b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2022.vcxproj b/src/samples/Samples/0_Introduction/clock_nvrtc/clock_nvrtc_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/concurrentKernels/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/.vscode/extensions.json b/src/samples/Samples/0_Introduction/concurrentKernels/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/.vscode/launch.json b/src/samples/Samples/0_Introduction/concurrentKernels/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/.vscode/tasks.json b/src/samples/Samples/0_Introduction/concurrentKernels/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/Makefile b/src/samples/Samples/0_Introduction/concurrentKernels/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/NsightEclipse.xml b/src/samples/Samples/0_Introduction/concurrentKernels/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/README.md b/src/samples/Samples/0_Introduction/concurrentKernels/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.cu b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.cu.hip b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.cu.hip
old mode 100644
new mode 100755
index 73b1cd7..e69de29
--- a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.cu.hip
+++ b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.cu.hip
@@ -1,231 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-//
-// This sample demonstrates the use of streams for concurrent execution. It also
-// illustrates how to introduce dependencies between CUDA streams with the
-// hipStreamWaitEvent function.
-//
-
-// Devices of compute capability 2.0 or higher can overlap the kernels
-//
-#include <hip/hip_cooperative_groups.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-
-namespace cg = cooperative_groups;
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"
-
-// This is a kernel that does no real work but runs at least for a specified
-// number of clocks
-__global__ void clock_block(clock_t *d_o, clock_t clock_count) {
-  unsigned int start_clock = (unsigned int)clock();
-
-  clock_t clock_offset = 0;
-
-  while (clock_offset < clock_count) {
-    unsigned int end_clock = (unsigned int)clock();
-
-    // The code below should work like
-    // this (thanks to modular arithmetics):
-    //
-    // clock_offset = (clock_t) (end_clock > start_clock ?
-    //                           end_clock - start_clock :
-    //                           end_clock + (0xffffffffu - start_clock));
-    //
-    // Indeed, let m = 2^32 then
-    // end - start = end + m - start (mod m).
-
-    clock_offset = (clock_t)(end_clock - start_clock);
-  }
-
-  d_o[0] = clock_offset;
-}
-
-// Single warp reduction kernel
-__global__ void sum(clock_t *d_clocks, int N) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  __shared__ clock_t s_clocks[32];
-
-  clock_t my_sum = 0;
-
-  for (int i = threadIdx.x; i < N; i += blockDim.x) {
-    my_sum += d_clocks[i];
-  }
-
-  s_clocks[threadIdx.x] = my_sum;
-  cg::sync(cta);
-
-  for (int i = 16; i > 0; i /= 2) {
-    if (threadIdx.x < i) {
-      s_clocks[threadIdx.x] += s_clocks[threadIdx.x + i];
-    }
-
-    cg::sync(cta);
-  }
-
-  d_clocks[0] = s_clocks[0];
-}
-
-int main(int argc, char **argv) {
-  int nkernels = 8;             // number of concurrent kernels
-  int nstreams = nkernels + 1;  // use one more stream than concurrent kernel
-  int nbytes = nkernels * sizeof(clock_t);  // number of data bytes
-  float kernel_time = 10;                   // time the kernel should run in ms
-  float elapsed_time;                       // timing variables
-  int cuda_device = 0;
-
-  printf("[%s] - Starting...\n", argv[0]);
-
-  // get number of kernels if overridden on the command line
-  if (checkCmdLineFlag(argc, (const char **)argv, "nkernels")) {
-    nkernels = getCmdLineArgumentInt(argc, (const char **)argv, "nkernels");
-    nstreams = nkernels + 1;
-  }
-
-  // use command-line specified CUDA device, otherwise use device with highest
-  // Gflops/s
-  cuda_device = findCudaDevice(argc, (const char **)argv);
-
-  hipDeviceProp_t deviceProp;
-  HIPCHECK(hipGetDevice(&cuda_device));
-
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, cuda_device));
-
-  if ((deviceProp.concurrentKernels == 0)) {
-    printf("> GPU does not support concurrent kernel execution\n");
-    printf("  CUDA kernel runs will be serialized\n");
-  }
-
-  printf("> Detected Compute SM %d.%d hardware with %d multi-processors\n",
-         deviceProp.major, deviceProp.minor, deviceProp.multiProcessorCount);
-
-  // allocate host memory
-  clock_t *a = 0;  // pointer to the array data in host memory
-  HIPCHECK(hipHostMalloc((void **)&a, nbytes));
-
-  // allocate device memory
-  clock_t *d_a = 0;  // pointers to data and init value in the device memory
-  HIPCHECK(hipMalloc((void **)&d_a, nbytes));
-
-  // allocate and initialize an array of stream handles
-  hipStream_t *streams =
-      (hipStream_t *)malloc(nstreams * sizeof(hipStream_t));
-
-  for (int i = 0; i < nstreams; i++) {
-    HIPCHECK(hipStreamCreate(&(streams[i])));
-  }
-
-  // create CUDA event handles
-  hipEvent_t start_event, stop_event;
-  HIPCHECK(hipEventCreate(&start_event));
-  HIPCHECK(hipEventCreate(&stop_event));
-
-  // the events are used for synchronization only and hence do not need to
-  // record timings this also makes events not introduce global sync points when
-  // recorded which is critical to get overlap
-  hipEvent_t *kernelEvent;
-  kernelEvent = (hipEvent_t *)malloc(nkernels * sizeof(hipEvent_t));
-
-  for (int i = 0; i < nkernels; i++) {
-    HIPCHECK(
-        hipEventCreateWithFlags(&(kernelEvent[i]), hipEventDisableTiming));
-  }
-
-  //////////////////////////////////////////////////////////////////////
-  // time execution with nkernels streams
-  clock_t total_clocks = 0;
-#if defined(__arm__) || defined(__aarch64__)
-  // the kernel takes more time than the channel reset time on arm archs, so to
-  // prevent hangs reduce time_clocks.
-  clock_t time_clocks = (clock_t)(kernel_time * (deviceProp.clockRate / 100));
-#else
-  clock_t time_clocks = (clock_t)(kernel_time * deviceProp.clockRate);
-#endif
-
-  hipEventRecord(start_event, 0);
-
-  // queue nkernels in separate streams and record when they are done
-  for (int i = 0; i < nkernels; ++i) {
-    clock_block<<<1, 1, 0, streams[i]>>>(&d_a[i], time_clocks);
-    total_clocks += time_clocks;
-    HIPCHECK(hipEventRecord(kernelEvent[i], streams[i]));
-
-    // make the last stream wait for the kernel event to be recorded
-    HIPCHECK(
-        hipStreamWaitEvent(streams[nstreams - 1], kernelEvent[i], 0));
-  }
-
-  // queue a sum kernel and a copy back to host in the last stream.
-  // the commands in this stream get dispatched as soon as all the kernel events
-  // have been recorded
-  sum<<<1, 32, 0, streams[nstreams - 1]>>>(d_a, nkernels);
-  HIPCHECK(hipMemcpyAsync(
-      a, d_a, sizeof(clock_t), hipMemcpyDeviceToHost, streams[nstreams - 1]));
-
-  // at this point the CPU has dispatched all work for the GPU and can continue
-  // processing other tasks in parallel
-
-  // in this sample we just wait until the GPU is done
-  HIPCHECK(hipEventRecord(stop_event, 0));
-  HIPCHECK(hipEventSynchronize(stop_event));
-  HIPCHECK(hipEventElapsedTime(&elapsed_time, start_event, stop_event));
-
-  printf("Expected time for serial execution of %d kernels = %.3fs\n", nkernels,
-         nkernels * kernel_time / 1000.0f);
-  printf("Expected time for concurrent execution of %d kernels = %.3fs\n",
-         nkernels, kernel_time / 1000.0f);
-  printf("Measured time for sample = %.3fs\n", elapsed_time / 1000.0f);
-
-  bool bTestResult = (a[0] > total_clocks);
-
-  // release resources
-  for (int i = 0; i < nkernels; i++) {
-    hipStreamDestroy(streams[i]);
-    hipEventDestroy(kernelEvent[i]);
-  }
-
-  free(streams);
-  free(kernelEvent);
-
-  hipEventDestroy(start_event);
-  hipEventDestroy(stop_event);
-  hipHostFree(a);
-  hipFree(d_a);
-
-  if (!bTestResult) {
-    printf("Test failed!\n");
-    exit(EXIT_FAILURE);
-  }
-
-  printf("Test passed\n");
-  exit(EXIT_SUCCESS);
-}
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.out b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2017.sln b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2017.vcxproj b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2019.sln b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2019.vcxproj b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2022.sln b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2022.vcxproj b/src/samples/Samples/0_Introduction/concurrentKernels/concurrentKernels_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/cppIntegration/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/.vscode/extensions.json b/src/samples/Samples/0_Introduction/cppIntegration/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/.vscode/launch.json b/src/samples/Samples/0_Introduction/cppIntegration/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/.vscode/tasks.json b/src/samples/Samples/0_Introduction/cppIntegration/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/Makefile b/src/samples/Samples/0_Introduction/cppIntegration/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/NsightEclipse.xml b/src/samples/Samples/0_Introduction/cppIntegration/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/README.md b/src/samples/Samples/0_Introduction/cppIntegration/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration.cu b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration.cu.hip b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration.cu.hip
old mode 100644
new mode 100755
index 410c222..e69de29
--- a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration.cu.hip
+++ b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration.cu.hip
@@ -1,175 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* 
- * Example of integrating CUDA functions into an existing
- * application / framework.
- * Host part of the device code.
- * Compiled with Cuda compiler.
- */
-
-// System includes
-#include <stdlib.h>
-#include <stdio.h>
-//#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-#include <assert.h>
-
-// CUDA runtime
-#include <hip/hip_runtime.h>
-
-// helper functions and utilities to work with CUDA
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"
-
-#ifndef MAX
-#define MAX(a, b) (a > b ? a : b)
-#endif
-
-////////////////////////////////////////////////////////////////////////////////
-// declaration, forward
-
-extern "C" void computeGold(char *reference, char *idata,
-                            const unsigned int len);
-extern "C" void computeGold2(int2 *reference, int2 *idata,
-                             const unsigned int len);
-
-///////////////////////////////////////////////////////////////////////////////
-//! Simple test kernel for device functionality
-//! @param g_odata  memory to process (in and out)
-///////////////////////////////////////////////////////////////////////////////
-__global__ void kernel(int *g_data) {
-  // write data to global memory
-  const unsigned int tid = threadIdx.x;
-  int data = g_data[tid];
-
-  // use integer arithmetic to process all four bytes with one thread
-  // this serializes the execution, but is the simplest solutions to avoid
-  // bank conflicts for this very low number of threads
-  // in general it is more efficient to process each byte by a separate thread,
-  // to avoid bank conflicts the access pattern should be
-  // g_data[4 * wtid + wid], where wtid is the thread id within the half warp
-  // and wid is the warp id
-  // see also the programming guide for a more in depth discussion.
-  g_data[tid] =
-      ((((data << 0) >> 24) - 10) << 24) | ((((data << 8) >> 24) - 10) << 16) |
-      ((((data << 16) >> 24) - 10) << 8) | ((((data << 24) >> 24) - 10) << 0);
-}
-
-///////////////////////////////////////////////////////////////////////////////
-//! Demonstration that int2 data can be used in the cpp code
-//! @param g_odata  memory to process (in and out)
-///////////////////////////////////////////////////////////////////////////////
-__global__ void kernel2(int2 *g_data) {
-  // write data to global memory
-  const unsigned int tid = threadIdx.x;
-  int2 data = g_data[tid];
-
-  // use integer arithmetic to process all four bytes with one thread
-  // this serializes the execution, but is the simplest solutions to avoid
-  // bank conflicts for this very low number of threads
-  // in general it is more efficient to process each byte by a separate thread,
-  // to avoid bank conflicts the access pattern should be
-  // g_data[4 * wtid + wid], where wtid is the thread id within the half warp
-  // and wid is the warp id
-  // see also the programming guide for a more in depth discussion.
-  g_data[tid].x = data.x - data.y;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Entry point for Cuda functionality on host side
-//! @param argc  command line argument count
-//! @param argv  command line arguments
-//! @param data  data to process on the device
-//! @param len   len of \a data
-////////////////////////////////////////////////////////////////////////////////
-extern "C" bool runTest(const int argc, const char **argv, char *data,
-                        int2 *data_int2, unsigned int len) {
-  // use command-line specified CUDA device, otherwise use device with highest
-  // Gflops/s
-  findCudaDevice(argc, (const char **)argv);
-
-  const unsigned int num_threads = len / 4;
-  assert(0 == (len % 4));
-  const unsigned int mem_size = sizeof(char) * len;
-  const unsigned int mem_size_int2 = sizeof(int2) * len;
-
-  // allocate device memory
-  char *d_data;
-  HIPCHECK(hipMalloc((void **)&d_data, mem_size));
-  // copy host memory to device
-  HIPCHECK(hipMemcpy(d_data, data, mem_size, hipMemcpyHostToDevice));
-  // allocate device memory for int2 version
-  int2 *d_data_int2;
-  HIPCHECK(hipMalloc((void **)&d_data_int2, mem_size_int2));
-  // copy host memory to device
-  HIPCHECK(hipMemcpy(d_data_int2, data_int2, mem_size_int2,
-                             hipMemcpyHostToDevice));
-
-  // setup execution parameters
-  dim3 grid(1, 1, 1);
-  dim3 threads(num_threads, 1, 1);
-  dim3 threads2(len, 1, 1);  // more threads needed fir separate int2 version
-  // execute the kernel
-  kernel<<<grid, threads>>>((int *)d_data);
-  kernel2<<<grid, threads2>>>(d_data_int2);
-
-  // check if kernel execution generated and error
-  getLastCudaError("Kernel execution failed");
-
-  // compute reference solutions
-  char *reference = (char *)malloc(mem_size);
-  computeGold(reference, data, len);
-  int2 *reference2 = (int2 *)malloc(mem_size_int2);
-  computeGold2(reference2, data_int2, len);
-
-  // copy results from device to host
-  HIPCHECK(hipMemcpy(data, d_data, mem_size, hipMemcpyDeviceToHost));
-  HIPCHECK(hipMemcpy(data_int2, d_data_int2, mem_size_int2,
-                             hipMemcpyDeviceToHost));
-
-  // check result
-  bool success = true;
-
-  for (unsigned int i = 0; i < len; i++) {
-    if (reference[i] != data[i] || reference2[i].x != data_int2[i].x ||
-        reference2[i].y != data_int2[i].y) {
-      success = false;
-    }
-  }
-
-  // cleanup memory
-  HIPCHECK(hipFree(d_data));
-  HIPCHECK(hipFree(d_data_int2));
-  free(reference);
-  free(reference2);
-
-  return success;
-}
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration.out b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_gold.cpp b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_gold_hipified.cpp b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2017.sln b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2017.vcxproj b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2019.sln b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2019.vcxproj b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2022.sln b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2022.vcxproj b/src/samples/Samples/0_Introduction/cppIntegration/cppIntegration_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/main.cpp b/src/samples/Samples/0_Introduction/cppIntegration/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppIntegration/main_hipified.cpp b/src/samples/Samples/0_Introduction/cppIntegration/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/cppOverload/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/.vscode/extensions.json b/src/samples/Samples/0_Introduction/cppOverload/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/.vscode/launch.json b/src/samples/Samples/0_Introduction/cppOverload/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/.vscode/tasks.json b/src/samples/Samples/0_Introduction/cppOverload/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/Makefile b/src/samples/Samples/0_Introduction/cppOverload/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/NsightEclipse.xml b/src/samples/Samples/0_Introduction/cppOverload/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/README.md b/src/samples/Samples/0_Introduction/cppOverload/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/cppOverload.cu b/src/samples/Samples/0_Introduction/cppOverload/cppOverload.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/cppOverload.cu.hip b/src/samples/Samples/0_Introduction/cppOverload/cppOverload.cu.hip
old mode 100644
new mode 100755
index 9932963..e69de29
--- a/src/samples/Samples/0_Introduction/cppOverload/cppOverload.cu.hip
+++ b/src/samples/Samples/0_Introduction/cppOverload/cppOverload.cu.hip
@@ -1,190 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#define THREAD_N 256
-#define N 1024
-#define DIV_UP(a, b) (((a) + (b) - 1) / (b))
-
-// Includes, system
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include "helper_cuda_hipified.h"
-#include <helper_string.h>
-#include <helper_math.h>
-#include "cppOverload_kernel.cuh"
-
-const char *sampleName = "C++ Function Overloading";
-
-#define OUTPUT_ATTR(attr)                                         \
-  printf("Shared Size:   %d\n", (int)attr.sharedSizeBytes);       \
-  printf("Constant Size: %d\n", (int)attr.constSizeBytes);        \
-  printf("Local Size:    %d\n", (int)attr.localSizeBytes);        \
-  printf("Max Threads Per Block: %d\n", attr.maxThreadsPerBlock); \
-  printf("Number of Registers: %d\n", attr.numRegs);              \
-  printf("PTX Version: %d\n", attr.ptxVersion);                   \
-  printf("Binary Version: %d\n", attr.binaryVersion);
-
-bool check_func1(int *hInput, int *hOutput, int a) {
-  for (int i = 0; i < N; ++i) {
-    int cpuRes = hInput[i] * a + i;
-
-    if (hOutput[i] != cpuRes) {
-      return false;
-    }
-  }
-
-  return true;
-}
-
-bool check_func2(int2 *hInput, int *hOutput, int a) {
-  for (int i = 0; i < N; i++) {
-    int cpuRes = (hInput[i].x + hInput[i].y) * a + i;
-
-    if (hOutput[i] != cpuRes) {
-      return false;
-    }
-  }
-
-  return true;
-}
-
-bool check_func3(int *hInput1, int *hInput2, int *hOutput, int a) {
-  for (int i = 0; i < N; i++) {
-    if (hOutput[i] != (hInput1[i] + hInput2[i]) * a + i) {
-      return false;
-    }
-  }
-
-  return true;
-}
-
-int main(int argc, const char *argv[]) {
-  int *hInput = NULL;
-  int *hOutput = NULL;
-  int *dInput = NULL;
-  int *dOutput = NULL;
-
-  printf("%s starting...\n", sampleName);
-
-  int deviceCount;
-  checkCudaErrors(hipGetDeviceCount(&deviceCount));
-  printf("Device Count: %d\n", deviceCount);
-
-  int deviceID = findCudaDevice(argc, argv);
-  hipDeviceProp_t prop;
-  checkCudaErrors(hipGetDeviceProperties(&prop, deviceID));
-  if (prop.major < 2) {
-    printf(
-        "ERROR: cppOverload requires GPU devices with compute SM 2.0 or "
-        "higher.\n");
-    printf("Current GPU device has compute SM%d.%d, Exiting...", prop.major,
-           prop.minor);
-    exit(EXIT_WAIVED);
-  }
-
-  checkCudaErrors(hipSetDevice(deviceID));
-
-  // Allocate device memory
-  checkCudaErrors(hipMalloc(&dInput, sizeof(int) * N * 2));
-  checkCudaErrors(hipMalloc(&dOutput, sizeof(int) * N));
-
-  // Allocate host memory
-  checkCudaErrors(hipHostMalloc(&hInput, sizeof(int) * N * 2));
-  checkCudaErrors(hipHostMalloc(&hOutput, sizeof(int) * N));
-
-  for (int i = 0; i < N * 2; i++) {
-    hInput[i] = i;
-  }
-
-  // Copy data from host to device
-  checkCudaErrors(
-      hipMemcpy(dInput, hInput, sizeof(int) * N * 2, hipMemcpyHostToDevice));
-
-  // Test C++ overloading
-  bool testResult = true;
-  bool funcResult = true;
-  int a = 1;
-
-  void (*func1)(const int *, int *, int);
-  void (*func2)(const int2 *, int *, int);
-  void (*func3)(const int *, const int *, int *, int);
-  struct hipFuncAttributes attr;
-
-  // overload function 1
-  func1 = simple_kernel;
-  memset(&attr, 0, sizeof(attr));
-  checkCudaErrors(hipFuncSetCacheConfig(*func1, hipFuncCachePreferShared));
-  checkCudaErrors(hipFuncGetAttributes(&attr, *func1));
-  OUTPUT_ATTR(attr);
-  (*func1)<<<DIV_UP(N, THREAD_N), THREAD_N>>>(dInput, dOutput, a);
-  checkCudaErrors(
-      hipMemcpy(hOutput, dOutput, sizeof(int) * N, hipMemcpyDeviceToHost));
-  funcResult = check_func1(hInput, hOutput, a);
-  printf("simple_kernel(const int *pIn, int *pOut, int a) %s\n\n",
-         funcResult ? "PASSED" : "FAILED");
-  testResult &= funcResult;
-
-  // overload function 2
-  func2 = simple_kernel;
-  memset(&attr, 0, sizeof(attr));
-  checkCudaErrors(hipFuncSetCacheConfig(*func2, hipFuncCachePreferShared));
-  checkCudaErrors(hipFuncGetAttributes(&attr, *func2));
-  OUTPUT_ATTR(attr);
-  (*func2)<<<DIV_UP(N, THREAD_N), THREAD_N>>>((int2 *)dInput, dOutput, a);
-  checkCudaErrors(
-      hipMemcpy(hOutput, dOutput, sizeof(int) * N, hipMemcpyDeviceToHost));
-  funcResult = check_func2(reinterpret_cast<int2 *>(hInput), hOutput, a);
-  printf("simple_kernel(const int2 *pIn, int *pOut, int a) %s\n\n",
-         funcResult ? "PASSED" : "FAILED");
-  testResult &= funcResult;
-
-  // overload function 3
-  func3 = simple_kernel;
-  memset(&attr, 0, sizeof(attr));
-  checkCudaErrors(hipFuncSetCacheConfig(*func3, hipFuncCachePreferShared));
-  checkCudaErrors(hipFuncGetAttributes(&attr, *func3));
-  OUTPUT_ATTR(attr);
-  (*func3)<<<DIV_UP(N, THREAD_N), THREAD_N>>>(dInput, dInput + N, dOutput, a);
-  checkCudaErrors(
-      hipMemcpy(hOutput, dOutput, sizeof(int) * N, hipMemcpyDeviceToHost));
-  funcResult = check_func3(&hInput[0], &hInput[N], hOutput, a);
-  printf(
-      "simple_kernel(const int *pIn1, const int *pIn2, int *pOut, int a) "
-      "%s\n\n",
-      funcResult ? "PASSED" : "FAILED");
-  testResult &= funcResult;
-
-  checkCudaErrors(hipFree(dInput));
-  checkCudaErrors(hipFree(dOutput));
-  checkCudaErrors(hipHostFree(hOutput));
-  checkCudaErrors(hipHostFree(hInput));
-
-  checkCudaErrors(hipDeviceSynchronize());
-
-  exit(testResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/0_Introduction/cppOverload/cppOverload_kernel.cuh b/src/samples/Samples/0_Introduction/cppOverload/cppOverload_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/cppOverload_kernel_hipified.cuh b/src/samples/Samples/0_Introduction/cppOverload/cppOverload_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2017.sln b/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2017.vcxproj b/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2019.sln b/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2019.vcxproj b/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2022.sln b/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2022.vcxproj b/src/samples/Samples/0_Introduction/cppOverload/cppOverload_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/cudaOpenMP/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/.vscode/extensions.json b/src/samples/Samples/0_Introduction/cudaOpenMP/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/.vscode/launch.json b/src/samples/Samples/0_Introduction/cudaOpenMP/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/.vscode/tasks.json b/src/samples/Samples/0_Introduction/cudaOpenMP/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/Makefile b/src/samples/Samples/0_Introduction/cudaOpenMP/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/README.md b/src/samples/Samples/0_Introduction/cudaOpenMP/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP.cu b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP.cu.hip b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP.cu.hip
old mode 100644
new mode 100755
index 7f4d166..e69de29
--- a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP.cu.hip
+++ b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP.cu.hip
@@ -1,160 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Multi-GPU sample using OpenMP for threading on the CPU side
- * needs a compiler that supports OpenMP 2.0
- */
-
-#include "helper_cuda_hipified.h"
-#include <omp.h>
-#include <stdio.h>  // stdio functions are used since C++ streams aren't necessarily thread safe
-#include "HIPCHECK.h"
-using namespace std;
-
-// a simple kernel that simply increments each array element by b
-__global__ void kernelAddConstant(int *g_a, const int b) {
-  int idx = blockIdx.x * blockDim.x + threadIdx.x;
-  g_a[idx] += b;
-}
-
-// a predicate that checks whether each array element is set to its index plus b
-int correctResult(int *data, const int n, const int b) {
-  for (int i = 0; i < n; i++)
-    if (data[i] != i + b) return 0;
-
-  return 1;
-}
-
-int main(int argc, char *argv[]) {
-  int num_gpus = 0;  // number of CUDA GPUs
-
-  printf("%s Starting...\n\n", argv[0]);
-
-  /////////////////////////////////////////////////////////////////
-  // determine the number of CUDA capable GPUs
-  //
-  hipGetDeviceCount(&num_gpus);
-
-  if (num_gpus < 1) {
-    printf("no CUDA capable devices were detected\n");
-    return 1;
-  }
-
-  /////////////////////////////////////////////////////////////////
-  // display CPU and GPU configuration
-  //
-  printf("number of host CPUs:\t%d\n", omp_get_num_procs());
-  printf("number of CUDA devices:\t%d\n", num_gpus);
-
-  for (int i = 0; i < num_gpus; i++) {
-    hipDeviceProp_t dprop;
-    hipGetDeviceProperties(&dprop, i);
-    printf("   %d: %s\n", i, dprop.name);
-  }
-
-  printf("---------------------------\n");
-
-  /////////////////////////////////////////////////////////////////
-  // initialize data
-  //
-  unsigned int n = num_gpus * 8192;
-  unsigned int nbytes = n * sizeof(int);
-  int *a = 0;  // pointer to data on the CPU
-  int b = 3;   // value by which the array is incremented
-  a = (int *)malloc(nbytes);
-
-  if (0 == a) {
-    printf("couldn't allocate CPU memory\n");
-    return 1;
-  }
-
-  for (unsigned int i = 0; i < n; i++) a[i] = i;
-
-  ////////////////////////////////////////////////////////////////
-  // run as many CPU threads as there are CUDA devices
-  //   each CPU thread controls a different device, processing its
-  //   portion of the data.  It's possible to use more CPU threads
-  //   than there are CUDA devices, in which case several CPU
-  //   threads will be allocating resources and launching kernels
-  //   on the same device.  For example, try omp_set_num_threads(2*num_gpus);
-  //   Recall that all variables declared inside an "omp parallel" scope are
-  //   local to each CPU thread
-  //
-  omp_set_num_threads(
-      num_gpus);  // create as many CPU threads as there are CUDA devices
-// omp_set_num_threads(2*num_gpus);// create twice as many CPU threads as there
-// are CUDA devices
-#pragma omp parallel
-  {
-    unsigned int cpu_thread_id = omp_get_thread_num();
-    unsigned int num_cpu_threads = omp_get_num_threads();
-
-    // set and check the CUDA device for this CPU thread
-    int gpu_id = -1;
-    HIPCHECK(hipSetDevice(
-        cpu_thread_id %
-        num_gpus));  // "% num_gpus" allows more CPU threads than GPU devices
-    HIPCHECK(hipGetDevice(&gpu_id));
-    printf("CPU thread %d (of %d) uses CUDA device %d\n", cpu_thread_id,
-           num_cpu_threads, gpu_id);
-
-    int *d_a =
-        0;  // pointer to memory on the device associated with this CPU thread
-    int *sub_a =
-        a +
-        cpu_thread_id * n /
-            num_cpu_threads;  // pointer to this CPU thread's portion of data
-    unsigned int nbytes_per_kernel = nbytes / num_cpu_threads;
-    dim3 gpu_threads(128);  // 128 threads per block
-    dim3 gpu_blocks(n / (gpu_threads.x * num_cpu_threads));
-
-    HIPCHECK(hipMalloc((void **)&d_a, nbytes_per_kernel));
-    HIPCHECK(hipMemset(d_a, 0, nbytes_per_kernel));
-    HIPCHECK(
-        hipMemcpy(d_a, sub_a, nbytes_per_kernel, hipMemcpyHostToDevice));
-    kernelAddConstant<<<gpu_blocks, gpu_threads>>>(d_a, b);
-
-    HIPCHECK(
-        hipMemcpy(sub_a, d_a, nbytes_per_kernel, hipMemcpyDeviceToHost));
-    HIPCHECK(hipFree(d_a));
-  }
-  printf("---------------------------\n");
-
-  if (hipSuccess != hipGetLastError())
-    printf("%s\n", hipGetErrorString(hipGetLastError()));
-
-  ////////////////////////////////////////////////////////////////
-  // check the result
-  //
-  bool bResult = correctResult(a, n, b);
-
-  if (a) free(a);  // free CPU memory
-
-  exit(bResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2017.sln b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2017.vcxproj b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2019.sln b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2019.vcxproj b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2022.sln b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2022.vcxproj b/src/samples/Samples/0_Introduction/cudaOpenMP/cudaOpenMP_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/fp16ScalarProduct/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/.vscode/extensions.json b/src/samples/Samples/0_Introduction/fp16ScalarProduct/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/.vscode/launch.json b/src/samples/Samples/0_Introduction/fp16ScalarProduct/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/.vscode/tasks.json b/src/samples/Samples/0_Introduction/fp16ScalarProduct/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/Makefile b/src/samples/Samples/0_Introduction/fp16ScalarProduct/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/NsightEclipse.xml b/src/samples/Samples/0_Introduction/fp16ScalarProduct/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/README.md b/src/samples/Samples/0_Introduction/fp16ScalarProduct/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.cu b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.cu.hip b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.cu.hip
old mode 100644
new mode 100755
index b3e697c..e69de29
--- a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.cu.hip
+++ b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.cu.hip
@@ -1,216 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "hip/hip_fp16.h"
-#include "helper_cuda_hipified.h"
-
-#include <cstdio>
-#include <cstdlib>
-#include <ctime>
-#include "HIPCHECK.h"
-#define NUM_OF_BLOCKS 128
-#define NUM_OF_THREADS 128
-
-__forceinline__ __device__ void reduceInShared_intrinsics(half2 *const v) {
-  if (threadIdx.x < 64)
-    v[threadIdx.x] = __hadd2(v[threadIdx.x], v[threadIdx.x + 64]);
-  __syncthreads();
-  if (threadIdx.x < 32)
-    v[threadIdx.x] = __hadd2(v[threadIdx.x], v[threadIdx.x + 32]);
-  __syncthreads();
-  if (threadIdx.x < 16)
-    v[threadIdx.x] = __hadd2(v[threadIdx.x], v[threadIdx.x + 16]);
-  __syncthreads();
-  if (threadIdx.x < 8)
-    v[threadIdx.x] = __hadd2(v[threadIdx.x], v[threadIdx.x + 8]);
-  __syncthreads();
-  if (threadIdx.x < 4)
-    v[threadIdx.x] = __hadd2(v[threadIdx.x], v[threadIdx.x + 4]);
-  __syncthreads();
-  if (threadIdx.x < 2)
-    v[threadIdx.x] = __hadd2(v[threadIdx.x], v[threadIdx.x + 2]);
-  __syncthreads();
-  if (threadIdx.x < 1)
-    v[threadIdx.x] = __hadd2(v[threadIdx.x], v[threadIdx.x + 1]);
-  __syncthreads();
-}
-
-__forceinline__ __device__ void reduceInShared_native(half2 *const v) {
-  if (threadIdx.x < 64) v[threadIdx.x] = v[threadIdx.x] + v[threadIdx.x + 64];
-  __syncthreads();
-  if (threadIdx.x < 32) v[threadIdx.x] = v[threadIdx.x] + v[threadIdx.x + 32];
-  __syncthreads();
-  if (threadIdx.x < 16) v[threadIdx.x] = v[threadIdx.x] + v[threadIdx.x + 16];
-  __syncthreads();
-  if (threadIdx.x < 8) v[threadIdx.x] = v[threadIdx.x] + v[threadIdx.x + 8];
-  __syncthreads();
-  if (threadIdx.x < 4) v[threadIdx.x] = v[threadIdx.x] + v[threadIdx.x + 4];
-  __syncthreads();
-  if (threadIdx.x < 2) v[threadIdx.x] = v[threadIdx.x] + v[threadIdx.x + 2];
-  __syncthreads();
-  if (threadIdx.x < 1) v[threadIdx.x] = v[threadIdx.x] + v[threadIdx.x + 1];
-  __syncthreads();
-}
-
-__global__ void scalarProductKernel_intrinsics(half2 const *const a,
-                                               half2 const *const b,
-                                               float *const results,
-                                               size_t const size) {
-  const int stride = gridDim.x * blockDim.x;
-  __shared__ half2 shArray[NUM_OF_THREADS];
-
-  shArray[threadIdx.x] = __float2half2_rn(0.f);
-  half2 value = __float2half2_rn(0.f);
-
-  for (int i = threadIdx.x + blockDim.x + blockIdx.x; i < size; i += stride) {
-    value = __hfma2(a[i], b[i], value);
-  }
-
-  shArray[threadIdx.x] = value;
-  __syncthreads();
-  reduceInShared_intrinsics(shArray);
-
-  if (threadIdx.x == 0) {
-    half2 result = shArray[0];
-    float f_result = __low2float(result) + __high2float(result);
-    results[blockIdx.x] = f_result;
-  }
-}
-
-__global__ void scalarProductKernel_native(half2 const *const a,
-                                           half2 const *const b,
-                                           float *const results,
-                                           size_t const size) {
-  const int stride = gridDim.x * blockDim.x;
-  __shared__ half2 shArray[NUM_OF_THREADS];
-
-  half2 value(0.f, 0.f);
-  shArray[threadIdx.x] = value;
-
-  for (int i = threadIdx.x + blockDim.x + blockIdx.x; i < size; i += stride) {
-    value = a[i] * b[i] + value;
-  }
-
-  shArray[threadIdx.x] = value;
-  __syncthreads();
-  reduceInShared_native(shArray);
-
-  if (threadIdx.x == 0) {
-    half2 result = shArray[0];
-    float f_result = (float)result.y + (float)result.x;
-    results[blockIdx.x] = f_result;
-  }
-}
-
-void generateInput(half2 *a, size_t size) {
-  for (size_t i = 0; i < size; ++i) {
-    half2 temp;
-    temp.x = static_cast<float>(rand() % 4);
-    temp.y = static_cast<float>(rand() % 2);
-    a[i] = temp;
-  }
-}
-
-int main(int argc, char *argv[]) {
-  srand((unsigned int)time(NULL));
-  size_t size = NUM_OF_BLOCKS * NUM_OF_THREADS * 16;
-
-  half2 *vec[2];
-  half2 *devVec[2];
-
-  float *results;
-  float *devResults;
-
-  int devID = findCudaDevice(argc, (const char **)argv);
-
-  hipDeviceProp_t devProp;
-  HIPCHECK(hipGetDeviceProperties(&devProp, devID));
-
-  if (devProp.major < 5 || (devProp.major == 5 && devProp.minor < 3)) {
-    printf(
-        "ERROR: fp16ScalarProduct requires GPU devices with compute SM 5.3 or "
-        "higher.\n");
-    return EXIT_WAIVED;
-  }
-
-  for (int i = 0; i < 2; ++i) {
-    HIPCHECK(hipHostMalloc((void **)&vec[i], size * sizeof *vec[i]));
-    HIPCHECK(hipMalloc((void **)&devVec[i], size * sizeof *devVec[i]));
-  }
-
-  HIPCHECK(
-      hipHostMalloc((void **)&results, NUM_OF_BLOCKS * sizeof *results));
-  HIPCHECK(
-      hipMalloc((void **)&devResults, NUM_OF_BLOCKS * sizeof *devResults));
-
-  for (int i = 0; i < 2; ++i) {
-    generateInput(vec[i], size);
-    HIPCHECK(hipMemcpy(devVec[i], vec[i], size * sizeof *vec[i],
-                               hipMemcpyHostToDevice));
-  }
-
-  scalarProductKernel_native<<<NUM_OF_BLOCKS, NUM_OF_THREADS>>>(
-      devVec[0], devVec[1], devResults, size);
-
-  HIPCHECK(hipMemcpy(results, devResults,
-                             NUM_OF_BLOCKS * sizeof *results,
-                             hipMemcpyDeviceToHost));
-
-  float result_native = 0;
-  for (int i = 0; i < NUM_OF_BLOCKS; ++i) {
-    result_native += results[i];
-  }
-  printf("Result native operators\t: %f \n", result_native);
-
-  scalarProductKernel_intrinsics<<<NUM_OF_BLOCKS, NUM_OF_THREADS>>>(
-      devVec[0], devVec[1], devResults, size);
-
-  HIPCHECK(hipMemcpy(results, devResults,
-                             NUM_OF_BLOCKS * sizeof *results,
-                             hipMemcpyDeviceToHost));
-
-  float result_intrinsics = 0;
-  for (int i = 0; i < NUM_OF_BLOCKS; ++i) {
-    result_intrinsics += results[i];
-  }
-  printf("Result intrinsics\t: %f \n", result_intrinsics);
-
-  printf("&&&& fp16ScalarProduct %s\n",
-         (fabs(result_intrinsics - result_native) < 0.00001) ? "PASSED"
-                                                             : "FAILED");
-
-  for (int i = 0; i < 2; ++i) {
-    HIPCHECK(hipFree(devVec[i]));
-    HIPCHECK(hipHostFree(vec[i]));
-  }
-
-  HIPCHECK(hipFree(devResults));
-  HIPCHECK(hipHostFree(results));
-
-  return EXIT_SUCCESS;
-}
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.out b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2017.sln b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2017.vcxproj b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2019.sln b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2019.vcxproj b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2022.sln b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2022.vcxproj b/src/samples/Samples/0_Introduction/fp16ScalarProduct/fp16ScalarProduct_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/matrixMul/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul/.vscode/extensions.json b/src/samples/Samples/0_Introduction/matrixMul/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul/.vscode/launch.json b/src/samples/Samples/0_Introduction/matrixMul/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul/.vscode/tasks.json b/src/samples/Samples/0_Introduction/matrixMul/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul/Makefile b/src/samples/Samples/0_Introduction/matrixMul/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul/NsightEclipse.xml b/src/samples/Samples/0_Introduction/matrixMul/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul/README.md b/src/samples/Samples/0_Introduction/matrixMul/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul/matrixMul.cu b/src/samples/Samples/0_Introduction/matrixMul/matrixMul.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul/matrixMul.cu.hip b/src/samples/Samples/0_Introduction/matrixMul/matrixMul.cu.hip
old mode 100644
new mode 100755
index 63a244d..e69de29
--- a/src/samples/Samples/0_Introduction/matrixMul/matrixMul.cu.hip
+++ b/src/samples/Samples/0_Introduction/matrixMul/matrixMul.cu.hip
@@ -1,356 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/**
- * Matrix multiplication: C = A * B.
- * Host code.
- *
- * This sample implements matrix multiplication which makes use of shared memory
- * to ensure data reuse, the matrix multiplication is done using tiling approach.
- * It has been written for clarity of exposition to illustrate various CUDA programming
- * principles, not with the goal of providing the most performant generic kernel for matrix multiplication.
- * See also:
- * V. Volkov and J. Demmel, "Benchmarking GPUs to tune dense linear algebra,"
- * in Proc. 2008 ACM/IEEE Conf. on Supercomputing (SC '08),
- * Piscataway, NJ: IEEE Press, 2008, pp. Art. 31:1-11.
- */
-
-// System includes
-#include <stdio.h>
-//#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <assert.h>
-
-// CUDA runtime
-#include <hip/hip_runtime.h>
-#include <hip/hip_runtime_api.h>
-
-// Helper functions and utilities to work with CUDA
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-
-/**
- * Matrix multiplication (CUDA Kernel) on the device: C = A * B
- * wA is A's width and wB is B's width
- */
-template <int BLOCK_SIZE> __global__ void MatrixMulCUDA(float *C, float *A,
-    float *B, int wA,
-    int wB) {
-  // Block index
-  int bx = blockIdx.x;
-  int by = blockIdx.y;
-
-  // Thread index
-  int tx = threadIdx.x;
-  int ty = threadIdx.y;
-
-  // Index of the first sub-matrix of A processed by the block
-  int aBegin = wA * BLOCK_SIZE * by;
-
-  // Index of the last sub-matrix of A processed by the block
-  int aEnd   = aBegin + wA - 1;
-
-  // Step size used to iterate through the sub-matrices of A
-  int aStep  = BLOCK_SIZE;
-
-  // Index of the first sub-matrix of B processed by the block
-  int bBegin = BLOCK_SIZE * bx;
-
-  // Step size used to iterate through the sub-matrices of B
-  int bStep  = BLOCK_SIZE * wB;
-
-  // Csub is used to store the element of the block sub-matrix
-  // that is computed by the thread
-  float Csub = 0;
-
-  // Loop over all the sub-matrices of A and B
-  // required to compute the block sub-matrix
-  for (int a = aBegin, b = bBegin;
-       a <= aEnd;
-       a += aStep, b += bStep) {
-    // Declaration of the shared memory array As used to
-    // store the sub-matrix of A
-    __shared__ float As[BLOCK_SIZE][BLOCK_SIZE];
-
-    // Declaration of the shared memory array Bs used to
-    // store the sub-matrix of B
-    __shared__ float Bs[BLOCK_SIZE][BLOCK_SIZE];
-
-    // Load the matrices from device memory
-    // to shared memory; each thread loads
-    // one element of each matrix
-    As[ty][tx] = A[a + wA * ty + tx];
-    Bs[ty][tx] = B[b + wB * ty + tx];
-
-    // Synchronize to make sure the matrices are loaded
-    __syncthreads();
-
-    // Multiply the two matrices together;
-    // each thread computes one element
-    // of the block sub-matrix
-#pragma unroll
-
-    for (int k = 0; k < BLOCK_SIZE; ++k) {
-      Csub += As[ty][k] * Bs[k][tx];
-    }
-
-    // Synchronize to make sure that the preceding
-    // computation is done before loading two new
-    // sub-matrices of A and B in the next iteration
-    __syncthreads();
-  }
-
-  // Write the block sub-matrix to device memory;
-  // each thread writes one element
-  int c = wB * BLOCK_SIZE * by + BLOCK_SIZE * bx;
-  C[c + wB * ty + tx] = Csub;
-}
-
-void ConstantInit(float *data, int size, float val) {
-  for (int i = 0; i < size; ++i) {
-    data[i] = val;
-  }
-}
-
-/**
- * Run a simple test of matrix multiplication using CUDA
- */
-int MatrixMultiply(int argc, char **argv,
-                   int block_size, const dim3 &dimsA,
-                   const dim3 &dimsB) {
-  // Allocate host memory for matrices A and B
-  unsigned int size_A = dimsA.x * dimsA.y;
-  unsigned int mem_size_A = sizeof(float) * size_A;
-  float *h_A;
-  HIPCHECK(hipHostMalloc(&h_A, mem_size_A));
-  unsigned int size_B = dimsB.x * dimsB.y;
-  unsigned int mem_size_B = sizeof(float) * size_B;
-  float *h_B;
-  HIPCHECK(hipHostMalloc(&h_B, mem_size_B));
-  hipStream_t stream;
-
-  // Initialize host memory
-  const float valB = 0.01f;
-  ConstantInit(h_A, size_A, 1.0f);
-  ConstantInit(h_B, size_B, valB);
-
-  // Allocate device memory
-  float *d_A, *d_B, *d_C;
-
-  // Allocate host matrix C
-  dim3 dimsC(dimsB.x, dimsA.y, 1);
-  unsigned int mem_size_C = dimsC.x * dimsC.y * sizeof(float);
-  float *h_C;
-  HIPCHECK(hipHostMalloc(&h_C, mem_size_C));
-
-  if (h_C == NULL) {
-    fprintf(stderr, "Failed to allocate host matrix C!\n");
-    exit(EXIT_FAILURE);
-  }
-
-  HIPCHECK(hipMalloc(reinterpret_cast<void **>(&d_A), mem_size_A));
-  HIPCHECK(hipMalloc(reinterpret_cast<void **>(&d_B), mem_size_B));
-  HIPCHECK(hipMalloc(reinterpret_cast<void **>(&d_C), mem_size_C));
-  // Allocate CUDA events that we'll use for timing
-  hipEvent_t start, stop;
-  HIPCHECK(hipEventCreate(&start));
-  HIPCHECK(hipEventCreate(&stop));
-
-  HIPCHECK(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
-
-  // copy host memory to device
-  HIPCHECK(
-      hipMemcpyAsync(d_A, h_A, mem_size_A, hipMemcpyHostToDevice, stream));
-  HIPCHECK(
-      hipMemcpyAsync(d_B, h_B, mem_size_B, hipMemcpyHostToDevice, stream));
-
-  // Setup execution parameters
-  dim3 threads(block_size, block_size);
-  dim3 grid(dimsB.x / threads.x, dimsA.y / threads.y);
-
-  // Create and start timer
-  printf("Computing result using CUDA Kernel...\n");
-
-  // Performs warmup operation using matrixMul CUDA kernel
-  if (block_size == 16) {
-    MatrixMulCUDA<16>
-        <<<grid, threads, 0, stream>>>(d_C, d_A, d_B, dimsA.x, dimsB.x);
-  } else {
-    MatrixMulCUDA<32>
-        <<<grid, threads, 0, stream>>>(d_C, d_A, d_B, dimsA.x, dimsB.x);
-  }
-
-  printf("done\n");
-  HIPCHECK(hipStreamSynchronize(stream));
-
-  // Record the start event
-  HIPCHECK(hipEventRecord(start, stream));
-
-  // Execute the kernel
-  int nIter = 300;
-
-  for (int j = 0; j < nIter; j++) {
-    if (block_size == 16) {
-      MatrixMulCUDA<16>
-          <<<grid, threads, 0, stream>>>(d_C, d_A, d_B, dimsA.x, dimsB.x);
-    } else {
-      MatrixMulCUDA<32>
-          <<<grid, threads, 0, stream>>>(d_C, d_A, d_B, dimsA.x, dimsB.x);
-    }
-  }
-
-  // Record the stop event
-  HIPCHECK(hipEventRecord(stop, stream));
-
-  // Wait for the stop event to complete
-  HIPCHECK(hipEventSynchronize(stop));
-
-  float msecTotal = 0.0f;
-  HIPCHECK(hipEventElapsedTime(&msecTotal, start, stop));
-
-  // Compute and print the performance
-  float msecPerMatrixMul = msecTotal / nIter;
-  double flopsPerMatrixMul = 2.0 * static_cast<double>(dimsA.x) *
-                             static_cast<double>(dimsA.y) *
-                             static_cast<double>(dimsB.x);
-  double gigaFlops =
-      (flopsPerMatrixMul * 1.0e-9f) / (msecPerMatrixMul / 1000.0f);
-  printf(
-      "Performance= %.2f GFlop/s, Time= %.3f msec, Size= %.0f Ops,"
-      " WorkgroupSize= %u threads/block\n",
-      gigaFlops, msecPerMatrixMul, flopsPerMatrixMul, threads.x * threads.y);
-
-  // Copy result from device to host
-  HIPCHECK(
-      hipMemcpyAsync(h_C, d_C, mem_size_C, hipMemcpyDeviceToHost, stream));
-  HIPCHECK(hipStreamSynchronize(stream));
-
-  printf("Checking computed result for correctness: ");
-  bool correct = true;
-
-  // test relative error by the formula
-  //     |<x, y>_cpu - <x,y>_gpu|/<|x|, |y|>  < eps
-  double eps = 1.e-6;  // machine zero
-
-  for (int i = 0; i < static_cast<int>(dimsC.x * dimsC.y); i++) {
-    double abs_err = fabs(h_C[i] - (dimsA.x * valB));
-    double dot_length = dimsA.x;
-    double abs_val = fabs(h_C[i]);
-    double rel_err = abs_err / abs_val / dot_length;
-
-    if (rel_err > eps) {
-      printf("Error! Matrix[%05d]=%.8f, ref=%.8f error term is > %E\n",
-             i, h_C[i], dimsA.x * valB, eps);
-      correct = false;
-    }
-  }
-
-  printf("%s\n", correct ? "Result = PASS" : "Result = FAIL");
-
-  // Clean up memory
-  HIPCHECK(hipHostFree(h_A));
-  HIPCHECK(hipHostFree(h_B));
-  HIPCHECK(hipHostFree(h_C));
-  HIPCHECK(hipFree(d_A));
-  HIPCHECK(hipFree(d_B));
-  HIPCHECK(hipFree(d_C));
-  HIPCHECK(hipEventDestroy(start));
-  HIPCHECK(hipEventDestroy(stop));
-  printf(
-      "\nNOTE: The CUDA Samples are not meant for performance "
-      "measurements. Results may vary when GPU Boost is enabled.\n");
-
-  if (correct) {
-    return EXIT_SUCCESS;
-  } else {
-    return EXIT_FAILURE;
-  }
-}
-
-
-/**
- * Program main
- */
-int main(int argc, char **argv) {
-  printf("[Matrix Multiply Using CUDA] - Starting...\n");
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "help") ||
-      checkCmdLineFlag(argc, (const char **)argv, "?")) {
-    printf("Usage -device=n (n >= 0 for deviceID)\n");
-    printf("      -wA=WidthA -hA=HeightA (Width x Height of Matrix A)\n");
-    printf("      -wB=WidthB -hB=HeightB (Width x Height of Matrix B)\n");
-    printf("  Note: Outer matrix dimensions of A & B matrices" \
-           " must be equal.\n");
-
-    exit(EXIT_SUCCESS);
-  }
-
-  // This will pick the best possible CUDA capable device, otherwise
-  // override the device ID based on input provided at the command line
-  int dev = findCudaDevice(argc, (const char **)argv);
-
-  int block_size = 32;
-
-  dim3 dimsA(5 * 2 * block_size, 5 * 2 * block_size, 1);
-  dim3 dimsB(5 * 4 * block_size, 5 * 2 * block_size, 1);
-
-  // width of Matrix A
-  if (checkCmdLineFlag(argc, (const char **)argv, "wA")) {
-    dimsA.x = getCmdLineArgumentInt(argc, (const char **)argv, "wA");
-  }
-
-  // height of Matrix A
-  if (checkCmdLineFlag(argc, (const char **)argv, "hA")) {
-    dimsA.y = getCmdLineArgumentInt(argc, (const char **)argv, "hA");
-  }
-
-  // width of Matrix B
-  if (checkCmdLineFlag(argc, (const char **)argv, "wB")) {
-    dimsB.x = getCmdLineArgumentInt(argc, (const char **)argv, "wB");
-  }
-
-  // height of Matrix B
-  if (checkCmdLineFlag(argc, (const char **)argv, "hB")) {
-    dimsB.y = getCmdLineArgumentInt(argc, (const char **)argv, "hB");
-  }
-
-  if (dimsA.x != dimsB.y) {
-    printf("Error: outer matrix dimensions must be equal. (%d != %d)\n",
-           dimsA.x, dimsB.y);
-    exit(EXIT_FAILURE);
-  }
-
-  printf("MatrixA(%d,%d), MatrixB(%d,%d)\n", dimsA.x, dimsA.y,
-         dimsB.x, dimsB.y);
-
-  HIPCHECK(hipProfilerStart());
-  int matrix_result = MatrixMultiply(argc, argv, block_size, dimsA, dimsB);
-  HIPCHECK(hipProfilerStop());
-
-  exit(matrix_result);
-}
diff --git a/src/samples/Samples/0_Introduction/matrixMul/matrixMul.out b/src/samples/Samples/0_Introduction/matrixMul/matrixMul.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2017.sln b/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2017.vcxproj b/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2019.sln b/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2019.vcxproj b/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2022.sln b/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2022.vcxproj b/src/samples/Samples/0_Introduction/matrixMul/matrixMul_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/matrixMulDrv/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/.vscode/extensions.json b/src/samples/Samples/0_Introduction/matrixMulDrv/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/.vscode/launch.json b/src/samples/Samples/0_Introduction/matrixMulDrv/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/.vscode/tasks.json b/src/samples/Samples/0_Introduction/matrixMulDrv/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/Makefile b/src/samples/Samples/0_Introduction/matrixMulDrv/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/README.md b/src/samples/Samples/0_Introduction/matrixMulDrv/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMul.h b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMul.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv.cpp b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_hipified.cpp b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2017.sln b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2017.vcxproj b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2019.sln b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2019.vcxproj b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2022.sln b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2022.vcxproj b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMulDrv_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMul_hipified.h b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMul_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMul_kernel.cu b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMul_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMul_kernel.cu.hip b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMul_kernel.cu.hip
old mode 100644
new mode 100755
index dec7158..e69de29
--- a/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMul_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/matrixMulDrv/matrixMul_kernel.cu.hip
@@ -1,130 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* Matrix multiplication: C = A * B.
- * Device code.
- */
-
-#ifndef _MATRIXMUL_KERNEL_H_
-#define _MATRIXMUL_KERNEL_H_
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-
-#define AS(i, j) As[i][j]
-#define BS(i, j) Bs[i][j]
-
-////////////////////////////////////////////////////////////////////////////////
-//! Matrix multiplication on the device: C = A * B
-//! wA is A's width and wB is B's width
-////////////////////////////////////////////////////////////////////////////////
-template <int block_size, typename size_type>
-__device__ void matrixMul(float *C, float *A, float *B, size_type wA,
-                          size_type wB) {
-  // Block index
-  size_type bx = blockIdx.x;
-  size_type by = blockIdx.y;
-
-  // Thread index
-  size_type tx = threadIdx.x;
-  size_type ty = threadIdx.y;
-
-  // Index of the first sub-matrix of A processed by the block
-  size_type aBegin = wA * block_size * by;
-
-  // Index of the last sub-matrix of A processed by the block
-  size_type aEnd = aBegin + wA - 1;
-
-  // Step size used to iterate through the sub-matrices of A
-  size_type aStep = block_size;
-
-  // Index of the first sub-matrix of B processed by the block
-  size_type bBegin = block_size * bx;
-
-  // Step size used to iterate through the sub-matrices of B
-  size_type bStep = block_size * wB;
-
-  // Csub is used to store the element of the block sub-matrix
-  // that is computed by the thread
-  float Csub = 0;
-
-  // Loop over all the sub-matrices of A and B
-  // required to compute the block sub-matrix
-  for (size_type a = aBegin, b = bBegin; a <= aEnd; a += aStep, b += bStep) {
-    // Declaration of the shared memory array As used to
-    // store the sub-matrix of A
-    __shared__ float As[block_size][block_size];
-
-    // Declaration of the shared memory array Bs used to
-    // store the sub-matrix of B
-    __shared__ float Bs[block_size][block_size];
-
-    // Load the matrices from device memory
-    // to shared memory; each thread loads
-    // one element of each matrix
-    AS(ty, tx) = A[a + wA * ty + tx];
-    BS(ty, tx) = B[b + wB * ty + tx];
-
-    // Synchronize to make sure the matrices are loaded
-    __syncthreads();
-
-    // Multiply the two matrices together;
-    // each thread computes one element
-    // of the block sub-matrix
-#pragma unroll
-
-    for (size_type k = 0; k < block_size; ++k) Csub += AS(ty, k) * BS(k, tx);
-
-    // Synchronize to make sure that the preceding
-    // computation is done before loading two new
-    // sub-matrices of A and B in the next iteration
-    __syncthreads();
-  }
-
-  // Write the block sub-matrix to device memory;
-  // each thread writes one element
-  size_type c = wB * block_size * by + block_size * bx;
-  C[c + wB * ty + tx] = Csub;
-}
-
-// C wrappers around our template kernel
-extern "C" __global__ void matrixMul_bs8_64bit(float *C, float *A, float *B,
-                                               size_t wA, size_t wB) {
-  matrixMul<8, size_t>(C, A, B, wA, wB);
-}
-extern "C" __global__ void matrixMul_bs16_64bit(float *C, float *A, float *B,
-                                                size_t wA, size_t wB) {
-  matrixMul<16, size_t>(C, A, B, wA, wB);
-}
-extern "C" __global__ void matrixMul_bs32_64bit(float *C, float *A, float *B,
-                                                size_t wA, size_t wB) {
-  matrixMul<32, size_t>(C, A, B, wA, wB);
-}
-
-#endif  // #ifndef _MATRIXMUL_KERNEL_H_
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/.vscode/extensions.json b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/.vscode/launch.json b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/.vscode/tasks.json b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/Makefile b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/README.md b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/cuda_drvapi_dynlink.c b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/cuda_drvapi_dynlink.c
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/cuda_drvapi_dynlink.h b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/cuda_drvapi_dynlink.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/cuda_drvapi_dynlink_cuda.h b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/cuda_drvapi_dynlink_cuda.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/cuda_drvapi_dynlink_cuda_hipified.h b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/cuda_drvapi_dynlink_cuda_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/cuda_drvapi_dynlink_hipified.h b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/cuda_drvapi_dynlink_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/extras/README.TXT b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/extras/README.TXT
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/extras/matrixMul_kernel_32.ptx b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/extras/matrixMul_kernel_32.ptx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/extras/matrixMul_kernel_64.ptx b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/extras/matrixMul_kernel_64.ptx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/extras/ptx2c.py b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/extras/ptx2c.py
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/helper_cuda_drvapi.h b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/helper_cuda_drvapi.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/helper_cuda_drvapi_hipified.h b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/helper_cuda_drvapi_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul.h b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT.cpp b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_hipified.cpp b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2017.sln b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2017.vcxproj b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2019.sln b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2019.vcxproj b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2022.sln b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2022.vcxproj b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMulDynlinkJIT_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_gold.cpp b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_gold_hipified.cpp b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_hipified.h b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_kernel_32_ptxdump.c b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_kernel_32_ptxdump.c
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_kernel_32_ptxdump.h b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_kernel_32_ptxdump.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_kernel_32_ptxdump_hipified.h b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_kernel_32_ptxdump_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_kernel_64_ptxdump.c b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_kernel_64_ptxdump.c
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_kernel_64_ptxdump.h b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_kernel_64_ptxdump.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_kernel_64_ptxdump_hipified.h b/src/samples/Samples/0_Introduction/matrixMulDynlinkJIT/matrixMul_kernel_64_ptxdump_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/.vscode/extensions.json b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/.vscode/launch.json b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/.vscode/tasks.json b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/Makefile b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/README.md b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul.cpp b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_hipified.cpp b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_kernel.cu b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_kernel.cu.hip b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_kernel.cu.hip
old mode 100644
new mode 100755
index b365b74..e69de29
--- a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_kernel.cu.hip
@@ -1,132 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/**
- * Matrix multiplication: C = A * B.
- * Host code.
- *
- * This sample implements matrix multiplication as described in Chapter 3
- * of the programming guide.
- * It has been written for clarity of exposition to illustrate various CUDA
- * programming principles, not with the goal of providing the most
- * performant generic kernel for matrix multiplication.
- *
- * See also:
- * V. Volkov and J. Demmel, "Benchmarking GPUs to tune dense linear algebra,"
- * in Proc. 2008 ACM/IEEE Conf. on Supercomputing (SC '08),
- * Piscataway, NJ: IEEE Press, 2008, pp. Art. 31:1-11.
- */
-
-/**
- * Matrix multiplication (CUDA Kernel) on the device: C = A * B
- * wA is A's width and wB is B's width
- */
-
-#include <hip/hip_cooperative_groups.h>
-
-template <int BLOCK_SIZE>
-__device__ void matrixMulCUDA(float *C, float *A, float *B, int wA, int wB) {
-  // Handle to thread block group
-  cooperative_groups::thread_block cta =
-      cooperative_groups::this_thread_block();
-  // Block index
-  int bx = blockIdx.x;
-  int by = blockIdx.y;
-
-  // Thread index
-  int tx = threadIdx.x;
-  int ty = threadIdx.y;
-
-  // Index of the first sub-matrix of A processed by the block
-  int aBegin = wA * BLOCK_SIZE * by;
-
-  // Index of the last sub-matrix of A processed by the block
-  int aEnd = aBegin + wA - 1;
-
-  // Step size used to iterate through the sub-matrices of A
-  int aStep = BLOCK_SIZE;
-
-  // Index of the first sub-matrix of B processed by the block
-  int bBegin = BLOCK_SIZE * bx;
-
-  // Step size used to iterate through the sub-matrices of B
-  int bStep = BLOCK_SIZE * wB;
-
-  // Csub is used to store the element of the block sub-matrix
-  // that is computed by the thread
-  float Csub = 0;
-
-  // Loop over all the sub-matrices of A and B
-  // required to compute the block sub-matrix
-  for (int a = aBegin, b = bBegin; a <= aEnd; a += aStep, b += bStep) {
-    // Declaration of the shared memory array As used to
-    // store the sub-matrix of A
-    __shared__ float As[BLOCK_SIZE][BLOCK_SIZE];
-
-    // Declaration of the shared memory array Bs used to
-    // store the sub-matrix of B
-    __shared__ float Bs[BLOCK_SIZE][BLOCK_SIZE];
-
-    // Load the matrices from device memory
-    // to shared memory; each thread loads
-    // one element of each matrix
-    As[ty][tx] = A[a + wA * ty + tx];
-    Bs[ty][tx] = B[b + wB * ty + tx];
-
-    // Synchronize to make sure the matrices are loaded
-    cooperative_groups::sync(cta);
-
-// Multiply the two matrices together;
-// each thread computes one element
-// of the block sub-matrix
-#pragma unroll
-    for (int k = 0; k < BLOCK_SIZE; ++k) {
-      Csub += As[ty][k] * Bs[k][tx];
-    }
-
-    // Synchronize to make sure that the preceding
-    // computation is done before loading two new
-    // sub-matrices of A and B in the next iteration
-    cooperative_groups::sync(cta);
-  }
-
-  // Write the block sub-matrix to device memory;
-  // each thread writes one element
-  int c = wB * BLOCK_SIZE * by + BLOCK_SIZE * bx;
-  C[c + wB * ty + tx] = Csub;
-}
-
-extern "C" __global__ void matrixMulCUDA_block16(float *C, float *A, float *B,
-                                                 int wA, int wB) {
-  matrixMulCUDA<16>(C, A, B, wA, wB);
-}
-
-extern "C" __global__ void matrixMulCUDA_block32(float *C, float *A, float *B,
-                                                 int wA, int wB) {
-  matrixMulCUDA<32>(C, A, B, wA, wB);
-}
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2017.sln b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2017.vcxproj b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2019.sln b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2019.vcxproj b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2022.sln b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2022.vcxproj b/src/samples/Samples/0_Introduction/matrixMul_nvrtc/matrixMul_nvrtc_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/mergeSort/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/.vscode/extensions.json b/src/samples/Samples/0_Introduction/mergeSort/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/.vscode/launch.json b/src/samples/Samples/0_Introduction/mergeSort/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/.vscode/tasks.json b/src/samples/Samples/0_Introduction/mergeSort/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/Makefile b/src/samples/Samples/0_Introduction/mergeSort/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/NsightEclipse.xml b/src/samples/Samples/0_Introduction/mergeSort/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/README.md b/src/samples/Samples/0_Introduction/mergeSort/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/bitonic.cu b/src/samples/Samples/0_Introduction/mergeSort/bitonic.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/bitonic.cu.hip b/src/samples/Samples/0_Introduction/mergeSort/bitonic.cu.hip
old mode 100644
new mode 100755
index fc01b30..e69de29
--- a/src/samples/Samples/0_Introduction/mergeSort/bitonic.cu.hip
+++ b/src/samples/Samples/0_Introduction/mergeSort/bitonic.cu.hip
@@ -1,279 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-#include "helper_cuda_hipified.h"
-#include <assert.h>
-#include "mergeSort_common.h"
-
-inline __device__ void Comparator(uint &keyA, uint &valA, uint &keyB,
-                                  uint &valB, uint arrowDir) {
-  uint t;
-
-  if ((keyA > keyB) == arrowDir) {
-    t = keyA;
-    keyA = keyB;
-    keyB = t;
-    t = valA;
-    valA = valB;
-    valB = t;
-  }
-}
-
-__global__ void bitonicSortSharedKernel(uint *d_DstKey, uint *d_DstVal,
-                                        uint *d_SrcKey, uint *d_SrcVal,
-                                        uint arrayLength, uint sortDir) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  // Shared memory storage for one or more short vectors
-  __shared__ uint s_key[SHARED_SIZE_LIMIT];
-  __shared__ uint s_val[SHARED_SIZE_LIMIT];
-
-  // Offset to the beginning of subbatch and load data
-  d_SrcKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_SrcVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_DstKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_DstVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  s_key[threadIdx.x + 0] = d_SrcKey[0];
-  s_val[threadIdx.x + 0] = d_SrcVal[0];
-  s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
-      d_SrcKey[(SHARED_SIZE_LIMIT / 2)];
-  s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
-      d_SrcVal[(SHARED_SIZE_LIMIT / 2)];
-
-  for (uint size = 2; size < arrayLength; size <<= 1) {
-    // Bitonic merge
-    uint dir = (threadIdx.x & (size / 2)) != 0;
-
-    for (uint stride = size / 2; stride > 0; stride >>= 1) {
-      cg::sync(cta);
-      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
-      Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
-                 s_val[pos + stride], dir);
-    }
-  }
-
-  // ddd == sortDir for the last bitonic merge step
-  {
-    for (uint stride = arrayLength / 2; stride > 0; stride >>= 1) {
-      cg::sync(cta);
-      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
-      Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
-                 s_val[pos + stride], sortDir);
-    }
-  }
-
-  cg::sync(cta);
-  d_DstKey[0] = s_key[threadIdx.x + 0];
-  d_DstVal[0] = s_val[threadIdx.x + 0];
-  d_DstKey[(SHARED_SIZE_LIMIT / 2)] =
-      s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
-  d_DstVal[(SHARED_SIZE_LIMIT / 2)] =
-      s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
-}
-
-// Helper function (also used by odd-even merge sort)
-extern "C" uint factorRadix2(uint *log2L, uint L) {
-  if (!L) {
-    *log2L = 0;
-    return 0;
-  }
- else {
-    for (*log2L = 0; (L & 1) == 0; L >>= 1, *log2L++) ;
-    return L;
-  }
-}
-
-extern "C" void bitonicSortShared(uint *d_DstKey, uint *d_DstVal,
-                                  uint *d_SrcKey, uint *d_SrcVal,
-                                  uint batchSize, uint arrayLength,
-                                  uint sortDir) {
-  // Nothing to sort
-  if (arrayLength < 2) {
-    return;
-  }
-
-  // Only power-of-two array lengths are supported by this implementation
-  uint log2L;
-  uint factorizationRemainder = factorRadix2(&log2L, arrayLength);
-  assert(factorizationRemainder == 1);
-
-  uint blockCount = batchSize * arrayLength / SHARED_SIZE_LIMIT;
-  uint threadCount = SHARED_SIZE_LIMIT / 2;
-
-  assert(arrayLength <= SHARED_SIZE_LIMIT);
-  assert((batchSize * arrayLength) % SHARED_SIZE_LIMIT == 0);
-
-  bitonicSortSharedKernel<<<blockCount, threadCount>>>(
-      d_DstKey, d_DstVal, d_SrcKey, d_SrcVal, arrayLength, sortDir);
-  getLastCudaError("bitonicSortSharedKernel<<<>>> failed!\n");
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Merge step 3: merge elementary intervals
-////////////////////////////////////////////////////////////////////////////////
-static inline __host__ __device__ uint iDivUp(uint a, uint b) {
-  return ((a % b) == 0) ? (a / b) : (a / b + 1);
-}
-
-static inline __host__ __device__ uint getSampleCount(uint dividend) {
-  return iDivUp(dividend, SAMPLE_STRIDE);
-}
-
-template <uint sortDir>
-static inline __device__ void ComparatorExtended(uint &keyA, uint &valA,
-                                                 uint &flagA, uint &keyB,
-                                                 uint &valB, uint &flagB,
-                                                 uint arrowDir) {
-  uint t;
-
-  if ((!(flagA || flagB) && ((keyA > keyB) == arrowDir)) ||
-      ((arrowDir == sortDir) && (flagA == 1)) ||
-      ((arrowDir != sortDir) && (flagB == 1))) {
-    t = keyA;
-    keyA = keyB;
-    keyB = t;
-    t = valA;
-    valA = valB;
-    valB = t;
-    t = flagA;
-    flagA = flagB;
-    flagB = t;
-  }
-}
-
-template <uint sortDir>
-__global__ void bitonicMergeElementaryIntervalsKernel(
-    uint *d_DstKey, uint *d_DstVal, uint *d_SrcKey, uint *d_SrcVal,
-    uint *d_LimitsA, uint *d_LimitsB, uint stride, uint N) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  __shared__ uint s_key[2 * SAMPLE_STRIDE];
-  __shared__ uint s_val[2 * SAMPLE_STRIDE];
-  __shared__ uint s_inf[2 * SAMPLE_STRIDE];
-
-  const uint intervalI = blockIdx.x & ((2 * stride) / SAMPLE_STRIDE - 1);
-  const uint segmentBase = (blockIdx.x - intervalI) * SAMPLE_STRIDE;
-  d_SrcKey += segmentBase;
-  d_SrcVal += segmentBase;
-  d_DstKey += segmentBase;
-  d_DstVal += segmentBase;
-
-  // Set up threadblock-wide parameters
-  __shared__ uint startSrcA, lenSrcA, startSrcB, lenSrcB, startDst;
-
-  if (threadIdx.x == 0) {
-    uint segmentElementsA = stride;
-    uint segmentElementsB =min(stride, N - segmentBase - stride);
-    uint segmentSamplesA = stride / SAMPLE_STRIDE;
-    uint segmentSamplesB = getSampleCount(segmentElementsB);
-    uint segmentSamples = segmentSamplesA + segmentSamplesB;
-
-    startSrcA = d_LimitsA[blockIdx.x];
-    startSrcB = d_LimitsB[blockIdx.x];
-    startDst = startSrcA + startSrcB;
-
-    uint endSrcA = (intervalI + 1 < segmentSamples) ? d_LimitsA[blockIdx.x + 1]
-                                                    : segmentElementsA;
-    uint endSrcB = (intervalI + 1 < segmentSamples) ? d_LimitsB[blockIdx.x + 1]
-                                                    : segmentElementsB;
-    lenSrcA = endSrcA - startSrcA;
-    lenSrcB = endSrcB - startSrcB;
-  }
-
-  s_inf[threadIdx.x + 0] = 1;
-  s_inf[threadIdx.x + SAMPLE_STRIDE] = 1;
-
-  // Load input data
-  cg::sync(cta);
-
-  if (threadIdx.x < lenSrcA) {
-    s_key[threadIdx.x] = d_SrcKey[0 + startSrcA + threadIdx.x];
-    s_val[threadIdx.x] = d_SrcVal[0 + startSrcA + threadIdx.x];
-    s_inf[threadIdx.x] = 0;
-  }
-
-  // Prepare for bitonic merge by inversing the ordering
-  if (threadIdx.x < lenSrcB) {
-    s_key[2 * SAMPLE_STRIDE - 1 - threadIdx.x] =
-        d_SrcKey[stride + startSrcB + threadIdx.x];
-    s_val[2 * SAMPLE_STRIDE - 1 - threadIdx.x] =
-        d_SrcVal[stride + startSrcB + threadIdx.x];
-    s_inf[2 * SAMPLE_STRIDE - 1 - threadIdx.x] = 0;
-  }
-
-  //"Extended" bitonic merge
-  for (uint stride = SAMPLE_STRIDE; stride > 0; stride >>= 1) {
-    cg::sync(cta);
-    uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
-    ComparatorExtended<sortDir>(s_key[pos + 0], s_val[pos + 0], s_inf[pos + 0],
-                                s_key[pos + stride], s_val[pos + stride],
-                                s_inf[pos + stride], sortDir);
-  }
-
-  // Store sorted data
-  cg::sync(cta);
-  d_DstKey += startDst;
-  d_DstVal += startDst;
-
-  if (threadIdx.x < lenSrcA) {
-    d_DstKey[threadIdx.x] = s_key[threadIdx.x];
-    d_DstVal[threadIdx.x] = s_val[threadIdx.x];
-  }
-
-  if (threadIdx.x < lenSrcB) {
-    d_DstKey[lenSrcA + threadIdx.x] = s_key[lenSrcA + threadIdx.x];
-    d_DstVal[lenSrcA + threadIdx.x] = s_val[lenSrcA + threadIdx.x];
-  }
-}
-
-extern "C" void bitonicMergeElementaryIntervals(uint *d_DstKey, uint *d_DstVal,
-                                                uint *d_SrcKey, uint *d_SrcVal,
-                                                uint *d_LimitsA,
-                                                uint *d_LimitsB, uint stride,
-                                                uint N, uint sortDir) {
-  uint lastSegmentElements = N % (2 * stride);
-
-  uint mergePairs = (lastSegmentElements > stride)
-                        ? getSampleCount(N)
-                        : (N - lastSegmentElements) / SAMPLE_STRIDE;
-
-  if (sortDir) {
-    bitonicMergeElementaryIntervalsKernel<1U><<<mergePairs, SAMPLE_STRIDE>>>(
-        d_DstKey, d_DstVal, d_SrcKey, d_SrcVal, d_LimitsA, d_LimitsB, stride,
-        N);
-    getLastCudaError("mergeElementaryIntervalsKernel<1> failed\n");
-  } else {
-    bitonicMergeElementaryIntervalsKernel<0U><<<mergePairs, SAMPLE_STRIDE>>>(
-        d_DstKey, d_DstVal, d_SrcKey, d_SrcVal, d_LimitsA, d_LimitsB, stride,
-        N);
-    getLastCudaError("mergeElementaryIntervalsKernel<0> failed\n");
-  }
-}
diff --git a/src/samples/Samples/0_Introduction/mergeSort/main.cpp b/src/samples/Samples/0_Introduction/mergeSort/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/main_hipified.cpp b/src/samples/Samples/0_Introduction/mergeSort/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort.cu b/src/samples/Samples/0_Introduction/mergeSort/mergeSort.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort.cu.hip b/src/samples/Samples/0_Introduction/mergeSort/mergeSort.cu.hip
old mode 100644
new mode 100755
index 04afbd9..e69de29
--- a/src/samples/Samples/0_Introduction/mergeSort/mergeSort.cu.hip
+++ b/src/samples/Samples/0_Introduction/mergeSort/mergeSort.cu.hip
@@ -1,530 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Based on "Designing efficient sorting algorithms for manycore GPUs"
- * by Nadathur Satish, Mark Harris, and Michael Garland
- * http://mgarland.org/files/papers/gpusort-ipdps09.pdf
- *
- * Victor Podlozhnyuk 09/24/2009
- */
-
-#include <assert.h>
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-#include "HIPCHECK.h"
-#include "helper_cuda_hipified.h"
-#include "mergeSort_common.h"
-
-////////////////////////////////////////////////////////////////////////////////
-// Helper functions
-////////////////////////////////////////////////////////////////////////////////
-static inline __host__ __device__ uint iDivUp(uint a, uint b) {
-  return ((a % b) == 0) ? (a / b) : (a / b + 1);
-}
-
-static inline __host__ __device__ uint getSampleCount(uint dividend) {
-  return iDivUp(dividend, SAMPLE_STRIDE);
-}
-
-#define W (sizeof(uint) * 8)
-static inline __device__ uint nextPowerOfTwo(uint x) {
-  /*
-      --x;
-      x |= x >> 1;
-      x |= x >> 2;
-      x |= x >> 4;
-      x |= x >> 8;
-      x |= x >> 16;
-      return ++x;
-  */
-  return 1U << (W - __clz(x - 1));
-}
-
-template <uint sortDir>
-static inline __device__ uint binarySearchInclusive(uint val, uint *data,
-                                                    uint L, uint stride) {
-  if (L == 0) {
-    return 0;
-  }
-
-  uint pos = 0;
-
-  for (; stride > 0; stride >>= 1) {
-    uint newPos = min(pos + stride, L);
-
-    if ((sortDir && (data[newPos - 1] <= val)) ||
-        (!sortDir && (data[newPos - 1] >= val))) {
-      pos = newPos;
-    }
-  }
-
-  return pos;
-}
-
-template <uint sortDir>
-static inline __device__ uint binarySearchExclusive(uint val, uint *data,
-                                                    uint L, uint stride) {
-  if (L == 0) {
-    return 0;
-  }
-
-  uint pos = 0;
-
-  for (; stride > 0; stride >>= 1) {
-    uint newPos = min(pos + stride, L);
-
-    if ((sortDir && (data[newPos - 1] < val)) ||
-        (!sortDir && (data[newPos - 1] > val))) {
-      pos = newPos;
-    }
-  }
-
-  return pos;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Bottom-level merge sort (binary search-based)
-////////////////////////////////////////////////////////////////////////////////
-template <uint sortDir>
-__global__ void mergeSortSharedKernel(uint *d_DstKey, uint *d_DstVal,
-                                      uint *d_SrcKey, uint *d_SrcVal,
-                                      uint arrayLength) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  __shared__ uint s_key[SHARED_SIZE_LIMIT];
-  __shared__ uint s_val[SHARED_SIZE_LIMIT];
-
-  d_SrcKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_SrcVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_DstKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_DstVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  s_key[threadIdx.x + 0] = d_SrcKey[0];
-  s_val[threadIdx.x + 0] = d_SrcVal[0];
-  s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
-      d_SrcKey[(SHARED_SIZE_LIMIT / 2)];
-  s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
-      d_SrcVal[(SHARED_SIZE_LIMIT / 2)];
-
-  for (uint stride = 1; stride < arrayLength; stride <<= 1) {
-    uint lPos = threadIdx.x & (stride - 1);
-    uint *baseKey = s_key + 2 * (threadIdx.x - lPos);
-    uint *baseVal = s_val + 2 * (threadIdx.x - lPos);
-
-    cg::sync(cta);
-    uint keyA = baseKey[lPos + 0];
-    uint valA = baseVal[lPos + 0];
-    uint keyB = baseKey[lPos + stride];
-    uint valB = baseVal[lPos + stride];
-    uint posA =
-        binarySearchExclusive<sortDir>(keyA, baseKey + stride, stride, stride) +
-        lPos;
-    uint posB =
-        binarySearchInclusive<sortDir>(keyB, baseKey + 0, stride, stride) +
-        lPos;
-
-    cg::sync(cta);
-    baseKey[posA] = keyA;
-    baseVal[posA] = valA;
-    baseKey[posB] = keyB;
-    baseVal[posB] = valB;
-  }
-
-  cg::sync(cta);
-  d_DstKey[0] = s_key[threadIdx.x + 0];
-  d_DstVal[0] = s_val[threadIdx.x + 0];
-  d_DstKey[(SHARED_SIZE_LIMIT / 2)] =
-      s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
-  d_DstVal[(SHARED_SIZE_LIMIT / 2)] =
-      s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
-}
-
-static void mergeSortShared(uint *d_DstKey, uint *d_DstVal, uint *d_SrcKey,
-                            uint *d_SrcVal, uint batchSize, uint arrayLength,
-                            uint sortDir) {
-  if (arrayLength < 2) {
-    return;
-  }
-
-  assert(SHARED_SIZE_LIMIT % arrayLength == 0);
-  assert(((batchSize * arrayLength) % SHARED_SIZE_LIMIT) == 0);
-  uint blockCount = batchSize * arrayLength / SHARED_SIZE_LIMIT;
-  uint threadCount = SHARED_SIZE_LIMIT / 2;
-
-  if (sortDir) {
-    mergeSortSharedKernel<1U><<<blockCount, threadCount>>>(
-        d_DstKey, d_DstVal, d_SrcKey, d_SrcVal, arrayLength);
-    getLastCudaError("mergeSortShared<1><<<>>> failed\n");
-  } else {
-    mergeSortSharedKernel<0U><<<blockCount, threadCount>>>(
-        d_DstKey, d_DstVal, d_SrcKey, d_SrcVal, arrayLength);
-    getLastCudaError("mergeSortShared<0><<<>>> failed\n");
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Merge step 1: generate sample ranks
-////////////////////////////////////////////////////////////////////////////////
-template <uint sortDir>
-__global__ void generateSampleRanksKernel(uint *d_RanksA, uint *d_RanksB,
-                                          uint *d_SrcKey, uint stride, uint N,
-                                          uint threadCount) {
-  uint pos = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (pos >= threadCount) {
-    return;
-  }
-
-  const uint i = pos & ((stride / SAMPLE_STRIDE) - 1);
-  const uint segmentBase = (pos - i) * (2 * SAMPLE_STRIDE);
-  d_SrcKey += segmentBase;
-  d_RanksA += segmentBase / SAMPLE_STRIDE;
-  d_RanksB += segmentBase / SAMPLE_STRIDE;
-
-  const uint segmentElementsA = stride;
-  const uint segmentElementsB = min(stride, N - segmentBase - stride);
-  const uint segmentSamplesA = getSampleCount(segmentElementsA);
-  const uint segmentSamplesB = getSampleCount(segmentElementsB);
-
-  if (i < segmentSamplesA) {
-    d_RanksA[i] = i * SAMPLE_STRIDE;
-    d_RanksB[i] = binarySearchExclusive<sortDir>(
-        d_SrcKey[i * SAMPLE_STRIDE], d_SrcKey + stride, segmentElementsB,
-        nextPowerOfTwo(segmentElementsB));
-  }
-
-  if (i < segmentSamplesB) {
-    d_RanksB[(stride / SAMPLE_STRIDE) + i] = i * SAMPLE_STRIDE;
-    d_RanksA[(stride / SAMPLE_STRIDE) + i] = binarySearchInclusive<sortDir>(
-        d_SrcKey[stride + i * SAMPLE_STRIDE], d_SrcKey + 0, segmentElementsA,
-        nextPowerOfTwo(segmentElementsA));
-  }
-}
-
-static void generateSampleRanks(uint *d_RanksA, uint *d_RanksB, uint *d_SrcKey,
-                                uint stride, uint N, uint sortDir) {
-  uint lastSegmentElements = N % (2 * stride);
-  uint threadCount =
-      (lastSegmentElements > stride)
-          ? (N + 2 * stride - lastSegmentElements) / (2 * SAMPLE_STRIDE)
-          : (N - lastSegmentElements) / (2 * SAMPLE_STRIDE);
-
-  if (sortDir) {
-    generateSampleRanksKernel<1U><<<iDivUp(threadCount, 256), 256>>>(
-        d_RanksA, d_RanksB, d_SrcKey, stride, N, threadCount);
-    getLastCudaError("generateSampleRanksKernel<1U><<<>>> failed\n");
-  } else {
-    generateSampleRanksKernel<0U><<<iDivUp(threadCount, 256), 256>>>(
-        d_RanksA, d_RanksB, d_SrcKey, stride, N, threadCount);
-    getLastCudaError("generateSampleRanksKernel<0U><<<>>> failed\n");
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Merge step 2: generate sample ranks and indices
-////////////////////////////////////////////////////////////////////////////////
-__global__ void mergeRanksAndIndicesKernel(uint *d_Limits, uint *d_Ranks,
-                                           uint stride, uint N,
-                                           uint threadCount) {
-  uint pos = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (pos >= threadCount) {
-    return;
-  }
-
-  const uint i = pos & ((stride / SAMPLE_STRIDE) - 1);
-  const uint segmentBase = (pos - i) * (2 * SAMPLE_STRIDE);
-  d_Ranks += (pos - i) * 2;
-  d_Limits += (pos - i) * 2;
-
-  const uint segmentElementsA = stride;
-  const uint segmentElementsB = min(stride, N - segmentBase - stride);
-  const uint segmentSamplesA = getSampleCount(segmentElementsA);
-  const uint segmentSamplesB = getSampleCount(segmentElementsB);
-
-  if (i < segmentSamplesA) {
-    uint dstPos = binarySearchExclusive<1U>(
-                      d_Ranks[i], d_Ranks + segmentSamplesA, segmentSamplesB,
-                      nextPowerOfTwo(segmentSamplesB)) +
-                  i;
-    d_Limits[dstPos] = d_Ranks[i];
-  }
-
-  if (i < segmentSamplesB) {
-    uint dstPos = binarySearchInclusive<1U>(d_Ranks[segmentSamplesA + i],
-                                            d_Ranks, segmentSamplesA,
-                                            nextPowerOfTwo(segmentSamplesA)) +
-                  i;
-    d_Limits[dstPos] = d_Ranks[segmentSamplesA + i];
-  }
-}
-
-static void mergeRanksAndIndices(uint *d_LimitsA, uint *d_LimitsB,
-                                 uint *d_RanksA, uint *d_RanksB, uint stride,
-                                 uint N) {
-  uint lastSegmentElements = N % (2 * stride);
-  uint threadCount =
-      (lastSegmentElements > stride)
-          ? (N + 2 * stride - lastSegmentElements) / (2 * SAMPLE_STRIDE)
-          : (N - lastSegmentElements) / (2 * SAMPLE_STRIDE);
-
-  mergeRanksAndIndicesKernel<<<iDivUp(threadCount, 256), 256>>>(
-      d_LimitsA, d_RanksA, stride, N, threadCount);
-  getLastCudaError("mergeRanksAndIndicesKernel(A)<<<>>> failed\n");
-
-  mergeRanksAndIndicesKernel<<<iDivUp(threadCount, 256), 256>>>(
-      d_LimitsB, d_RanksB, stride, N, threadCount);
-  getLastCudaError("mergeRanksAndIndicesKernel(B)<<<>>> failed\n");
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Merge step 3: merge elementary intervals
-////////////////////////////////////////////////////////////////////////////////
-template <uint sortDir>
-inline __device__ void merge(uint *dstKey, uint *dstVal, uint *srcAKey,
-                             uint *srcAVal, uint *srcBKey, uint *srcBVal,
-                             uint lenA, uint nPowTwoLenA, uint lenB,
-                             uint nPowTwoLenB, cg::thread_block cta) {
-  uint keyA, valA, keyB, valB, dstPosA, dstPosB;
-
-  if (threadIdx.x < lenA) {
-    keyA = srcAKey[threadIdx.x];
-    valA = srcAVal[threadIdx.x];
-    dstPosA = binarySearchExclusive<sortDir>(keyA, srcBKey, lenB, nPowTwoLenB) +
-              threadIdx.x;
-  }
-
-  if (threadIdx.x < lenB) {
-    keyB = srcBKey[threadIdx.x];
-    valB = srcBVal[threadIdx.x];
-    dstPosB = binarySearchInclusive<sortDir>(keyB, srcAKey, lenA, nPowTwoLenA) +
-              threadIdx.x;
-  }
-
-  cg::sync(cta);
-
-  if (threadIdx.x < lenA) {
-    dstKey[dstPosA] = keyA;
-    dstVal[dstPosA] = valA;
-  }
-
-  if (threadIdx.x < lenB) {
-    dstKey[dstPosB] = keyB;
-    dstVal[dstPosB] = valB;
-  }
-}
-
-template <uint sortDir>
-__global__ void mergeElementaryIntervalsKernel(uint *d_DstKey, uint *d_DstVal,
-                                               uint *d_SrcKey, uint *d_SrcVal,
-                                               uint *d_LimitsA, uint *d_LimitsB,
-                                               uint stride, uint N) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  __shared__ uint s_key[2 * SAMPLE_STRIDE];
-  __shared__ uint s_val[2 * SAMPLE_STRIDE];
-
-  const uint intervalI = blockIdx.x & ((2 * stride) / SAMPLE_STRIDE - 1);
-  const uint segmentBase = (blockIdx.x - intervalI) * SAMPLE_STRIDE;
-  d_SrcKey += segmentBase;
-  d_SrcVal += segmentBase;
-  d_DstKey += segmentBase;
-  d_DstVal += segmentBase;
-
-  // Set up threadblock-wide parameters
-  __shared__ uint startSrcA, startSrcB, lenSrcA, lenSrcB, startDstA, startDstB;
-
-  if (threadIdx.x == 0) {
-    uint segmentElementsA = stride;
-    uint segmentElementsB = min(stride, N - segmentBase - stride);
-    uint segmentSamplesA = getSampleCount(segmentElementsA);
-    uint segmentSamplesB = getSampleCount(segmentElementsB);
-    uint segmentSamples = segmentSamplesA + segmentSamplesB;
-
-    startSrcA = d_LimitsA[blockIdx.x];
-    startSrcB = d_LimitsB[blockIdx.x];
-    uint endSrcA = (intervalI + 1 < segmentSamples) ? d_LimitsA[blockIdx.x + 1]
-                                                    : segmentElementsA;
-    uint endSrcB = (intervalI + 1 < segmentSamples) ? d_LimitsB[blockIdx.x + 1]
-                                                    : segmentElementsB;
-    lenSrcA = endSrcA - startSrcA;
-    lenSrcB = endSrcB - startSrcB;
-    startDstA = startSrcA + startSrcB;
-    startDstB = startDstA + lenSrcA;
-  }
-
-  // Load main input data
-  cg::sync(cta);
-
-  if (threadIdx.x < lenSrcA) {
-    s_key[threadIdx.x + 0] = d_SrcKey[0 + startSrcA + threadIdx.x];
-    s_val[threadIdx.x + 0] = d_SrcVal[0 + startSrcA + threadIdx.x];
-  }
-
-  if (threadIdx.x < lenSrcB) {
-    s_key[threadIdx.x + SAMPLE_STRIDE] =
-        d_SrcKey[stride + startSrcB + threadIdx.x];
-    s_val[threadIdx.x + SAMPLE_STRIDE] =
-        d_SrcVal[stride + startSrcB + threadIdx.x];
-  }
-
-  // Merge data in shared memory
-  cg::sync(cta);
-  merge<sortDir>(s_key, s_val, s_key + 0, s_val + 0, s_key + SAMPLE_STRIDE,
-                 s_val + SAMPLE_STRIDE, lenSrcA, SAMPLE_STRIDE, lenSrcB,
-                 SAMPLE_STRIDE, cta);
-
-  // Store merged data
-  cg::sync(cta);
-
-  if (threadIdx.x < lenSrcA) {
-    d_DstKey[startDstA + threadIdx.x] = s_key[threadIdx.x];
-    d_DstVal[startDstA + threadIdx.x] = s_val[threadIdx.x];
-  }
-
-  if (threadIdx.x < lenSrcB) {
-    d_DstKey[startDstB + threadIdx.x] = s_key[lenSrcA + threadIdx.x];
-    d_DstVal[startDstB + threadIdx.x] = s_val[lenSrcA + threadIdx.x];
-  }
-}
-
-static void mergeElementaryIntervals(uint *d_DstKey, uint *d_DstVal,
-                                     uint *d_SrcKey, uint *d_SrcVal,
-                                     uint *d_LimitsA, uint *d_LimitsB,
-                                     uint stride, uint N, uint sortDir) {
-  uint lastSegmentElements = N % (2 * stride);
-  uint mergePairs = (lastSegmentElements > stride)
-                        ? getSampleCount(N)
-                        : (N - lastSegmentElements) / SAMPLE_STRIDE;
-
-  if (sortDir) {
-    mergeElementaryIntervalsKernel<1U><<<mergePairs, SAMPLE_STRIDE>>>(
-        d_DstKey, d_DstVal, d_SrcKey, d_SrcVal, d_LimitsA, d_LimitsB, stride,
-        N);
-    getLastCudaError("mergeElementaryIntervalsKernel<1> failed\n");
-  } else {
-    mergeElementaryIntervalsKernel<0U><<<mergePairs, SAMPLE_STRIDE>>>(
-        d_DstKey, d_DstVal, d_SrcKey, d_SrcVal, d_LimitsA, d_LimitsB, stride,
-        N);
-    getLastCudaError("mergeElementaryIntervalsKernel<0> failed\n");
-  }
-}
-
-extern "C" void bitonicSortShared(uint *d_DstKey, uint *d_DstVal,
-                                  uint *d_SrcKey, uint *d_SrcVal,
-                                  uint batchSize, uint arrayLength,
-                                  uint sortDir);
-
-extern "C" void bitonicMergeElementaryIntervals(uint *d_DstKey, uint *d_DstVal,
-                                                uint *d_SrcKey, uint *d_SrcVal,
-                                                uint *d_LimitsA,
-                                                uint *d_LimitsB, uint stride,
-                                                uint N, uint sortDir);
-
-static uint *d_RanksA, *d_RanksB, *d_LimitsA, *d_LimitsB;
-static const uint MAX_SAMPLE_COUNT = 32768;
-
-extern "C" void initMergeSort(void) {
-  HIPCHECK(
-      hipMalloc((void **)&d_RanksA, MAX_SAMPLE_COUNT * sizeof(uint)));
-  HIPCHECK(
-      hipMalloc((void **)&d_RanksB, MAX_SAMPLE_COUNT * sizeof(uint)));
-  HIPCHECK(
-      hipMalloc((void **)&d_LimitsA, MAX_SAMPLE_COUNT * sizeof(uint)));
-  HIPCHECK(
-      hipMalloc((void **)&d_LimitsB, MAX_SAMPLE_COUNT * sizeof(uint)));
-}
-
-extern "C" void closeMergeSort(void) {
-  HIPCHECK(hipFree(d_RanksA));
-  HIPCHECK(hipFree(d_RanksB));
-  HIPCHECK(hipFree(d_LimitsB));
-  HIPCHECK(hipFree(d_LimitsA));
-}
-
-extern "C" void mergeSort(uint *d_DstKey, uint *d_DstVal, uint *d_BufKey,
-                          uint *d_BufVal, uint *d_SrcKey, uint *d_SrcVal,
-                          uint N, uint sortDir) {
-  uint stageCount = 0;
-
-  for (uint stride = SHARED_SIZE_LIMIT; stride < N; stride <<= 1, stageCount++)
-    ;
-
-  uint *ikey, *ival, *okey, *oval;
-
-  if (stageCount & 1) {
-    ikey = d_BufKey;
-    ival = d_BufVal;
-    okey = d_DstKey;
-    oval = d_DstVal;
-  } else {
-    ikey = d_DstKey;
-    ival = d_DstVal;
-    okey = d_BufKey;
-    oval = d_BufVal;
-  }
-
-  assert(N <= (SAMPLE_STRIDE * MAX_SAMPLE_COUNT));
-  assert(N % SHARED_SIZE_LIMIT == 0);
-  mergeSortShared(ikey, ival, d_SrcKey, d_SrcVal, N / SHARED_SIZE_LIMIT,
-                  SHARED_SIZE_LIMIT, sortDir);
-
-  for (uint stride = SHARED_SIZE_LIMIT; stride < N; stride <<= 1) {
-    uint lastSegmentElements = N % (2 * stride);
-
-    // Find sample ranks and prepare for limiters merge
-    generateSampleRanks(d_RanksA, d_RanksB, ikey, stride, N, sortDir);
-
-    // Merge ranks and indices
-    mergeRanksAndIndices(d_LimitsA, d_LimitsB, d_RanksA, d_RanksB, stride, N);
-
-    // Merge elementary intervals
-    mergeElementaryIntervals(okey, oval, ikey, ival, d_LimitsA, d_LimitsB,
-                             stride, N, sortDir);
-
-    if (lastSegmentElements <= stride) {
-      // Last merge segment consists of a single array which just needs to be
-      // passed through
-      HIPCHECK(hipMemcpy(
-          okey + (N - lastSegmentElements), ikey + (N - lastSegmentElements),
-          lastSegmentElements * sizeof(uint), hipMemcpyDeviceToDevice));
-      HIPCHECK(hipMemcpy(
-          oval + (N - lastSegmentElements), ival + (N - lastSegmentElements),
-          lastSegmentElements * sizeof(uint), hipMemcpyDeviceToDevice));
-    }
-
-    uint *t;
-    t = ikey;
-    ikey = okey;
-    okey = t;
-    t = ival;
-    ival = oval;
-    oval = t;
-  }
-}
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort.out b/src/samples/Samples/0_Introduction/mergeSort/mergeSort.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_common.h b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_common_hipified.h b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_host.cpp b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_host.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_host_hipified.cpp b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_host_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_validate.cpp b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_validate.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_validate_hipified.cpp b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_validate_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2017.sln b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2017.vcxproj b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2019.sln b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2019.vcxproj b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2022.sln b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2022.vcxproj b/src/samples/Samples/0_Introduction/mergeSort/mergeSort_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleAWBarrier/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleAWBarrier/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleAWBarrier/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleAWBarrier/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/Makefile b/src/samples/Samples/0_Introduction/simpleAWBarrier/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleAWBarrier/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/README.md b/src/samples/Samples/0_Introduction/simpleAWBarrier/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier.cu b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier.cu.hip b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier.cu.hip
old mode 100644
new mode 100755
index 2b5b24a..097e148
--- a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier.cu.hip
@@ -28,8 +28,6 @@
 
 // Includes, system
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 
 // Includes CUDA
 #include <hip/hip_runtime.h>
@@ -37,10 +35,10 @@
 #include <hip/hip_cooperative_groups.h>
 
 // Utilities and timing functions
-#include "helper_functions.h"  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
+#include <helper_functions.h>  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
 
 // CUDA helper functions
-#include "helper_cuda_hipified.h"  // helper functions for CUDA error check
+#include <helper_cuda.h>  // helper functions for CUDA error check
 
 namespace cg = cooperative_groups;
 
@@ -147,7 +145,7 @@ int main(int argc, char **argv) {
   int dev = findCudaDevice(argc, (const char **)argv);
 
   int major = 0;
-  HIPCHECK(
+  checkCudaErrors(
       hipDeviceGetAttribute(&major, hipDeviceAttributeComputeCapabilityMajor, dev));
 
   // Arrive-Wait Barrier require a GPU of Volta (SM7X) architecture or higher.
@@ -157,7 +155,7 @@ int main(int argc, char **argv) {
   }
 
   int supportsCooperativeLaunch = 0;
-  HIPCHECK(hipDeviceGetAttribute(&supportsCooperativeLaunch,
+  checkCudaErrors(hipDeviceGetAttribute(&supportsCooperativeLaunch,
                                          hipDeviceAttributeCooperativeLaunch, dev));
 
   if (!supportsCooperativeLaunch) {
@@ -180,11 +178,11 @@ int runNormVecByDotProductAWBarrier(int argc, char **argv, int deviceId) {
   double *d_partialResults;
   int size = 10000000;
 
-  HIPCHECK(hipHostMalloc(&vecA, sizeof(float) * size));
-  HIPCHECK(hipHostMalloc(&vecB, sizeof(float) * size));
+  checkCudaErrors(hipHostMalloc(&vecA, sizeof(float) * size));
+  checkCudaErrors(hipHostMalloc(&vecB, sizeof(float) * size));
 
-  HIPCHECK(hipMalloc(&d_vecA, sizeof(float) * size));
-  HIPCHECK(hipMalloc(&d_vecB, sizeof(float) * size));
+  checkCudaErrors(hipMalloc(&d_vecA, sizeof(float) * size));
+  checkCudaErrors(hipMalloc(&d_vecB, sizeof(float) * size));
 
   float baseVal = 2.0;
   for (int i = 0; i < size; i++) {
@@ -192,31 +190,31 @@ int runNormVecByDotProductAWBarrier(int argc, char **argv, int deviceId) {
   }
 
   hipStream_t stream;
-  HIPCHECK(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
+  checkCudaErrors(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
 
-  HIPCHECK(hipMemcpyAsync(d_vecA, vecA, sizeof(float) * size,
+  checkCudaErrors(hipMemcpyAsync(d_vecA, vecA, sizeof(float) * size,
                                   hipMemcpyHostToDevice, stream));
-  HIPCHECK(hipMemcpyAsync(d_vecB, vecB, sizeof(float) * size,
+  checkCudaErrors(hipMemcpyAsync(d_vecB, vecB, sizeof(float) * size,
                                   hipMemcpyHostToDevice, stream));
 
   // Kernel configuration, where a one-dimensional
   // grid and one-dimensional blocks are configured.
   int minGridSize = 0, blockSize = 0;
-  HIPCHECK(hipOccupancyMaxPotentialBlockSize(
+  checkCudaErrors(hipOccupancyMaxPotentialBlockSize(
       &minGridSize, &blockSize, (void *)normVecByDotProductAWBarrier, 0, size));
 
   int smemSize = ((blockSize / 32) + 1) * sizeof(double);
 
   int numBlocksPerSm = 0;
-  HIPCHECK(hipOccupancyMaxActiveBlocksPerMultiprocessor(
+  checkCudaErrors(hipOccupancyMaxActiveBlocksPerMultiprocessor(
       &numBlocksPerSm, normVecByDotProductAWBarrier, blockSize, smemSize));
 
   int multiProcessorCount = 0;
-  HIPCHECK(hipDeviceGetAttribute(
+  checkCudaErrors(hipDeviceGetAttribute(
       &multiProcessorCount, hipDeviceAttributeMultiprocessorCount, deviceId));
 
   minGridSize = multiProcessorCount * numBlocksPerSm;
-  HIPCHECK(hipMalloc(&d_partialResults, minGridSize * sizeof(double)));
+  checkCudaErrors(hipMalloc(&d_partialResults, minGridSize * sizeof(double)));
 
   printf(
       "Launching normVecByDotProductAWBarrier kernel with numBlocks = %d "
@@ -228,13 +226,13 @@ int runNormVecByDotProductAWBarrier(int argc, char **argv, int deviceId) {
   void *kernelArgs[] = {(void *)&d_vecA, (void *)&d_vecB,
                         (void *)&d_partialResults, (void *)&size};
 
-  HIPCHECK(
+  checkCudaErrors(
       hipLaunchCooperativeKernel((void *)normVecByDotProductAWBarrier, dimGrid,
                                   dimBlock, kernelArgs, smemSize, stream));
 
-  HIPCHECK(hipMemcpyAsync(vecA, d_vecA, sizeof(float) * size,
+  checkCudaErrors(hipMemcpyAsync(vecA, d_vecA, sizeof(float) * size,
                                   hipMemcpyDeviceToHost, stream));
-  HIPCHECK(hipStreamSynchronize(stream));
+  checkCudaErrors(hipStreamSynchronize(stream));
 
   float expectedResult = (baseVal / sqrt(size * baseVal * baseVal));
   unsigned int matches = 0;
@@ -248,11 +246,11 @@ int runNormVecByDotProductAWBarrier(int argc, char **argv, int deviceId) {
   }
 
   printf("Result = %s\n", matches == size ? "PASSED" : "FAILED");
-  HIPCHECK(hipFree(d_vecA));
-  HIPCHECK(hipFree(d_vecB));
-  HIPCHECK(hipFree(d_partialResults));
+  checkCudaErrors(hipFree(d_vecA));
+  checkCudaErrors(hipFree(d_vecB));
+  checkCudaErrors(hipFree(d_partialResults));
 
-  HIPCHECK(hipHostFree(vecA));
-  HIPCHECK(hipHostFree(vecB));
+  checkCudaErrors(hipHostFree(vecA));
+  checkCudaErrors(hipHostFree(vecB));
   return matches == size;
 }
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2017.sln b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2019.sln b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2022.sln b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleAWBarrier/simpleAWBarrier_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleAssert/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleAssert/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleAssert/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleAssert/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/Makefile b/src/samples/Samples/0_Introduction/simpleAssert/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleAssert/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/README.md b/src/samples/Samples/0_Introduction/simpleAssert/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert.cu b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert.cu.hip b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert.cu.hip
old mode 100644
new mode 100755
index cb3a67b..e69de29
--- a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert.cu.hip
@@ -1,131 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifdef _WIN32
-#define WINDOWS_LEAN_AND_MEAN
-#define NOMINMAX
-#include <windows.h>
-#else
-#include <sys/utsname.h>
-#endif
-
-// Includes, system
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <cassert>
-
-// Includes CUDA
-#include <hip/hip_runtime.h>
-
-// Utilities and timing functions
-#include "helper_functions.h"  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
-
-// CUDA helper functions
-#include "helper_cuda_hipified.h"  // helper functions for CUDA error check
-
-const char *sampleName = "simpleAssert";
-
-////////////////////////////////////////////////////////////////////////////////
-// Auto-Verification Code
-bool testResult = true;
-
-////////////////////////////////////////////////////////////////////////////////
-// Kernels
-////////////////////////////////////////////////////////////////////////////////
-//! Tests assert function.
-//! Thread whose id > N will print assertion failed error message.
-////////////////////////////////////////////////////////////////////////////////
-__global__ void testKernel(int N) {
-  int gtid = blockIdx.x * blockDim.x + threadIdx.x;
-  assert(gtid < N);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Declaration, forward
-void runTest(int argc, char **argv);
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  printf("%s starting...\n", sampleName);
-
-  runTest(argc, argv);
-
-  printf("%s completed, returned %s\n", sampleName,
-         testResult ? "OK" : "ERROR!");
-  exit(testResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-
-void runTest(int argc, char **argv) {
-  int Nblocks = 2;
-  int Nthreads = 32;
-  hipError_t error;
-
-#ifndef _WIN32
-  utsname OS_System_Type;
-  uname(&OS_System_Type);
-
-  printf("OS_System_Type.release = %s\n", OS_System_Type.release);
-
-  if (!strcasecmp(OS_System_Type.sysname, "Darwin")) {
-    printf("simpleAssert is not current supported on Mac OSX\n\n");
-    exit(EXIT_SUCCESS);
-  } else {
-    printf("OS Info: <%s>\n\n", OS_System_Type.version);
-  }
-
-#endif
-
-  // This will pick the best possible CUDA capable device
-  findCudaDevice(argc, (const char **)argv);
-
-  // Kernel configuration, where a one-dimensional
-  // grid and one-dimensional blocks are configured.
-  dim3 dimGrid(Nblocks);
-  dim3 dimBlock(Nthreads);
-
-  printf("Launch kernel to generate assertion failures\n");
-  testKernel<<<dimGrid, dimBlock>>>(60);
-
-  // Synchronize (flushes assert output).
-  printf("\n-- Begin assert output\n\n");
-  error = hipDeviceSynchronize();
-  printf("\n-- End assert output\n\n");
-
-  // Check for errors and failed asserts in asynchronous kernel launch.
-  if (error == hipErrorAssert) {
-    printf(
-        "Device assert failed as expected, "
-        "CUDA error message is: %s\n\n",
-        hipGetErrorString(error));
-  }
-
-  testResult = error == hipErrorAssert;
-}
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2017.sln b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2019.sln b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2022.sln b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleAssert/simpleAssert_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/Makefile b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/README.md b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert.cpp b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_hipified.cpp b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_kernel.cu b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_kernel.cu.hip b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_kernel.cu.hip
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2017.sln b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2019.sln b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2022.sln b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleAssert_nvrtc/simpleAssert_nvrtc_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/Makefile b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/README.md b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics.cu b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics.cu.hip b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics.cu.hip
old mode 100644
new mode 100755
index 9ee569d..e69de29
--- a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics.cu.hip
@@ -1,136 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* A simple program demonstrating trivial use of global memory atomic
- * device functions (atomic*() functions).
- */
-
-// includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-
-#ifdef _WIN32
-#define WINDOWS_LEAN_AND_MEAN
-#define NOMINMAX
-#include <windows.h>
-#endif
-
-// Includes CUDA
-#include <hip/hip_runtime.h>
-
-// Utilities and timing functions
-#include "helper_functions.h"  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
-
-// CUDA helper functions
-#include "helper_cuda_hipified.h"  // helper functions for CUDA error check
-
-// Includes, kernels
-#include "simpleAtomicIntrinsics_kernel.cuh"
-
-const char *sampleName = "simpleAtomicIntrinsics";
-
-////////////////////////////////////////////////////////////////////////////////
-// Auto-Verification Code
-bool testResult = true;
-
-////////////////////////////////////////////////////////////////////////////////
-// Declaration, forward
-void runTest(int argc, char **argv);
-
-extern "C" bool computeGold(int *gpuData, const int len);
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  printf("%s starting...\n", sampleName);
-
-  runTest(argc, argv);
-
-  printf("%s completed, returned %s\n", sampleName,
-         testResult ? "OK" : "ERROR!");
-  exit(testResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run a simple test for CUDA
-////////////////////////////////////////////////////////////////////////////////
-void runTest(int argc, char **argv) {
-  hipStream_t stream;
-  // This will pick the best possible CUDA capable device
-  findCudaDevice(argc, (const char **)argv);
-
-  StopWatchInterface *timer;
-  sdkCreateTimer(&timer);
-  sdkStartTimer(&timer);
-
-  unsigned int numThreads = 256;
-  unsigned int numBlocks = 64;
-  unsigned int numData = 11;
-  unsigned int memSize = sizeof(int) * numData;
-
-  // allocate mem for the result on host side
-  int *hOData;
-  HIPCHECK(hipHostMalloc(&hOData, memSize));
-
-  // initialize the memory
-  for (unsigned int i = 0; i < numData; i++) hOData[i] = 0;
-
-  // To make the AND and XOR tests generate something other than 0...
-  hOData[8] = hOData[10] = 0xff;
-
-  HIPCHECK(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
-  // allocate device memory for result
-  int *dOData;
-  HIPCHECK(hipMalloc((void **)&dOData, memSize));
-  // copy host memory to device to initialize to zero
-  HIPCHECK(
-      hipMemcpyAsync(dOData, hOData, memSize, hipMemcpyHostToDevice, stream));
-
-  // execute the kernel
-  testKernel<<<numBlocks, numThreads, 0, stream>>>(dOData);
-
-  // Copy result from device to host
-  HIPCHECK(
-      hipMemcpyAsync(hOData, dOData, memSize, hipMemcpyDeviceToHost, stream));
-  HIPCHECK(hipStreamSynchronize(stream));
-
-  sdkStopTimer(&timer);
-  printf("Processing time: %f (ms)\n", sdkGetTimerValue(&timer));
-  sdkDeleteTimer(&timer);
-
-  // Compute reference solution
-  testResult = computeGold(hOData, numThreads * numBlocks);
-
-  // Cleanup memory
-  HIPCHECK(hipHostFree(hOData));
-  HIPCHECK(hipFree(dOData));
-}
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_cpu.cpp b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_cpu.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_cpu_hipified.cpp b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_cpu_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_kernel.cuh b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_kernel_hipified.cuh b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2017.sln b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2019.sln b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2022.sln b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics/simpleAtomicIntrinsics_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/Makefile b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/README.md b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics.cpp b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_cpu.cpp b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_cpu.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_cpu_hipified.cpp b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_cpu_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_hipified.cpp b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_kernel.cuh b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_kernel_hipified.cuh b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2017.sln b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2019.sln b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2022.sln b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleAtomicIntrinsics_nvrtc/simpleAtomicIntrinsics_nvrtc_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleAttributes/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleAttributes/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleAttributes/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleAttributes/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/Makefile b/src/samples/Samples/0_Introduction/simpleAttributes/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleAttributes/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/README.md b/src/samples/Samples/0_Introduction/simpleAttributes/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes.cu b/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes.cu.hip b/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes.cu.hip
old mode 100644
new mode 100755
index eb6d14a..e69de29
--- a/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes.cu.hip
@@ -1,217 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-
-// includes CUDA
-#include <hip/hip_runtime.h>
-
-// includes, project
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"  // helper functions for SDK examples
-
-////////////////////////////////////////////////////////////////////////////////
-// declaration, forward
-void runTest(int argc, char **argv);
-
-hipAccessPolicyWindow initAccessPolicyWindow(void) {
-  hipAccessPolicyWindow accessPolicyWindow = {0};
-  accessPolicyWindow.base_ptr = (void *)0;
-  accessPolicyWindow.num_bytes = 0;
-  accessPolicyWindow.hitRatio = 0.f;
-  accessPolicyWindow.hitProp = hipAccessPropertyNormal;
-  accessPolicyWindow.missProp = hipAccessPropertyStreaming;
-  return accessPolicyWindow;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Simple test kernel for device functionality
-//! @param data  input data in global memory
-//! @param dataSize  input data size
-//! @param bigData  input bigData in global memory
-//! @param bigDataSize  input bigData size
-//! @param hitcount how many data access are done within block
-////////////////////////////////////////////////////////////////////////////////
-static __global__ void kernCacheSegmentTest(int *data, int dataSize, int *trash,
-                                            int bigDataSize, int hitCount) {
-  __shared__ unsigned int hit;
-  int row = blockIdx.y * blockDim.y + threadIdx.y;
-  int col = blockIdx.x * blockDim.x + threadIdx.x;
-  int tID = row * blockDim.y + col;
-  uint32_t psRand = tID;
-
-  atomicExch(&hit, 0);
-  __syncthreads();
-  while (hit < hitCount) {
-    psRand ^= psRand << 13;
-    psRand ^= psRand >> 17;
-    psRand ^= psRand << 5;
-
-    int idx = tID - psRand;
-    if (idx < 0) {
-      idx = -idx;
-    }
-
-    if ((tID % 2) == 0) {
-      data[psRand % dataSize] = data[psRand % dataSize] + data[idx % dataSize];
-    } else {
-      trash[psRand % bigDataSize] =
-          trash[psRand % bigDataSize] + trash[idx % bigDataSize];
-    }
-
-    atomicAdd(&hit, 1);
-  }
-}
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) { runTest(argc, argv); }
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run a simple test for CUDA
-////////////////////////////////////////////////////////////////////////////////
-void runTest(int argc, char **argv) {
-  bool bTestResult = true;
-  hipAccessPolicyWindow accessPolicyWindow;
-  hipDeviceProp_t deviceProp;
-  cudaStreamAttrValue streamAttrValue;
-  hipStream_t stream;
-  cudaStreamAttrID streamAttrID;
-  dim3 threads(32, 32);
-  int *dataDevicePointer;
-  int *dataHostPointer;
-  int dataSize;
-  int *bigDataDevicePointer;
-  int *bigDataHostPointer;
-  int bigDataSize;
-  StopWatchInterface *timer = 0;
-
-  printf("%s Starting...\n\n", argv[0]);
-
-  // use command-line specified CUDA device, otherwise use device with highest
-  // Gflops/s
-  int devID = findCudaDevice(argc, (const char **)argv);
-  sdkCreateTimer(&timer);
-  sdkStartTimer(&timer);
-  // Get device properties
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, devID));
-  dim3 blocks(deviceProp.maxGridSize[1], 1);
-
-  // Make sure device the l2 optimization
-  if (deviceProp.persistingL2CacheMaxSize == 0) {
-    printf(
-        "Waiving execution as device %d does not support persisting L2 "
-        "Caching\n",
-        devID);
-    exit(EXIT_WAIVED);
-  }
-
-  // Create stream to assiocate with window
-  HIPCHECK(hipStreamCreate(&stream));
-
-  // Set the amount of l2 cache that will be persisting to maximum the device
-  // can support
-  HIPCHECK(hipDeviceSetLimit(cudaLimitPersistingL2CacheSize,
-                                     deviceProp.persistingL2CacheMaxSize));
-
-  // Stream attribute to set
-  streamAttrID = cudaStreamAttributeAccessPolicyWindow;
-
-  // Default window
-  streamAttrValue.accessPolicyWindow = initAccessPolicyWindow();
-  accessPolicyWindow = initAccessPolicyWindow();
-
-  // Allocate size of both buffers
-  bigDataSize = (deviceProp.l2CacheSize * 4) / sizeof(int);
-  dataSize = (deviceProp.l2CacheSize / 4) / sizeof(int);
-
-  // Allocate data
-  HIPCHECK(hipHostMalloc(&dataHostPointer, dataSize * sizeof(int)));
-  HIPCHECK(
-      hipHostMalloc(&bigDataHostPointer, bigDataSize * sizeof(int)));
-
-  for (int i = 0; i < bigDataSize; ++i) {
-    if (i < dataSize) {
-      dataHostPointer[i] = i;
-    }
-
-    bigDataHostPointer[bigDataSize - i - 1] = i;
-  }
-
-  HIPCHECK(
-      hipMalloc((void **)&dataDevicePointer, dataSize * sizeof(int)));
-  HIPCHECK(
-      hipMalloc((void **)&bigDataDevicePointer, bigDataSize * sizeof(int)));
-  HIPCHECK(hipMemcpyAsync(dataDevicePointer, dataHostPointer,
-                                  dataSize * sizeof(int),
-                                  hipMemcpyHostToDevice, stream));
-  HIPCHECK(hipMemcpyAsync(bigDataDevicePointer, bigDataHostPointer,
-                                  bigDataSize * sizeof(int),
-                                  hipMemcpyHostToDevice, stream));
-
-  // Make a window for the buffer of interest
-  accessPolicyWindow.base_ptr = (void *)dataDevicePointer;
-  accessPolicyWindow.num_bytes = dataSize * sizeof(int);
-  accessPolicyWindow.hitRatio = 1.f;
-  accessPolicyWindow.hitProp = hipAccessPropertyPersisting;
-  accessPolicyWindow.missProp = hipAccessPropertyNormal;
-  streamAttrValue.accessPolicyWindow = accessPolicyWindow;
-
-  // Assign window to stream
-  HIPCHECK(
-      cudaStreamSetAttribute(stream, streamAttrID, &streamAttrValue));
-
-  // Demote any previous persisting lines
-  HIPCHECK(cudaCtxResetPersistingL2Cache());
-
-  HIPCHECK(hipStreamSynchronize(stream));
-  kernCacheSegmentTest<<<blocks, threads, 0, stream>>>(
-      dataDevicePointer, dataSize, bigDataDevicePointer, bigDataSize, 0xAFFFF);
-
-  HIPCHECK(hipStreamSynchronize(stream));
-  // check if kernel execution generated and error
-  getLastCudaError("Kernel execution failed");
-
-  // Free memory
-  HIPCHECK(hipHostFree(dataHostPointer));
-  HIPCHECK(hipHostFree(bigDataHostPointer));
-  HIPCHECK(hipFree(dataDevicePointer));
-  HIPCHECK(hipFree(bigDataDevicePointer));
-
-  sdkStopTimer(&timer);
-  printf("Processing time: %f (ms)\n", sdkGetTimerValue(&timer));
-  sdkDeleteTimer(&timer);
-
-  exit(bTestResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2017.sln b/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2019.sln b/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2022.sln b/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleAttributes/simpleAttributes_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleCUDA2GL/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleCUDA2GL/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleCUDA2GL/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleCUDA2GL/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/Makefile b/src/samples/Samples/0_Introduction/simpleCUDA2GL/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleCUDA2GL/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/README.md b/src/samples/Samples/0_Introduction/simpleCUDA2GL/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/data/ref_simpleCUDA2GL.ppm b/src/samples/Samples/0_Introduction/simpleCUDA2GL/data/ref_simpleCUDA2GL.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/findgllib.mk b/src/samples/Samples/0_Introduction/simpleCUDA2GL/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/main.cpp b/src/samples/Samples/0_Introduction/simpleCUDA2GL/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/main_hipified.cpp b/src/samples/Samples/0_Introduction/simpleCUDA2GL/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL.cu b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL.cu.hip b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL.cu.hip
old mode 100644
new mode 100755
index 7f0c62c..e69de29
--- a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL.cu.hip
@@ -1,63 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// Utilities and system includes
-
-#include "helper_cuda_hipified.h"
-
-// clamp x to range [a, b]
-__device__ float clamp(float x, float a, float b) { return max(a, min(b, x)); }
-
-__device__ int clamp(int x, int a, int b) { return max(a, min(b, x)); }
-
-// convert floating point rgb color to 8-bit integer
-__device__ int rgbToInt(float r, float g, float b) {
-  r = clamp(r, 0.0f, 255.0f);
-  g = clamp(g, 0.0f, 255.0f);
-  b = clamp(b, 0.0f, 255.0f);
-  return (int(b) << 16) | (int(g) << 8) | int(r);
-}
-
-__global__ void cudaProcess(unsigned int *g_odata, int imgw) {
-  extern __shared__ uchar4 sdata[];
-
-  int tx = threadIdx.x;
-  int ty = threadIdx.y;
-  int bw = blockDim.x;
-  int bh = blockDim.y;
-  int x = blockIdx.x * bw + tx;
-  int y = blockIdx.y * bh + ty;
-
-  uchar4 c4 = make_uchar4((x & 0x20) ? 100 : 0, 0, (y & 0x20) ? 100 : 0, 0);
-  g_odata[y * imgw + x] = rgbToInt(c4.z, c4.y, c4.x);
-}
-
-extern "C" void launch_cudaProcess(dim3 grid, dim3 block, int sbytes,
-                                   unsigned int *g_odata, int imgw) {
-  cudaProcess<<<grid, block, sbytes>>>(g_odata, imgw);
-}
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2017.sln b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2019.sln b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2022.sln b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleCUDA2GL/simpleCUDA2GL_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleCallback/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleCallback/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleCallback/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleCallback/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/Makefile b/src/samples/Samples/0_Introduction/simpleCallback/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleCallback/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/README.md b/src/samples/Samples/0_Introduction/simpleCallback/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/multithreading.cpp b/src/samples/Samples/0_Introduction/simpleCallback/multithreading.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/multithreading.h b/src/samples/Samples/0_Introduction/simpleCallback/multithreading.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/multithreading_hipified.cpp b/src/samples/Samples/0_Introduction/simpleCallback/multithreading_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/multithreading_hipified.h b/src/samples/Samples/0_Introduction/simpleCallback/multithreading_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback.cu b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback.cu.hip b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback.cu.hip
old mode 100644
new mode 100755
index bab74a3..e69de29
--- a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback.cu.hip
@@ -1,216 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This sample implements multi-threaded heterogeneous computing workloads with
- * the new CPU callbacks for CUDA streams and events introduced with CUDA 5.0.
- * Together with the thread safety of the CUDA API implementing heterogeneous
- * workloads that float between CPU threads and GPUs has become simple and
- * efficient.
- *
- * The workloads in the sample follow the form CPU preprocess -> GPU process ->
- * CPU postprocess.
- * Each CPU processing step is handled by its own dedicated thread. GPU
- * workloads are sent to all available GPUs in the system.
- *
- */
-
-// System includes
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-
-// helper functions and utilities to work with CUDA
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-
-#include "multithreading.h"
-
-const int N_workloads = 8;
-const int N_elements_per_workload = 100000;
-
-CUTBarrier thread_barrier;
-
-void  myStreamCallback(hipStream_t event, hipError_t status, void *data);
-
-struct heterogeneous_workload {
-  int id;
-  int cudaDeviceID;
-
-  int *h_data;
-  int *d_data;
-  hipStream_t stream;
-
-  bool success;
-};
-
-__global__ void incKernel(int *data, int N) {
-  int i = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (i < N) data[i]++;
-}
-
-CUT_THREADPROC launch(void *void_arg) {
-  heterogeneous_workload *workload = (heterogeneous_workload *)void_arg;
-
-  // Select GPU for this CPU thread
-  HIPCHECK(hipSetDevice(workload->cudaDeviceID));
-
-  // Allocate Resources
-  HIPCHECK(hipStreamCreate(&workload->stream));
-  HIPCHECK(
-      hipMalloc(&workload->d_data, N_elements_per_workload * sizeof(int)));
-  HIPCHECK(hipHostMalloc(&workload->h_data,
-                                N_elements_per_workload * sizeof(int),
-                                hipHostMallocPortable));
-
-  // CPU thread generates data
-  for (int i = 0; i < N_elements_per_workload; ++i) {
-    workload->h_data[i] = workload->id + i;
-  }
-
-  // Schedule work for GPU in CUDA stream without blocking the CPU thread
-  // Note: Dedicated streams enable concurrent execution of workloads on the GPU
-  dim3 block(512);
-  dim3 grid((N_elements_per_workload + block.x - 1) / block.x);
-
-  HIPCHECK(hipMemcpyAsync(workload->d_data, workload->h_data,
-                                  N_elements_per_workload * sizeof(int),
-                                  hipMemcpyHostToDevice, workload->stream));
-  incKernel<<<grid, block, 0, workload->stream>>>(workload->d_data,
-                                                  N_elements_per_workload);
-  HIPCHECK(hipMemcpyAsync(workload->h_data, workload->d_data,
-                                  N_elements_per_workload * sizeof(int),
-                                  hipMemcpyDeviceToHost, workload->stream));
-
-  // New in CUDA 5.0: Add a CPU callback which is called once all currently
-  // pending operations in the CUDA stream have finished
-  HIPCHECK(
-      hipStreamAddCallback(workload->stream, myStreamCallback, workload, 0));
-
-  CUT_THREADEND;
-  // CPU thread end of life, GPU continues to process data...
-}
-
-CUT_THREADPROC postprocess(void *void_arg) {
-  heterogeneous_workload *workload = (heterogeneous_workload *)void_arg;
-  // ... GPU is done with processing, continue on new CPU thread...
-
-  // Select GPU for this CPU thread
-  checkCudaErrors(hipSetDevice(workload->cudaDeviceID));
-
-  // CPU thread consumes results from GPU
-  workload->success = true;
-
-  for (int i = 0; i < N_workloads; ++i) {
-    workload->success &= workload->h_data[i] == i + workload->id + 1;
-  }
-
-  // Free Resources
-  HIPCHECK(hipFree(workload->d_data));
-  HIPCHECK(hipHostFree(workload->h_data));
-  HIPCHECK(hipStreamDestroy(workload->stream));
-
-  // Signal the end of the heterogeneous workload to main thread
-  cutIncrementBarrier(&thread_barrier);
-
-  CUT_THREADEND;
-}
-
-void myStreamCallback(hipStream_t stream, hipError_t status,
-                                void *data) {
-  // Check status of GPU after stream operations are done
-  HIPCHECK(status);
-
-  // Spawn new CPU worker thread and continue processing on the CPU
-  cutStartThread(postprocess, data);
-}
-
-int main(int argc, char **argv) {
-  int N_gpus, max_gpus = 0;
-  int gpuInfo[32];  // assume a maximum of 32 GPUs in a system configuration
-
-  printf("Starting simpleCallback\n");
-
-  checkCudaErrors(hipGetDeviceCount(&N_gpus));
-  printf("Found %d CUDA capable GPUs\n", N_gpus);
-
-  if (N_gpus > 32) {
-    printf("simpleCallback only supports 32 GPU(s)\n");
-  }
-
-  for (int devid = 0; devid < N_gpus; devid++) {
-    int SMversion;
-    hipDeviceProp_t deviceProp;
-    hipSetDevice(devid);
-    hipGetDeviceProperties(&deviceProp, devid);
-    SMversion = deviceProp.major << 4 + deviceProp.minor;
-    printf("GPU[%d] %s supports SM %d.%d", devid, deviceProp.name,
-           deviceProp.major, deviceProp.minor);
-    printf(", %s GPU Callback Functions\n",
-           (SMversion >= 0x11) ? "capable" : "NOT capable");
-
-    if (SMversion >= 0x11) {
-      gpuInfo[max_gpus++] = devid;
-    }
-  }
-
-  printf("%d GPUs available to run Callback Functions\n", max_gpus);
-
-  heterogeneous_workload *workloads;
-  workloads = (heterogeneous_workload *)malloc(N_workloads *
-                                               sizeof(heterogeneous_workload));
-  ;
-  thread_barrier = cutCreateBarrier(N_workloads);
-
-  // Main thread spawns a CPU worker thread for each heterogeneous workload
-  printf("Starting %d heterogeneous computing workloads\n", N_workloads);
-
-  for (int i = 0; i < N_workloads; ++i) {
-    workloads[i].id = i;
-    workloads[i].cudaDeviceID = gpuInfo[i % max_gpus];  // i % N_gpus;
-
-    cutStartThread(launch, &workloads[i]);
-  }
-
-  // Sleep until all workloads have finished
-  cutWaitForBarrier(&thread_barrier);
-  printf("Total of %d workloads finished:\n", N_workloads);
-
-  bool success = true;
-
-  for (int i = 0; i < N_workloads; ++i) {
-    success &= workloads[i].success;
-  }
-
-  printf("%s\n", success ? "Success" : "Failure");
-
-  free(workloads);
-
-  exit(success ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback.out b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2017.sln b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2019.sln b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2022.sln b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleCallback/simpleCallback_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/Makefile b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/README.md b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups.cu b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups.cu.hip b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups.cu.hip
old mode 100644
new mode 100755
index 6d61b9e..e69de29
--- a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups.cu.hip
@@ -1,180 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/**
- *
- * This sample is a simple code that illustrates basic usage of
- * cooperative groups within the thread block. The code launches a single
- * thread block, creates a cooperative group of all threads in the block,
- * and a set of tiled partition cooperative groups. For each, it uses a
- * generic reduction function to calculate the sum of all the ranks in
- * that group. In each case the result is printed, together with the
- * expected answer (which is calculated using the analytical formula
- * (n-1)*n)/2, noting that the ranks start at zero).
- *
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <hip/hip_cooperative_groups.h>
-
-using namespace cooperative_groups;
-
-/**
- * CUDA device function
- *
- * calculates the sum of val across the group g. The workspace array, x,
- * must be large enough to contain g.size() integers.
- */
-__device__ int sumReduction(thread_group g, int *x, int val) {
-  // rank of this thread in the group
-  int lane = g.thread_rank();
-
-  // for each iteration of this loop, the number of threads active in the
-  // reduction, i, is halved, and each active thread (with index [lane])
-  // performs a single summation of it's own value with that
-  // of a "partner" (with index [lane+i]).
-  for (int i = g.size() / 2; i > 0; i /= 2) {
-    // store value for this thread in temporary array
-    x[lane] = val;
-
-    // synchronize all threads in group
-    g.sync();
-
-    if (lane < i)
-      // active threads perform summation of their value with
-      // their partner's value
-      val += x[lane + i];
-
-    // synchronize all threads in group
-    g.sync();
-  }
-
-  // master thread in group returns result, and others return -1.
-  if (g.thread_rank() == 0)
-    return val;
-  else
-    return -1;
-}
-
-/**
- * CUDA kernel device code
- *
- * Creates cooperative groups and performs reductions
- */
-__global__ void cgkernel() {
-  // threadBlockGroup includes all threads in the block
-  thread_block threadBlockGroup = this_thread_block();
-  int threadBlockGroupSize = threadBlockGroup.size();
-
-  // workspace array in shared memory required for reduction
-  extern __shared__ int workspace[];
-
-  int input, output, expectedOutput;
-
-  // input to reduction, for each thread, is its' rank in the group
-  input = threadBlockGroup.thread_rank();
-
-  // expected output from analytical formula (n-1)(n)/2
-  // (noting that indexing starts at 0 rather than 1)
-  expectedOutput = (threadBlockGroupSize - 1) * threadBlockGroupSize / 2;
-
-  // perform reduction
-  output = sumReduction(threadBlockGroup, workspace, input);
-
-  // master thread in group prints out result
-  if (threadBlockGroup.thread_rank() == 0) {
-    printf(
-        " Sum of all ranks 0..%d in threadBlockGroup is %d (expected %d)\n\n",
-        (int)threadBlockGroup.size() - 1, output, expectedOutput);
-
-    printf(" Now creating %d groups, each of size 16 threads:\n\n",
-           (int)threadBlockGroup.size() / 16);
-  }
-
-  threadBlockGroup.sync();
-
-  // each tiledPartition16 group includes 16 threads
-  thread_block_tile<16> tiledPartition16 =
-      tiled_partition<16>(threadBlockGroup);
-
-  // This offset allows each group to have its own unique area in the workspace
-  // array
-  int workspaceOffset =
-      threadBlockGroup.thread_rank() - tiledPartition16.thread_rank();
-
-  // input to reduction, for each thread, is its' rank in the group
-  input = tiledPartition16.thread_rank();
-
-  // expected output from analytical formula (n-1)(n)/2
-  // (noting that indexing starts at 0 rather than 1)
-  expectedOutput = 15 * 16 / 2;
-
-  // Perform reduction
-  output = sumReduction(tiledPartition16, workspace + workspaceOffset, input);
-
-  // each master thread prints out result
-  if (tiledPartition16.thread_rank() == 0)
-    printf(
-        "   Sum of all ranks 0..15 in this tiledPartition16 group is %d "
-        "(expected %d)\n",
-        output, expectedOutput);
-
-  return;
-}
-
-/**
- * Host main routine
- */
-int main() {
-  // Error code to check return values for CUDA calls
-  hipError_t err;
-
-  // Launch the kernel
-
-  int blocksPerGrid = 1;
-  int threadsPerBlock = 64;
-
-  printf("\nLaunching a single block with %d threads...\n\n", threadsPerBlock);
-
-  // we use the optional third argument to specify the size
-  // of shared memory required in the kernel
-  cgkernel<<<blocksPerGrid, threadsPerBlock, threadsPerBlock * sizeof(int)>>>();
-  err = hipDeviceSynchronize();
-
-  if (err != hipSuccess) {
-    fprintf(stderr, "Failed to launch kernel (error code %s)!\n",
-            hipGetErrorString(err));
-    exit(EXIT_FAILURE);
-  }
-
-  printf("\n...Done.\n\n");
-
-  return 0;
-}
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups.out b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2017.sln b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2019.sln b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2022.sln b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleCooperativeGroups/simpleCooperativeGroups_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleCubemapTexture/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleCubemapTexture/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleCubemapTexture/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleCubemapTexture/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/Makefile b/src/samples/Samples/0_Introduction/simpleCubemapTexture/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleCubemapTexture/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/README.md b/src/samples/Samples/0_Introduction/simpleCubemapTexture/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture.cu b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture.cu.hip b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture.cu.hip
old mode 100644
new mode 100755
index 910a4ae..e69de29
--- a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture.cu.hip
@@ -1,271 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
-* This sample demonstrates how to use texture fetches from layered 2D textures
-* in CUDA C
-*
-* This sample first generates a 3D input data array for the layered texture
-* and the expected output. Then it starts CUDA C kernels, one for each layer,
-* which fetch their layer's texture data (using normalized texture coordinates)
-* transform it to the expected output, and write it to a 3D output data array.
-*/
-
-// includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-
-// includes CUDA
-#include <hip/hip_runtime.h>
-
-// helper functions and utilities to work with CUDA
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-
-static const char *sSDKname = "simpleCubemapTexture";
-
-// includes, kernels
-
-////////////////////////////////////////////////////////////////////////////////
-//! Transform a cubemap face of a linear buffe using cubemap texture lookups
-//! @param g_odata  output data in global memory
-////////////////////////////////////////////////////////////////////////////////
-__global__ void transformKernel(float *g_odata, int width,
-                                hipTextureObject_t tex) {
-  // calculate this thread's data point
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  // 0.5f offset and division are necessary to access the original data points
-  // in the texture (such that bilinear interpolation will not be activated).
-  // For details, see also CUDA Programming Guide, Appendix D
-
-  float u = ((x + 0.5f) / (float)width) * 2.f - 1.f;
-  float v = ((y + 0.5f) / (float)width) * 2.f - 1.f;
-
-  float cx, cy, cz;
-
-  for (unsigned int face = 0; face < 6; face++) {
-    // Layer 0 is positive X face
-    if (face == 0) {
-      cx = 1;
-      cy = -v;
-      cz = -u;
-    }
-    // Layer 1 is negative X face
-    else if (face == 1) {
-      cx = -1;
-      cy = -v;
-      cz = u;
-    }
-    // Layer 2 is positive Y face
-    else if (face == 2) {
-      cx = u;
-      cy = 1;
-      cz = v;
-    }
-    // Layer 3 is negative Y face
-    else if (face == 3) {
-      cx = u;
-      cy = -1;
-      cz = -v;
-    }
-    // Layer 4 is positive Z face
-    else if (face == 4) {
-      cx = u;
-      cy = -v;
-      cz = 1;
-    }
-    // Layer 4 is negative Z face
-    else if (face == 5) {
-      cx = -u;
-      cy = -v;
-      cz = -1;
-    }
-
-    // read from texture, do expected transformation and write to global memory
-    g_odata[face * width * width + y * width + x] =
-        -texCubemap<float>(tex, cx, cy, cz);
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  // use command-line specified CUDA device, otherwise use device with highest
-  // Gflops/s
-  int devID = findCudaDevice(argc, (const char **)argv);
-
-  bool bResult = true;
-
-  // get number of SMs on this GPU
-  hipDeviceProp_t deviceProps;
-
-  HIPCHECK(hipGetDeviceProperties(&deviceProps, devID));
-  printf("CUDA device [%s] has %d Multi-Processors ", deviceProps.name,
-         deviceProps.multiProcessorCount);
-  printf("SM %d.%d\n", deviceProps.major, deviceProps.minor);
-
-  if (deviceProps.major < 2) {
-    printf(
-        "%s requires SM 2.0 or higher for support of Texture Arrays.  Test "
-        "will exit... \n",
-        sSDKname);
-
-    exit(EXIT_WAIVED);
-  }
-
-  // generate input data for layered texture
-  unsigned int width = 64, num_faces = 6, num_layers = 1;
-  unsigned int cubemap_size = width * width * num_faces;
-  unsigned int size = cubemap_size * num_layers * sizeof(float);
-  float *h_data = (float *)malloc(size);
-
-  for (int i = 0; i < (int)(cubemap_size * num_layers); i++) {
-    h_data[i] = (float)i;
-  }
-
-  // this is the expected transformation of the input data (the expected output)
-  float *h_data_ref = (float *)malloc(size);
-
-  for (unsigned int layer = 0; layer < num_layers; layer++) {
-    for (int i = 0; i < (int)(cubemap_size); i++) {
-      h_data_ref[layer * cubemap_size + i] =
-          -h_data[layer * cubemap_size + i] + layer;
-    }
-  }
-
-  // allocate device memory for result
-  float *d_data = NULL;
-  HIPCHECK(hipMalloc((void **)&d_data, size));
-
-  // allocate array and copy image data
-  hipChannelFormatDesc channelDesc =
-      hipCreateChannelDesc(32, 0, 0, 0, hipChannelFormatKindFloat);
-  hipArray *cu_3darray;
-  //    HIPCHECK(hipMalloc3DArray( &cu_3darray, &channelDesc,
-  //    make_hipExtent(width, height, num_layers), hipArrayLayered ));
-  HIPCHECK(hipMalloc3DArray(&cu_3darray, &channelDesc,
-                                    make_hipExtent(width, width, num_faces),
-                                    hipArrayCubemap));
-  hipMemcpy3DParms myparms = {0};
-  myparms.srcPos = make_hipPos(0, 0, 0);
-  myparms.dstPos = make_hipPos(0, 0, 0);
-  myparms.srcPtr =
-      make_hipPitchedPtr(h_data, width * sizeof(float), width, width);
-  myparms.dstArray = cu_3darray;
-  myparms.extent = make_hipExtent(width, width, num_faces);
-  myparms.kind = hipMemcpyHostToDevice;
-  HIPCHECK(hipMemcpy3D(&myparms));
-
-  hipTextureObject_t tex;
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = cu_3darray;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = true;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.addressMode[2] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(hipCreateTextureObject(&tex, &texRes, &texDescr, NULL));
-
-  dim3 dimBlock(8, 8, 1);
-  dim3 dimGrid(width / dimBlock.x, width / dimBlock.y, 1);
-
-  printf(
-      "Covering Cubemap data array of %d~3 x %d: Grid size is %d x %d, each "
-      "block has 8 x 8 threads\n",
-      width, num_layers, dimGrid.x, dimGrid.y);
-
-  transformKernel<<<dimGrid, dimBlock>>>(d_data, width,
-                                         tex);  // warmup (for better timing)
-
-  // check if kernel execution generated an error
-  getLastCudaError("warmup Kernel execution failed");
-
-  HIPCHECK(hipDeviceSynchronize());
-
-  StopWatchInterface *timer = NULL;
-  sdkCreateTimer(&timer);
-  sdkStartTimer(&timer);
-
-  // execute the kernel
-  transformKernel<<<dimGrid, dimBlock, 0>>>(d_data, width, tex);
-
-  // check if kernel execution generated an error
-  getLastCudaError("Kernel execution failed");
-
-  HIPCHECK(hipDeviceSynchronize());
-  sdkStopTimer(&timer);
-  printf("Processing time: %.3f msec\n", sdkGetTimerValue(&timer));
-  printf("%.2f Mtexlookups/sec\n",
-         (cubemap_size / (sdkGetTimerValue(&timer) / 1000.0f) / 1e6));
-  sdkDeleteTimer(&timer);
-
-  // allocate mem for the result on host side
-  float *h_odata = (float *)malloc(size);
-  // copy result from device to host
-  HIPCHECK(hipMemcpy(h_odata, d_data, size, hipMemcpyDeviceToHost));
-
-  // write regression file if necessary
-  if (checkCmdLineFlag(argc, (const char **)argv, "regression")) {
-    // write file for regression test
-    sdkWriteFile<float>("./data/regression.dat", h_odata, width * width, 0.0f,
-                        false);
-  } else {
-    printf("Comparing kernel output to expected data\n");
-
-#define MIN_EPSILON_ERROR 5e-3f
-    bResult =
-        compareData(h_odata, h_data_ref, cubemap_size, MIN_EPSILON_ERROR, 0.0f);
-  }
-
-  // cleanup memory
-  free(h_data);
-  free(h_data_ref);
-  free(h_odata);
-
-  HIPCHECK(hipDestroyTextureObject(tex));
-  HIPCHECK(hipFree(d_data));
-  HIPCHECK(hipFreeArray(cu_3darray));
-
-  exit(bResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture.out b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2017.sln b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2019.sln b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2022.sln b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleCubemapTexture/simpleCubemapTexture_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleDrvRuntime/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleDrvRuntime/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleDrvRuntime/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleDrvRuntime/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/Makefile b/src/samples/Samples/0_Introduction/simpleDrvRuntime/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/README.md b/src/samples/Samples/0_Introduction/simpleDrvRuntime/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime.cpp b/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_hipified.cpp b/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2017.sln b/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2019.sln b/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2022.sln b/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleDrvRuntime/simpleDrvRuntime_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/vectorAdd_kernel.cu b/src/samples/Samples/0_Introduction/simpleDrvRuntime/vectorAdd_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleDrvRuntime/vectorAdd_kernel.cu.hip b/src/samples/Samples/0_Introduction/simpleDrvRuntime/vectorAdd_kernel.cu.hip
old mode 100644
new mode 100755
index 72e20f6..e69de29
--- a/src/samples/Samples/0_Introduction/simpleDrvRuntime/vectorAdd_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleDrvRuntime/vectorAdd_kernel.cu.hip
@@ -1,43 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* Vector addition: C = A + B.
- *
- * This sample is a very basic sample that implements element by element
- * vector addition. It is the same as the sample illustrating Chapter 3
- * of the programming guide with some additions like error checking.
- *
- */
-
-// Device code
-extern "C" __global__ void VecAdd_kernel(const float *A, const float *B,
-                                         float *C, int N) {
-  int i = blockDim.x * blockIdx.x + threadIdx.x;
-
-  if (i < N) C[i] = A[i] + B[i];
-}
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleHyperQ/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleHyperQ/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleHyperQ/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleHyperQ/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/Makefile b/src/samples/Samples/0_Introduction/simpleHyperQ/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleHyperQ/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/README.md b/src/samples/Samples/0_Introduction/simpleHyperQ/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/doc/HyperQ.docx b/src/samples/Samples/0_Introduction/simpleHyperQ/doc/HyperQ.docx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/doc/HyperQ.pdf b/src/samples/Samples/0_Introduction/simpleHyperQ/doc/HyperQ.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ.cu b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ.cu.hip b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ.cu.hip
old mode 100644
new mode 100755
index a7956e1..9cb206f
--- a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ.cu.hip
@@ -36,8 +36,6 @@
 
 #include <hip/hip_cooperative_groups.h>
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 
 namespace cg = cooperative_groups;
 #include "helper_cuda_hipified.h"
@@ -128,8 +126,8 @@ int main(int argc, char **argv) {
 
   // Get device properties
   hipDeviceProp_t deviceProp;
-  HIPCHECK(hipGetDevice(&cuda_device));
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, cuda_device));
+  checkCudaErrors(hipGetDevice(&cuda_device));
+  checkCudaErrors(hipGetDeviceProperties(&deviceProp, cuda_device));
 
   // HyperQ is available in devices of Compute Capability 3.5 and higher
   if (deviceProp.major < 3 || (deviceProp.major == 3 && deviceProp.minor < 5)) {
@@ -149,24 +147,24 @@ int main(int argc, char **argv) {
 
   // Allocate host memory for the output (reduced to a single value)
   clock_t *a = 0;
-  HIPCHECK(hipHostMalloc((void **)&a, sizeof(clock_t)));
+  checkCudaErrors(hipHostMalloc((void **)&a, sizeof(clock_t)));
 
   // Allocate device memory for the output (one value for each kernel)
   clock_t *d_a = 0;
-  HIPCHECK(hipMalloc((void **)&d_a, 2 * nstreams * sizeof(clock_t)));
+  checkCudaErrors(hipMalloc((void **)&d_a, 2 * nstreams * sizeof(clock_t)));
 
   // Allocate and initialize an array of stream handles
   hipStream_t *streams =
       (hipStream_t *)malloc(nstreams * sizeof(hipStream_t));
 
   for (int i = 0; i < nstreams; i++) {
-    HIPCHECK(hipStreamCreate(&(streams[i])));
+    checkCudaErrors(hipStreamCreate(&(streams[i])));
   }
 
   // Create CUDA event handles
   hipEvent_t start_event, stop_event;
-  HIPCHECK(hipEventCreate(&start_event));
-  HIPCHECK(hipEventCreate(&stop_event));
+  checkCudaErrors(hipEventCreate(&start_event));
+  checkCudaErrors(hipEventCreate(&stop_event));
 
   // Target time per kernel is kernel_time ms, clockRate is in KHz
   // Target number of clocks = target time * clock frequency
@@ -180,7 +178,7 @@ int main(int argc, char **argv) {
   clock_t total_clocks = 0;
 
   // Start the clock
-  HIPCHECK(hipEventRecord(start_event, 0));
+  checkCudaErrors(hipEventRecord(start_event, 0));
 
   // Queue pairs of {kernel_A, kernel_B} in separate streams
   for (int i = 0; i < nstreams; ++i) {
@@ -191,7 +189,7 @@ int main(int argc, char **argv) {
   }
 
   // Stop the clock in stream 0 (i.e. all previous kernels will be complete)
-  HIPCHECK(hipEventRecord(stop_event, 0));
+  checkCudaErrors(hipEventRecord(stop_event, 0));
 
   // At this point the CPU has dispatched all work for the GPU and can
   // continue processing other tasks in parallel. In this sample we just want
@@ -199,12 +197,12 @@ int main(int argc, char **argv) {
 
   // Run the sum kernel and copy the result back to host
   sum<<<1, 32>>>(d_a, 2 * nstreams);
-  HIPCHECK(hipMemcpy(a, d_a, sizeof(clock_t), hipMemcpyDeviceToHost));
+  checkCudaErrors(hipMemcpy(a, d_a, sizeof(clock_t), hipMemcpyDeviceToHost));
 
   // stop_event will have been recorded but including the synchronize here to
   // prevent copy/paste errors!
-  HIPCHECK(hipEventSynchronize(stop_event));
-  HIPCHECK(hipEventElapsedTime(&elapsed_time, start_event, stop_event));
+  checkCudaErrors(hipEventSynchronize(stop_event));
+  checkCudaErrors(hipEventElapsedTime(&elapsed_time, start_event, stop_event));
 
   printf(
       "Expected time for serial execution of %d sets of kernels is between "
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ.out b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2017.sln b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2019.sln b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2022.sln b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleHyperQ/simpleHyperQ_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleIPC/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleIPC/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleIPC/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleIPC/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/Makefile b/src/samples/Samples/0_Introduction/simpleIPC/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleIPC/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/README.md b/src/samples/Samples/0_Introduction/simpleIPC/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu.hip b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu.hip
old mode 100644
new mode 100755
index 659e73f..e69de29
--- a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC.cu.hip
@@ -1,332 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This sample demonstrates Inter Process Communication
- * using one process per GPU for computation.
- */
-#include <stdio.h>
-#include <stdlib.h>
-#include <vector>
-#include "helper_cuda.h"
-#include "helper_multiprocess.h"
-#include "HIPCHECK.h"
-static const char shmName[] = "simpleIPCshm";
-// For direct NVLINK and PCI-E peers, at max 8 simultaneous peers are allowed
-// For NVSWITCH connected peers like DGX-2, simultaneous peers are not limited
-// in the same way.
-#define MAX_DEVICES (32)
-#define DATA_SIZE (64ULL << 20ULL)  // 64MB
-
-#if defined(__linux__)
-#define cpu_atomic_add32(a, x) __sync_add_and_fetch(a, x)
-#elif defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64)
-#define cpu_atomic_add32(a, x) InterlockedAdd((volatile LONG *)a, x)
-#else
-#error Unsupported system
-#endif
-
-typedef struct shmStruct_st {
-  size_t nprocesses;
-  int barrier;
-  int sense;
-  int devices[MAX_DEVICES];
-  hipIpcMemHandle_t memHandle[MAX_DEVICES];
-  hipIpcEventHandle_t eventHandle[MAX_DEVICES];
-} shmStruct;
-
-__global__ void simpleKernel(char *ptr, int sz, char val) {
-  int idx = blockIdx.x * blockDim.x + threadIdx.x;
-  for (; idx < sz; idx += (gridDim.x * blockDim.x)) {
-    ptr[idx] = val;
-  }
-}
-
-static void barrierWait(volatile int *barrier, volatile int *sense,
-                        unsigned int n) {
-  int count;
-
-  // Check-in
-  count = cpu_atomic_add32(barrier, 1);
-  if (count == n)  // Last one in
-    *sense = 1;
-  while (!*sense)
-    ;
-
-  // Check-out
-  count = cpu_atomic_add32(barrier, -1);
-  if (count == 0)  // Last one out
-    *sense = 0;
-  while (*sense)
-    ;
-}
-
-static void childProcess(int id) {
-  volatile shmStruct *shm = NULL;
-  hipStream_t stream;
-  sharedMemoryInfo info;
-  size_t procCount, i;
-  int blocks = 0;
-  int threads = 128;
-  hipDeviceProp_t prop;
-  std::vector<void *> ptrs;
-  std::vector<hipEvent_t> events;
-  std::vector<char> verification_buffer(DATA_SIZE);
-
-  if (sharedMemoryOpen(shmName, sizeof(shmStruct), &info) != 0) {
-    printf("Failed to create shared memory slab\n");
-    exit(EXIT_FAILURE);
-  }
-  shm = (volatile shmStruct *)info.addr;
-  procCount = shm->nprocesses;
-
-  printf("Process %d: Starting on device %d...\n", id, shm->devices[id]);
-
-  HIPCHECK(hipSetDevice(shm->devices[id]));
-  HIPCHECK(hipGetDeviceProperties(&prop, shm->devices[id]));
-  HIPCHECK(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
-  HIPCHECK(hipOccupancyMaxActiveBlocksPerMultiprocessor(
-      &blocks, simpleKernel, threads, 0));
-  blocks *= prop.multiProcessorCount;
-
-  // Open and track all the allocations and events created in the master
-  // process for use later
-  for (i = 0; i < procCount; i++) {
-    void *ptr = NULL;
-    hipEvent_t event;
-
-    // Notice, we don't need to explicitly enable peer access for
-    // allocations on other devices.
-    HIPCHECK(
-        hipIpcOpenMemHandle(&ptr, *(hipIpcMemHandle_t *)&shm->memHandle[i],
-                             hipIpcMemLazyEnablePeerAccess));
-    HIPCHECK(hipIpcOpenEventHandle(
-        &event, *(hipIpcEventHandle_t *)&shm->eventHandle[i]));
-
-    ptrs.push_back(ptr);
-    events.push_back(event);
-  }
-
-  // At each iteration of the loop, each sibling process will push work on
-  // their respective devices accessing the next peer mapped buffer allocated
-  // by the master process (these can come from other sibling processes as
-  // well). To coordinate each process' access, we force the stream to wait for
-  // the work already accessing this buffer asynchronously through IPC events,
-  // allowing the CPU processes to continue to queue more work.
-  for (i = 0; i < procCount; i++) {
-    size_t bufferId = (i + id) % procCount;
-    // Wait for the buffer to be accessed to be ready
-    HIPCHECK(hipStreamWaitEvent(stream, events[bufferId], 0));
-    // Push a simple kernel on it
-    simpleKernel<<<blocks, threads, 0, stream>>>((char *)ptrs[bufferId],
-                                                 DATA_SIZE, id);
-    HIPCHECK(hipGetLastError());
-    // Signal that this buffer is ready for the next consumer
-    HIPCHECK(hipEventRecord(events[bufferId], stream));
-    // Wait for all my sibling processes to push this stage of their work
-    // before proceeding to the next. This prevents siblings from racing
-    // ahead and clobbering the recorded event or waiting on the wrong
-    // recorded event.
-    barrierWait(&shm->barrier, &shm->sense, (unsigned int)procCount);
-    if (id == 0) {
-      printf("Step %lld done\n", (unsigned long long)i);
-    }
-  }
-
-  // Now wait for my buffer to be ready so I can copy it locally and verify it
-  HIPCHECK(hipStreamWaitEvent(stream, events[id], 0));
-  HIPCHECK(hipMemcpyAsync(&verification_buffer[0], ptrs[id], DATA_SIZE,
-                                  hipMemcpyDeviceToHost, stream));
-  // And wait for all the queued up work to complete
-  HIPCHECK(hipStreamSynchronize(stream));
-
-  printf("Process %d: verifying...\n", id);
-
-  // The contents should have the id of the sibling just after me
-  char compareId = (char)((id + 1) % procCount);
-  for (unsigned long long j = 0; j < DATA_SIZE; j++) {
-    if (verification_buffer[j] != compareId) {
-      printf("Process %d: Verification mismatch at %lld: %d != %d\n", id, j,
-             (int)verification_buffer[j], (int)compareId);
-    }
-  }
-
-  // Clean up!
-  for (i = 0; i < procCount; i++) {
-    HIPCHECK(hipIpcCloseMemHandle(ptrs[i]));
-    HIPCHECK(hipEventDestroy(events[i]));
-  }
-
-  HIPCHECK(hipStreamDestroy(stream));
-
-  printf("Process %d complete!\n", id);
-}
-
-static void parentProcess(char *app) {
-  sharedMemoryInfo info;
-  int devCount, i;
-  volatile shmStruct *shm = NULL;
-  std::vector<void *> ptrs;
-  std::vector<hipEvent_t> events;
-  std::vector<Process> processes;
-
-  HIPCHECK(hipGetDeviceCount(&devCount));
-
-  if (sharedMemoryCreate(shmName, sizeof(*shm), &info) != 0) {
-    printf("Failed to create shared memory slab\n");
-    exit(EXIT_FAILURE);
-  }
-  shm = (volatile shmStruct *)info.addr;
-  memset((void *)shm, 0, sizeof(*shm));
-
-  // Pick all the devices that can access each other's memory for this test
-  // Keep in mind that CUDA has minimal support for fork() without a
-  // corresponding exec() in the child process, but in this case our
-  // spawnProcess will always exec, so no need to worry.
-  for (i = 0; i < devCount; i++) {
-    bool allPeers = true;
-    hipDeviceProp_t prop;
-    HIPCHECK(hipGetDeviceProperties(&prop, i));
-
-    // CUDA IPC is only supported on devices with unified addressing
-    //if (!prop.unifiedAddressing) {
-    //  printf("Device %d does not support unified addressing, skipping...\n", i);
-    //  continue;
-    //}
-    // This sample requires two processes accessing each device, so we need
-    // to ensure exclusive or prohibited mode is not set
-    if (prop.computeMode != hipComputeModeDefault) {
-      printf("Device %d is in an unsupported compute mode for this sample\n",
-             i);
-      continue;
-    }
-
-    for (int j = 0; j < shm->nprocesses; j++) {
-      int canAccessPeerIJ, canAccessPeerJI;
-      HIPCHECK(
-          hipDeviceCanAccessPeer(&canAccessPeerJI, shm->devices[j], i));
-      HIPCHECK(
-          hipDeviceCanAccessPeer(&canAccessPeerIJ, i, shm->devices[j]));
-      if (!canAccessPeerIJ || !canAccessPeerJI) {
-        allPeers = false;
-        break;
-      }
-    }
-    if (allPeers) {
-      // Enable peers here.  This isn't necessary for IPC, but it will
-      // setup the peers for the device.  For systems that only allow 8
-      // peers per GPU at a time, this acts to remove devices from CanAccessPeer
-      for (int j = 0; j < shm->nprocesses; j++) {
-        HIPCHECK(hipSetDevice(i));
-        HIPCHECK(hipDeviceEnablePeerAccess(shm->devices[j], 0));
-        HIPCHECK(hipSetDevice(shm->devices[j]));
-        HIPCHECK(hipDeviceEnablePeerAccess(i, 0));
-      }
-      shm->devices[shm->nprocesses++] = i;
-      if (shm->nprocesses >= MAX_DEVICES) break;
-    } else {
-      printf(
-          "Device %d is not peer capable with some other selected peers, "
-          "skipping\n",
-          i);
-    }
-  }
-
-  if (shm->nprocesses == 0) {
-    printf("No CUDA devices support IPC\n");
-    exit(EXIT_WAIVED);
-  }
-
-  // Now allocate memory and an event for each process and fill the shared
-  // memory buffer with the IPC handles to communicate
-  for (i = 0; i < shm->nprocesses; i++) {
-    void *ptr = NULL;
-    hipEvent_t event;
-
-    HIPCHECK(hipSetDevice(shm->devices[i]));
-    HIPCHECK(hipMalloc(&ptr, DATA_SIZE));
-    HIPCHECK(
-        hipIpcGetMemHandle((hipIpcMemHandle_t *)&shm->memHandle[i], ptr));
-    //HIPCHECK(hipEventCreate(
-    //    &event, hipEventDisableTiming | hipEventInterprocess));
-    HIPCHECK(hipEventCreate(&event));
-    HIPCHECK(hipIpcGetEventHandle(
-        (hipIpcEventHandle_t *)&shm->eventHandle[i], event));
-
-    ptrs.push_back(ptr);
-    events.push_back(event);
-  }
-
-  // Launch the child processes!
-  for (i = 0; i < shm->nprocesses; i++) {
-    char devIdx[10];
-    char *const args[] = {app, devIdx, NULL};
-    Process process;
-
-    SPRINTF(devIdx, "%d", i);
-
-    if (spawnProcess(&process, app, args)) {
-      printf("Failed to create process\n");
-      exit(EXIT_FAILURE);
-    }
-
-    processes.push_back(process);
-  }
-
-  // And wait for them to finish
-  for (i = 0; i < processes.size(); i++) {
-    if (waitProcess(&processes[i]) != EXIT_SUCCESS) {
-      printf("Process %d failed!\n", i);
-      exit(EXIT_FAILURE);
-    }
-  }
-
-  // Clean up!
-  for (i = 0; i < shm->nprocesses; i++) {
-    HIPCHECK(hipSetDevice(shm->devices[i]));
-    HIPCHECK(hipEventSynchronize(events[i]));
-    HIPCHECK(hipEventDestroy(events[i]));
-    HIPCHECK(hipFree(ptrs[i]));
-  }
-
-  sharedMemoryClose(&info);
-}
-
-int main(int argc, char **argv) {
-#if defined(__arm__) || defined(__aarch64__)
-  printf("Not supported on ARM\n");
-  return EXIT_WAIVED;
-#else
-  if (argc == 1) {
-    parentProcess(argv[0]);
-  } else {
-    childProcess(atoi(argv[1]));
-  }
-  return EXIT_SUCCESS;
-#endif
-}
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2017.sln b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2019.sln b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2022.sln b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleIPC/simpleIPC_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleLayeredTexture/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleLayeredTexture/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleLayeredTexture/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleLayeredTexture/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/Makefile b/src/samples/Samples/0_Introduction/simpleLayeredTexture/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleLayeredTexture/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/README.md b/src/samples/Samples/0_Introduction/simpleLayeredTexture/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.cu b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.cu.hip b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.cu.hip
old mode 100644
new mode 100755
index bf5ca67..e69de29
--- a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.cu.hip
@@ -1,219 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
-* This sample demonstrates how to use texture fetches from layered 2D textures
-* in CUDA C
-*
-* This sample first generates a 3D input data array for the layered texture
-* and the expected output. Then it starts CUDA C kernels, one for each layer,
-* which fetch their layer's texture data (using normalized texture coordinates)
-* transform it to the expected output, and write it to a 3D output data array.
-*/
-
-// includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-
-// includes, kernels
-#include <hip/hip_runtime.h>
-
-// includes, project
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"  // helper for shared that are common to CUDA Samples
-
-static const char *sSDKname = "simpleLayeredTexture";
-
-////////////////////////////////////////////////////////////////////////////////
-//! Transform a layer of a layered 2D texture using texture lookups
-//! @param g_odata  output data in global memory
-////////////////////////////////////////////////////////////////////////////////
-__global__ void transformKernel(float *g_odata, int width, int height,
-                                int layer, hipTextureObject_t tex) {
-  // calculate this thread's data point
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  // 0.5f offset and division are necessary to access the original data points
-  // in the texture (such that bilinear interpolation will not be activated).
-  // For details, see also CUDA Programming Guide, Appendix D
-  float u = (x + 0.5f) / (float)width;
-  float v = (y + 0.5f) / (float)height;
-
-  // read from texture, do expected transformation and write to global memory
-  g_odata[layer * width * height + y * width + x] =
-      -tex2DLayered<float>(tex, u, v, layer) + layer;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  printf("[%s] - Starting...\n", sSDKname);
-
-  // use command-line specified CUDA device, otherwise use device with highest
-  // Gflops/s
-  int devID = findCudaDevice(argc, (const char **)argv);
-
-  bool bResult = true;
-
-  // get number of SMs on this GPU
-  hipDeviceProp_t deviceProps;
-
-  HIPCHECK(hipGetDeviceProperties(&deviceProps, devID));
-  printf("CUDA device [%s] has %d Multi-Processors ", deviceProps.name,
-         deviceProps.multiProcessorCount);
-  printf("SM %d.%d\n", deviceProps.major, deviceProps.minor);
-
-  // generate input data for layered texture
-  unsigned int width = 512, height = 512, num_layers = 5;
-  unsigned int size = width * height * num_layers * sizeof(float);
-  float *h_data = (float *)malloc(size);
-
-  for (unsigned int layer = 0; layer < num_layers; layer++)
-    for (int i = 0; i < (int)(width * height); i++) {
-      h_data[layer * width * height + i] = (float)i;
-    }
-
-  // this is the expected transformation of the input data (the expected output)
-  float *h_data_ref = (float *)malloc(size);
-
-  for (unsigned int layer = 0; layer < num_layers; layer++)
-    for (int i = 0; i < (int)(width * height); i++) {
-      h_data_ref[layer * width * height + i] =
-          -h_data[layer * width * height + i] + layer;
-    }
-
-  // allocate device memory for result
-  float *d_data = NULL;
-  HIPCHECK(hipMalloc((void **)&d_data, size));
-
-  // allocate array and copy image data
-  hipChannelFormatDesc channelDesc =
-      hipCreateChannelDesc(32, 0, 0, 0, hipChannelFormatKindFloat);
-  hipArray *cu_3darray;
-  HIPCHECK(hipMalloc3DArray(&cu_3darray, &channelDesc,
-                                    make_hipExtent(width, height, num_layers),
-                                    hipArrayLayered));
-  hipMemcpy3DParms myparms = {0};
-  myparms.srcPos = make_hipPos(0, 0, 0);
-  myparms.dstPos = make_hipPos(0, 0, 0);
-  myparms.srcPtr =
-      make_hipPitchedPtr(h_data, width * sizeof(float), width, height);
-  myparms.dstArray = cu_3darray;
-  myparms.extent = make_hipExtent(width, height, num_layers);
-  myparms.kind = hipMemcpyHostToDevice;
-  HIPCHECK(hipMemcpy3D(&myparms));
-
-  hipTextureObject_t tex;
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = cu_3darray;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = true;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(hipCreateTextureObject(&tex, &texRes, &texDescr, NULL));
-
-  dim3 dimBlock(8, 8, 1);
-  dim3 dimGrid(width / dimBlock.x, height / dimBlock.y, 1);
-
-  printf(
-      "Covering 2D data array of %d x %d: Grid size is %d x %d, each block has "
-      "8 x 8 threads\n",
-      width, height, dimGrid.x, dimGrid.y);
-
-  transformKernel<<<dimGrid, dimBlock>>>(d_data, width, height, 0,
-                                         tex);  // warmup (for better timing)
-
-  // check if kernel execution generated an error
-  getLastCudaError("warmup Kernel execution failed");
-
-  HIPCHECK(hipDeviceSynchronize());
-
-  StopWatchInterface *timer = NULL;
-  sdkCreateTimer(&timer);
-  sdkStartTimer(&timer);
-
-  // execute the kernel
-  for (unsigned int layer = 0; layer < num_layers; layer++)
-    transformKernel<<<dimGrid, dimBlock, 0>>>(d_data, width, height, layer,
-                                              tex);
-
-  // check if kernel execution generated an error
-  getLastCudaError("Kernel execution failed");
-
-  HIPCHECK(hipDeviceSynchronize());
-  sdkStopTimer(&timer);
-  printf("Processing time: %.3f msec\n", sdkGetTimerValue(&timer));
-  printf("%.2f Mtexlookups/sec\n",
-         (width * height * num_layers / (sdkGetTimerValue(&timer) / 1000.0f) /
-          1e6));
-  sdkDeleteTimer(&timer);
-
-  // allocate mem for the result on host side
-  float *h_odata = (float *)malloc(size);
-  // copy result from device to host
-  HIPCHECK(hipMemcpy(h_odata, d_data, size, hipMemcpyDeviceToHost));
-
-  // write regression file if necessary
-  if (checkCmdLineFlag(argc, (const char **)argv, "regression")) {
-    // write file for regression test
-    sdkWriteFile<float>("./data/regression.dat", h_odata, width * height, 0.0f,
-                        false);
-  } else {
-    printf("Comparing kernel output to expected data\n");
-
-#define MIN_EPSILON_ERROR 5e-3f
-    bResult = compareData(h_odata, h_data_ref, width * height * num_layers,
-                          MIN_EPSILON_ERROR, 0.0f);
-  }
-
-  // cleanup memory
-  free(h_data);
-  free(h_data_ref);
-  free(h_odata);
-
-  HIPCHECK(hipDestroyTextureObject(tex));
-  HIPCHECK(hipFree(d_data));
-  HIPCHECK(hipFreeArray(cu_3darray));
-
-  exit(bResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.out b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2017.sln b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2019.sln b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2022.sln b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleLayeredTexture/simpleLayeredTexture_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleMPI/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleMPI/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleMPI/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleMPI/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/Makefile b/src/samples/Samples/0_Introduction/simpleMPI/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/README.md b/src/samples/Samples/0_Introduction/simpleMPI/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI.cpp b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI.cu b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI.cu.hip b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI.cu.hip
old mode 100644
new mode 100755
index 337ab3f..e69de29
--- a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI.cu.hip
@@ -1,103 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* Simple example demonstrating how to use MPI with CUDA
-*
-*  Generate some random numbers on one node.
-*  Dispatch them to all nodes.
-*  Compute their square root on each node's GPU.
-*  Compute the average of the results using MPI.
-*
-*  simpleMPI.cu: GPU part, compiled with nvcc
-*/
-
-#include <iostream>
-using std::cerr;
-using std::endl;
-
-#include "simpleMPI.h"
-
-// Error handling macro
-#define CUDA_CHECK(call)                                                 \
-  if ((call) != hipSuccess) {                                           \
-    hipError_t err = hipGetLastError();                                \
-    cerr << "CUDA error calling \"" #call "\", code is " << err << endl; \
-    my_abort(err);                                                       \
-  }
-
-// Device code
-// Very simple GPU Kernel that computes square roots of input numbers
-__global__ void simpleMPIKernel(float *input, float *output) {
-  int tid = blockIdx.x * blockDim.x + threadIdx.x;
-  output[tid] = sqrt(input[tid]);
-}
-
-// Initialize an array with random data (between 0 and 1)
-void initData(float *data, int dataSize) {
-  for (int i = 0; i < dataSize; i++) {
-    data[i] = (float)rand() / RAND_MAX;
-  }
-}
-
-// CUDA computation on each node
-// No MPI here, only CUDA
-void computeGPU(float *hostData, int blockSize, int gridSize) {
-  int dataSize = blockSize * gridSize;
-
-  // Allocate data on GPU memory
-  float *deviceInputData = NULL;
-  CUDA_CHECK(hipMalloc((void **)&deviceInputData, dataSize * sizeof(float)));
-
-  float *deviceOutputData = NULL;
-  CUDA_CHECK(hipMalloc((void **)&deviceOutputData, dataSize * sizeof(float)));
-
-  // Copy to GPU memory
-  CUDA_CHECK(hipMemcpy(deviceInputData, hostData, dataSize * sizeof(float),
-                        hipMemcpyHostToDevice));
-
-  // Run kernel
-  simpleMPIKernel<<<gridSize, blockSize>>>(deviceInputData, deviceOutputData);
-
-  // Copy data back to CPU memory
-  CUDA_CHECK(hipMemcpy(hostData, deviceOutputData, dataSize * sizeof(float),
-                        hipMemcpyDeviceToHost));
-
-  // Free GPU memory
-  CUDA_CHECK(hipFree(deviceInputData));
-  CUDA_CHECK(hipFree(deviceOutputData));
-}
-
-float sum(float *data, int size) {
-  float accum = 0.f;
-
-  for (int i = 0; i < size; i++) {
-    accum += data[i];
-  }
-
-  return accum;
-}
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI.h b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_hipified.cpp b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_hipified.h b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2017.sln b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2019.sln b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2022.sln b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleMPI/simpleMPI_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleMultiCopy/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleMultiCopy/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleMultiCopy/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleMultiCopy/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/Makefile b/src/samples/Samples/0_Introduction/simpleMultiCopy/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleMultiCopy/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/README.md b/src/samples/Samples/0_Introduction/simpleMultiCopy/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.cu b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.cu.hip b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.cu.hip
old mode 100644
new mode 100755
index 997e612..d37b290
--- a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.cu.hip
@@ -1,4 +1,4 @@
-#include "hip/hip_runtime.h"
+
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -45,16 +45,14 @@ const char *sSDKname = "simpleMultiCopy";
 
 // includes, system
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 
 // include CUDA
-#include <hip/hip_runtime.h>
+#include "hip/hip_runtime.h"
 
 // includes, project
 #include "helper_cuda_hipified.h"
 #include "helper_functions.h"  // helper for shared that are common to CUDA Samples
-#include "HIPCHECK.h"
+
 // includes, kernels
 // Declare the CUDA kernels here and main() code that is needed to launch
 // Compute workload on the system
@@ -130,12 +128,12 @@ int main(int argc, char *argv[]) {
   } else {
     // Otherwise pick the device with the highest Gflops/s
     cuda_device = gpuGetMaxGflopsDeviceId();
-    HIPCHECK(hipSetDevice(cuda_device));
-    HIPCHECK(hipGetDeviceProperties(&deviceProp, cuda_device));
+    checkCudaErrors(hipSetDevice(cuda_device));
+    checkCudaErrors(hipGetDeviceProperties(&deviceProp, cuda_device));
     printf("> Using CUDA device [%d]: %s\n", cuda_device, deviceProp.name);
   }
 
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, cuda_device));
+  checkCudaErrors(hipGetDeviceProperties(&deviceProp, cuda_device));
   printf("[%s] has %d MP(s) x %d (Cores/MP) = %d (Cores)\n", deviceProp.name,
          deviceProp.multiProcessorCount,
          _ConvertSMVer2Cores(deviceProp.major, deviceProp.minor),
@@ -168,17 +166,17 @@ int main(int argc, char *argv[]) {
   h_data_sink = (int *)malloc(memsize);
 
   for (int i = 0; i < STREAM_COUNT; ++i) {
-    HIPCHECK(
-        hipHostMalloc((void **)&h_data_in[i], memsize, hipHostMallocDefault));
-    HIPCHECK(hipMalloc(&d_data_in[i], memsize));
-    HIPCHECK(hipMemset(d_data_in[i], 0, memsize));
+    checkCudaErrors(
+        hipHostAlloc(&h_data_in[i], memsize, hipHostMallocDefault));
+    checkCudaErrors(hipMalloc(&d_data_in[i], memsize));
+    checkCudaErrors(hipMemset(d_data_in[i], 0, memsize));
 
-    HIPCHECK(
-        hipHostMalloc((void **)&h_data_out[i], memsize, hipHostMallocDefault));
-    HIPCHECK(hipMalloc(&d_data_out[i], memsize));
+    checkCudaErrors(
+        hipHostAlloc(&h_data_out[i], memsize, hipHostMallocDefault));
+    checkCudaErrors(hipMalloc(&d_data_out[i], memsize));
 
-    HIPCHECK(hipStreamCreate(&stream[i]));
-    HIPCHECK(hipEventCreate(&cycleDone[i]));
+    checkCudaErrors(hipStreamCreate(&stream[i]));
+    checkCudaErrors(hipEventCreate(&cycleDone[i]));
 
     hipEventRecord(cycleDone[i], stream[i]);
   }
@@ -193,7 +191,7 @@ int main(int argc, char *argv[]) {
 
   // Time copies and kernel
   hipEventRecord(start, 0);
-  HIPCHECK(hipMemcpyAsync(d_data_in[0], h_data_in[0], memsize,
+  checkCudaErrors(hipMemcpyAsync(d_data_in[0], h_data_in[0], memsize,
                                   hipMemcpyHostToDevice, 0));
   hipEventRecord(stop, 0);
   hipEventSynchronize(stop);
@@ -202,7 +200,7 @@ int main(int argc, char *argv[]) {
   hipEventElapsedTime(&memcpy_h2d_time, start, stop);
 
   hipEventRecord(start, 0);
-  HIPCHECK(hipMemcpyAsync(h_data_out[0], d_data_out[0], memsize,
+  checkCudaErrors(hipMemcpyAsync(h_data_out[0], d_data_out[0], memsize,
                                   hipMemcpyDeviceToHost, 0));
   hipEventRecord(stop, 0);
   hipEventSynchronize(stop);
@@ -220,20 +218,18 @@ int main(int argc, char *argv[]) {
 
   printf("\n");
   printf("Relevant properties of this CUDA device\n");
-  /*
   printf(
       "(%s) Can overlap one CPU<>GPU data transfer with GPU kernel execution "
       "(device property \"deviceOverlap\")\n",
       deviceProp.deviceOverlap ? "X" : " ");
-*/
   // printf("(%s) Can execute several GPU kernels simultaneously (compute
   // capability >= 2.0)\n", deviceProp.major >= 2 ? "X": " ");
- /* printf(
+  printf(
       "(%s) Can overlap two CPU<>GPU data transfers with GPU kernel execution\n"
       "    (Compute Capability >= 2.0 AND (Tesla product OR Quadro "
       "4000/5000/6000/K5000)\n",
       (deviceProp.major >= 2 && deviceProp.asyncEngineCount > 1) ? "X" : " ");
-*/
+
   printf("\n");
   printf("Measured timings (throughput):\n");
   printf(" Memcpy host to device\t: %f ms (%f GB/s)\n", memcpy_h2d_time,
@@ -331,16 +327,16 @@ float processWithStreams(int streams_used) {
         d_data_out[current_stream], d_data_in[current_stream], N, inner_reps);
 
     // Upload next frame
-    HIPCHECK(
+    checkCudaErrors(
         hipMemcpyAsync(d_data_in[next_stream], h_data_in[next_stream], memsize,
                         hipMemcpyHostToDevice, stream[next_stream]));
 
     // Download current frame
-    HIPCHECK(hipMemcpyAsync(
+    checkCudaErrors(hipMemcpyAsync(
         h_data_out[current_stream], d_data_out[current_stream], memsize,
         hipMemcpyDeviceToHost, stream[current_stream]));
 
-    HIPCHECK(
+    checkCudaErrors(
         hipEventRecord(cycleDone[current_stream], stream[current_stream]));
 
     current_stream = next_stream;
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.out b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2017.sln b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2019.sln b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2022.sln b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleMultiCopy/simpleMultiCopy_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleMultiGPU/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleMultiGPU/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleMultiGPU/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleMultiGPU/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/Makefile b/src/samples/Samples/0_Introduction/simpleMultiGPU/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleMultiGPU/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/README.md b/src/samples/Samples/0_Introduction/simpleMultiGPU/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.cu b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.cu.hip b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.cu.hip
old mode 100644
new mode 100755
index cc5376e..e69de29
--- a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.cu.hip
@@ -1,239 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This application demonstrates how to use the CUDA API to use multiple GPUs,
- * with an emphasis on simple illustration of the techniques (not on
- * performance).
- *
- * Note that in order to detect multiple GPUs in your system you have to disable
- * SLI in the nvidia control panel. Otherwise only one GPU is visible to the
- * application. On the other side, you can still extend your desktop to screens
- * attached to both GPUs.
- */
-
-// System includes
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <assert.h>
-
-// CUDA runtime
-#include <hip/hip_runtime.h>
-
-// helper functions and utilities to work with CUDA
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-
-#ifndef MAX
-#define MAX(a, b) (a > b ? a : b)
-#endif
-
-#include "simpleMultiGPU.h"
-
-////////////////////////////////////////////////////////////////////////////////
-// Data configuration
-////////////////////////////////////////////////////////////////////////////////
-const int MAX_GPU_COUNT = 32;
-const int DATA_N = 1048576 * 32;
-
-////////////////////////////////////////////////////////////////////////////////
-// Simple reduction kernel.
-// Refer to the 'reduction' CUDA Sample describing
-// reduction optimization strategies
-////////////////////////////////////////////////////////////////////////////////
-__global__ static void reduceKernel(float *d_Result, float *d_Input, int N) {
-  const int tid = blockIdx.x * blockDim.x + threadIdx.x;
-  const int threadN = gridDim.x * blockDim.x;
-  float sum = 0;
-
-  for (int pos = tid; pos < N; pos += threadN) sum += d_Input[pos];
-
-  d_Result[tid] = sum;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  // Solver config
-  TGPUplan plan[MAX_GPU_COUNT];
-
-  // GPU reduction results
-  float h_SumGPU[MAX_GPU_COUNT];
-
-  float sumGPU;
-  double sumCPU, diff;
-
-  int i, j, gpuBase, GPU_N;
-
-  const int BLOCK_N = 32;
-  const int THREAD_N = 256;
-  const int ACCUM_N = BLOCK_N * THREAD_N;
-
-  printf("Starting simpleMultiGPU\n");
-  HIPCHECK(hipGetDeviceCount(&GPU_N));
-
-  if (GPU_N > MAX_GPU_COUNT) {
-    GPU_N = MAX_GPU_COUNT;
-  }
-
-  printf("CUDA-capable device count: %i\n", GPU_N);
-
-  printf("Generating input data...\n\n");
-
-  // Subdividing input data across GPUs
-  // Get data sizes for each GPU
-  for (i = 0; i < GPU_N; i++) {
-    plan[i].dataN = DATA_N / GPU_N;
-  }
-
-  // Take into account "odd" data sizes
-  for (i = 0; i < DATA_N % GPU_N; i++) {
-    plan[i].dataN++;
-  }
-
-  // Assign data ranges to GPUs
-  gpuBase = 0;
-
-  for (i = 0; i < GPU_N; i++) {
-    plan[i].h_Sum = h_SumGPU + i;
-    gpuBase += plan[i].dataN;
-  }
-
-  // Create streams for issuing GPU command asynchronously and allocate memory
-  // (GPU and System page-locked)
-  for (i = 0; i < GPU_N; i++) {
-    HIPCHECK(hipSetDevice(i));
-    HIPCHECK(hipStreamCreate(&plan[i].stream));
-    // Allocate memory
-    HIPCHECK(
-        hipMalloc((void **)&plan[i].d_Data, plan[i].dataN * sizeof(float)));
-    HIPCHECK(
-        hipMalloc((void **)&plan[i].d_Sum, ACCUM_N * sizeof(float)));
-    HIPCHECK(hipHostMalloc((void **)&plan[i].h_Sum_from_device,
-                                   ACCUM_N * sizeof(float)));
-    HIPCHECK(hipHostMalloc((void **)&plan[i].h_Data,
-                                   plan[i].dataN * sizeof(float)));
-
-    for (j = 0; j < plan[i].dataN; j++) {
-      plan[i].h_Data[j] = (float)rand() / (float)RAND_MAX;
-    }
-  }
-
-  // Start timing and compute on GPU(s)
-  printf("Computing with %d GPUs...\n", GPU_N);
-  // create and start timer
-  StopWatchInterface *timer = NULL;
-  sdkCreateTimer(&timer);
-
-  // start the timer
-  sdkStartTimer(&timer);
-
-  // Copy data to GPU, launch the kernel and copy data back. All asynchronously
-  for (i = 0; i < GPU_N; i++) {
-    // Set device
-    HIPCHECK(hipSetDevice(i));
-
-    // Copy input data from CPU
-    HIPCHECK(hipMemcpyAsync(plan[i].d_Data, plan[i].h_Data,
-                                    plan[i].dataN * sizeof(float),
-                                    hipMemcpyHostToDevice, plan[i].stream));
-
-    // Perform GPU computations
-    reduceKernel<<<BLOCK_N, THREAD_N, 0, plan[i].stream>>>(
-        plan[i].d_Sum, plan[i].d_Data, plan[i].dataN);
-    getLastCudaError("reduceKernel() execution failed.\n");
-
-    // Read back GPU results
-    HIPCHECK(hipMemcpyAsync(plan[i].h_Sum_from_device, plan[i].d_Sum,
-                                    ACCUM_N * sizeof(float),
-                                    hipMemcpyDeviceToHost, plan[i].stream));
-  }
-
-  // Process GPU results
-  for (i = 0; i < GPU_N; i++) {
-    float sum;
-
-    // Set device
-    HIPCHECK(hipSetDevice(i));
-
-    // Wait for all operations to finish
-    hipStreamSynchronize(plan[i].stream);
-
-    // Finalize GPU reduction for current subvector
-    sum = 0;
-
-    for (j = 0; j < ACCUM_N; j++) {
-      sum += plan[i].h_Sum_from_device[j];
-    }
-
-    *(plan[i].h_Sum) = (float)sum;
-
-    // Shut down this GPU
-    HIPCHECK(hipHostFree(plan[i].h_Sum_from_device));
-    HIPCHECK(hipFree(plan[i].d_Sum));
-    HIPCHECK(hipFree(plan[i].d_Data));
-    HIPCHECK(hipStreamDestroy(plan[i].stream));
-  }
-
-  sumGPU = 0;
-
-  for (i = 0; i < GPU_N; i++) {
-    sumGPU += h_SumGPU[i];
-  }
-
-  sdkStopTimer(&timer);
-  printf("  GPU Processing time: %f (ms)\n\n", sdkGetTimerValue(&timer));
-  sdkDeleteTimer(&timer);
-
-  // Compute on Host CPU
-  printf("Computing with Host CPU...\n\n");
-
-  sumCPU = 0;
-
-  for (i = 0; i < GPU_N; i++) {
-    for (j = 0; j < plan[i].dataN; j++) {
-      sumCPU += plan[i].h_Data[j];
-    }
-  }
-
-  // Compare GPU and CPU results
-  printf("Comparing GPU and Host CPU results...\n");
-  diff = fabs(sumCPU - sumGPU) / fabs(sumCPU);
-  printf("  GPU sum: %f\n  CPU sum: %f\n", sumGPU, sumCPU);
-  printf("  Relative difference: %E \n\n", diff);
-
-  // Cleanup and shutdown
-  for (i = 0; i < GPU_N; i++) {
-    HIPCHECK(hipSetDevice(i));
-    HIPCHECK(hipHostFree(plan[i].h_Data));
-  }
-
-  exit((diff < 1e-5) ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.h b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.out b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_hipified.h b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2017.sln b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2019.sln b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2022.sln b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleMultiGPU/simpleMultiGPU_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleOccupancy/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleOccupancy/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleOccupancy/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleOccupancy/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/Makefile b/src/samples/Samples/0_Introduction/simpleOccupancy/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleOccupancy/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/README.md b/src/samples/Samples/0_Introduction/simpleOccupancy/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.cu b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.cu.hip b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.cu.hip
old mode 100644
new mode 100755
index 2f9817e..e69de29
--- a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.cu.hip
@@ -1,241 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <iostream>
-#include "helper_cuda_hipified.h"  // helper functions for CUDA error check
-#include "HIPCHECK.h"
-const int manualBlockSize = 32;
-
-////////////////////////////////////////////////////////////////////////////////
-// Test kernel
-//
-// This kernel squares each array element. Each thread addresses
-// himself with threadIdx and blockIdx, so that it can handle any
-// execution configuration, including anything the launch configurator
-// API suggests.
-////////////////////////////////////////////////////////////////////////////////
-__global__ void square(int *array, int arrayCount) {
-  extern __shared__ int dynamicSmem[];
-  int idx = threadIdx.x + blockIdx.x * blockDim.x;
-
-  if (idx < arrayCount) {
-    array[idx] *= array[idx];
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Potential occupancy calculator
-//
-// The potential occupancy is calculated according to the kernel and
-// execution configuration the user desires. Occupancy is defined in
-// terms of active blocks per multiprocessor, and the user can convert
-// it to other metrics.
-//
-// This wrapper routine computes the occupancy of kernel, and reports
-// it in terms of active warps / maximum warps per SM.
-////////////////////////////////////////////////////////////////////////////////
-static double reportPotentialOccupancy(void *kernel, int blockSize,
-                                       size_t dynamicSMem) {
-  int device;
-  hipDeviceProp_t prop;
-
-  int numBlocks;
-  int activeWarps;
-  int maxWarps;
-
-  double occupancy;
-
-  HIPCHECK(hipGetDevice(&device));
-  HIPCHECK(hipGetDeviceProperties(&prop, device));
-
-  HIPCHECK(hipOccupancyMaxActiveBlocksPerMultiprocessor(
-      &numBlocks, kernel, blockSize, dynamicSMem));
-
-  activeWarps = numBlocks * blockSize / prop.warpSize;
-  maxWarps = prop.maxThreadsPerMultiProcessor / prop.warpSize;
-
-  occupancy = (double)activeWarps / maxWarps;
-
-  return occupancy;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Occupancy-based launch configurator
-//
-// The launch configurator, hipOccupancyMaxPotentialBlockSize and
-// cudaOccupancyMaxPotentialBlockSizeVariableSMem, suggests a block
-// size that achieves the best theoretical occupancy. It also returns
-// the minimum number of blocks needed to achieve the occupancy on the
-// whole device.
-//
-// This launch configurator is purely occupancy-based. It doesn't
-// translate directly to performance, but the suggestion should
-// nevertheless be a good starting point for further optimizations.
-//
-// This function configures the launch based on the "automatic"
-// argument, records the runtime, and reports occupancy and runtime.
-////////////////////////////////////////////////////////////////////////////////
-static int launchConfig(int *array, int arrayCount, bool automatic) {
-  int blockSize;
-  int minGridSize;
-  int gridSize;
-  size_t dynamicSMemUsage = 0;
-
-  hipEvent_t start;
-  hipEvent_t end;
-
-  float elapsedTime;
-
-  double potentialOccupancy;
-
-  HIPCHECK(hipEventCreate(&start));
-  HIPCHECK(hipEventCreate(&end));
-
-  if (automatic) {
-    HIPCHECK(hipOccupancyMaxPotentialBlockSize(
-        &minGridSize, &blockSize, (void *)square, dynamicSMemUsage,
-        arrayCount));
-
-    std::cout << "Suggested block size: " << blockSize << std::endl
-              << "Minimum grid size for maximum occupancy: " << minGridSize
-              << std::endl;
-  } else {
-    // This block size is too small. Given limited number of
-    // active blocks per multiprocessor, the number of active
-    // threads will be limited, and thus unable to achieve maximum
-    // occupancy.
-    //
-    blockSize = manualBlockSize;
-  }
-
-  // Round up
-  //
-  gridSize = (arrayCount + blockSize - 1) / blockSize;
-
-  // Launch and profile
-  //
-  HIPCHECK(hipEventRecord(start));
-  square<<<gridSize, blockSize, dynamicSMemUsage>>>(array, arrayCount);
-  HIPCHECK(hipEventRecord(end));
-
-  HIPCHECK(hipDeviceSynchronize());
-
-  // Calculate occupancy
-  //
-  potentialOccupancy =
-      reportPotentialOccupancy((void *)square, blockSize, dynamicSMemUsage);
-
-  std::cout << "Potential occupancy: " << potentialOccupancy * 100 << "%"
-            << std::endl;
-
-  // Report elapsed time
-  //
-  HIPCHECK(hipEventElapsedTime(&elapsedTime, start, end));
-  std::cout << "Elapsed time: " << elapsedTime << "ms" << std::endl;
-
-  return 0;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// The test
-//
-// The test generates an array and squares it with a CUDA kernel, then
-// verifies the result.
-////////////////////////////////////////////////////////////////////////////////
-static int test(bool automaticLaunchConfig, const int count = 1000000) {
-  int *array;
-  int *dArray;
-  int size = count * sizeof(int);
-
-  array = new int[count];
-
-  for (int i = 0; i < count; i += 1) {
-    array[i] = i;
-  }
-
-  HIPCHECK(hipMalloc(&dArray, size));
-  HIPCHECK(hipMemcpy(dArray, array, size, hipMemcpyHostToDevice));
-
-  for (int i = 0; i < count; i += 1) {
-    array[i] = 0;
-  }
-
-  launchConfig(dArray, count, automaticLaunchConfig);
-
-  HIPCHECK(hipMemcpy(array, dArray, size, hipMemcpyDeviceToHost));
-  HIPCHECK(hipFree(dArray));
-
-  // Verify the return data
-  //
-  for (int i = 0; i < count; i += 1) {
-    if (array[i] != i * i) {
-      std::cout << "element " << i << " expected " << i * i << " actual "
-                << array[i] << std::endl;
-      return 1;
-    }
-  }
-  delete[] array;
-
-  return 0;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Sample Main
-//
-// The sample runs the test with manually configured launch and
-// automatically configured launch, and reports the occupancy and
-// performance.
-////////////////////////////////////////////////////////////////////////////////
-int main() {
-  int status;
-
-  std::cout << "starting Simple Occupancy" << std::endl << std::endl;
-
-  std::cout << "[ Manual configuration with " << manualBlockSize
-            << " threads per block ]" << std::endl;
-
-  status = test(false);
-  if (status) {
-    std::cerr << "Test failed\n" << std::endl;
-    return -1;
-  }
-
-  std::cout << std::endl;
-
-  std::cout << "[ Automatic, occupancy-based configuration ]" << std::endl;
-  status = test(true);
-  if (status) {
-    std::cerr << "Test failed\n" << std::endl;
-    return -1;
-  }
-
-  std::cout << std::endl;
-  std::cout << "Test PASSED\n" << std::endl;
-
-  return 0;
-}
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.out b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2017.sln b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2019.sln b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2022.sln b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleOccupancy/simpleOccupancy_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleP2P/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleP2P/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleP2P/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleP2P/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/Makefile b/src/samples/Samples/0_Introduction/simpleP2P/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleP2P/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/README.md b/src/samples/Samples/0_Introduction/simpleP2P/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.cu b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.cu.hip b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.cu.hip
old mode 100644
new mode 100755
index d49e033..e69de29
--- a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.cu.hip
@@ -1,263 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This sample demonstrates a combination of Peer-to-Peer (P2P) and
- * Unified Virtual Address Space (UVA) features new to SDK 4.0
- */
-
-// includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-
-// CUDA includes
-#include <hip/hip_runtime.h>
-
-// includes, project
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"  // helper for shared that are common to CUDA Samples
-
-__global__ void SimpleKernel(float *src, float *dst) {
-  // Just a dummy kernel, doing enough for us to verify that everything
-  // worked
-  const int idx = blockIdx.x * blockDim.x + threadIdx.x;
-  dst[idx] = src[idx] * 2.0f;
-}
-
-inline bool IsAppBuiltAs64() { return sizeof(void *) == 8; }
-
-int main(int argc, char **argv) {
-  printf("[%s] - Starting...\n", argv[0]);
-
-  if (!IsAppBuiltAs64()) {
-    printf(
-        "%s is only supported with on 64-bit OSs and the application must be "
-        "built as a 64-bit target.  Test is being waived.\n",
-        argv[0]);
-    exit(EXIT_WAIVED);
-  }
-
-  // Number of GPUs
-  printf("Checking for multiple GPUs...\n");
-  int gpu_n;
-  HIPCHECK(hipGetDeviceCount(&gpu_n));
-  printf("CUDA-capable device count: %i\n", gpu_n);
-
-  if (gpu_n < 2) {
-    printf(
-        "Two or more GPUs with Peer-to-Peer access capability are required for "
-        "%s.\n",
-        argv[0]);
-    printf("Waiving test.\n");
-    exit(EXIT_WAIVED);
-  }
-
-  // Query device properties
-  hipDeviceProp_t prop[64];
-  int gpuid[2];  // we want to find the first two GPU's that can support P2P
-
-  for (int i = 0; i < gpu_n; i++) {
-    HIPCHECK(hipGetDeviceProperties(&prop[i], i));
-  }
-  // Check possibility for peer access
-  printf("\nChecking GPU(s) for support of peer to peer memory access...\n");
-
-  int can_access_peer;
-  int p2pCapableGPUs[2];  // We take only 1 pair of P2P capable GPUs
-  p2pCapableGPUs[0] = p2pCapableGPUs[1] = -1;
-
-  // Show all the combinations of supported P2P GPUs
-  for (int i = 0; i < gpu_n; i++) {
-    for (int j = 0; j < gpu_n; j++) {
-      if (i == j) {
-        continue;
-      }
-      HIPCHECK(hipDeviceCanAccessPeer(&can_access_peer, i, j));
-      printf("> Peer access from %s (GPU%d) -> %s (GPU%d) : %s\n", prop[i].name,
-             i, prop[j].name, j, can_access_peer ? "Yes" : "No");
-      if (can_access_peer && p2pCapableGPUs[0] == -1) {
-        p2pCapableGPUs[0] = i;
-        p2pCapableGPUs[1] = j;
-      }
-    }
-  }
-
-  if (p2pCapableGPUs[0] == -1 || p2pCapableGPUs[1] == -1) {
-    printf(
-        "Two or more GPUs with Peer-to-Peer access capability are required for "
-        "%s.\n",
-        argv[0]);
-    printf(
-        "Peer to Peer access is not available amongst GPUs in the system, "
-        "waiving test.\n");
-
-    exit(EXIT_WAIVED);
-  }
-
-  // Use first pair of p2p capable GPUs detected.
-  gpuid[0] = p2pCapableGPUs[0];
-  gpuid[1] = p2pCapableGPUs[1];
-
-  // Enable peer access
-  printf("Enabling peer access between GPU%d and GPU%d...\n", gpuid[0],
-         gpuid[1]);
-  HIPCHECK(hipSetDevice(gpuid[0]));
-  HIPCHECK(hipDeviceEnablePeerAccess(gpuid[1], 0));
-  HIPCHECK(hipSetDevice(gpuid[1]));
-  HIPCHECK(hipDeviceEnablePeerAccess(gpuid[0], 0));
-
-  // Allocate buffers
-  const size_t buf_size = 1024 * 1024 * 16 * sizeof(float);
-  printf("Allocating buffers (%iMB on GPU%d, GPU%d and CPU Host)...\n",
-         int(buf_size / 1024 / 1024), gpuid[0], gpuid[1]);
-  HIPCHECK(hipSetDevice(gpuid[0]));
-  float *g0;
-  HIPCHECK(hipMalloc(&g0, buf_size));
-  HIPCHECK(hipSetDevice(gpuid[1]));
-  float *g1;
-  HIPCHECK(hipMalloc(&g1, buf_size));
-  float *h0;
-  HIPCHECK(
-      hipHostMalloc(&h0, buf_size));  // Automatically portable with UVA
-
-  // Create CUDA event handles
-  printf("Creating event handles...\n");
-  hipEvent_t start_event, stop_event;
-  float time_memcpy;
-  int eventflags = hipEventBlockingSync;
-  HIPCHECK(hipEventCreateWithFlags(&start_event, eventflags));
-  HIPCHECK(hipEventCreateWithFlags(&stop_event, eventflags));
-
-  // P2P memcopy() benchmark
-  HIPCHECK(hipEventRecord(start_event, 0));
-
-  for (int i = 0; i < 100; i++) {
-    // With UVA we don't need to specify source and target devices, the
-    // runtime figures this out by itself from the pointers
-    // Ping-pong copy between GPUs
-    if (i % 2 == 0) {
-      HIPCHECK(hipMemcpy(g1, g0, buf_size, hipMemcpyDefault));
-    } else {
-      HIPCHECK(hipMemcpy(g0, g1, buf_size, hipMemcpyDefault));
-    }
-  }
-
-  HIPCHECK(hipEventRecord(stop_event, 0));
-  HIPCHECK(hipEventSynchronize(stop_event));
-  HIPCHECK(hipEventElapsedTime(&time_memcpy, start_event, stop_event));
-  printf("hipMemcpyPeer / hipMemcpy between GPU%d and GPU%d: %.2fGB/s\n",
-         gpuid[0], gpuid[1],
-         (1.0f / (time_memcpy / 1000.0f)) * ((100.0f * buf_size)) / 1024.0f /
-             1024.0f / 1024.0f);
-
-  // Prepare host buffer and copy to GPU 0
-  printf("Preparing host buffer and memcpy to GPU%d...\n", gpuid[0]);
-
-  for (int i = 0; i < buf_size / sizeof(float); i++) {
-    h0[i] = float(i % 4096);
-  }
-
-  HIPCHECK(hipSetDevice(gpuid[0]));
-  HIPCHECK(hipMemcpy(g0, h0, buf_size, hipMemcpyDefault));
-
-  // Kernel launch configuration
-  const dim3 threads(512, 1);
-  const dim3 blocks((buf_size / sizeof(float)) / threads.x, 1);
-
-  // Run kernel on GPU 1, reading input from the GPU 0 buffer, writing
-  // output to the GPU 1 buffer
-  printf(
-      "Run kernel on GPU%d, taking source data from GPU%d and writing to "
-      "GPU%d...\n",
-      gpuid[1], gpuid[0], gpuid[1]);
-  HIPCHECK(hipSetDevice(gpuid[1]));
-  SimpleKernel<<<blocks, threads>>>(g0, g1);
-
-  HIPCHECK(hipDeviceSynchronize());
-
-  // Run kernel on GPU 0, reading input from the GPU 1 buffer, writing
-  // output to the GPU 0 buffer
-  printf(
-      "Run kernel on GPU%d, taking source data from GPU%d and writing to "
-      "GPU%d...\n",
-      gpuid[0], gpuid[1], gpuid[0]);
-  HIPCHECK(hipSetDevice(gpuid[0]));
-  SimpleKernel<<<blocks, threads>>>(g1, g0);
-
-  HIPCHECK(hipDeviceSynchronize());
-
-  // Copy data back to host and verify
-  printf("Copy data back to host from GPU%d and verify results...\n", gpuid[0]);
-  HIPCHECK(hipMemcpy(h0, g0, buf_size, hipMemcpyDefault));
-
-  int error_count = 0;
-
-  for (int i = 0; i < buf_size / sizeof(float); i++) {
-    // Re-generate input data and apply 2x '* 2.0f' computation of both
-    // kernel runs
-    if (h0[i] != float(i % 4096) * 2.0f * 2.0f) {
-      printf("Verification error @ element %i: val = %f, ref = %f\n", i, h0[i],
-             (float(i % 4096) * 2.0f * 2.0f));
-
-      if (error_count++ > 10) {
-        break;
-      }
-    }
-  }
-
-  // Disable peer access (also unregisters memory for non-UVA cases)
-  printf("Disabling peer access...\n");
-  HIPCHECK(hipSetDevice(gpuid[0]));
-  HIPCHECK(hipDeviceDisablePeerAccess(gpuid[1]));
-  HIPCHECK(hipSetDevice(gpuid[1]));
-  HIPCHECK(hipDeviceDisablePeerAccess(gpuid[0]));
-
-  // Cleanup and shutdown
-  printf("Shutting down...\n");
-  HIPCHECK(hipEventDestroy(start_event));
-  HIPCHECK(hipEventDestroy(stop_event));
-  HIPCHECK(hipSetDevice(gpuid[0]));
-  HIPCHECK(hipFree(g0));
-  HIPCHECK(hipSetDevice(gpuid[1]));
-  HIPCHECK(hipFree(g1));
-  HIPCHECK(hipHostFree(h0));
-
-  for (int i = 0; i < gpu_n; i++) {
-    HIPCHECK(hipSetDevice(i));
-  }
-
-  if (error_count != 0) {
-    printf("Test failed!\n");
-    exit(EXIT_FAILURE);
-  } else {
-    printf("Test passed\n");
-    exit(EXIT_SUCCESS);
-  }
-}
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.out b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2017.sln b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2019.sln b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2022.sln b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleP2P/simpleP2P_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/.vscode/launch.json b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/Makefile b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/README.md b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.cu b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.cu.hip b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.cu.hip
old mode 100644
new mode 100755
index 578adf6..e69de29
--- a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.cu.hip
+++ b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.cu.hip
@@ -1,314 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* pitchLinearTexture
-*
-* This example demonstrates how to use textures bound to pitch linear memory.
-* It performs a shift of matrix elements using wrap addressing mode (aka
-* periodic boundary conditions) on two arrays, a pitch linear and a CUDA array,
-* in order to highlight the differences in using each.
-*
-* Textures binding to pitch linear memory is a new feature in CUDA 2.2,
-* and allows use of texture features such as wrap addressing mode and
-* filtering which are not possible with textures bound to regular linear memory
-*/
-
-// includes, system
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-
-#ifdef _WIN32
-#define WINDOWS_LEAN_AND_MEAN
-#define NOMINMAX
-#include <windows.h>
-#endif
-
-// Includes CUDA
-#include <hip/hip_runtime.h>
-
-// Utilities and timing functions
-#include "helper_functions.h"  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
-
-// CUDA helper functions
-#include "helper_cuda_hipified.h"  // helper functions for CUDA error check
-
-#define NUM_REPS 100  // number of repetitions performed
-#define TILE_DIM 16   // tile/block size
-
-const char *sSDKsample = "simplePitchLinearTexture";
-
-// Auto-Verification Code
-bool bTestResult = true;
-
-////////////////////////////////////////////////////////////////////////////////
-// NB: (1) The second argument "pitch" is in elements, not bytes
-//     (2) normalized coordinates are used (required for wrap address mode)
-////////////////////////////////////////////////////////////////////////////////
-//! Shifts matrix elements using pitch linear array
-//! @param odata  output data in global memory
-////////////////////////////////////////////////////////////////////////////////
-__global__ void shiftPitchLinear(float *odata, int pitch, int width, int height,
-                                 int shiftX, int shiftY,
-                                 hipTextureObject_t texRefPL) {
-  int xid = blockIdx.x * blockDim.x + threadIdx.x;
-  int yid = blockIdx.y * blockDim.y + threadIdx.y;
-
-  odata[yid * pitch + xid] = tex2D<float>(
-      texRefPL, (xid + shiftX) / (float)width, (yid + shiftY) / (float)height);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Shifts matrix elements using regular array
-//! @param odata  output data in global memory
-////////////////////////////////////////////////////////////////////////////////
-__global__ void shiftArray(float *odata, int pitch, int width, int height,
-                           int shiftX, int shiftY,
-                           hipTextureObject_t texRefArray) {
-  int xid = blockIdx.x * blockDim.x + threadIdx.x;
-  int yid = blockIdx.y * blockDim.y + threadIdx.y;
-
-  odata[yid * pitch + xid] =
-      tex2D<float>(texRefArray, (xid + shiftX) / (float)width,
-                   (yid + shiftY) / (float)height);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Declaration, forward
-void runTest(int argc, char **argv);
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  printf("%s starting...\n\n", sSDKsample);
-
-  runTest(argc, argv);
-
-  printf("%s completed, returned %s\n", sSDKsample,
-         bTestResult ? "OK" : "ERROR!");
-  exit(bTestResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run a simple test for CUDA
-////////////////////////////////////////////////////////////////////////////////
-void runTest(int argc, char **argv) {
-  // Set array size
-  const int nx = 2048;
-  const int ny = 2048;
-
-  // Setup shifts applied to x and y data
-  const int x_shift = 5;
-  const int y_shift = 7;
-
-  if ((nx % TILE_DIM != 0) || (ny % TILE_DIM != 0)) {
-    printf("nx and ny must be multiples of TILE_DIM\n");
-    exit(EXIT_FAILURE);
-  }
-
-  // Setup execution configuration parameters
-  dim3 dimGrid(nx / TILE_DIM, ny / TILE_DIM), dimBlock(TILE_DIM, TILE_DIM);
-
-  // This will pick the best possible CUDA capable device
-  int devID = findCudaDevice(argc, (const char **)argv);
-
-  // CUDA events for timing
-  hipEvent_t start, stop;
-  hipEventCreate(&start);
-  hipEventCreate(&stop);
-
-  // Host allocation and initialization
-  float *h_idata = (float *)malloc(sizeof(float) * nx * ny);
-  float *h_odata = (float *)malloc(sizeof(float) * nx * ny);
-  float *gold = (float *)malloc(sizeof(float) * nx * ny);
-
-  for (int i = 0; i < nx * ny; ++i) {
-    h_idata[i] = (float)i;
-  }
-
-  // Device memory allocation
-  // Pitch linear input data
-  float *d_idataPL;
-  size_t d_pitchBytes;
-
-  HIPCHECK(hipMallocPitch((void **)&d_idataPL, &d_pitchBytes,
-                                  nx * sizeof(float), ny));
-
-  // Array input data
-  hipArray *d_idataArray;
-  hipChannelFormatDesc channelDesc = hipCreateChannelDesc<float>();
-
-  HIPCHECK(hipMallocArray(&d_idataArray, &channelDesc, nx, ny));
-
-  // Pitch linear output data
-  float *d_odata;
-  HIPCHECK(hipMallocPitch((void **)&d_odata, &d_pitchBytes,
-                                  nx * sizeof(float), ny));
-
-  // Copy host data to device
-  // Pitch linear
-  size_t h_pitchBytes = nx * sizeof(float);
-
-  HIPCHECK(hipMemcpy2D(d_idataPL, d_pitchBytes, h_idata, h_pitchBytes,
-                               nx * sizeof(float), ny, hipMemcpyHostToDevice));
-
-  // Array
-  HIPCHECK(hipMemcpyToArray(d_idataArray, 0, 0, h_idata,
-                                    nx * ny * sizeof(float),
-                                    hipMemcpyHostToDevice));
-
-  hipTextureObject_t texRefPL;
-  hipTextureObject_t texRefArray;
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypePitch2D;
-  texRes.res.pitch2D.devPtr = d_idataPL;
-  texRes.res.pitch2D.desc = channelDesc;
-  texRes.res.pitch2D.width = nx;
-  texRes.res.pitch2D.height = ny;
-  texRes.res.pitch2D.pitchInBytes = h_pitchBytes;
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = true;
-  texDescr.filterMode = hipFilterModePoint;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(hipCreateTextureObject(&texRefPL, &texRes, &texDescr, NULL));
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = d_idataArray;
-  texDescr.normalizedCoords = true;
-  texDescr.filterMode = hipFilterModePoint;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-  HIPCHECK(
-      hipCreateTextureObject(&texRefArray, &texRes, &texDescr, NULL));
-
-  // Reference calculation
-  for (int j = 0; j < ny; ++j) {
-    int jshift = (j + y_shift) % ny;
-
-    for (int i = 0; i < nx; ++i) {
-      int ishift = (i + x_shift) % nx;
-      gold[j * nx + i] = h_idata[jshift * nx + ishift];
-    }
-  }
-
-  // Run ShiftPitchLinear kernel
-  HIPCHECK(
-      hipMemset2D(d_odata, d_pitchBytes, 0, nx * sizeof(float), ny));
-
-  HIPCHECK(hipEventRecord(start, 0));
-
-  for (int i = 0; i < NUM_REPS; ++i) {
-    shiftPitchLinear<<<dimGrid, dimBlock>>>(d_odata,
-                                            (int)(d_pitchBytes / sizeof(float)),
-                                            nx, ny, x_shift, y_shift, texRefPL);
-  }
-
-  HIPCHECK(hipEventRecord(stop, 0));
-  HIPCHECK(hipEventSynchronize(stop));
-  float timePL;
-  HIPCHECK(hipEventElapsedTime(&timePL, start, stop));
-
-  // Check results
-  HIPCHECK(hipMemcpy2D(h_odata, h_pitchBytes, d_odata, d_pitchBytes,
-                               nx * sizeof(float), ny, hipMemcpyDeviceToHost));
-
-  bool res = compareData(gold, h_odata, nx * ny, 0.0f, 0.15f);
-
-  bTestResult = true;
-
-  if (res == false) {
-    printf("*** shiftPitchLinear failed ***\n");
-    bTestResult = false;
-  }
-
-  // Run ShiftArray kernel
-  HIPCHECK(
-      hipMemset2D(d_odata, d_pitchBytes, 0, nx * sizeof(float), ny));
-  HIPCHECK(hipEventRecord(start, 0));
-
-  for (int i = 0; i < NUM_REPS; ++i) {
-    shiftArray<<<dimGrid, dimBlock>>>(d_odata,
-                                      (int)(d_pitchBytes / sizeof(float)), nx,
-                                      ny, x_shift, y_shift, texRefArray);
-  }
-
-  HIPCHECK(hipEventRecord(stop, 0));
-  HIPCHECK(hipEventSynchronize(stop));
-  float timeArray;
-  HIPCHECK(hipEventElapsedTime(&timeArray, start, stop));
-
-  // Check results
-  HIPCHECK(hipMemcpy2D(h_odata, h_pitchBytes, d_odata, d_pitchBytes,
-                               nx * sizeof(float), ny, hipMemcpyDeviceToHost));
-  res = compareData(gold, h_odata, nx * ny, 0.0f, 0.15f);
-
-  if (res == false) {
-    printf("*** shiftArray failed ***\n");
-    bTestResult = false;
-  }
-
-  float bandwidthPL =
-      2.f * 1000.f * nx * ny * sizeof(float) / (1.e+9f) / (timePL / NUM_REPS);
-  float bandwidthArray = 2.f * 1000.f * nx * ny * sizeof(float) / (1.e+9f) /
-                         (timeArray / NUM_REPS);
-
-  printf("\nBandwidth (GB/s) for pitch linear: %.2e; for array: %.2e\n",
-         bandwidthPL, bandwidthArray);
-
-  float fetchRatePL = nx * ny / 1.e+6f / (timePL / (1000.0f * NUM_REPS));
-  float fetchRateArray = nx * ny / 1.e+6f / (timeArray / (1000.0f * NUM_REPS));
-
-  printf(
-      "\nTexture fetch rate (Mpix/s) for pitch linear: "
-      "%.2e; for array: %.2e\n\n",
-      fetchRatePL, fetchRateArray);
-
-  // Cleanup
-  free(h_idata);
-  free(h_odata);
-  free(gold);
-
-  HIPCHECK(hipDestroyTextureObject(texRefPL));
-  HIPCHECK(hipDestroyTextureObject(texRefArray));
-  HIPCHECK(hipFree(d_idataPL));
-  HIPCHECK(hipFreeArray(d_idataArray));
-  HIPCHECK(hipFree(d_odata));
-
-  HIPCHECK(hipEventDestroy(start));
-  HIPCHECK(hipEventDestroy(stop));
-}
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.out b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2017.sln b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2019.sln b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2022.sln b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simplePitchLinearTexture/simplePitchLinearTexture_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simplePrintf/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simplePrintf/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/.vscode/launch.json b/src/samples/Samples/0_Introduction/simplePrintf/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simplePrintf/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/Makefile b/src/samples/Samples/0_Introduction/simplePrintf/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/README.md b/src/samples/Samples/0_Introduction/simplePrintf/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf.cu b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf.cu.hip b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf.cu.hip
old mode 100644
new mode 100755
index 80320d7..e69de29
--- a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf.cu.hip
+++ b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf.cu.hip
@@ -1,76 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// System includes
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <assert.h>
-
-// CUDA runtime
-#include <hip/hip_runtime.h>
-
-// helper functions and utilities to work with CUDA
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-
-#ifndef MAX
-#define MAX(a, b) (a > b ? a : b)
-#endif
-
-__global__ void testKernel(int val) {
-  printf("[%d, %d]:\t\tValue is:%d\n", blockIdx.y * gridDim.x + blockIdx.x,
-         threadIdx.z * blockDim.x * blockDim.y + threadIdx.y * blockDim.x +
-             threadIdx.x,
-         val);
-}
-
-int main(int argc, char **argv) {
-  int devID;
-  hipDeviceProp_t props;
-
-  // This will pick the best possible CUDA capable device
-  devID = findCudaDevice(argc, (const char **)argv);
-
-  // Get GPU information
-  HIPCHECK(hipGetDevice(&devID));
-  HIPCHECK(hipGetDeviceProperties(&props, devID));
-  printf("Device %d: \"%s\" with Compute %d.%d capability\n", devID, props.name,
-         props.major, props.minor);
-
-  printf("printf() is called. Output:\n\n");
-
-  // Kernel configuration, where a two-dimensional grid and
-  // three-dimensional blocks are configured.
-  dim3 dimGrid(2, 2);
-  dim3 dimBlock(2, 2, 2);
-  testKernel<<<dimGrid, dimBlock>>>(10);
-  hipDeviceSynchronize();
-
-  return EXIT_SUCCESS;
-}
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf.out b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2017.sln b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2019.sln b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2022.sln b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simplePrintf/simplePrintf_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/Makefile b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/README.md b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary.cu b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary.cu.hip b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary.cu.hip
old mode 100644
new mode 100755
index 5f9509e..e69de29
--- a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary.cu.hip
@@ -1,30 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-__device__ float multiplyByTwo(float number) { return number * 2.0f; }
-
-__device__ float divideByTwo(float number) { return number * 0.5f; }
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary.cuh b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary_hipified.cuh b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleDeviceLibrary_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation.cu b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation.cu.hip b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation.cu.hip
old mode 100644
new mode 100755
index 3f01638..e69de29
--- a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation.cu.hip
@@ -1,166 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// System includes.
-#include <stdio.h>
-//#include "rocprofiler.h"
-#include <iostream>
-#include "HIPCHECK.h"
-// STL.
-#include <vector>
-
-// CUDA runtime.
-#include <hip/hip_runtime.h>
-
-// Helper functions and utilities to work with CUDA.
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-
-// Device library includes.
-#include "simpleDeviceLibrary.cuh"
-
-using std::cout;
-using std::endl;
-
-using std::vector;
-
-#define EPS 1e-5
-
-typedef unsigned int uint;
-typedef float (*deviceFunc)(float);
-
-const char *sampleName = "simpleSeparateCompilation";
-
-////////////////////////////////////////////////////////////////////////////////
-// Auto-Verification Code
-bool testResult = true;
-
-////////////////////////////////////////////////////////////////////////////////
-// Static device pointers to __device__ functions.
-__device__ deviceFunc dMultiplyByTwoPtr = multiplyByTwo;
-__device__ deviceFunc dDivideByTwoPtr = divideByTwo;
-//__global__ deviceFunc dMultiplyByTwoPtr = multiplyByTwo;
-//__global__ deviceFunc dDivideByTwoPtr = divideByTwo;
-
-////////////////////////////////////////////////////////////////////////////////
-// Kernels
-////////////////////////////////////////////////////////////////////////////////
-//! Transforms vector.
-//! Applies the __device__ function "f" to each element of the vector "v".
-////////////////////////////////////////////////////////////////////////////////
-__global__ void transformVector(float *v, deviceFunc f, uint size) {
-  uint tid = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (tid < size) {
-    v[tid] = (*f)(v[tid]);
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Declaration, forward
-void runTest(int argc, const char **argv);
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  cout << sampleName << " starting..." << endl;
-
-  runTest(argc, (const char **)argv);
-
-  cout << sampleName << " completed, returned " << (testResult ? "OK" : "ERROR")
-       << endl;
-
-  exit(testResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-
-void runTest(int argc, const char **argv) {
-  try {
-    // This will pick the best possible CUDA capable device.
-    findCudaDevice(argc, (const char **)argv);
-
-    // Create host vector.
-    const uint kVectorSize = 1000;
-
-    vector<float> hVector(kVectorSize);
-
-    for (uint i = 0; i < kVectorSize; ++i) {
-      hVector[i] = rand() / static_cast<float>(RAND_MAX);
-    }
-
-    // Create and populate device vector.
-    float *dVector;
-    HIPCHECK(hipMalloc(&dVector, kVectorSize * sizeof(float)));
-
-    HIPCHECK(hipMemcpy(dVector, &hVector[0],
-                               kVectorSize * sizeof(float),
-                               hipMemcpyHostToDevice));
-
-    // Kernel configuration, where a one-dimensional
-    // grid and one-dimensional blocks are configured.
-    const int nThreads = 1024;
-    const int nBlocks = 1;
-
-    dim3 dimGrid(nBlocks);
-    dim3 dimBlock(nThreads);
-
-    // Test library functions.
-    deviceFunc hFunctionPtr;
-
-    hipMemcpyFromSymbol(&hFunctionPtr, HIP_SYMBOL(dMultiplyByTwoPtr), sizeof(deviceFunc));
-    transformVector<<<dimGrid, dimBlock>>>(dVector, hFunctionPtr, kVectorSize);
-    HIPCHECK(hipGetLastError());
-
-    hipMemcpyFromSymbol(&hFunctionPtr, HIP_SYMBOL(dDivideByTwoPtr), sizeof(deviceFunc));
-    transformVector<<<dimGrid, dimBlock>>>(dVector, hFunctionPtr, kVectorSize);
-    HIPCHECK(hipGetLastError());
-
-    // Download results.
-    vector<float> hResultVector(kVectorSize);
-
-    HIPCHECK(hipMemcpy(&hResultVector[0], dVector,
-                               kVectorSize * sizeof(float),
-                               hipMemcpyDeviceToHost));
-
-    // Check results.
-    for (int i = 0; i < kVectorSize; ++i) {
-      if (fabs(hVector[i] - hResultVector[i]) > EPS) {
-        cout << "Computations were incorrect..." << endl;
-        testResult = false;
-        break;
-      }
-    }
-
-    // Free resources.
-    if (dVector) HIPCHECK(hipFree(dVector));
-  } catch (...) {
-    cout << "Error occured, exiting..." << endl;
-
-    exit(EXIT_FAILURE);
-  }
-}
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2017.sln b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2019.sln b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2022.sln b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleSeparateCompilation/simpleSeparateCompilation_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleStreams/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleStreams/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleStreams/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleStreams/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/Makefile b/src/samples/Samples/0_Introduction/simpleStreams/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleStreams/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/README.md b/src/samples/Samples/0_Introduction/simpleStreams/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams.cu b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams.cu.hip b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams.cu.hip
old mode 100644
new mode 100755
index 524cc08..96ce636
--- a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams.cu.hip
@@ -1,4 +1,4 @@
-#include "hip/hip_runtime.h"
+
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -59,8 +59,6 @@ const char *sDeviceSyncMethod[] = {
 
 // System includes
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <assert.h>
 
 // CUDA runtime
@@ -126,7 +124,7 @@ inline void AllocateHostMemory(bool bPinGenericMemory, int **pp_a,
         "system memory\n",
         (float)nbytes / 1048576.0f);
     // pin allocate memory
-    HIPCHECK(
+    checkCudaErrors(
         hipHostRegister(*ppAligned_a, nbytes, hipHostRegisterMapped));
   } else
 #endif
@@ -135,7 +133,7 @@ inline void AllocateHostMemory(bool bPinGenericMemory, int **pp_a,
     printf("> hipHostMalloc() allocating %4.2f Mbytes of system memory\n",
            (float)nbytes / 1048576.0f);
     // allocate host memory (pinned is required for achieve asynchronicity)
-    HIPCHECK(hipHostMalloc((void **)pp_a, nbytes));
+    checkCudaErrors(hipHostMalloc((void **)pp_a, nbytes));
     *ppAligned_a = *pp_a;
   }
 }
@@ -147,7 +145,7 @@ inline void FreeHostMemory(bool bPinGenericMemory, int **pp_a,
   // CUDA 4.0 support pinning of generic host memory
   if (bPinGenericMemory) {
     // unpin and delete host memory
-    HIPCHECK(hipHostUnregister(*ppAligned_a));
+    checkCudaErrors(hipHostUnregister(*ppAligned_a));
 #ifdef WIN32
     VirtualFree(*pp_a, 0, MEM_RELEASE);
 #else
@@ -252,7 +250,7 @@ int main(int argc, char **argv) {
 
   // check the compute capability of the device
   int num_devices = 0;
-  HIPCHECK(hipGetDeviceCount(&num_devices));
+  checkCudaErrors(hipGetDeviceCount(&num_devices));
 
   if (0 == num_devices) {
     printf(
@@ -268,11 +266,11 @@ int main(int argc, char **argv) {
     return EXIT_FAILURE;
   }
 
-  HIPCHECK(hipSetDevice(cuda_device));
+  checkCudaErrors(hipSetDevice(cuda_device));
 
   // Checking for compute capabilities
   hipDeviceProp_t deviceProp;
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, cuda_device));
+  checkCudaErrors(hipGetDeviceProperties(&deviceProp, cuda_device));
 
   niterations = 5;
 
@@ -311,7 +309,7 @@ int main(int argc, char **argv) {
   // enable use of blocking sync, to reduce CPU usage
   printf("> Using CPU/GPU Device Synchronization method (%s)\n",
          sDeviceSyncMethod[device_sync_method]);
-  HIPCHECK(hipSetDeviceFlags(
+  checkCudaErrors(hipSetDeviceFlags(
       device_sync_method | (bPinGenericMemory ? hipDeviceMapHost : 0)));
 
   // allocate host memory
@@ -327,10 +325,10 @@ int main(int argc, char **argv) {
   // allocate device memory
   int *d_a = 0,
       *d_c = 0;  // pointers to data and init value in the device memory
-  HIPCHECK(hipMalloc((void **)&d_a, nbytes));
-  HIPCHECK(hipMemset(d_a, 0x0, nbytes));
-  HIPCHECK(hipMalloc((void **)&d_c, sizeof(int)));
-  HIPCHECK(hipMemcpy(d_c, &c, sizeof(int), hipMemcpyHostToDevice));
+  checkCudaErrors(hipMalloc((void **)&d_a, nbytes));
+  checkCudaErrors(hipMemset(d_a, 0x0, nbytes));
+  checkCudaErrors(hipMalloc((void **)&d_c, sizeof(int)));
+  checkCudaErrors(hipMemcpy(d_c, &c, sizeof(int), hipMemcpyHostToDevice));
 
   printf("\nStarting Test\n");
 
@@ -339,7 +337,7 @@ int main(int argc, char **argv) {
       (hipStream_t *)malloc(nstreams * sizeof(hipStream_t));
 
   for (int i = 0; i < nstreams; i++) {
-    HIPCHECK(hipStreamCreate(&(streams[i])));
+    checkCudaErrors(hipStreamCreate(&(streams[i])));
   }
 
   // create CUDA event handles
@@ -349,47 +347,47 @@ int main(int argc, char **argv) {
       ((device_sync_method == hipDeviceScheduleBlockingSync) ? hipEventBlockingSync
                                                       : hipEventDefault);
 
-  HIPCHECK(hipEventCreateWithFlags(&start_event, eventflags));
-  HIPCHECK(hipEventCreateWithFlags(&stop_event, eventflags));
+  checkCudaErrors(hipEventCreateWithFlags(&start_event, eventflags));
+  checkCudaErrors(hipEventCreateWithFlags(&stop_event, eventflags));
 
   // time memcopy from device
-  HIPCHECK(hipEventRecord(start_event, 0));  // record in stream-0, to
+  checkCudaErrors(hipEventRecord(start_event, 0));  // record in stream-0, to
                                                      // ensure that all previous
                                                      // CUDA calls have
                                                      // completed
-  HIPCHECK(hipMemcpyAsync(hAligned_a, d_a, nbytes,
+  checkCudaErrors(hipMemcpyAsync(hAligned_a, d_a, nbytes,
                                   hipMemcpyDeviceToHost, streams[0]));
-  HIPCHECK(hipEventRecord(stop_event, 0));
-  HIPCHECK(hipEventSynchronize(
+  checkCudaErrors(hipEventRecord(stop_event, 0));
+  checkCudaErrors(hipEventSynchronize(
       stop_event));  // block until the event is actually recorded
-  HIPCHECK(hipEventElapsedTime(&time_memcpy, start_event, stop_event));
+  checkCudaErrors(hipEventElapsedTime(&time_memcpy, start_event, stop_event));
   printf("memcopy:\t%.2f\n", time_memcpy);
 
   // time kernel
   threads = dim3(512, 1);
   blocks = dim3(n / threads.x, 1);
-  HIPCHECK(hipEventRecord(start_event, 0));
+  checkCudaErrors(hipEventRecord(start_event, 0));
   init_array<<<blocks, threads, 0, streams[0]>>>(d_a, d_c, niterations);
-  HIPCHECK(hipEventRecord(stop_event, 0));
-  HIPCHECK(hipEventSynchronize(stop_event));
-  HIPCHECK(hipEventElapsedTime(&time_kernel, start_event, stop_event));
+  checkCudaErrors(hipEventRecord(stop_event, 0));
+  checkCudaErrors(hipEventSynchronize(stop_event));
+  checkCudaErrors(hipEventElapsedTime(&time_kernel, start_event, stop_event));
   printf("kernel:\t\t%.2f\n", time_kernel);
 
   //////////////////////////////////////////////////////////////////////
   // time non-streamed execution for reference
   threads = dim3(512, 1);
   blocks = dim3(n / threads.x, 1);
-  HIPCHECK(hipEventRecord(start_event, 0));
+  checkCudaErrors(hipEventRecord(start_event, 0));
 
   for (int k = 0; k < nreps; k++) {
     init_array<<<blocks, threads>>>(d_a, d_c, niterations);
-    HIPCHECK(
+    checkCudaErrors(
         hipMemcpy(hAligned_a, d_a, nbytes, hipMemcpyDeviceToHost));
   }
 
-  HIPCHECK(hipEventRecord(stop_event, 0));
-  HIPCHECK(hipEventSynchronize(stop_event));
-  HIPCHECK(hipEventElapsedTime(&elapsed_time, start_event, stop_event));
+  checkCudaErrors(hipEventRecord(stop_event, 0));
+  checkCudaErrors(hipEventSynchronize(stop_event));
+  checkCudaErrors(hipEventElapsedTime(&elapsed_time, start_event, stop_event));
   printf("non-streamed:\t%.2f\n", elapsed_time / nreps);
 
   //////////////////////////////////////////////////////////////////////
@@ -398,9 +396,9 @@ int main(int argc, char **argv) {
   blocks = dim3(n / (nstreams * threads.x), 1);
   memset(hAligned_a, 255,
          nbytes);  // set host memory bits to all 1s, for testing correctness
-  HIPCHECK(hipMemset(
+  checkCudaErrors(hipMemset(
       d_a, 0, nbytes));  // set device memory to all 0s, for testing correctness
-  HIPCHECK(hipEventRecord(start_event, 0));
+  checkCudaErrors(hipEventRecord(start_event, 0));
 
   for (int k = 0; k < nreps; k++) {
     // asynchronously launch nstreams kernels, each operating on its own portion
@@ -415,15 +413,15 @@ int main(int argc, char **argv) {
     //   commence executing when all previous CUDA calls in stream x have
     //   completed
     for (int i = 0; i < nstreams; i++) {
-      HIPCHECK(hipMemcpyAsync(hAligned_a + i * n / nstreams,
+      checkCudaErrors(hipMemcpyAsync(hAligned_a + i * n / nstreams,
                                       d_a + i * n / nstreams, nbytes / nstreams,
                                       hipMemcpyDeviceToHost, streams[i]));
     }
   }
 
-  HIPCHECK(hipEventRecord(stop_event, 0));
-  HIPCHECK(hipEventSynchronize(stop_event));
-  HIPCHECK(hipEventElapsedTime(&elapsed_time, start_event, stop_event));
+  checkCudaErrors(hipEventRecord(stop_event, 0));
+  checkCudaErrors(hipEventSynchronize(stop_event));
+  checkCudaErrors(hipEventElapsedTime(&elapsed_time, start_event, stop_event));
   printf("%d streams:\t%.2f\n", nstreams, elapsed_time / nreps);
 
   // check whether the output is correct
@@ -432,17 +430,17 @@ int main(int argc, char **argv) {
 
   // release resources
   for (int i = 0; i < nstreams; i++) {
-    HIPCHECK(hipStreamDestroy(streams[i]));
+    checkCudaErrors(hipStreamDestroy(streams[i]));
   }
 
-  HIPCHECK(hipEventDestroy(start_event));
-  HIPCHECK(hipEventDestroy(stop_event));
+  checkCudaErrors(hipEventDestroy(start_event));
+  checkCudaErrors(hipEventDestroy(stop_event));
 
   // Free hipHostMalloc or Generic Host allocated memory (from CUDA 4.0)
   FreeHostMemory(bPinGenericMemory, &h_a, &hAligned_a, nbytes);
 
-  HIPCHECK(hipFree(d_a));
-  HIPCHECK(hipFree(d_c));
+  checkCudaErrors(hipFree(d_a));
+  checkCudaErrors(hipFree(d_c));
 
   return bResults ? EXIT_SUCCESS : EXIT_FAILURE;
 }
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams.out b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2017.sln b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2019.sln b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2022.sln b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleStreams/simpleStreams_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/Makefile b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/README.md b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/data/ref_rotated.pgm b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/data/ref_rotated.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/data/teapot512.pgm b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/data/teapot512.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.cu b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.cu.hip b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.cu.hip
old mode 100644
new mode 100755
index ff6260b..e69de29
--- a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite.cu.hip
@@ -1,299 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This sample demonstrates how use texture fetches in CUDA
- *
- * This sample takes an input PGM image (imageFilename) and generates
- * an output PGM image (imageFilename_out).  This CUDA kernel performs
- * a simple 2D transform (rotation) on the texture coordinates (u,v).
- */
-
-// Includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-
-#ifdef _WIN32
-#define WINDOWS_LEAN_AND_MEAN
-#define NOMINMAX
-#include <windows.h>
-#endif
-
-// Includes CUDA
-#include <hip/hip_runtime.h>
-
-// Utilities and timing functions
-#include "helper_functions.h"  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
-
-// CUDA helper functions
-#include "helper_cuda_hipified.h"  // helper functions for CUDA error check
-
-#define MIN_EPSILON_ERROR 5e-3f
-
-////////////////////////////////////////////////////////////////////////////////
-// Define the files that are to be save and the reference images for validation
-const char *imageFilename = "teapot512.pgm";
-const char *refFilename = "ref_rotated.pgm";
-float angle = 0.5f;  // angle to rotate image by (in radians)
-
-// Auto-Verification Code
-bool testResult = true;
-
-static const char *sampleName = "simpleSurfaceWrite";
-
-////////////////////////////////////////////////////////////////////////////////
-// Kernels
-////////////////////////////////////////////////////////////////////////////////
-//! Write to a cuArray (texture data source) using surface writes
-//! @param gIData input data in global memory
-////////////////////////////////////////////////////////////////////////////////
-__global__ void surfaceWriteKernel(float *gIData, int width, int height,
-                                   hipSurfaceObject_t outputSurface) {
-  // calculate surface coordinates
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  // read from global memory and write to cuarray (via surface reference)
-  //surf2Dwrite(gIData[y * width + x], outputSurface, x * 4, y,
-             // hipBoundaryModeTrap);
-  surf2Dwrite(gIData[y * width + x], outputSurface, x * 4, y);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Transform an image using texture lookups
-//! @param gOData  output data in global memory
-////////////////////////////////////////////////////////////////////////////////
-__global__ void transformKernel(float *gOData, int width, int height,
-                                float theta, hipTextureObject_t tex) {
-  // calculate normalized texture coordinates
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  float u = x / (float)width;
-  float v = y / (float)height;
-
-  // transform coordinates
-  u -= 0.5f;
-  v -= 0.5f;
-  float tu = u * cosf(theta) - v * sinf(theta) + 0.5f;
-  float tv = v * cosf(theta) + u * sinf(theta) + 0.5f;
-
-  // read from texture and write to global memory
-  gOData[y * width + x] = tex2D<float>(tex, tu, tv);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Declaration, forward
-void runTest(int argc, char **argv);
-
-extern "C" void computeGold(float *reference, float *idata,
-                            const unsigned int len);
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  printf("%s starting...\n", sampleName);
-
-  // Process command-line arguments
-  if (argc > 1) {
-    if (checkCmdLineFlag(argc, (const char **)argv, "input")) {
-      getCmdLineArgumentString(argc, (const char **)argv, "input",
-                               (char **)&imageFilename);
-
-      if (checkCmdLineFlag(argc, (const char **)argv, "reference")) {
-        getCmdLineArgumentString(argc, (const char **)argv, "reference",
-                                 (char **)&refFilename);
-      } else {
-        printf("-input flag should be used with -reference flag");
-        exit(EXIT_FAILURE);
-      }
-    } else if (checkCmdLineFlag(argc, (const char **)argv, "reference")) {
-      printf("-reference flag should be used with -input flag");
-      exit(EXIT_FAILURE);
-    }
-  }
-
-  runTest(argc, argv);
-
-  printf("%s completed, returned %s\n", sampleName,
-         testResult ? "OK" : "ERROR!");
-  exit(testResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run a simple test for CUDA
-////////////////////////////////////////////////////////////////////////////////
-void runTest(int argc, char **argv) {
-  // Use command-line specified CUDA device,
-  // otherwise use device with highest Gflops/s
-  int devID = findCudaDevice(argc, (const char **)argv);
-
-  // Get number of SMs on this GPU
-  hipDeviceProp_t deviceProps;
-
-  HIPCHECK(hipGetDeviceProperties(&deviceProps, devID));
-  printf("CUDA device [%s] has %d Multi-Processors, SM %d.%d\n",
-         deviceProps.name, deviceProps.multiProcessorCount, deviceProps.major,
-         deviceProps.minor);
-
-  // Load image from disk
-  float *hData = NULL;
-  unsigned int width, height;
-  char *imagePath = sdkFindFilePath(imageFilename, argv[0]);
-
-  if (imagePath == NULL) {
-    printf("Unable to source image input file: %s\n", imageFilename);
-    exit(EXIT_FAILURE);
-  }
-
-  sdkLoadPGM(imagePath, &hData, &width, &height);
-
-  unsigned int size = width * height * sizeof(float);
-  printf("Loaded '%s', %d x %d pixels\n", imageFilename, width, height);
-
-  // Load reference image from image (output)
-  float *hDataRef = (float *)malloc(size);
-  char *refPath = sdkFindFilePath(refFilename, argv[0]);
-
-  if (refPath == NULL) {
-    printf("Unable to find reference image file: %s\n", refFilename);
-    exit(EXIT_FAILURE);
-  }
-
-  sdkLoadPGM(refPath, &hDataRef, &width, &height);
-
-  // Allocate device memory for result
-  float *dData = NULL;
-  HIPCHECK(hipMalloc((void **)&dData, size));
-
-  // Allocate array and copy image data
-  hipChannelFormatDesc channelDesc =
-      hipCreateChannelDesc(32, 0, 0, 0, hipChannelFormatKindFloat);
-  hipArray *cuArray;
-  HIPCHECK(hipMallocArray(&cuArray, &channelDesc, width, height,
-                                  hipArraySurfaceLoadStore));
-
-  dim3 dimBlock(8, 8, 1);
-  dim3 dimGrid(width / dimBlock.x, height / dimBlock.y, 1);
-
-  hipSurfaceObject_t outputSurface;
-  hipResourceDesc surfRes;
-  memset(&surfRes, 0, sizeof(hipResourceDesc));
-  surfRes.resType = hipResourceTypeArray;
-  surfRes.res.array.array = cuArray;
-
-  HIPCHECK(hipCreateSurfaceObject(&outputSurface, &surfRes));
-#if 1
-  HIPCHECK(hipMemcpy(dData, hData, size, hipMemcpyHostToDevice));
-  surfaceWriteKernel<<<dimGrid, dimBlock>>>(dData, width, height,
-                                            outputSurface);
-#else  // This is what differs from the example simpleTexture
-  HIPCHECK(
-      hipMemcpyToArray(cuArray, 0, 0, hData, size, hipMemcpyHostToDevice));
-#endif
-
-  hipTextureObject_t tex;
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = cuArray;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = true;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(hipCreateTextureObject(&tex, &texRes, &texDescr, NULL));
-
-  // Warmup
-  transformKernel<<<dimGrid, dimBlock, 0>>>(dData, width, height, angle, tex);
-
-  HIPCHECK(hipDeviceSynchronize());
-
-  StopWatchInterface *timer = NULL;
-  sdkCreateTimer(&timer);
-  sdkStartTimer(&timer);
-
-  // Execute the kernel
-  transformKernel<<<dimGrid, dimBlock, 0>>>(dData, width, height, angle, tex);
-
-  // Check if kernel execution generated an error
-  getLastCudaError("Kernel execution failed");
-
-  hipDeviceSynchronize();
-  sdkStopTimer(&timer);
-  printf("Processing time: %f (ms)\n", sdkGetTimerValue(&timer));
-  printf("%.2f Mpixels/sec\n",
-         (width * height / (sdkGetTimerValue(&timer) / 1000.0f)) / 1e6);
-  sdkDeleteTimer(&timer);
-
-  // Allocate mem for the result on host side
-  float *hOData = (float *)malloc(size);
-  // copy result from device to host
-  HIPCHECK(hipMemcpy(hOData, dData, size, hipMemcpyDeviceToHost));
-
-  // Write result to file
-  char outputFilename[1024];
-  strcpy(outputFilename, "output.pgm");
-  sdkSavePGM("output.pgm", hOData, width, height);
-  printf("Wrote '%s'\n", outputFilename);
-
-  // Write regression file if necessary
-  if (checkCmdLineFlag(argc, (const char **)argv, "regression")) {
-    // Write file for regression test
-    sdkWriteFile<float>("./data/regression.dat", hOData, width * height, 0.0f,
-                        false);
-  } else {
-    // We need to reload the data from disk,
-    // because it is inverted upon output
-    sdkLoadPGM(outputFilename, &hOData, &width, &height);
-
-    printf("Comparing files\n");
-    printf("\toutput:    <%s>\n", outputFilename);
-    printf("\treference: <%s>\n", refPath);
-    testResult =
-        compareData(hOData, hDataRef, width * height, MIN_EPSILON_ERROR, 0.0f);
-  }
-
-  HIPCHECK(hipDestroySurfaceObject(outputSurface));
-  HIPCHECK(hipDestroyTextureObject(tex));
-  HIPCHECK(hipFree(dData));
-  HIPCHECK(hipFreeArray(cuArray));
-  free(imagePath);
-  free(refPath);
-}
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2017.sln b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2019.sln b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2022.sln b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleSurfaceWrite/simpleSurfaceWrite_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleTemplates/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleTemplates/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleTemplates/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleTemplates/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/Makefile b/src/samples/Samples/0_Introduction/simpleTemplates/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleTemplates/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/README.md b/src/samples/Samples/0_Introduction/simpleTemplates/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/sharedmem.cuh b/src/samples/Samples/0_Introduction/simpleTemplates/sharedmem.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/sharedmem_hipified.cuh b/src/samples/Samples/0_Introduction/simpleTemplates/sharedmem_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates.cu b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates.cu.hip b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates.cu.hip
old mode 100644
new mode 100755
index 7ca670f..e69de29
--- a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates.cu.hip
@@ -1,267 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* This sample is a templatized version of the template project.
-* It also shows how to correctly templatize dynamically allocated shared
-* memory arrays.
-* Host code.
-*/
-
-// System includes
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <assert.h>
-#include <string.h>
-#include <math.h>
-
-// CUDA runtime
-#include <hip/hip_runtime.h>
-
-// helper functions and utilities to work with CUDA
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-
-#ifndef MAX
-#define MAX(a, b) (a > b ? a : b)
-#endif
-
-// includes, kernels
-#include "sharedmem.cuh"
-
-int g_TotalFailures = 0;
-
-////////////////////////////////////////////////////////////////////////////////
-//! Simple test kernel for device functionality
-//! @param g_idata  input data in global memory
-//! @param g_odata  output data in global memory
-////////////////////////////////////////////////////////////////////////////////
-template <class T>
-__global__ void testKernel(T *g_idata, T *g_odata) {
-  // Shared mem size is determined by the host app at run time
-  SharedMemory<T> smem;
-  T *sdata = smem.getPointer();
-
-  // access thread id
-  const unsigned int tid = threadIdx.x;
-  // access number of threads in this block
-  const unsigned int num_threads = blockDim.x;
-
-  // read in input data from global memory
-  sdata[tid] = g_idata[tid];
-  __syncthreads();
-
-  // perform some computations
-  sdata[tid] = (T)num_threads * sdata[tid];
-  __syncthreads();
-
-  // write data to global memory
-  g_odata[tid] = sdata[tid];
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// declaration, forward
-template <class T>
-void runTest(int argc, char **argv, int len);
-
-template <class T>
-void computeGold(T *reference, T *idata, const unsigned int len) {
-  const T T_len = static_cast<T>(len);
-
-  for (unsigned int i = 0; i < len; ++i) {
-    reference[i] = idata[i] * T_len;
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  printf("> runTest<float,32>\n");
-  runTest<float>(argc, argv, 32);
-  printf("> runTest<int,64>\n");
-  runTest<int>(argc, argv, 64);
-
-  printf("\n[simpleTemplates] -> Test Results: %d Failures\n", g_TotalFailures);
-
-  exit(g_TotalFailures == 0 ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-
-// To completely templatize runTest (below) with cutil, we need to use
-// template specialization to wrap up CUTIL's array comparison and file writing
-// functions for different types.
-
-// Here's the generic wrapper for cutCompare*
-template <class T>
-class ArrayComparator {
- public:
-  bool compare(const T *reference, T *data, unsigned int len) {
-    fprintf(stderr,
-            "Error: no comparison function implemented for this type\n");
-    return false;
-  }
-};
-
-// Here's the specialization for ints:
-template <>
-class ArrayComparator<int> {
- public:
-  bool compare(const int *reference, int *data, unsigned int len) {
-    return compareData(reference, data, len, 0.15f, 0.0f);
-  }
-};
-
-// Here's the specialization for floats:
-template <>
-class ArrayComparator<float> {
- public:
-  bool compare(const float *reference, float *data, unsigned int len) {
-    return compareData(reference, data, len, 0.15f, 0.15f);
-  }
-};
-
-// Here's the generic wrapper for cutWriteFile*
-template <class T>
-class ArrayFileWriter {
- public:
-  bool write(const char *filename, T *data, unsigned int len, float epsilon) {
-    fprintf(stderr,
-            "Error: no file write function implemented for this type\n");
-    return false;
-  }
-};
-
-// Here's the specialization for ints:
-template <>
-class ArrayFileWriter<int> {
- public:
-  bool write(const char *filename, int *data, unsigned int len, float epsilon) {
-    return sdkWriteFile(filename, data, len, epsilon, false);
-  }
-};
-
-// Here's the specialization for floats:
-template <>
-class ArrayFileWriter<float> {
- public:
-  bool write(const char *filename, float *data, unsigned int len,
-             float epsilon) {
-    return sdkWriteFile(filename, data, len, epsilon, false);
-  }
-};
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run a simple test for CUDA
-////////////////////////////////////////////////////////////////////////////////
-template <class T>
-void runTest(int argc, char **argv, int len) {
-  int devID;
-  hipDeviceProp_t deviceProps;
-
-  devID = findCudaDevice(argc, (const char **)argv);
-
-  // get number of SMs on this GPU
-  HIPCHECK(hipGetDeviceProperties(&deviceProps, devID));
-  printf("CUDA device [%s] has %d Multi-Processors\n", deviceProps.name,
-         deviceProps.multiProcessorCount);
-
-  // create and start timer
-  StopWatchInterface *timer = NULL;
-  sdkCreateTimer(&timer);
-
-  // start the timer
-  sdkStartTimer(&timer);
-
-  unsigned int num_threads = len;
-  unsigned int mem_size = sizeof(float) * num_threads;
-
-  // allocate host memory
-  T *h_idata = (T *)malloc(mem_size);
-
-  // initialize the memory
-  for (unsigned int i = 0; i < num_threads; ++i) {
-    h_idata[i] = (T)i;
-  }
-
-  // allocate device memory
-  T *d_idata;
-  HIPCHECK(hipMalloc((void **)&d_idata, mem_size));
-  // copy host memory to device
-  HIPCHECK(
-      hipMemcpy(d_idata, h_idata, mem_size, hipMemcpyHostToDevice));
-
-  // allocate device memory for result
-  T *d_odata;
-  HIPCHECK(hipMalloc((void **)&d_odata, mem_size));
-
-  // setup execution parameters
-  dim3 grid(1, 1, 1);
-  dim3 threads(num_threads, 1, 1);
-
-  // execute the kernel
-  testKernel<T><<<grid, threads, mem_size>>>(d_idata, d_odata);
-
-  // check if kernel execution generated and error
-  getLastCudaError("Kernel execution failed");
-
-  // allocate mem for the result on host side
-  T *h_odata = (T *)malloc(mem_size);
-  // copy result from device to host
-  HIPCHECK(hipMemcpy(h_odata, d_odata, sizeof(T) * num_threads,
-                             hipMemcpyDeviceToHost));
-
-  sdkStopTimer(&timer);
-  printf("Processing time: %f (ms)\n", sdkGetTimerValue(&timer));
-  sdkDeleteTimer(&timer);
-
-  // compute reference solution
-  T *reference = (T *)malloc(mem_size);
-  computeGold<T>(reference, h_idata, num_threads);
-
-  ArrayComparator<T> comparator;
-  ArrayFileWriter<T> writer;
-
-  // check result
-  if (checkCmdLineFlag(argc, (const char **)argv, "regression")) {
-    // write file for regression test
-    writer.write("./data/regression.dat", h_odata, num_threads, 0.0f);
-  } else {
-    // custom output handling when no regression test running
-    // in this case check if the result is equivalent to the expected solution
-    bool res = comparator.compare(reference, h_odata, num_threads);
-    printf("Compare %s\n\n", (1 == res) ? "OK" : "MISMATCH");
-    g_TotalFailures += (1 != res);
-  }
-
-  // cleanup memory
-  free(h_idata);
-  free(h_odata);
-  free(reference);
-  HIPCHECK(hipFree(d_idata));
-  HIPCHECK(hipFree(d_odata));
-}
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates.out b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2017.sln b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2019.sln b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2022.sln b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleTemplates/simpleTemplates_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/Makefile b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/README.md b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/sharedmem.cuh b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/sharedmem.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/sharedmem_hipified.cuh b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/sharedmem_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates.cpp b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_hipified.cpp b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_kernel.cu b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_kernel.cu.hip b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_kernel.cu.hip
old mode 100644
new mode 100755
index 89eed5d..e69de29
--- a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_kernel.cu.hip
@@ -1,71 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// includes, kernels
-#include "sharedmem.cuh"
-
-////////////////////////////////////////////////////////////////////////////////
-//! Simple test kernel for device functionality
-//! @param g_idata  input data in global memory
-//! @param g_odata  output data in global memory
-////////////////////////////////////////////////////////////////////////////////
-
-template <class T>
-__device__ void testKernel(T *g_idata, T *g_odata) {
-  // Shared mem size is determined by the host app at run time
-  SharedMemory<T> smem;
-
-  T *sdata = smem.getPointer();
-
-  // access thread id
-  const unsigned int tid = threadIdx.x;
-
-  // access number of threads in this block
-  const unsigned int num_threads = blockDim.x;
-
-  // read in input data from global memory
-  sdata[tid] = g_idata[tid];
-
-  __syncthreads();
-
-  // perform some computations
-  sdata[tid] = (T)num_threads * sdata[tid];
-
-  __syncthreads();
-
-  // write data to global memory
-  g_odata[tid] = sdata[tid];
-}
-
-extern "C" __global__ void testFloat(float *p1, float *p2) {
-  testKernel<float>(p1, p2);
-}
-
-extern "C" __global__ void testInt(int *p1, int *p2) {
-  testKernel<int>(p1, p2);
-}
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2017.sln b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2019.sln b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2022.sln b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleTemplates_nvrtc/simpleTemplates_nvrtc_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleTexture/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleTexture/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleTexture/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleTexture/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/Makefile b/src/samples/Samples/0_Introduction/simpleTexture/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleTexture/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/README.md b/src/samples/Samples/0_Introduction/simpleTexture/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/data/ref_rotated.pgm b/src/samples/Samples/0_Introduction/simpleTexture/data/ref_rotated.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/data/teapot512.pgm b/src/samples/Samples/0_Introduction/simpleTexture/data/teapot512.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/data/teapot512_out.pgm b/src/samples/Samples/0_Introduction/simpleTexture/data/teapot512_out.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture.cu b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture.cu.hip b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture.cu.hip
old mode 100644
new mode 100755
index 1fcf35a..e69de29
--- a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture.cu.hip
@@ -1,254 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This sample demonstrates how use texture fetches in CUDA
- *
- * This sample takes an input PGM image (image_filename) and generates
- * an output PGM image (image_filename_out).  This CUDA kernel performs
- * a simple 2D transform (rotation) on the texture coordinates (u,v).
- */
-
-// Includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-
-#ifdef _WIN32
-#define WINDOWS_LEAN_AND_MEAN
-#define NOMINMAX
-#include <windows.h>
-#endif
-
-// Includes CUDA
-#include <hip/hip_runtime.h>
-
-// Utilities and timing functions
-#include "helper_functions.h"  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
-
-// CUDA helper functions
-#include "helper_cuda_hipified.h"  // helper functions for CUDA error check
-
-#define MAX_EPSILON_ERROR 5e-3f
-
-// Define the files that are to be save and the reference images for validation
-const char *imageFilename = "teapot512.pgm";
-const char *refFilename = "ref_rotated.pgm";
-
-const char *sampleName = "simpleTexture";
-
-////////////////////////////////////////////////////////////////////////////////
-// Constants
-const float angle = 0.5f;  // angle to rotate image by (in radians)
-
-// Auto-Verification Code
-bool testResult = true;
-
-////////////////////////////////////////////////////////////////////////////////
-//! Transform an image using texture lookups
-//! @param outputData  output data in global memory
-////////////////////////////////////////////////////////////////////////////////
-__global__ void transformKernel(float *outputData, int width, int height,
-                                float theta, hipTextureObject_t tex) {
-  // calculate normalized texture coordinates
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  float u = (float)x - (float)width / 2;
-  float v = (float)y - (float)height / 2;
-  float tu = u * cosf(theta) - v * sinf(theta);
-  float tv = v * cosf(theta) + u * sinf(theta);
-
-  tu /= (float)width;
-  tv /= (float)height;
-
-  // read from texture and write to global memory
-  outputData[y * width + x] = tex2D<float>(tex, tu + 0.5f, tv + 0.5f);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Declaration, forward
-void runTest(int argc, char **argv);
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  printf("%s starting...\n", sampleName);
-
-  // Process command-line arguments
-  if (argc > 1) {
-    if (checkCmdLineFlag(argc, (const char **)argv, "input")) {
-      getCmdLineArgumentString(argc, (const char **)argv, "input",
-                               (char **)&imageFilename);
-
-      if (checkCmdLineFlag(argc, (const char **)argv, "reference")) {
-        getCmdLineArgumentString(argc, (const char **)argv, "reference",
-                                 (char **)&refFilename);
-      } else {
-        printf("-input flag should be used with -reference flag");
-        exit(EXIT_FAILURE);
-      }
-    } else if (checkCmdLineFlag(argc, (const char **)argv, "reference")) {
-      printf("-reference flag should be used with -input flag");
-      exit(EXIT_FAILURE);
-    }
-  }
-
-  runTest(argc, argv);
-
-  printf("%s completed, returned %s\n", sampleName,
-         testResult ? "OK" : "ERROR!");
-  exit(testResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run a simple test for CUDA
-////////////////////////////////////////////////////////////////////////////////
-void runTest(int argc, char **argv) {
-  int devID = findCudaDevice(argc, (const char **)argv);
-
-  // load image from disk
-  float *hData = NULL;
-  unsigned int width, height;
-  char *imagePath = sdkFindFilePath(imageFilename, argv[0]);
-
-  if (imagePath == NULL) {
-    printf("Unable to source image file: %s\n", imageFilename);
-    exit(EXIT_FAILURE);
-  }
-
-  sdkLoadPGM(imagePath, &hData, &width, &height);
-
-  unsigned int size = width * height * sizeof(float);
-  printf("Loaded '%s', %d x %d pixels\n", imageFilename, width, height);
-
-  // Load reference image from image (output)
-  float *hDataRef = (float *)malloc(size);
-  char *refPath = sdkFindFilePath(refFilename, argv[0]);
-
-  if (refPath == NULL) {
-    printf("Unable to find reference image file: %s\n", refFilename);
-    exit(EXIT_FAILURE);
-  }
-
-  sdkLoadPGM(refPath, &hDataRef, &width, &height);
-
-  // Allocate device memory for result
-  float *dData = NULL;
-  HIPCHECK(hipMalloc((void **)&dData, size));
-
-  // Allocate array and copy image data
-  hipChannelFormatDesc channelDesc =
-      hipCreateChannelDesc(32, 0, 0, 0, hipChannelFormatKindFloat);
-  hipArray *cuArray;
-  HIPCHECK(hipMallocArray(&cuArray, &channelDesc, width, height));
-  HIPCHECK(
-      hipMemcpyToArray(cuArray, 0, 0, hData, size, hipMemcpyHostToDevice));
-
-  hipTextureObject_t tex;
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = cuArray;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = true;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(hipCreateTextureObject(&tex, &texRes, &texDescr, NULL));
-
-  dim3 dimBlock(8, 8, 1);
-  dim3 dimGrid(width / dimBlock.x, height / dimBlock.y, 1);
-
-  // Warmup
-  transformKernel<<<dimGrid, dimBlock, 0>>>(dData, width, height, angle, tex);
-
-  HIPCHECK(hipDeviceSynchronize());
-  StopWatchInterface *timer = NULL;
-  sdkCreateTimer(&timer);
-  sdkStartTimer(&timer);
-
-  // Execute the kernel
-  transformKernel<<<dimGrid, dimBlock, 0>>>(dData, width, height, angle, tex);
-
-  // Check if kernel execution generated an error
-  getLastCudaError("Kernel execution failed");
-
-  HIPCHECK(hipDeviceSynchronize());
-  sdkStopTimer(&timer);
-  printf("Processing time: %f (ms)\n", sdkGetTimerValue(&timer));
-  printf("%.2f Mpixels/sec\n",
-         (width * height / (sdkGetTimerValue(&timer) / 1000.0f)) / 1e6);
-  sdkDeleteTimer(&timer);
-
-  // Allocate mem for the result on host side
-  float *hOutputData = (float *)malloc(size);
-  // copy result from device to host
-  HIPCHECK(hipMemcpy(hOutputData, dData, size, hipMemcpyDeviceToHost));
-
-  // Write result to file
-  char outputFilename[1024];
-  strcpy(outputFilename, imagePath);
-  strcpy(outputFilename + strlen(imagePath) - 4, "_out.pgm");
-  sdkSavePGM(outputFilename, hOutputData, width, height);
-  printf("Wrote '%s'\n", outputFilename);
-
-  // Write regression file if necessary
-  if (checkCmdLineFlag(argc, (const char **)argv, "regression")) {
-    // Write file for regression test
-    sdkWriteFile<float>("./data/regression.dat", hOutputData, width * height,
-                        0.0f, false);
-  } else {
-    // We need to reload the data from disk,
-    // because it is inverted upon output
-    sdkLoadPGM(outputFilename, &hOutputData, &width, &height);
-
-    printf("Comparing files\n");
-    printf("\toutput:    <%s>\n", outputFilename);
-    printf("\treference: <%s>\n", refPath);
-
-    testResult = compareData(hOutputData, hDataRef, width * height,
-                             MAX_EPSILON_ERROR, 0.15f);
-  }
-
-  HIPCHECK(hipDestroyTextureObject(tex));
-  HIPCHECK(hipFree(dData));
-  HIPCHECK(hipFreeArray(cuArray));
-  free(imagePath);
-  free(refPath);
-}
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2017.sln b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2019.sln b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2022.sln b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleTexture/simpleTexture_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleTexture3D/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleTexture3D/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleTexture3D/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleTexture3D/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/Makefile b/src/samples/Samples/0_Introduction/simpleTexture3D/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleTexture3D/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/README.md b/src/samples/Samples/0_Introduction/simpleTexture3D/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/data/Bucky.raw b/src/samples/Samples/0_Introduction/simpleTexture3D/data/Bucky.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/data/ref_texture3D.bin b/src/samples/Samples/0_Introduction/simpleTexture3D/data/ref_texture3D.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/doc/sshot_lg.JPG b/src/samples/Samples/0_Introduction/simpleTexture3D/doc/sshot_lg.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/doc/sshot_md.JPG b/src/samples/Samples/0_Introduction/simpleTexture3D/doc/sshot_md.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/doc/sshot_sm.JPG b/src/samples/Samples/0_Introduction/simpleTexture3D/doc/sshot_sm.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/findgllib.mk b/src/samples/Samples/0_Introduction/simpleTexture3D/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D.cpp b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_hipified.cpp b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_kernel.cu b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_kernel.cu.hip b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_kernel.cu.hip
old mode 100644
new mode 100755
index bb9c818..e69de29
--- a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_kernel.cu.hip
@@ -1,144 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef _SIMPLETEXTURE3D_KERNEL_CU_
-#define _SIMPLETEXTURE3D_KERNEL_CU_
-
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-
-#include "helper_cuda_hipified.h"
-#include <helper_math.h>
-
-typedef unsigned int uint;
-typedef unsigned char uchar;
-
-hipArray *d_volumeArray = 0;
-hipTextureObject_t tex;  // 3D texture
-
-__global__ void d_render(uint *d_output, uint imageW, uint imageH, float w,
-                         hipTextureObject_t texObj) {
-  uint x = __umul24(blockIdx.x, blockDim.x) + threadIdx.x;
-  uint y = __umul24(blockIdx.y, blockDim.y) + threadIdx.y;
-
-  float u = x / (float)imageW;
-  float v = y / (float)imageH;
-  // read from 3D texture
-  float voxel = tex3D<float>(texObj, u, v, w);
-
-  if ((x < imageW) && (y < imageH)) {
-    // write output color
-    uint i = __umul24(y, imageW) + x;
-    d_output[i] = voxel * 255;
-  }
-}
-
-extern "C" void setTextureFilterMode(bool bLinearFilter) {
-  if (tex) {
-    HIPCHECK(hipDestroyTextureObject(tex));
-  }
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = d_volumeArray;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = true;
-  texDescr.filterMode =
-      bLinearFilter ? hipFilterModeLinear : hipFilterModePoint;
-  ;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.addressMode[2] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeNormalizedFloat;
-
-  HIPCHECK(hipCreateTextureObject(&tex, &texRes, &texDescr, NULL));
-}
-
-extern "C" void initCuda(const uchar *h_volume, hipExtent volumeSize) {
-  // create 3D array
-  hipChannelFormatDesc channelDesc = hipCreateChannelDesc<uchar>();
-  HIPCHECK(hipMalloc3DArray(&d_volumeArray, &channelDesc, volumeSize));
-
-  // copy data to 3D array
-  hipMemcpy3DParms copyParams = {0};
-  copyParams.srcPtr =
-      make_hipPitchedPtr((void *)h_volume, volumeSize.width * sizeof(uchar),
-                          volumeSize.width, volumeSize.height);
-  copyParams.dstArray = d_volumeArray;
-  copyParams.extent = volumeSize;
-  copyParams.kind = hipMemcpyHostToDevice;
-  HIPCHECK(hipMemcpy3D(&copyParams));
-
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = d_volumeArray;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  // access with normalized texture coordinates
-  texDescr.normalizedCoords = true;
-  // linear interpolation
-  texDescr.filterMode = hipFilterModeLinear;
-  // wrap texture coordinates
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.addressMode[2] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeNormalizedFloat;
-
-  HIPCHECK(hipCreateTextureObject(&tex, &texRes, &texDescr, NULL));
-}
-
-extern "C" void render_kernel(dim3 gridSize, dim3 blockSize, uint *d_output,
-                              uint imageW, uint imageH, float w) {
-  d_render<<<gridSize, blockSize>>>(d_output, imageW, imageH, w, tex);
-}
-
-void cleanupCuda() {
-  if (tex) {
-    HIPCHECK(hipDestroyTextureObject(tex));
-  }
-  if (d_volumeArray) {
-    HIPCHECK(hipFreeArray(d_volumeArray));
-  }
-}
-
-#endif  // #ifndef _SIMPLETEXTURE3D_KERNEL_CU_
-
-
-#endif  // #ifndef _SIMPLETEXTURE3D_KERNEL_CU_
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2017.sln b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2019.sln b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2022.sln b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleTexture3D/simpleTexture3D_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleTextureDrv/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleTextureDrv/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleTextureDrv/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleTextureDrv/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/Makefile b/src/samples/Samples/0_Introduction/simpleTextureDrv/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/README.md b/src/samples/Samples/0_Introduction/simpleTextureDrv/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/data/ref_rotated.pgm b/src/samples/Samples/0_Introduction/simpleTextureDrv/data/ref_rotated.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/data/teapot512.pgm b/src/samples/Samples/0_Introduction/simpleTextureDrv/data/teapot512.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/data/teapot512_out.pgm b/src/samples/Samples/0_Introduction/simpleTextureDrv/data/teapot512_out.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv.cpp b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_hipified.cpp b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2017.sln b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2019.sln b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2022.sln b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTextureDrv_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTexture_kernel.cu b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTexture_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTexture_kernel.cu.hip b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTexture_kernel.cu.hip
old mode 100644
new mode 100755
index d878b25..e69de29
--- a/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTexture_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleTextureDrv/simpleTexture_kernel.cu.hip
@@ -1,56 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef _SIMPLETEXTURE_KERNEL_H_
-#define _SIMPLETEXTURE_KERNEL_H_
-#include <hip/hip_runtime.h>
-
-////////////////////////////////////////////////////////////////////////////////
-//! Transform an image using texture lookups
-//! @param g_odata  output data in global memory
-////////////////////////////////////////////////////////////////////////////////
-extern "C" __global__ void transformKernel(float *g_odata, int width,
-                                           int height, float theta,
-                                           hipTextureObject_t tex) {
-  // calculate normalized texture coordinates
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  float u = (float)x - (float)width / 2;
-  float v = (float)y - (float)height / 2;
-  float tu = u * cosf(theta) - v * sinf(theta);
-  float tv = v * cosf(theta) + u * sinf(theta);
-
-  tu /= (float)width;
-  tv /= (float)height;
-
-  // read from texture and write to global memory
-  g_odata[y * width + x] = tex2D<float>(tex, tu + 0.5f, tv + 0.5f);
-}
-
-#endif  // #ifndef _SIMPLETEXTURE_KERNEL_H_
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/Makefile b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/README.md b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics.cu b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics.cu.hip b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics.cu.hip
old mode 100644
new mode 100755
index bd26310..e69de29
--- a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics.cu.hip
@@ -1,311 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// System includes
-#include <assert.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-
-// CUDA runtime
-#include <hip/hip_runtime.h>
-
-// helper functions and utilities to work with CUDA
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"
-//#include <hipify/__clang_cuda_intrinsics.h>
-#ifndef MAX
-#define MAX(a, b) (a > b ? a : b)
-#endif
-
-static const char *sSDKsample = "[simpleVoteIntrinsics]\0";
-
-////////////////////////////////////////////////////////////////////////////////
-// Global types and parameters
-////////////////////////////////////////////////////////////////////////////////
-#define VOTE_DATA_GROUP 4
-
-////////////////////////////////////////////////////////////////////////////////
-// CUDA Voting Kernel functions
-////////////////////////////////////////////////////////////////////////////////
-#include "simpleVote_kernel.cuh"
-
-// Generate the test pattern for Tests 1 and 2
-void genVoteTestPattern(unsigned int *VOTE_PATTERN, int size) {
-  // For testing VOTE.Any (all of these threads will return 0)
-  for (int i = 0; i < size / 4; i++) {
-    VOTE_PATTERN[i] = 0x00000000;
-  }
-
-  // For testing VOTE.Any (1/2 these threads will return 1)
-  for (int i = 2 * size / 8; i < 4 * size / 8; i++) {
-    VOTE_PATTERN[i] = (i & 0x01) ? i : 0;
-  }
-
-  // For testing VOTE.all (1/2 of these threads will return 0)
-  for (int i = 2 * size / 4; i < 3 * size / 4; i++) {
-    VOTE_PATTERN[i] = (i & 0x01) ? 0 : i;
-  }
-
-  // For testing VOTE.all (all of these threads will return 1)
-  for (int i = 3 * size / 4; i < 4 * size / 4; i++) {
-    VOTE_PATTERN[i] = 0xffffffff;
-  }
-}
-
-int checkErrors1(unsigned int *h_result, int start, int end, int warp_size,
-                 const char *voteType) {
-  int i, sum = 0;
-
-  for (sum = 0, i = start; i < end; i++) {
-    sum += h_result[i];
-  }
-
-  if (sum > 0) {
-    printf("\t<%s>[%d - %d] = ", voteType, start, end - 1);
-
-    for (i = start; i < end; i++) {
-      printf("%d", h_result[i]);
-    }
-
-    printf("%d values FAILED\n", sum);
-  }
-
-  return (sum > 0);
-}
-
-int checkErrors2(unsigned int *h_result, int start, int end, int warp_size,
-                 const char *voteType) {
-  int i, sum = 0;
-
-  for (sum = 0, i = start; i < end; i++) {
-    sum += h_result[i];
-  }
-
-  if (sum != warp_size) {
-    printf("\t<%s>[%d - %d] = ", voteType, start, end - 1);
-
-    for (i = start; i < end; i++) {
-      printf("%d", h_result[i]);
-    }
-
-    printf(" - FAILED\n");
-  }
-
-  return (sum != warp_size);
-}
-
-// Verification code for Kernel #1
-int checkResultsVoteAnyKernel1(unsigned int *h_result, int size,
-                               int warp_size) {
-  int error_count = 0;
-
-  error_count += checkErrors1(h_result, 0, VOTE_DATA_GROUP * warp_size / 4,
-                              warp_size, "Vote.Any");
-  error_count +=
-      checkErrors2(h_result, VOTE_DATA_GROUP * warp_size / 4,
-                   2 * VOTE_DATA_GROUP * warp_size / 4, warp_size, "Vote.Any");
-  error_count +=
-      checkErrors2(h_result, 2 * VOTE_DATA_GROUP * warp_size / 4,
-                   3 * VOTE_DATA_GROUP * warp_size / 4, warp_size, "Vote.Any");
-  error_count +=
-      checkErrors2(h_result, 3 * VOTE_DATA_GROUP * warp_size / 4,
-                   4 * VOTE_DATA_GROUP * warp_size / 4, warp_size, "Vote.Any");
-
-  printf((error_count == 0) ? "\tOK\n" : "\tERROR\n");
-  return error_count;
-}
-
-// Verification code for Kernel #2
-int checkResultsVoteAllKernel2(unsigned int *h_result, int size,
-                               int warp_size) {
-  int error_count = 0;
-
-  error_count += checkErrors1(h_result, 0, VOTE_DATA_GROUP * warp_size / 4,
-                              warp_size, "Vote.All");
-  error_count +=
-      checkErrors1(h_result, VOTE_DATA_GROUP * warp_size / 4,
-                   2 * VOTE_DATA_GROUP * warp_size / 4, warp_size, "Vote.All");
-  error_count +=
-      checkErrors1(h_result, 2 * VOTE_DATA_GROUP * warp_size / 4,
-                   3 * VOTE_DATA_GROUP * warp_size / 4, warp_size, "Vote.All");
-  error_count +=
-      checkErrors2(h_result, 3 * VOTE_DATA_GROUP * warp_size / 4,
-                   4 * VOTE_DATA_GROUP * warp_size / 4, warp_size, "Vote.All");
-
-  printf((error_count == 0) ? "\tOK\n" : "\tERROR\n");
-  return error_count;
-}
-
-// Verification code for Kernel #3
-int checkResultsVoteAnyKernel3(bool *hinfo, int size) {
-  int i, error_count = 0;
-
-  for (i = 0; i < size * 3; i++) {
-    switch (i % 3) {
-      case 0:
-
-        // First warp should be all zeros.
-        if (hinfo[i] != (i >= size * 1)) {
-          error_count++;
-        }
-
-        break;
-
-      case 1:
-
-        // First warp and half of second should be all zeros.
-        if (hinfo[i] != (i >= size * 3 / 2)) {
-          error_count++;
-        }
-
-        break;
-
-      case 2:
-
-        // First two warps should be all zeros.
-        if (hinfo[i] != (i >= size * 2)) {
-          error_count++;
-        }
-
-        break;
-    }
-  }
-
-  printf((error_count == 0) ? "\tOK\n" : "\tERROR\n");
-  return error_count;
-}
-
-int main(int argc, char **argv) {
-  unsigned int *h_input, *h_result;
-  unsigned int *d_input, *d_result;
-
-  bool *dinfo = NULL, *hinfo = NULL;
-  int error_count[3] = {0, 0, 0};
-
-  hipDeviceProp_t deviceProp;
-  int devID, warp_size = 32;
-
-  printf("%s\n", sSDKsample);
-
-  // This will pick the best possible CUDA capable device
-  devID = findCudaDevice(argc, (const char **)argv);
-
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, devID));
-
-  // Statistics about the GPU device
-  printf(
-      "> GPU device has %d Multi-Processors, SM %d.%d compute capabilities\n\n",
-      deviceProp.multiProcessorCount, deviceProp.major, deviceProp.minor);
-
-  h_input = (unsigned int *)malloc(VOTE_DATA_GROUP * warp_size *
-                                   sizeof(unsigned int));
-  h_result = (unsigned int *)malloc(VOTE_DATA_GROUP * warp_size *
-                                    sizeof(unsigned int));
-  HIPCHECK(
-      hipMalloc(reinterpret_cast<void **>(&d_input),
-                 VOTE_DATA_GROUP * warp_size * sizeof(unsigned int)));
-  HIPCHECK(
-      hipMalloc(reinterpret_cast<void **>(&d_result),
-                 VOTE_DATA_GROUP * warp_size * sizeof(unsigned int)));
-  genVoteTestPattern(h_input, VOTE_DATA_GROUP * warp_size);
-  HIPCHECK(hipMemcpy(d_input, h_input,
-                             VOTE_DATA_GROUP * warp_size * sizeof(unsigned int),
-                             hipMemcpyHostToDevice));
-
-  // Start of Vote Any Test Kernel #1
-  printf("[VOTE Kernel Test 1/3]\n");
-  printf("\tRunning <<Vote.Any>> kernel1 ...\n");
-  {
-    HIPCHECK(hipDeviceSynchronize());
-    dim3 gridBlock(1, 1);
-    dim3 threadBlock(VOTE_DATA_GROUP * warp_size, 1);
-    VoteAnyKernel1<<<gridBlock, threadBlock>>>(d_input, d_result,
-                                               VOTE_DATA_GROUP * warp_size);
-    getLastCudaError("VoteAnyKernel() execution failed\n");
-    HIPCHECK(hipDeviceSynchronize());
-  }
-  HIPCHECK(hipMemcpy(h_result, d_result,
-                             VOTE_DATA_GROUP * warp_size * sizeof(unsigned int),
-                             hipMemcpyDeviceToHost));
-  error_count[0] += checkResultsVoteAnyKernel1(
-      h_result, VOTE_DATA_GROUP * warp_size, warp_size);
-
-  // Start of Vote All Test Kernel #2
-  printf("\n[VOTE Kernel Test 2/3]\n");
-  printf("\tRunning <<Vote.All>> kernel2 ...\n");
-  {
-    HIPCHECK(hipDeviceSynchronize());
-    dim3 gridBlock(1, 1);
-    dim3 threadBlock(VOTE_DATA_GROUP * warp_size, 1);
-    VoteAllKernel2<<<gridBlock, threadBlock>>>(d_input, d_result,
-                                               VOTE_DATA_GROUP * warp_size);
-    getLastCudaError("VoteAllKernel() execution failed\n");
-    HIPCHECK(hipDeviceSynchronize());
-  }
-  HIPCHECK(hipMemcpy(h_result, d_result,
-                             VOTE_DATA_GROUP * warp_size * sizeof(unsigned int),
-                             hipMemcpyDeviceToHost));
-  error_count[1] += checkResultsVoteAllKernel2(
-      h_result, VOTE_DATA_GROUP * warp_size, warp_size);
-
-  // Second Vote Kernel Test #3 (both Any/All)
-  hinfo = reinterpret_cast<bool *>(calloc(warp_size * 3 * 3, sizeof(bool)));
-  hipMalloc(reinterpret_cast<void **>(&dinfo),
-             warp_size * 3 * 3 * sizeof(bool));
-  hipMemcpy(dinfo, hinfo, warp_size * 3 * 3 * sizeof(bool),
-             hipMemcpyHostToDevice);
-
-  printf("\n[VOTE Kernel Test 3/3]\n");
-  printf("\tRunning <<Vote.Any>> kernel3 ...\n");
-  {
-    HIPCHECK(hipDeviceSynchronize());
-    VoteAnyKernel3<<<1, warp_size * 3>>>(dinfo, warp_size);
-    HIPCHECK(hipDeviceSynchronize());
-  }
-
-  hipMemcpy(hinfo, dinfo, warp_size * 3 * 3 * sizeof(bool),
-             hipMemcpyDeviceToHost);
-
-  error_count[2] = checkResultsVoteAnyKernel3(hinfo, warp_size * 3);
-
-  // Now free these resources for Test #1,2
-  HIPCHECK(hipFree(d_input));
-  HIPCHECK(hipFree(d_result));
-  free(h_input);
-  free(h_result);
-
-  // Free resources from Test #3
-  free(hinfo);
-  hipFree(dinfo);
-
-  printf("\tShutting down...\n");
-
-  return (error_count[0] == 0 && error_count[1] == 0 && error_count[2] == 0)
-             ? EXIT_SUCCESS
-             : EXIT_FAILURE;
-}
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2017.sln b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2019.sln b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2022.sln b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVoteIntrinsics_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVote_kernel.cuh b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVote_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVote_kernel_hipified.cuh b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics/simpleVote_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/Makefile b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/README.md b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics.cpp b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_hipified.cpp b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2017.sln b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2019.sln b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2022.sln b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVoteIntrinsics_nvrtc_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVote_kernel.cuh b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVote_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVote_kernel_hipified.cuh b/src/samples/Samples/0_Introduction/simpleVoteIntrinsics_nvrtc/simpleVote_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/simpleZeroCopy/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/.vscode/extensions.json b/src/samples/Samples/0_Introduction/simpleZeroCopy/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/.vscode/launch.json b/src/samples/Samples/0_Introduction/simpleZeroCopy/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/.vscode/tasks.json b/src/samples/Samples/0_Introduction/simpleZeroCopy/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/Makefile b/src/samples/Samples/0_Introduction/simpleZeroCopy/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/NsightEclipse.xml b/src/samples/Samples/0_Introduction/simpleZeroCopy/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/README.md b/src/samples/Samples/0_Introduction/simpleZeroCopy/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.cu b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.cu.hip b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.cu.hip
old mode 100644
new mode 100755
index f9fe2da..e6ad156
--- a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.cu.hip
+++ b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.cu.hip
@@ -1,4 +1,4 @@
-#include "hip/hip_runtime.h"
+
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -29,8 +29,6 @@
 // System includes
 #include <assert.h>
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 
 // CUDA runtime
 #include <hip/hip_runtime.h>
@@ -112,15 +110,15 @@ int main(int argc, char **argv) {
   if (bPinGenericMemory) {
     printf("> Using Generic System Paged Memory (malloc)\n");
   } else {
-    printf("> Using CUDA Host Allocated (hipHostAlloc)\n");
+    printf("> Using CUDA Host Allocated (hipHostMalloc)\n");
   }
 
-  HIPCHECK(hipSetDevice(idev));
+  checkCudaErrors(hipSetDevice(idev));
 
   /* Verify the selected device supports mapped memory and set the device
      flags for mapping host memory. */
 
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, idev));
+  checkCudaErrors(hipGetDeviceProperties(&deviceProp, idev));
 
 #if CUDART_VERSION >= 2020
 
@@ -131,12 +129,9 @@ int main(int argc, char **argv) {
     exit(EXIT_SUCCESS);
   }
 
-  HIPCHECK(hipSetDeviceFlags(hipDeviceMapHost));
+  checkCudaErrors(hipSetDeviceFlags(hipDeviceMapHost));
 #else
-  fprintf(stderr,
-          "CUDART version %d.%d does not support "
-          "<hipDeviceProp_t.canMapHostMemory> field\n",
-          , CUDART_VERSION / 1000, (CUDART_VERSION % 100) / 10);
+  fprintf(stderr, "CUDART version %d.%d does not support <hipDeviceProp_t.canMapHostMemory> field\n" , CUDART_VERSION / 1000, (CUDART_VERSION % 100) / 10);
 
   exit(EXIT_SUCCESS);
 #endif
@@ -171,16 +166,16 @@ int main(int argc, char **argv) {
     b = (float *)ALIGN_UP(b_UA, MEMORY_ALIGNMENT);
     c = (float *)ALIGN_UP(c_UA, MEMORY_ALIGNMENT);
 
-    HIPCHECK(hipHostRegister(a, bytes, hipHostRegisterMapped));
-    HIPCHECK(hipHostRegister(b, bytes, hipHostRegisterMapped));
-    HIPCHECK(hipHostRegister(c, bytes, hipHostRegisterMapped));
+    checkCudaErrors(hipHostRegister(a, bytes, hipHostRegisterMapped));
+    checkCudaErrors(hipHostRegister(b, bytes, hipHostRegisterMapped));
+    checkCudaErrors(hipHostRegister(c, bytes, hipHostRegisterMapped));
 #endif
   } else {
 #if CUDART_VERSION >= 2020
     flags = hipHostMallocMapped;
-    HIPCHECK(hipHostAlloc((void **)&a, bytes, flags));
-    HIPCHECK(hipHostAlloc((void **)&b, bytes, flags));
-    HIPCHECK(hipHostAlloc((void **)&c, bytes, flags));
+    checkCudaErrors(hipHostMalloc((void **)&a, bytes, flags));
+    checkCudaErrors(hipHostMalloc((void **)&b, bytes, flags));
+    checkCudaErrors(hipHostMalloc((void **)&c, bytes, flags));
 #endif
   }
 
@@ -195,9 +190,9 @@ int main(int argc, char **argv) {
        memory space. */
 
 #if CUDART_VERSION >= 2020
-  HIPCHECK(hipHostGetDevicePointer((void **)&d_a, (void *)a, 0));
-  HIPCHECK(hipHostGetDevicePointer((void **)&d_b, (void *)b, 0));
-  HIPCHECK(hipHostGetDevicePointer((void **)&d_c, (void *)c, 0));
+  checkCudaErrors(hipHostGetDevicePointer((void **)&d_a, (void *)a, 0));
+  checkCudaErrors(hipHostGetDevicePointer((void **)&d_b, (void *)b, 0));
+  checkCudaErrors(hipHostGetDevicePointer((void **)&d_c, (void *)c, 0));
 #endif
 
   /* Call the GPU kernel using the CPU pointers residing in CPU mapped memory.
@@ -206,7 +201,7 @@ int main(int argc, char **argv) {
   dim3 block(256);
   dim3 grid((unsigned int)ceil(nelem / (float)block.x));
   vectorAddGPU<<<grid, block>>>(d_a, d_b, d_c, nelem);
-  HIPCHECK(hipDeviceSynchronize());
+  checkCudaErrors(hipDeviceSynchronize());
   getLastCudaError("vectorAddGPU() execution failed");
 
   /* Compare the results */
@@ -231,18 +226,18 @@ int main(int argc, char **argv) {
 
   if (bPinGenericMemory) {
 #if CUDART_VERSION >= 4000
-    HIPCHECK(hipHostUnregister(a));
-    HIPCHECK(hipHostUnregister(b));
-    HIPCHECK(hipHostUnregister(c));
+    checkCudaErrors(hipHostUnregister(a));
+    checkCudaErrors(hipHostUnregister(b));
+    checkCudaErrors(hipHostUnregister(c));
     free(a_UA);
     free(b_UA);
     free(c_UA);
 #endif
   } else {
 #if CUDART_VERSION >= 2020
-    HIPCHECK(hipHostFree(a));
-    HIPCHECK(hipHostFree(b));
-    HIPCHECK(hipHostFree(c));
+    checkCudaErrors(hipHostFree(a));
+    checkCudaErrors(hipHostFree(b));
+    checkCudaErrors(hipHostFree(c));
 #endif
   }
 
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.out b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2017.sln b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2017.vcxproj b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2019.sln b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2019.vcxproj b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2022.sln b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2022.vcxproj b/src/samples/Samples/0_Introduction/simpleZeroCopy/simpleZeroCopy_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/systemWideAtomics/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/systemWideAtomics/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/systemWideAtomics/.vscode/extensions.json b/src/samples/Samples/0_Introduction/systemWideAtomics/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/systemWideAtomics/.vscode/launch.json b/src/samples/Samples/0_Introduction/systemWideAtomics/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/systemWideAtomics/.vscode/tasks.json b/src/samples/Samples/0_Introduction/systemWideAtomics/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/systemWideAtomics/Makefile b/src/samples/Samples/0_Introduction/systemWideAtomics/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/systemWideAtomics/NsightEclipse.xml b/src/samples/Samples/0_Introduction/systemWideAtomics/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/systemWideAtomics/README.md b/src/samples/Samples/0_Introduction/systemWideAtomics/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/systemWideAtomics/systemWideAtomics.cu b/src/samples/Samples/0_Introduction/systemWideAtomics/systemWideAtomics.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/systemWideAtomics/systemWideAtomics.cu.hip b/src/samples/Samples/0_Introduction/systemWideAtomics/systemWideAtomics.cu.hip
old mode 100644
new mode 100755
index befac35..e69de29
--- a/src/samples/Samples/0_Introduction/systemWideAtomics/systemWideAtomics.cu.hip
+++ b/src/samples/Samples/0_Introduction/systemWideAtomics/systemWideAtomics.cu.hip
@@ -1,346 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* A program demonstrating trivial use of system-wide atomics on migratable
- * memory.
- */
-
-#include <hip/hip_runtime.h>
-#include "helper_cuda_hipified.h"
-#include <math.h>
-#include <stdint.h>
-#include <cstdio>
-#include <ctime>
-#include "HIPCHECK.h"
-#define min(a, b) (a) < (b) ? (a) : (b)
-#define max(a, b) (a) > (b) ? (a) : (b)
-
-#define LOOP_NUM 50
-
-__global__ void atomicKernel(int *atom_arr) {
-  unsigned int tid = blockDim.x * blockIdx.x + threadIdx.x;
-
-  for (int i = 0; i < LOOP_NUM; i++) {
-    // Atomic addition
-    atomicAdd_system(&atom_arr[0], 10);
-
-    // Atomic exchange
-    atomicExch_system(&atom_arr[1], tid);
-
-    // Atomic maximum
-    atomicMax_system(&atom_arr[2], tid);
-
-    // Atomic minimum
-    atomicMin_system(&atom_arr[3], tid);
-
-    // Atomic increment (modulo 17+1)
-    //atomicInc_system((unsigned int *)&atom_arr[4], 17);
-    atomicInc((unsigned int *)&atom_arr[4], 17);
-
-
-    // Atomic decrement
-    //atomicDec_system((unsigned int *)&atom_arr[5], 137);
-    atomicDec((unsigned int *)&atom_arr[4], 17);
-
-    // Atomic compare-and-swap
-    atomicCAS_system(&atom_arr[6], tid - 1, tid);
-
-    // Bitwise atomic instructions
-
-    // Atomic AND
-    atomicAnd_system(&atom_arr[7], 2 * tid + 7);
-
-    // Atomic OR
-    atomicOr_system(&atom_arr[8], 1 << tid);
-
-    // Atomic XOR
-    atomicXor_system(&atom_arr[9], tid);
-  }
-}
-
-void atomicKernel_CPU(int *atom_arr, int no_of_threads) {
-  for (int i = no_of_threads; i < 2 * no_of_threads; i++) {
-    for (int j = 0; j < LOOP_NUM; j++) {
-      // Atomic addition
-      __sync_fetch_and_add(&atom_arr[0], 10);
-
-      // Atomic exchange
-      __sync_lock_test_and_set(&atom_arr[1], i);
-
-      // Atomic maximum
-      int old, expected;
-      do {
-        expected = atom_arr[2];
-        old = __sync_val_compare_and_swap(&atom_arr[2], expected,
-                                          max(expected, i));
-      } while (old != expected);
-
-      // Atomic minimum
-      do {
-        expected = atom_arr[3];
-        old = __sync_val_compare_and_swap(&atom_arr[3], expected,
-                                          min(expected, i));
-      } while (old != expected);
-
-      // Atomic increment (modulo 17+1)
-      int limit = 17;
-      do {
-        expected = atom_arr[4];
-        old = __sync_val_compare_and_swap(
-            &atom_arr[4], expected, (expected >= limit) ? 0 : expected + 1);
-      } while (old != expected);
-
-      // Atomic decrement
-      limit = 137;
-      do {
-        expected = atom_arr[5];
-        old = __sync_val_compare_and_swap(
-            &atom_arr[5], expected,
-            ((expected == 0) || (expected > limit)) ? limit : expected - 1);
-      } while (old != expected);
-
-      // Atomic compare-and-swap
-      __sync_val_compare_and_swap(&atom_arr[6], i - 1, i);
-
-      // Bitwise atomic instructions
-
-      // Atomic AND
-      __sync_fetch_and_and(&atom_arr[7], 2 * i + 7);
-
-      // Atomic OR
-      __sync_fetch_and_or(&atom_arr[8], 1 << i);
-
-      // Atomic XOR
-      // 11th element should be 0xff
-      __sync_fetch_and_xor(&atom_arr[9], i);
-    }
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Compute reference data set
-//! Each element is multiplied with the number of threads / array length
-//! @param reference  reference data, computed but preallocated
-//! @param idata      input data as provided to device
-//! @param len        number of elements in reference / idata
-////////////////////////////////////////////////////////////////////////////////
-int verify(int *testData, const int len) {
-  int val = 0;
-
-  for (int i = 0; i < len * LOOP_NUM; ++i) {
-    val += 10;
-  }
-
-  if (val != testData[0]) {
-    printf("atomicAdd failed val = %d testData = %d\n", val, testData[0]);
-    return false;
-  }
-
-  val = 0;
-
-  bool found = false;
-
-  for (int i = 0; i < len; ++i) {
-    // second element should be a member of [0, len)
-    if (i == testData[1]) {
-      found = true;
-      break;
-    }
-  }
-
-  if (!found) {
-    printf("atomicExch failed\n");
-    return false;
-  }
-
-  val = -(1 << 8);
-
-  for (int i = 0; i < len; ++i) {
-    // third element should be len-1
-    val = max(val, i);
-  }
-
-  if (val != testData[2]) {
-    printf("atomicMax failed\n");
-    return false;
-  }
-
-  val = 1 << 8;
-
-  for (int i = 0; i < len; ++i) {
-    val = min(val, i);
-  }
-
-  if (val != testData[3]) {
-    printf("atomicMin failed\n");
-    return false;
-  }
-
-  int limit = 17;
-  val = 0;
-
-  for (int i = 0; i < len * LOOP_NUM; ++i) {
-    val = (val >= limit) ? 0 : val + 1;
-  }
-
-  if (val != testData[4]) {
-    printf("atomicInc failed\n");
-    return false;
-  }
-
-  limit = 137;
-  val = 0;
-
-  for (int i = 0; i < len * LOOP_NUM; ++i) {
-    val = ((val == 0) || (val > limit)) ? limit : val - 1;
-  }
-
-  if (val != testData[5]) {
-    printf("atomicDec failed\n");
-    return false;
-  }
-
-  found = false;
-
-  for (int i = 0; i < len; ++i) {
-    // seventh element should be a member of [0, len)
-    if (i == testData[6]) {
-      found = true;
-      break;
-    }
-  }
-
-  if (!found) {
-    printf("atomicCAS failed\n");
-    return false;
-  }
-
-  val = 0xff;
-
-  for (int i = 0; i < len; ++i) {
-    // 8th element should be 1
-    val &= (2 * i + 7);
-  }
-
-  if (val != testData[7]) {
-    printf("atomicAnd failed\n");
-    return false;
-  }
-
-  val = 0;
-
-  for (int i = 0; i < len; ++i) {
-    // 9th element should be 0xff
-    val |= (1 << i);
-  }
-
-  if (val != testData[8]) {
-    printf("atomicOr failed\n");
-    return false;
-  }
-
-  val = 0xff;
-
-  for (int i = 0; i < len; ++i) {
-    // 11th element should be 0xff
-    val ^= i;
-  }
-
-  if (val != testData[9]) {
-    printf("atomicXor failed\n");
-    return false;
-  }
-
-  return true;
-}
-
-int main(int argc, char **argv) {
-  // set device
-  hipDeviceProp_t device_prop;
-  int dev_id = findCudaDevice(argc, (const char **)argv);
-  checkCudaErrors(hipGetDeviceProperties(&device_prop, dev_id));
-
-  if (!device_prop.managedMemory) {
-    // This samples requires being run on a device that supports Unified Memory
-    fprintf(stderr, "Unified Memory not supported on this device\n");
-    exit(EXIT_WAIVED);
-  }
-
-  if (device_prop.computeMode == hipComputeModeProhibited) {
-    // This sample requires being run with a default or process exclusive mode
-    fprintf(stderr,
-            "This sample requires a device in either default or process "
-            "exclusive mode\n");
-    exit(EXIT_WAIVED);
-  }
-
-  if (device_prop.major < 6) {
-    printf(
-        "%s: requires a minimum CUDA compute 6.0 capability, waiving "
-        "testing.\n",
-        argv[0]);
-    exit(EXIT_WAIVED);
-  }
-
-  unsigned int numThreads = 256;
-  unsigned int numBlocks = 64;
-  unsigned int numData = 10;
-
-  int *atom_arr;
-
-  if (device_prop.pageableMemoryAccess) {
-    printf("CAN access pageable memory\n");
-    atom_arr = (int *)malloc(sizeof(int) * numData);
-  } else {
-    printf("CANNOT access pageable memory\n");
-    checkCudaErrors(hipMallocManaged(&atom_arr, sizeof(int) * numData));
-  }
-
-  for (unsigned int i = 0; i < numData; i++) atom_arr[i] = 0;
-
-  // To make the AND and XOR tests generate something other than 0...
-  atom_arr[7] = atom_arr[9] = 0xff;
-
-  atomicKernel<<<numBlocks, numThreads>>>(atom_arr);
-  atomicKernel_CPU(atom_arr, numBlocks * numThreads);
-
-  checkCudaErrors(hipDeviceSynchronize());
-
-  // Compute & verify reference solution
-  int testResult = verify(atom_arr, 2 * numThreads * numBlocks);
-
-  if (device_prop.pageableMemoryAccess) {
-    free(atom_arr);
-  } else {
-    hipFree(atom_arr);
-  }
-
-  printf("systemWideAtomics completed, returned %s \n",
-         testResult ? "OK" : "ERROR!");
-  exit(testResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/0_Introduction/template/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/template/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/.vscode/extensions.json b/src/samples/Samples/0_Introduction/template/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/.vscode/launch.json b/src/samples/Samples/0_Introduction/template/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/.vscode/tasks.json b/src/samples/Samples/0_Introduction/template/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/Makefile b/src/samples/Samples/0_Introduction/template/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/NsightEclipse.xml b/src/samples/Samples/0_Introduction/template/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/README.md b/src/samples/Samples/0_Introduction/template/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/template.cu b/src/samples/Samples/0_Introduction/template/template.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/template.cu.hip b/src/samples/Samples/0_Introduction/template/template.cu.hip
old mode 100644
new mode 100755
index 80217ba..e69de29
--- a/src/samples/Samples/0_Introduction/template/template.cu.hip
+++ b/src/samples/Samples/0_Introduction/template/template.cu.hip
@@ -1,168 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* Template project which demonstrates the basics on how to setup a project
- * example application.
- * Host code.
- */
-
-// includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-
-// includes CUDA
-#include <hip/hip_runtime.h>
-
-// includes, project
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h" // helper functions for SDK examples
-
-////////////////////////////////////////////////////////////////////////////////
-// declaration, forward
-void runTest(int argc, char **argv);
-
-extern "C" void computeGold(float *reference, float *idata,
-                            const unsigned int len);
-
-////////////////////////////////////////////////////////////////////////////////
-//! Simple test kernel for device functionality
-//! @param g_idata  input data in global memory
-//! @param g_odata  output data in global memory
-////////////////////////////////////////////////////////////////////////////////
-__global__ void testKernel(float *g_idata, float *g_odata) {
-  // shared memory
-  // the size is determined by the host application
-  extern __shared__ float sdata[];
-
-  // access thread id
-  const unsigned int tid = threadIdx.x;
-  // access number of threads in this block
-  const unsigned int num_threads = blockDim.x;
-
-  // read in input data from global memory
-  sdata[tid] = g_idata[tid];
-  __syncthreads();
-
-  // perform some computations
-  sdata[tid] = (float)num_threads * sdata[tid];
-  __syncthreads();
-
-  // write data to global memory
-  g_odata[tid] = sdata[tid];
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) { runTest(argc, argv); }
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run a simple test for CUDA
-////////////////////////////////////////////////////////////////////////////////
-void runTest(int argc, char **argv) {
-  bool bTestResult = true;
-
-  printf("%s Starting...\n\n", argv[0]);
-
-  // use command-line specified CUDA device, otherwise use device with highest
-  // Gflops/s
-  int devID = findCudaDevice(argc, (const char **)argv);
-
-  StopWatchInterface *timer = 0;
-  sdkCreateTimer(&timer);
-  sdkStartTimer(&timer);
-
-  unsigned int num_threads = 32;
-  unsigned int mem_size = sizeof(float) * num_threads;
-
-  // allocate host memory
-  float *h_idata = (float *)malloc(mem_size);
-
-  // initalize the memory
-  for (unsigned int i = 0; i < num_threads; ++i) {
-    h_idata[i] = (float)i;
-  }
-
-  // allocate device memory
-  float *d_idata;
-  HIPCHECK(hipMalloc((void **)&d_idata, mem_size));
-  // copy host memory to device
-  HIPCHECK(
-      hipMemcpy(d_idata, h_idata, mem_size, hipMemcpyHostToDevice));
-
-  // allocate device memory for result
-  float *d_odata;
-  HIPCHECK(hipMalloc((void **)&d_odata, mem_size));
-
-  // setup execution parameters
-  dim3 grid(1, 1, 1);
-  dim3 threads(num_threads, 1, 1);
-
-  // execute the kernel
-  testKernel<<<grid, threads, mem_size>>>(d_idata, d_odata);
-
-  // check if kernel execution generated and error
-  getLastCudaError("Kernel execution failed");
-
-  // allocate mem for the result on host side
-  float *h_odata = (float *)malloc(mem_size);
-  // copy result from device to host
-  HIPCHECK(hipMemcpy(h_odata, d_odata, sizeof(float) * num_threads,
-                             hipMemcpyDeviceToHost));
-
-  sdkStopTimer(&timer);
-  printf("Processing time: %f (ms)\n", sdkGetTimerValue(&timer));
-  sdkDeleteTimer(&timer);
-
-  // compute reference solution
-  float *reference = (float *)malloc(mem_size);
-  computeGold(reference, h_idata, num_threads);
-
-  // check result
-  if (checkCmdLineFlag(argc, (const char **)argv, "regression")) {
-    // write file for regression test
-    sdkWriteFile("./data/regression.dat", h_odata, num_threads, 0.0f, false);
-  } else {
-    // custom output handling when no regression test running
-    // in this case check if the result is equivalent to the expected solution
-    bTestResult = compareData(reference, h_odata, num_threads, 0.0f, 0.0f);
-  }
-
-  // cleanup memory
-  free(h_idata);
-  free(h_odata);
-  free(reference);
-  HIPCHECK(hipFree(d_idata));
-  HIPCHECK(hipFree(d_odata));
-
-  exit(bTestResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/0_Introduction/template/template.out b/src/samples/Samples/0_Introduction/template/template.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/template_cpu.cpp b/src/samples/Samples/0_Introduction/template/template_cpu.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/template_cpu_hipified.cpp b/src/samples/Samples/0_Introduction/template/template_cpu_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/template_vs2017.sln b/src/samples/Samples/0_Introduction/template/template_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/template_vs2017.vcxproj b/src/samples/Samples/0_Introduction/template/template_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/template_vs2019.sln b/src/samples/Samples/0_Introduction/template/template_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/template_vs2019.vcxproj b/src/samples/Samples/0_Introduction/template/template_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/template_vs2022.sln b/src/samples/Samples/0_Introduction/template/template_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/template/template_vs2022.vcxproj b/src/samples/Samples/0_Introduction/template/template_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/vectorAdd/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/.vscode/extensions.json b/src/samples/Samples/0_Introduction/vectorAdd/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/.vscode/launch.json b/src/samples/Samples/0_Introduction/vectorAdd/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/.vscode/tasks.json b/src/samples/Samples/0_Introduction/vectorAdd/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/Makefile b/src/samples/Samples/0_Introduction/vectorAdd/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/NsightEclipse.xml b/src/samples/Samples/0_Introduction/vectorAdd/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/README.md b/src/samples/Samples/0_Introduction/vectorAdd/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd.cu b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd.cu.hip b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd.cu.hip
old mode 100644
new mode 100755
index 1c991f7..e69de29
--- a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd.cu.hip
+++ b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd.cu.hip
@@ -1,213 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/**
- * Vector addition: C = A + B.
- *
- * This sample is a very basic sample that implements element by element
- * vector addition. It is the same as the sample illustrating Chapter 2
- * of the programming guide with some additions like error checking.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-
-// For the CUDA runtime routines (prefixed with "cuda_")
-#include <hip/hip_runtime.h>
-
-#include "helper_cuda_hipified.h"
-/**
- * CUDA Kernel Device code
- *
- * Computes the vector addition of A and B into C. The 3 vectors have the same
- * number of elements numElements.
- */
-__global__ void vectorAdd(const float *A, const float *B, float *C,
-                          int numElements) {
-  int i = blockDim.x * blockIdx.x + threadIdx.x;
-
-  if (i < numElements) {
-    C[i] = A[i] + B[i] + 0.0f;
-  }
-}
-
-/**
- * Host main routine
- */
-int main(void) {
-  // Error code to check return values for CUDA calls
-  hipError_t err = hipSuccess;
-
-  // Print the vector length to be used, and compute its size
-  int numElements = 50000;
-  size_t size = numElements * sizeof(float);
-  printf("[Vector addition of %d elements]\n", numElements);
-
-  // Allocate the host input vector A
-  float *h_A = (float *)malloc(size);
-
-  // Allocate the host input vector B
-  float *h_B = (float *)malloc(size);
-
-  // Allocate the host output vector C
-  float *h_C = (float *)malloc(size);
-
-  // Verify that allocations succeeded
-  if (h_A == NULL || h_B == NULL || h_C == NULL) {
-    fprintf(stderr, "Failed to allocate host vectors!\n");
-    exit(EXIT_FAILURE);
-  }
-
-  // Initialize the host input vectors
-  for (int i = 0; i < numElements; ++i) {
-    h_A[i] = rand() / (float)RAND_MAX;
-    h_B[i] = rand() / (float)RAND_MAX;
-  }
-
-  // Allocate the device input vector A
-  float *d_A = NULL;
-  err = hipMalloc((void **)&d_A, size);
-
-  if (err != hipSuccess) {
-    fprintf(stderr, "Failed to allocate device vector A (error code %s)!\n",
-            hipGetErrorString(err));
-    exit(EXIT_FAILURE);
-  }
-
-  // Allocate the device input vector B
-  float *d_B = NULL;
-  err = hipMalloc((void **)&d_B, size);
-
-  if (err != hipSuccess) {
-    fprintf(stderr, "Failed to allocate device vector B (error code %s)!\n",
-            hipGetErrorString(err));
-    exit(EXIT_FAILURE);
-  }
-
-  // Allocate the device output vector C
-  float *d_C = NULL;
-  err = hipMalloc((void **)&d_C, size);
-
-  if (err != hipSuccess) {
-    fprintf(stderr, "Failed to allocate device vector C (error code %s)!\n",
-            hipGetErrorString(err));
-    exit(EXIT_FAILURE);
-  }
-
-  // Copy the host input vectors A and B in host memory to the device input
-  // vectors in
-  // device memory
-  printf("Copy input data from the host memory to the CUDA device\n");
-  err = hipMemcpy(d_A, h_A, size, hipMemcpyHostToDevice);
-
-  if (err != hipSuccess) {
-    fprintf(stderr,
-            "Failed to copy vector A from host to device (error code %s)!\n",
-            hipGetErrorString(err));
-    exit(EXIT_FAILURE);
-  }
-
-  err = hipMemcpy(d_B, h_B, size, hipMemcpyHostToDevice);
-
-  if (err != hipSuccess) {
-    fprintf(stderr,
-            "Failed to copy vector B from host to device (error code %s)!\n",
-            hipGetErrorString(err));
-    exit(EXIT_FAILURE);
-  }
-
-  // Launch the Vector Add CUDA Kernel
-  int threadsPerBlock = 256;
-  int blocksPerGrid = (numElements + threadsPerBlock - 1) / threadsPerBlock;
-  printf("CUDA kernel launch with %d blocks of %d threads\n", blocksPerGrid,
-         threadsPerBlock);
-  vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, numElements);
-  err = hipGetLastError();
-
-  if (err != hipSuccess) {
-    fprintf(stderr, "Failed to launch vectorAdd kernel (error code %s)!\n",
-            hipGetErrorString(err));
-    exit(EXIT_FAILURE);
-  }
-
-  // Copy the device result vector in device memory to the host result vector
-  // in host memory.
-  printf("Copy output data from the CUDA device to the host memory\n");
-  err = hipMemcpy(h_C, d_C, size, hipMemcpyDeviceToHost);
-
-  if (err != hipSuccess) {
-    fprintf(stderr,
-            "Failed to copy vector C from device to host (error code %s)!\n",
-            hipGetErrorString(err));
-    exit(EXIT_FAILURE);
-  }
-
-  // Verify that the result vector is correct
-  for (int i = 0; i < numElements; ++i) {
-    if (fabs(h_A[i] + h_B[i] - h_C[i]) > 1e-5) {
-      fprintf(stderr, "Result verification failed at element %d!\n", i);
-      exit(EXIT_FAILURE);
-    }
-  }
-
-  printf("Test PASSED\n");
-
-  // Free device global memory
-  err = hipFree(d_A);
-
-  if (err != hipSuccess) {
-    fprintf(stderr, "Failed to free device vector A (error code %s)!\n",
-            hipGetErrorString(err));
-    exit(EXIT_FAILURE);
-  }
-
-  err = hipFree(d_B);
-
-  if (err != hipSuccess) {
-    fprintf(stderr, "Failed to free device vector B (error code %s)!\n",
-            hipGetErrorString(err));
-    exit(EXIT_FAILURE);
-  }
-
-  err = hipFree(d_C);
-
-  if (err != hipSuccess) {
-    fprintf(stderr, "Failed to free device vector C (error code %s)!\n",
-            hipGetErrorString(err));
-    exit(EXIT_FAILURE);
-  }
-
-  // Free host memory
-  free(h_A);
-  free(h_B);
-  free(h_C);
-
-  printf("Done\n");
-  return 0;
-}
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd.out b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2017.sln b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2017.vcxproj b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2019.sln b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2019.vcxproj b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2022.sln b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2022.vcxproj b/src/samples/Samples/0_Introduction/vectorAdd/vectorAdd_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/vectorAddDrv/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/.vscode/extensions.json b/src/samples/Samples/0_Introduction/vectorAddDrv/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/.vscode/launch.json b/src/samples/Samples/0_Introduction/vectorAddDrv/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/.vscode/tasks.json b/src/samples/Samples/0_Introduction/vectorAddDrv/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/Makefile b/src/samples/Samples/0_Introduction/vectorAddDrv/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/README.md b/src/samples/Samples/0_Introduction/vectorAddDrv/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv.cpp b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_hipified.cpp b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2017.sln b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2017.vcxproj b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2019.sln b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2019.vcxproj b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2022.sln b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2022.vcxproj b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAddDrv_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAdd_kernel.cu b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAdd_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAdd_kernel.cu.hip b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAdd_kernel.cu.hip
old mode 100644
new mode 100755
index 8c2afb9..e69de29
--- a/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAdd_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/vectorAddDrv/vectorAdd_kernel.cu.hip
@@ -1,42 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-/* Vector addition: C = A + B.
- *
- * This sample is a very basic sample that implements element by element
- * vector addition. It is the same as the sample illustrating Chapter 3
- * of the programming guide with some additions like error checking.
- *
- */
-
-// Device code
-extern "C" __global__ void VecAdd_kernel(const float *A, const float *B,
-                                         float *C, int N) {
-  int i = blockDim.x * blockIdx.x + threadIdx.x;
-
-  if (i < N) C[i] = A[i] + B[i];
-}
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/vectorAddMMAP/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/.vscode/extensions.json b/src/samples/Samples/0_Introduction/vectorAddMMAP/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/.vscode/launch.json b/src/samples/Samples/0_Introduction/vectorAddMMAP/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/.vscode/tasks.json b/src/samples/Samples/0_Introduction/vectorAddMMAP/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/Makefile b/src/samples/Samples/0_Introduction/vectorAddMMAP/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/README.md b/src/samples/Samples/0_Introduction/vectorAddMMAP/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/multidevicealloc_memmap.cpp b/src/samples/Samples/0_Introduction/vectorAddMMAP/multidevicealloc_memmap.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/multidevicealloc_memmap.hpp b/src/samples/Samples/0_Introduction/vectorAddMMAP/multidevicealloc_memmap.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/multidevicealloc_memmap_hipified.cpp b/src/samples/Samples/0_Introduction/vectorAddMMAP/multidevicealloc_memmap_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP.cpp b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_hipified.cpp b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2017.sln b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2017.vcxproj b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2019.sln b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2019.vcxproj b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2022.sln b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2022.vcxproj b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAddMMAP_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAdd_kernel.cu b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAdd_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAdd_kernel.cu.hip b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAdd_kernel.cu.hip
old mode 100644
new mode 100755
index 72e20f6..e69de29
--- a/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAdd_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/vectorAddMMAP/vectorAdd_kernel.cu.hip
@@ -1,43 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* Vector addition: C = A + B.
- *
- * This sample is a very basic sample that implements element by element
- * vector addition. It is the same as the sample illustrating Chapter 3
- * of the programming guide with some additions like error checking.
- *
- */
-
-// Device code
-extern "C" __global__ void VecAdd_kernel(const float *A, const float *B,
-                                         float *C, int N) {
-  int i = blockDim.x * blockIdx.x + threadIdx.x;
-
-  if (i < N) C[i] = A[i] + B[i];
-}
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/.vscode/c_cpp_properties.json b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/.vscode/extensions.json b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/.vscode/launch.json b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/.vscode/tasks.json b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/Makefile b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/README.md b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd.cpp b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_hipified.cpp b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_kernel.cu b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_kernel.cu.hip b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_kernel.cu.hip
old mode 100644
new mode 100755
index bb459dd..e69de29
--- a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_kernel.cu.hip
+++ b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_kernel.cu.hip
@@ -1,43 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/**
- * CUDA Kernel Device code
- *
- * Computes the vector addition of A and B into C. The 3 vectors have the same
- * number of elements numElements.
- */
-
-extern "C" __global__ void vectorAdd(const float *A, const float *B, float *C,
-                                     int numElements) {
-  int i = blockDim.x * blockIdx.x + threadIdx.x;
-
-  if (i < numElements) {
-    C[i] = A[i] + B[i];
-  }
-}
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2017.sln b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2017.vcxproj b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2019.sln b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2019.vcxproj b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2022.sln b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2022.vcxproj b/src/samples/Samples/0_Introduction/vectorAdd_nvrtc/vectorAdd_nvrtc_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/README.md b/src/samples/Samples/1_Utilities/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/.vscode/c_cpp_properties.json b/src/samples/Samples/1_Utilities/bandwidthTest/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/.vscode/extensions.json b/src/samples/Samples/1_Utilities/bandwidthTest/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/.vscode/launch.json b/src/samples/Samples/1_Utilities/bandwidthTest/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/.vscode/tasks.json b/src/samples/Samples/1_Utilities/bandwidthTest/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/Makefile b/src/samples/Samples/1_Utilities/bandwidthTest/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/NsightEclipse.xml b/src/samples/Samples/1_Utilities/bandwidthTest/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/README.md b/src/samples/Samples/1_Utilities/bandwidthTest/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.cu b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.cu.hip b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.cu.hip
old mode 100644
new mode 100755
index b17ae07..e69de29
--- a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.cu.hip
+++ b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.cu.hip
@@ -1,969 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This is a simple test program to measure the memcopy bandwidth of the GPU.
- * It can measure device to device copy bandwidth, host to device copy bandwidth
- * for pageable and pinned memory, and device to host copy bandwidth for
- * pageable and pinned memory.
- *
- * Usage:
- * ./bandwidthTest [option]...
- */
-
-// CUDA runtime
-#include <hip/hip_runtime.h>
-
-// includes
-#include "helper_cuda_hipified.h"  // helper functions for CUDA error checking and initialization
-#include "helper_functions.h"  // helper for shared functions common to CUDA Samples
-
-#include <hip/hip_runtime.h>
-
-#include <cassert>
-#include <iostream>
-#include <memory>
-#include "HIPCHECK.h"
-static const char *sSDKsample = "CUDA Bandwidth Test";
-
-// defines, project
-#define MEMCOPY_ITERATIONS 100
-#define DEFAULT_SIZE (32 * (1e6))      // 32 M
-#define DEFAULT_INCREMENT (4 * (1e6))  // 4 M
-#define CACHE_CLEAR_SIZE (16 * (1e6))  // 16 M
-
-// shmoo mode defines
-#define SHMOO_MEMSIZE_MAX (64 * (1e6))       // 64 M
-#define SHMOO_MEMSIZE_START (1e3)            // 1 KB
-#define SHMOO_INCREMENT_1KB (1e3)            // 1 KB
-#define SHMOO_INCREMENT_2KB (2 * 1e3)        // 2 KB
-#define SHMOO_INCREMENT_10KB (10 * (1e3))    // 10KB
-#define SHMOO_INCREMENT_100KB (100 * (1e3))  // 100 KB
-#define SHMOO_INCREMENT_1MB (1e6)            // 1 MB
-#define SHMOO_INCREMENT_2MB (2 * 1e6)        // 2 MB
-#define SHMOO_INCREMENT_4MB (4 * 1e6)        // 4 MB
-#define SHMOO_LIMIT_20KB (20 * (1e3))        // 20 KB
-#define SHMOO_LIMIT_50KB (50 * (1e3))        // 50 KB
-#define SHMOO_LIMIT_100KB (100 * (1e3))      // 100 KB
-#define SHMOO_LIMIT_1MB (1e6)                // 1 MB
-#define SHMOO_LIMIT_16MB (16 * 1e6)          // 16 MB
-#define SHMOO_LIMIT_32MB (32 * 1e6)          // 32 MB
-
-// CPU cache flush
-#define FLUSH_SIZE (256 * 1024 * 1024)
-char *flush_buf;
-
-// enums, project
-enum testMode { QUICK_MODE, RANGE_MODE, SHMOO_MODE };
-enum memcpyKind { DEVICE_TO_HOST, HOST_TO_DEVICE, DEVICE_TO_DEVICE };
-enum printMode { USER_READABLE, CSV };
-enum memoryMode { PINNED, PAGEABLE };
-
-const char *sMemoryCopyKind[] = {"Device to Host", "Host to Device",
-                                 "Device to Device", NULL};
-
-const char *sMemoryMode[] = {"PINNED", "PAGEABLE", NULL};
-
-// if true, use CPU based timing for everything
-static bool bDontUseGPUTiming;
-
-int *pArgc = NULL;
-char **pArgv = NULL;
-
-////////////////////////////////////////////////////////////////////////////////
-// declaration, forward
-int runTest(const int argc, const char **argv);
-void testBandwidth(unsigned int start, unsigned int end, unsigned int increment,
-                   testMode mode, memcpyKind kind, printMode printmode,
-                   memoryMode memMode, int startDevice, int endDevice, bool wc);
-void testBandwidthQuick(unsigned int size, memcpyKind kind, printMode printmode,
-                        memoryMode memMode, int startDevice, int endDevice,
-                        bool wc);
-void testBandwidthRange(unsigned int start, unsigned int end,
-                        unsigned int increment, memcpyKind kind,
-                        printMode printmode, memoryMode memMode,
-                        int startDevice, int endDevice, bool wc);
-void testBandwidthShmoo(memcpyKind kind, printMode printmode,
-                        memoryMode memMode, int startDevice, int endDevice,
-                        bool wc);
-float testDeviceToHostTransfer(unsigned int memSize, memoryMode memMode,
-                               bool wc);
-float testHostToDeviceTransfer(unsigned int memSize, memoryMode memMode,
-                               bool wc);
-float testDeviceToDeviceTransfer(unsigned int memSize);
-void printResultsReadable(unsigned int *memSizes, double *bandwidths,
-                          unsigned int count, memcpyKind kind,
-                          memoryMode memMode, int iNumDevs, bool wc);
-void printResultsCSV(unsigned int *memSizes, double *bandwidths,
-                     unsigned int count, memcpyKind kind, memoryMode memMode,
-                     int iNumDevs, bool wc);
-void printHelp(void);
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  pArgc = &argc;
-  pArgv = argv;
-
-  flush_buf = (char *)malloc(FLUSH_SIZE);
-
-  // set logfile name and start logs
-  printf("[%s] - Starting...\n", sSDKsample);
-
-  int iRetVal = runTest(argc, (const char **)argv);
-
-  if (iRetVal < 0) {
-    HIPCHECK(hipSetDevice(0));
-  }
-
-  // finish
-  printf("%s\n", (iRetVal == 0) ? "Result = PASS" : "Result = FAIL");
-
-  printf(
-      "\nNOTE: The CUDA Samples are not meant for performance measurements. "
-      "Results may vary when GPU Boost is enabled.\n");
-
-  free(flush_buf);
-
-  exit((iRetVal == 0) ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-
-///////////////////////////////////////////////////////////////////////////////
-// Parse args, run the appropriate tests
-///////////////////////////////////////////////////////////////////////////////
-int runTest(const int argc, const char **argv) {
-  int start = DEFAULT_SIZE;
-  int end = DEFAULT_SIZE;
-  int startDevice = 0;
-  int endDevice = 0;
-  int increment = DEFAULT_INCREMENT;
-  testMode mode = QUICK_MODE;
-  bool htod = false;
-  bool dtoh = false;
-  bool dtod = false;
-  bool wc = false;
-  char *modeStr;
-  char *device = NULL;
-  printMode printmode = USER_READABLE;
-  char *memModeStr = NULL;
-  memoryMode memMode = PINNED;
-
-  // process command line args
-  if (checkCmdLineFlag(argc, argv, "help")) {
-    printHelp();
-    return 0;
-  }
-
-  if (checkCmdLineFlag(argc, argv, "csv")) {
-    printmode = CSV;
-  }
-
-  if (getCmdLineArgumentString(argc, argv, "memory", &memModeStr)) {
-    if (strcmp(memModeStr, "pageable") == 0) {
-      memMode = PAGEABLE;
-    } else if (strcmp(memModeStr, "pinned") == 0) {
-      memMode = PINNED;
-    } else {
-      printf("Invalid memory mode - valid modes are pageable or pinned\n");
-      printf("See --help for more information\n");
-      return -1000;
-    }
-  } else {
-    // default - pinned memory
-    memMode = PINNED;
-  }
-
-  if (getCmdLineArgumentString(argc, argv, "device", &device)) {
-    int deviceCount;
-    hipError_t error_id = hipGetDeviceCount(&deviceCount);
-
-    if (error_id != hipSuccess) {
-      printf("hipGetDeviceCount returned %d\n-> %s\n", (int)error_id,
-             hipGetErrorString(error_id));
-      exit(EXIT_FAILURE);
-    }
-
-    if (deviceCount == 0) {
-      printf("!!!!!No devices found!!!!!\n");
-      return -2000;
-    }
-
-    if (strcmp(device, "all") == 0) {
-      printf(
-          "\n!!!!!Cumulative Bandwidth to be computed from all the devices "
-          "!!!!!!\n\n");
-      startDevice = 0;
-      endDevice = deviceCount - 1;
-    } else {
-      startDevice = endDevice = atoi(device);
-
-      if (startDevice >= deviceCount || startDevice < 0) {
-        printf(
-            "\n!!!!!Invalid GPU number %d given hence default gpu %d will be "
-            "used !!!!!\n",
-            startDevice, 0);
-        startDevice = endDevice = 0;
-      }
-    }
-  }
-
-  printf("Running on...\n\n");
-
-  for (int currentDevice = startDevice; currentDevice <= endDevice;
-       currentDevice++) {
-    hipDeviceProp_t deviceProp;
-    hipError_t error_id = hipGetDeviceProperties(&deviceProp, currentDevice);
-
-    if (error_id == hipSuccess) {
-      printf(" Device %d: %s\n", currentDevice, deviceProp.name);
-
-      if (deviceProp.computeMode == hipComputeModeProhibited) {
-        fprintf(stderr,
-                "Error: device is running in <Compute Mode Prohibited>, no "
-                "threads can use ::hipSetDevice().\n");
-        HIPCHECK(hipSetDevice(currentDevice));
-
-        exit(EXIT_FAILURE);
-      }
-    } else {
-      printf("hipGetDeviceProperties returned %d\n-> %s\n", (int)error_id,
-             hipGetErrorString(error_id));
-      HIPCHECK(hipSetDevice(currentDevice));
-
-      exit(EXIT_FAILURE);
-    }
-  }
-
-  if (getCmdLineArgumentString(argc, argv, "mode", &modeStr)) {
-    // figure out the mode
-    if (strcmp(modeStr, "quick") == 0) {
-      printf(" Quick Mode\n\n");
-      mode = QUICK_MODE;
-    } else if (strcmp(modeStr, "shmoo") == 0) {
-      printf(" Shmoo Mode\n\n");
-      mode = SHMOO_MODE;
-    } else if (strcmp(modeStr, "range") == 0) {
-      printf(" Range Mode\n\n");
-      mode = RANGE_MODE;
-    } else {
-      printf("Invalid mode - valid modes are quick, range, or shmoo\n");
-      printf("See --help for more information\n");
-      return -3000;
-    }
-  } else {
-    // default mode - quick
-    printf(" Quick Mode\n\n");
-    mode = QUICK_MODE;
-  }
-
-  if (checkCmdLineFlag(argc, argv, "htod")) {
-    htod = true;
-  }
-
-  if (checkCmdLineFlag(argc, argv, "dtoh")) {
-    dtoh = true;
-  }
-
-  if (checkCmdLineFlag(argc, argv, "dtod")) {
-    dtod = true;
-  }
-
-#if CUDART_VERSION >= 2020
-
-  if (checkCmdLineFlag(argc, argv, "wc")) {
-    wc = true;
-  }
-
-#endif
-
-  if (checkCmdLineFlag(argc, argv, "cputiming")) {
-    bDontUseGPUTiming = true;
-  }
-
-  if (!htod && !dtoh && !dtod) {
-    // default:  All
-    htod = true;
-    dtoh = true;
-    dtod = true;
-  }
-
-  if (RANGE_MODE == mode) {
-    if (checkCmdLineFlag(argc, (const char **)argv, "start")) {
-      start = getCmdLineArgumentInt(argc, argv, "start");
-
-      if (start <= 0) {
-        printf("Illegal argument - start must be greater than zero\n");
-        return -4000;
-      }
-    } else {
-      printf("Must specify a starting size in range mode\n");
-      printf("See --help for more information\n");
-      return -5000;
-    }
-
-    if (checkCmdLineFlag(argc, (const char **)argv, "end")) {
-      end = getCmdLineArgumentInt(argc, argv, "end");
-
-      if (end <= 0) {
-        printf("Illegal argument - end must be greater than zero\n");
-        return -6000;
-      }
-
-      if (start > end) {
-        printf("Illegal argument - start is greater than end\n");
-        return -7000;
-      }
-    } else {
-      printf("Must specify an end size in range mode.\n");
-      printf("See --help for more information\n");
-      return -8000;
-    }
-
-    if (checkCmdLineFlag(argc, argv, "increment")) {
-      increment = getCmdLineArgumentInt(argc, argv, "increment");
-
-      if (increment <= 0) {
-        printf("Illegal argument - increment must be greater than zero\n");
-        return -9000;
-      }
-    } else {
-      printf("Must specify an increment in user mode\n");
-      printf("See --help for more information\n");
-      return -10000;
-    }
-  }
-
-  if (htod) {
-    testBandwidth((unsigned int)start, (unsigned int)end,
-                  (unsigned int)increment, mode, HOST_TO_DEVICE, printmode,
-                  memMode, startDevice, endDevice, wc);
-  }
-
-  if (dtoh) {
-    testBandwidth((unsigned int)start, (unsigned int)end,
-                  (unsigned int)increment, mode, DEVICE_TO_HOST, printmode,
-                  memMode, startDevice, endDevice, wc);
-  }
-
-  if (dtod) {
-    testBandwidth((unsigned int)start, (unsigned int)end,
-                  (unsigned int)increment, mode, DEVICE_TO_DEVICE, printmode,
-                  memMode, startDevice, endDevice, wc);
-  }
-
-  // Ensure that we reset all CUDA Devices in question
-  for (int nDevice = startDevice; nDevice <= endDevice; nDevice++) {
-    hipSetDevice(nDevice);
-  }
-
-  return 0;
-}
-
-///////////////////////////////////////////////////////////////////////////////
-//  Run a bandwidth test
-///////////////////////////////////////////////////////////////////////////////
-void testBandwidth(unsigned int start, unsigned int end, unsigned int increment,
-                   testMode mode, memcpyKind kind, printMode printmode,
-                   memoryMode memMode, int startDevice, int endDevice,
-                   bool wc) {
-  switch (mode) {
-    case QUICK_MODE:
-      testBandwidthQuick(DEFAULT_SIZE, kind, printmode, memMode, startDevice,
-                         endDevice, wc);
-      break;
-
-    case RANGE_MODE:
-      testBandwidthRange(start, end, increment, kind, printmode, memMode,
-                         startDevice, endDevice, wc);
-      break;
-
-    case SHMOO_MODE:
-      testBandwidthShmoo(kind, printmode, memMode, startDevice, endDevice, wc);
-      break;
-
-    default:
-      break;
-  }
-}
-
-//////////////////////////////////////////////////////////////////////
-//  Run a quick mode bandwidth test
-//////////////////////////////////////////////////////////////////////
-void testBandwidthQuick(unsigned int size, memcpyKind kind, printMode printmode,
-                        memoryMode memMode, int startDevice, int endDevice,
-                        bool wc) {
-  testBandwidthRange(size, size, DEFAULT_INCREMENT, kind, printmode, memMode,
-                     startDevice, endDevice, wc);
-}
-
-///////////////////////////////////////////////////////////////////////
-//  Run a range mode bandwidth test
-//////////////////////////////////////////////////////////////////////
-void testBandwidthRange(unsigned int start, unsigned int end,
-                        unsigned int increment, memcpyKind kind,
-                        printMode printmode, memoryMode memMode,
-                        int startDevice, int endDevice, bool wc) {
-  // count the number of copies we're going to run
-  unsigned int count = 1 + ((end - start) / increment);
-
-  unsigned int *memSizes = (unsigned int *)malloc(count * sizeof(unsigned int));
-  double *bandwidths = (double *)malloc(count * sizeof(double));
-
-  // Before calculating the cumulative bandwidth, initialize bandwidths array to
-  // NULL
-  for (unsigned int i = 0; i < count; i++) {
-    bandwidths[i] = 0.0;
-  }
-
-  // Use the device asked by the user
-  for (int currentDevice = startDevice; currentDevice <= endDevice;
-       currentDevice++) {
-    hipSetDevice(currentDevice);
-
-    // run each of the copies
-    for (unsigned int i = 0; i < count; i++) {
-      memSizes[i] = start + i * increment;
-
-      switch (kind) {
-        case DEVICE_TO_HOST:
-          bandwidths[i] += testDeviceToHostTransfer(memSizes[i], memMode, wc);
-          break;
-
-        case HOST_TO_DEVICE:
-          bandwidths[i] += testHostToDeviceTransfer(memSizes[i], memMode, wc);
-          break;
-
-        case DEVICE_TO_DEVICE:
-          bandwidths[i] += testDeviceToDeviceTransfer(memSizes[i]);
-          break;
-      }
-    }
-  }  // Complete the bandwidth computation on all the devices
-
-  // print results
-  if (printmode == CSV) {
-    printResultsCSV(memSizes, bandwidths, count, kind, memMode,
-                    (1 + endDevice - startDevice), wc);
-  } else {
-    printResultsReadable(memSizes, bandwidths, count, kind, memMode,
-                         (1 + endDevice - startDevice), wc);
-  }
-
-  // clean up
-  free(memSizes);
-  free(bandwidths);
-}
-
-//////////////////////////////////////////////////////////////////////////////
-// Intense shmoo mode - covers a large range of values with varying increments
-//////////////////////////////////////////////////////////////////////////////
-void testBandwidthShmoo(memcpyKind kind, printMode printmode,
-                        memoryMode memMode, int startDevice, int endDevice,
-                        bool wc) {
-  // count the number of copies to make
-  unsigned int count =
-      1 + (SHMOO_LIMIT_20KB / SHMOO_INCREMENT_1KB) +
-      ((SHMOO_LIMIT_50KB - SHMOO_LIMIT_20KB) / SHMOO_INCREMENT_2KB) +
-      ((SHMOO_LIMIT_100KB - SHMOO_LIMIT_50KB) / SHMOO_INCREMENT_10KB) +
-      ((SHMOO_LIMIT_1MB - SHMOO_LIMIT_100KB) / SHMOO_INCREMENT_100KB) +
-      ((SHMOO_LIMIT_16MB - SHMOO_LIMIT_1MB) / SHMOO_INCREMENT_1MB) +
-      ((SHMOO_LIMIT_32MB - SHMOO_LIMIT_16MB) / SHMOO_INCREMENT_2MB) +
-      ((SHMOO_MEMSIZE_MAX - SHMOO_LIMIT_32MB) / SHMOO_INCREMENT_4MB);
-
-  unsigned int *memSizes = (unsigned int *)malloc(count * sizeof(unsigned int));
-  double *bandwidths = (double *)malloc(count * sizeof(double));
-
-  // Before calculating the cumulative bandwidth, initialize bandwidths array to
-  // NULL
-  for (unsigned int i = 0; i < count; i++) {
-    bandwidths[i] = 0.0;
-  }
-
-  // Use the device asked by the user
-  for (int currentDevice = startDevice; currentDevice <= endDevice;
-       currentDevice++) {
-    hipSetDevice(currentDevice);
-    // Run the shmoo
-    int iteration = 0;
-    unsigned int memSize = 0;
-
-    while (memSize <= SHMOO_MEMSIZE_MAX) {
-      if (memSize < SHMOO_LIMIT_20KB) {
-        memSize += SHMOO_INCREMENT_1KB;
-      } else if (memSize < SHMOO_LIMIT_50KB) {
-        memSize += SHMOO_INCREMENT_2KB;
-      } else if (memSize < SHMOO_LIMIT_100KB) {
-        memSize += SHMOO_INCREMENT_10KB;
-      } else if (memSize < SHMOO_LIMIT_1MB) {
-        memSize += SHMOO_INCREMENT_100KB;
-      } else if (memSize < SHMOO_LIMIT_16MB) {
-        memSize += SHMOO_INCREMENT_1MB;
-      } else if (memSize < SHMOO_LIMIT_32MB) {
-        memSize += SHMOO_INCREMENT_2MB;
-      } else {
-        memSize += SHMOO_INCREMENT_4MB;
-      }
-
-      memSizes[iteration] = memSize;
-
-      switch (kind) {
-        case DEVICE_TO_HOST:
-          bandwidths[iteration] +=
-              testDeviceToHostTransfer(memSizes[iteration], memMode, wc);
-          break;
-
-        case HOST_TO_DEVICE:
-          bandwidths[iteration] +=
-              testHostToDeviceTransfer(memSizes[iteration], memMode, wc);
-          break;
-
-        case DEVICE_TO_DEVICE:
-          bandwidths[iteration] +=
-              testDeviceToDeviceTransfer(memSizes[iteration]);
-          break;
-      }
-
-      iteration++;
-      printf(".");
-      fflush(0);
-    }
-  }  // Complete the bandwidth computation on all the devices
-
-  // print results
-  printf("\n");
-
-  if (CSV == printmode) {
-    printResultsCSV(memSizes, bandwidths, count, kind, memMode,
-                    (1 + endDevice - startDevice), wc);
-  } else {
-    printResultsReadable(memSizes, bandwidths, count, kind, memMode,
-                         (1 + endDevice - startDevice), wc);
-  }
-
-  // clean up
-  free(memSizes);
-  free(bandwidths);
-}
-
-///////////////////////////////////////////////////////////////////////////////
-//  test the bandwidth of a device to host memcopy of a specific size
-///////////////////////////////////////////////////////////////////////////////
-float testDeviceToHostTransfer(unsigned int memSize, memoryMode memMode,
-                               bool wc) {
-  StopWatchInterface *timer = NULL;
-  float elapsedTimeInMs = 0.0f;
-  float bandwidthInGBs = 0.0f;
-  unsigned char *h_idata = NULL;
-  unsigned char *h_odata = NULL;
-  hipEvent_t start, stop;
-
-  sdkCreateTimer(&timer);
-  HIPCHECK(hipEventCreate(&start));
-  HIPCHECK(hipEventCreate(&stop));
-
-  // allocate host memory
-  if (PINNED == memMode) {
-  // pinned memory mode - use special function to get OS-pinned memory
-#if CUDART_VERSION >= 2020
-    HIPCHECK(hipHostAlloc((void **)&h_idata, memSize,
-                                  (wc) ? hipHostMallocWriteCombined : 0));
-    HIPCHECK(hipHostAlloc((void **)&h_odata, memSize,
-                                  (wc) ? hipHostMallocWriteCombined : 0));
-#else
-    HIPCHECK(hipHostMalloc((void **)&h_idata, memSize));
-    HIPCHECK(hipHostMalloc((void **)&h_odata, memSize));
-#endif
-  } else {
-    // pageable memory mode - use malloc
-    h_idata = (unsigned char *)malloc(memSize);
-    h_odata = (unsigned char *)malloc(memSize);
-
-    if (h_idata == 0 || h_odata == 0) {
-      fprintf(stderr, "Not enough memory avaialable on host to run test!\n");
-      exit(EXIT_FAILURE);
-    }
-  }
-
-  // initialize the memory
-  for (unsigned int i = 0; i < memSize / sizeof(unsigned char); i++) {
-    h_idata[i] = (unsigned char)(i & 0xff);
-  }
-
-  // allocate device memory
-  unsigned char *d_idata;
-  HIPCHECK(hipMalloc((void **)&d_idata, memSize));
-
-  // initialize the device memory
-  HIPCHECK(
-      hipMemcpy(d_idata, h_idata, memSize, hipMemcpyHostToDevice));
-
-  // copy data from GPU to Host
-  if (PINNED == memMode) {
-    if (bDontUseGPUTiming) sdkStartTimer(&timer);
-    HIPCHECK(hipEventRecord(start, 0));
-    for (unsigned int i = 0; i < MEMCOPY_ITERATIONS; i++) {
-      HIPCHECK(hipMemcpyAsync(h_odata, d_idata, memSize,
-                                      hipMemcpyDeviceToHost, 0));
-    }
-    HIPCHECK(hipEventRecord(stop, 0));
-    HIPCHECK(hipDeviceSynchronize());
-    HIPCHECK(hipEventElapsedTime(&elapsedTimeInMs, start, stop));
-    if (bDontUseGPUTiming) {
-      sdkStopTimer(&timer);
-      elapsedTimeInMs = sdkGetTimerValue(&timer);
-      sdkResetTimer(&timer);
-    }
-  } else {
-    elapsedTimeInMs = 0;
-    for (unsigned int i = 0; i < MEMCOPY_ITERATIONS; i++) {
-      sdkStartTimer(&timer);
-      HIPCHECK(
-          hipMemcpy(h_odata, d_idata, memSize, hipMemcpyDeviceToHost));
-      sdkStopTimer(&timer);
-      elapsedTimeInMs += sdkGetTimerValue(&timer);
-      sdkResetTimer(&timer);
-      memset(flush_buf, i, FLUSH_SIZE);
-    }
-  }
-
-  // calculate bandwidth in GB/s
-  double time_s = elapsedTimeInMs / 1e3;
-  bandwidthInGBs = (memSize * (float)MEMCOPY_ITERATIONS) / (double)1e9;
-  bandwidthInGBs = bandwidthInGBs / time_s;
-  // clean up memory
-  HIPCHECK(hipEventDestroy(stop));
-  HIPCHECK(hipEventDestroy(start));
-  sdkDeleteTimer(&timer);
-
-  if (PINNED == memMode) {
-    HIPCHECK(hipHostFree(h_idata));
-    HIPCHECK(hipHostFree(h_odata));
-  } else {
-    free(h_idata);
-    free(h_odata);
-  }
-
-  HIPCHECK(hipFree(d_idata));
-
-  return bandwidthInGBs;
-}
-
-///////////////////////////////////////////////////////////////////////////////
-//! test the bandwidth of a host to device memcopy of a specific size
-///////////////////////////////////////////////////////////////////////////////
-float testHostToDeviceTransfer(unsigned int memSize, memoryMode memMode,
-                               bool wc) {
-  StopWatchInterface *timer = NULL;
-  float elapsedTimeInMs = 0.0f;
-  float bandwidthInGBs = 0.0f;
-  hipEvent_t start, stop;
-  sdkCreateTimer(&timer);
-  HIPCHECK(hipEventCreate(&start));
-  HIPCHECK(hipEventCreate(&stop));
-
-  // allocate host memory
-  unsigned char *h_odata = NULL;
-
-  if (PINNED == memMode) {
-#if CUDART_VERSION >= 2020
-    // pinned memory mode - use special function to get OS-pinned memory
-    HIPCHECK(hipHostAlloc((void **)&h_odata, memSize,
-                                  (wc) ? hipHostMallocWriteCombined : 0));
-#else
-    // pinned memory mode - use special function to get OS-pinned memory
-    HIPCHECK(hipHostMalloc((void **)&h_odata, memSize));
-#endif
-  } else {
-    // pageable memory mode - use malloc
-    h_odata = (unsigned char *)malloc(memSize);
-
-    if (h_odata == 0) {
-      fprintf(stderr, "Not enough memory available on host to run test!\n");
-      exit(EXIT_FAILURE);
-    }
-  }
-
-  unsigned char *h_cacheClear1 = (unsigned char *)malloc(CACHE_CLEAR_SIZE);
-  unsigned char *h_cacheClear2 = (unsigned char *)malloc(CACHE_CLEAR_SIZE);
-
-  if (h_cacheClear1 == 0 || h_cacheClear2 == 0) {
-    fprintf(stderr, "Not enough memory available on host to run test!\n");
-    exit(EXIT_FAILURE);
-  }
-
-  // initialize the memory
-  for (unsigned int i = 0; i < memSize / sizeof(unsigned char); i++) {
-    h_odata[i] = (unsigned char)(i & 0xff);
-  }
-
-  for (unsigned int i = 0; i < CACHE_CLEAR_SIZE / sizeof(unsigned char); i++) {
-    h_cacheClear1[i] = (unsigned char)(i & 0xff);
-    h_cacheClear2[i] = (unsigned char)(0xff - (i & 0xff));
-  }
-
-  // allocate device memory
-  unsigned char *d_idata;
-  HIPCHECK(hipMalloc((void **)&d_idata, memSize));
-
-  // copy host memory to device memory
-  if (PINNED == memMode) {
-    if (bDontUseGPUTiming) sdkStartTimer(&timer);
-    HIPCHECK(hipEventRecord(start, 0));
-    for (unsigned int i = 0; i < MEMCOPY_ITERATIONS; i++) {
-      HIPCHECK(hipMemcpyAsync(d_idata, h_odata, memSize,
-                                      hipMemcpyHostToDevice, 0));
-    }
-    HIPCHECK(hipEventRecord(stop, 0));
-    HIPCHECK(hipDeviceSynchronize());
-    HIPCHECK(hipEventElapsedTime(&elapsedTimeInMs, start, stop));
-    if (bDontUseGPUTiming) {
-      sdkStopTimer(&timer);
-      elapsedTimeInMs = sdkGetTimerValue(&timer);
-      sdkResetTimer(&timer);
-    }
-  } else {
-    elapsedTimeInMs = 0;
-    for (unsigned int i = 0; i < MEMCOPY_ITERATIONS; i++) {
-      sdkStartTimer(&timer);
-      HIPCHECK(
-          hipMemcpy(d_idata, h_odata, memSize, hipMemcpyHostToDevice));
-      sdkStopTimer(&timer);
-      elapsedTimeInMs += sdkGetTimerValue(&timer);
-      sdkResetTimer(&timer);
-      memset(flush_buf, i, FLUSH_SIZE);
-    }
-  }
-
-  // calculate bandwidth in GB/s
-  double time_s = elapsedTimeInMs / 1e3;
-  bandwidthInGBs = (memSize * (float)MEMCOPY_ITERATIONS) / (double)1e9;
-  bandwidthInGBs = bandwidthInGBs / time_s;
-  // clean up memory
-  HIPCHECK(hipEventDestroy(stop));
-  HIPCHECK(hipEventDestroy(start));
-  sdkDeleteTimer(&timer);
-
-  if (PINNED == memMode) {
-    HIPCHECK(hipHostFree(h_odata));
-  } else {
-    free(h_odata);
-  }
-
-  free(h_cacheClear1);
-  free(h_cacheClear2);
-  HIPCHECK(hipFree(d_idata));
-
-  return bandwidthInGBs;
-}
-
-///////////////////////////////////////////////////////////////////////////////
-//! test the bandwidth of a device to device memcopy of a specific size
-///////////////////////////////////////////////////////////////////////////////
-float testDeviceToDeviceTransfer(unsigned int memSize) {
-  StopWatchInterface *timer = NULL;
-  float elapsedTimeInMs = 0.0f;
-  float bandwidthInGBs = 0.0f;
-  hipEvent_t start, stop;
-
-  sdkCreateTimer(&timer);
-  HIPCHECK(hipEventCreate(&start));
-  HIPCHECK(hipEventCreate(&stop));
-
-  // allocate host memory
-  unsigned char *h_idata = (unsigned char *)malloc(memSize);
-
-  if (h_idata == 0) {
-    fprintf(stderr, "Not enough memory avaialable on host to run test!\n");
-    exit(EXIT_FAILURE);
-  }
-
-  // initialize the host memory
-  for (unsigned int i = 0; i < memSize / sizeof(unsigned char); i++) {
-    h_idata[i] = (unsigned char)(i & 0xff);
-  }
-
-  // allocate device memory
-  unsigned char *d_idata;
-  HIPCHECK(hipMalloc((void **)&d_idata, memSize));
-  unsigned char *d_odata;
-  HIPCHECK(hipMalloc((void **)&d_odata, memSize));
-
-  // initialize memory
-  HIPCHECK(
-      hipMemcpy(d_idata, h_idata, memSize, hipMemcpyHostToDevice));
-
-  // run the memcopy
-  sdkStartTimer(&timer);
-  HIPCHECK(hipEventRecord(start, 0));
-
-  for (unsigned int i = 0; i < MEMCOPY_ITERATIONS; i++) {
-    HIPCHECK(
-        hipMemcpy(d_odata, d_idata, memSize, hipMemcpyDeviceToDevice));
-  }
-
-  HIPCHECK(hipEventRecord(stop, 0));
-
-  // Since device to device memory copies are non-blocking,
-  // hipDeviceSynchronize() is required in order to get
-  // proper timing.
-  HIPCHECK(hipDeviceSynchronize());
-
-  // get the total elapsed time in ms
-  sdkStopTimer(&timer);
-  HIPCHECK(hipEventElapsedTime(&elapsedTimeInMs, start, stop));
-
-  if (bDontUseGPUTiming) {
-    elapsedTimeInMs = sdkGetTimerValue(&timer);
-  }
-
-  // calculate bandwidth in GB/s
-  double time_s = elapsedTimeInMs / 1e3;
-  bandwidthInGBs = (2.0f * memSize * (float)MEMCOPY_ITERATIONS) / (double)1e9;
-  bandwidthInGBs = bandwidthInGBs / time_s;
-
-  // clean up memory
-  sdkDeleteTimer(&timer);
-  free(h_idata);
-  HIPCHECK(hipEventDestroy(stop));
-  HIPCHECK(hipEventDestroy(start));
-  HIPCHECK(hipFree(d_idata));
-  HIPCHECK(hipFree(d_odata));
-
-  return bandwidthInGBs;
-}
-
-/////////////////////////////////////////////////////////
-// print results in an easily read format
-////////////////////////////////////////////////////////
-void printResultsReadable(unsigned int *memSizes, double *bandwidths,
-                          unsigned int count, memcpyKind kind,
-                          memoryMode memMode, int iNumDevs, bool wc) {
-  printf(" %s Bandwidth, %i Device(s)\n", sMemoryCopyKind[kind], iNumDevs);
-  printf(" %s Memory Transfers\n", sMemoryMode[memMode]);
-
-  if (wc) {
-    printf(" Write-Combined Memory Writes are Enabled");
-  }
-
-  printf("   Transfer Size (Bytes)\tBandwidth(GB/s)\n");
-  unsigned int i;
-
-  for (i = 0; i < (count - 1); i++) {
-    printf("   %u\t\t\t%s%.1f\n", memSizes[i],
-           (memSizes[i] < 10000) ? "\t" : "", bandwidths[i]);
-  }
-
-  printf("   %u\t\t\t%s%.1f\n\n", memSizes[i],
-         (memSizes[i] < 10000) ? "\t" : "", bandwidths[i]);
-}
-
-///////////////////////////////////////////////////////////////////////////
-// print results in a database format
-///////////////////////////////////////////////////////////////////////////
-void printResultsCSV(unsigned int *memSizes, double *bandwidths,
-                     unsigned int count, memcpyKind kind, memoryMode memMode,
-                     int iNumDevs, bool wc) {
-  std::string sConfig;
-
-  // log config information
-  if (kind == DEVICE_TO_DEVICE) {
-    sConfig += "D2D";
-  } else {
-    if (kind == DEVICE_TO_HOST) {
-      sConfig += "D2H";
-    } else if (kind == HOST_TO_DEVICE) {
-      sConfig += "H2D";
-    }
-
-    if (memMode == PAGEABLE) {
-      sConfig += "-Paged";
-    } else if (memMode == PINNED) {
-      sConfig += "-Pinned";
-
-      if (wc) {
-        sConfig += "-WriteCombined";
-      }
-    }
-  }
-
-  unsigned int i;
-  double dSeconds = 0.0;
-
-  for (i = 0; i < count; i++) {
-    dSeconds = (double)memSizes[i] / (bandwidths[i] * (double)(1e9));
-    printf(
-        "bandwidthTest-%s, Bandwidth = %.1f GB/s, Time = %.5f s, Size = %u "
-        "bytes, NumDevsUsed = %d\n",
-        sConfig.c_str(), bandwidths[i], dSeconds, memSizes[i], iNumDevs);
-  }
-}
-
-///////////////////////////////////////////////////////////////////////////
-// Print help screen
-///////////////////////////////////////////////////////////////////////////
-void printHelp(void) {
-  printf("Usage:  bandwidthTest [OPTION]...\n");
-  printf(
-      "Test the bandwidth for device to host, host to device, and device to "
-      "device transfers\n");
-  printf("\n");
-  printf(
-      "Example:  measure the bandwidth of device to host pinned memory copies "
-      "in the range 1024 Bytes to 102400 Bytes in 1024 Byte increments\n");
-  printf(
-      "./bandwidthTest --memory=pinned --mode=range --start=1024 --end=102400 "
-      "--increment=1024 --dtoh\n");
-
-  printf("\n");
-  printf("Options:\n");
-  printf("--help\tDisplay this help menu\n");
-  printf("--csv\tPrint results as a CSV\n");
-  printf("--device=[deviceno]\tSpecify the device device to be used\n");
-  printf("  all - compute cumulative bandwidth on all the devices\n");
-  printf("  0,1,2,...,n - Specify any particular device to be used\n");
-  printf("--memory=[MEMMODE]\tSpecify which memory mode to use\n");
-  printf("  pageable - pageable memory\n");
-  printf("  pinned   - non-pageable system memory\n");
-  printf("--mode=[MODE]\tSpecify the mode to use\n");
-  printf("  quick - performs a quick measurement\n");
-  printf("  range - measures a user-specified range of values\n");
-  printf("  shmoo - performs an intense shmoo of a large range of values\n");
-
-  printf("--htod\tMeasure host to device transfers\n");
-  printf("--dtoh\tMeasure device to host transfers\n");
-  printf("--dtod\tMeasure device to device transfers\n");
-#if CUDART_VERSION >= 2020
-  printf("--wc\tAllocate pinned memory as write-combined\n");
-#endif
-  printf("--cputiming\tForce CPU-based timing always\n");
-
-  printf("Range mode options\n");
-  printf("--start=[SIZE]\tStarting transfer size in bytes\n");
-  printf("--end=[SIZE]\tEnding transfer size in bytes\n");
-  printf("--increment=[SIZE]\tIncrement size in bytes\n");
-}
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.out b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2017.sln b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2017.vcxproj b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2019.sln b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2019.vcxproj b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2022.sln b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2022.vcxproj b/src/samples/Samples/1_Utilities/bandwidthTest/bandwidthTest_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/.vscode/c_cpp_properties.json b/src/samples/Samples/1_Utilities/deviceQuery/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/.vscode/extensions.json b/src/samples/Samples/1_Utilities/deviceQuery/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/.vscode/launch.json b/src/samples/Samples/1_Utilities/deviceQuery/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/.vscode/tasks.json b/src/samples/Samples/1_Utilities/deviceQuery/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/Makefile b/src/samples/Samples/1_Utilities/deviceQuery/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/NsightEclipse.xml b/src/samples/Samples/1_Utilities/deviceQuery/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/README.md b/src/samples/Samples/1_Utilities/deviceQuery/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery.cpp b/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_hipified.cpp b/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2017.sln b/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2017.vcxproj b/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2019.sln b/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2019.vcxproj b/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2022.sln b/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2022.vcxproj b/src/samples/Samples/1_Utilities/deviceQuery/deviceQuery_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/.vscode/c_cpp_properties.json b/src/samples/Samples/1_Utilities/deviceQueryDrv/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/.vscode/extensions.json b/src/samples/Samples/1_Utilities/deviceQueryDrv/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/.vscode/launch.json b/src/samples/Samples/1_Utilities/deviceQueryDrv/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/.vscode/tasks.json b/src/samples/Samples/1_Utilities/deviceQueryDrv/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/Makefile b/src/samples/Samples/1_Utilities/deviceQueryDrv/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/NsightEclipse.xml b/src/samples/Samples/1_Utilities/deviceQueryDrv/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/README.md b/src/samples/Samples/1_Utilities/deviceQueryDrv/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv.cpp b/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_hipified.cpp b/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2017.sln b/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2017.vcxproj b/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2019.sln b/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2019.vcxproj b/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2022.sln b/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2022.vcxproj b/src/samples/Samples/1_Utilities/deviceQueryDrv/deviceQueryDrv_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/.vscode/c_cpp_properties.json b/src/samples/Samples/1_Utilities/topologyQuery/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/.vscode/extensions.json b/src/samples/Samples/1_Utilities/topologyQuery/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/.vscode/launch.json b/src/samples/Samples/1_Utilities/topologyQuery/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/.vscode/tasks.json b/src/samples/Samples/1_Utilities/topologyQuery/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/Makefile b/src/samples/Samples/1_Utilities/topologyQuery/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/NsightEclipse.xml b/src/samples/Samples/1_Utilities/topologyQuery/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/README.md b/src/samples/Samples/1_Utilities/topologyQuery/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.cu b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.cu.hip b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.cu.hip
old mode 100644
new mode 100755
index acaafe4..e69de29
--- a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.cu.hip
+++ b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.cu.hip
@@ -1,82 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This sample demonstrates how to use query information on the current system
- * topology using a SDK 8.0 API.
- */
-
-// includes CUDA
-#include <hip/hip_runtime.h>
-
-// includes, project
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"  // helper for shared that are common to CUDA Samples
-#include "HIPCHECK.h"
-int main(int argc, char **argv) {
-  int deviceCount = 0;
-  HIPCHECK(hipGetDeviceCount(&deviceCount));
-
-  // Enumerates Device <-> Device links
-  for (int device1 = 0; device1 < deviceCount; device1++) {
-    for (int device2 = 0; device2 < deviceCount; device2++) {
-      if (device1 == device2) continue;
-
-      int perfRank = 0;
-      int atomicSupported = 0;
-      int accessSupported = 0;
-
-      HIPCHECK(hipDeviceGetP2PAttribute(
-          &accessSupported, hipDevP2PAttrAccessSupported, device1, device2));
-      HIPCHECK(hipDeviceGetP2PAttribute(
-          &perfRank, hipDevP2PAttrPerformanceRank, device1, device2));
-      HIPCHECK(hipDeviceGetP2PAttribute(
-          &atomicSupported, hipDevP2PAttrNativeAtomicSupported, device1,
-          device2));
-
-      if (accessSupported) {
-        std::cout << "GPU" << device1 << " <-> GPU" << device2 << ":"
-                  << std::endl;
-        std::cout << "  * Atomic Supported: "
-                  << (atomicSupported ? "yes" : "no") << std::endl;
-        std::cout << "  * Perf Rank: " << perfRank << std::endl;
-      }
-    }
-  }
-
-  // Enumerates Device <-> Host links
-  for (int device = 0; device < deviceCount; device++) {
-    int atomicSupported = 0;
-    HIPCHECK(hipDeviceGetAttribute(
-        &atomicSupported, hipDeviceAttributeHostNativeAtomicSupported, device));
-    std::cout << "GPU" << device << " <-> CPU:" << std::endl;
-    std::cout << "  * Atomic Supported: " << (atomicSupported ? "yes" : "no")
-              << std::endl;
-  }
-
-  return 0;
-}
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.out b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2017.sln b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2017.vcxproj b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2019.sln b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2019.vcxproj b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2022.sln b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2022.vcxproj b/src/samples/Samples/1_Utilities/topologyQuery/topologyQuery_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/README.md b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_consumer.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_consumer.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_consumer.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_consumer.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_consumer_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_consumer_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_consumer_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_consumer_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_producer.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_producer.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_producer.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_producer.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_producer_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_producer_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_producer_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/cuda_producer_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/eglstrm_common.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/eglstrm_common.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/eglstrm_common.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/eglstrm_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/eglstrm_common_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/eglstrm_common_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/eglstrm_common_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/eglstrm_common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/findegl.mk b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/findegl.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/helper.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/helper.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/helper_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/helper_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/kernel.cu b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/kernel.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/kernel.cu.hip
old mode 100644
new mode 100755
index a3d1a85..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/kernel.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/kernel.cu.hip
@@ -1,143 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-//
-// DESCRIPTION:   Simple CUDA consumer rendering sample app
-//
-
-#include <EGL/egl.h>
-#include <EGL/eglext.h>
-#include <hip/hip_runtime.h>
-#include <hip/hip_runtime.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-
-#include "eglstrm_common.h"
-
-extern bool isCrossDevice;
-
-__device__ static unsigned int numErrors = 0, errorFound = 0;
-__device__ void checkProducerDataGPU(char *data, int size, char expectedVal,
-                                     int frameNumber) {
-  if ((data[blockDim.x * blockIdx.x + threadIdx.x] != expectedVal) &&
-      (!errorFound)) {
-    printf("Producer FOUND:%d expected: %d at %d for trial %d %d\n",
-           data[blockDim.x * blockIdx.x + threadIdx.x], expectedVal,
-           (blockDim.x * blockIdx.x + threadIdx.x), frameNumber, numErrors);
-    numErrors++;
-    errorFound = 1;
-    return;
-  }
-}
-
-__device__ void checkConsumerDataGPU(char *data, int size, char expectedVal,
-                                     int frameNumber) {
-  if ((data[blockDim.x * blockIdx.x + threadIdx.x] != expectedVal) &&
-      (!errorFound)) {
-    printf("Consumer FOUND:%d expected: %d at %d for trial %d %d\n",
-           data[blockDim.x * blockIdx.x + threadIdx.x], expectedVal,
-           (blockDim.x * blockIdx.x + threadIdx.x), frameNumber, numErrors);
-    numErrors++;
-    errorFound = 1;
-    return;
-  }
-}
-
-__global__ void writeDataToBuffer(char *pSrc, char newVal) {
-  pSrc[blockDim.x * blockIdx.x + threadIdx.x] = newVal;
-}
-
-__global__ void testKernelConsumer(char *pSrc, char size, char expectedVal,
-                                   char newVal, int frameNumber) {
-  checkConsumerDataGPU(pSrc, size, expectedVal, frameNumber);
-}
-
-__global__ void testKernelProducer(char *pSrc, char size, char expectedVal,
-                                   char newVal, int frameNumber) {
-  checkProducerDataGPU(pSrc, size, expectedVal, frameNumber);
-}
-__global__ void getNumErrors(int *numErr) { *numErr = numErrors; }
-
-hipError_t cudaProducer_filter(hipStream_t pStream, char *pSrc, int width,
-                                int height, char expectedVal, char newVal,
-                                int frameNumber) {
-  // in case where consumer is on dgpu and producer is on igpu when return is
-  // called the frame is not copied back to igpu. So the consumer changes is not
-  // visible to producer
-  if (isCrossDevice == 0) {
-    testKernelProducer<<<(width * height) / 1024, 1024, 1, pStream>>>(
-        pSrc, width * height, expectedVal, newVal, frameNumber);
-  }
-  writeDataToBuffer<<<(width * height) / 1024, 1024, 1, pStream>>>(pSrc,
-                                                                   newVal);
-  return hipSuccess;
-};
-
-hipError_t cudaConsumer_filter(hipStream_t cStream, char *pSrc, int width,
-                                int height, char expectedVal, char newVal,
-                                int frameNumber) {
-  testKernelConsumer<<<(width * height) / 1024, 1024, 1, cStream>>>(
-      pSrc, width * height, expectedVal, newVal, frameNumber);
-  writeDataToBuffer<<<(width * height) / 1024, 1024, 1, cStream>>>(pSrc,
-                                                                   newVal);
-  return hipSuccess;
-};
-
-hipError_t cudaGetValueMismatch() {
-  int numErr_h;
-  int *numErr_d = NULL;
-  hipError_t err = hipSuccess;
-  err = hipMalloc(&numErr_d, sizeof(int));
-  if (err != hipSuccess) {
-    printf("Cuda Main: hipMalloc failed with %s\n", hipGetErrorString(err));
-    return err;
-  }
-  getNumErrors<<<1, 1>>>(numErr_d);
-  err = hipDeviceSynchronize();
-  if (err != hipSuccess) {
-    printf("Cuda Main: hipDeviceSynchronize failed with %s\n",
-           hipGetErrorString(err));
-  }
-  err = hipMemcpy(&numErr_h, numErr_d, sizeof(int), hipMemcpyDeviceToHost);
-  if (err != hipSuccess) {
-    printf("Cuda Main: hipMemcpy failed with %s\n", hipGetErrorString(err));
-    hipFree(numErr_d);
-    return err;
-  }
-  err = hipFree(numErr_d);
-  if (err != hipSuccess) {
-    printf("Cuda Main: hipFree failed with %s\n", hipGetErrorString(err));
-    return err;
-  }
-  if (numErr_h > 0) {
-    return hipErrorUnknown;
-  }
-  return hipSuccess;
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/main.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/main_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_CrossGPU/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/README.md b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_consumer.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_consumer.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_consumer.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_consumer.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_consumer_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_consumer_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_consumer_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_consumer_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_f_2.yuv b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_f_2.yuv
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_producer.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_producer.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_producer.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_producer.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_producer_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_producer_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_producer_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/cuda_producer_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/eglstrm_common.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/eglstrm_common.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/eglstrm_common.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/eglstrm_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/eglstrm_common_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/eglstrm_common_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/eglstrm_common_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/eglstrm_common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/findegl.mk b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/findegl.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/main.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/main_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/EGLStream_CUDA_Interop/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/EGLSync_CUDAEvent_Interop.cu b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/EGLSync_CUDAEvent_Interop.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/EGLSync_CUDAEvent_Interop.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/EGLSync_CUDAEvent_Interop.cu.hip
old mode 100644
new mode 100755
index 7ec5868..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/EGLSync_CUDAEvent_Interop.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/EGLSync_CUDAEvent_Interop.cu.hip
@@ -1,786 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// Simple interop app demonstrating EGLImage + EGLSync interop with CUDA.
-// Using EGLSync - CUDA Event interop one can achieve synchronization on GPU
-// itself for GL-EGL-CUDA operations instead of blocking CPU for
-// synchronization. This app requires GLES 3.2 or higher
-
-//---------------------------INCLUDES---------------------------------//
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <time.h>
-#include "graphics_interface.h"
-#include <hip/hip_runtime.h>
-#include <helper_cuda_drvapi.h>
-#include <cudaEGL.h>
-#include <EGL/egl.h>
-#include <EGL/eglext.h>
-#include <GLES3/gl32.h>
-#include "egl_common.h"
-
-//---------------------------DEFINES---------------------------------//
-#define MAX_ITR 100
-
-#define FAILURE 0
-#define SUCCESS 1
-#define WAIVED 2
-
-#define BLOCK_SIZE 16
-
-#define GL_READ 0
-#define GL_WRITE 1
-//---------------------------MACROS---------------------------------//
-
-// Error-checking wrapper around GL calls
-#define GL_SAFE_CALL(call)                                              \
-  {                                                                     \
-    GLenum err;                                                         \
-    call;                                                               \
-    err = glGetError();                                                 \
-    if (err != GL_NO_ERROR) {                                           \
-      fprintf(stderr, "%s:%d GL error: %d\n", __FILE__, __LINE__, err); \
-      cleanup(FAILURE);                                                 \
-    }                                                                   \
-  }
-
-#define GL_SAFE_CALL_NO_CLEANUP(call, err)                                 \
-  {                                                                        \
-    GLenum status;                                                         \
-    call;                                                                  \
-    status = glGetError();                                                 \
-    if (status != GL_NO_ERROR) {                                           \
-      fprintf(stderr, "%s:%d GL error: %d\n", __FILE__, __LINE__, status); \
-      err = status;                                                        \
-    }                                                                      \
-  }
-
-// Error-checking wrapper around CUDA calls (taken from cutil.h)
-#define CUDA_SAFE_CALL(call)                                                  \
-  do {                                                                        \
-    hipError_t err = call;                                                     \
-    if (hipSuccess != err) {                                                 \
-      fprintf(stderr, "Cuda error in file '%s' in line %i : %s.\n", __FILE__, \
-              __LINE__, hipGetErrorString(err));                             \
-      cleanup(FAILURE);                                                       \
-    }                                                                         \
-  } while (0)
-
-#define CUDA_SAFE_CALL_NO_CLEANUP(call, err)                                  \
-  do {                                                                        \
-    hipError_t status = call;                                                  \
-    if (hipSuccess != status) {                                              \
-      fprintf(stderr, "Cuda error in file '%s' in line %i : %s.\n", __FILE__, \
-              __LINE__, hipGetErrorString(status));                          \
-      err = status;                                                           \
-    }                                                                         \
-  } while (0)
-
-#if defined(EXTENSION_LIST)
-EXTENSION_LIST(EXTLST_DECL)
-typedef void (*extlst_fnptr_t)(void);
-static struct {
-  extlst_fnptr_t *fnptr;
-  char const *name;
-} extensionList[] = {EXTENSION_LIST(EXTLST_ENTRY)};
-
-int eglSetupExtensions(void) {
-  unsigned int i;
-
-  for (i = 0; i < (sizeof(extensionList) / sizeof(*extensionList)); i++) {
-    *extensionList[i].fnptr = eglGetProcAddress(extensionList[i].name);
-    if (*extensionList[i].fnptr == NULL) {
-      printf("Couldn't get address of %s()\n", extensionList[i].name);
-      return 0;
-    }
-  }
-
-  return 1;
-}
-#endif
-
-#if defined(EXTENSION_LIST)
-EXTENSION_LIST(EXTLST_EXTERN)
-#endif
-
-//------------------------GLOBAL VARIABLES--------------------------//
-
-// GL texture
-GLuint tex[2] = {0};
-
-// Used to catch unexpected termination from GLUT
-int cleanExit = 0;
-
-// Use CPU Sync or GPU sync; Default GPU
-int useGpu = 1;
-
-// CUDA Resource
-hipGraphicsResource_t writeResource = NULL;
-hipGraphicsResource_t readResource = NULL;
-hipArray_t writeArray, readArray;
-hipDevice_t device;
-hipCtx_t context;
-
-// Which device to run on
-unsigned int dev = 0;
-
-// Default width, height, and iterations value
-int width = 2048;
-int height = 2048;
-int itr = MAX_ITR;
-
-// Error check variable
-__device__ static unsigned int numErrors = 0;
-
-//-----------------------FUNCTION PROTOTYPES------------------------//
-
-void checkSync(int argc, char **argv);
-int parseCmdLine(int argc, char **argv);
-void printUsage(void);
-void cleanup(int status);
-void exitHandler(void);
-void printStatus(int status);
-void checkSyncOnCPU(void);
-void checkSyncOnGPU(EGLDisplay dpy);
-
-__global__ void verify_and_update_kernel(hipSurfaceObject_t write, hipSurfaceObject_t read,
-                                         char expected, char newval, int width,
-                                         int height);
-extern "C" hipError_t cudaGetValueMismatch();
-
-//-----------------------FUNCTION DEFINITIONS------------------------//
-
-int main(int argc, char *argv[]) {
-#if defined(__linux__)
-  setenv("DISPLAY", ":0", 0);
-#endif
-
-  parseCmdLine(argc, argv);
-  atexit(exitHandler);
-
-  checkSync(argc, argv);
-  return 0;
-}
-
-int parseCmdLine(int argc, char **argv) {
-  int i;
-  for (i = 1; i < argc; i++) {
-    if (strcmp(argv[i], "-cpu") == 0) {
-      useGpu = 0;
-    }
-
-    if (strcmp(argv[i], "-h") == 0) {
-      printUsage();
-      cleanup(SUCCESS);
-    }
-
-    if (strcmp(argv[i], "-width") == 0) {
-      ++i;
-      if (i == argc) {
-        printf("width option must be followed by value\n");
-        return FAILURE;
-      }
-      if (sscanf(argv[i], "%d", &width) != 1) {
-        printf("Error: invalid width value\n");
-        return FAILURE;
-      }
-    }
-
-    if (strcmp(argv[i], "-height") == 0) {
-      ++i;
-      if (i == argc) {
-        printf("height option must be followed by value\n");
-        return FAILURE;
-      }
-      if (sscanf(argv[i], "%d", &height) != 1) {
-        printf("Error: invalid height value\n");
-        return FAILURE;
-      }
-    }
-    if (strcmp(argv[i], "-itr") == 0) {
-      ++i;
-      if (i == argc) {
-        printf("itr option must be followed by iteration value\n");
-        return FAILURE;
-      }
-      if (sscanf(argv[i], "%d", &itr) != 1) {
-        printf("Error: invalid iteration value\n");
-        return FAILURE;
-      }
-    }
-  }
-
-  return SUCCESS;
-}
-
-void printUsage(void) {
-  printf("Usage:\n");
-  printf("\t-h\tPrint command line options\n");
-  printf("\t-cpu\tSync on the CPU instead of the GPU\n");
-  printf("\t-width w\tSet the width to w\n");
-  printf("\t-height h\tSet the height to h\n");
-  printf("\t-itr i\tSet number of iterations to i\n");
-}
-
-void checkSync(int argc, char **argv) {
-  int x, y;
-  int bufferSize = width * height * 4;
-  unsigned char *pSurf_read = NULL, *pSurf_write = NULL;
-  int integrated;
-
-  hipError_t status = hipSuccess;
-
-  // Init values for variables
-  x = y = 0;
-
-  if (hipSuccess != (status = hipInit(0))) {
-    printf("Failed to initialize CUDA\n");
-  }
-  device = findCudaDeviceDRV(argc, (const char **)argv);
-
-  if (hipSuccess != (status = hipCtxCreate(&context, 0, device))) {
-    printf("failed to create CUDA context\n");
-  }
-  hipCtxPushCurrent(context);
-
-  status =
-      hipDeviceGetAttribute(&integrated, hipDeviceAttributeIntegrated, device);
-  if (status != hipSuccess) {
-    printf("Failed to get device attribute hipDeviceAttributeIntegrated\n");
-    cleanup(FAILURE);
-  }
-
-  if (integrated != 1) {
-    printf(
-        "EGLSync_CUDAEvent_Interop does not support dGPU. Waiving sample.\n");
-    cleanup(WAIVED);
-  }
-
-#if (defined(__arm__) || defined(__aarch64__)) && defined(__linux__)
-  graphics_setup_window(0, 0, width, height, "EGLSync_CUDA_Interop");
-#endif
-
-  pSurf_read = (unsigned char *)malloc(bufferSize);
-  pSurf_write = (unsigned char *)malloc(bufferSize);
-  if (pSurf_read == NULL || pSurf_write == NULL) {
-    printf("malloc failed\n");
-    cleanup(FAILURE);
-  }
-
-  for (x = 0; x < width; x++) {
-    for (y = 0; y < height; y++) {
-      pSurf_read[(y * width + x) * 4] = 1;
-      pSurf_read[(y * width + x) * 4 + 1] = 1;
-      pSurf_read[(y * width + x) * 4 + 2] = 1;
-      pSurf_read[(y * width + x) * 4 + 3] = 1;
-      pSurf_write[(y * width + x) * 4] = 0;
-      pSurf_write[(y * width + x) * 4 + 1] = 0;
-      pSurf_write[(y * width + x) * 4 + 2] = 0;
-      pSurf_write[(y * width + x) * 4 + 3] = 0;
-    }
-  }
-
-  // NOP call to error-check the above glut calls
-  GL_SAFE_CALL({});
-
-  // Init texture
-  GL_SAFE_CALL(glGenTextures(2, tex));
-
-  GL_SAFE_CALL(glBindTexture(GL_TEXTURE_2D, tex[GL_READ]));
-  GL_SAFE_CALL(
-      glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST));
-  GL_SAFE_CALL(
-      glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST));
-  GL_SAFE_CALL(glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA8, width, height, 0,
-                            GL_RGBA, GL_UNSIGNED_BYTE, pSurf_read));
-  GL_SAFE_CALL(glBindTexture(GL_TEXTURE_2D, 0));
-
-  GL_SAFE_CALL(glBindTexture(GL_TEXTURE_2D, tex[GL_WRITE]));
-  GL_SAFE_CALL(
-      glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST));
-  GL_SAFE_CALL(
-      glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST));
-  GL_SAFE_CALL(glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA8, width, height, 0,
-                            GL_RGBA, GL_UNSIGNED_BYTE, pSurf_write));
-  GL_SAFE_CALL(glBindTexture(GL_TEXTURE_2D, 0));
-
-  glFinish();
-
-  EGLDisplay eglDisplayHandle = eglGetCurrentDisplay();
-  if (eglDisplayHandle == EGL_NO_DISPLAY) {
-    printf("eglDisplayHandle failed \n");
-    cleanup(FAILURE);
-  } else {
-    printf("eglDisplay Handle created \n");
-  }
-
-  if (!eglSetupExtensions()) {
-    printf("SetupExtentions failed \n");
-    cleanup(FAILURE);
-  }
-
-  EGLContext eglCtx = eglGetCurrentContext();
-  if (eglCtx == EGL_NO_CONTEXT) {
-    printf("Context1 create failed with error %d\n", eglGetError());
-    cleanup(FAILURE);
-  }
-
-  // Create the EGL_Image
-  EGLint eglImgAttrs[] = {EGL_IMAGE_PRESERVED_KHR, EGL_TRUE, EGL_NONE,
-                          EGL_NONE};
-
-  EGLImageKHR eglImage1 =
-      eglCreateImageKHR(eglDisplayHandle, eglCtx, EGL_GL_TEXTURE_2D_KHR,
-                        (EGLClientBuffer)(intptr_t)tex[GL_READ], eglImgAttrs);
-  if (eglImage1 == EGL_NO_IMAGE_KHR) {
-    printf("EGLImage create failed for read texture with error %d\n",
-           eglGetError());
-    cleanup(FAILURE);
-  } else {
-    printf("EGLImage1 created \n");
-  }
-
-  EGLImageKHR eglImage2 =
-      eglCreateImageKHR(eglDisplayHandle, eglCtx, EGL_GL_TEXTURE_2D_KHR,
-                        (EGLClientBuffer)(intptr_t)tex[GL_WRITE], eglImgAttrs);
-  if (eglImage2 == EGL_NO_IMAGE_KHR) {
-    printf("EGLImage create failed for write texture with error %d\n",
-           eglGetError());
-    cleanup(FAILURE);
-  } else {
-    printf("EGLImage2 created \n");
-  }
-
-  glFinish();
-
-  status = cuGraphicsEGLRegisterImage(&writeResource, eglImage1,
-                                      hipGraphicsRegisterFlagsNone);
-  if (status != hipSuccess) {
-    printf("cuGraphicsEGLRegisterImage failed with Texture 1\n");
-    cleanup(FAILURE);
-  } else {
-    printf(
-        "cuGraphicsEGLRegisterImage Passed, writeResource created with texture "
-        "1\n");
-  }
-
-  status =
-      hipGraphicsSubResourceGetMappedArray(&writeArray, writeResource, 0, 0);
-  if (status != hipSuccess) {
-    printf(
-        "hipGraphicsSubResourceGetMappedArray failed for writeResource with "
-        "texture 1\n");
-    cleanup(FAILURE);
-  }
-
-  status = cuGraphicsEGLRegisterImage(&readResource, eglImage2,
-                                      hipGraphicsRegisterFlagsNone);
-  if (status != hipSuccess) {
-    printf(
-        "cuGraphicsEGLRegisterImage failed for readResource with Texture 2\n");
-    cleanup(FAILURE);
-  } else {
-    printf(
-        "cuGraphicsEGLRegisterImage Passed, readResource created with texture "
-        "2\n");
-  }
-
-  status = hipGraphicsSubResourceGetMappedArray(&readArray, readResource, 0, 0);
-  if (status != hipSuccess) {
-    printf("hipGraphicsSubResourceGetMappedArray failed for texture 2\n");
-    cleanup(FAILURE);
-  }
-
-  if (useGpu) {
-    printf("Using GPU Sync path\n");
-    checkSyncOnGPU(eglDisplayHandle);
-  } else {
-    printf("Using CPU Sync path\n");
-    checkSyncOnCPU();
-  }
-
-  free(pSurf_read);
-  free(pSurf_write);
-  cleanup(SUCCESS);
-}
-
-void checkSyncOnCPU(void) {
-  int z = 0;
-  unsigned char expectedData, newData;
-  hipError_t status = hipSuccess;
-  HIP_RESOURCE_DESC wdsc, rdsc;
-  memset(&wdsc, 0, sizeof(wdsc));
-  memset(&rdsc, 0, sizeof(rdsc));
-
-  expectedData = 0;
-  newData = 1;
-
-  wdsc.resType = HIP_RESOURCE_TYPE_ARRAY;
-  wdsc.res.array.hArray = writeArray;
-  hipSurfaceObject_t writeSurface;
-  rdsc.resType = HIP_RESOURCE_TYPE_ARRAY;
-  rdsc.res.array.hArray = readArray;
-  hipSurfaceObject_t readSurface;
-
-  status = cuSurfObjectCreate(&writeSurface, &wdsc);
-  if (status != hipSuccess) {
-    printf("Surface bounding failed with status %d\n", status);
-    cleanup(FAILURE);
-  }
-  status = cuSurfObjectCreate(&readSurface, &rdsc);
-  if (status != hipSuccess) {
-    printf("Surface bounding failed\n");
-    cleanup(FAILURE);
-  }
-
-  for (z = 0; z < itr; z++) {
-    // GL call to copy from read texture to write texture
-    GL_SAFE_CALL(glCopyImageSubData(tex[GL_READ], GL_TEXTURE_2D, 0, 0, 0, 0,
-                                    tex[GL_WRITE], GL_TEXTURE_2D, 0, 0, 0, 0,
-                                    width, height, 1));
-
-    glFinish();
-
-    newData++;
-    expectedData++;
-
-    verify_and_update_kernel<<<(width * height) / 256, 256>>>(
-        writeSurface, readSurface, expectedData, newData, width, height);
-
-    status = hipCtxSynchronize();
-    if (status != hipSuccess) {
-      printf("hipCtxSynchronize failed \n");
-    }
-  }
-
-  hipError_t err = cudaGetValueMismatch();
-  if (err != hipSuccess) {
-    printf("Value mismatch seen when using CPU sync\n");
-    cleanup(FAILURE);
-  }
-
-  // Clean up CUDA writeResource
-  status = hipGraphicsUnregisterResource(writeResource);
-  if (status != hipSuccess) {
-    printf("Failed to unregister %d", status);
-    cleanup(FAILURE);
-  } else {
-    printf("Unregistered writeResource. \n");
-  }
-
-  // Clean up CUDA readResource
-  status = hipGraphicsUnregisterResource(readResource);
-  if (status != hipSuccess) {
-    printf("Failed to unregister %d", status);
-    cleanup(FAILURE);
-  } else {
-    printf("Unregistered readResource. \n");
-  }
-}
-
-/*
-    Performs same function as checkSyncOnCPU
-    Here instead of glFinish() and hipCtxSynchronize like in checkSyncOnCPU,
-    we make use of EGLSync, CUDA Event and hipStreamWaitEvent, eglWaitSyncKHR to
-   achieve the synchronization due to this CPU is not blocked for any
-   synchronization needed between GL-EGL & CUDA operations all synchronizations
-   happens on the GPU only.
-*/
-void checkSyncOnGPU(EGLDisplay dpy) {
-  int z = 0;
-  unsigned char expectedData, newData;
-  hipError_t err;
-  hipError_t status = hipSuccess;
-  hipStream_t stream;
-  hipEvent_t timingDisabledEvent;
-  HIP_RESOURCE_DESC wdsc, rdsc;
-  memset(&wdsc, 0, sizeof(wdsc));
-  memset(&rdsc, 0, sizeof(rdsc));
-
-  expectedData = 0;
-  newData = 1;
-
-  wdsc.resType = HIP_RESOURCE_TYPE_ARRAY;
-  wdsc.res.array.hArray = writeArray;
-  hipSurfaceObject_t writeSurface;
-  rdsc.resType = HIP_RESOURCE_TYPE_ARRAY;
-  rdsc.res.array.hArray = readArray;
-  hipSurfaceObject_t readSurface;
-
-  status = cuSurfObjectCreate(&writeSurface, &wdsc);
-  if (status != hipSuccess) {
-    printf("Surface bounding failed with status %d\n", status);
-    cleanup(FAILURE);
-  }
-  status = cuSurfObjectCreate(&readSurface, &rdsc);
-  if (status != hipSuccess) {
-    printf("Surface bounding failed\n");
-    cleanup(FAILURE);
-  }
-
-  status = hipStreamCreateWithFlags(&stream, hipStreamDefault);
-  if (status != hipSuccess) {
-    printf("Stream creation failed\n");
-    cleanup(FAILURE);
-  }
-
-  // Creates timing disabled event which uses non-blocking synchronization
-  status = hipEventCreateWithFlags(&timingDisabledEvent, hipEventDisableTiming);
-  if (status != hipSuccess) {
-    printf("Default event creation failed\n");
-    cleanup(FAILURE);
-  }
-
-  /*
-      1. We perform texture-to-texture copy in GLES which is async function
-      2. Followed by creating EGLSync and a CUDA Event from that EGLSync object
-      3. Using hipStreamWaitEvent() we wait in GPU for the GLES to finish texture
-     copy.
-      4. CUDA kernel verfiy_and_update_kernel verifies if the copied data by
-     GLES is correct, and it updates the buffer with new values.
-      5. This is followed by eglWaitSyncKHR() which waits for the cuda kernel to
-     finish, so that in the next iteration GLES can perform the copying of the
-     updated buffer to write texture,
-  */
-  for (z = 0; z < itr; z++) {
-    // GL call to copy from read texture to write texture
-    GL_SAFE_CALL(glCopyImageSubData(tex[GL_READ], GL_TEXTURE_2D, 0, 0, 0, 0,
-                                    tex[GL_WRITE], GL_TEXTURE_2D, 0, 0, 0, 0,
-                                    width, height, 1));
-
-    EGLSyncKHR eglSyncForGL, eglSyncForCuda;
-    EGLBoolean egl_status = EGL_TRUE;
-    EGLAttribKHR eglattrib[] = {EGL_CUDA_EVENT_HANDLE_NV,
-                                (EGLAttrib)timingDisabledEvent, EGL_NONE};
-
-    hipEvent_t cudaEGLSyncEvent;
-
-    eglSyncForGL = eglCreateSyncKHR(dpy, EGL_SYNC_FENCE_KHR, NULL);
-
-    if (eglSyncForGL == EGL_NO_SYNC_KHR) {
-      printf(" EGL Sync creation failed\n");
-      cleanup(FAILURE);
-    }
-
-    status = cuEventCreateFromEGLSync(&cudaEGLSyncEvent, eglSyncForGL,
-                                      hipEventDefault);
-    if (status != hipSuccess) {
-      printf("CUDA event creation from EGLSync failed\n");
-      cleanup(FAILURE);
-    }
-
-    // We wait from CUDA in GPU for GL-EGL operation completion
-    status = hipStreamWaitEvent(stream, cudaEGLSyncEvent, 0);
-    if (status != hipSuccess) {
-      printf("Stream wait for event created from EGLSync failed\n");
-      cleanup(FAILURE);
-    }
-
-    egl_status = eglDestroySyncKHR(dpy, eglSyncForGL);
-    if (egl_status != EGL_TRUE) {
-      printf("EGL sync object destruction failed\n");
-      cleanup(FAILURE);
-    }
-
-    newData++;
-    expectedData++;
-
-    // Verifies the values in readSurface which is copied by
-    // glCopyImageSubData() And writes value of newData into writeSurface
-    verify_and_update_kernel<<<(width * height) / 256, 256, 0, stream>>>(
-        writeSurface, readSurface, expectedData, newData, width, height);
-
-    status = hipEventDestroy(cudaEGLSyncEvent);
-    if (status != hipSuccess) {
-      printf("Event Destroy failed\n");
-      cleanup(FAILURE);
-    }
-
-    status = hipEventRecord(timingDisabledEvent, stream);
-    if (status != hipSuccess) {
-      printf("Event Record failed\n");
-      cleanup(FAILURE);
-    }
-
-    // creating an EGL sync object linked to a CUDA event object
-    eglSyncForCuda = eglCreateSync64KHR(dpy, EGL_SYNC_CUDA_EVENT_NV, eglattrib);
-
-    // We wait from EGL for CUDA operation completion
-    egl_status = eglWaitSyncKHR(dpy, eglSyncForCuda, 0);
-    if (egl_status != EGL_TRUE) {
-      printf("eglWaitSyncKHR failed\n");
-      cleanup(FAILURE);
-    }
-    egl_status = eglDestroySyncKHR(dpy, eglSyncForCuda);
-    if (egl_status != EGL_TRUE) {
-      printf("EGL sync object destruction failed\n");
-      cleanup(FAILURE);
-    }
-  }
-
-  err = cudaGetValueMismatch();
-  if (err != hipSuccess) {
-    printf("Value mismatch seen when using GPU sync\n");
-    cleanup(FAILURE);
-  }
-
-  // Clean up CUDA writeResource
-  status = hipGraphicsUnregisterResource(writeResource);
-  if (status != hipSuccess) {
-    printf("Failed to unregister %d", status);
-    cleanup(FAILURE);
-  } else {
-    printf("Unregistered writeResource. \n");
-  }
-
-  // Clean up CUDA readResource
-  status = hipGraphicsUnregisterResource(readResource);
-  if (status != hipSuccess) {
-    printf("Failed to unregister %d", status);
-    cleanup(FAILURE);
-  } else {
-    printf("Unregistered readResource. \n");
-  }
-}
-
-// Verifies the values in readSurface whether they are expected ones
-// And writes value of newData into writeSurface
-__global__ void verify_and_update_kernel(hipSurfaceObject_t write, hipSurfaceObject_t read,
-                                         char expected, char newval, int width,
-                                         int height) {
-  unsigned int x = blockDim.x * blockIdx.x + threadIdx.x;
-  unsigned int y = blockDim.y * blockIdx.y + threadIdx.y;
-
-  if (x < width && y < height) {
-    uchar4 check;
-    surf2Dread(&check, read, x * 4, y);
-    if (check.x != expected || check.y != expected || check.z != expected ||
-        check.w != expected) {
-      printf(
-          "Mismatch found in values read[0]= %u read[1]= %u read[2]= %u "
-          "read[3]= %u expected is %u\n",
-          check.x, check.y, check.z, check.w, expected);
-      numErrors++;
-      return;
-    }
-    uchar4 data = make_uchar4(newval, newval, newval, newval);
-    surf2Dwrite(data, write, x * 4, y);
-  }
-}
-
-__global__ void getNumErrors(int *numErr) { *numErr = numErrors; }
-
-extern "C" hipError_t cudaGetValueMismatch() {
-  int numErr_h;
-  int *numErr_d = NULL;
-  hipError_t err = hipSuccess;
-
-  err = hipMalloc(&numErr_d, sizeof(int));
-  if (err != hipSuccess) {
-    printf("Cuda Main: hipMemcpy failed with %s\n", hipGetErrorString(err));
-    hipFree(numErr_d);
-    return err;
-  }
-
-  getNumErrors<<<1, 1>>>(numErr_d);
-  err = hipDeviceSynchronize();
-  if (err != hipSuccess) {
-    printf("Cuda Main: hipDeviceSynchronize failed with %s\n",
-           hipGetErrorString(err));
-  }
-  err = hipMemcpy(&numErr_h, numErr_d, sizeof(int), hipMemcpyDeviceToHost);
-  if (err != hipSuccess) {
-    printf("Cuda Main: hipMemcpy failed with %s\n", hipGetErrorString(err));
-    hipFree(numErr_d);
-    return err;
-  }
-  err = hipFree(numErr_d);
-  if (err != hipSuccess) {
-    printf("Cuda Main: hipFree failed with %s\n", hipGetErrorString(err));
-    return err;
-  }
-  if (numErr_h > 0) {
-    return hipErrorUnknown;
-  }
-  return hipSuccess;
-}
-
-// Clean up state and exit. If status is SUCCESS, regression success is printed
-// to stdout. This will happen if the glut timer is triggered. If status is
-// anything else, the regression failure message is printed.
-void cleanup(int status) {
-  GLenum glErr = GL_NO_ERROR;
-  hipError_t cudaErr = hipSuccess;
-  int exitStatus = status;
-
-  // Clean up GL
-  if (*tex) {
-    GL_SAFE_CALL_NO_CLEANUP(glDeleteTextures(2, tex), glErr);
-  }
-
-  // Print test status and exit
-  if (glErr != GL_NO_ERROR || cudaErr != hipSuccess) exitStatus = FAILURE;
-
-  printStatus(exitStatus);
-
-  cleanExit = 1;
-
-  graphics_close_window();
-
-  if (exitStatus == FAILURE) exit(EXIT_FAILURE);
-
-  if (exitStatus == WAIVED) exit(EXIT_WAIVED);
-
-  exit(0);
-}
-
-void exitHandler(void) {
-  if (!cleanExit) {
-    printf("&&&& EGLSync_CUDAEvent_Interop unexpected failure \n");
-    printStatus(FAILURE);
-  }
-}
-
-// Print test success or fail for regression testing
-void printStatus(int status) {
-  switch (status) {
-    case SUCCESS:
-      printf("&&&& EGLSync_CUDAEvent_Interop PASSED\n");
-      break;
-    case WAIVED:
-      printf("&&&& EGLSync_CUDAEvent_Interop WAIVED\n");
-      break;
-    default:
-      printf("&&&& EGLSync_CUDAEvent_Interop FAILED\n");
-      break;
-  }
-  fflush(stdout);
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/README.md b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/egl_common.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/egl_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/egl_common_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/egl_common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/findegl.mk b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/findegl.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/graphics_interface.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/graphics_interface.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/graphics_interface_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/EGLSync_CUDAEvent_Interop/graphics_interface_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers.cpp b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_kernels.cu b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_kernels.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_kernels.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_kernels.cu.hip
old mode 100644
new mode 100755
index af7c61e..57ad723
--- a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_kernels.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_kernels.cu.hip
@@ -27,15 +27,13 @@
  */
 
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <stdlib.h>
 #include <hip/hip_cooperative_groups.h>
 
 namespace cg = cooperative_groups;
 
 #include "helper_cuda_hipified.h"
-
+#include "HIPCHECK.h"
 #include "FunctionPointers_kernels.h"
 
 // Texture object for reading image
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_kernels.h b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_kernels.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_kernels_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_kernels_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/FunctionPointers_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/README.md b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/data/ref_orig.pgm b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/data/ref_orig.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/data/ref_shared.pgm b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/data/ref_shared.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/data/ref_tex.pgm b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/data/ref_tex.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/data/teapot512.pgm b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/data/teapot512.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/findgllib.mk b/src/samples/Samples/2_Concepts_and_Techniques/FunctionPointers/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/MC_EstimatePiInlineP_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/README.md b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/inc/cudasharedmem.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/inc/cudasharedmem.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/inc/cudasharedmem_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/inc/cudasharedmem_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/inc/piestimator.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/inc/piestimator.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/inc/piestimator_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/inc/piestimator_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/inc/test.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/inc/test.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/inc/test_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/inc/test_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/main.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/main_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/piestimator.cu b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/piestimator.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/piestimator.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/piestimator.cu.hip
old mode 100644
new mode 100755
index c56c703..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/piestimator.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/piestimator.cu.hip
@@ -1,284 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "../inc/piestimator.h"
-
-#include <string>
-#include <vector>
-#include <numeric>
-#include <stdexcept>
-#include <typeinfo>
-#include <hip/hip_runtime.h>
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-#include <hiprand_kernel.h>
-
-using std::string;
-using std::vector;
-
-// RNG init kernel
-__global__ void initRNG(hiprandState *const rngStates, const unsigned int seed) {
-  // Determine thread ID
-  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
-
-  // Initialise the RNG
-  hiprand_init(seed, tid, 0, &rngStates[tid]);
-}
-
-__device__ unsigned int reduce_sum(unsigned int in, cg::thread_block cta) {
-  extern __shared__ unsigned int sdata[];
-
-  // Perform first level of reduction:
-  // - Write to shared memory
-  unsigned int ltid = threadIdx.x;
-
-  sdata[ltid] = in;
-  cg::sync(cta);
-
-  // Do reduction in shared mem
-  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
-    if (ltid < s) {
-      sdata[ltid] += sdata[ltid + s];
-    }
-
-    cg::sync(cta);
-  }
-
-  return sdata[0];
-}
-
-__device__ inline void getPoint(float &x, float &y, hiprandState &state) {
-  x = hiprand_uniform(&state);
-  y = hiprand_uniform(&state);
-}
-__device__ inline void getPoint(double &x, double &y, hiprandState &state) {
-  x = hiprand_uniform_double(&state);
-  y = hiprand_uniform_double(&state);
-}
-
-// Estimator kernel
-template <typename Real>
-__global__ void computeValue(unsigned int *const results,
-                             hiprandState *const rngStates,
-                             const unsigned int numSims) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  // Determine thread ID
-  unsigned int bid = blockIdx.x;
-  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int step = gridDim.x * blockDim.x;
-
-  // Initialise the RNG
-  hiprandState localState = rngStates[tid];
-
-  // Count the number of points which lie inside the unit quarter-circle
-  unsigned int pointsInside = 0;
-
-  for (unsigned int i = tid; i < numSims; i += step) {
-    Real x;
-    Real y;
-    getPoint(x, y, localState);
-    Real l2norm2 = x * x + y * y;
-
-    if (l2norm2 < static_cast<Real>(1)) {
-      pointsInside++;
-    }
-  }
-
-  // Reduce within the block
-  pointsInside = reduce_sum(pointsInside, cta);
-
-  // Store the result
-  if (threadIdx.x == 0) {
-    results[bid] = pointsInside;
-  }
-}
-
-template <typename Real>
-PiEstimator<Real>::PiEstimator(unsigned int numSims, unsigned int device,
-                               unsigned int threadBlockSize, unsigned int seed)
-    : m_numSims(numSims),
-      m_device(device),
-      m_threadBlockSize(threadBlockSize),
-      m_seed(seed) {}
-
-template <typename Real>
-Real PiEstimator<Real>::operator()() {
-  hipError_t cudaResult = hipSuccess;
-  struct hipDeviceProp_t deviceProperties;
-  struct hipFuncAttributes funcAttributes;
-
-  // Get device properties
-  cudaResult = hipGetDeviceProperties(&deviceProperties, m_device);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not get device properties: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Check precision is valid
-  if (typeid(Real) == typeid(double) &&
-      (deviceProperties.major < 1 ||
-       (deviceProperties.major == 1 && deviceProperties.minor < 3))) {
-    throw std::runtime_error("Device does not have double precision support");
-  }
-
-  // Attach to GPU
-  cudaResult = hipSetDevice(m_device);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not set CUDA device: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Determine how to divide the work between cores
-  dim3 block;
-  dim3 grid;
-  block.x = m_threadBlockSize;
-  grid.x = (m_numSims + m_threadBlockSize - 1) / m_threadBlockSize;
-
-  // Aim to launch around ten or more times as many blocks as there
-  // are multiprocessors on the target device.
-  unsigned int blocksPerSM = 10;
-  unsigned int numSMs = deviceProperties.multiProcessorCount;
-
-  while (grid.x > 2 * blocksPerSM * numSMs) {
-    grid.x >>= 1;
-  }
-
-  // Get initRNG function properties and check the maximum block size
-  cudaResult = hipFuncGetAttributes(&funcAttributes, initRNG);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not get function attributes: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
-    throw std::runtime_error(
-        "Block X dimension is too large for initRNG kernel");
-  }
-
-  // Get computeValue function properties and check the maximum block size
-  cudaResult = hipFuncGetAttributes(&funcAttributes, computeValue<Real>);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not get function attributes: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
-    throw std::runtime_error(
-        "Block X dimension is too large for computeValue kernel");
-  }
-
-  // Check the dimensions are valid
-  if (block.x > (unsigned int)deviceProperties.maxThreadsDim[0]) {
-    throw std::runtime_error("Block X dimension is too large for device");
-  }
-
-  if (grid.x > (unsigned int)deviceProperties.maxGridSize[0]) {
-    throw std::runtime_error("Grid X dimension is too large for device");
-  }
-
-  // Allocate memory for RNG states
-  hiprandState *d_rngStates = 0;
-  cudaResult =
-      hipMalloc((void **)&d_rngStates, grid.x * block.x * sizeof(hiprandState));
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not allocate memory on device for RNG states: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Allocate memory for result
-  // Each thread block will produce one result
-  unsigned int *d_results = 0;
-  cudaResult = hipMalloc((void **)&d_results, grid.x * sizeof(unsigned int));
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not allocate memory on device for partial results: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Initialise RNG
-  initRNG<<<grid, block>>>(d_rngStates, m_seed);
-
-  // Count the points inside unit quarter-circle
-  computeValue<Real><<<grid, block, block.x * sizeof(unsigned int)>>>(
-      d_results, d_rngStates, m_numSims);
-
-  // Copy partial results back
-  vector<unsigned int> results(grid.x);
-  cudaResult = hipMemcpy(&results[0], d_results, grid.x * sizeof(unsigned int),
-                          hipMemcpyDeviceToHost);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not copy partial results to host: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Complete sum-reduction on host
-  Real value =
-      static_cast<Real>(std::accumulate(results.begin(), results.end(), 0));
-
-  // Determine the proportion of points inside the quarter-circle,
-  // i.e. the area of the unit quarter-circle
-  value /= m_numSims;
-
-  // Value is currently an estimate of the area of a unit quarter-circle, so we
-  // can scale to a full circle by multiplying by four. Now since the area of a
-  // circle is pi * r^2, and r is one, the value will be an estimate for the
-  // value of pi.
-  value *= 4;
-
-  // Cleanup
-  if (d_rngStates) {
-    hipFree(d_rngStates);
-    d_rngStates = 0;
-  }
-
-  if (d_results) {
-    hipFree(d_results);
-    d_results = 0;
-  }
-
-  return value;
-}
-
-// Explicit template instantiation
-template class PiEstimator<float>;
-template class PiEstimator<double>;
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/test.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/test.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/test_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineP/src/test_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/MC_EstimatePiInlineQ_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/README.md b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/inc/cudasharedmem.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/inc/cudasharedmem.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/inc/cudasharedmem_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/inc/cudasharedmem_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/inc/piestimator.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/inc/piestimator.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/inc/piestimator_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/inc/piestimator_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/inc/test.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/inc/test.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/inc/test_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/inc/test_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/main.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/main_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/piestimator.cu b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/piestimator.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/piestimator.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/piestimator.cu.hip
old mode 100644
new mode 100755
index 1af6884..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/piestimator.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/piestimator.cu.hip
@@ -1,394 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-
-#include "../inc/piestimator.h"
-
-#include <string>
-#include <vector>
-#include <numeric>
-#include <stdexcept>
-#include <typeinfo>
-#include <hip/hip_runtime.h>
- #include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-#include <hiprand.h>
-#include <hiprand_kernel.h>
-
-#include "../inc/cudasharedmem.h"
-
-using std::string;
-using std::vector;
-
-// Helper templates to support float and double in same code
-template <typename L, typename R>
-struct TYPE_IS {
-  static const bool test = false;
-};
-template <typename L>
-struct TYPE_IS<L, L> {
-  static const bool test = true;
-};
-template <bool, class L, class R>
-struct IF {
-  typedef R type;
-};
-template <class L, class R>
-struct IF<true, L, R> {
-  typedef L type;
-};
-
-// RNG init kernel
-template <typename rngState_t, typename rngDirectionVectors_t>
-__global__ void initRNG(rngState_t *const rngStates,
-                        rngDirectionVectors_t *const rngDirections,
-                        unsigned int numDrawsPerDirection) {
-  // Determine thread ID
-  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int step = gridDim.x * blockDim.x;
-
-  // Determine offset to avoid overlapping sub-sequences
-  unsigned int offset = tid * ((numDrawsPerDirection + step - 1) / step);
-
-  // Initialise the RNG
-  hiprand_init(rngDirections[0], offset, &rngStates[tid]);
-  hiprand_init(rngDirections[1], offset, &rngStates[tid + step]);
-}
-
-__device__ unsigned int reduce_sum(unsigned int in, cg::thread_block cta) {
-  extern __shared__ unsigned int sdata[];
-
-  // Perform first level of reduction:
-  // - Write to shared memory
-  unsigned int ltid = threadIdx.x;
-
-  sdata[ltid] = in;
-  cg::sync(cta);
-
-  // Do reduction in shared mem
-  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
-    if (ltid < s) {
-      sdata[ltid] += sdata[ltid + s];
-    }
-
-    cg::sync(cta);
-  }
-
-  return sdata[0];
-}
-
-__device__ inline void getPoint(float &x, float &y, hiprandStateSobol32 &state1,
-                                hiprandStateSobol32 &state2) {
-  x = hiprand_uniform(&state1);
-  y = hiprand_uniform(&state2);
-}
-__device__ inline void getPoint(double &x, double &y,
-                                curandStateSobol64 &state1,
-                                curandStateSobol64 &state2) {
-  x = hiprand_uniform_double(&state1);
-  y = hiprand_uniform_double(&state2);
-}
-
-// Estimator kernel
-template <typename Real, typename rngState_t>
-__global__ void computeValue(unsigned int *const results,
-                             rngState_t *const rngStates,
-                             const unsigned int numSims) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  // Determine thread ID
-  unsigned int bid = blockIdx.x;
-  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int step = gridDim.x * blockDim.x;
-
-  // Initialise the RNG
-  rngState_t localState1 = rngStates[tid];
-  rngState_t localState2 = rngStates[tid + step];
-
-  // Count the number of points which lie inside the unit quarter-circle
-  unsigned int pointsInside = 0;
-
-  for (unsigned int i = tid; i < numSims; i += step) {
-    Real x;
-    Real y;
-    getPoint(x, y, localState1, localState2);
-    Real l2norm2 = x * x + y * y;
-
-    if (l2norm2 < static_cast<Real>(1)) {
-      pointsInside++;
-    }
-  }
-
-  // Reduce within the block
-  pointsInside = reduce_sum(pointsInside, cta);
-
-  // Store the result
-  if (threadIdx.x == 0) {
-    results[bid] = pointsInside;
-  }
-}
-
-template <typename Real>
-PiEstimator<Real>::PiEstimator(unsigned int numSims, unsigned int device,
-                               unsigned int threadBlockSize)
-    : m_numSims(numSims),
-      m_device(device),
-      m_threadBlockSize(threadBlockSize) {}
-
-template <typename Real>
-Real PiEstimator<Real>::operator()() {
-  hipError_t cudaResult = hipSuccess;
-  struct hipDeviceProp_t deviceProperties;
-  struct hipFuncAttributes funcAttributes;
-
-  // Determine type of generator to use (32- or 64-bit)
-  typedef typename IF<TYPE_IS<Real, double>::test, curandStateSobol64_t,
-                      hiprandStateSobol32_t>::type curandStateSobol_sz;
-  typedef
-      typename IF<TYPE_IS<Real, double>::test, curandDirectionVectors64_t,
-                  hiprandDirectionVectors32_t>::type curandDirectionVectors_sz;
-
-  // Get device properties
-  cudaResult = hipGetDeviceProperties(&deviceProperties, m_device);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not get device properties: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Check precision is valid
-  if (typeid(Real) == typeid(double) &&
-      (deviceProperties.major < 1 ||
-       (deviceProperties.major == 1 && deviceProperties.minor < 3))) {
-    throw std::runtime_error("Device does not have double precision support");
-  }
-
-  // Attach to GPU
-  cudaResult = hipSetDevice(m_device);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not set CUDA device: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Determine how to divide the work between cores
-  dim3 block;
-  dim3 grid;
-  block.x = m_threadBlockSize;
-  grid.x = (m_numSims + m_threadBlockSize - 1) / m_threadBlockSize;
-
-  // Aim to launch around ten or more times as many blocks as there
-  // are multiprocessors on the target device.
-  unsigned int blocksPerSM = 10;
-  unsigned int numSMs = deviceProperties.multiProcessorCount;
-
-  while (grid.x > 2 * blocksPerSM * numSMs) {
-    grid.x >>= 1;
-  }
-
-  // Get initRNG function properties and check the maximum block size
-  cudaResult = hipFuncGetAttributes(
-      &funcAttributes, initRNG<curandStateSobol_sz, curandDirectionVectors_sz>);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not get function attributes: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
-    throw std::runtime_error(
-        "Block X dimension is too large for initRNG kernel");
-  }
-
-  // Get computeValue function properties and check the maximum block size
-  cudaResult = hipFuncGetAttributes(&funcAttributes,
-                                     computeValue<Real, curandStateSobol_sz>);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not get function attributes: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
-    throw std::runtime_error(
-        "Block X dimension is too large for computeValue kernel");
-  }
-
-  // Check the dimensions are valid
-  if (block.x > (unsigned int)deviceProperties.maxThreadsDim[0]) {
-    throw std::runtime_error("Block X dimension is too large for device");
-  }
-
-  if (grid.x > (unsigned int)deviceProperties.maxGridSize[0]) {
-    throw std::runtime_error("Grid X dimension is too large for device");
-  }
-
-  // Allocate memory for RNG states and direction vectors
-  curandStateSobol_sz *d_rngStates = 0;
-  curandDirectionVectors_sz *d_rngDirections = 0;
-  cudaResult = hipMalloc((void **)&d_rngStates,
-                          2 * grid.x * block.x * sizeof(curandStateSobol_sz));
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not allocate memory on device for RNG states: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  cudaResult = hipMalloc((void **)&d_rngDirections,
-                          2 * sizeof(curandDirectionVectors_sz));
-
-  if (cudaResult != hipSuccess) {
-    string msg(
-        "Could not allocate memory on device for RNG direction vectors: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Allocate memory for result
-  // Each thread block will produce one result
-  unsigned int *d_results = 0;
-  cudaResult = hipMalloc((void **)&d_results, grid.x * sizeof(unsigned int));
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not allocate memory on device for partial results: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Generate direction vectors on the host and copy to the device
-  if (typeid(Real) == typeid(float)) {
-    hiprandDirectionVectors32_t *rngDirections;
-    hiprandStatus_t curandResult = curandGetDirectionVectors32(
-        &rngDirections, CURAND_DIRECTION_VECTORS_32_JOEKUO6);
-
-    if (curandResult != HIPRAND_STATUS_SUCCESS) {
-      string msg(
-          "Could not get direction vectors for quasi-random number "
-          "generator: ");
-      msg += curandResult;
-      throw std::runtime_error(msg);
-    }
-
-    cudaResult = hipMemcpy(d_rngDirections, rngDirections,
-                            2 * sizeof(hiprandDirectionVectors32_t),
-                            hipMemcpyHostToDevice);
-
-    if (cudaResult != hipSuccess) {
-      string msg("Could not copy direction vectors to device: ");
-      msg += hipGetErrorString(cudaResult);
-      throw std::runtime_error(msg);
-    }
-  } else if (typeid(Real) == typeid(double)) {
-    curandDirectionVectors64_t *rngDirections;
-    hiprandStatus_t curandResult = curandGetDirectionVectors64(
-        &rngDirections, CURAND_DIRECTION_VECTORS_64_JOEKUO6);
-
-    if (curandResult != HIPRAND_STATUS_SUCCESS) {
-      string msg(
-          "Could not get direction vectors for quasi-random number "
-          "generator: ");
-      msg += curandResult;
-      throw std::runtime_error(msg);
-    }
-
-    cudaResult = hipMemcpy(d_rngDirections, rngDirections,
-                            2 * sizeof(curandDirectionVectors64_t),
-                            hipMemcpyHostToDevice);
-
-    if (cudaResult != hipSuccess) {
-      string msg("Could not copy direction vectors to device: ");
-      msg += hipGetErrorString(cudaResult);
-      throw std::runtime_error(msg);
-    }
-  } else {
-    string msg(
-        "Could not get direction vectors for random number generator of "
-        "specified type");
-    throw std::runtime_error(msg);
-  }
-
-  // Initialise RNG
-  initRNG<<<grid, block>>>(d_rngStates, d_rngDirections, m_numSims);
-
-  // Count the points inside unit quarter-circle
-  computeValue<Real><<<grid, block, block.x * sizeof(unsigned int)>>>(
-      d_results, d_rngStates, m_numSims);
-
-  // Copy partial results back
-  vector<unsigned int> results(grid.x);
-  cudaResult = hipMemcpy(&results[0], d_results, grid.x * sizeof(unsigned int),
-                          hipMemcpyDeviceToHost);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not copy partial results to host: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Complete sum-reduction on host
-  Real value =
-      static_cast<Real>(std::accumulate(results.begin(), results.end(), 0));
-
-  // Determine the proportion of points inside the quarter-circle,
-  // i.e. the area of the unit quarter-circle
-  value /= m_numSims;
-
-  // Value is currently an estimate of the area of a unit quarter-circle, so we
-  // can scale to a full circle by multiplying by four. Now since the area of a
-  // circle is pi * r^2, and r is one, the value will be an estimate for the
-  // value of pi.
-  value *= 4;
-
-  // Cleanup
-  if (d_rngStates) {
-    hipFree(d_rngStates);
-    d_rngStates = 0;
-  }
-
-  if (d_rngDirections) {
-    hipFree(d_rngDirections);
-    d_rngDirections = 0;
-  }
-
-  if (d_results) {
-    hipFree(d_results);
-    d_results = 0;
-  }
-
-  return value;
-}
-
-// Explicit template instantiation
-template class PiEstimator<float>;
-template class PiEstimator<double>;
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/test.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/test.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/test_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiInlineQ/src/test_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/MC_EstimatePiP_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/README.md b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/inc/cudasharedmem.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/inc/cudasharedmem.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/inc/cudasharedmem_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/inc/cudasharedmem_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/inc/piestimator.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/inc/piestimator.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/inc/piestimator_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/inc/piestimator_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/inc/test.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/inc/test.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/inc/test_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/inc/test_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/main.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/main_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/piestimator.cu b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/piestimator.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/piestimator.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/piestimator.cu.hip
old mode 100644
new mode 100755
index b71421d..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/piestimator.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/piestimator.cu.hip
@@ -1,294 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "../inc/piestimator.h"
-
-#include <string>
-#include <vector>
-#include <numeric>
-#include <stdexcept>
-#include <typeinfo>
-#include <hip/hip_runtime.h>
- #include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-#include <hiprand.h>
-
-using std::string;
-using std::vector;
-
-__device__ unsigned int reduce_sum(unsigned int in, cg::thread_block cta) {
-  extern __shared__ unsigned int sdata[];
-
-  // Perform first level of reduction:
-  // - Write to shared memory
-  unsigned int ltid = threadIdx.x;
-
-  sdata[ltid] = in;
-  cg::sync(cta);
-
-  // Do reduction in shared mem
-  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
-    if (ltid < s) {
-      sdata[ltid] += sdata[ltid + s];
-    }
-
-    cg::sync(cta);
-  }
-
-  return sdata[0];
-}
-
-// Estimator kernel
-template <typename Real>
-__global__ void computeValue(unsigned int *const results,
-                             const Real *const points,
-                             const unsigned int numSims) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  // Determine thread ID
-  unsigned int bid = blockIdx.x;
-  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int step = gridDim.x * blockDim.x;
-
-  // Shift the input/output pointers
-  const Real *pointx = points + tid;
-  const Real *pointy = pointx + numSims;
-
-  // Count the number of points which lie inside the unit quarter-circle
-  unsigned int pointsInside = 0;
-
-  for (unsigned int i = tid; i < numSims;
-       i += step, pointx += step, pointy += step) {
-    Real x = *pointx;
-    Real y = *pointy;
-    Real l2norm2 = x * x + y * y;
-
-    if (l2norm2 < static_cast<Real>(1)) {
-      pointsInside++;
-    }
-  }
-
-  // Reduce within the block
-  pointsInside = reduce_sum(pointsInside, cta);
-
-  // Store the result
-  if (threadIdx.x == 0) {
-    results[bid] = pointsInside;
-  }
-}
-
-template <typename Real>
-PiEstimator<Real>::PiEstimator(unsigned int numSims, unsigned int device,
-                               unsigned int threadBlockSize, unsigned int seed)
-    : m_numSims(numSims),
-      m_device(device),
-      m_threadBlockSize(threadBlockSize),
-      m_seed(seed) {}
-
-template <typename Real>
-Real PiEstimator<Real>::operator()() {
-  hipError_t cudaResult = hipSuccess;
-  struct hipDeviceProp_t deviceProperties;
-  struct hipFuncAttributes funcAttributes;
-
-  // Get device properties
-  cudaResult = hipGetDeviceProperties(&deviceProperties, m_device);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not get device properties: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Check precision is valid
-  if (typeid(Real) == typeid(double) &&
-      (deviceProperties.major < 1 ||
-       (deviceProperties.major == 1 && deviceProperties.minor < 3))) {
-    throw std::runtime_error("Device does not have double precision support");
-  }
-
-  // Attach to GPU
-  cudaResult = hipSetDevice(m_device);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not set CUDA device: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Determine how to divide the work between cores
-  dim3 block;
-  dim3 grid;
-  block.x = m_threadBlockSize;
-  grid.x = (m_numSims + m_threadBlockSize - 1) / m_threadBlockSize;
-
-  // Aim to launch around ten or more times as many blocks as there
-  // are multiprocessors on the target device.
-  unsigned int blocksPerSM = 10;
-  unsigned int numSMs = deviceProperties.multiProcessorCount;
-
-  while (grid.x > 2 * blocksPerSM * numSMs) {
-    grid.x >>= 1;
-  }
-
-  // Get computeValue function properties and check the maximum block size
-  cudaResult = hipFuncGetAttributes(&funcAttributes, computeValue<Real>);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not get function attributes: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
-    throw std::runtime_error(
-        "Block X dimension is too large for computeValue kernel");
-  }
-
-  // Check the dimensions are valid
-  if (block.x > (unsigned int)deviceProperties.maxThreadsDim[0]) {
-    throw std::runtime_error("Block X dimension is too large for device");
-  }
-
-  if (grid.x > (unsigned int)deviceProperties.maxGridSize[0]) {
-    throw std::runtime_error("Grid X dimension is too large for device");
-  }
-
-  // Allocate memory for points
-  // Each simulation has two random numbers to give X and Y coordinate
-  Real *d_points = 0;
-  cudaResult = hipMalloc((void **)&d_points, 2 * m_numSims * sizeof(Real));
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not allocate memory on device for random numbers: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Allocate memory for result
-  // Each thread block will produce one result
-  unsigned int *d_results = 0;
-  cudaResult = hipMalloc((void **)&d_results, grid.x * sizeof(unsigned int));
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not allocate memory on device for partial results: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Generate random points in unit square
-  hiprandStatus_t curandResult;
-  hiprandGenerator_t prng;
-  curandResult = hiprandCreateGenerator(&prng, HIPRAND_RNG_PSEUDO_DEFAULT);
-
-  if (curandResult != HIPRAND_STATUS_SUCCESS) {
-    string msg("Could not create pseudo-random number generator: ");
-    msg += curandResult;
-    throw std::runtime_error(msg);
-  }
-
-  curandResult = hiprandSetPseudoRandomGeneratorSeed(prng, m_seed);
-
-  if (curandResult != HIPRAND_STATUS_SUCCESS) {
-    string msg("Could not set seed for pseudo-random number generator: ");
-    msg += curandResult;
-    throw std::runtime_error(msg);
-  }
-
-  if (typeid(Real) == typeid(float)) {
-    curandResult =
-        hiprandGenerateUniform(prng, (float *)d_points, 2 * m_numSims);
-  } else if (typeid(Real) == typeid(double)) {
-    curandResult =
-        hiprandGenerateUniformDouble(prng, (double *)d_points, 2 * m_numSims);
-  } else {
-    string msg("Could not generate random numbers of specified type");
-    throw std::runtime_error(msg);
-  }
-
-  if (curandResult != HIPRAND_STATUS_SUCCESS) {
-    string msg("Could not generate pseudo-random numbers: ");
-    msg += curandResult;
-    throw std::runtime_error(msg);
-  }
-
-  curandResult = hiprandDestroyGenerator(prng);
-
-  if (curandResult != HIPRAND_STATUS_SUCCESS) {
-    string msg("Could not destroy pseudo-random number generator: ");
-    msg += curandResult;
-    throw std::runtime_error(msg);
-  }
-
-  // Count the points inside unit quarter-circle
-  computeValue<Real><<<grid, block, block.x * sizeof(unsigned int)>>>(
-      d_results, d_points, m_numSims);
-
-  // Copy partial results back
-  vector<unsigned int> results(grid.x);
-  cudaResult = hipMemcpy(&results[0], d_results, grid.x * sizeof(unsigned int),
-                          hipMemcpyDeviceToHost);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not copy partial results to host: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Complete sum-reduction on host
-  Real value =
-      static_cast<Real>(std::accumulate(results.begin(), results.end(), 0));
-
-  // Determine the proportion of points inside the quarter-circle,
-  // i.e. the area of the unit quarter-circle
-  value /= m_numSims;
-
-  // Value is currently an estimate of the area of a unit quarter-circle, so we
-  // can scale to a full circle by multiplying by four. Now since the area of a
-  // circle is pi * r^2, and r is one, the value will be an estimate for the
-  // value of pi.
-  value *= 4;
-
-  // Cleanup
-  if (d_points) {
-    hipFree(d_points);
-    d_points = 0;
-  }
-
-  if (d_results) {
-    hipFree(d_results);
-    d_results = 0;
-  }
-
-  return value;
-}
-
-// Explicit template instantiation
-template class PiEstimator<float>;
-template class PiEstimator<double>;
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/test.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/test.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/test_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiP/src/test_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/MC_EstimatePiQ_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/README.md b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/inc/cudasharedmem.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/inc/cudasharedmem.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/inc/cudasharedmem_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/inc/cudasharedmem_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/inc/piestimator.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/inc/piestimator.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/inc/piestimator_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/inc/piestimator_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/inc/test.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/inc/test.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/inc/test_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/inc/test_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/main.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/main_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/piestimator.cu b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/piestimator.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/piestimator.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/piestimator.cu.hip
old mode 100644
new mode 100755
index 581aa2c..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/piestimator.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/piestimator.cu.hip
@@ -1,312 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "../inc/piestimator.h"
-
-#include <string>
-#include <vector>
-#include <numeric>
-#include <stdexcept>
-#include <typeinfo>
-#include <hip/hip_runtime.h>
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-#include <hiprand.h>
-
-using std::string;
-using std::vector;
-
-__device__ unsigned int reduce_sum(unsigned int in, cg::thread_block cta) {
-  extern __shared__ unsigned int sdata[];
-
-  // Perform first level of reduction:
-  // - Write to shared memory
-  unsigned int ltid = threadIdx.x;
-
-  sdata[ltid] = in;
-  cg::sync(cta);
-
-  // Do reduction in shared mem
-  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
-    if (ltid < s) {
-      sdata[ltid] += sdata[ltid + s];
-    }
-
-    cg::sync(cta);
-  }
-
-  return sdata[0];
-}
-
-// Estimator kernel
-template <typename Real>
-__global__ void computeValue(unsigned int *const results,
-                             const Real *const points,
-                             const unsigned int numSims) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  // Determine thread ID
-  unsigned int bid = blockIdx.x;
-  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int step = gridDim.x * blockDim.x;
-
-  // Shift the input/output pointers
-  const Real *pointx = points + tid;
-  const Real *pointy = pointx + numSims;
-
-  // Count the number of points which lie inside the unit quarter-circle
-  unsigned int pointsInside = 0;
-
-  for (unsigned int i = tid; i < numSims;
-       i += step, pointx += step, pointy += step) {
-    Real x = *pointx;
-    Real y = *pointy;
-    Real l2norm2 = x * x + y * y;
-
-    if (l2norm2 < static_cast<Real>(1)) {
-      pointsInside++;
-    }
-  }
-
-  // Reduce within the block
-  pointsInside = reduce_sum(pointsInside, cta);
-
-  // Store the result
-  if (threadIdx.x == 0) {
-    results[bid] = pointsInside;
-  }
-}
-
-template <typename Real>
-PiEstimator<Real>::PiEstimator(unsigned int numSims, unsigned int device,
-                               unsigned int threadBlockSize)
-    : m_numSims(numSims),
-      m_device(device),
-      m_threadBlockSize(threadBlockSize) {}
-
-template <typename Real>
-Real PiEstimator<Real>::operator()() {
-  hipError_t cudaResult = hipSuccess;
-  struct hipDeviceProp_t deviceProperties;
-  struct hipFuncAttributes funcAttributes;
-
-  // Get device properties
-  cudaResult = hipGetDeviceProperties(&deviceProperties, m_device);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not get device properties: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Check precision is valid
-  if (typeid(Real) == typeid(double) &&
-      (deviceProperties.major < 1 ||
-       (deviceProperties.major == 1 && deviceProperties.minor < 3))) {
-    throw std::runtime_error("Device does not have double precision support");
-  }
-
-  // Attach to GPU
-  cudaResult = hipSetDevice(m_device);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not set CUDA device: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Determine how to divide the work between cores
-  dim3 block;
-  dim3 grid;
-  block.x = m_threadBlockSize;
-  grid.x = (m_numSims + m_threadBlockSize - 1) / m_threadBlockSize;
-
-  // Aim to launch around ten or more times as many blocks as there
-  // are multiprocessors on the target device.
-  unsigned int blocksPerSM = 10;
-  unsigned int numSMs = deviceProperties.multiProcessorCount;
-
-  while (grid.x > 2 * blocksPerSM * numSMs) {
-    grid.x >>= 1;
-  }
-
-  // Get computeValue function properties and check the maximum block size
-  cudaResult = hipFuncGetAttributes(&funcAttributes, computeValue<Real>);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not get function attributes: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
-    throw std::runtime_error(
-        "Block X dimension is too large for computeValue kernel");
-  }
-
-  // Check the dimensions are valid
-  if (block.x > (unsigned int)deviceProperties.maxThreadsDim[0]) {
-    throw std::runtime_error("Block X dimension is too large for device");
-  }
-
-  if (grid.x > (unsigned int)deviceProperties.maxGridSize[0]) {
-    throw std::runtime_error("Grid X dimension is too large for device");
-  }
-
-  // Allocate memory for points
-  // Each simulation has two random numbers to give X and Y coordinate
-  Real *d_points = 0;
-  cudaResult = hipMalloc((void **)&d_points, 2 * m_numSims * sizeof(Real));
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not allocate memory on device for random numbers: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Allocate memory for result
-  // Each thread block will produce one result
-  unsigned int *d_results = 0;
-  cudaResult = hipMalloc((void **)&d_results, grid.x * sizeof(unsigned int));
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not allocate memory on device for partial results: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Generate random points in unit square
-  hiprandStatus_t curandResult;
-  hiprandGenerator_t qrng;
-
-  if (typeid(Real) == typeid(float)) {
-    curandResult = hiprandCreateGenerator(&qrng, HIPRAND_RNG_QUASI_SOBOL32);
-  } else if (typeid(Real) == typeid(double)) {
-    curandResult = hiprandCreateGenerator(&qrng, HIPRAND_RNG_QUASI_SOBOL64);
-  } else {
-    string msg("Could not create random number generator of specified type");
-    throw std::runtime_error(msg);
-  }
-
-  if (curandResult != HIPRAND_STATUS_SUCCESS) {
-    string msg("Could not create quasi-random number generator: ");
-    msg += curandResult;
-    throw std::runtime_error(msg);
-  }
-
-  curandResult = hiprandSetQuasiRandomGeneratorDimensions(qrng, 2);
-
-  if (curandResult != HIPRAND_STATUS_SUCCESS) {
-    string msg(
-        "Could not set number of dimensions for quasi-random number "
-        "generator: ");
-    msg += curandResult;
-    throw std::runtime_error(msg);
-  }
-
-  curandResult =
-      curandSetGeneratorOrdering(qrng, CURAND_ORDERING_QUASI_DEFAULT);
-
-  if (curandResult != HIPRAND_STATUS_SUCCESS) {
-    string msg("Could not set order for quasi-random number generator: ");
-    msg += curandResult;
-    throw std::runtime_error(msg);
-  }
-
-  if (typeid(Real) == typeid(float)) {
-    curandResult =
-        hiprandGenerateUniform(qrng, (float *)d_points, 2 * m_numSims);
-  } else if (typeid(Real) == typeid(double)) {
-    curandResult =
-        hiprandGenerateUniformDouble(qrng, (double *)d_points, 2 * m_numSims);
-  } else {
-    string msg("Could not generate random numbers of specified type");
-    throw std::runtime_error(msg);
-  }
-
-  if (curandResult != HIPRAND_STATUS_SUCCESS) {
-    string msg("Could not generate quasi-random numbers: ");
-    msg += curandResult;
-    throw std::runtime_error(msg);
-  }
-
-  curandResult = hiprandDestroyGenerator(qrng);
-
-  if (curandResult != HIPRAND_STATUS_SUCCESS) {
-    string msg("Could not destroy quasi-random number generator: ");
-    msg += curandResult;
-    throw std::runtime_error(msg);
-  }
-
-  // Count the points inside unit quarter-circle
-  computeValue<Real><<<grid, block, block.x * sizeof(unsigned int)>>>(
-      d_results, d_points, m_numSims);
-
-  // Copy partial results back
-  vector<unsigned int> results(grid.x);
-  cudaResult = hipMemcpy(&results[0], d_results, grid.x * sizeof(unsigned int),
-                          hipMemcpyDeviceToHost);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not copy partial results to host: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Complete sum-reduction on host
-  Real value =
-      static_cast<Real>(std::accumulate(results.begin(), results.end(), 0));
-
-  // Determine the proportion of points inside the quarter-circle,
-  // i.e. the area of the unit quarter-circle
-  value /= m_numSims;
-
-  // Value is currently an estimate of the area of a unit quarter-circle, so we
-  // can scale to a full circle by multiplying by four. Now since the area of a
-  // circle is pi * r^2, and r is one, the value will be an estimate for the
-  // value of pi.
-  value *= 4;
-
-  // Cleanup
-  if (d_points) {
-    hipFree(d_points);
-    d_points = 0;
-  }
-
-  if (d_results) {
-    hipFree(d_results);
-    d_results = 0;
-  }
-
-  return value;
-}
-
-// Explicit template instantiation
-template class PiEstimator<float>;
-template class PiEstimator<double>;
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/test.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/test.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/test_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_EstimatePiQ/src/test_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/MC_SingleAsianOptionP_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/README.md b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/asianoption.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/asianoption.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/asianoption_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/asianoption_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/cudasharedmem.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/cudasharedmem.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/cudasharedmem_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/cudasharedmem_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/pricingengine.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/pricingengine.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/pricingengine_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/pricingengine_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/test.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/test.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/test_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/inc/test_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/main.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/main_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/pricingengine.cu b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/pricingengine.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/pricingengine.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/pricingengine.cu.hip
old mode 100644
new mode 100755
index ba594cb..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/pricingengine.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/pricingengine.cu.hip
@@ -1,375 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "../inc/pricingengine.h"
-
-#include <string>
-#include <vector>
-#include <numeric>
-#include <stdexcept>
-#include <typeinfo>
-#include <hip/hip_runtime.h>
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-#include <hiprand_kernel.h>
-
-#include "../inc/asianoption.h"
-#include "../inc/cudasharedmem.h"
-
-using std::string;
-using std::vector;
-
-// RNG init kernel
-__global__ void initRNG(hiprandState *const rngStates, const unsigned int seed) {
-  // Determine thread ID
-  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
-
-  // Initialise the RNG
-  hiprand_init(seed, tid, 0, &rngStates[tid]);
-}
-
-__device__ inline float getPathStep(float &drift, float &diffusion,
-                                    hiprandState &state) {
-  return expf(drift + diffusion * hiprand_normal(&state));
-}
-__device__ inline double getPathStep(double &drift, double &diffusion,
-                                     hiprandState &state) {
-  return exp(drift + diffusion * hiprand_normal_double(&state));
-}
-
-// Path generation kernel
-template <typename Real>
-__global__ void generatePaths(Real *const paths, hiprandState *const rngStates,
-                              const AsianOption<Real> *const option,
-                              const unsigned int numSims,
-                              const unsigned int numTimesteps) {
-  // Determine thread ID
-  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int step = gridDim.x * blockDim.x;
-
-  // Compute parameters
-  Real drift =
-      (option->r - static_cast<Real>(0.5) * option->sigma * option->sigma) *
-      option->dt;
-  Real diffusion = option->sigma * sqrt(option->dt);
-
-  // Initialise the RNG
-  hiprandState localState = rngStates[tid];
-
-  for (unsigned int i = tid; i < numSims; i += step) {
-    // Shift the output pointer
-    Real *output = paths + i;
-
-    // Simulate the path
-    Real s = static_cast<Real>(1);
-
-    for (unsigned int t = 0; t < numTimesteps; t++, output += numSims) {
-      s *= getPathStep(drift, diffusion, localState);
-      *output = s;
-    }
-  }
-}
-
-template <typename Real>
-__device__ Real reduce_sum(Real in, cg::thread_block cta) {
-  SharedMemory<Real> sdata;
-
-  // Perform first level of reduction:
-  // - Write to shared memory
-  unsigned int ltid = threadIdx.x;
-
-  sdata[ltid] = in;
-  cg::sync(cta);
-
-  // Do reduction in shared mem
-  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
-    if (ltid < s) {
-      sdata[ltid] += sdata[ltid + s];
-    }
-
-    cg::sync(cta);
-  }
-
-  return sdata[0];
-}
-
-// Valuation kernel
-template <typename Real>
-__global__ void computeValue(Real *const values, const Real *const paths,
-                             const AsianOption<Real> *const option,
-                             const unsigned int numSims,
-                             const unsigned int numTimesteps) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  // Determine thread ID
-  unsigned int bid = blockIdx.x;
-  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int step = gridDim.x * blockDim.x;
-
-  Real sumPayoffs = static_cast<Real>(0);
-
-  for (unsigned int i = tid; i < numSims; i += step) {
-    // Shift the input pointer
-    const Real *path = paths + i;
-    // Compute the arithmetic average
-    Real avg = static_cast<Real>(0);
-
-    for (unsigned int t = 0; t < numTimesteps; t++, path += numSims) {
-      avg += *path;
-    }
-
-    avg = avg * option->spot / numTimesteps;
-    // Compute the payoff
-    Real payoff = avg - option->strike;
-
-    if (option->type == AsianOption<Real>::Put) {
-      payoff = -payoff;
-    }
-
-    payoff = max(static_cast<Real>(0), payoff);
-    // Accumulate payoff locally
-    sumPayoffs += payoff;
-  }
-
-  // Reduce within the block
-  sumPayoffs = reduce_sum<Real>(sumPayoffs, cta);
-
-  // Store the result
-  if (threadIdx.x == 0) {
-    values[bid] = sumPayoffs;
-  }
-}
-
-template <typename Real>
-PricingEngine<Real>::PricingEngine(unsigned int numSims, unsigned int device,
-                                   unsigned int threadBlockSize,
-                                   unsigned int seed)
-    : m_numSims(numSims),
-      m_device(device),
-      m_threadBlockSize(threadBlockSize),
-      m_seed(seed) {}
-
-template <typename Real>
-void PricingEngine<Real>::operator()(AsianOption<Real> &option) {
-  hipError_t cudaResult = hipSuccess;
-  struct hipDeviceProp_t deviceProperties;
-  struct hipFuncAttributes funcAttributes;
-
-  // Get device properties
-  cudaResult = hipGetDeviceProperties(&deviceProperties, m_device);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not get device properties: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Check precision is valid
-  unsigned int deviceVersion =
-      deviceProperties.major * 10 + deviceProperties.minor;
-
-  if (typeid(Real) == typeid(double) && deviceVersion < 13) {
-    throw std::runtime_error("Device does not have double precision support");
-  }
-
-  // Attach to GPU
-  cudaResult = hipSetDevice(m_device);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not set CUDA device: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Determine how to divide the work between cores
-  dim3 block;
-  dim3 grid;
-  block.x = m_threadBlockSize;
-  grid.x = (m_numSims + m_threadBlockSize - 1) / m_threadBlockSize;
-
-  // Aim to launch around ten or more times as many blocks as there
-  // are multiprocessors on the target device.
-  unsigned int blocksPerSM = 10;
-  unsigned int numSMs = deviceProperties.multiProcessorCount;
-
-  while (grid.x > 2 * blocksPerSM * numSMs) {
-    grid.x >>= 1;
-  }
-
-  // Get initRNG function properties and check the maximum block size
-  cudaResult = hipFuncGetAttributes(&funcAttributes,(const void*) initRNG);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not get function attributes: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
-    throw std::runtime_error(
-        "Block X dimension is too large for initRNG kernel");
-  }
-
-  // Get generatePaths function properties and check the maximum block size
-  cudaResult = hipFuncGetAttributes(&funcAttributes, (const void*)generatePaths<Real>);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not get function attributes: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
-    throw std::runtime_error(
-        "Block X dimension is too large for generatePaths kernel");
-  }
-
-  // Get computeValue function properties and check the maximum block size
-  cudaResult = hipFuncGetAttributes(&funcAttributes,(const void*) computeValue<Real>);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not get function attributes: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  if (block.x > (unsigned int)funcAttributes.maxThreadsPerBlock) {
-    throw std::runtime_error(
-        "Block X dimension is too large for computeValue kernel");
-  }
-
-  // Setup problem on GPU
-  AsianOption<Real> *d_option = 0;
-  cudaResult = hipMalloc((void **)&d_option, sizeof(AsianOption<Real>));
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not allocate memory on device for option data: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  cudaResult = hipMemcpy(d_option, &option, sizeof(AsianOption<Real>),
-                          hipMemcpyHostToDevice);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not copy data to device: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Allocate memory for paths
-  Real *d_paths = 0;
-  int numTimesteps = static_cast<int>(option.tenor / option.dt);
-  cudaResult =
-      hipMalloc((void **)&d_paths, m_numSims * numTimesteps * sizeof(Real));
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not allocate memory on device for paths: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Allocate memory for RNG states
-  hiprandState *d_rngStates = 0;
-  cudaResult =
-      hipMalloc((void **)&d_rngStates, grid.x * block.x * sizeof(hiprandState));
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not allocate memory on device for RNG state: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Allocate memory for result
-  Real *d_values = 0;
-  cudaResult = hipMalloc((void **)&d_values, grid.x * sizeof(Real));
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not allocate memory on device for partial results: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Initialise RNG
-  initRNG<<<grid, block>>>(d_rngStates, m_seed);
-
-  // Generate paths
-  generatePaths<Real><<<grid, block>>>(d_paths, d_rngStates, d_option,
-                                       m_numSims, numTimesteps);
-
-  // Compute value
-  computeValue<<<grid, block, block.x * sizeof(Real)>>>(
-      d_values, d_paths, d_option, m_numSims, numTimesteps);
-
-  // Copy partial results back
-  vector<Real> values(grid.x);
-  cudaResult = hipMemcpy(&values[0], d_values, grid.x * sizeof(Real),
-                          hipMemcpyDeviceToHost);
-
-  if (cudaResult != hipSuccess) {
-    string msg("Could not copy partial results to host: ");
-    msg += hipGetErrorString(cudaResult);
-    throw std::runtime_error(msg);
-  }
-
-  // Complete sum-reduction on host
-  option.value =
-      std::accumulate(values.begin(), values.end(), static_cast<Real>(0));
-
-  // Compute the mean
-  option.value /= m_numSims;
-
-  // Discount to present value
-  option.value *= exp(-option.r * option.tenor);
-
-  // Cleanup
-  if (d_option) {
-    hipFree(d_option);
-    d_option = 0;
-  }
-
-  if (d_paths) {
-    hipFree(d_paths);
-    d_paths = 0;
-  }
-
-  if (d_rngStates) {
-    hipFree(d_rngStates);
-    d_rngStates = 0;
-  }
-
-  if (d_values) {
-    hipFree(d_values);
-    d_values = 0;
-  }
-}
-
-// Explicit template instantiation
-template class PricingEngine<float>;
-template class PricingEngine<double>;
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/test.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/test.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/test_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/MC_SingleAsianOptionP/src/test_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/README.md b/src/samples/Samples/2_Concepts_and_Techniques/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/README.md b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter.cpp b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_cpu.cpp b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_cpu.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_cpu_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_cpu_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_kernel.cu b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_kernel.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_kernel.cu.hip
old mode 100644
new mode 100755
index 6ffd9c5..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_kernel.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_kernel.cu.hip
@@ -1,494 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef _BOXFILTER_KERNEL_CH_
-#define _BOXFILTER_KERNEL_CH_
-
-#include <helper_math.h>
-#include "helper_functions.h"
-
-hipTextureObject_t tex;
-hipTextureObject_t texTempArray;
-hipTextureObject_t rgbaTex;
-hipTextureObject_t rgbaTexTempArray;
-hipArray *d_array, *d_tempArray;
-
-////////////////////////////////////////////////////////////////////////////////
-// These are CUDA Helper functions
-
-// This will output the proper CUDA error strings in the event that a CUDA host
-// call returns an error
-#define HIPCHECK(err) __HIPCHECK(err, __FILE__, __LINE__)
-
-inline void __HIPCHECK(hipError_t err, const char *file, const int line) {
-  if (hipSuccess != err) {
-    fprintf(stderr, "%s(%i) : CUDA Runtime API error %d: %s.\n", file, line,
-            (int)err, hipGetErrorString(err));
-    exit(EXIT_FAILURE);
-  }
-}
-
-/*
-  Perform a fast box filter using the sliding window method.
-
-  As the kernel moves from left to right, we add in the contribution of the
-  new sample on the right, and subtract the value of the exiting sample on the
-  left. This only requires 2 adds and a mul per output value, independent of the
-  filter radius. The box filter is separable, so to perform a 2D box filter we
-  perform the filter in the x direction, followed by the same filter in the y
-  direction. Applying multiple iterations of the box filter converges towards a
-  Gaussian blur. Using CUDA, rows or columns of the image are processed in
-  parallel. This version duplicates edge pixels.
-
-  Note that the x (row) pass suffers from uncoalesced global memory reads,
-  since each thread is reading from a different row. For this reason it is
-  better to use texture lookups for the x pass.
-  The y (column) pass is perfectly coalesced.
-
-  Parameters
-  id - pointer to input data in global memory
-  od - pointer to output data in global memory
-  w  - image width
-  h  - image height
-  r  - filter radius
-
-  e.g. for r = 2, w = 8:
-
-  0 1 2 3 4 5 6 7
-  x - -
-  - x - -
-  - - x - -
-    - - x - -
-      - - x - -
-        - - x - -
-          - - x -
-            - - x
-*/
-
-// process row
-__device__ void d_boxfilter_x(float *id, float *od, int w, int h, int r) {
-  float scale = 1.0f / (float)((r << 1) + 1);
-
-  float t;
-  // do left edge
-  t = id[0] * r;
-
-  for (int x = 0; x < (r + 1); x++) {
-    t += id[x];
-  }
-
-  od[0] = t * scale;
-
-  for (int x = 1; x < (r + 1); x++) {
-    t += id[x + r];
-    t -= id[0];
-    od[x] = t * scale;
-  }
-
-  // main loop
-  for (int x = (r + 1); x < w - r; x++) {
-    t += id[x + r];
-    t -= id[x - r - 1];
-    od[x] = t * scale;
-  }
-
-  // do right edge
-  for (int x = w - r; x < w; x++) {
-    t += id[w - 1];
-    t -= id[x - r - 1];
-    od[x] = t * scale;
-  }
-}
-
-// process column
-__device__ void d_boxfilter_y(float *id, float *od, int w, int h, int r) {
-  float scale = 1.0f / (float)((r << 1) + 1);
-
-  float t;
-  // do left edge
-  t = id[0] * r;
-
-  for (int y = 0; y < (r + 1); y++) {
-    t += id[y * w];
-  }
-
-  od[0] = t * scale;
-
-  for (int y = 1; y < (r + 1); y++) {
-    t += id[(y + r) * w];
-    t -= id[0];
-    od[y * w] = t * scale;
-  }
-
-  // main loop
-  for (int y = (r + 1); y < (h - r); y++) {
-    t += id[(y + r) * w];
-    t -= id[((y - r) * w) - w];
-    od[y * w] = t * scale;
-  }
-
-  // do right edge
-  for (int y = h - r; y < h; y++) {
-    t += id[(h - 1) * w];
-    t -= id[((y - r) * w) - w];
-    od[y * w] = t * scale;
-  }
-}
-
-__global__ void d_boxfilter_x_global(float *id, float *od, int w, int h,
-                                     int r) {
-  unsigned int y = blockIdx.x * blockDim.x + threadIdx.x;
-  d_boxfilter_x(&id[y * w], &od[y * w], w, h, r);
-}
-
-__global__ void d_boxfilter_y_global(float *id, float *od, int w, int h,
-                                     int r) {
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  d_boxfilter_y(&id[x], &od[x], w, h, r);
-}
-
-// texture version
-// texture fetches automatically clamp to edge of image
-__global__ void d_boxfilter_x_tex(float *od, int w, int h, int r,
-                                  hipTextureObject_t tex) {
-  float scale = 1.0f / (float)((r << 1) + 1);
-  unsigned int y = blockIdx.x * blockDim.x + threadIdx.x;
-
-  float t = 0.0f;
-
-  for (int x = -r; x <= r; x++) {
-    t += tex2D<float>(tex, x, y);
-  }
-
-  od[y * w] = t * scale;
-
-  for (int x = 1; x < w; x++) {
-    t += tex2D<float>(tex, x + r, y);
-    t -= tex2D<float>(tex, x - r - 1, y);
-    od[y * w + x] = t * scale;
-  }
-}
-
-__global__ void d_boxfilter_y_tex(float *od, int w, int h, int r,
-                                  hipTextureObject_t tex) {
-  float scale = 1.0f / (float)((r << 1) + 1);
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-
-  float t = 0.0f;
-
-  for (int y = -r; y <= r; y++) {
-    t += tex2D<float>(tex, x, y);
-  }
-
-  od[x] = t * scale;
-
-  for (int y = 1; y < h; y++) {
-    t += tex2D<float>(tex, x, y + r);
-    t -= tex2D<float>(tex, x, y - r - 1);
-    od[y * w + x] = t * scale;
-  }
-}
-
-// RGBA version
-// reads from 32-bit unsigned int array holding 8-bit RGBA
-
-// convert floating point rgba color to 32-bit integer
-__device__ unsigned int rgbaFloatToInt(float4 rgba) {
-  rgba.x = __saturatef(rgba.x);  // clamp to [0.0, 1.0]
-  rgba.y = __saturatef(rgba.y);
-  rgba.z = __saturatef(rgba.z);
-  rgba.w = __saturatef(rgba.w);
-  return ((unsigned int)(rgba.w * 255.0f) << 24) |
-         ((unsigned int)(rgba.z * 255.0f) << 16) |
-         ((unsigned int)(rgba.y * 255.0f) << 8) |
-         ((unsigned int)(rgba.x * 255.0f));
-}
-
-__device__ float4 rgbaIntToFloat(unsigned int c) {
-  float4 rgba;
-  rgba.x = (c & 0xff) * 0.003921568627f;          //  /255.0f;
-  rgba.y = ((c >> 8) & 0xff) * 0.003921568627f;   //  /255.0f;
-  rgba.z = ((c >> 16) & 0xff) * 0.003921568627f;  //  /255.0f;
-  rgba.w = ((c >> 24) & 0xff) * 0.003921568627f;  //  /255.0f;
-  return rgba;
-}
-
-// row pass using texture lookups
-__global__ void d_boxfilter_rgba_x(unsigned int *od, int w, int h, int r,
-                                   hipTextureObject_t rgbaTex) {
-  float scale = 1.0f / (float)((r << 1) + 1);
-  unsigned int y = blockIdx.x * blockDim.x + threadIdx.x;
-
-  // as long as address is always less than height, we do work
-  if (y < h) {
-    float4 t = make_float4(0.0f);
-
-    for (int x = -r; x <= r; x++) {
-      t += tex2D<float4>(rgbaTex, x, y);
-    }
-
-    od[y * w] = rgbaFloatToInt(t * scale);
-
-    for (int x = 1; x < w; x++) {
-      t += tex2D<float4>(rgbaTex, x + r, y);
-      t -= tex2D<float4>(rgbaTex, x - r - 1, y);
-      od[y * w + x] = rgbaFloatToInt(t * scale);
-    }
-  }
-}
-
-// column pass using coalesced global memory reads
-__global__ void d_boxfilter_rgba_y(unsigned int *id, unsigned int *od, int w,
-                                   int h, int r) {
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  id = &id[x];
-  od = &od[x];
-
-  float scale = 1.0f / (float)((r << 1) + 1);
-
-  float4 t;
-  // do left edge
-  t = rgbaIntToFloat(id[0]) * r;
-
-  for (int y = 0; y < (r + 1); y++) {
-    t += rgbaIntToFloat(id[y * w]);
-  }
-
-  od[0] = rgbaFloatToInt(t * scale);
-
-  for (int y = 1; y < (r + 1); y++) {
-    t += rgbaIntToFloat(id[(y + r) * w]);
-    t -= rgbaIntToFloat(id[0]);
-    od[y * w] = rgbaFloatToInt(t * scale);
-  }
-
-  // main loop
-  for (int y = (r + 1); y < (h - r); y++) {
-    t += rgbaIntToFloat(id[(y + r) * w]);
-    t -= rgbaIntToFloat(id[((y - r) * w) - w]);
-    od[y * w] = rgbaFloatToInt(t * scale);
-  }
-
-  // do right edge
-  for (int y = h - r; y < h; y++) {
-    t += rgbaIntToFloat(id[(h - 1) * w]);
-    t -= rgbaIntToFloat(id[((y - r) * w) - w]);
-    od[y * w] = rgbaFloatToInt(t * scale);
-  }
-}
-
-extern "C" void initTexture(int width, int height, void *pImage, bool useRGBA) {
-  // copy image data to array
-  hipChannelFormatDesc channelDesc;
-  if (useRGBA) {
-    channelDesc =
-        hipCreateChannelDesc(8, 8, 8, 8, hipChannelFormatKindUnsigned);
-  } else {
-    channelDesc =
-        hipCreateChannelDesc(32, 0, 0, 0, hipChannelFormatKindFloat);
-  }
-  HIPCHECK(hipMallocArray(&d_array, &channelDesc, width, height));
-
-  size_t bytesPerElem = (useRGBA ? sizeof(uchar4) : sizeof(float));
-  HIPCHECK(hipMemcpy2DToArray(
-      d_array, 0, 0, pImage, width * bytesPerElem, width * bytesPerElem, height,
-      hipMemcpyHostToDevice));
-
-  HIPCHECK(hipMallocArray(&d_tempArray, &channelDesc, width, height));
-
-  // set texture parameters
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = d_array;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeNormalizedFloat;
-
-  HIPCHECK(hipCreateTextureObject(&rgbaTex, &texRes, &texDescr, NULL));
-
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = d_tempArray;
-
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeClamp;
-  texDescr.addressMode[1] = hipAddressModeClamp;
-  texDescr.readMode = hipReadModeNormalizedFloat;
-
-  HIPCHECK(
-      hipCreateTextureObject(&rgbaTexTempArray, &texRes, &texDescr, NULL));
-
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = d_array;
-
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = true;
-  texDescr.filterMode = hipFilterModePoint;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(hipCreateTextureObject(&tex, &texRes, &texDescr, NULL));
-
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = d_tempArray;
-
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = true;
-  texDescr.filterMode = hipFilterModePoint;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(
-      hipCreateTextureObject(&texTempArray, &texRes, &texDescr, NULL));
-}
-
-extern "C" void freeTextures() {
-  HIPCHECK(hipDestroyTextureObject(tex));
-  HIPCHECK(hipDestroyTextureObject(texTempArray));
-  HIPCHECK(hipDestroyTextureObject(rgbaTex));
-  HIPCHECK(hipDestroyTextureObject(rgbaTexTempArray));
-  HIPCHECK(hipFreeArray(d_array));
-  HIPCHECK(hipFreeArray(d_tempArray));
-}
-
-/*
-    Perform 2D box filter on image using CUDA
-
-    Parameters:
-    d_src  - pointer to input image in device memory
-    d_temp - pointer to temporary storage in device memory
-    d_dest - pointer to destination image in device memory
-    width  - image width
-    height - image height
-    radius - filter radius
-    iterations - number of iterations
-
-*/
-extern "C" double boxFilter(float *d_src, float *d_temp, float *d_dest,
-                            int width, int height, int radius, int iterations,
-                            int nthreads, StopWatchInterface *timer) {
-  // var for kernel timing
-  double dKernelTime = 0.0;
-
-  // sync host and start computation timer_kernel
-  HIPCHECK(hipDeviceSynchronize());
-
-  for (int i = 0; i < iterations; i++) {
-    sdkResetTimer(&timer);
-    // use texture for horizontal pass
-    if (iterations > 1) {
-      d_boxfilter_x_tex<<<height / nthreads, nthreads, 0>>>(
-          d_temp, width, height, radius, texTempArray);
-    } else {
-      d_boxfilter_x_tex<<<height / nthreads, nthreads, 0>>>(
-          d_temp, width, height, radius, tex);
-    }
-
-    d_boxfilter_y_global<<<width / nthreads, nthreads, 0>>>(
-        d_temp, d_dest, width, height, radius);
-
-    // sync host and stop computation timer_kernel
-    HIPCHECK(hipDeviceSynchronize());
-    dKernelTime += sdkGetTimerValue(&timer);
-
-    if (iterations > 1) {
-      // copy result back from global memory to array
-      HIPCHECK(hipMemcpy2DToArray(
-          d_tempArray, 0, 0, d_dest, width * sizeof(float),
-          width * sizeof(float), height, hipMemcpyDeviceToDevice));
-    }
-  }
-
-  return ((dKernelTime / 1000.) / (double)iterations);
-}
-
-// RGBA version
-extern "C" double boxFilterRGBA(unsigned int *d_src, unsigned int *d_temp,
-                                unsigned int *d_dest, int width, int height,
-                                int radius, int iterations, int nthreads,
-                                StopWatchInterface *timer) {
-  // var for kernel computation timing
-  double dKernelTime;
-
-  for (int i = 0; i < iterations; i++) {
-    // sync host and start kernel computation timer_kernel
-    dKernelTime = 0.0;
-    HIPCHECK(hipDeviceSynchronize());
-    sdkResetTimer(&timer);
-
-    // use texture for horizontal pass
-    if (iterations > 1) {
-      d_boxfilter_rgba_x<<<height / nthreads, nthreads, 0>>>(
-          d_temp, width, height, radius, rgbaTexTempArray);
-    } else {
-      d_boxfilter_rgba_x<<<height / nthreads, nthreads, 0>>>(
-          d_temp, width, height, radius, rgbaTex);
-    }
-
-    d_boxfilter_rgba_y<<<width / nthreads, nthreads, 0>>>(d_temp, d_dest, width,
-                                                          height, radius);
-
-    // sync host and stop computation timer_kernel
-    HIPCHECK(hipDeviceSynchronize());
-    dKernelTime += sdkGetTimerValue(&timer);
-
-    if (iterations > 1) {
-      // copy result back from global memory to array
-      HIPCHECK(hipMemcpy2DToArray(
-          d_tempArray, 0, 0, d_dest, width * sizeof(unsigned int),
-          width * sizeof(unsigned int), height, hipMemcpyDeviceToDevice));
-    }
-  }
-
-  return ((dKernelTime / 1000.) / (double)iterations);
-}
-
-#endif  // #ifndef _BOXFILTER_KERNEL_H_
-ned int), height, hipMemcpyDeviceToDevice));
-    }
-  }
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/boxFilter_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/data/ref_14.ppm b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/data/ref_14.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/data/ref_22.ppm b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/data/ref_22.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/data/teapot1024.ppm b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/data/teapot1024.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/findgllib.mk b/src/samples/Samples/2_Concepts_and_Techniques/boxFilter/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/README.md b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable.cu b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable.cu.hip
old mode 100644
new mode 100755
index a2d2e6d..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable.cu.hip
@@ -1,215 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <assert.h>
-#include "helper_cuda_hipified.h"
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-#include "convolutionSeparable_common.h"
-
-////////////////////////////////////////////////////////////////////////////////
-// Convolution kernel storage
-////////////////////////////////////////////////////////////////////////////////
-__constant__ float c_Kernel[KERNEL_LENGTH];
-
-extern "C" void setConvolutionKernel(float *h_Kernel) {
-  hipMemcpyToSymbol(HIP_SYMBOL(c_Kernel), h_Kernel, KERNEL_LENGTH * sizeof(float));
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Row convolution filter
-////////////////////////////////////////////////////////////////////////////////
-#define ROWS_BLOCKDIM_X 16
-#define ROWS_BLOCKDIM_Y 4
-#define ROWS_RESULT_STEPS 8
-#define ROWS_HALO_STEPS 1
-
-__global__ void convolutionRowsKernel(float *d_Dst, float *d_Src, int imageW,
-                                      int imageH, int pitch) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  __shared__ float
-      s_Data[ROWS_BLOCKDIM_Y][(ROWS_RESULT_STEPS + 2 * ROWS_HALO_STEPS) *
-                              ROWS_BLOCKDIM_X];
-
-  // Offset to the left halo edge
-  const int baseX =
-      (blockIdx.x * ROWS_RESULT_STEPS - ROWS_HALO_STEPS) * ROWS_BLOCKDIM_X +
-      threadIdx.x;
-  const int baseY = blockIdx.y * ROWS_BLOCKDIM_Y + threadIdx.y;
-
-  d_Src += baseY * pitch + baseX;
-  d_Dst += baseY * pitch + baseX;
-
-// Load main data
-#pragma unroll
-
-  for (int i = ROWS_HALO_STEPS; i < ROWS_HALO_STEPS + ROWS_RESULT_STEPS; i++) {
-    s_Data[threadIdx.y][threadIdx.x + i * ROWS_BLOCKDIM_X] =
-        d_Src[i * ROWS_BLOCKDIM_X];
-  }
-
-// Load left halo
-#pragma unroll
-
-  for (int i = 0; i < ROWS_HALO_STEPS; i++) {
-    s_Data[threadIdx.y][threadIdx.x + i * ROWS_BLOCKDIM_X] =
-        (baseX >= -i * ROWS_BLOCKDIM_X) ? d_Src[i * ROWS_BLOCKDIM_X] : 0;
-  }
-
-// Load right halo
-#pragma unroll
-
-  for (int i = ROWS_HALO_STEPS + ROWS_RESULT_STEPS;
-       i < ROWS_HALO_STEPS + ROWS_RESULT_STEPS + ROWS_HALO_STEPS; i++) {
-    s_Data[threadIdx.y][threadIdx.x + i * ROWS_BLOCKDIM_X] =
-        (imageW - baseX > i * ROWS_BLOCKDIM_X) ? d_Src[i * ROWS_BLOCKDIM_X] : 0;
-  }
-
-  // Compute and store results
-  cg::sync(cta);
-#pragma unroll
-
-  for (int i = ROWS_HALO_STEPS; i < ROWS_HALO_STEPS + ROWS_RESULT_STEPS; i++) {
-    float sum = 0;
-
-#pragma unroll
-
-    for (int j = -KERNEL_RADIUS; j <= KERNEL_RADIUS; j++) {
-      sum += c_Kernel[KERNEL_RADIUS - j] *
-             s_Data[threadIdx.y][threadIdx.x + i * ROWS_BLOCKDIM_X + j];
-    }
-
-    d_Dst[i * ROWS_BLOCKDIM_X] = sum;
-  }
-}
-
-extern "C" void convolutionRowsGPU(float *d_Dst, float *d_Src, int imageW,
-                                   int imageH) {
-  assert(ROWS_BLOCKDIM_X * ROWS_HALO_STEPS >= KERNEL_RADIUS);
-  assert(imageW % (ROWS_RESULT_STEPS * ROWS_BLOCKDIM_X) == 0);
-  assert(imageH % ROWS_BLOCKDIM_Y == 0);
-
-  dim3 blocks(imageW / (ROWS_RESULT_STEPS * ROWS_BLOCKDIM_X),
-              imageH / ROWS_BLOCKDIM_Y);
-  dim3 threads(ROWS_BLOCKDIM_X, ROWS_BLOCKDIM_Y);
-
-  convolutionRowsKernel<<<blocks, threads>>>(d_Dst, d_Src, imageW, imageH,
-                                             imageW);
-  getLastCudaError("convolutionRowsKernel() execution failed\n");
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Column convolution filter
-////////////////////////////////////////////////////////////////////////////////
-#define COLUMNS_BLOCKDIM_X 16
-#define COLUMNS_BLOCKDIM_Y 8
-#define COLUMNS_RESULT_STEPS 8
-#define COLUMNS_HALO_STEPS 1
-
-__global__ void convolutionColumnsKernel(float *d_Dst, float *d_Src, int imageW,
-                                         int imageH, int pitch) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  __shared__ float s_Data[COLUMNS_BLOCKDIM_X][(COLUMNS_RESULT_STEPS +
-                                               2 * COLUMNS_HALO_STEPS) *
-                                                  COLUMNS_BLOCKDIM_Y +
-                                              1];
-
-  // Offset to the upper halo edge
-  const int baseX = blockIdx.x * COLUMNS_BLOCKDIM_X + threadIdx.x;
-  const int baseY = (blockIdx.y * COLUMNS_RESULT_STEPS - COLUMNS_HALO_STEPS) *
-                        COLUMNS_BLOCKDIM_Y +
-                    threadIdx.y;
-  d_Src += baseY * pitch + baseX;
-  d_Dst += baseY * pitch + baseX;
-
-// Main data
-#pragma unroll
-
-  for (int i = COLUMNS_HALO_STEPS;
-       i < COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS; i++) {
-    s_Data[threadIdx.x][threadIdx.y + i * COLUMNS_BLOCKDIM_Y] =
-        d_Src[i * COLUMNS_BLOCKDIM_Y * pitch];
-  }
-
-// Upper halo
-#pragma unroll
-
-  for (int i = 0; i < COLUMNS_HALO_STEPS; i++) {
-    s_Data[threadIdx.x][threadIdx.y + i * COLUMNS_BLOCKDIM_Y] =
-        (baseY >= -i * COLUMNS_BLOCKDIM_Y)
-            ? d_Src[i * COLUMNS_BLOCKDIM_Y * pitch]
-            : 0;
-  }
-
-// Lower halo
-#pragma unroll
-
-  for (int i = COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS;
-       i < COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS + COLUMNS_HALO_STEPS;
-       i++) {
-    s_Data[threadIdx.x][threadIdx.y + i * COLUMNS_BLOCKDIM_Y] =
-        (imageH - baseY > i * COLUMNS_BLOCKDIM_Y)
-            ? d_Src[i * COLUMNS_BLOCKDIM_Y * pitch]
-            : 0;
-  }
-
-  // Compute and store results
-  cg::sync(cta);
-#pragma unroll
-
-  for (int i = COLUMNS_HALO_STEPS;
-       i < COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS; i++) {
-    float sum = 0;
-#pragma unroll
-
-    for (int j = -KERNEL_RADIUS; j <= KERNEL_RADIUS; j++) {
-      sum += c_Kernel[KERNEL_RADIUS - j] *
-             s_Data[threadIdx.x][threadIdx.y + i * COLUMNS_BLOCKDIM_Y + j];
-    }
-
-    d_Dst[i * COLUMNS_BLOCKDIM_Y * pitch] = sum;
-  }
-}
-
-extern "C" void convolutionColumnsGPU(float *d_Dst, float *d_Src, int imageW,
-                                      int imageH) {
-  assert(COLUMNS_BLOCKDIM_Y * COLUMNS_HALO_STEPS >= KERNEL_RADIUS);
-  assert(imageW % COLUMNS_BLOCKDIM_X == 0);
-  assert(imageH % (COLUMNS_RESULT_STEPS * COLUMNS_BLOCKDIM_Y) == 0);
-
-  dim3 blocks(imageW / COLUMNS_BLOCKDIM_X,
-              imageH / (COLUMNS_RESULT_STEPS * COLUMNS_BLOCKDIM_Y));
-  dim3 threads(COLUMNS_BLOCKDIM_X, COLUMNS_BLOCKDIM_Y);
-
-  convolutionColumnsKernel<<<blocks, threads>>>(d_Dst, d_Src, imageW, imageH,
-                                                imageW);
-  getLastCudaError("convolutionColumnsKernel() execution failed\n");
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable.out b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_common.h b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_common_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_gold.cpp b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_gold_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/convolutionSeparable_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/doc/convolutionSeparable.doc b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/doc/convolutionSeparable.doc
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/doc/convolutionSeparable.pdf b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/doc/convolutionSeparable.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/doc/convolutionSeparable.vsd b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/doc/convolutionSeparable.vsd
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/main.cpp b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/main_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/convolutionSeparable/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/README.md b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture.cu b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture.cu.hip
old mode 100644
new mode 100755
index 99eabc9..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture.cu.hip
@@ -1,165 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-#include "helper_cuda_hipified.h"
-
-#include "convolutionTexture_common.h"
-
-////////////////////////////////////////////////////////////////////////////////
-// GPU-specific defines
-////////////////////////////////////////////////////////////////////////////////
-// Maps to a single instruction on G8x / G9x / G10x
-#define IMAD(a, b, c) (__mul24((a), (b)) + (c))
-
-// Use unrolled innermost convolution loop
-#define UNROLL_INNER 1
-
-// Round a / b to nearest higher integer value
-inline int iDivUp(int a, int b) { return (a % b != 0) ? (a / b + 1) : (a / b); }
-
-// Align a to nearest higher multiple of b
-inline int iAlignUp(int a, int b) { return (a % b != 0) ? (a - a % b + b) : a; }
-
-////////////////////////////////////////////////////////////////////////////////
-// Convolution kernel and input array storage
-////////////////////////////////////////////////////////////////////////////////
-__constant__ float c_Kernel[KERNEL_LENGTH];
-
-extern "C" void setConvolutionKernel(float *h_Kernel) {
-  hipMemcpyToSymbol(HIP_SYMBOL(c_Kernel), h_Kernel, KERNEL_LENGTH * sizeof(float));
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Loop unrolling templates, needed for best performance
-////////////////////////////////////////////////////////////////////////////////
-template <int i>
-__device__ float convolutionRow(float x, float y, hipTextureObject_t texSrc) {
-  return tex2D<float>(texSrc, x + (float)(KERNEL_RADIUS - i), y) * c_Kernel[i] +
-         convolutionRow<i - 1>(x, y, texSrc);
-}
-
-template <>
-__device__ float convolutionRow<-1>(float x, float y,
-                                    hipTextureObject_t texSrc) {
-  return 0;
-}
-
-template <int i>
-__device__ float convolutionColumn(float x, float y,
-                                   hipTextureObject_t texSrc) {
-  return tex2D<float>(texSrc, x, y + (float)(KERNEL_RADIUS - i)) * c_Kernel[i] +
-         convolutionColumn<i - 1>(x, y, texSrc);
-}
-
-template <>
-__device__ float convolutionColumn<-1>(float x, float y,
-                                       hipTextureObject_t texSrc) {
-  return 0;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Row convolution filter
-////////////////////////////////////////////////////////////////////////////////
-__global__ void convolutionRowsKernel(float *d_Dst, int imageW, int imageH,
-                                      hipTextureObject_t texSrc) {
-  const int ix = IMAD(blockDim.x, blockIdx.x, threadIdx.x);
-  const int iy = IMAD(blockDim.y, blockIdx.y, threadIdx.y);
-  const float x = (float)ix + 0.5f;
-  const float y = (float)iy + 0.5f;
-
-  if (ix >= imageW || iy >= imageH) {
-    return;
-  }
-
-  float sum = 0;
-
-#if (UNROLL_INNER)
-  sum = convolutionRow<2 * KERNEL_RADIUS>(x, y, texSrc);
-#else
-
-  for (int k = -KERNEL_RADIUS; k <= KERNEL_RADIUS; k++) {
-    sum += tex2D<float>(texSrc, x + (float)k, y) * c_Kernel[KERNEL_RADIUS - k];
-  }
-
-#endif
-
-  d_Dst[IMAD(iy, imageW, ix)] = sum;
-}
-
-extern "C" void convolutionRowsGPU(float *d_Dst, hipArray *a_Src, int imageW,
-                                   int imageH, hipTextureObject_t texSrc) {
-  dim3 threads(16, 12);
-  dim3 blocks(iDivUp(imageW, threads.x), iDivUp(imageH, threads.y));
-
-  convolutionRowsKernel<<<blocks, threads>>>(d_Dst, imageW, imageH, texSrc);
-  getLastCudaError("convolutionRowsKernel() execution failed\n");
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Column convolution filter
-////////////////////////////////////////////////////////////////////////////////
-__global__ void convolutionColumnsKernel(float *d_Dst, int imageW, int imageH,
-                                         hipTextureObject_t texSrc) {
-  const int ix = IMAD(blockDim.x, blockIdx.x, threadIdx.x);
-  const int iy = IMAD(blockDim.y, blockIdx.y, threadIdx.y);
-  const float x = (float)ix + 0.5f;
-  const float y = (float)iy + 0.5f;
-
-  if (ix >= imageW || iy >= imageH) {
-    return;
-  }
-
-  float sum = 0;
-
-#if (UNROLL_INNER)
-  sum = convolutionColumn<2 * KERNEL_RADIUS>(x, y, texSrc);
-#else
-
-  for (int k = -KERNEL_RADIUS; k <= KERNEL_RADIUS; k++) {
-    sum += tex2D<float>(texSrc, x, y + (float)k) * c_Kernel[KERNEL_RADIUS - k];
-  }
-
-#endif
-
-  d_Dst[IMAD(iy, imageW, ix)] = sum;
-}
-
-extern "C" void convolutionColumnsGPU(float *d_Dst, hipArray *a_Src,
-                                      int imageW, int imageH,
-                                      hipTextureObject_t texSrc) {
-  dim3 threads(16, 12);
-  dim3 blocks(iDivUp(imageW, threads.x), iDivUp(imageH, threads.y));
-
-  convolutionColumnsKernel<<<blocks, threads>>>(d_Dst, imageW, imageH, texSrc);
-  getLastCudaError("convolutionColumnsKernel() execution failed\n");
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_common.h b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_common_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_gold.cpp b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_gold_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/convolutionTexture_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/doc/Performance.xls b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/doc/Performance.xls
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/main.cpp b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/main_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/convolutionTexture/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/README.md b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/cuHook.cpp b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/cuHook.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/cuHook_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/cuHook_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/libcuhook.cpp b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/libcuhook.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/libcuhook.h b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/libcuhook.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/libcuhook_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/libcuhook_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/cuHook/libcuhook_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/cuHook/libcuhook_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/BmpUtil.cpp b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/BmpUtil.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/BmpUtil.h b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/BmpUtil.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/BmpUtil_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/BmpUtil_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/BmpUtil_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/BmpUtil_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/Common.h b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/Common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/Common_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/Common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/DCT8x8_Gold.cpp b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/DCT8x8_Gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/DCT8x8_Gold.h b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/DCT8x8_Gold.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/DCT8x8_Gold_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/DCT8x8_Gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/DCT8x8_Gold_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/DCT8x8_Gold_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/README.md b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/data/teapot512.bmp b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/data/teapot512.bmp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/data/teapot512.ppm b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/data/teapot512.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8.cu b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8.cu.hip
old mode 100644
new mode 100755
index bcf46d2..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8.cu.hip
@@ -1,669 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/**
-**************************************************************************
-* \file dct8x8.cu
-* \brief Contains entry point, wrappers to host and device code and benchmark.
-*
-* This sample implements forward and inverse Discrete Cosine Transform to blocks
-* of image pixels (of 8x8 size), as in JPEG standard. The typical work flow is
-*as
-* follows:
-* 1. Run CPU version (Host code) and measure execution time;
-* 2. Run CUDA version (Device code) and measure execution time;
-* 3. Output execution timings and calculate CUDA speedup.
-*/
-
-#include "Common.h"
-#include "DCT8x8_Gold.h"
-#include "BmpUtil.h"
-
-/**
-*  The number of DCT kernel calls
-*/
-#define BENCHMARK_SIZE 10
-
-/**
-*  The PSNR values over this threshold indicate images equality
-*/
-#define PSNR_THRESHOLD_EQUAL 40
-
-// includes kernels
-#include "dct8x8_kernel1.cuh"
-#include "dct8x8_kernel2.cuh"
-#include "dct8x8_kernel_short.cuh"
-#include "dct8x8_kernel_quantization.cuh"
-
-/**
-**************************************************************************
-*  Wrapper function for 1st gold version of DCT, quantization and IDCT
-*implementations
-*
-* \param ImgSrc         [IN] - Source byte image plane
-* \param ImgDst         [IN] - Quantized result byte image plane
-* \param Stride         [IN] - Stride for both source and result planes
-* \param Size           [IN] - Size of both planes
-*
-* \return Execution time in milliseconds
-*/
-float WrapperGold1(byte *ImgSrc, byte *ImgDst, int Stride, ROI Size) {
-  // allocate float buffers for DCT and other data
-  int StrideF;
-  float *ImgF1 = MallocPlaneFloat(Size.width, Size.height, &StrideF);
-  float *ImgF2 = MallocPlaneFloat(Size.width, Size.height, &StrideF);
-
-  // convert source image to float representation
-  CopyByte2Float(ImgSrc, Stride, ImgF1, StrideF, Size);
-  AddFloatPlane(-128.0f, ImgF1, StrideF, Size);
-
-  // create and start CUDA timer
-  StopWatchInterface *timerGold = 0;
-  sdkCreateTimer(&timerGold);
-  sdkResetTimer(&timerGold);
-
-  // perform block-wise DCT processing and benchmarking
-  for (int i = 0; i < BENCHMARK_SIZE; i++) {
-    sdkStartTimer(&timerGold);
-    computeDCT8x8Gold1(ImgF1, ImgF2, StrideF, Size);
-    sdkStopTimer(&timerGold);
-  }
-
-  // stop and destroy CUDA timer
-  float TimerGoldSpan = sdkGetAverageTimerValue(&timerGold);
-  sdkDeleteTimer(&timerGold);
-
-  // perform quantization
-  quantizeGoldFloat(ImgF2, StrideF, Size);
-
-  // perform block-wise IDCT processing
-  computeIDCT8x8Gold1(ImgF2, ImgF1, StrideF, Size);
-
-  // convert image back to byte representation
-  AddFloatPlane(128.0f, ImgF1, StrideF, Size);
-  CopyFloat2Byte(ImgF1, StrideF, ImgDst, Stride, Size);
-
-  // free float buffers
-  FreePlane(ImgF1);
-  FreePlane(ImgF2);
-
-  // return time taken by the operation
-  return TimerGoldSpan;
-}
-
-/**
-**************************************************************************
-*  Wrapper function for 2nd gold version of DCT, quantization and IDCT
-*implementations
-*
-* \param ImgSrc         [IN] - Source byte image plane
-* \param ImgDst         [IN] - Quantized result byte image plane
-* \param Stride         [IN] - Stride for both source and result planes
-* \param Size           [IN] - Size of both planes
-*
-* \return Execution time in milliseconds
-*/
-float WrapperGold2(byte *ImgSrc, byte *ImgDst, int Stride, ROI Size) {
-  // allocate float buffers for DCT and other data
-  int StrideF;
-  float *ImgF1 = MallocPlaneFloat(Size.width, Size.height, &StrideF);
-  float *ImgF2 = MallocPlaneFloat(Size.width, Size.height, &StrideF);
-
-  // convert source image to float representation
-  CopyByte2Float(ImgSrc, Stride, ImgF1, StrideF, Size);
-  AddFloatPlane(-128.0f, ImgF1, StrideF, Size);
-
-  // create and start CUDA timer
-  StopWatchInterface *timerGold = 0;
-  sdkCreateTimer(&timerGold);
-  sdkResetTimer(&timerGold);
-
-  // perform block-wise DCT processing and benchmarking
-  for (int i = 0; i < BENCHMARK_SIZE; i++) {
-    sdkStartTimer(&timerGold);
-    computeDCT8x8Gold2(ImgF1, ImgF2, StrideF, Size);
-    sdkStopTimer(&timerGold);
-  }
-
-  // stop and destroy CUDA timer
-  float TimerGoldSpan = sdkGetAverageTimerValue(&timerGold);
-  sdkDeleteTimer(&timerGold);
-
-  // perform quantization
-  quantizeGoldFloat(ImgF2, StrideF, Size);
-
-  // perform block-wise IDCT processing
-  computeIDCT8x8Gold2(ImgF2, ImgF1, StrideF, Size);
-
-  // convert image back to byte representation
-  AddFloatPlane(128.0f, ImgF1, StrideF, Size);
-  CopyFloat2Byte(ImgF1, StrideF, ImgDst, Stride, Size);
-
-  // free float buffers
-  FreePlane(ImgF1);
-  FreePlane(ImgF2);
-
-  // return time taken by the operation
-  return TimerGoldSpan;
-}
-
-/**
-**************************************************************************
-*  Wrapper function for 1st CUDA version of DCT, quantization and IDCT
-*implementations
-*
-* \param ImgSrc         [IN] - Source byte image plane
-* \param ImgDst         [IN] - Quantized result byte image plane
-* \param Stride         [IN] - Stride for both source and result planes
-* \param Size           [IN] - Size of both planes
-*
-* \return Execution time in milliseconds
-*/
-float WrapperCUDA1(byte *ImgSrc, byte *ImgDst, int Stride, ROI Size) {
-  // prepare channel format descriptor for passing texture into kernels
-  hipChannelFormatDesc floattex = hipCreateChannelDesc<float>();
-
-  // allocate device memory
-  hipArray *Src;
-  float *Dst;
-  size_t DstStride;
-  HIPCHECK(hipMallocArray(&Src, &floattex, Size.width, Size.height));
-  HIPCHECK(hipMallocPitch((void **)(&Dst), &DstStride,
-                                  Size.width * sizeof(float), Size.height));
-  DstStride /= sizeof(float);
-
-  // convert source image to float representation
-  int ImgSrcFStride;
-  float *ImgSrcF = MallocPlaneFloat(Size.width, Size.height, &ImgSrcFStride);
-  CopyByte2Float(ImgSrc, Stride, ImgSrcF, ImgSrcFStride, Size);
-  AddFloatPlane(-128.0f, ImgSrcF, ImgSrcFStride, Size);
-
-  // copy from host memory to device
-  HIPCHECK(hipMemcpy2DToArray(
-      Src, 0, 0, ImgSrcF, ImgSrcFStride * sizeof(float),
-      Size.width * sizeof(float), Size.height, hipMemcpyHostToDevice));
-
-  // setup execution parameters
-  dim3 threads(BLOCK_SIZE, BLOCK_SIZE);
-  dim3 grid(Size.width / BLOCK_SIZE, Size.height / BLOCK_SIZE);
-
-  // create and start CUDA timer
-  StopWatchInterface *timerCUDA = 0;
-  sdkCreateTimer(&timerCUDA);
-  sdkResetTimer(&timerCUDA);
-
-  // execute DCT kernel and benchmark
-  hipTextureObject_t TexSrc;
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = Src;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(hipCreateTextureObject(&TexSrc, &texRes, &texDescr, NULL));
-
-  for (int i = 0; i < BENCHMARK_SIZE; i++) {
-    sdkStartTimer(&timerCUDA);
-    CUDAkernel1DCT<<<grid, threads>>>(Dst, (int)DstStride, 0, 0, TexSrc);
-    HIPCHECK(hipDeviceSynchronize());
-    sdkStopTimer(&timerCUDA);
-  }
-
-  getLastCudaError("Kernel execution failed");
-
-  // finalize CUDA timer
-  float TimerCUDASpan = sdkGetAverageTimerValue(&timerCUDA);
-  sdkDeleteTimer(&timerCUDA);
-
-  // execute Quantization kernel
-  CUDAkernelQuantizationFloat<<<grid, threads>>>(Dst, (int)DstStride);
-  getLastCudaError("Kernel execution failed");
-
-  // copy quantized coefficients from host memory to device array
-  HIPCHECK(hipMemcpy2DToArray(Src, 0, 0, Dst, DstStride * sizeof(float),
-                                      Size.width * sizeof(float), Size.height,
-                                      hipMemcpyDeviceToDevice));
-
-  // execute IDCT kernel
-  CUDAkernel1IDCT<<<grid, threads>>>(Dst, (int)DstStride, 0, 0, TexSrc);
-  getLastCudaError("Kernel execution failed");
-
-  // copy quantized image block to host
-  HIPCHECK(hipMemcpy2D(
-      ImgSrcF, ImgSrcFStride * sizeof(float), Dst, DstStride * sizeof(float),
-      Size.width * sizeof(float), Size.height, hipMemcpyDeviceToHost));
-
-  // convert image back to byte representation
-  AddFloatPlane(128.0f, ImgSrcF, ImgSrcFStride, Size);
-  CopyFloat2Byte(ImgSrcF, ImgSrcFStride, ImgDst, Stride, Size);
-
-  // clean up memory
-  HIPCHECK(hipDestroyTextureObject(TexSrc));
-  HIPCHECK(hipFreeArray(Src));
-  HIPCHECK(hipFree(Dst));
-  FreePlane(ImgSrcF);
-
-  // return time taken by the operation
-  return TimerCUDASpan;
-}
-
-/**
-**************************************************************************
-*  Wrapper function for 2nd CUDA version of DCT, quantization and IDCT
-*implementations
-*
-* \param ImgSrc         [IN] - Source byte image plane
-* \param ImgDst         [IN] - Quantized result byte image plane
-* \param Stride         [IN] - Stride for both source and result planes
-* \param Size           [IN] - Size of both planes
-*
-* \return Execution time in milliseconds
-*/
-
-float WrapperCUDA2(byte *ImgSrc, byte *ImgDst, int Stride, ROI Size) {
-  // allocate host buffers for DCT and other data
-  int StrideF;
-  float *ImgF1 = MallocPlaneFloat(Size.width, Size.height, &StrideF);
-
-  // convert source image to float representation
-  CopyByte2Float(ImgSrc, Stride, ImgF1, StrideF, Size);
-  AddFloatPlane(-128.0f, ImgF1, StrideF, Size);
-
-  // allocate device memory
-  float *src, *dst;
-  size_t DeviceStride;
-  HIPCHECK(hipMallocPitch((void **)&src, &DeviceStride,
-                                  Size.width * sizeof(float), Size.height));
-  HIPCHECK(hipMallocPitch((void **)&dst, &DeviceStride,
-                                  Size.width * sizeof(float), Size.height));
-  DeviceStride /= sizeof(float);
-
-  // copy from host memory to device
-  HIPCHECK(hipMemcpy2D(
-      src, DeviceStride * sizeof(float), ImgF1, StrideF * sizeof(float),
-      Size.width * sizeof(float), Size.height, hipMemcpyHostToDevice));
-
-  // create and start CUDA timer
-  StopWatchInterface *timerCUDA = 0;
-  sdkCreateTimer(&timerCUDA);
-
-  // setup execution parameters
-  dim3 GridFullWarps(Size.width / KER2_BLOCK_WIDTH,
-                     Size.height / KER2_BLOCK_HEIGHT, 1);
-  dim3 ThreadsFullWarps(8, KER2_BLOCK_WIDTH / 8, KER2_BLOCK_HEIGHT / 8);
-
-  // perform block-wise DCT processing and benchmarking
-  const int numIterations = 100;
-
-  for (int i = -1; i < numIterations; i++) {
-    if (i == 0) {
-      HIPCHECK(hipDeviceSynchronize());
-      sdkResetTimer(&timerCUDA);
-      sdkStartTimer(&timerCUDA);
-    }
-
-    CUDAkernel2DCT<<<GridFullWarps, ThreadsFullWarps>>>(dst, src,
-                                                        (int)DeviceStride);
-    getLastCudaError("Kernel execution failed");
-  }
-
-  HIPCHECK(hipDeviceSynchronize());
-  sdkStopTimer(&timerCUDA);
-
-  // finalize timing of CUDA Kernels
-  float avgTime = (float)sdkGetTimerValue(&timerCUDA) / (float)numIterations;
-  sdkDeleteTimer(&timerCUDA);
-  printf("%f MPix/s //%f ms\n",
-         (1E-6 * (float)Size.width * (float)Size.height) / (1E-3 * avgTime),
-         avgTime);
-
-  // setup execution parameters for quantization
-  dim3 ThreadsSmallBlocks(BLOCK_SIZE, BLOCK_SIZE);
-  dim3 GridSmallBlocks(Size.width / BLOCK_SIZE, Size.height / BLOCK_SIZE);
-
-  // execute Quantization kernel
-  CUDAkernelQuantizationFloat<<<GridSmallBlocks, ThreadsSmallBlocks>>>(
-      dst, (int)DeviceStride);
-  getLastCudaError("Kernel execution failed");
-
-  // perform block-wise IDCT processing
-  CUDAkernel2IDCT<<<GridFullWarps, ThreadsFullWarps>>>(src, dst,
-                                                       (int)DeviceStride);
-  HIPCHECK(hipDeviceSynchronize());
-  getLastCudaError("Kernel execution failed");
-
-  // copy quantized image block to host
-  HIPCHECK(hipMemcpy2D(
-      ImgF1, StrideF * sizeof(float), src, DeviceStride * sizeof(float),
-      Size.width * sizeof(float), Size.height, hipMemcpyDeviceToHost));
-
-  // convert image back to byte representation
-  AddFloatPlane(128.0f, ImgF1, StrideF, Size);
-  CopyFloat2Byte(ImgF1, StrideF, ImgDst, Stride, Size);
-
-  // clean up memory
-  HIPCHECK(hipFree(dst));
-  HIPCHECK(hipFree(src));
-  FreePlane(ImgF1);
-
-  // return time taken by the operation
-  return avgTime;
-}
-
-/**
-**************************************************************************
-*  Wrapper function for short CUDA version of DCT, quantization and IDCT
-*implementations
-*
-* \param ImgSrc         [IN] - Source byte image plane
-* \param ImgDst         [IN] - Quantized result byte image plane
-* \param Stride         [IN] - Stride for both source and result planes
-* \param Size           [IN] - Size of both planes
-*
-* \return Execution time in milliseconds
-*/
-float WrapperCUDAshort(byte *ImgSrc, byte *ImgDst, int Stride, ROI Size) {
-  // allocate host buffers for DCT and other data
-  int StrideS;
-  short *ImgS1 = MallocPlaneShort(Size.width, Size.height, &StrideS);
-
-  // convert source image to short representation centered at 128
-  for (int i = 0; i < Size.height; i++) {
-    for (int j = 0; j < Size.width; j++) {
-      ImgS1[i * StrideS + j] = (short)ImgSrc[i * Stride + j] - 128;
-    }
-  }
-
-  // allocate device memory
-  short *SrcDst;
-  size_t DeviceStride;
-  HIPCHECK(hipMallocPitch((void **)(&SrcDst), &DeviceStride,
-                                  Size.width * sizeof(short), Size.height));
-  DeviceStride /= sizeof(short);
-
-  // copy from host memory to device
-  HIPCHECK(hipMemcpy2D(
-      SrcDst, DeviceStride * sizeof(short), ImgS1, StrideS * sizeof(short),
-      Size.width * sizeof(short), Size.height, hipMemcpyHostToDevice));
-
-  // create and start CUDA timer
-  StopWatchInterface *timerLibJpeg = 0;
-  sdkCreateTimer(&timerLibJpeg);
-  sdkResetTimer(&timerLibJpeg);
-
-  // setup execution parameters
-  dim3 GridShort(Size.width / KERS_BLOCK_WIDTH, Size.height / KERS_BLOCK_HEIGHT,
-                 1);
-  dim3 ThreadsShort(8, KERS_BLOCK_WIDTH / 8, KERS_BLOCK_HEIGHT / 8);
-
-  // perform block-wise DCT processing and benchmarking
-  sdkStartTimer(&timerLibJpeg);
-  CUDAkernelShortDCT<<<GridShort, ThreadsShort>>>(SrcDst, (int)DeviceStride);
-  HIPCHECK(hipDeviceSynchronize());
-  sdkStopTimer(&timerLibJpeg);
-  getLastCudaError("Kernel execution failed");
-
-  // stop and destroy CUDA timer
-  float TimerLibJpegSpan16b = sdkGetAverageTimerValue(&timerLibJpeg);
-  sdkDeleteTimer(&timerLibJpeg);
-
-  // setup execution parameters for quantization
-  dim3 ThreadsSmallBlocks(BLOCK_SIZE, BLOCK_SIZE);
-  dim3 GridSmallBlocks(Size.width / BLOCK_SIZE, Size.height / BLOCK_SIZE);
-
-  // execute Quantization kernel
-  CUDAkernelQuantizationShort<<<GridSmallBlocks, ThreadsSmallBlocks>>>(
-      SrcDst, (int)DeviceStride);
-  getLastCudaError("Kernel execution failed");
-
-  // perform block-wise IDCT processing
-  CUDAkernelShortIDCT<<<GridShort, ThreadsShort>>>(SrcDst, (int)DeviceStride);
-  HIPCHECK(hipDeviceSynchronize());
-  getLastCudaError("Kernel execution failed");
-
-  // copy quantized image block to host
-  HIPCHECK(hipMemcpy2D(
-      ImgS1, StrideS * sizeof(short), SrcDst, DeviceStride * sizeof(short),
-      Size.width * sizeof(short), Size.height, hipMemcpyDeviceToHost));
-
-  // convert image back to byte representation
-  for (int i = 0; i < Size.height; i++) {
-    for (int j = 0; j < Size.width; j++) {
-      ImgDst[i * Stride + j] = clamp_0_255(ImgS1[i * StrideS + j] + 128);
-    }
-  }
-
-  // free float buffers
-  HIPCHECK(hipFree(SrcDst));
-  FreePlane(ImgS1);
-
-  // return time taken by the operation
-  return TimerLibJpegSpan16b;
-}
-
-/**
-**************************************************************************
-*  Program entry point
-*
-* \param argc       [IN] - Number of command-line arguments
-* \param argv       [IN] - Array of command-line arguments
-*
-* \return Status code
-*/
-
-int main(int argc, char **argv) {
-  //
-  // Sample initialization
-  //
-  printf("%s Starting...\n\n", argv[0]);
-
-  // initialize CUDA
-  findCudaDevice(argc, (const char **)argv);
-
-  // source and results image filenames
-  char SampleImageFname[] = "teapot512.bmp";
-  char SampleImageFnameResGold1[] = "teapot512_gold1.bmp";
-  char SampleImageFnameResGold2[] = "teapot512_gold2.bmp";
-  char SampleImageFnameResCUDA1[] = "teapot512_cuda1.bmp";
-  char SampleImageFnameResCUDA2[] = "teapot512_cuda2.bmp";
-  char SampleImageFnameResCUDAshort[] = "teapot512_cuda_short.bmp";
-
-  char *pSampleImageFpath = sdkFindFilePath(SampleImageFname, argv[0]);
-
-  if (pSampleImageFpath == NULL) {
-    printf("dct8x8 could not locate Sample Image <%s>\nExiting...\n",
-           pSampleImageFpath);
-    exit(EXIT_FAILURE);
-  }
-
-  // preload image (acquire dimensions)
-  int ImgWidth, ImgHeight;
-  ROI ImgSize;
-  int res = PreLoadBmp(pSampleImageFpath, &ImgWidth, &ImgHeight);
-  ImgSize.width = ImgWidth;
-  ImgSize.height = ImgHeight;
-
-  // CONSOLE INFORMATION: saying hello to user
-  printf("CUDA sample DCT/IDCT implementation\n");
-  printf("===================================\n");
-  printf("Loading test image: %s... ", SampleImageFname);
-
-  if (res) {
-    printf("\nError: Image file not found or invalid!\n");
-    exit(EXIT_FAILURE);
-    return 1;
-  }
-
-  // check image dimensions are multiples of BLOCK_SIZE
-  if (ImgWidth % BLOCK_SIZE != 0 || ImgHeight % BLOCK_SIZE != 0) {
-    printf("\nError: Input image dimensions must be multiples of 8!\n");
-    exit(EXIT_FAILURE);
-    return 1;
-  }
-
-  printf("[%d x %d]... ", ImgWidth, ImgHeight);
-
-  // allocate image buffers
-  int ImgStride;
-  byte *ImgSrc = MallocPlaneByte(ImgWidth, ImgHeight, &ImgStride);
-  byte *ImgDstGold1 = MallocPlaneByte(ImgWidth, ImgHeight, &ImgStride);
-  byte *ImgDstGold2 = MallocPlaneByte(ImgWidth, ImgHeight, &ImgStride);
-  byte *ImgDstCUDA1 = MallocPlaneByte(ImgWidth, ImgHeight, &ImgStride);
-  byte *ImgDstCUDA2 = MallocPlaneByte(ImgWidth, ImgHeight, &ImgStride);
-  byte *ImgDstCUDAshort = MallocPlaneByte(ImgWidth, ImgHeight, &ImgStride);
-
-  // load sample image
-  LoadBmpAsGray(pSampleImageFpath, ImgStride, ImgSize, ImgSrc);
-
-  //
-  // RUNNING WRAPPERS
-  //
-
-  // compute Gold 1 version of DCT/quantization/IDCT
-  printf("Success\nRunning Gold 1 (CPU) version... ");
-  float TimeGold1 = WrapperGold1(ImgSrc, ImgDstGold1, ImgStride, ImgSize);
-
-  // compute Gold 2 version of DCT/quantization/IDCT
-  printf("Success\nRunning Gold 2 (CPU) version... ");
-  float TimeGold2 = WrapperGold2(ImgSrc, ImgDstGold2, ImgStride, ImgSize);
-
-  // compute CUDA 1 version of DCT/quantization/IDCT
-  printf("Success\nRunning CUDA 1 (GPU) version... ");
-  float TimeCUDA1 = WrapperCUDA1(ImgSrc, ImgDstCUDA1, ImgStride, ImgSize);
-
-  // compute CUDA 2 version of DCT/quantization/IDCT
-  printf("Success\nRunning CUDA 2 (GPU) version... ");
-  float TimeCUDA2 = WrapperCUDA2(ImgSrc, ImgDstCUDA2, ImgStride, ImgSize);
-
-  // compute CUDA short version of DCT/quantization/IDCT
-  printf("Success\nRunning CUDA short (GPU) version... ");
-  float TimeCUDAshort =
-      WrapperCUDAshort(ImgSrc, ImgDstCUDAshort, ImgStride, ImgSize);
-  //
-  // Execution statistics, result saving and validation
-  //
-
-  // dump result of Gold 1 processing
-  printf("Success\nDumping result to %s... ", SampleImageFnameResGold1);
-  DumpBmpAsGray(SampleImageFnameResGold1, ImgDstGold1, ImgStride, ImgSize);
-
-  // dump result of Gold 2 processing
-  printf("Success\nDumping result to %s... ", SampleImageFnameResGold2);
-  DumpBmpAsGray(SampleImageFnameResGold2, ImgDstGold2, ImgStride, ImgSize);
-
-  // dump result of CUDA 1 processing
-  printf("Success\nDumping result to %s... ", SampleImageFnameResCUDA1);
-  DumpBmpAsGray(SampleImageFnameResCUDA1, ImgDstCUDA1, ImgStride, ImgSize);
-
-  // dump result of CUDA 2 processing
-  printf("Success\nDumping result to %s... ", SampleImageFnameResCUDA2);
-  DumpBmpAsGray(SampleImageFnameResCUDA2, ImgDstCUDA2, ImgStride, ImgSize);
-
-  // dump result of CUDA short processing
-  printf("Success\nDumping result to %s... ", SampleImageFnameResCUDAshort);
-  DumpBmpAsGray(SampleImageFnameResCUDAshort, ImgDstCUDAshort, ImgStride,
-                ImgSize);
-  // print speed info
-  printf("Success\n");
-
-  printf("Processing time (CUDA 1)    : %f ms \n", TimeCUDA1);
-  printf("Processing time (CUDA 2)    : %f ms \n", TimeCUDA2);
-  printf("Processing time (CUDA short): %f ms \n", TimeCUDAshort);
-
-  // calculate PSNR between each pair of images
-  float PSNR_Src_DstGold1 =
-      CalculatePSNR(ImgSrc, ImgDstGold1, ImgStride, ImgSize);
-  float PSNR_Src_DstGold2 =
-      CalculatePSNR(ImgSrc, ImgDstGold2, ImgStride, ImgSize);
-  float PSNR_Src_DstCUDA1 =
-      CalculatePSNR(ImgSrc, ImgDstCUDA1, ImgStride, ImgSize);
-  float PSNR_Src_DstCUDA2 =
-      CalculatePSNR(ImgSrc, ImgDstCUDA2, ImgStride, ImgSize);
-  float PSNR_Src_DstCUDAshort =
-      CalculatePSNR(ImgSrc, ImgDstCUDAshort, ImgStride, ImgSize);
-  float PSNR_DstGold1_DstCUDA1 =
-      CalculatePSNR(ImgDstGold1, ImgDstCUDA1, ImgStride, ImgSize);
-  float PSNR_DstGold2_DstCUDA2 =
-      CalculatePSNR(ImgDstGold2, ImgDstCUDA2, ImgStride, ImgSize);
-  float PSNR_DstGold2_DstCUDA16b =
-      CalculatePSNR(ImgDstGold2, ImgDstCUDAshort, ImgStride, ImgSize);
-
-  printf("PSNR Original    <---> CPU(Gold 1)    : %f\n", PSNR_Src_DstGold1);
-  printf("PSNR Original    <---> CPU(Gold 2)    : %f\n", PSNR_Src_DstGold2);
-  printf("PSNR Original    <---> GPU(CUDA 1)    : %f\n", PSNR_Src_DstCUDA1);
-  printf("PSNR Original    <---> GPU(CUDA 2)    : %f\n", PSNR_Src_DstCUDA2);
-  printf("PSNR Original    <---> GPU(CUDA short): %f\n", PSNR_Src_DstCUDAshort);
-  printf("PSNR CPU(Gold 1) <---> GPU(CUDA 1)    : %f\n",
-         PSNR_DstGold1_DstCUDA1);
-  printf("PSNR CPU(Gold 2) <---> GPU(CUDA 2)    : %f\n",
-         PSNR_DstGold2_DstCUDA2);
-  printf("PSNR CPU(Gold 2) <---> GPU(CUDA short): %f\n",
-         PSNR_DstGold2_DstCUDA16b);
-
-  bool bTestResult = (PSNR_DstGold1_DstCUDA1 > PSNR_THRESHOLD_EQUAL &&
-                      PSNR_DstGold2_DstCUDA2 > PSNR_THRESHOLD_EQUAL &&
-                      PSNR_DstGold2_DstCUDA16b > PSNR_THRESHOLD_EQUAL);
-
-  //
-  // Finalization
-  //
-
-  // release byte planes
-  FreePlane(ImgSrc);
-  FreePlane(ImgDstGold1);
-  FreePlane(ImgDstGold2);
-  FreePlane(ImgDstCUDA1);
-  FreePlane(ImgDstCUDA2);
-  FreePlane(ImgDstCUDAshort);
-
-  // finalize
-  printf("\nTest Summary...\n");
-
-  if (!bTestResult) {
-    printf("Test failed!\n");
-    exit(EXIT_FAILURE);
-  }
-
-  printf("Test passed\n");
-  exit(EXIT_SUCCESS);
-}
-finalize
-  printf("\nTest Summary...\n");
-
-  if (!bTestResult) {
-    printf("Test failed!\n");
-    exit(EXIT_FAILURE);
-  }
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel1.cuh b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel1.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel1_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel1_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel2.cuh b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel2.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel2_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel2_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel_quantization.cuh b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel_quantization.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel_quantization_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel_quantization_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel_short.cuh b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel_short.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel_short_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_kernel_short_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/dct8x8_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/BarbaraBlocks1.bmp b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/BarbaraBlocks1.bmp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/BarbaraBlocks2.bmp b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/BarbaraBlocks2.bmp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/BarbaraBlocks3.bmp b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/BarbaraBlocks3.bmp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/CosineBasis.png b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/CosineBasis.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/Cosines.xls b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/Cosines.xls
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/DctJpeg.png b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/DctJpeg.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/barbara.bmp b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/barbara.bmp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/barbara_lg.png b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/barbara_lg.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/barbara_md.png b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/barbara_md.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/barbara_sm.png b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/barbara_sm.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/dct8x8.doc b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/dct8x8.doc
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/dct8x8.pdf b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/doc/dct8x8.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/teapot512_cuda1.bmp b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/teapot512_cuda1.bmp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/teapot512_cuda2.bmp b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/teapot512_cuda2.bmp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/teapot512_cuda_short.bmp b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/teapot512_cuda_short.bmp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/teapot512_gold1.bmp b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/teapot512_gold1.bmp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/teapot512_gold2.bmp b/src/samples/Samples/2_Concepts_and_Techniques/dct8x8/teapot512_gold2.bmp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/README.md b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_large.cuh b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_large.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_large_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_large_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_large_multi.cuh b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_large_multi.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_large_multi_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_large_multi_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_large_onei.cuh b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_large_onei.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_large_onei_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_large_onei_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_small.cuh b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_small.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_small_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_kernel_small_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_large.cu b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_large.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_large.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_large.cu.hip
old mode 100644
new mode 100755
index f98a3a3..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_large.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_large.cu.hip
@@ -1,370 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* Computation of eigenvalues of a large symmetric, tridiagonal matrix */
-
-// includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-#include <float.h>
-
-// includes, project
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-#include "config.h"
-#include "structs.h"
-#include "util.h"
-#include "matlab.h"
-
-#include "bisect_large.cuh"
-
-// includes, kernels
-#include "bisect_kernel_large.cuh"
-#include "bisect_kernel_large_onei.cuh"
-#include "bisect_kernel_large_multi.cuh"
-
-////////////////////////////////////////////////////////////////////////////////
-//! Initialize variables and memory for result
-//! @param  result handles to memory
-//! @param  matrix_size  size of the matrix
-////////////////////////////////////////////////////////////////////////////////
-void initResultDataLargeMatrix(ResultDataLarge &result,
-                               const unsigned int mat_size) {
-  // helper variables to initialize memory
-  unsigned int zero = 0;
-  unsigned int mat_size_f = sizeof(float) * mat_size;
-  unsigned int mat_size_ui = sizeof(unsigned int) * mat_size;
-
-  float *tempf = (float *)malloc(mat_size_f);
-  unsigned int *tempui = (unsigned int *)malloc(mat_size_ui);
-
-  for (unsigned int i = 0; i < mat_size; ++i) {
-    tempf[i] = 0.0f;
-    tempui[i] = 0;
-  }
-
-  // number of intervals containing only one eigenvalue after the first step
-  HIPCHECK(hipMalloc((void **)&result.g_num_one, sizeof(unsigned int)));
-  HIPCHECK(hipMemcpy(result.g_num_one, &zero, sizeof(unsigned int),
-                             hipMemcpyHostToDevice));
-
-  // number of (thread) blocks of intervals with multiple eigenvalues after
-  // the first iteration
-  HIPCHECK(
-      hipMalloc((void **)&result.g_num_blocks_mult, sizeof(unsigned int)));
-  HIPCHECK(hipMemcpy(result.g_num_blocks_mult, &zero,
-                             sizeof(unsigned int), hipMemcpyHostToDevice));
-
-  HIPCHECK(hipMalloc((void **)&result.g_left_one, mat_size_f));
-  HIPCHECK(hipMalloc((void **)&result.g_right_one, mat_size_f));
-  HIPCHECK(hipMalloc((void **)&result.g_pos_one, mat_size_ui));
-
-  HIPCHECK(hipMalloc((void **)&result.g_left_mult, mat_size_f));
-  HIPCHECK(hipMalloc((void **)&result.g_right_mult, mat_size_f));
-  HIPCHECK(hipMalloc((void **)&result.g_left_count_mult, mat_size_ui));
-  HIPCHECK(hipMalloc((void **)&result.g_right_count_mult, mat_size_ui));
-
-  HIPCHECK(
-      hipMemcpy(result.g_left_one, tempf, mat_size_f, hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy(result.g_right_one, tempf, mat_size_f,
-                             hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy(result.g_pos_one, tempui, mat_size_ui,
-                             hipMemcpyHostToDevice));
-
-  HIPCHECK(hipMemcpy(result.g_left_mult, tempf, mat_size_f,
-                             hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy(result.g_right_mult, tempf, mat_size_f,
-                             hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy(result.g_left_count_mult, tempui, mat_size_ui,
-                             hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy(result.g_right_count_mult, tempui, mat_size_ui,
-                             hipMemcpyHostToDevice));
-
-  HIPCHECK(hipMalloc((void **)&result.g_blocks_mult, mat_size_ui));
-  HIPCHECK(hipMemcpy(result.g_blocks_mult, tempui, mat_size_ui,
-                             hipMemcpyHostToDevice));
-  HIPCHECK(hipMalloc((void **)&result.g_blocks_mult_sum, mat_size_ui));
-  HIPCHECK(hipMemcpy(result.g_blocks_mult_sum, tempui, mat_size_ui,
-                             hipMemcpyHostToDevice));
-
-  HIPCHECK(hipMalloc((void **)&result.g_lambda_mult, mat_size_f));
-  HIPCHECK(hipMemcpy(result.g_lambda_mult, tempf, mat_size_f,
-                             hipMemcpyHostToDevice));
-  HIPCHECK(hipMalloc((void **)&result.g_pos_mult, mat_size_ui));
-  HIPCHECK(hipMemcpy(result.g_pos_mult, tempf, mat_size_ui,
-                             hipMemcpyHostToDevice));
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Cleanup result memory
-//! @param result  handles to memory
-////////////////////////////////////////////////////////////////////////////////
-void cleanupResultDataLargeMatrix(ResultDataLarge &result) {
-  HIPCHECK(hipFree(result.g_num_one));
-  HIPCHECK(hipFree(result.g_num_blocks_mult));
-  HIPCHECK(hipFree(result.g_left_one));
-  HIPCHECK(hipFree(result.g_right_one));
-  HIPCHECK(hipFree(result.g_pos_one));
-  HIPCHECK(hipFree(result.g_left_mult));
-  HIPCHECK(hipFree(result.g_right_mult));
-  HIPCHECK(hipFree(result.g_left_count_mult));
-  HIPCHECK(hipFree(result.g_right_count_mult));
-  HIPCHECK(hipFree(result.g_blocks_mult));
-  HIPCHECK(hipFree(result.g_blocks_mult_sum));
-  HIPCHECK(hipFree(result.g_lambda_mult));
-  HIPCHECK(hipFree(result.g_pos_mult));
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run the kernels to compute the eigenvalues for large matrices
-//! @param  input   handles to input data
-//! @param  result  handles to result data
-//! @param  mat_size  matrix size
-//! @param  precision  desired precision of eigenvalues
-//! @param  lg  lower limit of Gerschgorin interval
-//! @param  ug  upper limit of Gerschgorin interval
-//! @param  iterations  number of iterations (for timing)
-////////////////////////////////////////////////////////////////////////////////
-void computeEigenvaluesLargeMatrix(const InputData &input,
-                                   const ResultDataLarge &result,
-                                   const unsigned int mat_size,
-                                   const float precision, const float lg,
-                                   const float ug,
-                                   const unsigned int iterations) {
-  dim3 blocks(1, 1, 1);
-  dim3 threads(MAX_THREADS_BLOCK, 1, 1);
-
-  StopWatchInterface *timer_step1 = NULL;
-  StopWatchInterface *timer_step2_one = NULL;
-  StopWatchInterface *timer_step2_mult = NULL;
-  StopWatchInterface *timer_total = NULL;
-  sdkCreateTimer(&timer_step1);
-  sdkCreateTimer(&timer_step2_one);
-  sdkCreateTimer(&timer_step2_mult);
-  sdkCreateTimer(&timer_total);
-
-  sdkStartTimer(&timer_total);
-
-  // do for multiple iterations to improve timing accuracy
-  for (unsigned int iter = 0; iter < iterations; ++iter) {
-    sdkStartTimer(&timer_step1);
-    bisectKernelLarge<<<blocks, threads>>>(
-        input.g_a, input.g_b, mat_size, lg, ug, 0, mat_size, precision,
-        result.g_num_one, result.g_num_blocks_mult, result.g_left_one,
-        result.g_right_one, result.g_pos_one, result.g_left_mult,
-        result.g_right_mult, result.g_left_count_mult,
-        result.g_right_count_mult, result.g_blocks_mult,
-        result.g_blocks_mult_sum);
-
-    getLastCudaError("Kernel launch failed.");
-    HIPCHECK(hipDeviceSynchronize());
-    sdkStopTimer(&timer_step1);
-
-    // get the number of intervals containing one eigenvalue after the first
-    // processing step
-    unsigned int num_one_intervals;
-    HIPCHECK(hipMemcpy(&num_one_intervals, result.g_num_one,
-                               sizeof(unsigned int), hipMemcpyDeviceToHost));
-
-    dim3 grid_onei;
-    grid_onei.x = getNumBlocksLinear(num_one_intervals, MAX_THREADS_BLOCK);
-    dim3 threads_onei;
-    // use always max number of available threads to better balance load times
-    // for matrix data
-    threads_onei.x = MAX_THREADS_BLOCK;
-
-    // compute eigenvalues for intervals that contained only one eigenvalue
-    // after the first processing step
-    sdkStartTimer(&timer_step2_one);
-
-    bisectKernelLarge_OneIntervals<<<grid_onei, threads_onei>>>(
-        input.g_a, input.g_b, mat_size, num_one_intervals, result.g_left_one,
-        result.g_right_one, result.g_pos_one, precision);
-
-    getLastCudaError("bisectKernelLarge_OneIntervals() FAILED.");
-    HIPCHECK(hipDeviceSynchronize());
-    sdkStopTimer(&timer_step2_one);
-
-    // process intervals that contained more than one eigenvalue after
-    // the first processing step
-
-    // get the number of blocks of intervals that contain, in total when
-    // each interval contains only one eigenvalue, not more than
-    // MAX_THREADS_BLOCK threads
-    unsigned int num_blocks_mult = 0;
-    HIPCHECK(hipMemcpy(&num_blocks_mult, result.g_num_blocks_mult,
-                               sizeof(unsigned int), hipMemcpyDeviceToHost));
-
-    // setup the execution environment
-    dim3 grid_mult(num_blocks_mult, 1, 1);
-    dim3 threads_mult(MAX_THREADS_BLOCK, 1, 1);
-
-    sdkStartTimer(&timer_step2_mult);
-
-    bisectKernelLarge_MultIntervals<<<grid_mult, threads_mult>>>(
-        input.g_a, input.g_b, mat_size, result.g_blocks_mult,
-        result.g_blocks_mult_sum, result.g_left_mult, result.g_right_mult,
-        result.g_left_count_mult, result.g_right_count_mult,
-        result.g_lambda_mult, result.g_pos_mult, precision);
-
-    getLastCudaError("bisectKernelLarge_MultIntervals() FAILED.");
-    HIPCHECK(hipDeviceSynchronize());
-    sdkStopTimer(&timer_step2_mult);
-  }
-
-  sdkStopTimer(&timer_total);
-
-  printf("Average time step 1: %f ms\n",
-         sdkGetTimerValue(&timer_step1) / (float)iterations);
-  printf("Average time step 2, one intervals: %f ms\n",
-         sdkGetTimerValue(&timer_step2_one) / (float)iterations);
-  printf("Average time step 2, mult intervals: %f ms\n",
-         sdkGetTimerValue(&timer_step2_mult) / (float)iterations);
-
-  printf("Average time TOTAL: %f ms\n",
-         sdkGetTimerValue(&timer_total) / (float)iterations);
-
-  sdkDeleteTimer(&timer_step1);
-  sdkDeleteTimer(&timer_step2_one);
-  sdkDeleteTimer(&timer_step2_mult);
-  sdkDeleteTimer(&timer_total);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Process the result, that is obtain result from device and do simple sanity
-//! checking
-//! @param  input   handles to input data
-//! @param  result  handles to result data
-//! @param  mat_size  matrix size
-//! @param  filename  output filename
-////////////////////////////////////////////////////////////////////////////////
-bool processResultDataLargeMatrix(const InputData &input,
-                                  const ResultDataLarge &result,
-                                  const unsigned int mat_size,
-                                  const char *filename,
-                                  const unsigned int user_defined,
-                                  char *exec_path) {
-  bool bCompareResult = false;
-  const unsigned int mat_size_ui = sizeof(unsigned int) * mat_size;
-  const unsigned int mat_size_f = sizeof(float) * mat_size;
-
-  // copy data from intervals that contained more than one eigenvalue after
-  // the first processing step
-  float *lambda_mult = (float *)malloc(sizeof(float) * mat_size);
-  HIPCHECK(hipMemcpy(lambda_mult, result.g_lambda_mult,
-                             sizeof(float) * mat_size, hipMemcpyDeviceToHost));
-  unsigned int *pos_mult =
-      (unsigned int *)malloc(sizeof(unsigned int) * mat_size);
-  HIPCHECK(hipMemcpy(pos_mult, result.g_pos_mult,
-                             sizeof(unsigned int) * mat_size,
-                             hipMemcpyDeviceToHost));
-
-  unsigned int *blocks_mult_sum =
-      (unsigned int *)malloc(sizeof(unsigned int) * mat_size);
-  HIPCHECK(hipMemcpy(blocks_mult_sum, result.g_blocks_mult_sum,
-                             sizeof(unsigned int) * mat_size,
-                             hipMemcpyDeviceToHost));
-
-  unsigned int num_one_intervals;
-  HIPCHECK(hipMemcpy(&num_one_intervals, result.g_num_one,
-                             sizeof(unsigned int), hipMemcpyDeviceToHost));
-
-  unsigned int sum_blocks_mult = mat_size - num_one_intervals;
-
-  // copy data for intervals that contained one eigenvalue after the first
-  // processing step
-  float *left_one = (float *)malloc(mat_size_f);
-  float *right_one = (float *)malloc(mat_size_f);
-  unsigned int *pos_one = (unsigned int *)malloc(mat_size_ui);
-  HIPCHECK(hipMemcpy(left_one, result.g_left_one, mat_size_f,
-                             hipMemcpyDeviceToHost));
-  HIPCHECK(hipMemcpy(right_one, result.g_right_one, mat_size_f,
-                             hipMemcpyDeviceToHost));
-  HIPCHECK(hipMemcpy(pos_one, result.g_pos_one, mat_size_ui,
-                             hipMemcpyDeviceToHost));
-
-  // extract eigenvalues
-  float *eigenvals = (float *)malloc(mat_size_f);
-
-  // singleton intervals generated in the second step
-  for (unsigned int i = 0; i < sum_blocks_mult; ++i) {
-    eigenvals[pos_mult[i] - 1] = lambda_mult[i];
-  }
-
-  // singleton intervals generated in the first step
-  unsigned int index = 0;
-
-  for (unsigned int i = 0; i < num_one_intervals; ++i, ++index) {
-    eigenvals[pos_one[i] - 1] = left_one[i];
-  }
-
-  if (1 == user_defined) {
-    // store result
-    writeTridiagSymMatlab(filename, input.a, input.b + 1, eigenvals, mat_size);
-    // getLastCudaError( sdkWriteFilef( filename, eigenvals, mat_size, 0.0f));
-
-    printf("User requests non-default argument(s), skipping self-check!\n");
-    bCompareResult = true;
-  } else {
-    // compare with reference solution
-
-    float *reference = NULL;
-    unsigned int input_data_size = 0;
-
-    char *ref_path = sdkFindFilePath("reference.dat", exec_path);
-    assert(NULL != ref_path);
-    sdkReadFile(ref_path, &reference, &input_data_size, false);
-    assert(input_data_size == mat_size);
-
-    // there's an imprecision of Sturm count computation which makes an
-    // additional offset necessary
-    float tolerance = 1.0e-5f + 5.0e-6f;
-
-    if (sdkCompareL2fe(reference, eigenvals, mat_size, tolerance) == true) {
-      bCompareResult = true;
-    } else {
-      bCompareResult = false;
-    }
-
-    free(ref_path);
-    free(reference);
-  }
-
-  freePtr(eigenvals);
-  freePtr(lambda_mult);
-  freePtr(pos_mult);
-  freePtr(blocks_mult_sum);
-  freePtr(left_one);
-  freePtr(right_one);
-  freePtr(pos_one);
-
-  return bCompareResult;
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_large.cuh b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_large.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_large_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_large_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_small.cu b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_small.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_small.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_small.cu.hip
old mode 100644
new mode 100755
index 75c2b72..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_small.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_small.cu.hip
@@ -1,184 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* Computation of eigenvalues of a small symmetric, tridiagonal matrix */
-
-// includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-#include <float.h>
-
-// includes, project
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-#include "config.h"
-#include "structs.h"
-#include "matlab.h"
-
-// includes, kernels
-#include "bisect_kernel_small.cuh"
-
-// includes, file
-#include "bisect_small.cuh"
-
-////////////////////////////////////////////////////////////////////////////////
-//! Determine eigenvalues for matrices smaller than MAX_SMALL_MATRIX
-//! @param TimingIterations  number of iterations for timing
-//! @param  input  handles to input data of kernel
-//! @param  result handles to result of kernel
-//! @param  mat_size  matrix size
-//! @param  lg  lower limit of Gerschgorin interval
-//! @param  ug  upper limit of Gerschgorin interval
-//! @param  precision  desired precision of eigenvalues
-//! @param  iterations  number of iterations for timing
-////////////////////////////////////////////////////////////////////////////////
-void computeEigenvaluesSmallMatrix(const InputData &input,
-                                   ResultDataSmall &result,
-                                   const unsigned int mat_size, const float lg,
-                                   const float ug, const float precision,
-                                   const unsigned int iterations) {
-  StopWatchInterface *timer = NULL;
-  sdkCreateTimer(&timer);
-  sdkStartTimer(&timer);
-
-  for (unsigned int i = 0; i < iterations; ++i) {
-    dim3 blocks(1, 1, 1);
-    dim3 threads(MAX_THREADS_BLOCK_SMALL_MATRIX, 1, 1);
-
-    bisectKernel<<<blocks, threads>>>(input.g_a, input.g_b, mat_size,
-                                      result.g_left, result.g_right,
-                                      result.g_left_count, result.g_right_count,
-                                      lg, ug, 0, mat_size, precision);
-  }
-
-  HIPCHECK(hipDeviceSynchronize());
-  sdkStopTimer(&timer);
-  getLastCudaError("Kernel launch failed");
-  printf("Average time: %f ms (%i iterations)\n",
-         sdkGetTimerValue(&timer) / (float)iterations, iterations);
-
-  sdkDeleteTimer(&timer);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Initialize variables and memory for the result for small matrices
-//! @param result  handles to the necessary memory
-//! @param  mat_size  matrix_size
-////////////////////////////////////////////////////////////////////////////////
-void initResultSmallMatrix(ResultDataSmall &result,
-                           const unsigned int mat_size) {
-  result.mat_size_f = sizeof(float) * mat_size;
-  result.mat_size_ui = sizeof(unsigned int) * mat_size;
-
-  result.eigenvalues = (float *)malloc(result.mat_size_f);
-
-  // helper variables
-  result.zero_f = (float *)malloc(result.mat_size_f);
-  result.zero_ui = (unsigned int *)malloc(result.mat_size_ui);
-
-  for (unsigned int i = 0; i < mat_size; ++i) {
-    result.zero_f[i] = 0.0f;
-    result.zero_ui[i] = 0;
-
-    result.eigenvalues[i] = 0.0f;
-  }
-
-  HIPCHECK(hipMalloc((void **)&result.g_left, result.mat_size_f));
-  HIPCHECK(hipMalloc((void **)&result.g_right, result.mat_size_f));
-
-  HIPCHECK(
-      hipMalloc((void **)&result.g_left_count, result.mat_size_ui));
-  HIPCHECK(
-      hipMalloc((void **)&result.g_right_count, result.mat_size_ui));
-
-  // initialize result memory
-  HIPCHECK(hipMemcpy(result.g_left, result.zero_f, result.mat_size_f,
-                             hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy(result.g_right, result.zero_f, result.mat_size_f,
-                             hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy(result.g_right_count, result.zero_ui,
-                             result.mat_size_ui, hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy(result.g_left_count, result.zero_ui,
-                             result.mat_size_ui, hipMemcpyHostToDevice));
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Cleanup memory and variables for result for small matrices
-//! @param  result  handle to variables
-////////////////////////////////////////////////////////////////////////////////
-void cleanupResultSmallMatrix(ResultDataSmall &result) {
-  freePtr(result.eigenvalues);
-  freePtr(result.zero_f);
-  freePtr(result.zero_ui);
-
-  HIPCHECK(hipFree(result.g_left));
-  HIPCHECK(hipFree(result.g_right));
-  HIPCHECK(hipFree(result.g_left_count));
-  HIPCHECK(hipFree(result.g_right_count));
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Process the result obtained on the device, that is transfer to host and
-//! perform basic sanity checking
-//! @param  input  handles to input data
-//! @param  result  handles to result data
-//! @param  mat_size   matrix size
-//! @param  filename  output filename
-////////////////////////////////////////////////////////////////////////////////
-void processResultSmallMatrix(const InputData &input,
-                              const ResultDataSmall &result,
-                              const unsigned int mat_size,
-                              const char *filename) {
-  const unsigned int mat_size_f = sizeof(float) * mat_size;
-  const unsigned int mat_size_ui = sizeof(unsigned int) * mat_size;
-
-  // copy data back to host
-  float *left = (float *)malloc(mat_size_f);
-  unsigned int *left_count = (unsigned int *)malloc(mat_size_ui);
-
-  HIPCHECK(
-      hipMemcpy(left, result.g_left, mat_size_f, hipMemcpyDeviceToHost));
-  HIPCHECK(hipMemcpy(left_count, result.g_left_count, mat_size_ui,
-                             hipMemcpyDeviceToHost));
-
-  float *eigenvalues = (float *)malloc(mat_size_f);
-
-  for (unsigned int i = 0; i < mat_size; ++i) {
-    eigenvalues[left_count[i]] = left[i];
-  }
-
-  // save result in matlab format
-  writeTridiagSymMatlab(filename, input.a, input.b + 1, eigenvalues, mat_size);
-
-  freePtr(left);
-  freePtr(left_count);
-  freePtr(eigenvalues);
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_small.cuh b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_small.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_small_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_small_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_util.cu b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_util.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_util.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_util.cu.hip
old mode 100644
new mode 100755
index 1061c2a..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_util.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/bisect_util.cu.hip
@@ -1,530 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* Utility / shared functionality for bisection kernels */
-
-#ifndef _BISECT_UTIL_H_
-#define _BISECT_UTIL_H_
-
-#include <hip/hip_runtime.h>
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-
-// includes, project
-#include "config.h"
-#include "util.h"
-
-////////////////////////////////////////////////////////////////////////////////
-//! Compute the next lower power of two of n
-//! @param  n  number for which next higher power of two is sought
-////////////////////////////////////////////////////////////////////////////////
-__device__ inline int floorPow2(int n) {
-  // early out if already power of two
-  if (0 == (n & (n - 1))) {
-    return n;
-  }
-
-  int exp;
-  frexp((float)n, &exp);
-  return (1 << (exp - 1));
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Compute the next higher power of two of n
-//! @param  n  number for which next higher power of two is sought
-////////////////////////////////////////////////////////////////////////////////
-__device__ inline int ceilPow2(int n) {
-  // early out if already power of two
-  if (0 == (n & (n - 1))) {
-    return n;
-  }
-
-  int exp;
-  frexp((float)n, &exp);
-  return (1 << exp);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Compute midpoint of interval [\a left, \a right] avoiding overflow if
-//! possible
-//! @param left   left / lower limit of interval
-//! @param right  right / upper limit of interval
-////////////////////////////////////////////////////////////////////////////////
-__device__ inline float computeMidpoint(const float left, const float right) {
-  float mid;
-
-  if (sign_f(left) == sign_f(right)) {
-    mid = left + (right - left) * 0.5f;
-  } else {
-    mid = (left + right) * 0.5f;
-  }
-
-  return mid;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Check if interval converged and store appropriately
-//! @param  addr    address where to store the information of the interval
-//! @param  s_left  shared memory storage for left interval limits
-//! @param  s_right  shared memory storage for right interval limits
-//! @param  s_left_count  shared memory storage for number of eigenvalues less
-//!                       than left interval limits
-//! @param  s_right_count  shared memory storage for number of eigenvalues less
-//!                       than right interval limits
-//! @param  left   lower limit of interval
-//! @param  right  upper limit of interval
-//! @param  left_count  eigenvalues less than \a left
-//! @param  right_count  eigenvalues less than \a right
-//! @param  precision  desired precision for eigenvalues
-////////////////////////////////////////////////////////////////////////////////
-template <class S, class T>
-__device__ void storeInterval(unsigned int addr, float *s_left, float *s_right,
-                              T *s_left_count, T *s_right_count, float left,
-                              float right, S left_count, S right_count,
-                              float precision) {
-  s_left_count[addr] = left_count;
-  s_right_count[addr] = right_count;
-
-  // check if interval converged
-  float t0 = abs(right - left);
-  float t1 = max(abs(left), abs(right)) * precision;
-
-  if (t0 <= max(MIN_ABS_INTERVAL, t1)) {
-    // compute mid point
-    float lambda = computeMidpoint(left, right);
-
-    // mark as converged
-    s_left[addr] = lambda;
-    s_right[addr] = lambda;
-  } else {
-    // store current limits
-    s_left[addr] = left;
-    s_right[addr] = right;
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Compute number of eigenvalues that are smaller than x given a symmetric,
-//! real, and tridiagonal matrix
-//! @param  g_d  diagonal elements stored in global memory
-//! @param  g_s  superdiagonal elements stored in global memory
-//! @param  n    size of matrix
-//! @param  x    value for which the number of eigenvalues that are smaller is
-//!              seeked
-//! @param  tid  thread identified (e.g. threadIdx.x or gtid)
-//! @param  num_intervals_active  number of active intervals / threads that
-//!                               currently process an interval
-//! @param  s_d  scratch space to store diagonal entries of the tridiagonal
-//!              matrix in shared memory
-//! @param  s_s  scratch space to store superdiagonal entries of the tridiagonal
-//!              matrix in shared memory
-//! @param  converged  flag if the current thread is already converged (that
-//!         is count does not have to be computed)
-////////////////////////////////////////////////////////////////////////////////
-__device__ inline unsigned int computeNumSmallerEigenvals(
-    float *g_d, float *g_s, const unsigned int n, const float x,
-    const unsigned int tid, const unsigned int num_intervals_active, float *s_d,
-    float *s_s, unsigned int converged, cg::thread_block cta) {
-  float delta = 1.0f;
-  unsigned int count = 0;
-
-  cg::sync(cta);
-
-  // read data into shared memory
-  if (threadIdx.x < n) {
-    s_d[threadIdx.x] = *(g_d + threadIdx.x);
-    s_s[threadIdx.x] = *(g_s + threadIdx.x - 1);
-  }
-
-  cg::sync(cta);
-
-  // perform loop only for active threads
-  if ((tid < num_intervals_active) && (0 == converged)) {
-    // perform (optimized) Gaussian elimination to determine the number
-    // of eigenvalues that are smaller than n
-    for (unsigned int k = 0; k < n; ++k) {
-      delta = s_d[k] - x - (s_s[k] * s_s[k]) / delta;
-      count += (delta < 0) ? 1 : 0;
-    }
-
-  }  // end if thread currently processing an interval
-
-  return count;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Compute number of eigenvalues that are smaller than x given a symmetric,
-//! real, and tridiagonal matrix
-//! @param  g_d  diagonal elements stored in global memory
-//! @param  g_s  superdiagonal elements stored in global memory
-//! @param  n    size of matrix
-//! @param  x    value for which the number of eigenvalues that are smaller is
-//!              seeked
-//! @param  tid  thread identified (e.g. threadIdx.x or gtid)
-//! @param  num_intervals_active  number of active intervals / threads that
-//!                               currently process an interval
-//! @param  s_d  scratch space to store diagonal entries of the tridiagonal
-//!              matrix in shared memory
-//! @param  s_s  scratch space to store superdiagonal entries of the tridiagonal
-//!              matrix in shared memory
-//! @param  converged  flag if the current thread is already converged (that
-//!         is count does not have to be computed)
-////////////////////////////////////////////////////////////////////////////////
-__device__ inline unsigned int computeNumSmallerEigenvalsLarge(
-    float *g_d, float *g_s, const unsigned int n, const float x,
-    const unsigned int tid, const unsigned int num_intervals_active, float *s_d,
-    float *s_s, unsigned int converged, cg::thread_block cta) {
-  float delta = 1.0f;
-  unsigned int count = 0;
-
-  unsigned int rem = n;
-
-  // do until whole diagonal and superdiagonal has been loaded and processed
-  for (unsigned int i = 0; i < n; i += blockDim.x) {
-    cg::sync(cta);
-
-    // read new chunk of data into shared memory
-    if ((i + threadIdx.x) < n) {
-      s_d[threadIdx.x] = *(g_d + i + threadIdx.x);
-      s_s[threadIdx.x] = *(g_s + i + threadIdx.x - 1);
-    }
-
-    cg::sync(cta);
-
-    if (tid < num_intervals_active) {
-      // perform (optimized) Gaussian elimination to determine the number
-      // of eigenvalues that are smaller than n
-      for (unsigned int k = 0; k < min((int)rem, (int)blockDim.x); ++k) {
-        delta = s_d[k] - x - (s_s[k] * s_s[k]) / delta;
-        // delta = (abs( delta) < (1.0e-10)) ? -(1.0e-10) : delta;
-        count += (delta < 0) ? 1 : 0;
-      }
-
-    }  // end if thread currently processing an interval
-
-    rem -= blockDim.x;
-  }
-
-  return count;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Store all non-empty intervals resulting from the subdivision of the interval
-//! currently processed by the thread
-//! @param  addr  base address for storing intervals
-//! @param  num_threads_active  number of threads / intervals in current sweep
-//! @param  s_left  shared memory storage for left interval limits
-//! @param  s_right  shared memory storage for right interval limits
-//! @param  s_left_count  shared memory storage for number of eigenvalues less
-//!                       than left interval limits
-//! @param  s_right_count  shared memory storage for number of eigenvalues less
-//!                       than right interval limits
-//! @param  left   lower limit of interval
-//! @param  mid    midpoint of interval
-//! @param  right  upper limit of interval
-//! @param  left_count  eigenvalues less than \a left
-//! @param  mid_count  eigenvalues less than \a mid
-//! @param  right_count  eigenvalues less than \a right
-//! @param  precision  desired precision for eigenvalues
-//! @param  compact_second_chunk  shared mem flag if second chunk is used and
-//!                               ergo requires compaction
-//! @param  s_compaction_list_exc  helper array for stream compaction,
-//!                                s_compaction_list_exc[tid] = 1 when the
-//!                                thread generated two child intervals
-//! @is_active_interval  mark is thread has a second non-empty child interval
-////////////////////////////////////////////////////////////////////////////////
-template <class S, class T>
-__device__ void storeNonEmptyIntervals(
-    unsigned int addr, const unsigned int num_threads_active, float *s_left,
-    float *s_right, T *s_left_count, T *s_right_count, float left, float mid,
-    float right, const S left_count, const S mid_count, const S right_count,
-    float precision, unsigned int &compact_second_chunk,
-    T *s_compaction_list_exc, unsigned int &is_active_second) {
-  // check if both child intervals are valid
-  if ((left_count != mid_count) && (mid_count != right_count)) {
-    // store the left interval
-    storeInterval(addr, s_left, s_right, s_left_count, s_right_count, left, mid,
-                  left_count, mid_count, precision);
-
-    // mark that a second interval has been generated, only stored after
-    // stream compaction of second chunk
-    is_active_second = 1;
-    s_compaction_list_exc[threadIdx.x] = 1;
-    atomicExch(&compact_second_chunk, 1);
-  } else {
-    // only one non-empty child interval
-
-    // mark that no second child
-    is_active_second = 0;
-    s_compaction_list_exc[threadIdx.x] = 0;
-
-    // store the one valid child interval
-    if (left_count != mid_count) {
-      storeInterval(addr, s_left, s_right, s_left_count, s_right_count, left,
-                    mid, left_count, mid_count, precision);
-    } else {
-      storeInterval(addr, s_left, s_right, s_left_count, s_right_count, mid,
-                    right, mid_count, right_count, precision);
-    }
-  }
-}
-////////////////////////////////////////////////////////////////////////////////
-//! Create indices for compaction, that is process \a s_compaction_list_exc
-//! which is 1 for intervals that generated a second child and 0 otherwise
-//! and create for each of the non-zero elements the index where the new
-//! interval belongs to in a compact representation of all generated second
-//! childs
-//! @param   s_compaction_list_exc  list containing the flags which threads
-//!                                 generated two children
-//! @param   num_threads_compaction number of threads to employ for compaction
-////////////////////////////////////////////////////////////////////////////////
-template <class T>
-__device__ void createIndicesCompaction(T *s_compaction_list_exc,
-                                        unsigned int num_threads_compaction,
-                                        cg::thread_block cta) {
-  unsigned int offset = 1;
-  const unsigned int tid = threadIdx.x;
-
-  // higher levels of scan tree
-  for (int d = (num_threads_compaction >> 1); d > 0; d >>= 1) {
-    cg::sync(cta);
-
-    if (tid < d) {
-      unsigned int ai = offset * (2 * tid + 1) - 1;
-      unsigned int bi = offset * (2 * tid + 2) - 1;
-
-      s_compaction_list_exc[bi] =
-          s_compaction_list_exc[bi] + s_compaction_list_exc[ai];
-    }
-
-    offset <<= 1;
-  }
-
-  // traverse down tree: first down to level 2 across
-  for (int d = 2; d < num_threads_compaction; d <<= 1) {
-    offset >>= 1;
-    cg::sync(cta);
-
-    if (tid < (d - 1)) {
-      unsigned int ai = offset * (tid + 1) - 1;
-      unsigned int bi = ai + (offset >> 1);
-
-      s_compaction_list_exc[bi] =
-          s_compaction_list_exc[bi] + s_compaction_list_exc[ai];
-    }
-  }
-
-  cg::sync(cta);
-}
-
-///////////////////////////////////////////////////////////////////////////////
-//! Perform stream compaction for second child intervals
-//! @param  s_left  shared
-//! @param  s_left  shared memory storage for left interval limits
-//! @param  s_right  shared memory storage for right interval limits
-//! @param  s_left_count  shared memory storage for number of eigenvalues less
-//!                       than left interval limits
-//! @param  s_right_count  shared memory storage for number of eigenvalues less
-//!                       than right interval limits
-//! @param  mid    midpoint of current interval (left of new interval)
-//! @param  right  upper limit of interval
-//! @param  mid_count  eigenvalues less than \a mid
-//! @param  s_compaction_list  list containing the indices where the data has
-//!         to be stored
-//! @param  num_threads_active  number of active threads / intervals
-//! @is_active_interval  mark is thread has a second non-empty child interval
-///////////////////////////////////////////////////////////////////////////////
-template <class T>
-__device__ void compactIntervals(float *s_left, float *s_right, T *s_left_count,
-                                 T *s_right_count, float mid, float right,
-                                 unsigned int mid_count,
-                                 unsigned int right_count, T *s_compaction_list,
-                                 unsigned int num_threads_active,
-                                 unsigned int is_active_second) {
-  const unsigned int tid = threadIdx.x;
-
-  // perform compaction / copy data for all threads where the second
-  // child is not dead
-  if ((tid < num_threads_active) && (1 == is_active_second)) {
-    unsigned int addr_w = num_threads_active + s_compaction_list[tid];
-
-    s_left[addr_w] = mid;
-    s_right[addr_w] = right;
-    s_left_count[addr_w] = mid_count;
-    s_right_count[addr_w] = right_count;
-  }
-}
-
-///////////////////////////////////////////////////////////////////////////////
-//! Store intervals that have already converged (w.r.t. the desired precision),
-//! duplicating intervals that contain multiple eigenvalues
-//! @param  s_left  shared memory storage for left interval limits
-//! @param  s_right  shared memory storage for right interval limits
-//! @param  s_left_count  shared memory storage for number of eigenvalues less
-//!                       than left interval limits
-//! @param  s_right_count  shared memory storage for number of eigenvalues less
-//!                       than right interval limits
-//! @param  left   lower limit of interval
-//! @param  mid    midpoint of interval (updated if split is necessary)
-//! @param  right  upper limit of interval
-//! @param  left_count  eigenvalues less than \a left
-//! @param  mid_count  eigenvalues less than \a mid
-//! @param  right_count  eigenvalues less than \a right
-//! @param  s_compaction_list_exc  helper array for stream compaction, updated
-//!                                at tid if split is necessary
-//! @param  compact_second_chunk  shared mem flag if second chunk is used and
-//!                               ergo requires compaction
-//! @param  num_threads_active  number of active threads / intervals
-///////////////////////////////////////////////////////////////////////////////
-template <class T, class S>
-__device__ void storeIntervalConverged(float *s_left, float *s_right,
-                                       T *s_left_count, T *s_right_count,
-                                       float &left, float &mid, float &right,
-                                       S &left_count, S &mid_count,
-                                       S &right_count, T *s_compaction_list_exc,
-                                       unsigned int &compact_second_chunk,
-                                       const unsigned int num_threads_active) {
-  const unsigned int tid = threadIdx.x;
-  const unsigned int multiplicity = right_count - left_count;
-
-  // check multiplicity of eigenvalue
-  if (1 == multiplicity) {
-    // just re-store intervals, simple eigenvalue
-    s_left[tid] = left;
-    s_right[tid] = right;
-    s_left_count[tid] = left_count;
-    s_right_count[tid] = right_count;
-
-    // mark that no second child / clear
-    s_right_count[tid + num_threads_active] = 0;
-    s_compaction_list_exc[tid] = 0;
-  } else {
-    // number of eigenvalues after the split less than mid
-    mid_count = left_count + (multiplicity >> 1);
-
-    // store left interval
-    s_left[tid] = left;
-    s_right[tid] = right;
-    s_left_count[tid] = left_count;
-    s_right_count[tid] = mid_count;
-
-    mid = left;
-
-    // mark that second child interval exists
-    s_right_count[tid + num_threads_active] = right_count;
-    s_compaction_list_exc[tid] = 1;
-    compact_second_chunk = 1;
-  }
-}
-
-template <class T, class S>
-__device__ void storeIntervalConverged(float *s_left, float *s_right,
-                                       T *s_left_count, T *s_right_count,
-                                       float &left, float &mid, float &right,
-                                       S &left_count, S &mid_count,
-                                       S &right_count, T *s_compaction_list_exc,
-                                       unsigned int &compact_second_chunk,
-                                       const unsigned int num_threads_active,
-                                       unsigned int &is_active_second) {
-  const unsigned int tid = threadIdx.x;
-  const unsigned int multiplicity = right_count - left_count;
-
-  // check multiplicity of eigenvalue
-  if (1 == multiplicity) {
-    // just re-store intervals, simple eigenvalue
-    s_left[tid] = left;
-    s_right[tid] = right;
-    s_left_count[tid] = left_count;
-    s_right_count[tid] = right_count;
-
-    // mark that no second child / clear
-    is_active_second = 0;
-    s_compaction_list_exc[tid] = 0;
-  } else {
-    // number of eigenvalues after the split less than mid
-    mid_count = left_count + (multiplicity >> 1);
-
-    // store left interval
-    s_left[tid] = left;
-    s_right[tid] = right;
-    s_left_count[tid] = left_count;
-    s_right_count[tid] = mid_count;
-
-    mid = left;
-
-    // mark that second child interval exists
-    is_active_second = 1;
-    s_compaction_list_exc[tid] = 1;
-    compact_second_chunk = 1;
-  }
-}
-
-///////////////////////////////////////////////////////////////////////////////
-//! Subdivide interval if active and not already converged
-//! @param tid  id of thread
-//! @param  s_left  shared memory storage for left interval limits
-//! @param  s_right  shared memory storage for right interval limits
-//! @param  s_left_count  shared memory storage for number of eigenvalues less
-//!                       than left interval limits
-//! @param  s_right_count  shared memory storage for number of eigenvalues less
-//!                       than right interval limits
-//! @param  num_threads_active  number of active threads in warp
-//! @param  left   lower limit of interval
-//! @param  right  upper limit of interval
-//! @param  left_count  eigenvalues less than \a left
-//! @param  right_count  eigenvalues less than \a right
-//! @param  all_threads_converged  shared memory flag if all threads are
-//!                                 converged
-///////////////////////////////////////////////////////////////////////////////
-template <class T>
-__device__ void subdivideActiveInterval(
-    const unsigned int tid, float *s_left, float *s_right, T *s_left_count,
-    T *s_right_count, const unsigned int num_threads_active, float &left,
-    float &right, unsigned int &left_count, unsigned int &right_count,
-    float &mid, unsigned int &all_threads_converged) {
-  // for all active threads
-  if (tid < num_threads_active) {
-    left = s_left[tid];
-    right = s_right[tid];
-    left_count = s_left_count[tid];
-    right_count = s_right_count[tid];
-
-    // check if thread already converged
-    if (left != right) {
-      mid = computeMidpoint(left, right);
-      atomicExch(&all_threads_converged, 0);
-    } else if ((right_count - left_count) > 1) {
-      // mark as not converged if multiple eigenvalues enclosed
-      // duplicate interval in storeIntervalsConverged()
-      atomicExch(&all_threads_converged, 0);
-    }
-
-  }  // end for all active threads
-}
-
-#endif  // #ifndef _BISECT_UTIL_H_
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/config.h b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/config.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/config_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/config_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/data/diagonal.dat b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/data/diagonal.dat
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/data/reference.dat b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/data/reference.dat
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/data/superdiagonal.dat b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/data/superdiagonal.dat
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/doc/eigenvalues.doc b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/doc/eigenvalues.doc
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/doc/eigenvalues.pdf b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/doc/eigenvalues.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues.out b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/eigenvalues_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/gerschgorin.cpp b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/gerschgorin.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/gerschgorin.h b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/gerschgorin.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/gerschgorin_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/gerschgorin_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/gerschgorin_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/gerschgorin_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/main.cu b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/main.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/main.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/main.cu.hip
old mode 100644
new mode 100755
index 771b226..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/main.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/main.cu.hip
@@ -1,327 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* Computation of eigenvalues of symmetric, tridiagonal matrix using
- * bisection.
- */
-
-// includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-#include <float.h>
-#include <assert.h>
-
-// includes, project
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-#include "config.h"
-#include "structs.h"
-#include "matlab.h"
-#include "util.h"
-#include "gerschgorin.h"
-
-#include "bisect_small.cuh"
-#include "bisect_large.cuh"
-
-////////////////////////////////////////////////////////////////////////////////
-// declaration, forward
-bool runTest(int argc, char **argv);
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  bool bQAResults = false;
-
-  printf("Starting eigenvalues\n");
-
-  bQAResults = runTest(argc, argv);
-  printf("Test %s\n", bQAResults ? "Succeeded!" : "Failed!");
-
-  exit(bQAResults ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Initialize the input data to the algorithm
-//! @param input  handles to the input data
-//! @param exec_path  path where executable is run (argv[0])
-//! @param mat_size  size of the matrix
-//! @param user_defined  1 if the matrix size has been requested by the user,
-//!                      0 if the default size
-////////////////////////////////////////////////////////////////////////////////
-void initInputData(InputData &input, char *exec_path,
-                   const unsigned int mat_size,
-                   const unsigned int user_defined) {
-  // allocate memory
-  input.a = (float *)malloc(sizeof(float) * mat_size);
-  input.b = (float *)malloc(sizeof(float) * mat_size);
-
-  if (1 == user_defined) {
-    // initialize diagonal and superdiagonal entries with random values
-    srand(278217421);
-
-    // srand( clock());
-    for (unsigned int i = 0; i < mat_size; ++i) {
-      input.a[i] = (float)(2.0 * (((double)rand() / (double)RAND_MAX) - 0.5));
-      input.b[i] = (float)(2.0 * (((double)rand() / (double)RAND_MAX) - 0.5));
-    }
-
-    // the first element of s is used as padding on the device (thus the
-    // whole vector is copied to the device but the kernels are launched
-    // with (s+1) as start address
-    input.b[0] = 0.0f;
-  } else {
-    // read default matrix
-    unsigned int input_data_size = mat_size;
-    char *diag_path = sdkFindFilePath("diagonal.dat", exec_path);
-    assert(NULL != diag_path);
-    sdkReadFile(diag_path, &(input.a), &input_data_size, false);
-
-    char *sdiag_path = sdkFindFilePath("superdiagonal.dat", exec_path);
-    assert(NULL != sdiag_path);
-    sdkReadFile(sdiag_path, &(input.b), &input_data_size, false);
-
-    free(diag_path);
-    free(sdiag_path);
-  }
-
-  // allocate device memory for input
-  HIPCHECK(hipMalloc((void **)&(input.g_a), sizeof(float) * mat_size));
-  HIPCHECK(
-      hipMalloc((void **)&(input.g_b_raw), sizeof(float) * mat_size));
-
-  // copy data to device
-  HIPCHECK(hipMemcpy(input.g_a, input.a, sizeof(float) * mat_size,
-                             hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy(input.g_b_raw, input.b, sizeof(float) * mat_size,
-                             hipMemcpyHostToDevice));
-
-  input.g_b = input.g_b_raw + 1;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Clean up input data, in particular allocated memory
-//! @param input  handles to the input data
-////////////////////////////////////////////////////////////////////////////////
-void cleanupInputData(InputData &input) {
-  freePtr(input.a);
-  freePtr(input.b);
-
-  HIPCHECK(hipFree(input.g_a));
-  input.g_a = NULL;
-  HIPCHECK(hipFree(input.g_b_raw));
-  input.g_b_raw = NULL;
-  input.g_b = NULL;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Check if a specific matrix size has to be used
-//! @param argc  number of command line arguments (from main(argc, argv)
-//! @param argv  pointers to command line arguments (from main(argc, argv)
-//! @param matrix_size  size of matrix, updated if specific size specified on
-//!                     command line
-////////////////////////////////////////////////////////////////////////////////
-void getMatrixSize(int argc, char **argv, unsigned int &mat_size,
-                   unsigned int &user_defined) {
-  int temp = -1;
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "matrix-size")) {
-    temp = getCmdLineArgumentInt(argc, (const char **)argv, "matrix-size");
-  }
-
-  if (temp > 0) {
-    mat_size = (unsigned int)temp;
-    // data type short is used in the kernel
-    assert(mat_size < (1 << 16));
-
-    // mat_size should be large than 2
-    assert(mat_size >= 2);
-
-    user_defined = 1;
-  }
-
-  printf("Matrix size: %i x %i\n", mat_size, mat_size);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Check if a specific precision of the eigenvalue has to be obtained
-//! @param argc  number of command line arguments (from main(argc, argv)
-//! @param argv  pointers to command line arguments (from main(argc, argv)
-//! @param iters_timing  numbers of iterations for timing, updated if a
-//!                      specific number is specified on the command line
-//! @param user_defined  1 if the precision has been requested by the user,
-//!                      0 if the default size
-////////////////////////////////////////////////////////////////////////////////
-void getPrecision(int argc, char **argv, float &precision,
-                  unsigned int &user_defined) {
-  float temp = -1.0f;
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "precision")) {
-    temp = getCmdLineArgumentFloat(argc, (const char **)argv, "precision");
-    printf("Precision is between [0.001, 0.000001]\n");
-  }
-
-  if (temp > 1e-6 && temp <= 0.001) {
-    precision = temp;
-    user_defined = 1;
-  }
-
-  printf("Precision: %f\n", precision);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Check if a particular number of iterations for timings has to be used
-//! @param argc  number of command line arguments (from main(argc, argv)
-//! @param argv  pointers to command line arguments (from main(argc, argv)
-//! @param  iters_timing  number of timing iterations, updated if user
-//!                       specific value
-////////////////////////////////////////////////////////////////////////////////
-void getItersTiming(int argc, char **argv, unsigned int &iters_timing) {
-  int temp = -1;
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "iters-timing")) {
-    temp = getCmdLineArgumentInt(argc, (const char **)argv, "iters-timing");
-  }
-
-  if (temp > 0) {
-    iters_timing = temp;
-  }
-
-  printf("Iterations to be timed: %i\n", iters_timing);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Check if a particular filename has to be used for the file where the result
-//! is stored
-//! @param argc  number of command line arguments (from main(argc, argv)
-//! @param argv  pointers to command line arguments (from main(argc, argv)
-//! @param  filename  filename of result file, updated if user specified
-//!                   filename
-////////////////////////////////////////////////////////////////////////////////
-void getResultFilename(int argc, char **argv, char *&filename) {
-  char *temp = NULL;
-  getCmdLineArgumentString(argc, (const char **)argv, "filename-result", &temp);
-
-  if (NULL != temp) {
-    filename = (char *)malloc(sizeof(char) * strlen(temp));
-    strcpy(filename, temp);
-
-    free(temp);
-  }
-
-  printf("Result filename: '%s'\n", filename);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run a simple test for CUDA
-////////////////////////////////////////////////////////////////////////////////
-bool runTest(int argc, char **argv) {
-  bool bCompareResult = false;
-
-  findCudaDevice(argc, (const char **)argv);
-
-  StopWatchInterface *timer = NULL;
-  StopWatchInterface *timer_total = NULL;
-  sdkCreateTimer(&timer);
-  sdkCreateTimer(&timer_total);
-
-  // default
-  unsigned int mat_size = 2048;
-  // flag if the matrix size is due to explicit user request
-  unsigned int user_defined = 0;
-  // desired precision of eigenvalues
-  float precision = 0.00001f;
-  unsigned int iters_timing = 100;
-  char *result_file = (char *)"eigenvalues.dat";
-
-  // check if there is a command line request for the matrix size
-  getMatrixSize(argc, argv, mat_size, user_defined);
-
-  // check if user requested specific precision
-  getPrecision(argc, argv, precision, user_defined);
-
-  // check if user requested specific number of iterations for timing
-  getItersTiming(argc, argv, iters_timing);
-
-  // file name for result file
-  getResultFilename(argc, argv, result_file);
-
-  // set up input
-  InputData input;
-  initInputData(input, argv[0], mat_size, user_defined);
-
-  // compute Gerschgorin interval
-  float lg = FLT_MAX;
-  float ug = -FLT_MAX;
-  computeGerschgorin(input.a, input.b + 1, mat_size, lg, ug);
-  printf("Gerschgorin interval: %f / %f\n", lg, ug);
-
-  // two kernels, for small matrices a lot of overhead can be avoided
-  if (mat_size <= MAX_SMALL_MATRIX) {
-    // initialize memory for result
-    ResultDataSmall result;
-    initResultSmallMatrix(result, mat_size);
-
-    // run the kernel
-    computeEigenvaluesSmallMatrix(input, result, mat_size, lg, ug, precision,
-                                  iters_timing);
-
-    // get the result from the device and do some sanity checks,
-    // save the result
-    processResultSmallMatrix(input, result, mat_size, result_file);
-
-    // clean up
-    cleanupResultSmallMatrix(result);
-
-    printf("User requests non-default argument(s), skipping self-check!\n");
-    bCompareResult = true;
-  } else {
-    // initialize memory for result
-    ResultDataLarge result;
-    initResultDataLargeMatrix(result, mat_size);
-
-    // run the kernel
-    computeEigenvaluesLargeMatrix(input, result, mat_size, precision, lg, ug,
-                                  iters_timing);
-
-    // get the result from the device and do some sanity checks
-    // save the result if user specified matrix size
-    bCompareResult = processResultDataLargeMatrix(
-        input, result, mat_size, result_file, user_defined, argv[0]);
-
-    // cleanup
-    cleanupResultDataLargeMatrix(result);
-  }
-
-  cleanupInputData(input);
-
-  return bCompareResult;
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/matlab.cpp b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/matlab.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/matlab.h b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/matlab.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/matlab_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/matlab_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/matlab_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/matlab_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/structs.h b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/structs.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/structs_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/structs_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/util.h b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/util.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/util_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/eigenvalues/util_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/histogram/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/histogram/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/histogram/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/histogram/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/histogram/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/histogram/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/README.md b/src/samples/Samples/2_Concepts_and_Techniques/histogram/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/doc/histogram.doc b/src/samples/Samples/2_Concepts_and_Techniques/histogram/doc/histogram.doc
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/doc/histogram.pdf b/src/samples/Samples/2_Concepts_and_Techniques/histogram/doc/histogram.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/doc/histogram.vsd b/src/samples/Samples/2_Concepts_and_Techniques/histogram/doc/histogram.vsd
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram.out b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram256.cu b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram256.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram256.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram256.cu.hip
old mode 100644
new mode 100755
index 5203865..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram256.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram256.cu.hip
@@ -1,166 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <assert.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-#include "helper_cuda_hipified.h"
-#include "histogram_common.h"
-
-////////////////////////////////////////////////////////////////////////////////
-// Shortcut shared memory atomic addition functions
-////////////////////////////////////////////////////////////////////////////////
-
-#define TAG_MASK 0xFFFFFFFFU
-inline __device__ void addByte(uint *s_WarpHist, uint data, uint threadTag) {
-  atomicAdd(s_WarpHist + data, 1);
-}
-
-inline __device__ void addWord(uint *s_WarpHist, uint data, uint tag) {
-  addByte(s_WarpHist, (data >> 0) & 0xFFU, tag);
-  addByte(s_WarpHist, (data >> 8) & 0xFFU, tag);
-  addByte(s_WarpHist, (data >> 16) & 0xFFU, tag);
-  addByte(s_WarpHist, (data >> 24) & 0xFFU, tag);
-}
-
-__global__ void histogram256Kernel(uint *d_PartialHistograms, uint *d_Data,
-                                   uint dataCount) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  // Per-warp subhistogram storage
-  __shared__ uint s_Hist[HISTOGRAM256_THREADBLOCK_MEMORY];
-  uint *s_WarpHist =
-      s_Hist + (threadIdx.x >> LOG2_WARP_SIZE) * HISTOGRAM256_BIN_COUNT;
-
-// Clear shared memory storage for current threadblock before processing
-#pragma unroll
-
-  for (uint i = 0;
-       i < (HISTOGRAM256_THREADBLOCK_MEMORY / HISTOGRAM256_THREADBLOCK_SIZE);
-       i++) {
-    s_Hist[threadIdx.x + i * HISTOGRAM256_THREADBLOCK_SIZE] = 0;
-  }
-
-  // Cycle through the entire data set, update subhistograms for each warp
-  const uint tag = threadIdx.x << (UINT_BITS - LOG2_WARP_SIZE);
-
-  cg::sync(cta);
-
-  for (uint pos = UMAD(blockIdx.x, blockDim.x, threadIdx.x); pos < dataCount;
-       pos += UMUL(blockDim.x, gridDim.x)) {
-    uint data = d_Data[pos];
-    addWord(s_WarpHist, data, tag);
-  }
-
-  // Merge per-warp histograms into per-block and write to global memory
-  cg::sync(cta);
-
-  for (uint bin = threadIdx.x; bin < HISTOGRAM256_BIN_COUNT;
-       bin += HISTOGRAM256_THREADBLOCK_SIZE) {
-    uint sum = 0;
-
-    for (uint i = 0; i < WARP_COUNT; i++) {
-      sum += s_Hist[bin + i * HISTOGRAM256_BIN_COUNT] & TAG_MASK;
-    }
-
-    d_PartialHistograms[blockIdx.x * HISTOGRAM256_BIN_COUNT + bin] = sum;
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Merge histogram256() output
-// Run one threadblock per bin; each threadblock adds up the same bin counter
-// from every partial histogram. Reads are uncoalesced, but mergeHistogram256
-// takes only a fraction of total processing time
-////////////////////////////////////////////////////////////////////////////////
-#define MERGE_THREADBLOCK_SIZE 256
-
-__global__ void mergeHistogram256Kernel(uint *d_Histogram,
-                                        uint *d_PartialHistograms,
-                                        uint histogramCount) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-
-  uint sum = 0;
-
-  for (uint i = threadIdx.x; i < histogramCount; i += MERGE_THREADBLOCK_SIZE) {
-    sum += d_PartialHistograms[blockIdx.x + i * HISTOGRAM256_BIN_COUNT];
-  }
-
-  __shared__ uint data[MERGE_THREADBLOCK_SIZE];
-  data[threadIdx.x] = sum;
-
-  for (uint stride = MERGE_THREADBLOCK_SIZE / 2; stride > 0; stride >>= 1) {
-    cg::sync(cta);
-
-    if (threadIdx.x < stride) {
-      data[threadIdx.x] += data[threadIdx.x + stride];
-    }
-  }
-
-  if (threadIdx.x == 0) {
-    d_Histogram[blockIdx.x] = data[0];
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Host interface to GPU histogram
-////////////////////////////////////////////////////////////////////////////////
-// histogram256kernel() intermediate results buffer
-static const uint PARTIAL_HISTOGRAM256_COUNT = 240;
-static uint *d_PartialHistograms;
-
-// Internal memory allocation
-extern "C" void initHistogram256(void) {
-  HIPCHECK(hipMalloc(
-      (void **)&d_PartialHistograms,
-      PARTIAL_HISTOGRAM256_COUNT * HISTOGRAM256_BIN_COUNT * sizeof(uint)));
-}
-
-// Internal memory deallocation
-extern "C" void closeHistogram256(void) {
-  HIPCHECK(hipFree(d_PartialHistograms));
-}
-
-extern "C" void histogram256(uint *d_Histogram, void *d_Data, uint byteCount) {
-  assert(byteCount % sizeof(uint) == 0);
-  histogram256Kernel<<<PARTIAL_HISTOGRAM256_COUNT,
-                       HISTOGRAM256_THREADBLOCK_SIZE>>>(
-      d_PartialHistograms, (uint *)d_Data, byteCount / sizeof(uint));
-  getLastCudaError("histogram256Kernel() execution failed\n");
-
-  mergeHistogram256Kernel<<<HISTOGRAM256_BIN_COUNT, MERGE_THREADBLOCK_SIZE>>>(
-      d_Histogram, d_PartialHistograms, PARTIAL_HISTOGRAM256_COUNT);
-  getLastCudaError("mergeHistogram256Kernel() execution failed\n");
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram64.cu b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram64.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram64.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram64.cu.hip
old mode 100644
new mode 100755
index b8f51e9..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram64.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram64.cu.hip
@@ -1,208 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <assert.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-#include "helper_cuda_hipified.h"
-#include "histogram_common.h"
-
-////////////////////////////////////////////////////////////////////////////////
-// GPU-specific common definitions
-////////////////////////////////////////////////////////////////////////////////
-// Data type used for input data fetches
-typedef uint4 data_t;
-
-// May change on future hardware, so better parametrize the code
-#define SHARED_MEMORY_BANKS 16
-
-////////////////////////////////////////////////////////////////////////////////
-// Main computation pass: compute gridDim.x partial histograms
-////////////////////////////////////////////////////////////////////////////////
-// Count a byte into shared-memory storage
-inline __device__ void addByte(uchar *s_ThreadBase, uint data) {
-  s_ThreadBase[UMUL(data, HISTOGRAM64_THREADBLOCK_SIZE)]++;
-}
-
-// Count four bytes of a word
-inline __device__ void addWord(uchar *s_ThreadBase, uint data) {
-  // Only higher 6 bits of each byte matter, as this is a 64-bin histogram
-  addByte(s_ThreadBase, (data >> 2) & 0x3FU);
-  addByte(s_ThreadBase, (data >> 10) & 0x3FU);
-  addByte(s_ThreadBase, (data >> 18) & 0x3FU);
-  addByte(s_ThreadBase, (data >> 26) & 0x3FU);
-}
-
-__global__ void histogram64Kernel(uint *d_PartialHistograms, data_t *d_Data,
-                                  uint dataCount) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  // Encode thread index in order to avoid bank conflicts in s_Hist[] access:
-  // each group of SHARED_MEMORY_BANKS threads accesses consecutive shared
-  // memory banks
-  // and the same bytes [0..3] within the banks
-  // Because of this permutation block size should be a multiple of 4 *
-  // SHARED_MEMORY_BANKS
-  const uint threadPos = ((threadIdx.x & ~(SHARED_MEMORY_BANKS * 4 - 1)) << 0) |
-                         ((threadIdx.x & (SHARED_MEMORY_BANKS - 1)) << 2) |
-                         ((threadIdx.x & (SHARED_MEMORY_BANKS * 3)) >> 4);
-
-  // Per-thread histogram storage
-  __shared__ uchar s_Hist[HISTOGRAM64_THREADBLOCK_SIZE * HISTOGRAM64_BIN_COUNT];
-  uchar *s_ThreadBase = s_Hist + threadPos;
-
-// Initialize shared memory (writing 32-bit words)
-#pragma unroll
-
-  for (uint i = 0; i < (HISTOGRAM64_BIN_COUNT / 4); i++) {
-    ((uint *)s_Hist)[threadIdx.x + i * HISTOGRAM64_THREADBLOCK_SIZE] = 0;
-  }
-
-  // Read data from global memory and submit to the shared-memory histogram
-  // Since histogram counters are byte-sized, every single thread can't do more
-  // than 255 submission
-  cg::sync(cta);
-
-  for (uint pos = UMAD(blockIdx.x, blockDim.x, threadIdx.x); pos < dataCount;
-       pos += UMUL(blockDim.x, gridDim.x)) {
-    data_t data = d_Data[pos];
-    addWord(s_ThreadBase, data.x);
-    addWord(s_ThreadBase, data.y);
-    addWord(s_ThreadBase, data.z);
-    addWord(s_ThreadBase, data.w);
-  }
-
-  // Accumulate per-thread histograms into per-block and write to global memory
-  cg::sync(cta);
-
-  if (threadIdx.x < HISTOGRAM64_BIN_COUNT) {
-    uchar *s_HistBase =
-        s_Hist + UMUL(threadIdx.x, HISTOGRAM64_THREADBLOCK_SIZE);
-
-    uint sum = 0;
-    uint pos = 4 * (threadIdx.x & (SHARED_MEMORY_BANKS - 1));
-
-#pragma unroll
-
-    for (uint i = 0; i < (HISTOGRAM64_THREADBLOCK_SIZE / 4); i++) {
-      sum += s_HistBase[pos + 0] + s_HistBase[pos + 1] + s_HistBase[pos + 2] +
-             s_HistBase[pos + 3];
-      pos = (pos + 4) & (HISTOGRAM64_THREADBLOCK_SIZE - 1);
-    }
-
-    d_PartialHistograms[blockIdx.x * HISTOGRAM64_BIN_COUNT + threadIdx.x] = sum;
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Merge histogram64() output
-// Run one threadblock per bin; each threadbock adds up the same bin counter
-// from every partial histogram. Reads are uncoalesced, but mergeHistogram64
-// takes only a fraction of total processing time
-////////////////////////////////////////////////////////////////////////////////
-#define MERGE_THREADBLOCK_SIZE 256
-
-__global__ void mergeHistogram64Kernel(uint *d_Histogram,
-                                       uint *d_PartialHistograms,
-                                       uint histogramCount) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  __shared__ uint data[MERGE_THREADBLOCK_SIZE];
-
-  uint sum = 0;
-
-  for (uint i = threadIdx.x; i < histogramCount; i += MERGE_THREADBLOCK_SIZE) {
-    sum += d_PartialHistograms[blockIdx.x + i * HISTOGRAM64_BIN_COUNT];
-  }
-
-  data[threadIdx.x] = sum;
-
-  for (uint stride = MERGE_THREADBLOCK_SIZE / 2; stride > 0; stride >>= 1) {
-    cg::sync(cta);
-
-    if (threadIdx.x < stride) {
-      data[threadIdx.x] += data[threadIdx.x + stride];
-    }
-  }
-
-  if (threadIdx.x == 0) {
-    d_Histogram[blockIdx.x] = data[0];
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// CPU interface to GPU histogram calculator
-////////////////////////////////////////////////////////////////////////////////
-// histogram64kernel() intermediate results buffer
-// MAX_PARTIAL_HISTOGRAM64_COUNT == 32768 and HISTOGRAM64_THREADBLOCK_SIZE == 64
-// amounts to max. 480MB of input data
-static const uint MAX_PARTIAL_HISTOGRAM64_COUNT = 32768;
-static uint *d_PartialHistograms;
-
-// Internal memory allocation
-extern "C" void initHistogram64(void) {
-  assert(HISTOGRAM64_THREADBLOCK_SIZE % (4 * SHARED_MEMORY_BANKS) == 0);
-  HIPCHECK(hipMalloc(
-      (void **)&d_PartialHistograms,
-      MAX_PARTIAL_HISTOGRAM64_COUNT * HISTOGRAM64_BIN_COUNT * sizeof(uint)));
-}
-
-// Internal memory deallocation
-extern "C" void closeHistogram64(void) {
-  HIPCHECK(hipFree(d_PartialHistograms));
-}
-
-// Round a / b to nearest higher integer value
-inline uint iDivUp(uint a, uint b) {
-  return (a % b != 0) ? (a / b + 1) : (a / b);
-}
-
-// Snap a to nearest lower multiple of b
-inline uint iSnapDown(uint a, uint b) { return a - a % b; }
-
-extern "C" void histogram64(uint *d_Histogram, void *d_Data, uint byteCount) {
-  const uint histogramCount = iDivUp(
-      byteCount, HISTOGRAM64_THREADBLOCK_SIZE * iSnapDown(255, sizeof(data_t)));
-
-  assert(byteCount % sizeof(data_t) == 0);
-  assert(histogramCount <= MAX_PARTIAL_HISTOGRAM64_COUNT);
-
-  histogram64Kernel<<<histogramCount, HISTOGRAM64_THREADBLOCK_SIZE>>>(
-      d_PartialHistograms, (data_t *)d_Data, byteCount / sizeof(data_t));
-  getLastCudaError("histogram64Kernel() execution failed\n");
-
-  mergeHistogram64Kernel<<<HISTOGRAM64_BIN_COUNT, MERGE_THREADBLOCK_SIZE>>>(
-      d_Histogram, d_PartialHistograms, histogramCount);
-  getLastCudaError("mergeHistogram64() execution failed\n");
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_common.h b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_common_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_gold.cpp b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_gold_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/histogram/histogram_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/main.cpp b/src/samples/Samples/2_Concepts_and_Techniques/histogram/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/histogram/main_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/histogram/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/README.md b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/bmploader.cpp b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/bmploader.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/bmploader_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/bmploader_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/data/portrait_noise.bmp b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/data/portrait_noise.bmp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/data/ref_knn.ppm b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/data/ref_knn.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/data/ref_nlm.ppm b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/data/ref_nlm.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/data/ref_nlm2.ppm b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/data/ref_nlm2.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/data/ref_passthru.ppm b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/data/ref_passthru.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/doc/NLM_lg.png b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/doc/NLM_lg.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/doc/NLM_md.png b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/doc/NLM_md.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/doc/NLM_sm.png b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/doc/NLM_sm.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/doc/imageDenoising.doc b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/doc/imageDenoising.doc
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/doc/imageDenoising.pdf b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/doc/imageDenoising.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/findgllib.mk b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising.cu b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising.cu.hip
old mode 100644
new mode 100755
index 001f56f..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising.cu.hip
@@ -1,115 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This sample demonstrates two adaptive image denoising techniques:
- * KNN and NLM, based on computation of both geometric and color distance
- * between texels. While both techniques are already implemented in the
- * DirectX SDK using shaders, massively speeded up variation
- * of the latter technique, taking advantage of shared memory, is implemented
- * in addition to DirectX counterparts.
- * See supplied whitepaper for more explanations.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-#include "helper_cuda_hipified.h"
-#include "imageDenoising_hipified.h"
-#include <hip/hip_cooperative_groups.h>
-
-////////////////////////////////////////////////////////////////////////////////
-// Helper functions
-////////////////////////////////////////////////////////////////////////////////
-float Max(float x, float y) { return (x > y) ? x : y; }
-
-float Min(float x, float y) { return (x < y) ? x : y; }
-
-int iDivUp(int a, int b) { return ((a % b) != 0) ? (a / b + 1) : (a / b); }
-
-__device__ float lerpf(float a, float b, float c) { return a + (b - a) * c; }
-
-__device__ float vecLen(float4 a, float4 b) {
-  return ((b.x - a.x) * (b.x - a.x) + (b.y - a.y) * (b.y - a.y) +
-          (b.z - a.z) * (b.z - a.z));
-}
-
-__device__ TColor make_color(float r, float g, float b, float a) {
-  return ((int)(a * 255.0f) << 24) | ((int)(b * 255.0f) << 16) |
-         ((int)(g * 255.0f) << 8) | ((int)(r * 255.0f) << 0);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Global data handlers and parameters
-////////////////////////////////////////////////////////////////////////////////
-// Texture object and channel descriptor for image texture
-hipTextureObject_t texImage;
-hipChannelFormatDesc uchar4tex = hipCreateChannelDesc<uchar4>();
-
-// CUDA array descriptor
-hipArray *a_Src;
-
-////////////////////////////////////////////////////////////////////////////////
-// Filtering kernels
-////////////////////////////////////////////////////////////////////////////////
-#include "imageDenoising_copy_kernel_hipified.cuh"
-#include "imageDenoising_knn_kernel_hipified.cuh"
-#include "imageDenoising_nlm_kernel_hipified.cuh"
-#include "imageDenoising_nlm2_kernel_hipified.cuh"
-
-extern "C" hipError_t CUDA_MallocArray(uchar4 **h_Src, int imageW,
-                                        int imageH) {
-  hipError_t error;
-
-  error = hipMallocArray(&a_Src, &uchar4tex, imageW, imageH);
-  error = hipMemcpy2DToArray(a_Src, 0, 0, *h_Src, sizeof(uchar4) * imageW,
-                              sizeof(uchar4) * imageW, imageH,
-                              hipMemcpyHostToDevice);
-
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = a_Src;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeNormalizedFloat;
-
-  HIPCHECK(hipCreateTextureObject(&texImage, &texRes, &texDescr, NULL));
-
-  return error;
-}
-
-extern "C" hipError_t CUDA_FreeArray() { return hipFreeArray(a_Src); }
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising.h b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoisingGL.cpp b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoisingGL.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoisingGL_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoisingGL_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_copy_kernel.cuh b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_copy_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_copy_kernel_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_copy_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_knn_kernel.cuh b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_knn_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_knn_kernel_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_knn_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_nlm2_kernel.cuh b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_nlm2_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_nlm2_kernel_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_nlm2_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_nlm_kernel.cuh b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_nlm_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_nlm_kernel_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_nlm_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/imageDenoising/imageDenoising_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/README.md b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX.cu b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX.cu.hip
old mode 100644
new mode 100755
index 9a6aa02..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX.cu.hip
@@ -1,116 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Demonstration of inline PTX (assembly language) usage in CUDA kernels
- */
-
-// System includes
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <assert.h>
-
-// CUDA runtime
-#include <hip/hip_runtime.h>
-
-// helper functions and utilities to work with CUDA
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-
-__global__ void sequence_gpu(int *d_ptr, int length)
-{
-    int elemID = blockIdx.x * blockDim.x + threadIdx.x;
-
-    if (elemID < length)
-    {
-        unsigned int laneid;
-        //This command gets the lane ID within the current warp
-        asm("mov.u32 %0, %%laneid;" : "=r"(laneid));
-        d_ptr[elemID] = laneid;
-    }
-}
-
-
-void sequence_cpu(int *h_ptr, int length)
-{
-    for (int elemID=0; elemID<length; elemID++)
-    {
-        h_ptr[elemID] = elemID % 32;
-    }
-}
-
-int main(int argc, char **argv)
-{
-    printf("CUDA inline PTX assembler sample\n");
-
-    const int N = 1000;
-
-    int dev = findCudaDevice(argc, (const char **) argv);
-
-    if (dev == -1)
-    {
-        return EXIT_FAILURE;
-    }
-
-    int *d_ptr;
-    HIPCHECK(hipMalloc(&d_ptr, N * sizeof(int)));
-
-    int *h_ptr;
-    HIPCHECK(hipHostMalloc(&h_ptr, N * sizeof(int)));
-
-    dim3 cudaBlockSize(256,1,1);
-    dim3 cudaGridSize((N + cudaBlockSize.x - 1) / cudaBlockSize.x, 1, 1);
-    sequence_gpu<<<cudaGridSize, cudaBlockSize>>>(d_ptr, N);
-    HIPCHECK(hipGetLastError());
-    HIPCHECK(hipDeviceSynchronize());
-
-    sequence_cpu(h_ptr, N);
-
-    int *h_d_ptr;
-    HIPCHECK(hipHostMalloc(&h_d_ptr, N *sizeof(int)));
-    HIPCHECK(hipMemcpy(h_d_ptr, d_ptr, N *sizeof(int), hipMemcpyDeviceToHost));
-
-    bool bValid = true;
-
-    for (int i=0; i<N && bValid; i++)
-    {
-        if (h_ptr[i] != h_d_ptr[i])
-        {
-            bValid = false;
-        }
-    }
-
-    printf("Test %s.\n", bValid ? "Successful" : "Failed");
-
-    HIPCHECK(hipFree(d_ptr));
-    HIPCHECK(hipHostFree(h_ptr));
-    HIPCHECK(hipHostFree(h_d_ptr));
-
-    return bValid ? EXIT_SUCCESS: EXIT_FAILURE;
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX/inlinePTX_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/README.md b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX.cpp b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_kernel.cu b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_kernel.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_kernel.cu.hip
old mode 100644
new mode 100755
index 18a6fe6..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_kernel.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_kernel.cu.hip
@@ -1,40 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-extern "C" __global__ void sequence_gpu(int *d_ptr, int length) {
-  int elemID = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (elemID < length) {
-    unsigned int laneid;
-
-    // This command gets the lane ID within the current warp
-    asm("mov.u32  %0, %%laneid;" : "=r"(laneid));
-
-    d_ptr[elemID] = laneid;
-  }
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/inlinePTX_nvrtc/inlinePTX_nvrtc_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/interval/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/interval/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/interval/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/interval/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/interval/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/interval/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/README.md b/src/samples/Samples/2_Concepts_and_Techniques/interval/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/abi/borland_prefix.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/abi/borland_prefix.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/abi/borland_suffix.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/abi/borland_suffix.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/abi/msvc_prefix.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/abi/msvc_prefix.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/abi/msvc_suffix.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/abi/msvc_suffix.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/abi_prefix.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/abi_prefix.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/abi_suffix.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/abi_suffix.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/auto_link.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/auto_link.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/borland.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/borland.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/codegear.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/codegear.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/comeau.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/comeau.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/common_edg.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/common_edg.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/compaq_cxx.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/compaq_cxx.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/digitalmars.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/digitalmars.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/gcc.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/gcc.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/gcc_xml.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/gcc_xml.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/greenhills.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/greenhills.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/hp_acc.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/hp_acc.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/intel.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/intel.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/kai.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/kai.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/metrowerks.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/metrowerks.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/mpw.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/mpw.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/pgi.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/pgi.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/sgi_mipspro.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/sgi_mipspro.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/sunpro_cc.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/sunpro_cc.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/vacpp.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/vacpp.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/visualc.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/compiler/visualc.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/no_tr1/cmath.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/no_tr1/cmath.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/no_tr1/complex.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/no_tr1/complex.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/no_tr1/functional.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/no_tr1/functional.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/no_tr1/memory.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/no_tr1/memory.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/no_tr1/utility.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/no_tr1/utility.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/aix.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/aix.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/amigaos.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/amigaos.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/beos.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/beos.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/bsd.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/bsd.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/cygwin.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/cygwin.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/hpux.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/hpux.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/irix.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/irix.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/linux.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/linux.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/macos.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/macos.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/qnxnto.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/qnxnto.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/solaris.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/solaris.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/vxworks.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/vxworks.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/win32.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/platform/win32.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/posix_features.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/posix_features.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/requires_threads.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/requires_threads.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/select_compiler_config.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/select_compiler_config.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/select_platform_config.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/select_platform_config.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/select_stdlib_config.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/select_stdlib_config.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/dinkumware.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/dinkumware.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/libcomo.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/libcomo.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/libstdcpp3.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/libstdcpp3.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/modena.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/modena.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/msl.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/msl.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/roguewave.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/roguewave.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/sgi.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/sgi.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/stlport.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/stlport.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/vacpp.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/stdlib/vacpp.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/suffix.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/suffix.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/user.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/user.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/warning_disable.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/config/warning_disable.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/limits.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/limits.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/arith.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/arith.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/arith2.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/arith2.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/arith3.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/arith3.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/checking.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/checking.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/compare.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/compare.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/compare/certain.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/compare/certain.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/compare/explicit.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/compare/explicit.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/compare/lexicographic.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/compare/lexicographic.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/compare/possible.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/compare/possible.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/compare/set.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/compare/set.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/compare/tribool.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/compare/tribool.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/constants.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/constants.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/alpha_rounding_control.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/alpha_rounding_control.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/bcc_rounding_control.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/bcc_rounding_control.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/bugs.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/bugs.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/c99_rounding_control.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/c99_rounding_control.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/c99sub_rounding_control.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/c99sub_rounding_control.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/division.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/division.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/ia64_rounding_control.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/ia64_rounding_control.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/interval_prototype.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/interval_prototype.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/msvc_rounding_control.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/msvc_rounding_control.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/ppc_rounding_control.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/ppc_rounding_control.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/sparc_rounding_control.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/sparc_rounding_control.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/test_input.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/test_input.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/x86_rounding_control.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/x86_rounding_control.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/x86gcc_rounding_control.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/detail/x86gcc_rounding_control.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/ext/integer.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/ext/integer.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/ext/x86_fast_rounding_control.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/ext/x86_fast_rounding_control.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/hw_rounding.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/hw_rounding.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/interval.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/interval.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/io.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/io.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/limits.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/limits.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/policies.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/policies.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/rounded_arith.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/rounded_arith.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/rounded_transc.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/rounded_transc.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/rounding.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/rounding.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/transc.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/transc.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/utility.hpp b/src/samples/Samples/2_Concepts_and_Techniques/interval/boost/numeric/interval/utility.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/cpu_interval.h b/src/samples/Samples/2_Concepts_and_Techniques/interval/cpu_interval.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/cpu_interval_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/interval/cpu_interval_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval.h b/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval_lib.h b/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval_lib.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval_lib_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval_lib_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval_rounded_arith.h b/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval_rounded_arith.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval_rounded_arith_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/interval/cuda_interval_rounded_arith_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval.cu b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval.cu.hip
old mode 100644
new mode 100755
index 79002e1..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval.cu.hip
@@ -1,165 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* Example of program using the interval_gpu<T> template class and operators:
- * Search for roots of a function using an interval Newton method.
-  *
- * Use the command-line argument "--n=<N>" to select which GPU implementation to
- * use,
- * otherwise the naive implementation will be used by default.
- * 0: the naive implementation
- * 1: the optimized implementation
- * 2: the recursive implementation
- *
- */
-
-const static char *sSDKsample = "Interval Computing";
-
-#include <iostream>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include "helper_cuda_hipified.h"
-#include "interval_hipified.h"
-#include "cuda_interval_hipified.h"
-#include "cpu_interval_hipified.h"
-
-int main(int argc, char *argv[]) {
-  int implementation_choice = 0;
-
-  printf("[%s]  starting ...\n\n", sSDKsample);
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "n")) {
-    implementation_choice =
-        getCmdLineArgumentInt(argc, (const char **)argv, "n");
-  }
-
-  // Pick the best GPU available, or if the developer selects one at the command
-  // line
-  int devID = findCudaDevice(argc, (const char **)argv);
-  hipDeviceProp_t deviceProp;
-  hipGetDeviceProperties(&deviceProp, devID);
-  printf("> GPU Device has Compute Capabilities SM %d.%d\n\n", deviceProp.major,
-         deviceProp.minor);
-
-  switch (implementation_choice) {
-    case 0:
-      printf("GPU naive implementation\n");
-      break;
-
-    case 1:
-      printf("GPU optimized implementation\n");
-      break;
-
-    case 2:
-      printf("GPU recursive implementation (requires Compute SM 2.0+)\n");
-      break;
-
-    default:
-      printf("GPU naive implementation\n");
-  }
-
-  interval_gpu<T> *d_result;
-  int *d_nresults;
-  int *h_nresults = new int[THREADS];
-  hipEvent_t start, stop;
-
-  CHECKED_CALL(hipSetDevice(devID));
-  CHECKED_CALL(hipMalloc((void **)&d_result,
-                          THREADS * DEPTH_RESULT * sizeof(*d_result)));
-  CHECKED_CALL(hipMalloc((void **)&d_nresults, THREADS * sizeof(*d_nresults)));
-  CHECKED_CALL(hipEventCreate(&start));
-  CHECKED_CALL(hipEventCreate(&stop));
-
-  // We need L1 cache to store the stack (only applicable to sm_20 and higher)
-  CHECKED_CALL(
-      hipFuncSetCacheConfig((const void*)test_interval_newton<T>, hipFuncCachePreferL1));
-
-  // Increase the stack size large enough for the non-inlined and recursive
-  // function calls (only applicable to sm_20 and higher)
-  CHECKED_CALL(hipDeviceSetLimit(hipLimitStackSize, 8192));
-
-  interval_gpu<T> i(0.01f, 4.0f);
-  std::cout << "Searching for roots in [" << i.lower() << ", " << i.upper()
-            << "]...\n";
-
-  CHECKED_CALL(hipEventRecord(start, 0));
-
-  for (int it = 0; it < NUM_RUNS; ++it) {
-    test_interval_newton<T><<<GRID_SIZE, BLOCK_SIZE>>>(d_result, d_nresults, i,
-                                                       implementation_choice);
-    CHECKED_CALL(hipGetLastError());
-  }
-
-  CHECKED_CALL(hipEventRecord(stop, 0));
-  CHECKED_CALL(hipDeviceSynchronize());
-
-  I_CPU *h_result = new I_CPU[THREADS * DEPTH_RESULT];
-  CHECKED_CALL(hipMemcpy(h_result, d_result,
-                          THREADS * DEPTH_RESULT * sizeof(*d_result),
-                          hipMemcpyDeviceToHost));
-  CHECKED_CALL(hipMemcpy(h_nresults, d_nresults, THREADS * sizeof(*d_nresults),
-                          hipMemcpyDeviceToHost));
-
-  std::cout << "Found " << h_nresults[0]
-            << " intervals that may contain the root(s)\n";
-  std::cout.precision(15);
-
-  for (int i = 0; i != h_nresults[0]; ++i) {
-    std::cout << " i[" << i << "] ="
-              << " [" << h_result[THREADS * i + 0].lower() << ", "
-              << h_result[THREADS * i + 0].upper() << "]\n";
-  }
-
-  float time;
-  CHECKED_CALL(hipEventElapsedTime(&time, start, stop));
-  std::cout << "Number of equations solved: " << THREADS << "\n";
-  std::cout << "Time per equation: "
-            << 1000000.0f * (time / (float)(THREADS)) / NUM_RUNS << " us\n";
-
-  CHECKED_CALL(hipEventDestroy(start));
-  CHECKED_CALL(hipEventDestroy(stop));
-  CHECKED_CALL(hipFree(d_result));
-  CHECKED_CALL(hipFree(d_nresults));
-
-  // Compute the results using a CPU implementation based on the Boost library
-  I_CPU i_cpu(0.01f, 4.0f);
-  I_CPU *h_result_cpu = new I_CPU[THREADS * DEPTH_RESULT];
-  int *h_nresults_cpu = new int[THREADS];
-  test_interval_newton_cpu<I_CPU>(h_result_cpu, h_nresults_cpu, i_cpu);
-
-  // Compare the CPU and GPU results
-  bool bTestResult =
-      checkAgainstHost(h_nresults, h_nresults_cpu, h_result, h_result_cpu);
-
-  delete[] h_result_cpu;
-  delete[] h_nresults_cpu;
-  delete[] h_result;
-  delete[] h_nresults;
-
-  exit(bTestResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval.h b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/interval/interval_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/particles/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/particles/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/particles/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/particles/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/particles/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/particles/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/README.md b/src/samples/Samples/2_Concepts_and_Techniques/particles/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/data/ref_particles.bin b/src/samples/Samples/2_Concepts_and_Techniques/particles/data/ref_particles.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/doc/particles.doc b/src/samples/Samples/2_Concepts_and_Techniques/particles/doc/particles.doc
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/doc/particles.pdf b/src/samples/Samples/2_Concepts_and_Techniques/particles/doc/particles.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/doc/screenshot_lg.png b/src/samples/Samples/2_Concepts_and_Techniques/particles/doc/screenshot_lg.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/doc/screenshot_md.png b/src/samples/Samples/2_Concepts_and_Techniques/particles/doc/screenshot_md.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/doc/screenshot_sm.png b/src/samples/Samples/2_Concepts_and_Techniques/particles/doc/screenshot_sm.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/findgllib.mk b/src/samples/Samples/2_Concepts_and_Techniques/particles/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem.cpp b/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem.cuh b/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem.h b/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem_cuda.cu b/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem_cuda.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem_cuda.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem_cuda.cu.hip
old mode 100644
new mode 100755
index 1b9d1c4..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem_cuda.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem_cuda.cu.hip
@@ -1,202 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// This file contains C wrappers around the some of the CUDA API and the
-// kernel functions so that they can be called from "particleSystem.cpp"
-
-#if defined(__APPLE__) || defined(MACOSX)
-#pragma clang diagnostic ignored "-Wdeprecated-declarations"
-#include <GLUT/glut.h>
-#else
-#include <GL/freeglut.h>
-#endif
-
-#include <cstdlib>
-#include <cstdio>
-#include <string.h>
-
-#include <hip/hip_runtime.h>
-#include <cuda_gl_interop.h>
-
-#include "helper_cuda_hipified.h"
-
-#include "helper_functions.h"
-#include "thrust/device_ptr.h"
-#include "thrust/for_each.h"
-#include "thrust/iterator/zip_iterator.h"
-#include "thrust/sort.h"
-
-#include "particles_kernel_impl.cuh"
-
-extern "C" {
-
-void cudaInit(int argc, char **argv) {
-  int devID;
-
-  // use command-line specified CUDA device, otherwise use device with highest
-  // Gflops/s
-  devID = findCudaDevice(argc, (const char **)argv);
-
-  if (devID < 0) {
-    printf("No CUDA Capable devices found, exiting...\n");
-    exit(EXIT_SUCCESS);
-  }
-}
-
-void allocateArray(void **devPtr, size_t size) {
-  HIPCHECK(hipMalloc(devPtr, size));
-}
-
-void freeArray(void *devPtr) { HIPCHECK(hipFree(devPtr)); }
-
-void threadSync() { HIPCHECK(hipDeviceSynchronize()); }
-
-void copyArrayToDevice(void *device, const void *host, int offset, int size) {
-  HIPCHECK(
-      hipMemcpy((char *)device + offset, host, size, hipMemcpyHostToDevice));
-}
-
-void registerGLBufferObject(uint vbo,
-                            struct hipGraphicsResource **cuda_vbo_resource) {
-  HIPCHECK(hipGraphicsGLRegisterBuffer(cuda_vbo_resource, vbo,
-                                               cudaGraphicsMapFlagsNone));
-}
-
-void unregisterGLBufferObject(struct hipGraphicsResource *cuda_vbo_resource) {
-  HIPCHECK(hipGraphicsUnregisterResource(cuda_vbo_resource));
-}
-
-void *mapGLBufferObject(struct hipGraphicsResource **cuda_vbo_resource) {
-  void *ptr;
-  HIPCHECK(hipGraphicsMapResources(1, cuda_vbo_resource, 0));
-  size_t num_bytes;
-  HIPCHECK(hipGraphicsResourceGetMappedPointer(
-      (void **)&ptr, &num_bytes, *cuda_vbo_resource));
-  return ptr;
-}
-
-void unmapGLBufferObject(struct hipGraphicsResource *cuda_vbo_resource) {
-  HIPCHECK(hipGraphicsUnmapResources(1, &cuda_vbo_resource, 0));
-}
-
-void copyArrayFromDevice(void *host, const void *device,
-                         struct hipGraphicsResource **cuda_vbo_resource,
-                         int size) {
-  if (cuda_vbo_resource) {
-    device = mapGLBufferObject(cuda_vbo_resource);
-  }
-
-  HIPCHECK(hipMemcpy(host, device, size, hipMemcpyDeviceToHost));
-
-  if (cuda_vbo_resource) {
-    unmapGLBufferObject(*cuda_vbo_resource);
-  }
-}
-
-void setParameters(SimParams *hostParams) {
-  // copy parameters to constant memory
-  HIPCHECK(hipMemcpyToSymbol(HIP_SYMBOL(params), hostParams, sizeof(SimParams)));
-}
-
-// Round a / b to nearest higher integer value
-uint iDivUp(uint a, uint b) { return (a % b != 0) ? (a / b + 1) : (a / b); }
-
-// compute grid and thread block size for a given number of elements
-void computeGridSize(uint n, uint blockSize, uint &numBlocks,
-                     uint &numThreads) {
-  numThreads = min(blockSize, n);
-  numBlocks = iDivUp(n, numThreads);
-}
-
-void integrateSystem(float *pos, float *vel, float deltaTime,
-                     uint numParticles) {
-  thrust::device_ptr<float4> d_pos4((float4 *)pos);
-  thrust::device_ptr<float4> d_vel4((float4 *)vel);
-
-  thrust::for_each(
-      thrust::make_zip_iterator(thrust::make_tuple(d_pos4, d_vel4)),
-      thrust::make_zip_iterator(
-          thrust::make_tuple(d_pos4 + numParticles, d_vel4 + numParticles)),
-      integrate_functor(deltaTime));
-}
-
-void calcHash(uint *gridParticleHash, uint *gridParticleIndex, float *pos,
-              int numParticles) {
-  uint numThreads, numBlocks;
-  computeGridSize(numParticles, 256, numBlocks, numThreads);
-
-  // execute the kernel
-  calcHashD<<<numBlocks, numThreads>>>(gridParticleHash, gridParticleIndex,
-                                       (float4 *)pos, numParticles);
-
-  // check if kernel invocation generated an error
-  getLastCudaError("Kernel execution failed");
-}
-
-void reorderDataAndFindCellStart(uint *cellStart, uint *cellEnd,
-                                 float *sortedPos, float *sortedVel,
-                                 uint *gridParticleHash,
-                                 uint *gridParticleIndex, float *oldPos,
-                                 float *oldVel, uint numParticles,
-                                 uint numCells) {
-  uint numThreads, numBlocks;
-  computeGridSize(numParticles, 256, numBlocks, numThreads);
-
-  // set all cells to empty
-  HIPCHECK(hipMemset(cellStart, 0xffffffff, numCells * sizeof(uint)));
-
-  uint smemSize = sizeof(uint) * (numThreads + 1);
-  reorderDataAndFindCellStartD<<<numBlocks, numThreads, smemSize>>>(
-      cellStart, cellEnd, (float4 *)sortedPos, (float4 *)sortedVel,
-      gridParticleHash, gridParticleIndex, (float4 *)oldPos, (float4 *)oldVel,
-      numParticles);
-  getLastCudaError("Kernel execution failed: reorderDataAndFindCellStartD");
-}
-
-void collide(float *newVel, float *sortedPos, float *sortedVel,
-             uint *gridParticleIndex, uint *cellStart, uint *cellEnd,
-             uint numParticles, uint numCells) {
-  // thread per particle
-  uint numThreads, numBlocks;
-  computeGridSize(numParticles, 64, numBlocks, numThreads);
-
-  // execute the kernel
-  collideD<<<numBlocks, numThreads>>>((float4 *)newVel, (float4 *)sortedPos,
-                                      (float4 *)sortedVel, gridParticleIndex,
-                                      cellStart, cellEnd, numParticles);
-
-  // check if kernel invocation generated an error
-  getLastCudaError("Kernel execution failed");
-}
-
-void sortParticles(uint *dGridParticleHash, uint *dGridParticleIndex,
-                   uint numParticles) {
-  thrust::sort_by_key(
-      thrust::device_ptr<uint>(dGridParticleHash),
-      thrust::device_ptr<uint>(dGridParticleHash + numParticles),
-      thrust::device_ptr<uint>(dGridParticleIndex));
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/particles/particleSystem_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles.cpp b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_kernel.cuh b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_kernel_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_kernel_impl.cuh b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_kernel_impl.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_kernel_impl_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_kernel_impl_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/particles/particles_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/render_particles.cpp b/src/samples/Samples/2_Concepts_and_Techniques/particles/render_particles.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/render_particles.h b/src/samples/Samples/2_Concepts_and_Techniques/particles/render_particles.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/render_particles_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/particles/render_particles_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/render_particles_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/particles/render_particles_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/shaders.cpp b/src/samples/Samples/2_Concepts_and_Techniques/particles/shaders.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/shaders.h b/src/samples/Samples/2_Concepts_and_Techniques/particles/shaders.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/shaders_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/particles/shaders_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/particles/shaders_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/particles/shaders_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/README.md b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/doc/readme.txt b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/doc/readme.txt
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust.cu b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust.cu.hip
old mode 100644
new mode 100755
index 69865bb..8bd4923
--- a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust.cu.hip
@@ -34,7 +34,7 @@
 #include <thrust/generate.h>
 #include <thrust/detail/type_traits.h>
 
-#include "helper_cuda_hipified.h"
+#include <helper_cuda.h>
 
 #include <algorithm>
 #include <time.h>
@@ -142,8 +142,8 @@ bool testSort(int argc, char **argv) {
 
   // run multiple iterations to compute an average sort time
   hipEvent_t start_event, stop_event;
-  HIPCHECK(hipEventCreate(&start_event));
-  HIPCHECK(hipEventCreate(&stop_event));
+  checkCudaErrors(hipEventCreate(&start_event));
+  checkCudaErrors(hipEventCreate(&stop_event));
 
   float totalTime = 0;
 
@@ -153,18 +153,18 @@ bool testSort(int argc, char **argv) {
 
     if (!keysOnly) d_values = h_values;
 
-    HIPCHECK(hipEventRecord(start_event, 0));
+    checkCudaErrors(hipEventRecord(start_event, 0));
 
     if (keysOnly)
       thrust::sort(d_keys.begin(), d_keys.end());
     else
       thrust::sort_by_key(d_keys.begin(), d_keys.end(), d_values.begin());
 
-    HIPCHECK(hipEventRecord(stop_event, 0));
-    HIPCHECK(hipEventSynchronize(stop_event));
+    checkCudaErrors(hipEventRecord(stop_event, 0));
+    checkCudaErrors(hipEventSynchronize(stop_event));
 
     float time = 0;
-    HIPCHECK(hipEventElapsedTime(&time, start_event, stop_event));
+    checkCudaErrors(hipEventElapsedTime(&time, start_event, stop_event));
     totalTime += time;
   }
 
@@ -188,8 +188,8 @@ bool testSort(int argc, char **argv) {
   bool bTestResult =
       thrust::is_sorted(h_keysSorted.begin(), h_keysSorted.end());
 
-  HIPCHECK(hipEventDestroy(start_event));
-  HIPCHECK(hipEventDestroy(stop_event));
+  checkCudaErrors(hipEventDestroy(start_event));
+  checkCudaErrors(hipEventDestroy(stop_event));
 
   if (!bTestResult && !quiet) {
     return false;
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/radixSortThrust/radixSortThrust_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/reduction/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/reduction/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/reduction/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/reduction/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/reduction/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/reduction/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/README.md b/src/samples/Samples/2_Concepts_and_Techniques/reduction/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction.cpp b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction.h b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_kernel.cu b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_kernel.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_kernel.cu.hip
old mode 100644
new mode 100755
index 9d53a89..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_kernel.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_kernel.cu.hip
@@ -1,1040 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
-    Parallel reduction kernels
-*/
-
-#ifndef _REDUCE_KERNEL_H_
-#define _REDUCE_KERNEL_H_
-
-#include <hip/hip_cooperative_groups.h>
-#include <cooperative_groups/reduce.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-
-namespace cg = cooperative_groups;
-
-// Utility class used to avoid linker errors with extern
-// unsized shared memory arrays with templated type
-template <class T>
-struct SharedMemory {
-  __device__ inline operator T *() {
-    extern __shared__ int __smem[];
-    return (T *)__smem;
-  }
-
-  __device__ inline operator const T *() const {
-    extern __shared__ int __smem[];
-    return (T *)__smem;
-  }
-};
-
-// specialize for double to avoid unaligned memory
-// access compile errors
-template <>
-struct SharedMemory<double> {
-  __device__ inline operator double *() {
-    extern __shared__ double __smem_d[];
-    return (double *)__smem_d;
-  }
-
-  __device__ inline operator const double *() const {
-    extern __shared__ double __smem_d[];
-    return (double *)__smem_d;
-  }
-};
-
-template <class T>
-__device__ __forceinline__ T warpReduceSum(unsigned int mask, T mySum) {
-  for (int offset = warpSize / 2; offset > 0; offset /= 2) {
-    mySum += __shfl_down_sync(mask, mySum, offset);
-  }
-  return mySum;
-}
-
-#if __CUDA_ARCH__ >= 800
-// Specialize warpReduceFunc for int inputs to use __reduce_add_sync intrinsic
-// when on SM 8.0 or higher
-template <>
-__device__ __forceinline__ int warpReduceSum<int>(unsigned int mask,
-                                                  int mySum) {
-  mySum = __reduce_add_sync(mask, mySum);
-  return mySum;
-}
-#endif
-
-/*
-    Parallel sum reduction using shared memory
-    - takes log(n) steps for n input elements
-    - uses n threads
-    - only works for power-of-2 arrays
-*/
-
-/* This reduction interleaves which threads are active by using the modulo
-   operator.  This operator is very expensive on GPUs, and the interleaved
-   inactivity means that no whole warps are active, which is also very
-   inefficient */
-template <class T>
-__global__ void reduce0(T *g_idata, T *g_odata, unsigned int n) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  T *sdata = SharedMemory<T>();
-
-  // load shared mem
-  unsigned int tid = threadIdx.x;
-  unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
-
-  sdata[tid] = (i < n) ? g_idata[i] : 0;
-
-  cg::sync(cta);
-
-  // do reduction in shared mem
-  for (unsigned int s = 1; s < blockDim.x; s *= 2) {
-    // modulo arithmetic is slow!
-    if ((tid % (2 * s)) == 0) {
-      sdata[tid] += sdata[tid + s];
-    }
-
-    cg::sync(cta);
-  }
-
-  // write result for this block to global mem
-  if (tid == 0) g_odata[blockIdx.x] = sdata[0];
-}
-
-/* This version uses contiguous threads, but its interleaved
-   addressing results in many shared memory bank conflicts.
-*/
-template <class T>
-__global__ void reduce1(T *g_idata, T *g_odata, unsigned int n) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  T *sdata = SharedMemory<T>();
-
-  // load shared mem
-  unsigned int tid = threadIdx.x;
-  unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
-
-  sdata[tid] = (i < n) ? g_idata[i] : 0;
-
-  cg::sync(cta);
-
-  // do reduction in shared mem
-  for (unsigned int s = 1; s < blockDim.x; s *= 2) {
-    int index = 2 * s * tid;
-
-    if (index < blockDim.x) {
-      sdata[index] += sdata[index + s];
-    }
-
-    cg::sync(cta);
-  }
-
-  // write result for this block to global mem
-  if (tid == 0) g_odata[blockIdx.x] = sdata[0];
-}
-
-/*
-    This version uses sequential addressing -- no divergence or bank conflicts.
-*/
-template <class T>
-__global__ void reduce2(T *g_idata, T *g_odata, unsigned int n) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  T *sdata = SharedMemory<T>();
-
-  // load shared mem
-  unsigned int tid = threadIdx.x;
-  unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
-
-  sdata[tid] = (i < n) ? g_idata[i] : 0;
-
-  cg::sync(cta);
-
-  // do reduction in shared mem
-  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
-    if (tid < s) {
-      sdata[tid] += sdata[tid + s];
-    }
-
-    cg::sync(cta);
-  }
-
-  // write result for this block to global mem
-  if (tid == 0) g_odata[blockIdx.x] = sdata[0];
-}
-
-/*
-    This version uses n/2 threads --
-    it performs the first level of reduction when reading from global memory.
-*/
-template <class T>
-__global__ void reduce3(T *g_idata, T *g_odata, unsigned int n) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  T *sdata = SharedMemory<T>();
-
-  // perform first level of reduction,
-  // reading from global memory, writing to shared memory
-  unsigned int tid = threadIdx.x;
-  unsigned int i = blockIdx.x * (blockDim.x * 2) + threadIdx.x;
-
-  T mySum = (i < n) ? g_idata[i] : 0;
-
-  if (i + blockDim.x < n) mySum += g_idata[i + blockDim.x];
-
-  sdata[tid] = mySum;
-  cg::sync(cta);
-
-  // do reduction in shared mem
-  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
-    if (tid < s) {
-      sdata[tid] = mySum = mySum + sdata[tid + s];
-    }
-
-    cg::sync(cta);
-  }
-
-  // write result for this block to global mem
-  if (tid == 0) g_odata[blockIdx.x] = mySum;
-}
-
-/*
-    This version uses the warp shuffle operation if available to reduce
-    warp synchronization. When shuffle is not available the final warp's
-    worth of work is unrolled to reduce looping overhead.
-
-    See
-   http://devblogs.nvidia.com/parallelforall/faster-parallel-reductions-kepler/
-    for additional information about using shuffle to perform a reduction
-    within a warp.
-
-    Note, this kernel needs a minimum of 64*sizeof(T) bytes of shared memory.
-    In other words if blockSize <= 32, allocate 64*sizeof(T) bytes.
-    If blockSize > 32, allocate blockSize*sizeof(T) bytes.
-*/
-template <class T, unsigned int blockSize>
-__global__ void reduce4(T *g_idata, T *g_odata, unsigned int n) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  T *sdata = SharedMemory<T>();
-
-  // perform first level of reduction,
-  // reading from global memory, writing to shared memory
-  unsigned int tid = threadIdx.x;
-  unsigned int i = blockIdx.x * (blockDim.x * 2) + threadIdx.x;
-
-  T mySum = (i < n) ? g_idata[i] : 0;
-
-  if (i + blockSize < n) mySum += g_idata[i + blockSize];
-
-  sdata[tid] = mySum;
-  cg::sync(cta);
-
-  // do reduction in shared mem
-  for (unsigned int s = blockDim.x / 2; s > 32; s >>= 1) {
-    if (tid < s) {
-      sdata[tid] = mySum = mySum + sdata[tid + s];
-    }
-
-    cg::sync(cta);
-  }
-
-  cg::thread_block_tile<32> tile32 = cg::tiled_partition<32>(cta);
-
-  if (cta.thread_rank() < 32) {
-    // Fetch final intermediate sum from 2nd warp
-    if (blockSize >= 64) mySum += sdata[tid + 32];
-    // Reduce final warp using shuffle
-    for (int offset = tile32.size() / 2; offset > 0; offset /= 2) {
-      mySum += tile32.shfl_down(mySum, offset);
-    }
-  }
-
-  // write result for this block to global mem
-  if (cta.thread_rank() == 0) g_odata[blockIdx.x] = mySum;
-}
-
-/*
-    This version is completely unrolled, unless warp shuffle is available, then
-    shuffle is used within a loop.  It uses a template parameter to achieve
-    optimal code for any (power of 2) number of threads.  This requires a switch
-    statement in the host code to handle all the different thread block sizes at
-    compile time. When shuffle is available, it is used to reduce warp
-   synchronization.
-
-    Note, this kernel needs a minimum of 64*sizeof(T) bytes of shared memory.
-    In other words if blockSize <= 32, allocate 64*sizeof(T) bytes.
-    If blockSize > 32, allocate blockSize*sizeof(T) bytes.
-*/
-template <class T, unsigned int blockSize>
-__global__ void reduce5(T *g_idata, T *g_odata, unsigned int n) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  T *sdata = SharedMemory<T>();
-
-  // perform first level of reduction,
-  // reading from global memory, writing to shared memory
-  unsigned int tid = threadIdx.x;
-  unsigned int i = blockIdx.x * (blockSize * 2) + threadIdx.x;
-
-  T mySum = (i < n) ? g_idata[i] : 0;
-
-  if (i + blockSize < n) mySum += g_idata[i + blockSize];
-
-  sdata[tid] = mySum;
-  cg::sync(cta);
-
-  // do reduction in shared mem
-  if ((blockSize >= 512) && (tid < 256)) {
-    sdata[tid] = mySum = mySum + sdata[tid + 256];
-  }
-
-  cg::sync(cta);
-
-  if ((blockSize >= 256) && (tid < 128)) {
-    sdata[tid] = mySum = mySum + sdata[tid + 128];
-  }
-
-  cg::sync(cta);
-
-  if ((blockSize >= 128) && (tid < 64)) {
-    sdata[tid] = mySum = mySum + sdata[tid + 64];
-  }
-
-  cg::sync(cta);
-
-  cg::thread_block_tile<32> tile32 = cg::tiled_partition<32>(cta);
-
-  if (cta.thread_rank() < 32) {
-    // Fetch final intermediate sum from 2nd warp
-    if (blockSize >= 64) mySum += sdata[tid + 32];
-    // Reduce final warp using shuffle
-    for (int offset = tile32.size() / 2; offset > 0; offset /= 2) {
-      mySum += tile32.shfl_down(mySum, offset);
-    }
-  }
-
-  // write result for this block to global mem
-  if (cta.thread_rank() == 0) g_odata[blockIdx.x] = mySum;
-}
-
-/*
-    This version adds multiple elements per thread sequentially.  This reduces
-   the overall cost of the algorithm while keeping the work complexity O(n) and
-   the step complexity O(log n). (Brent's Theorem optimization)
-
-    Note, this kernel needs a minimum of 64*sizeof(T) bytes of shared memory.
-    In other words if blockSize <= 32, allocate 64*sizeof(T) bytes.
-    If blockSize > 32, allocate blockSize*sizeof(T) bytes.
-*/
-template <class T, unsigned int blockSize, bool nIsPow2>
-__global__ void reduce6(T *g_idata, T *g_odata, unsigned int n) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  T *sdata = SharedMemory<T>();
-
-  // perform first level of reduction,
-  // reading from global memory, writing to shared memory
-  unsigned int tid = threadIdx.x;
-  unsigned int gridSize = blockSize * gridDim.x;
-
-  T mySum = 0;
-
-  // we reduce multiple elements per thread.  The number is determined by the
-  // number of active thread blocks (via gridDim).  More blocks will result
-  // in a larger gridSize and therefore fewer elements per thread
-  if (nIsPow2) {
-    unsigned int i = blockIdx.x * blockSize * 2 + threadIdx.x;
-    gridSize = gridSize << 1;
-
-    while (i < n) {
-      mySum += g_idata[i];
-      // ensure we don't read out of bounds -- this is optimized away for
-      // powerOf2 sized arrays
-      if ((i + blockSize) < n) {
-        mySum += g_idata[i + blockSize];
-      }
-      i += gridSize;
-    }
-  } else {
-    unsigned int i = blockIdx.x * blockSize + threadIdx.x;
-    while (i < n) {
-      mySum += g_idata[i];
-      i += gridSize;
-    }
-  }
-
-  // each thread puts its local sum into shared memory
-  sdata[tid] = mySum;
-  cg::sync(cta);
-
-  // do reduction in shared mem
-  if ((blockSize >= 512) && (tid < 256)) {
-    sdata[tid] = mySum = mySum + sdata[tid + 256];
-  }
-
-  cg::sync(cta);
-
-  if ((blockSize >= 256) && (tid < 128)) {
-    sdata[tid] = mySum = mySum + sdata[tid + 128];
-  }
-
-  cg::sync(cta);
-
-  if ((blockSize >= 128) && (tid < 64)) {
-    sdata[tid] = mySum = mySum + sdata[tid + 64];
-  }
-
-  cg::sync(cta);
-
-  cg::thread_block_tile<32> tile32 = cg::tiled_partition<32>(cta);
-
-  if (cta.thread_rank() < 32) {
-    // Fetch final intermediate sum from 2nd warp
-    if (blockSize >= 64) mySum += sdata[tid + 32];
-    // Reduce final warp using shuffle
-    for (int offset = tile32.size() / 2; offset > 0; offset /= 2) {
-      mySum += tile32.shfl_down(mySum, offset);
-    }
-  }
-
-  // write result for this block to global mem
-  if (cta.thread_rank() == 0) g_odata[blockIdx.x] = mySum;
-}
-
-template <typename T, unsigned int blockSize, bool nIsPow2>
-__global__ void reduce7(const T *__restrict__ g_idata, T *__restrict__ g_odata,
-                        unsigned int n) {
-  T *sdata = SharedMemory<T>();
-
-  // perform first level of reduction,
-  // reading from global memory, writing to shared memory
-  unsigned int tid = threadIdx.x;
-  unsigned int gridSize = blockSize * gridDim.x;
-  unsigned int maskLength = (blockSize & 31);  // 31 = warpSize-1
-  maskLength = (maskLength > 0) ? (32 - maskLength) : maskLength;
-  const unsigned int mask = (0xffffffff) >> maskLength;
-
-  T mySum = 0;
-
-  // we reduce multiple elements per thread.  The number is determined by the
-  // number of active thread blocks (via gridDim).  More blocks will result
-  // in a larger gridSize and therefore fewer elements per thread
-  if (nIsPow2) {
-    unsigned int i = blockIdx.x * blockSize * 2 + threadIdx.x;
-    gridSize = gridSize << 1;
-
-    while (i < n) {
-      mySum += g_idata[i];
-      // ensure we don't read out of bounds -- this is optimized away for
-      // powerOf2 sized arrays
-      if ((i + blockSize) < n) {
-        mySum += g_idata[i + blockSize];
-      }
-      i += gridSize;
-    }
-  } else {
-    unsigned int i = blockIdx.x * blockSize + threadIdx.x;
-    while (i < n) {
-      mySum += g_idata[i];
-      i += gridSize;
-    }
-  }
-
-  // Reduce within warp using shuffle or reduce_add if T==int & CUDA_ARCH ==
-  // SM 8.0
-  mySum = warpReduceSum<T>(mask, mySum);
-
-  // each thread puts its local sum into shared memory
-  if ((tid % warpSize) == 0) {
-    sdata[tid / warpSize] = mySum;
-  }
-
-  __syncthreads();
-
-  const unsigned int shmem_extent =
-      (blockSize / warpSize) > 0 ? (blockSize / warpSize) : 1;
-  const unsigned int ballot_result = __ballot_sync(mask, tid < shmem_extent);
-  if (tid < shmem_extent) {
-    mySum = sdata[tid];
-    // Reduce final warp using shuffle or reduce_add if T==int & CUDA_ARCH ==
-    // SM 8.0
-    mySum = warpReduceSum<T>(ballot_result, mySum);
-  }
-
-  // write result for this block to global mem
-  if (tid == 0) {
-    g_odata[blockIdx.x] = mySum;
-  }
-}
-
-// Performs a reduction step and updates numTotal with how many are remaining
-template <typename T, typename Group>
-__device__ T cg_reduce_n(T in, Group &threads) {
-  return cg::reduce(threads, in, cg::plus<T>());
-}
-
-template <class T>
-__global__ void cg_reduce(T *g_idata, T *g_odata, unsigned int n) {
-  // Shared memory for intermediate steps
-  T *sdata = SharedMemory<T>();
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  // Handle to tile in thread block
-  cg::thread_block_tile<32> tile = cg::tiled_partition<32>(cta);
-
-  unsigned int ctaSize = cta.size();
-  unsigned int numCtas = gridDim.x;
-  unsigned int threadRank = cta.thread_rank();
-  unsigned int threadIndex = (blockIdx.x * ctaSize) + threadRank;
-
-  T threadVal = 0;
-  {
-    unsigned int i = threadIndex;
-    unsigned int indexStride = (numCtas * ctaSize);
-    while (i < n) {
-      threadVal += g_idata[i];
-      i += indexStride;
-    }
-    sdata[threadRank] = threadVal;
-  }
-
-  // Wait for all tiles to finish and reduce within CTA
-  {
-    unsigned int ctaSteps = tile.meta_group_size();
-    unsigned int ctaIndex = ctaSize >> 1;
-    while (ctaIndex >= 32) {
-      cta.sync();
-      if (threadRank < ctaIndex) {
-        threadVal += sdata[threadRank + ctaIndex];
-        sdata[threadRank] = threadVal;
-      }
-      ctaSteps >>= 1;
-      ctaIndex >>= 1;
-    }
-  }
-
-  // Shuffle redux instead of smem redux
-  {
-    cta.sync();
-    if (tile.meta_group_rank() == 0) {
-      threadVal = cg_reduce_n(threadVal, tile);
-    }
-  }
-
-  if (threadRank == 0) g_odata[blockIdx.x] = threadVal;
-}
-
-template <class T, size_t BlockSize, size_t MultiWarpGroupSize>
-__global__ void multi_warp_cg_reduce(T *g_idata, T *g_odata, unsigned int n) {
-  // Shared memory for intermediate steps
-  T *sdata = SharedMemory<T>();
-  __shared__ cg::block_tile_memory<BlockSize> scratch;
-
-  // Handle to thread block group
-  auto cta = cg::this_thread_block(scratch);
-  // Handle to multiWarpTile in thread block
-  auto multiWarpTile = cg::tiled_partition<MultiWarpGroupSize>(cta);
-
-  unsigned int gridSize = BlockSize * gridDim.x;
-  T threadVal = 0;
-
-  // we reduce multiple elements per thread.  The number is determined by the
-  // number of active thread blocks (via gridDim).  More blocks will result
-  // in a larger gridSize and therefore fewer elements per thread
-  int nIsPow2 = !(n & n-1);
-  if (nIsPow2) {
-    unsigned int i = blockIdx.x * BlockSize * 2 + threadIdx.x;
-    gridSize = gridSize << 1;
-
-    while (i < n) {
-      threadVal += g_idata[i];
-      // ensure we don't read out of bounds -- this is optimized away for
-      // powerOf2 sized arrays
-      if ((i + BlockSize) < n) {
-        threadVal += g_idata[i + blockDim.x];
-      }
-      i += gridSize;
-    }
-  } else {
-    unsigned int i = blockIdx.x * BlockSize + threadIdx.x;
-    while (i < n) {
-      threadVal += g_idata[i];
-      i += gridSize;
-    }
-  }
-
-  threadVal = cg_reduce_n(threadVal, multiWarpTile);
-
-  if (multiWarpTile.thread_rank() == 0) {
-    sdata[multiWarpTile.meta_group_rank()] = threadVal;
-  }
-  cg::sync(cta);
-
-  if (threadIdx.x == 0) {
-    threadVal = 0;
-    for (int i=0; i < multiWarpTile.meta_group_size(); i++) {
-      threadVal += sdata[i];
-    }
-    g_odata[blockIdx.x] = threadVal;
-  }
-}
-
-extern "C" bool isPow2(unsigned int x);
-
-////////////////////////////////////////////////////////////////////////////////
-// Wrapper function for kernel launch
-////////////////////////////////////////////////////////////////////////////////
-template <class T>
-void reduce(int size, int threads, int blocks, int whichKernel, T *d_idata,
-            T *d_odata) {
-  dim3 dimBlock(threads, 1, 1);
-  dim3 dimGrid(blocks, 1, 1);
-
-  // when there is only one warp per block, we need to allocate two warps
-  // worth of shared memory so that we don't index shared memory out of bounds
-  int smemSize =
-      (threads <= 32) ? 2 * threads * sizeof(T) : threads * sizeof(T);
-
-  // as kernel 9 - multi_warp_cg_reduce cannot work for more than 64 threads
-  // we choose to set kernel 7 for this purpose.
-  if (threads < 64 && whichKernel == 9)
-  {
-    whichKernel = 7;
-  }
-
-  // choose which of the optimized versions of reduction to launch
-  switch (whichKernel) {
-    case 0:
-      reduce0<T><<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-      break;
-
-    case 1:
-      reduce1<T><<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-      break;
-
-    case 2:
-      reduce2<T><<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-      break;
-
-    case 3:
-      reduce3<T><<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-      break;
-
-    case 4:
-      switch (threads) {
-        case 512:
-          reduce4<T, 512>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 256:
-          reduce4<T, 256>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 128:
-          reduce4<T, 128>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 64:
-          reduce4<T, 64>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 32:
-          reduce4<T, 32>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 16:
-          reduce4<T, 16>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 8:
-          reduce4<T, 8>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 4:
-          reduce4<T, 4>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 2:
-          reduce4<T, 2>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 1:
-          reduce4<T, 1>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-      }
-
-      break;
-
-    case 5:
-      switch (threads) {
-        case 512:
-          reduce5<T, 512>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 256:
-          reduce5<T, 256>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 128:
-          reduce5<T, 128>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 64:
-          reduce5<T, 64>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 32:
-          reduce5<T, 32>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 16:
-          reduce5<T, 16>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 8:
-          reduce5<T, 8>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 4:
-          reduce5<T, 4>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 2:
-          reduce5<T, 2>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 1:
-          reduce5<T, 1>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-      }
-
-      break;
-
-    case 6:
-      if (isPow2(size)) {
-        switch (threads) {
-          case 512:
-            reduce6<T, 512, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 256:
-            reduce6<T, 256, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 128:
-            reduce6<T, 128, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 64:
-            reduce6<T, 64, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 32:
-            reduce6<T, 32, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 16:
-            reduce6<T, 16, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 8:
-            reduce6<T, 8, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 4:
-            reduce6<T, 4, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 2:
-            reduce6<T, 2, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 1:
-            reduce6<T, 1, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-        }
-      } else {
-        switch (threads) {
-          case 512:
-            reduce6<T, 512, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 256:
-            reduce6<T, 256, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 128:
-            reduce6<T, 128, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 64:
-            reduce6<T, 64, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 32:
-            reduce6<T, 32, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 16:
-            reduce6<T, 16, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 8:
-            reduce6<T, 8, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 4:
-            reduce6<T, 4, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 2:
-            reduce6<T, 2, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 1:
-            reduce6<T, 1, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-        }
-      }
-
-      break;
-
-    case 7:
-      // For reduce7 kernel we require only blockSize/warpSize
-      // number of elements in shared memory
-      smemSize = ((threads / 32) + 1) * sizeof(T);
-      if (isPow2(size)) {
-        switch (threads) {
-          case 1024:
-            reduce7<T, 1024, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-          case 512:
-            reduce7<T, 512, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 256:
-            reduce7<T, 256, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 128:
-            reduce7<T, 128, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 64:
-            reduce7<T, 64, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 32:
-            reduce7<T, 32, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 16:
-            reduce7<T, 16, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 8:
-            reduce7<T, 8, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 4:
-            reduce7<T, 4, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 2:
-            reduce7<T, 2, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 1:
-            reduce7<T, 1, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-        }
-      } else {
-        switch (threads) {
-          case 1024:
-            reduce7<T, 1024, true>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-          case 512:
-            reduce7<T, 512, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 256:
-            reduce7<T, 256, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 128:
-            reduce7<T, 128, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 64:
-            reduce7<T, 64, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 32:
-            reduce7<T, 32, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 16:
-            reduce7<T, 16, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 8:
-            reduce7<T, 8, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 4:
-            reduce7<T, 4, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 2:
-            reduce7<T, 2, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-
-          case 1:
-            reduce7<T, 1, false>
-                <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-            break;
-        }
-      }
-
-      break;
-    case 8:
-      cg_reduce<T><<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-      break;
-    case 9:
-      constexpr int numOfMultiWarpGroups = 2;
-      smemSize = numOfMultiWarpGroups * sizeof(T);
-      switch (threads) {
-        case 1024:
-          multi_warp_cg_reduce<T, 1024, 1024/numOfMultiWarpGroups>
-            <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 512:
-          multi_warp_cg_reduce<T, 512, 512/numOfMultiWarpGroups>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 256:
-          multi_warp_cg_reduce<T, 256, 256/numOfMultiWarpGroups>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 128:
-          multi_warp_cg_reduce<T, 128, 128/numOfMultiWarpGroups>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        case 64:
-          multi_warp_cg_reduce<T, 64, 64/numOfMultiWarpGroups>
-              <<<dimGrid, dimBlock, smemSize>>>(d_idata, d_odata, size);
-          break;
-
-        default:
-          printf("thread block size of < 64 is not supported for this kernel\n");
-          break;
-      }
-      break;
-  }
-}
-
-// Instantiate the reduction function for 3 types
-template void reduce<int>(int size, int threads, int blocks, int whichKernel,
-                          int *d_idata, int *d_odata);
-
-template void reduce<float>(int size, int threads, int blocks, int whichKernel,
-                            float *d_idata, float *d_odata);
-
-template void reduce<double>(int size, int threads, int blocks, int whichKernel,
-                             double *d_idata, double *d_odata);
-
-#endif  // #ifndef _REDUCE_KERNEL_H_
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/reduction/reduction_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/README.md b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG.cu b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG.cu.hip
old mode 100644
new mode 100755
index 8410a75..40f4bca
--- a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG.cu.hip
@@ -57,15 +57,13 @@
 // includes, system
 #include <stdlib.h>
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <string.h>
 #include <math.h>
 
 // includes, project
 #include "helper_functions.h"
 #include "helper_cuda_hipified.h"
-
+//#include <hipify/__clang_cuda_intrinsics.h>
 #include <hip/hip_runtime.h>
 
 const char *sSDKsample = "reductionMultiBlockCG";
@@ -179,7 +177,7 @@ int main(int argc, char **argv) {
   printf("%s Starting...\n\n", sSDKsample);
 
   dev = findCudaDevice(argc, (const char **)argv);
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, dev));
+  checkCudaErrors(hipGetDeviceProperties(&deviceProp, dev));
   if (!deviceProp.cooperativeLaunch) {
     printf(
         "\nSelected GPU (%d) does not support Cooperative Kernel Launch, "
@@ -237,7 +235,7 @@ void getNumBlocksAndThreads(int n, int maxBlocks, int maxThreads, int &blocks,
     threads = 1;
     blocks = 1;
   } else {
-    HIPCHECK(hipOccupancyMaxPotentialBlockSize(
+    checkCudaErrors(hipOccupancyMaxPotentialBlockSize(
         &blocks, &threads, reduceSinglePassMultiBlockCG));
   }
 
@@ -269,7 +267,7 @@ float benchmarkReduce(int n, int numThreads, int numBlocks, int maxThreads,
   // copy final sum from device to host
   error =
       hipMemcpy(&gpu_result, d_odata, sizeof(float), hipMemcpyDeviceToHost);
-  HIPCHECK(error);
+  checkCudaErrors(error);
 
   return gpu_result;
 }
@@ -289,8 +287,8 @@ bool runTest(int argc, char **argv, int device) {
 
   // Set the device to be used
   hipDeviceProp_t prop = {0};
-  HIPCHECK(hipSetDevice(device));
-  HIPCHECK(hipGetDeviceProperties(&prop, device));
+  checkCudaErrors(hipSetDevice(device));
+  checkCudaErrors(hipGetDeviceProperties(&prop, device));
 
   // create random input data on CPU
   unsigned int bytes = size * sizeof(float);
@@ -326,7 +324,7 @@ bool runTest(int argc, char **argv, int device) {
   // We calculate the occupancy to know how many block can actually fit on the
   // GPU
   int numBlocksPerSm = 0;
-  HIPCHECK(hipOccupancyMaxActiveBlocksPerMultiprocessor(
+  checkCudaErrors(hipOccupancyMaxActiveBlocksPerMultiprocessor(
       &numBlocksPerSm, reduceSinglePassMultiBlockCG, numThreads,
       numThreads * sizeof(double)));
 
@@ -344,12 +342,12 @@ bool runTest(int argc, char **argv, int device) {
   float *d_idata = NULL;
   float *d_odata = NULL;
 
-  HIPCHECK(hipMalloc((void **)&d_idata, bytes));
-  HIPCHECK(hipMalloc((void **)&d_odata, numBlocks * sizeof(float)));
+  checkCudaErrors(hipMalloc((void **)&d_idata, bytes));
+  checkCudaErrors(hipMalloc((void **)&d_odata, numBlocks * sizeof(float)));
 
   // copy data directly to device memory
-  HIPCHECK(hipMemcpy(d_idata, h_idata, bytes, hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy(d_odata, h_idata, numBlocks * sizeof(float),
+  checkCudaErrors(hipMemcpy(d_idata, h_idata, bytes, hipMemcpyHostToDevice));
+  checkCudaErrors(hipMemcpy(d_odata, h_idata, numBlocks * sizeof(float),
                              hipMemcpyHostToDevice));
 
   int testIterations = 100;
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/reductionMultiBlockCG/reductionMultiBlockCG_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/README.md b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd.cu b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd.cu.hip
old mode 100644
new mode 100755
index c1aa82c..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd.cu.hip
@@ -1,170 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This sample calculates scalar products of a
- * given set of input vector pairs
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <time.h>
-#include <string.h>
-
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-
-///////////////////////////////////////////////////////////////////////////////
-// Calculate scalar products of VectorN vectors of ElementN elements on CPU
-///////////////////////////////////////////////////////////////////////////////
-extern "C" void scalarProdCPU(float *h_C, float *h_A, float *h_B, int vectorN,
-                              int elementN);
-
-///////////////////////////////////////////////////////////////////////////////
-// Calculate scalar products of VectorN vectors of ElementN elements on GPU
-///////////////////////////////////////////////////////////////////////////////
-#include "scalarProd_kernel.cuh"
-
-////////////////////////////////////////////////////////////////////////////////
-// Helper function, returning uniformly distributed
-// random float in [low, high] range
-////////////////////////////////////////////////////////////////////////////////
-float RandFloat(float low, float high) {
-  float t = (float)rand() / (float)RAND_MAX;
-  return (1.0f - t) * low + t * high;
-}
-
-///////////////////////////////////////////////////////////////////////////////
-// Data configuration
-///////////////////////////////////////////////////////////////////////////////
-
-// Total number of input vector pairs; arbitrary
-const int VECTOR_N = 256;
-// Number of elements per vector; arbitrary,
-// but strongly preferred to be a multiple of warp size
-// to meet memory coalescing constraints
-const int ELEMENT_N = 4096;
-// Total number of data elements
-const int DATA_N = VECTOR_N * ELEMENT_N;
-
-const int DATA_SZ = DATA_N * sizeof(float);
-const int RESULT_SZ = VECTOR_N * sizeof(float);
-
-///////////////////////////////////////////////////////////////////////////////
-// Main program
-///////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  float *h_A, *h_B, *h_C_CPU, *h_C_GPU;
-  float *d_A, *d_B, *d_C;
-  double delta, ref, sum_delta, sum_ref, L1norm;
-  StopWatchInterface *hTimer = NULL;
-  int i;
-
-  printf("%s Starting...\n\n", argv[0]);
-
-  // use command-line specified CUDA device, otherwise use device with highest
-  // Gflops/s
-  findCudaDevice(argc, (const char **)argv);
-
-  sdkCreateTimer(&hTimer);
-
-  printf("Initializing data...\n");
-  printf("...allocating CPU memory.\n");
-  h_A = (float *)malloc(DATA_SZ);
-  h_B = (float *)malloc(DATA_SZ);
-  h_C_CPU = (float *)malloc(RESULT_SZ);
-  h_C_GPU = (float *)malloc(RESULT_SZ);
-
-  printf("...allocating GPU memory.\n");
-  HIPCHECK(hipMalloc((void **)&d_A, DATA_SZ));
-  HIPCHECK(hipMalloc((void **)&d_B, DATA_SZ));
-  HIPCHECK(hipMalloc((void **)&d_C, RESULT_SZ));
-
-  printf("...generating input data in CPU mem.\n");
-  srand(123);
-
-  // Generating input data on CPU
-  for (i = 0; i < DATA_N; i++) {
-    h_A[i] = RandFloat(0.0f, 1.0f);
-    h_B[i] = RandFloat(0.0f, 1.0f);
-  }
-
-  printf("...copying input data to GPU mem.\n");
-  // Copy options data to GPU memory for further processing
-  HIPCHECK(hipMemcpy(d_A, h_A, DATA_SZ, hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy(d_B, h_B, DATA_SZ, hipMemcpyHostToDevice));
-  printf("Data init done.\n");
-
-  printf("Executing GPU kernel...\n");
-  HIPCHECK(hipDeviceSynchronize());
-  sdkResetTimer(&hTimer);
-  sdkStartTimer(&hTimer);
-  scalarProdGPU<<<128, 256>>>(d_C, d_A, d_B, VECTOR_N, ELEMENT_N);
-  getLastCudaError("scalarProdGPU() execution failed\n");
-  HIPCHECK(hipDeviceSynchronize());
-  sdkStopTimer(&hTimer);
-  printf("GPU time: %f msecs.\n", sdkGetTimerValue(&hTimer));
-
-  printf("Reading back GPU result...\n");
-  // Read back GPU results to compare them to CPU results
-  HIPCHECK(hipMemcpy(h_C_GPU, d_C, RESULT_SZ, hipMemcpyDeviceToHost));
-
-  printf("Checking GPU results...\n");
-  printf("..running CPU scalar product calculation\n");
-  scalarProdCPU(h_C_CPU, h_A, h_B, VECTOR_N, ELEMENT_N);
-
-  printf("...comparing the results\n");
-  // Calculate max absolute difference and L1 distance
-  // between CPU and GPU results
-  sum_delta = 0;
-  sum_ref = 0;
-
-  for (i = 0; i < VECTOR_N; i++) {
-    delta = fabs(h_C_GPU[i] - h_C_CPU[i]);
-    ref = h_C_CPU[i];
-    sum_delta += delta;
-    sum_ref += ref;
-  }
-
-  L1norm = sum_delta / sum_ref;
-
-  printf("Shutting down...\n");
-  HIPCHECK(hipFree(d_C));
-  HIPCHECK(hipFree(d_B));
-  HIPCHECK(hipFree(d_A));
-  free(h_C_GPU);
-  free(h_C_CPU);
-  free(h_B);
-  free(h_A);
-  sdkDeleteTimer(&hTimer);
-
-  printf("L1 error: %E\n", L1norm);
-  printf((L1norm < 1e-6) ? "Test passed\n" : "Test failed!\n");
-  exit(L1norm < 1e-6 ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd.out b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_cpu.cpp b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_cpu.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_cpu_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_cpu_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_kernel.cuh b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_kernel_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/scan/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/scan/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/scan/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/scan/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/scan/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/scan/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/README.md b/src/samples/Samples/2_Concepts_and_Techniques/scan/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/main.cpp b/src/samples/Samples/2_Concepts_and_Techniques/scan/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/main_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/scan/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.cu b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.cu.hip
old mode 100644
new mode 100755
index 2dbdf6a..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.cu.hip
@@ -1,268 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <assert.h>
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-#include "helper_cuda_hipified.h"
-#include "scan_common.h"
-#include "HIPCHECK.h"
-// All three kernels run 512 threads per workgroup
-// Must be a power of two
-#define THREADBLOCK_SIZE 256
-
-////////////////////////////////////////////////////////////////////////////////
-// Basic scan codelets
-////////////////////////////////////////////////////////////////////////////////
-// Naive inclusive scan: O(N * log2(N)) operations
-// Allocate 2 * 'size' local memory, initialize the first half
-// with 'size' zeros avoiding if(pos >= offset) condition evaluation
-// and saving instructions
-inline __device__ uint scan1Inclusive(uint idata, volatile uint *s_Data,
-                                      uint size, cg::thread_block cta) {
-  uint pos = 2 * threadIdx.x - (threadIdx.x & (size - 1));
-  s_Data[pos] = 0;
-  pos += size;
-  s_Data[pos] = idata;
-
-  for (uint offset = 1; offset < size; offset <<= 1) {
-    cg::sync(cta);
-    uint t = s_Data[pos] + s_Data[pos - offset];
-    cg::sync(cta);
-    s_Data[pos] = t;
-  }
-
-  return s_Data[pos];
-}
-
-inline __device__ uint scan1Exclusive(uint idata, volatile uint *s_Data,
-                                      uint size, cg::thread_block cta) {
-  return scan1Inclusive(idata, s_Data, size, cta) - idata;
-}
-
-inline __device__ uint4 scan4Inclusive(uint4 idata4, volatile uint *s_Data,
-                                       uint size, cg::thread_block cta) {
-  // Level-0 inclusive scan
-  idata4.y += idata4.x;
-  idata4.z += idata4.y;
-  idata4.w += idata4.z;
-
-  // Level-1 exclusive scan
-  uint oval = scan1Exclusive(idata4.w, s_Data, size / 4, cta);
-
-  idata4.x += oval;
-  idata4.y += oval;
-  idata4.z += oval;
-  idata4.w += oval;
-
-  return idata4;
-}
-
-// Exclusive vector scan: the array to be scanned is stored
-// in local thread memory scope as uint4
-inline __device__ uint4 scan4Exclusive(uint4 idata4, volatile uint *s_Data,
-                                       uint size, cg::thread_block cta) {
-  uint4 odata4 = scan4Inclusive(idata4, s_Data, size, cta);
-  odata4.x -= idata4.x;
-  odata4.y -= idata4.y;
-  odata4.z -= idata4.z;
-  odata4.w -= idata4.w;
-  return odata4;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Scan kernels
-////////////////////////////////////////////////////////////////////////////////
-__global__ void scanExclusiveShared(uint4 *d_Dst, uint4 *d_Src, uint size) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  __shared__ uint s_Data[2 * THREADBLOCK_SIZE];
-
-  uint pos = blockIdx.x * blockDim.x + threadIdx.x;
-
-  // Load data
-  uint4 idata4 = d_Src[pos];
-
-  // Calculate exclusive scan
-  uint4 odata4 = scan4Exclusive(idata4, s_Data, size, cta);
-
-  // Write back
-  d_Dst[pos] = odata4;
-}
-
-// Exclusive scan of top elements of bottom-level scans (4 * THREADBLOCK_SIZE)
-__global__ void scanExclusiveShared2(uint *d_Buf, uint *d_Dst, uint *d_Src,
-                                     uint N, uint arrayLength) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  __shared__ uint s_Data[2 * THREADBLOCK_SIZE];
-
-  // Skip loads and stores for inactive threads of last threadblock (pos >= N)
-  uint pos = blockIdx.x * blockDim.x + threadIdx.x;
-
-  // Load top elements
-  // Convert results of bottom-level scan back to inclusive
-  uint idata = 0;
-
-  if (pos < N)
-    idata = d_Dst[(4 * THREADBLOCK_SIZE) - 1 + (4 * THREADBLOCK_SIZE) * pos] +
-            d_Src[(4 * THREADBLOCK_SIZE) - 1 + (4 * THREADBLOCK_SIZE) * pos];
-
-  // Compute
-  uint odata = scan1Exclusive(idata, s_Data, arrayLength, cta);
-
-  // Avoid out-of-bound access
-  if (pos < N) {
-    d_Buf[pos] = odata;
-  }
-}
-
-// Final step of large-array scan: combine basic inclusive scan with exclusive
-// scan of top elements of input arrays
-__global__ void uniformUpdate(uint4 *d_Data, uint *d_Buffer) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  __shared__ uint buf;
-  uint pos = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (threadIdx.x == 0) {
-    buf = d_Buffer[blockIdx.x];
-  }
-
-  cg::sync(cta);
-
-  uint4 data4 = d_Data[pos];
-  data4.x += buf;
-  data4.y += buf;
-  data4.z += buf;
-  data4.w += buf;
-  d_Data[pos] = data4;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Interface function
-////////////////////////////////////////////////////////////////////////////////
-// Derived as 32768 (max power-of-two gridDim.x) * 4 * THREADBLOCK_SIZE
-// Due to scanExclusiveShared<<<>>>() 1D block addressing
-extern "C" const uint MAX_BATCH_ELEMENTS = 64 * 1048576;
-extern "C" const uint MIN_SHORT_ARRAY_SIZE = 4;
-extern "C" const uint MAX_SHORT_ARRAY_SIZE = 4 * THREADBLOCK_SIZE;
-extern "C" const uint MIN_LARGE_ARRAY_SIZE = 8 * THREADBLOCK_SIZE;
-extern "C" const uint MAX_LARGE_ARRAY_SIZE =
-    4 * THREADBLOCK_SIZE * THREADBLOCK_SIZE;
-
-// Internal exclusive scan buffer
-static uint *d_Buf;
-
-extern "C" void initScan(void) {
-  HIPCHECK(
-      hipMalloc((void **)&d_Buf,
-                 (MAX_BATCH_ELEMENTS / (4 * THREADBLOCK_SIZE)) * sizeof(uint)));
-}
-
-extern "C" void closeScan(void) { HIPCHECK(hipFree(d_Buf)); }
-
-static uint factorRadix2(uint &log2L, uint L) {
-  if (!L) {
-    log2L = 0;
-    return 0;
-  } else {
-    for (log2L = 0; (L & 1) == 0; L >>= 1, log2L++)
-      ;
-
-    return L;
-  }
-}
-
-static uint iDivUp(uint dividend, uint divisor) {
-  return ((dividend % divisor) == 0) ? (dividend / divisor)
-                                     : (dividend / divisor + 1);
-}
-
-extern "C" size_t scanExclusiveShort(uint *d_Dst, uint *d_Src, uint batchSize,
-                                     uint arrayLength) {
-  // Check power-of-two factorization
-  uint log2L;
-  uint factorizationRemainder = factorRadix2(log2L, arrayLength);
-  assert(factorizationRemainder == 1);
-
-  // Check supported size range
-  assert((arrayLength >= MIN_SHORT_ARRAY_SIZE) &&
-         (arrayLength <= MAX_SHORT_ARRAY_SIZE));
-
-  // Check total batch size limit
-  assert((batchSize * arrayLength) <= MAX_BATCH_ELEMENTS);
-
-  // Check all threadblocks to be fully packed with data
-  assert((batchSize * arrayLength) % (4 * THREADBLOCK_SIZE) == 0);
-
-  scanExclusiveShared<<<(batchSize * arrayLength) / (4 * THREADBLOCK_SIZE),
-                        THREADBLOCK_SIZE>>>((uint4 *)d_Dst, (uint4 *)d_Src,
-                                            arrayLength);
-  getLastCudaError("scanExclusiveShared() execution FAILED\n");
-
-  return THREADBLOCK_SIZE;
-}
-
-extern "C" size_t scanExclusiveLarge(uint *d_Dst, uint *d_Src, uint batchSize,
-                                     uint arrayLength) {
-  // Check power-of-two factorization
-  uint log2L;
-  uint factorizationRemainder = factorRadix2(log2L, arrayLength);
-  assert(factorizationRemainder == 1);
-
-  // Check supported size range
-  assert((arrayLength >= MIN_LARGE_ARRAY_SIZE) &&
-         (arrayLength <= MAX_LARGE_ARRAY_SIZE));
-
-  // Check total batch size limit
-  assert((batchSize * arrayLength) <= MAX_BATCH_ELEMENTS);
-
-  scanExclusiveShared<<<(batchSize * arrayLength) / (4 * THREADBLOCK_SIZE),
-                        THREADBLOCK_SIZE>>>((uint4 *)d_Dst, (uint4 *)d_Src,
-                                            4 * THREADBLOCK_SIZE);
-  getLastCudaError("scanExclusiveShared() execution FAILED\n");
-
-  // Not all threadblocks need to be packed with input data:
-  // inactive threads of highest threadblock just don't do global reads and
-  // writes
-  const uint blockCount2 = iDivUp(
-      (batchSize * arrayLength) / (4 * THREADBLOCK_SIZE), THREADBLOCK_SIZE);
-  scanExclusiveShared2<<<blockCount2, THREADBLOCK_SIZE>>>(
-      (uint *)d_Buf, (uint *)d_Dst, (uint *)d_Src,
-      (batchSize * arrayLength) / (4 * THREADBLOCK_SIZE),
-      arrayLength / (4 * THREADBLOCK_SIZE));
-  getLastCudaError("scanExclusiveShared2() execution FAILED\n");
-
-  uniformUpdate<<<(batchSize * arrayLength) / (4 * THREADBLOCK_SIZE),
-                  THREADBLOCK_SIZE>>>((uint4 *)d_Dst, (uint *)d_Buf);
-  getLastCudaError("uniformUpdate() execution FAILED\n");
-
-  return THREADBLOCK_SIZE;
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.out b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_common.h b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_common_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_gold.cpp b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_gold_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/scan/scan_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/README.md b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/common.cuh b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/common.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/common_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/common_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/data/ref_00.ppm b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/data/ref_00.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/data/ref_09.ppm b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/data/ref_09.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/data/test.ppm b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/data/test.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/kernels.cuh b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/kernels.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/kernels_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/kernels_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_00.ppm b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_00.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_01.ppm b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_01.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_02.ppm b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_02.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_03.ppm b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_03.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_04.ppm b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_04.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_05.ppm b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_05.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_06.ppm b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_06.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_07.ppm b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_07.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_08.ppm b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_08.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_09.ppm b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/level_09.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTree.cu b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTree.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTree.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTree.cu.hip
old mode 100644
new mode 100755
index e3cd2a4..27d51ae
--- a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTree.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTree.cu.hip
@@ -39,8 +39,6 @@
 // System includes.
 #include <stdlib.h>
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <string.h>
 #include <math.h>
 
@@ -73,8 +71,8 @@
 #include <thrust/device_free.h>
 
 // Sample framework includes.
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
+#include <helper_functions.h>
+#include <helper_cuda.h>
 
 // Project includes.
 #include "common.cuh"
@@ -267,13 +265,13 @@ class Pyramid
                     thrust::device_ptr<uint> superVerticesOffsets,
                     thrust::device_ptr<uint> verticesIDs)
                 {
-                    HIPCHECK(
+                    checkCudaErrors(
                         hipMemcpy(&(superNodesOffsets_[0]),
                                    superVerticesOffsets.get(),
                                    sizeof(uint) * superNodesOffsets_.size(),
                                    hipMemcpyDeviceToHost));
 
-                    HIPCHECK(
+                    checkCudaErrors(
                         hipMemcpy(&(nodes_[0]),
                                    verticesIDs.get(),
                                    sizeof(uint) * nodes_.size(),
@@ -517,15 +515,15 @@ class SegmentationTreeBuilder
             dOutputEdgesFlags_ = pools.uintEdges.get();
 
             // Copy graph to the device memory
-            HIPCHECK(hipMemcpy(dVertices_.get(),
+            checkCudaErrors(hipMemcpy(dVertices_.get(),
                                        &(graph.vertices[0]),
                                        sizeof(uint) * verticesCount_,
                                        hipMemcpyHostToDevice));
-            HIPCHECK(hipMemcpy(dEdges_.get(),
+            checkCudaErrors(hipMemcpy(dEdges_.get(),
                                        &(graph.edges[0]),
                                        sizeof(uint) * edgesCount_,
                                        hipMemcpyHostToDevice));
-            HIPCHECK(hipMemcpy(dWeights_.get(),
+            checkCudaErrors(hipMemcpy(dWeights_.get(),
                                        &(graph.weights[0]),
                                        sizeof(float) * edgesCount_,
                                        hipMemcpyHostToDevice));
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust.out b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/segmentationTreeThrust/segmentationTreeThrust_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/README.md b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_integral_image.cuh b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_integral_image.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_integral_image_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_integral_image_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan.cu b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan.cu.hip
old mode 100644
new mode 100755
index 0096536..583de66
--- a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan.cu.hip
@@ -35,15 +35,12 @@
 // scan operation and shuffle xor operations are used
 
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 
 #include <hip/hip_runtime.h>
 
 #include "helper_cuda_hipified.h"
 #include "helper_functions.h"
 #include "shfl_integral_image.cuh"
-
 // Scan using shfl - takes log2(n) steps
 // This function demonstrates basic use of the shuffle intrinsic, __shfl_up,
 // to perform a scan operation across a block.
@@ -215,9 +212,9 @@ bool shuffle_simple_test(int argc, char **argv) {
   cuda_device = findCudaDevice(argc, (const char **)argv);
 
   hipDeviceProp_t deviceProp;
-  HIPCHECK(hipGetDevice(&cuda_device));
+  checkCudaErrors(hipGetDevice(&cuda_device));
 
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, cuda_device));
+  checkCudaErrors(hipGetDeviceProperties(&deviceProp, cuda_device));
 
   printf("> Detected Compute SM %d.%d hardware with %d multi-processors\n",
          deviceProp.major, deviceProp.minor, deviceProp.multiProcessorCount);
@@ -229,9 +226,9 @@ bool shuffle_simple_test(int argc, char **argv) {
     exit(EXIT_WAIVED);
   }
 
-  HIPCHECK(hipHostMalloc(reinterpret_cast<void **>(&h_data),
+  checkCudaErrors(hipHostMalloc(reinterpret_cast<void **>(&h_data),
                                  sizeof(int) * n_elements));
-  HIPCHECK(hipHostMalloc(reinterpret_cast<void **>(&h_result),
+  checkCudaErrors(hipHostMalloc(reinterpret_cast<void **>(&h_result),
                                  sizeof(int) * n_elements));
 
   // initialize data:
@@ -261,32 +258,32 @@ bool shuffle_simple_test(int argc, char **argv) {
 
   // initialize a timer
   hipEvent_t start, stop;
-  HIPCHECK(hipEventCreate(&start));
-  HIPCHECK(hipEventCreate(&stop));
+  checkCudaErrors(hipEventCreate(&start));
+  checkCudaErrors(hipEventCreate(&stop));
   float et = 0;
   float inc = 0;
 
-  HIPCHECK(hipMalloc(reinterpret_cast<void **>(&d_data), sz));
-  HIPCHECK(
+  checkCudaErrors(hipMalloc(reinterpret_cast<void **>(&d_data), sz));
+  checkCudaErrors(
       hipMalloc(reinterpret_cast<void **>(&d_partial_sums), partial_sz));
-  HIPCHECK(hipMemset(d_partial_sums, 0, partial_sz));
+  checkCudaErrors(hipMemset(d_partial_sums, 0, partial_sz));
 
-  HIPCHECK(
+  checkCudaErrors(
       hipHostMalloc(reinterpret_cast<void **>(&h_partial_sums), partial_sz));
-  HIPCHECK(hipMemcpy(d_data, h_data, sz, hipMemcpyHostToDevice));
+  checkCudaErrors(hipMemcpy(d_data, h_data, sz, hipMemcpyHostToDevice));
 
-  HIPCHECK(hipEventRecord(start, 0));
+  checkCudaErrors(hipEventRecord(start, 0));
   shfl_scan_test<<<gridSize, blockSize, shmem_sz>>>(d_data, 32, d_partial_sums);
   shfl_scan_test<<<p_gridSize, p_blockSize, shmem_sz>>>(d_partial_sums, 32);
   uniform_add<<<gridSize - 1, blockSize>>>(d_data + blockSize, d_partial_sums,
                                            n_elements);
-  HIPCHECK(hipEventRecord(stop, 0));
-  HIPCHECK(hipEventSynchronize(stop));
-  HIPCHECK(hipEventElapsedTime(&inc, start, stop));
+  checkCudaErrors(hipEventRecord(stop, 0));
+  checkCudaErrors(hipEventSynchronize(stop));
+  checkCudaErrors(hipEventElapsedTime(&inc, start, stop));
   et += inc;
 
-  HIPCHECK(hipMemcpy(h_result, d_data, sz, hipMemcpyDeviceToHost));
-  HIPCHECK(hipMemcpy(h_partial_sums, d_partial_sums, partial_sz,
+  checkCudaErrors(hipMemcpy(h_result, d_data, sz, hipMemcpyDeviceToHost));
+  checkCudaErrors(hipMemcpy(h_partial_sums, d_partial_sums, partial_sz,
                              hipMemcpyDeviceToHost));
 
   printf("Test Sum: %d\n", h_partial_sums[n_partialSums - 1]);
@@ -296,11 +293,11 @@ bool shuffle_simple_test(int argc, char **argv) {
 
   bool bTestResult = CPUverify(h_data, h_result, n_elements);
 
-  HIPCHECK(hipHostFree(h_data));
-  HIPCHECK(hipHostFree(h_result));
-  HIPCHECK(hipHostFree(h_partial_sums));
-  HIPCHECK(hipFree(d_data));
-  HIPCHECK(hipFree(d_partial_sums));
+  checkCudaErrors(hipHostFree(h_data));
+  checkCudaErrors(hipHostFree(h_result));
+  checkCudaErrors(hipHostFree(h_partial_sums));
+  checkCudaErrors(hipFree(d_data));
+  checkCudaErrors(hipFree(d_partial_sums));
 
   return bTestResult;
 }
@@ -319,7 +316,7 @@ bool shuffle_integral_image_test() {
   printf("\nComputing Integral Image Test on size %d x %d synthetic data\n", w,
          h);
   printf("---------------------------------------------------\n");
-  HIPCHECK(hipHostMalloc(reinterpret_cast<void **>(&h_image), sz));
+  checkCudaErrors(hipHostMalloc(reinterpret_cast<void **>(&h_image), sz));
   // fill test "image" with synthetic 1's data
   memset(h_image, 0, sz);
 
@@ -329,11 +326,11 @@ bool shuffle_integral_image_test() {
   int gridSize = h;
 
   // Create a synthetic image for testing
-  HIPCHECK(hipMalloc(reinterpret_cast<void **>(&d_data), sz));
-  HIPCHECK(hipMalloc(reinterpret_cast<void **>(&d_integral_image),
+  checkCudaErrors(hipMalloc(reinterpret_cast<void **>(&d_data), sz));
+  checkCudaErrors(hipMalloc(reinterpret_cast<void **>(&d_integral_image),
                              n_elements * sizeof(int) * 4));
-  HIPCHECK(hipMemset(d_data, 1, sz));
-  HIPCHECK(hipMemset(d_integral_image, 0, sz));
+  checkCudaErrors(hipMemset(d_data, 1, sz));
+  checkCudaErrors(hipMemset(d_integral_image, 0, sz));
 
   hipEvent_t start, stop;
   hipEventCreate(&start);
@@ -347,12 +344,12 @@ bool shuffle_integral_image_test() {
       reinterpret_cast<uint4 *>(d_data),
       reinterpret_cast<uint4 *>(d_integral_image));
   hipEventRecord(stop);
-  HIPCHECK(hipEventSynchronize(stop));
-  HIPCHECK(hipEventElapsedTime(&et, start, stop));
+  checkCudaErrors(hipEventSynchronize(stop));
+  checkCudaErrors(hipEventElapsedTime(&et, start, stop));
   printf("Method: Fast  Time (GPU Timer): %f ms ", et);
 
   // verify the scan line results
-  HIPCHECK(
+  checkCudaErrors(
       hipMemcpy(h_image, d_integral_image, sz, hipMemcpyDeviceToHost));
   err = verifyDataRowSums(h_image, w, h);
   printf("Diff = %d\n", err);
@@ -365,21 +362,21 @@ bool shuffle_integral_image_test() {
   shfl_vertical_shfl<<<testGrid, blockSz>>>((unsigned int *)d_integral_image, w,
                                             h);
   hipEventRecord(stop);
-  HIPCHECK(hipEventSynchronize(stop));
-  HIPCHECK(hipEventElapsedTime(&et, start, stop));
+  checkCudaErrors(hipEventSynchronize(stop));
+  checkCudaErrors(hipEventElapsedTime(&et, start, stop));
   printf("Method: Vertical Scan  Time (GPU Timer): %f ms ", et);
 
   // Verify the column results
-  HIPCHECK(
+  checkCudaErrors(
       hipMemcpy(h_image, d_integral_image, sz, hipMemcpyDeviceToHost));
   printf("\n");
 
   int finalSum = h_image[w * h - 1];
   printf("CheckSum: %d, (expect %dx%d=%d)\n", finalSum, w, h, w * h);
 
-  HIPCHECK(hipFree(d_data));
-  HIPCHECK(hipFree(d_integral_image));
-  HIPCHECK(hipHostFree(h_image));
+  checkCudaErrors(hipFree(d_data));
+  checkCudaErrors(hipFree(d_integral_image));
+  checkCudaErrors(hipHostFree(h_image));
   // verify final sum: if the final value in the corner is the same as the size
   // of the buffer (all 1's) then the integral image was generated successfully
   return (finalSum == w * h) ? true : false;
@@ -397,9 +394,9 @@ int main(int argc, char *argv[]) {
   cuda_device = findCudaDevice(argc, (const char **)argv);
 
   hipDeviceProp_t deviceProp;
-  HIPCHECK(hipGetDevice(&cuda_device));
+  checkCudaErrors(hipGetDevice(&cuda_device));
 
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, cuda_device));
+  checkCudaErrors(hipGetDeviceProperties(&deviceProp, cuda_device));
 
   printf("> Detected Compute SM %d.%d hardware with %d multi-processors\n",
          deviceProp.major, deviceProp.minor, deviceProp.multiProcessorCount);
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/shfl_scan_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/util.h b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/util.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/util_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/shfl_scan/util_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/README.md b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/bitonicSort.cu b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/bitonicSort.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/bitonicSort.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/bitonicSort.cu.hip
old mode 100644
new mode 100755
index 3b5c473..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/bitonicSort.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/bitonicSort.cu.hip
@@ -1,277 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-//Based on http://www.iti.fh-flensburg.de/lang/algorithmen/sortieren/bitonic/bitonicen.htm
-
-#include <assert.h>
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-#include "helper_cuda_hipified.h"
-#include "sortingNetworks_common.h"
-#include "sortingNetworks_common.cuh"
-
-////////////////////////////////////////////////////////////////////////////////
-// Monolithic bitonic sort kernel for short arrays fitting into shared memory
-////////////////////////////////////////////////////////////////////////////////
-__global__ void bitonicSortShared(uint *d_DstKey, uint *d_DstVal,
-                                  uint *d_SrcKey, uint *d_SrcVal,
-                                  uint arrayLength, uint dir) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  // Shared memory storage for one or more short vectors
-  __shared__ uint s_key[SHARED_SIZE_LIMIT];
-  __shared__ uint s_val[SHARED_SIZE_LIMIT];
-
-  // Offset to the beginning of subbatch and load data
-  d_SrcKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_SrcVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_DstKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_DstVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  s_key[threadIdx.x + 0] = d_SrcKey[0];
-  s_val[threadIdx.x + 0] = d_SrcVal[0];
-  s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
-      d_SrcKey[(SHARED_SIZE_LIMIT / 2)];
-  s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
-      d_SrcVal[(SHARED_SIZE_LIMIT / 2)];
-
-  for (uint size = 2; size < arrayLength; size <<= 1) {
-    // Bitonic merge
-    uint ddd = dir ^ ((threadIdx.x & (size / 2)) != 0);
-
-    for (uint stride = size / 2; stride > 0; stride >>= 1) {
-      cg::sync(cta);
-      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
-      Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
-                 s_val[pos + stride], ddd);
-    }
-  }
-
-  // ddd == dir for the last bitonic merge step
-  {
-    for (uint stride = arrayLength / 2; stride > 0; stride >>= 1) {
-      cg::sync(cta);
-      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
-      Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
-                 s_val[pos + stride], dir);
-    }
-  }
-
-  cg::sync(cta);
-  d_DstKey[0] = s_key[threadIdx.x + 0];
-  d_DstVal[0] = s_val[threadIdx.x + 0];
-  d_DstKey[(SHARED_SIZE_LIMIT / 2)] =
-      s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
-  d_DstVal[(SHARED_SIZE_LIMIT / 2)] =
-      s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Bitonic sort kernel for large arrays (not fitting into shared memory)
-////////////////////////////////////////////////////////////////////////////////
-// Bottom-level bitonic sort
-// Almost the same as bitonicSortShared with the exception of
-// even / odd subarrays being sorted in opposite directions
-// Bitonic merge accepts both
-// Ascending | descending or descending | ascending sorted pairs
-__global__ void bitonicSortShared1(uint *d_DstKey, uint *d_DstVal,
-                                   uint *d_SrcKey, uint *d_SrcVal) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  // Shared memory storage for current subarray
-  __shared__ uint s_key[SHARED_SIZE_LIMIT];
-  __shared__ uint s_val[SHARED_SIZE_LIMIT];
-
-  // Offset to the beginning of subarray and load data
-  d_SrcKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_SrcVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_DstKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_DstVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  s_key[threadIdx.x + 0] = d_SrcKey[0];
-  s_val[threadIdx.x + 0] = d_SrcVal[0];
-  s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
-      d_SrcKey[(SHARED_SIZE_LIMIT / 2)];
-  s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
-      d_SrcVal[(SHARED_SIZE_LIMIT / 2)];
-
-  for (uint size = 2; size < SHARED_SIZE_LIMIT; size <<= 1) {
-    // Bitonic merge
-    uint ddd = (threadIdx.x & (size / 2)) != 0;
-
-    for (uint stride = size / 2; stride > 0; stride >>= 1) {
-      cg::sync(cta);
-      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
-      Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
-                 s_val[pos + stride], ddd);
-    }
-  }
-
-  // Odd / even arrays of SHARED_SIZE_LIMIT elements
-  // sorted in opposite directions
-  uint ddd = blockIdx.x & 1;
-  {
-    for (uint stride = SHARED_SIZE_LIMIT / 2; stride > 0; stride >>= 1) {
-      cg::sync(cta);
-      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
-      Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
-                 s_val[pos + stride], ddd);
-    }
-  }
-
-  cg::sync(cta);
-  d_DstKey[0] = s_key[threadIdx.x + 0];
-  d_DstVal[0] = s_val[threadIdx.x + 0];
-  d_DstKey[(SHARED_SIZE_LIMIT / 2)] =
-      s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
-  d_DstVal[(SHARED_SIZE_LIMIT / 2)] =
-      s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
-}
-
-// Bitonic merge iteration for stride >= SHARED_SIZE_LIMIT
-__global__ void bitonicMergeGlobal(uint *d_DstKey, uint *d_DstVal,
-                                   uint *d_SrcKey, uint *d_SrcVal,
-                                   uint arrayLength, uint size, uint stride,
-                                   uint dir) {
-  uint global_comparatorI = blockIdx.x * blockDim.x + threadIdx.x;
-  uint comparatorI = global_comparatorI & (arrayLength / 2 - 1);
-
-  // Bitonic merge
-  uint ddd = dir ^ ((comparatorI & (size / 2)) != 0);
-  uint pos = 2 * global_comparatorI - (global_comparatorI & (stride - 1));
-
-  uint keyA = d_SrcKey[pos + 0];
-  uint valA = d_SrcVal[pos + 0];
-  uint keyB = d_SrcKey[pos + stride];
-  uint valB = d_SrcVal[pos + stride];
-
-  Comparator(keyA, valA, keyB, valB, ddd);
-
-  d_DstKey[pos + 0] = keyA;
-  d_DstVal[pos + 0] = valA;
-  d_DstKey[pos + stride] = keyB;
-  d_DstVal[pos + stride] = valB;
-}
-
-// Combined bitonic merge steps for
-// size > SHARED_SIZE_LIMIT and stride = [1 .. SHARED_SIZE_LIMIT / 2]
-__global__ void bitonicMergeShared(uint *d_DstKey, uint *d_DstVal,
-                                   uint *d_SrcKey, uint *d_SrcVal,
-                                   uint arrayLength, uint size, uint dir) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  // Shared memory storage for current subarray
-  __shared__ uint s_key[SHARED_SIZE_LIMIT];
-  __shared__ uint s_val[SHARED_SIZE_LIMIT];
-
-  d_SrcKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_SrcVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_DstKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_DstVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  s_key[threadIdx.x + 0] = d_SrcKey[0];
-  s_val[threadIdx.x + 0] = d_SrcVal[0];
-  s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
-      d_SrcKey[(SHARED_SIZE_LIMIT / 2)];
-  s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
-      d_SrcVal[(SHARED_SIZE_LIMIT / 2)];
-
-  // Bitonic merge
-  uint comparatorI =
-      UMAD(blockIdx.x, blockDim.x, threadIdx.x) & ((arrayLength / 2) - 1);
-  uint ddd = dir ^ ((comparatorI & (size / 2)) != 0);
-
-  for (uint stride = SHARED_SIZE_LIMIT / 2; stride > 0; stride >>= 1) {
-    cg::sync(cta);
-    uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
-    Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
-               s_val[pos + stride], ddd);
-  }
-
-  cg::sync(cta);
-  d_DstKey[0] = s_key[threadIdx.x + 0];
-  d_DstVal[0] = s_val[threadIdx.x + 0];
-  d_DstKey[(SHARED_SIZE_LIMIT / 2)] =
-      s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
-  d_DstVal[(SHARED_SIZE_LIMIT / 2)] =
-      s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Interface function
-////////////////////////////////////////////////////////////////////////////////
-// Helper function (also used by odd-even merge sort)
-extern "C" uint factorRadix2(uint *log2L, uint L) {
-  if (!L) {
-    *log2L = 0;
-    return 0;
-  } else {
-    for (*log2L = 0; (L & 1) == 0; L >>= 1, *log2L++)
-      ;
-
-    return L;
-  }
-}
-
-extern "C" uint bitonicSort(uint *d_DstKey, uint *d_DstVal, uint *d_SrcKey,
-                            uint *d_SrcVal, uint batchSize, uint arrayLength,
-                            uint dir) {
-  // Nothing to sort
-  if (arrayLength < 2) return 0;
-
-  // Only power-of-two array lengths are supported by this implementation
-  uint log2L;
-  uint factorizationRemainder = factorRadix2(&log2L, arrayLength);
-  assert(factorizationRemainder == 1);
-
-  dir = (dir != 0);
-
-  uint blockCount = batchSize * arrayLength / SHARED_SIZE_LIMIT;
-  uint threadCount = SHARED_SIZE_LIMIT / 2;
-
-  if (arrayLength <= SHARED_SIZE_LIMIT) {
-    assert((batchSize * arrayLength) % SHARED_SIZE_LIMIT == 0);
-    bitonicSortShared<<<blockCount, threadCount>>>(d_DstKey, d_DstVal, d_SrcKey,
-                                                   d_SrcVal, arrayLength, dir);
-  } else {
-    bitonicSortShared1<<<blockCount, threadCount>>>(d_DstKey, d_DstVal,
-                                                    d_SrcKey, d_SrcVal);
-
-    for (uint size = 2 * SHARED_SIZE_LIMIT; size <= arrayLength; size <<= 1)
-      for (unsigned stride = size / 2; stride > 0; stride >>= 1)
-        if (stride >= SHARED_SIZE_LIMIT) {
-          bitonicMergeGlobal<<<(batchSize * arrayLength) / 512, 256>>>(
-              d_DstKey, d_DstVal, d_DstKey, d_DstVal, arrayLength, size, stride,
-              dir);
-        } else {
-          bitonicMergeShared<<<blockCount, threadCount>>>(
-              d_DstKey, d_DstVal, d_DstKey, d_DstVal, arrayLength, size, dir);
-          break;
-        }
-  }
-
-  return threadCount;
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/main.cpp b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/main_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/oddEvenMergeSort.cu b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/oddEvenMergeSort.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/oddEvenMergeSort.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/oddEvenMergeSort.cu.hip
old mode 100644
new mode 100755
index 2288c60..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/oddEvenMergeSort.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/oddEvenMergeSort.cu.hip
@@ -1,181 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-//Based on http://www.iti.fh-flensburg.de/lang/algorithmen/sortieren/networks/oemen.htm
-
-
-#include <assert.h>
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-
-#include "helper_cuda_hipified.h"
-#include "sortingNetworks_common.h"
-#include "sortingNetworks_common.cuh"
-
-////////////////////////////////////////////////////////////////////////////////
-// Monolithic Bacther's sort kernel for short arrays fitting into shared memory
-////////////////////////////////////////////////////////////////////////////////
-__global__ void oddEvenMergeSortShared(uint *d_DstKey, uint *d_DstVal,
-                                       uint *d_SrcKey, uint *d_SrcVal,
-                                       uint arrayLength, uint dir) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  // Shared memory storage for one or more small vectors
-  __shared__ uint s_key[SHARED_SIZE_LIMIT];
-  __shared__ uint s_val[SHARED_SIZE_LIMIT];
-
-  // Offset to the beginning of subbatch and load data
-  d_SrcKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_SrcVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_DstKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  d_DstVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;
-  s_key[threadIdx.x + 0] = d_SrcKey[0];
-  s_val[threadIdx.x + 0] = d_SrcVal[0];
-  s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
-      d_SrcKey[(SHARED_SIZE_LIMIT / 2)];
-  s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] =
-      d_SrcVal[(SHARED_SIZE_LIMIT / 2)];
-
-  for (uint size = 2; size <= arrayLength; size <<= 1) {
-    uint stride = size / 2;
-    uint offset = threadIdx.x & (stride - 1);
-
-    {
-      cg::sync(cta);
-      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
-      Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride],
-                 s_val[pos + stride], dir);
-      stride >>= 1;
-    }
-
-    for (; stride > 0; stride >>= 1) {
-      cg::sync(cta);
-      uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));
-
-      if (offset >= stride)
-        Comparator(s_key[pos - stride], s_val[pos - stride], s_key[pos + 0],
-                   s_val[pos + 0], dir);
-    }
-  }
-
-  cg::sync(cta);
-  d_DstKey[0] = s_key[threadIdx.x + 0];
-  d_DstVal[0] = s_val[threadIdx.x + 0];
-  d_DstKey[(SHARED_SIZE_LIMIT / 2)] =
-      s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
-  d_DstVal[(SHARED_SIZE_LIMIT / 2)] =
-      s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Odd-even merge sort iteration kernel
-// for large arrays (not fitting into shared memory)
-////////////////////////////////////////////////////////////////////////////////
-__global__ void oddEvenMergeGlobal(uint *d_DstKey, uint *d_DstVal,
-                                   uint *d_SrcKey, uint *d_SrcVal,
-                                   uint arrayLength, uint size, uint stride,
-                                   uint dir) {
-  uint global_comparatorI = blockIdx.x * blockDim.x + threadIdx.x;
-
-  // Odd-even merge
-  uint pos = 2 * global_comparatorI - (global_comparatorI & (stride - 1));
-
-  if (stride < size / 2) {
-    uint offset = global_comparatorI & ((size / 2) - 1);
-
-    if (offset >= stride) {
-      uint keyA = d_SrcKey[pos - stride];
-      uint valA = d_SrcVal[pos - stride];
-      uint keyB = d_SrcKey[pos + 0];
-      uint valB = d_SrcVal[pos + 0];
-
-      Comparator(keyA, valA, keyB, valB, dir);
-
-      d_DstKey[pos - stride] = keyA;
-      d_DstVal[pos - stride] = valA;
-      d_DstKey[pos + 0] = keyB;
-      d_DstVal[pos + 0] = valB;
-    }
-  } else {
-    uint keyA = d_SrcKey[pos + 0];
-    uint valA = d_SrcVal[pos + 0];
-    uint keyB = d_SrcKey[pos + stride];
-    uint valB = d_SrcVal[pos + stride];
-
-    Comparator(keyA, valA, keyB, valB, dir);
-
-    d_DstKey[pos + 0] = keyA;
-    d_DstVal[pos + 0] = valA;
-    d_DstKey[pos + stride] = keyB;
-    d_DstVal[pos + stride] = valB;
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Interface function
-////////////////////////////////////////////////////////////////////////////////
-// Helper function
-extern "C" uint factorRadix2(uint *log2L, uint L);
-
-extern "C" void oddEvenMergeSort(uint *d_DstKey, uint *d_DstVal, uint *d_SrcKey,
-                                 uint *d_SrcVal, uint batchSize,
-                                 uint arrayLength, uint dir) {
-  // Nothing to sort
-  if (arrayLength < 2) return;
-
-  // Only power-of-two array lengths are supported by this implementation
-  uint log2L;
-  uint factorizationRemainder = factorRadix2(&log2L, arrayLength);
-  assert(factorizationRemainder == 1);
-
-  dir = (dir != 0);
-
-  uint blockCount = (batchSize * arrayLength) / SHARED_SIZE_LIMIT;
-  uint threadCount = SHARED_SIZE_LIMIT / 2;
-
-  if (arrayLength <= SHARED_SIZE_LIMIT) {
-    assert(SHARED_SIZE_LIMIT % arrayLength == 0);
-    oddEvenMergeSortShared<<<blockCount, threadCount>>>(
-        d_DstKey, d_DstVal, d_SrcKey, d_SrcVal, arrayLength, dir);
-  } else {
-    oddEvenMergeSortShared<<<blockCount, threadCount>>>(
-        d_DstKey, d_DstVal, d_SrcKey, d_SrcVal, SHARED_SIZE_LIMIT, dir);
-
-    for (uint size = 2 * SHARED_SIZE_LIMIT; size <= arrayLength; size <<= 1)
-      for (unsigned stride = size / 2; stride > 0; stride >>= 1) {
-        // Unlike with bitonic sort, combining bitonic merge steps with
-        // stride = [SHARED_SIZE_LIMIT / 2 .. 1] seems to be impossible as there
-        // are dependencies between data elements crossing the SHARED_SIZE_LIMIT
-        // borders
-        oddEvenMergeGlobal<<<(batchSize * arrayLength) / 512, 256>>>(
-            d_DstKey, d_DstVal, d_DstKey, d_DstVal, arrayLength, size, stride,
-            dir);
-      }
-  }
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks.out b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_common.cuh b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_common.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_common.h b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_common_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_common_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_common_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_validate.cpp b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_validate.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_validate_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_validate_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/sortingNetworks/sortingNetworks_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/README.md b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation.cu b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation.cu.hip
old mode 100644
new mode 100755
index 1d5aaa8..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation.cu.hip
@@ -1,246 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This sample demonstrates stream ordered memory allocation on a GPU using
- * hipMallocAsync and cudaMemPool family of APIs.
- *
- * basicStreamOrderedAllocation(): demonstrates stream ordered allocation using
- * hipMallocAsync/hipFreeAsync APIs with default settings.
- *
- * streamOrderedAllocationPostSync(): demonstrates if there's a synchronization
- * in between allocations, then setting the release threshold on the pool will
- * make sure the synchronize will not free memory back to the OS.
- */
-
-// System includes
-#include <assert.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <climits>
-
-// CUDA runtime
-#include <hip/hip_runtime.h>
-
-// helper functions and utilities to work with CUDA
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"
-
-#define MAX_ITER 20
-
-/* Add two vectors on the GPU */
-__global__ void vectorAddGPU(const float *a, const float *b, float *c, int N) {
-  int idx = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (idx < N) {
-    c[idx] = a[idx] + b[idx];
-  }
-}
-
-int basicStreamOrderedAllocation(const int dev, const int nelem, const float *a,
-                                 const float *b, float *c) {
-  float *d_a, *d_b, *d_c;  // Device buffers
-  float errorNorm, refNorm, ref, diff;
-  size_t bytes = nelem * sizeof(float);
-
-  hipStream_t stream;
-  printf("Starting basicStreamOrderedAllocation()\n");
-  HIPCHECK(hipSetDevice(dev));
-  HIPCHECK(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
-
-  HIPCHECK(hipMallocAsync(&d_a, bytes, stream));
-  HIPCHECK(hipMallocAsync(&d_b, bytes, stream));
-  HIPCHECK(hipMallocAsync(&d_c, bytes, stream));
-  HIPCHECK(
-      hipMemcpyAsync(d_a, a, bytes, hipMemcpyHostToDevice, stream));
-  HIPCHECK(
-      hipMemcpyAsync(d_b, b, bytes, hipMemcpyHostToDevice, stream));
-
-  dim3 block(256);
-  dim3 grid((unsigned int)ceil(nelem / (float)block.x));
-  vectorAddGPU<<<grid, block, 0, stream>>>(d_a, d_b, d_c, nelem);
-
-  HIPCHECK(hipFreeAsync(d_a, stream));
-  HIPCHECK(hipFreeAsync(d_b, stream));
-  HIPCHECK(
-      hipMemcpyAsync(c, d_c, bytes, hipMemcpyDeviceToHost, stream));
-  HIPCHECK(hipFreeAsync(d_c, stream));
-  HIPCHECK(hipStreamSynchronize(stream));
-
-  /* Compare the results */
-  printf("> Checking the results from vectorAddGPU() ...\n");
-  errorNorm = 0.f;
-  refNorm = 0.f;
-
-  for (int n = 0; n < nelem; n++) {
-    ref = a[n] + b[n];
-    diff = c[n] - ref;
-    errorNorm += diff * diff;
-    refNorm += ref * ref;
-  }
-
-  errorNorm = (float)sqrt((double)errorNorm);
-  refNorm = (float)sqrt((double)refNorm);
-  if (errorNorm / refNorm < 1.e-6f)
-    printf("basicStreamOrderedAllocation PASSED\n");
-
-  HIPCHECK(hipStreamDestroy(stream));
-
-  return errorNorm / refNorm < 1.e-6f ? EXIT_SUCCESS : EXIT_FAILURE;
-}
-
-// streamOrderedAllocationPostSync(): demonstrates If the application wants the
-// memory to persist in the pool beyond synchronization, then it sets the
-// release threshold on the pool. This way, when the application reaches the
-// "steady state", it is no longer allocating/freeing memory from the OS.
-int streamOrderedAllocationPostSync(const int dev, const int nelem,
-                                    const float *a, const float *b, float *c) {
-  float *d_a, *d_b, *d_c;  // Device buffers
-  float errorNorm, refNorm, ref, diff;
-  size_t bytes = nelem * sizeof(float);
-
-  hipStream_t stream;
-  hipMemPool_t memPool;
-  hipEvent_t start, end;
-  printf("Starting streamOrderedAllocationPostSync()\n");
-  HIPCHECK(hipSetDevice(dev));
-  HIPCHECK(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
-  HIPCHECK(hipEventCreate(&start));
-  HIPCHECK(hipEventCreate(&end));
-
-  HIPCHECK(hipDeviceGetDefaultMemPool(&memPool, dev));
-  uint64_t thresholdVal = ULONG_MAX;
-  // set high release threshold on the default pool so that hipFreeAsync will
-  // not actually release memory to the system. By default, the release
-  // threshold for a memory pool is set to zero. This implies that the CUDA
-  // driver is allowed to release a memory chunk back to the system as long as
-  // it does not contain any active suballocations.
-  HIPCHECK(hipMemPoolSetAttribute(
-      memPool, hipMemPoolAttrReleaseThreshold, (void *)&thresholdVal));
-
-  // Record the start event
-  HIPCHECK(hipEventRecord(start, stream));
-  for (int i = 0; i < MAX_ITER; i++) {
-    HIPCHECK(hipMallocAsync(&d_a, bytes, stream));
-    HIPCHECK(hipMallocAsync(&d_b, bytes, stream));
-    HIPCHECK(hipMallocAsync(&d_c, bytes, stream));
-    HIPCHECK(
-        hipMemcpyAsync(d_a, a, bytes, hipMemcpyHostToDevice, stream));
-    HIPCHECK(
-        hipMemcpyAsync(d_b, b, bytes, hipMemcpyHostToDevice, stream));
-
-    dim3 block(256);
-    dim3 grid((unsigned int)ceil(nelem / (float)block.x));
-    vectorAddGPU<<<grid, block, 0, stream>>>(d_a, d_b, d_c, nelem);
-
-    HIPCHECK(hipFreeAsync(d_a, stream));
-    HIPCHECK(hipFreeAsync(d_b, stream));
-    HIPCHECK(
-        hipMemcpyAsync(c, d_c, bytes, hipMemcpyDeviceToHost, stream));
-    HIPCHECK(hipFreeAsync(d_c, stream));
-    HIPCHECK(hipStreamSynchronize(stream));
-  }
-  HIPCHECK(hipEventRecord(end, stream));
-  // Wait for the end event to complete
-  HIPCHECK(hipEventSynchronize(end));
-
-  float msecTotal = 0.0f;
-  HIPCHECK(hipEventElapsedTime(&msecTotal, start, end));
-  printf("Total elapsed time = %f ms over %d iterations\n", msecTotal,
-         MAX_ITER);
-
-  /* Compare the results */
-  printf("> Checking the results from vectorAddGPU() ...\n");
-  errorNorm = 0.f;
-  refNorm = 0.f;
-
-  for (int n = 0; n < nelem; n++) {
-    ref = a[n] + b[n];
-    diff = c[n] - ref;
-    errorNorm += diff * diff;
-    refNorm += ref * ref;
-  }
-
-  errorNorm = (float)sqrt((double)errorNorm);
-  refNorm = (float)sqrt((double)refNorm);
-  if (errorNorm / refNorm < 1.e-6f)
-    printf("streamOrderedAllocationPostSync PASSED\n");
-
-  HIPCHECK(hipStreamDestroy(stream));
-
-  return errorNorm / refNorm < 1.e-6f ? EXIT_SUCCESS : EXIT_FAILURE;
-}
-
-int main(int argc, char **argv) {
-  int nelem;
-  int dev = 0;  // use default device 0
-  size_t bytes;
-  float *a, *b, *c;  // Host
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "help")) {
-    printf("Usage:  streamOrderedAllocation [OPTION]\n\n");
-    printf("Options:\n");
-    printf("  --device=[device #]  Specify the device to be used\n");
-    return EXIT_SUCCESS;
-  }
-
-  dev = findCudaDevice(argc, (const char **)argv);
-
-  int isMemPoolSupported = 0;
-  HIPCHECK(hipDeviceGetAttribute(&isMemPoolSupported,
-                                         hipDeviceAttributeMemoryPoolsSupported, dev));
-  if (!isMemPoolSupported) {
-    printf("Waiving execution as device does not support Memory Pools\n");
-    exit(EXIT_WAIVED);
-  }
-
-  // Allocate CPU memory.
-  nelem = 1048576;
-  bytes = nelem * sizeof(float);
-
-  a = (float *)malloc(bytes);
-  b = (float *)malloc(bytes);
-  c = (float *)malloc(bytes);
-  /* Initialize the vectors. */
-  for (int n = 0; n < nelem; n++) {
-    a[n] = rand() / (float)RAND_MAX;
-    b[n] = rand() / (float)RAND_MAX;
-  }
-
-  int ret1 = basicStreamOrderedAllocation(dev, nelem, a, b, c);
-  int ret2 = streamOrderedAllocationPostSync(dev, nelem, a, b, c);
-
-  /* Memory clean up */
-  free(a);
-  free(b);
-  free(c);
-
-  return ((ret1 == EXIT_SUCCESS && ret2 == EXIT_SUCCESS) ? EXIT_SUCCESS
-                                                         : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation.out b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocation/streamOrderedAllocation_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/README.md b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/streamOrderedAllocationIPC.cu b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/streamOrderedAllocationIPC.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/streamOrderedAllocationIPC.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/streamOrderedAllocationIPC.cu.hip
old mode 100644
new mode 100755
index c20f1d2..2cd9b07
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/streamOrderedAllocationIPC.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationIPC/streamOrderedAllocationIPC.cu.hip
@@ -32,16 +32,14 @@
  */
 
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <stdlib.h>
 #include <vector>
 #include <hip/hip_runtime.h>
 #define CUDA_DRIVER_API 1
-#include "helper_cuda.h"
+#include "helper_cuda_hipified.h"
 #include "helper_cuda_drvapi.h"
 #include "helper_multiprocess.h"
-
+#include "HIPCHECK.h"
 static const char shmName[] = "streamOrderedAllocationIPCshm";
 static const char ipcName[] = "streamOrderedAllocationIPC_pipe";
 // For direct NVLINK and PCI-E peers, at max 8 simultaneous peers are allowed
@@ -441,12 +439,3 @@ int main(int argc, char **argv) {
   return EXIT_SUCCESS;
 #endif
 }
-d(_WIN32) || defined(WIN64) || defined(_WIN64)
-  printf("Not supported on ARM\n");
-  return EXIT_WAIVED;
-#else
-  if (argc == 1) {
-    parentProcess(argv[0]);
-  } else {
-    childProcess(atoi(argv[1]));
-  }
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/README.md b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.cu b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.cu.hip
old mode 100644
new mode 100755
index 7e94df3..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.cu.hip
@@ -1,255 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This sample demonstrates peer-to-peer access of stream ordered memory
- * allocated with hipMallocAsync and cudaMemPool family of APIs through simple
- * kernel which does peer-to-peer to access & scales vector elements.
- */
-
-// System includes
-#include <assert.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <iostream>
-#include <map>
-#include <set>
-#include <utility>
-
-// CUDA runtime
-#include <hip/hip_runtime.h>
-
-// helper functions and utilities to work with CUDA
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"
-
-// Simple kernel to demonstrate copying hipMallocAsync memory via P2P to peer
-// device
-__global__ void copyP2PAndScale(const int *src, int *dst, int N) {
-  int idx = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (idx < N) {
-    // scale & store src vector.
-    dst[idx] = 2 * src[idx];
-  }
-}
-
-// Map of device version to device number
-std::multimap<std::pair<int, int>, int> getIdenticalGPUs() {
-  int numGpus = 0;
-  HIPCHECK(hipGetDeviceCount(&numGpus));
-
-  std::multimap<std::pair<int, int>, int> identicalGpus;
-
-  for (int i = 0; i < numGpus; i++) {
-    int isMemPoolSupported = 0;
-    HIPCHECK(hipDeviceGetAttribute(&isMemPoolSupported,
-                                           hipDeviceAttributeMemoryPoolsSupported, i));
-
-    // Filter unsupported devices
-    if (isMemPoolSupported) {
-      int major = 0, minor = 0;
-      HIPCHECK(
-          hipDeviceGetAttribute(&major, hipDeviceAttributeComputeCapabilityMajor, i));
-      HIPCHECK(
-          hipDeviceGetAttribute(&minor, hipDeviceAttributeComputeCapabilityMinor, i));
-      identicalGpus.emplace(std::make_pair(major, minor), i);
-    }
-  }
-
-  return identicalGpus;
-}
-
-std::pair<int, int> getP2PCapableGpuPair() {
-  constexpr size_t kNumGpusRequired = 2;
-
-  auto gpusByArch = getIdenticalGPUs();
-
-  auto it = gpusByArch.begin();
-  auto end = gpusByArch.end();
-
-  auto bestFit = std::make_pair(it, it);
-  // use std::distance to find the largest number of GPUs amongst architectures
-  auto distance = [](decltype(bestFit) p) {
-    return std::distance(p.first, p.second);
-  };
-
-  // Read each unique key/pair element in order
-  for (; it != end; it = gpusByArch.upper_bound(it->first)) {
-    // first and second are iterators bounded within the architecture group
-    auto testFit = gpusByArch.equal_range(it->first);
-    // Always use devices with highest architecture version or whichever has the
-    // most devices available
-    if (distance(bestFit) <= distance(testFit)) bestFit = testFit;
-  }
-
-  if (distance(bestFit) < kNumGpusRequired) {
-    printf(
-        "No Two or more GPUs with same architecture capable of cuda Memory "
-        "Pools found."
-        "\nWaiving the sample\n");
-    exit(EXIT_WAIVED);
-  }
-
-  std::set<int> bestFitDeviceIds;
-
-  // check & select peer-to-peer access capable GPU devices.
-  int devIds[2];
-  for (auto itr = bestFit.first; itr != bestFit.second; itr++) {
-    int deviceId = itr->second;
-    HIPCHECK(hipSetDevice(deviceId));
-
-    std::for_each(itr, bestFit.second, [&deviceId, &bestFitDeviceIds,
-                                        &kNumGpusRequired](
-                                           decltype(*itr) mapPair) {
-      if (deviceId != mapPair.second) {
-        int access = 0;
-        HIPCHECK(
-            hipDeviceCanAccessPeer(&access, deviceId, mapPair.second));
-        printf("Device=%d %s Access Peer Device=%d\n", deviceId,
-               access ? "CAN" : "CANNOT", mapPair.second);
-        if (access && bestFitDeviceIds.size() < kNumGpusRequired) {
-          bestFitDeviceIds.emplace(deviceId);
-          bestFitDeviceIds.emplace(mapPair.second);
-        } else {
-          printf("Ignoring device %i (max devices exceeded)\n", mapPair.second);
-        }
-      }
-    });
-
-    if (bestFitDeviceIds.size() >= kNumGpusRequired) {
-      printf("Selected p2p capable devices - ");
-      int i = 0;
-      for (auto devicesItr = bestFitDeviceIds.begin();
-           devicesItr != bestFitDeviceIds.end(); devicesItr++) {
-        devIds[i++] = *devicesItr;
-        printf("deviceId = %d  ", *devicesItr);
-      }
-      printf("\n");
-      break;
-    }
-  }
-
-  // if bestFitDeviceIds.size() == 0 it means the GPUs in system are not p2p
-  // capable, hence we add it without p2p capability check.
-  if (!bestFitDeviceIds.size()) {
-    printf("No Two or more Devices p2p capable found.. exiting..\n");
-    exit(EXIT_WAIVED);
-  }
-
-  auto p2pGpuPair = std::make_pair(devIds[0], devIds[1]);
-
-  return p2pGpuPair;
-}
-
-int memPoolP2PCopy() {
-  int *dev0_srcVec, *dev1_dstVec;  // Device buffers
-  hipStream_t stream1, stream2;
-  hipMemPool_t memPool;
-  hipEvent_t waitOnStream1;
-
-  // Allocate CPU memory.
-  size_t nelem = 1048576;
-  size_t bytes = nelem * sizeof(int);
-
-  int *a = (int *)malloc(bytes);
-  int *output = (int *)malloc(bytes);
-
-  /* Initialize the vectors. */
-  for (int n = 0; n < nelem; n++) {
-    a[n] = rand() / (int)RAND_MAX;
-  }
-
-  auto p2pDevices = getP2PCapableGpuPair();
-  printf("selected devices = %d & %d\n", p2pDevices.first, p2pDevices.second);
-  HIPCHECK(hipSetDevice(p2pDevices.first));
-  HIPCHECK(hipEventCreate(&waitOnStream1));
-
-  HIPCHECK(hipStreamCreateWithFlags(&stream1, hipStreamNonBlocking));
-
-  // Get the default mempool for device p2pDevices.first from the pair
-  HIPCHECK(hipDeviceGetDefaultMemPool(&memPool, p2pDevices.first));
-
-  // Allocate memory in a stream from the pool set above.
-  HIPCHECK(hipMallocAsync(&dev0_srcVec, bytes, stream1));
-
-  HIPCHECK(
-      hipMemcpyAsync(dev0_srcVec, a, bytes, hipMemcpyHostToDevice, stream1));
-  HIPCHECK(hipEventRecord(waitOnStream1, stream1));
-
-  HIPCHECK(hipSetDevice(p2pDevices.second));
-  HIPCHECK(hipStreamCreateWithFlags(&stream2, hipStreamNonBlocking));
-
-  // Allocate memory in p2pDevices.second device
-  HIPCHECK(hipMallocAsync(&dev1_dstVec, bytes, stream2));
-
-  // Setup peer mappings for p2pDevices.second device
-  hipMemAccessDesc desc;
-  memset(&desc, 0, sizeof(hipMemAccessDesc));
-  desc.location.type = hipMemLocationTypeDevice;
-  desc.location.id = p2pDevices.second;
-  desc.flags = hipMemAccessFlagsProtReadWrite;
-  HIPCHECK(hipMemPoolSetAccess(memPool, &desc, 1));
-
-  printf("> copyP2PAndScale kernel running ...\n");
-  dim3 block(256);
-  dim3 grid((unsigned int)ceil(nelem / (int)block.x));
-  HIPCHECK(hipStreamWaitEvent(stream2, waitOnStream1,3));
-  copyP2PAndScale<<<grid, block, 0, stream2>>>(dev0_srcVec, dev1_dstVec, nelem);
-
-  HIPCHECK(hipMemcpyAsync(output, dev1_dstVec, bytes,
-                                  hipMemcpyDeviceToHost, stream2));
-  HIPCHECK(hipFreeAsync(dev0_srcVec, stream2));
-  HIPCHECK(hipFreeAsync(dev1_dstVec, stream2));
-  HIPCHECK(hipStreamSynchronize(stream2));
-
-  /* Compare the results */
-  printf("> Checking the results from copyP2PAndScale() ...\n");
-
-  for (int n = 0; n < nelem; n++) {
-    if ((2 * a[n]) != output[n]) {
-      printf("mismatch i = %d expected = %d val = %d\n", n, 2 * a[n],
-             output[n]);
-      return EXIT_FAILURE;
-    }
-  }
-
-  free(a);
-  free(output);
-  HIPCHECK(hipStreamDestroy(stream1));
-  HIPCHECK(hipStreamDestroy(stream2));
-  printf("PASSED\n");
-
-  return EXIT_SUCCESS;
-}
-
-int main(int argc, char **argv) {
-  int ret = memPoolP2PCopy();
-  return ret;
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.out b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/streamOrderedAllocationP2P/streamOrderedAllocationP2P_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/NsightEclipse.xml b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/README.md b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.cu b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.cu.hip
old mode 100644
new mode 100755
index e841cba..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.cu.hip
@@ -1,466 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
-  Parallel reduction
-
-  This sample shows how to perform a reduction operation on an array of values
-  to produce a single value in a single kernel (as opposed to two or more
-  kernel calls as shown in the "reduction" CUDA Sample).  Single-pass
-  reduction requires global atomic instructions (Compute Capability 1.1 or
-  later) and the __threadfence() intrinsic (CUDA 2.2 or later).
-
-  Reductions are a very common computation in parallel algorithms.  Any time
-  an array of values needs to be reduced to a single value using a binary
-  associative operator, a reduction can be used.  Example applications include
-  statistics computations such as mean and standard deviation, and image
-  processing applications such as finding the total luminance of an
-  image.
-
-  This code performs sum reductions, but any associative operator such as
-  min() or max() could also be used.
-
-  It assumes the input size is a power of 2.
-
-  COMMAND LINE ARGUMENTS
-
-  "--shmoo":         Test performance for 1 to 32M elements with each of the 
-                     7 different kernels
-  "--n=<N>":         Specify the number of elements to reduce (default 1048576)
-  "--threads=<N>":   Specify the number of threads per block (default 128)
-  "--maxblocks=<N>": Specify the maximum number of thread blocks to launch 
-                     (kernel 6 only, default 64)
-  "--cpufinal":      Read back the per-block results and do final sum of block 
-                     sums on CPU (default false)
-  "--cputhresh=<N>": The threshold of number of blocks sums below which to 
-                     perform a CPU final reduction (default 1)
-  "--multipass":     Use a multipass reduction instead of a single-pass reduction
-*/
-
-// includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include <string.h>
-#include <math.h>
-#include "HIPCHECK.h"
-// includes, project
-#include "hip/hip_runtime.h"
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"
-#define VERSION_MAJOR (CUDART_VERSION / 1000)
-#define VERSION_MINOR (CUDART_VERSION % 100) / 10
-const char *sSDKsample = "threadFenceReduction";
-
-#if CUDART_VERSION >= 2020
-#include "threadFenceReduction_kernel_hipified.cuh"
-#include "threadFenceReduction_hipified.h"
-#else
-#pragma comment(user, "CUDA 2.2 is required to build for threadFenceReduction")
-#endif
-
-////////////////////////////////////////////////////////////////////////////////
-// declaration, forward
-bool runTest(int argc, char **argv);
-
-extern "C" {
-void reduce(int size, int threads, int blocks, float *d_idata, float *d_odata);
-void reduceSinglePass(int size, int threads, int blocks, float *d_idata,
-                      float *d_odata);
-}
-
-#if CUDART_VERSION < 2020
-void reduce(int size, int threads, int blocks, float *d_idata, float *d_odata) {
-  printf("reduce(), compiler not supported, aborting tests\n");
-}
-
-void reduceSinglePass(int size, int threads, int blocks, float *d_idata,
-                      float *d_odata) {
-  printf("reduceSinglePass(), compiler not supported, aborting tests\n");
-}
-#endif
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  hipDeviceProp_t deviceProp;
-  deviceProp.major = 0;
-  deviceProp.minor = 0;
-  int dev;
-
-  printf("%s Starting...\n\n", sSDKsample);
-
-  dev = findCudaDevice(argc, (const char **)argv);
-
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, dev));
-
-  printf("GPU Device supports SM %d.%d compute capability\n\n",
-         deviceProp.major, deviceProp.minor);
-
-  bool bTestResult = false;
-
-#if CUDART_VERSION >= 2020
-  bTestResult = runTest(argc, argv);
-#else
-  //print_NVCC_min_spec(sSDKsample, "2.2", "Version 185");
-  exit(EXIT_SUCCESS);
-#endif
-
-  exit(bTestResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Compute sum reduction on CPU
-//! We use Kahan summation for an accurate sum of large arrays.
-//! http://en.wikipedia.org/wiki/Kahan_summation_algorithm
-//!
-//! @param data       pointer to input data
-//! @param size       number of input data elements
-////////////////////////////////////////////////////////////////////////////////
-template <class T>
-T reduceCPU(T *data, int size) {
-  T sum = data[0];
-  T c = (T)0.0;
-
-  for (int i = 1; i < size; i++) {
-    T y = data[i] - c;
-    T t = sum + y;
-    c = (t - sum) - y;
-    sum = t;
-  }
-
-  return sum;
-}
-
-unsigned int nextPow2(unsigned int x) {
-  --x;
-  x |= x >> 1;
-  x |= x >> 2;
-  x |= x >> 4;
-  x |= x >> 8;
-  x |= x >> 16;
-  return ++x;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Compute the number of threads and blocks to use for the reduction
-// We set threads / block to the minimum of maxThreads and n/2.
-////////////////////////////////////////////////////////////////////////////////
-void getNumBlocksAndThreads(int n, int maxBlocks, int maxThreads, int &blocks,
-                            int &threads) {
-  if (n == 1) {
-    threads = 1;
-    blocks = 1;
-  } else {
-    threads = (n < maxThreads * 2) ? nextPow2(n / 2) : maxThreads;
-    blocks = max(1, n / (threads * 2));
-  }
-
-  blocks = min(maxBlocks, blocks);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// This function performs a reduction of the input data multiple times and
-// measures the average reduction time.
-////////////////////////////////////////////////////////////////////////////////
-float benchmarkReduce(int n, int numThreads, int numBlocks, int maxThreads,
-                      int maxBlocks, int testIterations, bool multiPass,
-                      bool cpuFinalReduction, int cpuFinalThreshold,
-                      StopWatchInterface *timer, float *h_odata, float *d_idata,
-                      float *d_odata) {
-  float gpu_result = 0;
-  bool bNeedReadback = true;
-  hipError_t error;
-
-  for (int i = 0; i < testIterations; ++i) {
-    gpu_result = 0;
-    unsigned int retCnt = 0;
-    //error = setRetirementCount(retCnt);
-    HIPCHECK(error);
-
-    hipDeviceSynchronize();
-    sdkStartTimer(&timer);
-
-    if (multiPass) {
-      // execute the kernel
-      reduce(n, numThreads, numBlocks, d_idata, d_odata);
-
-      // check if kernel execution generated an error
-      getLastCudaError("Kernel execution failed");
-
-      if (cpuFinalReduction) {
-        // sum partial sums from each block on CPU
-        // copy result from device to host
-        error = hipMemcpy(h_odata, d_odata, numBlocks * sizeof(float),
-                           hipMemcpyDeviceToHost);
-        HIPCHECK(error);
-
-        for (int i = 0; i < numBlocks; i++) {
-          gpu_result += h_odata[i];
-        }
-
-        bNeedReadback = false;
-      } else {
-        // sum partial block sums on GPU
-        int s = numBlocks;
-
-        while (s > cpuFinalThreshold) {
-          int threads = 0, blocks = 0;
-          getNumBlocksAndThreads(s, maxBlocks, maxThreads, blocks, threads);
-
-          reduce(s, threads, blocks, d_odata, d_odata);
-
-          s = s / (threads * 2);
-        }
-
-        if (s > 1) {
-          // copy result from device to host
-          error = hipMemcpy(h_odata, d_odata, s * sizeof(float),
-                             hipMemcpyDeviceToHost);
-          HIPCHECK(error);
-
-          for (int i = 0; i < s; i++) {
-            gpu_result += h_odata[i];
-          }
-
-          bNeedReadback = false;
-        }
-      }
-    } else {
-      getLastCudaError("Kernel execution failed");
-
-      // execute the kernel
-      reduceSinglePass(n, numThreads, numBlocks, d_idata, d_odata);
-
-      // check if kernel execution generated an error
-      getLastCudaError("Kernel execution failed");
-    }
-
-    hipDeviceSynchronize();
-    sdkStopTimer(&timer);
-  }
-
-  if (bNeedReadback) {
-    // copy final sum from device to host
-    error =
-        hipMemcpy(&gpu_result, d_odata, sizeof(float), hipMemcpyDeviceToHost);
-    HIPCHECK(error);
-  }
-
-  return gpu_result;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// This function calls benchmarkReduce multiple times for a range of array sizes
-// and prints a report in CSV (comma-separated value) format that can be used
-// for generating a "shmoo" plot showing the performance for each kernel
-// variation over a wide range of input sizes.
-////////////////////////////////////////////////////////////////////////////////
-void shmoo(int minN, int maxN, int maxThreads, int maxBlocks) {
-  // create random input data on CPU
-  unsigned int bytes = maxN * sizeof(float);
-
-  float *h_idata = (float *)malloc(bytes);
-
-  for (int i = 0; i < maxN; i++) {
-    // Keep the numbers small so we don't get truncation error in the sum
-    h_idata[i] = (rand() & 0xFF) / (float)RAND_MAX;
-  }
-
-  int maxNumBlocks = min(65535, maxN / maxThreads);
-
-  // allocate mem for the result on host side
-  float *h_odata = (float *)malloc(maxNumBlocks * sizeof(float));
-
-  // allocate device memory and data
-  float *d_idata = NULL;
-  float *d_odata = NULL;
-
-  HIPCHECK(hipMalloc((void **)&d_idata, bytes));
-  HIPCHECK(hipMalloc((void **)&d_odata, maxNumBlocks * sizeof(float)));
-
-  // copy data directly to device memory
-  HIPCHECK(hipMemcpy(d_idata, h_idata, bytes, hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy(d_odata, h_idata, maxNumBlocks * sizeof(float),
-                             hipMemcpyHostToDevice));
-
-  // warm-up
-  reduce(maxN, maxThreads, maxNumBlocks, d_idata, d_odata);
-  int testIterations = 100;
-
-  StopWatchInterface *timer = NULL;
-  sdkCreateTimer(&timer);
-
-  // print headers
-  printf("N, %d blocks one pass, %d blocks multipass\n", maxBlocks, maxBlocks);
-
-  for (int i = minN; i <= maxN; i *= 2) {
-    printf("%d, ", i);
-
-    for (int multiPass = 0; multiPass <= 1; multiPass++) {
-      sdkResetTimer(&timer);
-      int numBlocks = 0;
-      int numThreads = 0;
-      getNumBlocksAndThreads(i, maxBlocks, maxThreads, numBlocks, numThreads);
-
-      benchmarkReduce(i, numThreads, numBlocks, maxThreads, maxBlocks,
-                      testIterations, multiPass == 1, false, 1, timer, h_odata,
-                      d_idata, d_odata);
-
-      float reduceTime = sdkGetAverageTimerValue(&timer);
-      printf("%f%s", reduceTime, multiPass == 0 ? ", " : "\n");
-    }
-  }
-
-  printf("\n");
-
-  // cleanup
-  sdkDeleteTimer(&timer);
-  free(h_idata);
-  free(h_odata);
-
-  hipFree(d_idata);
-  hipFree(d_odata);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// The main function which runs the reduction test.
-////////////////////////////////////////////////////////////////////////////////
-bool runTest(int argc, char **argv) {
-  int size = 1 << 20;    // number of elements to reduce
-  int maxThreads = 128;  // number of threads per block
-  int maxBlocks = 64;
-  bool cpuFinalReduction = false;
-  int cpuFinalThreshold = 1;
-  bool multipass = false;
-  bool bTestResult = false;
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "n")) {
-    size = getCmdLineArgumentInt(argc, (const char **)argv, "n");
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "threads")) {
-    maxThreads = getCmdLineArgumentInt(argc, (const char **)argv, "threads");
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "maxblocks")) {
-    maxBlocks = getCmdLineArgumentInt(argc, (const char **)argv, "maxblocks");
-  }
-
-  printf("%d elements\n", size);
-  printf("%d threads (max)\n", maxThreads);
-
-  cpuFinalReduction = checkCmdLineFlag(argc, (const char **)argv, "cpufinal");
-  multipass = checkCmdLineFlag(argc, (const char **)argv, "multipass");
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "cputhresh")) {
-    cpuFinalThreshold =
-        getCmdLineArgumentInt(argc, (const char **)argv, "cputhresh");
-  }
-
-  bool runShmoo = checkCmdLineFlag(argc, (const char **)argv, "shmoo");
-
-  if (runShmoo) {
-    shmoo(1, 33554432, maxThreads, maxBlocks);
-  } else {
-    // create random input data on CPU
-    unsigned int bytes = size * sizeof(float);
-
-    float *h_idata = (float *)malloc(bytes);
-
-    for (int i = 0; i < size; i++) {
-      // Keep the numbers small so we don't get truncation error in the sum
-      h_idata[i] = (rand() & 0xFF) / (float)RAND_MAX;
-    }
-
-    int numBlocks = 0;
-    int numThreads = 0;
-    getNumBlocksAndThreads(size, maxBlocks, maxThreads, numBlocks, numThreads);
-
-    if (numBlocks == 1) {
-      cpuFinalThreshold = 1;
-    }
-
-    // allocate mem for the result on host side
-    float *h_odata = (float *)malloc(numBlocks * sizeof(float));
-
-    printf("%d blocks\n", numBlocks);
-
-    // allocate device memory and data
-    float *d_idata = NULL;
-    float *d_odata = NULL;
-
-    HIPCHECK(hipMalloc((void **)&d_idata, bytes));
-    HIPCHECK(hipMalloc((void **)&d_odata, numBlocks * sizeof(float)));
-
-    // copy data directly to device memory
-    HIPCHECK(
-        hipMemcpy(d_idata, h_idata, bytes, hipMemcpyHostToDevice));
-    HIPCHECK(hipMemcpy(d_odata, h_idata, numBlocks * sizeof(float),
-                               hipMemcpyHostToDevice));
-
-    // warm-up
-    reduce(size, numThreads, numBlocks, d_idata, d_odata);
-    int testIterations = 100;
-
-    StopWatchInterface *timer = 0;
-    sdkCreateTimer(&timer);
-
-    float gpu_result = 0;
-
-    gpu_result =
-        benchmarkReduce(size, numThreads, numBlocks, maxThreads, maxBlocks,
-                        testIterations, multipass, cpuFinalReduction,
-                        cpuFinalThreshold, timer, h_odata, d_idata, d_odata);
-
-    float reduceTime = sdkGetAverageTimerValue(&timer);
-    printf("Average time: %f ms\n", reduceTime);
-    printf("Bandwidth:    %f GB/s\n\n",
-           (size * sizeof(int)) / (reduceTime * 1.0e6));
-
-    // compute reference solution
-    float cpu_result = reduceCPU<float>(h_idata, size);
-
-    printf("GPU result = %0.12f\n", gpu_result);
-    printf("CPU result = %0.12f\n", cpu_result);
-
-    double threshold = 1e-8 * size;
-    double diff = abs((double)gpu_result - (double)cpu_result);
-    bTestResult = (diff < threshold);
-
-    // cleanup
-    sdkDeleteTimer(&timer);
-
-    free(h_idata);
-    free(h_odata);
-    hipFree(d_idata);
-    hipFree(d_odata);
-  }
-
-  return bTestResult;
-}
-
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.h b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.out b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_hipified.h b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_kernel.cuh b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_kernel_hipified.cuh b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/threadFenceReduction/threadFenceReduction_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/.vscode/c_cpp_properties.json b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/.vscode/extensions.json b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/.vscode/launch.json b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/.vscode/tasks.json b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/Makefile b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/README.md b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration.cpp b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_hipified.cpp b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_kernel.cu b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_kernel.cu.hip b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_kernel.cu.hip
old mode 100644
new mode 100755
index 42cc050..e69de29
--- a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_kernel.cu.hip
+++ b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_kernel.cu.hip
@@ -1,31 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-extern "C" __global__ void kernelFunction(int *input) {
-  input[threadIdx.x] = 32 - threadIdx.x;
-}
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2017.sln b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2017.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2019.sln b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2019.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2022.sln b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2022.vcxproj b/src/samples/Samples/2_Concepts_and_Techniques/threadMigration/threadMigration_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/README.md b/src/samples/Samples/3_CUDA_Features/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/StreamPriorities/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/StreamPriorities/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/StreamPriorities/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/StreamPriorities/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/StreamPriorities/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/StreamPriorities/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/StreamPriorities/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/StreamPriorities/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/StreamPriorities/Makefile b/src/samples/Samples/3_CUDA_Features/StreamPriorities/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/StreamPriorities/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/StreamPriorities/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/StreamPriorities/README.md b/src/samples/Samples/3_CUDA_Features/StreamPriorities/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.cu b/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.cu.hip b/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.cu.hip
old mode 100644
new mode 100755
index 87d030c..e69de29
--- a/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.cu.hip
@@ -1,202 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// std::system includes
-#include <cstdio>
-
-// CUDA-C includes
-#include <hip/hip_runtime.h>
-
-#include "helper_cuda_hipified.h"
-#include "HIPCHECK.h"
-#define TOTAL_SIZE 256 * 1024 * 1024
-#define EACH_SIZE 128 * 1024 * 1024
-
-// # threadblocks
-#define TBLOCKS 1024
-#define THREADS 512
-
-// throw error on equality
-#define ERR_EQ(X, Y)                                                           \
-  do {                                                                         \
-    if ((X) == (Y)) {                                                          \
-      fprintf(stderr, "Error in %s at %s:%d\n", __func__, __FILE__, __LINE__); \
-      exit(-1);                                                                \
-    }                                                                          \
-  } while (0)
-
-// throw error on difference
-#define ERR_NE(X, Y)                                                           \
-  do {                                                                         \
-    if ((X) != (Y)) {                                                          \
-      fprintf(stderr, "Error in %s at %s:%d\n", __func__, __FILE__, __LINE__); \
-      exit(-1);                                                                \
-    }                                                                          \
-  } while (0)
-
-// copy from source -> destination arrays
-__global__ void memcpy_kernel(int *dst, int *src, size_t n) {
-  int num = gridDim.x * blockDim.x;
-  int id = blockDim.x * blockIdx.x + threadIdx.x;
-
-  for (int i = id; i < n / sizeof(int); i += num) {
-    dst[i] = src[i];
-  }
-}
-
-// initialise memory
-void mem_init(int *buf, size_t n) {
-  for (int i = 0; i < n / sizeof(int); i++) {
-    buf[i] = i;
-  }
-}
-
-int main(int argc, char **argv) {
-  hipDeviceProp_t device_prop;
-  int dev_id;
-
-  printf("Starting [%s]...\n", argv[0]);
-
-  // set device
-  dev_id = findCudaDevice(argc, (const char **)argv);
-  HIPCHECK(hipGetDeviceProperties(&device_prop, dev_id));
-
-  if ((device_prop.major << 4) + device_prop.minor < 0x35) {
-    fprintf(stderr,
-            "%s requires Compute Capability of SM 3.5 or higher to "
-            "run.\nexiting...\n",
-            argv[0]);
-    exit(EXIT_WAIVED);
-  }
-
-  // get the range of priorities available
-  // [ greatest_priority, lowest_priority ]
-  int priority_low;
-  int priority_hi;
-  HIPCHECK(
-      hipDeviceGetStreamPriorityRange(&priority_low, &priority_hi));
-
-  printf("CUDA stream priority range: LOW: %d to HIGH: %d\n", priority_low,
-         priority_hi);
-
-  // create streams with highest and lowest available priorities
-  hipStream_t st_low;
-  hipStream_t st_hi;
-  HIPCHECK(hipStreamCreateWithPriority(&st_low, hipStreamNonBlocking,
-                                               priority_low));
-  HIPCHECK(
-      hipStreamCreateWithPriority(&st_hi, hipStreamNonBlocking, priority_hi));
-
-  size_t size;
-  size = TOTAL_SIZE;
-
-  // initialise host data
-  int *h_src_low;
-  int *h_src_hi;
-  ERR_EQ(h_src_low = (int *)malloc(size), NULL);
-  ERR_EQ(h_src_hi = (int *)malloc(size), NULL);
-  mem_init(h_src_low, size);
-  mem_init(h_src_hi, size);
-
-  // initialise device data
-  int *h_dst_low;
-  int *h_dst_hi;
-  ERR_EQ(h_dst_low = (int *)malloc(size), NULL);
-  ERR_EQ(h_dst_hi = (int *)malloc(size), NULL);
-  memset(h_dst_low, 0, size);
-  memset(h_dst_hi, 0, size);
-
-  // copy source data -> device
-  int *d_src_low;
-  int *d_src_hi;
-  HIPCHECK(hipMalloc(&d_src_low, size));
-  HIPCHECK(hipMalloc(&d_src_hi, size));
-  HIPCHECK(
-      hipMemcpy(d_src_low, h_src_low, size, hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy(d_src_hi, h_src_hi, size, hipMemcpyHostToDevice));
-
-  // allocate memory for memcopy destination
-  int *d_dst_low;
-  int *d_dst_hi;
-  HIPCHECK(hipMalloc(&d_dst_low, size));
-  HIPCHECK(hipMalloc(&d_dst_hi, size));
-
-  // create some events
-  hipEvent_t ev_start_low;
-  hipEvent_t ev_start_hi;
-  hipEvent_t ev_end_low;
-  hipEvent_t ev_end_hi;
-  HIPCHECK(hipEventCreate(&ev_start_low));
-  HIPCHECK(hipEventCreate(&ev_start_hi));
-  HIPCHECK(hipEventCreate(&ev_end_low));
-  HIPCHECK(hipEventCreate(&ev_end_hi));
-
-  /* */
-
-  // call pair of kernels repeatedly (with different priority streams)
-  HIPCHECK(hipEventRecord(ev_start_low, st_low));
-  HIPCHECK(hipEventRecord(ev_start_hi, st_hi));
-
-  for (int i = 0; i < TOTAL_SIZE; i += EACH_SIZE) {
-    int j = i / sizeof(int);
-    memcpy_kernel<<<TBLOCKS, THREADS, 0, st_low>>>(d_dst_low + j, d_src_low + j,
-                                                   EACH_SIZE);
-    memcpy_kernel<<<TBLOCKS, THREADS, 0, st_hi>>>(d_dst_hi + j, d_src_hi + j,
-                                                  EACH_SIZE);
-  }
-
-  HIPCHECK(hipEventRecord(ev_end_low, st_low));
-  HIPCHECK(hipEventRecord(ev_end_hi, st_hi));
-
-  HIPCHECK(hipEventSynchronize(ev_end_low));
-  HIPCHECK(hipEventSynchronize(ev_end_hi));
-
-  /* */
-
-  size = TOTAL_SIZE;
-  HIPCHECK(
-      hipMemcpy(h_dst_low, d_dst_low, size, hipMemcpyDeviceToHost));
-  HIPCHECK(hipMemcpy(h_dst_hi, d_dst_hi, size, hipMemcpyDeviceToHost));
-
-  // check results of kernels
-  ERR_NE(memcmp(h_dst_low, h_src_low, size), 0);
-  ERR_NE(memcmp(h_dst_hi, h_src_hi, size), 0);
-
-  // check timings
-  float ms_low;
-  float ms_hi;
-  HIPCHECK(hipEventElapsedTime(&ms_low, ev_start_low, ev_end_low));
-  HIPCHECK(hipEventElapsedTime(&ms_hi, ev_start_hi, ev_end_hi));
-
-  printf("elapsed time of kernels launched to LOW priority stream: %.3lf ms\n",
-         ms_low);
-  printf("elapsed time of kernels launched to HI  priority stream: %.3lf ms\n",
-         ms_hi);
-
-  exit(EXIT_SUCCESS);
-}
diff --git a/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.out b/src/samples/Samples/3_CUDA_Features/StreamPriorities/StreamPriorities.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/Makefile b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/README.md b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm.cu b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm.cu.hip b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm.cu.hip
old mode 100644
new mode 100755
index c830545..05c0694
--- a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm.cu.hip
@@ -60,16 +60,14 @@
 
 #include <assert.h>
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <hip/hip_runtime.h>
 #include <cuda_bf16.h>
 #include <mma.h>
 #include <cuda/pipeline>
-#include "HIPCHECK.h"
+
 // helper functions and utilities to work with CUDA
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
+#include <helper_functions.h>
+#include <helper_cuda.h>
 
 // Externally configurable parameters.
 
@@ -173,12 +171,12 @@
 
 enum kernels
 {
-    bf16mma_shmem_gemm_async_copy  = 0, // __nv_bfloat16 MMA shmem using kernel with async_copy 
+    bf16mma_shmem_gemm_async_copy  = 0, // __nv_bfloat16 MMA shmem using kernel with async_copy
     bf16mma_shmem_gemm             = 1, // __nv_bfloat16 MMA shmem using kernel normal copy (without async_copy).
     simple_bf16mma_gemm            = 2  // __nv_bfloat16 MMA non-shmem using simple kernel.
 };
 
-const char* kernelNames[] = {"compute_bf16gemm_async_copy", "compute_bf16gemm", 
+const char* kernelNames[] = {"compute_bf16gemm_async_copy", "compute_bf16gemm",
                             "simple_wmma_bf16gemm"};
 
 using namespace nvcuda;
@@ -244,7 +242,7 @@ __global__ void compute_bf16gemm(const __nv_bfloat16 *A, const __nv_bfloat16 *B,
         // Stream multiple C tiles to shared memory.
 #pragma unroll
         for (int i = 0; i < N; i++) {
-            *((int4*)(shmem_warp_stream_ptr + SHMEM_STRIDE * i) + laneId) = 
+            *((int4*)(shmem_warp_stream_ptr + SHMEM_STRIDE * i) + laneId) =
                 *((int4*)(src_gmem_warp_stream_ptr + GLOBAL_MEM_STRIDE * i) + laneId);
         }
 
@@ -289,7 +287,7 @@ __global__ void compute_bf16gemm(const __nv_bfloat16 *A, const __nv_bfloat16 *B,
         for (int tile_k = 0; tile_k < K_TILES; tile_k += CHUNK_K) {
             // Copy slices of the A and B matrices to shared memory.
             // The first half of the warps in the CTA copy the A matrix, the rest copy the B matrix.
-            size_t shmem_idx = warpId < (WARPS_PER_BLOCK/2) ? (M * (warpId % (WARPS_PER_BLOCK/2)) * 2) : 
+            size_t shmem_idx = warpId < (WARPS_PER_BLOCK/2) ? (M * (warpId % (WARPS_PER_BLOCK/2)) * 2) :
                                                               (N * (warpId % (WARPS_PER_BLOCK/2)) * 2 + shmem_idx_b_off);
 
             // First half of the warp copies the first row / column of the matrix,
@@ -565,7 +563,7 @@ __global__ void compute_bf16gemm_async_copy(const __nv_bfloat16 *A, const __nv_b
 
 // Performs an MxNxK bf16 GEMM (C=alpha*A*B + beta*C) assuming:
 //  1) Matrices are packed in memory.
-//  2) M, N and K are multiples of 16, 16 and 16 respectively. 
+//  2) M, N and K are multiples of 16, 16 and 16 respectively.
 //  3) A is row major, B is column major matrix.
 // Note: This is a less performant version of the compute_bf16gemm kernel. It is designed for
 //       demonstration purposes only to show the CUDA WMMA API use without relying on
@@ -581,7 +579,7 @@ __global__ void simple_wmma_bf16gemm(__nv_bfloat16 *a, __nv_bfloat16 *b, float *
    // Tile using a 2D grid
    int warpM = (blockIdx.x * blockDim.x + threadIdx.x) / warpSize;
    int warpN = (blockIdx.y * blockDim.y + threadIdx.y);
- 
+
    // Declare the fragments
    wmma::fragment<wmma::matrix_a, M, N, K, __nv_bfloat16, wmma::row_major> a_frag;
    wmma::fragment<wmma::matrix_b, M, N, K, __nv_bfloat16, wmma::col_major> b_frag;
@@ -592,7 +590,7 @@ __global__ void simple_wmma_bf16gemm(__nv_bfloat16 *a, __nv_bfloat16 *b, float *
 
    // Loop over k
    for (int i = 0; i < k_ld; i += K) {
-      int aCol = i; 
+      int aCol = i;
       int aRow = warpM * M;
 
       int bCol = i;
@@ -603,7 +601,7 @@ __global__ void simple_wmma_bf16gemm(__nv_bfloat16 *a, __nv_bfloat16 *b, float *
          // Load the inputs
          wmma::load_matrix_sync(a_frag, a + aCol + aRow * lda, lda);
          wmma::load_matrix_sync(b_frag, b + bRow + bCol * ldb, ldb);
- 
+
          // Perform the matrix multiplication
          wmma::mma_sync(acc_frag, a_frag, b_frag, acc_frag);
 
@@ -653,7 +651,7 @@ int main(int argc, char **argv)
     int dev = findCudaDevice(argc, (const char **)argv);
 
     hipDeviceProp_t deviceProp;
-    HIPCHECK(hipGetDeviceProperties(&deviceProp, dev));
+    checkCudaErrors(hipGetDeviceProperties(&deviceProp, dev));
 
     // Tensor cores require a GPU of Volta (SM8X) architecture or higher.
     if (deviceProp.major < 8) {
@@ -686,10 +684,10 @@ int main(int argc, char **argv)
     float *C = NULL;
     float *D = NULL;
 
-    HIPCHECK(hipMalloc((void**)&A, sizeof(__nv_bfloat16) * M_GLOBAL * K_GLOBAL));
-    HIPCHECK(hipMalloc((void**)&B, sizeof(__nv_bfloat16) * N_GLOBAL * K_GLOBAL));
-    HIPCHECK(hipMalloc((void**)&C, sizeof(float) * M_GLOBAL * N_GLOBAL));
-    HIPCHECK(hipMalloc((void**)&D, sizeof(float) * M_GLOBAL * N_GLOBAL));
+    checkCudaErrors(hipMalloc((void**)&A, sizeof(__nv_bfloat16) * M_GLOBAL * K_GLOBAL));
+    checkCudaErrors(hipMalloc((void**)&B, sizeof(__nv_bfloat16) * N_GLOBAL * K_GLOBAL));
+    checkCudaErrors(hipMalloc((void**)&C, sizeof(float) * M_GLOBAL * N_GLOBAL));
+    checkCudaErrors(hipMalloc((void**)&D, sizeof(float) * M_GLOBAL * N_GLOBAL));
 
     assert(((unsigned long long)A) % 128 == 0);
     assert(((unsigned long long)B) % 128 == 0);
@@ -700,10 +698,10 @@ int main(int argc, char **argv)
 
     printf("Preparing data for GPU...\n");
 
-    HIPCHECK(hipMemcpy(A, A_h, sizeof(__nv_bfloat16) * M_GLOBAL * K_GLOBAL, hipMemcpyHostToDevice));
-    HIPCHECK(hipMemcpy(B, B_h, sizeof(__nv_bfloat16) * N_GLOBAL * K_GLOBAL, hipMemcpyHostToDevice));
-    HIPCHECK(hipMemcpy(C, C_h, sizeof(float) * M_GLOBAL * N_GLOBAL, hipMemcpyHostToDevice));
-    HIPCHECK(hipMemset(D, 0, sizeof(float) * M_GLOBAL * N_GLOBAL));
+    checkCudaErrors(hipMemcpy(A, A_h, sizeof(__nv_bfloat16) * M_GLOBAL * K_GLOBAL, hipMemcpyHostToDevice));
+    checkCudaErrors(hipMemcpy(B, B_h, sizeof(__nv_bfloat16) * N_GLOBAL * K_GLOBAL, hipMemcpyHostToDevice));
+    checkCudaErrors(hipMemcpy(C, C_h, sizeof(float) * M_GLOBAL * N_GLOBAL, hipMemcpyHostToDevice));
+    checkCudaErrors(hipMemset(D, 0, sizeof(float) * M_GLOBAL * N_GLOBAL));
 
     enum {
         // Compute the right amount of shared memory to request.
@@ -721,9 +719,9 @@ int main(int argc, char **argv)
 
     hipEvent_t start, stop;
 
-    HIPCHECK(hipEventCreate(&start));    
-    HIPCHECK(hipEventCreate(&stop));
-    HIPCHECK(hipEventRecord(start));
+    checkCudaErrors(hipEventCreate(&start));
+    checkCudaErrors(hipEventCreate(&stop));
+    checkCudaErrors(hipEventRecord(start));
 
     // kernel to run - default (b16mma_shmem_gemm_async_copy == 0)
     kernels selected_kernel = bf16mma_shmem_gemm_async_copy;
@@ -747,22 +745,22 @@ int main(int argc, char **argv)
         {
             case bf16mma_shmem_gemm_async_copy :
             default:
-                HIPCHECK(hipFuncSetAttribute((const void *)compute_bf16gemm_async_copy, hipFuncAttributeMaxDynamicSharedMemorySize, SHMEM_SZ));
+                checkCudaErrors(hipFuncSetAttribute(compute_bf16gemm_async_copy, hipFuncAttributeMaxDynamicSharedMemorySize, SHMEM_SZ));
                 checkKernelErrors((compute_bf16gemm_async_copy<<<deviceProp.multiProcessorCount*2, THREADS_PER_BLOCK, SHMEM_SZ>>>(A, B, C, D, alpha, beta)));
                 break;
             case bf16mma_shmem_gemm :
-                HIPCHECK(hipFuncSetAttribute((const void *)compute_bf16gemm, hipFuncAttributeMaxDynamicSharedMemorySize, SHMEM_SZ));
+                checkCudaErrors(hipFuncSetAttribute(compute_bf16gemm, hipFuncAttributeMaxDynamicSharedMemorySize, SHMEM_SZ));
                 checkKernelErrors((compute_bf16gemm<<<deviceProp.multiProcessorCount*2, THREADS_PER_BLOCK, SHMEM_SZ>>>(A, B, C, D, alpha, beta)));
                 break;
         }
 #if CPU_DEBUG
-        HIPCHECK(hipMemcpy(result_hD, D, sizeof(float)*M_GLOBAL*N_GLOBAL, hipMemcpyDeviceToHost));
+        checkCudaErrors(hipMemcpy(result_hD, D, sizeof(float)*M_GLOBAL*N_GLOBAL, hipMemcpyDeviceToHost));
 #endif
     }
     else {
         dim3 gridDim;
         dim3 blockDim;
-     
+
         // blockDim.x must be a multple of warpSize
         // 128x4 means we have 16 warps and a block computes a 64x64 output tile
         blockDim.x = 128;
@@ -774,12 +772,12 @@ int main(int argc, char **argv)
         printf("Computing... using simple_wmma_gemm kernel\n");
         simple_wmma_bf16gemm<<<gridDim, blockDim>>>(A, B, C, D, M_GLOBAL, N_GLOBAL, K_GLOBAL, alpha, beta);
 #if CPU_DEBUG
-        HIPCHECK(hipMemcpy(result_hD, D, sizeof(float) * M_GLOBAL * N_GLOBAL, hipMemcpyDeviceToHost));
+        checkCudaErrors(hipMemcpy(result_hD, D, sizeof(float) * M_GLOBAL * N_GLOBAL, hipMemcpyDeviceToHost));
 #endif
     }
 
-    HIPCHECK(hipEventRecord(stop));
-    HIPCHECK(hipEventSynchronize(stop));
+    checkCudaErrors(hipEventRecord(stop));
+    checkCudaErrors(hipEventSynchronize(stop));
 
 #if CPU_DEBUG
     printf("Verifying correctness of the computations...\n");
@@ -803,7 +801,7 @@ int main(int argc, char **argv)
 
     float milliseconds = 0;
 
-    HIPCHECK(hipEventElapsedTime(&milliseconds, start, stop));
+    checkCudaErrors(hipEventElapsedTime(&milliseconds, start, stop));
 
     printf("Time: %f ms\n", milliseconds);
     printf("TFLOPS: %.2f\n", (((double)M_GLOBAL * N_GLOBAL * K_GLOBAL * 2)/(milliseconds/1000.)) / 1e12);
@@ -811,11 +809,10 @@ int main(int argc, char **argv)
     free(A_h);
     free(B_h);
     free(C_h);
-    HIPCHECK(hipFree((void*)A));
-    HIPCHECK(hipFree((void*)B));
-    HIPCHECK(hipFree((void*)C));
-    HIPCHECK(hipFree((void*)D));
+    checkCudaErrors(hipFree((void*)A));
+    checkCudaErrors(hipFree((void*)B));
+    checkCudaErrors(hipFree((void*)C));
+    checkCudaErrors(hipFree((void*)D));
 
     return 0;
 }
-
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2017.sln b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2019.sln b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2022.sln b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/bf16TensorCoreGemm/bf16TensorCoreGemm_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/Makefile b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/README.md b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG.cu b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG.cu.hip b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG.cu.hip
old mode 100644
new mode 100755
index ed7c9b9..e69de29
--- a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG.cu.hip
@@ -1,162 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This sample illustrates basic usage of binary partition cooperative groups
- * within the thread block tile when divergent path exists.
- * 1.) Each thread loads a value from random array.
- * 2.) then checks if it is odd or even.
- * 3.) create binary partition group based on the above predicate
- * 4.) we count the number of odd/even in the group based on size of the binary
-       groups
- * 5.) write it global counter of odd.
- * 6.) sum the values loaded by individual threads(using reduce) and write it to
-       global even & odd elements sum.
- *
- * **NOTE** :
- *    binary_partition results in splitting warp into divergent thread groups
- *    this is not good from performance perspective, but in cases where warp
- *    divergence is inevitable one can use binary_partition group.
-*/
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <hip/hip_cooperative_groups.h>
-#include <cooperative_groups/reduce.h>
-#include "helper_cuda_hipified.h"
-
-namespace cg = cooperative_groups;
-
-void initOddEvenArr(int *inputArr, unsigned int size) {
-  for (int i = 0; i < size; i++) {
-    inputArr[i] = rand() % 50;
-  }
-}
-
-/**
- * CUDA kernel device code
- *
- * Creates cooperative groups and performs odd/even counting & summation.
- */
-__global__ void oddEvenCountAndSumCG(int *inputArr, int *numOfOdds,
-                                     int *sumOfOddAndEvens, unsigned int size) {
-  cg::thread_block cta = cg::this_thread_block();
-  cg::grid_group grid = cg::this_grid();
-  cg::thread_block_tile<32> tile32 = cg::tiled_partition<32>(cta);
-
-  for (int i = grid.thread_rank(); i < size; i += grid.size()) {
-    int elem = inputArr[i];
-    auto subTile = cg::binary_partition(tile32, elem & 1);
-    if (elem & 1)  // Odd numbers group
-    {
-      int oddGroupSum = cg::reduce(subTile, elem, cg::plus<int>());
-
-      if (subTile.thread_rank() == 0) {
-        // Add number of odds present in this group of Odds.
-        atomicAdd(numOfOdds, subTile.size());
-
-        // Add local reduction of odds present in this group of Odds.
-        atomicAdd(&sumOfOddAndEvens[0], oddGroupSum);
-      }
-    } else  // Even numbers group
-    {
-      int evenGroupSum = cg::reduce(subTile, elem, cg::plus<int>());
-
-      if (subTile.thread_rank() == 0) {
-        // Add local reduction of even present in this group of evens.
-        atomicAdd(&sumOfOddAndEvens[1], evenGroupSum);
-      }
-    }
-    // reconverge warp so for next loop iteration we ensure convergence of
-    // above diverged threads to perform coalesced loads of inputArr.
-    cg::sync(tile32);
-  }
-}
-
-/**
- * Host main routine
- */
-int main(int argc, const char **argv) {
-  int deviceId = findCudaDevice(argc, argv);
-  int *h_inputArr, *d_inputArr;
-  int *h_numOfOdds, *d_numOfOdds;
-  int *h_sumOfOddEvenElems, *d_sumOfOddEvenElems;
-  unsigned int arrSize = 1024 * 100;
-
-  checkCudaErrors(hipHostMalloc(&h_inputArr, sizeof(int) * arrSize));
-  checkCudaErrors(hipHostMalloc(&h_numOfOdds, sizeof(int)));
-  checkCudaErrors(hipHostMalloc(&h_sumOfOddEvenElems, sizeof(int) * 2));
-  initOddEvenArr(h_inputArr, arrSize);
-
-  hipStream_t stream;
-  checkCudaErrors(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
-  checkCudaErrors(hipMalloc(&d_inputArr, sizeof(int) * arrSize));
-  checkCudaErrors(hipMalloc(&d_numOfOdds, sizeof(int)));
-  checkCudaErrors(hipMalloc(&d_sumOfOddEvenElems, sizeof(int) * 2));
-
-  checkCudaErrors(hipMemcpyAsync(d_inputArr, h_inputArr, sizeof(int) * arrSize,
-                                  hipMemcpyHostToDevice, stream));
-  checkCudaErrors(hipMemsetAsync(d_numOfOdds, 0, sizeof(int), stream));
-  checkCudaErrors(
-      hipMemsetAsync(d_sumOfOddEvenElems, 0, 2 * sizeof(int), stream));
-
-  // Launch the kernel
-  int threadsPerBlock = 0;
-  int blocksPerGrid = 0;
-  checkCudaErrors(hipOccupancyMaxPotentialBlockSize(
-      &blocksPerGrid, &threadsPerBlock, oddEvenCountAndSumCG, 0, 0));
-
-  printf("\nLaunching %d blocks with %d threads...\n\n", blocksPerGrid,
-         threadsPerBlock);
-
-  oddEvenCountAndSumCG<<<blocksPerGrid, threadsPerBlock, 0, stream>>>(
-      d_inputArr, d_numOfOdds, d_sumOfOddEvenElems, arrSize);
-
-  HIPCHECK(hipMemcpyAsync(h_numOfOdds, d_numOfOdds, sizeof(int),
-                                  hipMemcpyDeviceToHost, stream));
-  HIPCHECK(hipMemcpyAsync(h_sumOfOddEvenElems, d_sumOfOddEvenElems,
-                                  2 * sizeof(int), hipMemcpyDeviceToHost,
-                                  stream));
-  HIPCHECK(hipStreamSynchronize(stream));
-
-  printf("Array size = %d Num of Odds = %d Sum of Odds = %d Sum of Evens %d\n",
-         arrSize, h_numOfOdds[0], h_sumOfOddEvenElems[0],
-         h_sumOfOddEvenElems[1]);
-  printf("\n...Done.\n\n");
-
-  HIPCHECK(hipHostFree(h_inputArr));
-  HIPCHECK(hipHostFree(h_numOfOdds));
-  HIPCHECK(hipHostFree(h_sumOfOddEvenElems));
-
-  HIPCHECK(hipFree(d_inputArr));
-  HIPCHECK(hipFree(d_numOfOdds));
-  HIPCHECK(hipFree(d_sumOfOddEvenElems));
-
-  return EXIT_SUCCESS;
-}
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2017.sln b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2019.sln b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2022.sln b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/binaryPartitionCG/binaryPartitionCG_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/bindlessTexture/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/bindlessTexture/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/bindlessTexture/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/bindlessTexture/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/Makefile b/src/samples/Samples/3_CUDA_Features/bindlessTexture/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/bindlessTexture/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/README.md b/src/samples/Samples/3_CUDA_Features/bindlessTexture/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture.cpp b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture.h b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_hipified.cpp b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_hipified.h b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_kernel.cu b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_kernel.cu.hip b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_kernel.cu.hip
old mode 100644
new mode 100755
index 9cf3aaf..e69de29
--- a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_kernel.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_kernel.cu.hip
@@ -1,430 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
-  This sample has two kernels, one doing the rendering every frame, and
-  another one used to generate the mip map levels at startup.
-
-  For rendering we use a "virtual" texturing approach, where one 2d texture
-  stores pointers to the actual textures used. This can be achieved by the
-  new cudaTextureObject introduced in CUDA 5.0 and requiring sm3+ hardware.
-
-  The mipmap generation kernel uses cudaSurfaceObject and cudaTextureObject
-  passed as kernel arguments to compute the higher mip map level based on
-  the lower.
-*/
-
-#ifndef _BINDLESSTEXTURE_KERNEL_CU_
-#define _BINDLESSTEXTURE_KERNEL_CU_
-
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-
-#include <vector>
-
-#include "helper_cuda_hipified.h"
-#include <helper_math.h>
-
-#include "bindlessTexture.h"
-
-// set this to just see the mipmap chain of first image
-//#define SHOW_MIPMAPS
-
-// local references to resources
-
-Image atlasImage;
-std::vector<Image> contentImages;
-float highestLod = 1.0f;
-
-#ifndef MAX
-#define MAX(a, b) ((a > b) ? a : b)
-#endif
-
-//////////////////////////////////////////////////////////////////////////
-
-__host__ __device__ __inline__ uint2 encodeTextureObject(
-    hipTextureObject_t obj) {
-  return make_uint2((uint)(obj & 0xFFFFFFFF), (uint)(obj >> 32));
-}
-
-__host__ __device__ __inline__ hipTextureObject_t decodeTextureObject(
-    uint2 obj) {
-  return (((hipTextureObject_t)obj.x) | ((hipTextureObject_t)obj.y) << 32);
-}
-
-__device__ __inline__ float4 to_float4(uchar4 vec) {
-  return make_float4(vec.x, vec.y, vec.z, vec.w);
-}
-
-__device__ __inline__ uchar4 to_uchar4(float4 vec) {
-  return make_uchar4((uchar)vec.x, (uchar)vec.y, (uchar)vec.z, (uchar)vec.w);
-}
-
-//////////////////////////////////////////////////////////////////////////
-// Rendering
-
-// the atlas texture stores the 64 bit cudaTextureObjects
-// we use it for "virtual" texturing
-
-__global__ void d_render(uchar4 *d_output, uint imageW, uint imageH, float lod,
-                         hipTextureObject_t atlasTexture) {
-  uint x = blockIdx.x * blockDim.x + threadIdx.x;
-  uint y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  float u = x / (float)imageW;
-  float v = y / (float)imageH;
-
-  if ((x < imageW) && (y < imageH)) {
-    // read from 2D atlas texture and decode texture object
-    uint2 texCoded = tex2D<uint2>(atlasTexture, u, v);
-    hipTextureObject_t tex = decodeTextureObject(texCoded);
-
-    // read from cuda texture object, use template to specify what data will be
-    // returned. tex2DLod allows us to pass the lod (mip map level) directly.
-    // There is other functions with CUDA 5, e.g. tex2DGrad, that allow you
-    // to pass derivatives to perform automatic mipmap/anisotropic filtering.
-    float4 color = tex2DLod<float4>(tex, u, 1 - v, lod);
-    // In our sample tex is always valid, but for something like your own
-    // sparse texturing you would need to make sure to handle the zero case.
-
-    // write output color
-    uint i = y * imageW + x;
-    d_output[i] = to_uchar4(color * 255.0);
-  }
-}
-
-extern "C" void renderAtlasImage(dim3 gridSize, dim3 blockSize,
-                                 uchar4 *d_output, uint imageW, uint imageH,
-                                 float lod) {
-  // psuedo animate lod
-  lod = fmodf(lod, highestLod * 2);
-  lod = highestLod - fabs(lod - highestLod);
-
-#ifdef SHOW_MIPMAPS
-  lod = 0.0f;
-#endif
-
-  d_render<<<gridSize, blockSize>>>(d_output, imageW, imageH, lod,
-                                    atlasImage.textureObject);
-
-  HIPCHECK(hipGetLastError());
-}
-
-//////////////////////////////////////////////////////////////////////////
-// MipMap Generation
-
-//  A key benefit of using the new surface objects is that we don't need any
-//  global binding points anymore. We can directly pass them as function
-//  arguments.
-
-__global__ void d_mipmap(hipSurfaceObject_t mipOutput,
-                         hipTextureObject_t mipInput, uint imageW,
-                         uint imageH) {
-  uint x = blockIdx.x * blockDim.x + threadIdx.x;
-  uint y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  float px = 1.0 / float(imageW);
-  float py = 1.0 / float(imageH);
-
-  if ((x < imageW) && (y < imageH)) {
-    // take the average of 4 samples
-
-    // we are using the normalized access to make sure non-power-of-two textures
-    // behave well when downsized.
-    float4 color = (tex2D<float4>(mipInput, (x + 0) * px, (y + 0) * py)) +
-                   (tex2D<float4>(mipInput, (x + 1) * px, (y + 0) * py)) +
-                   (tex2D<float4>(mipInput, (x + 1) * px, (y + 1) * py)) +
-                   (tex2D<float4>(mipInput, (x + 0) * px, (y + 1) * py));
-
-    color /= 4.0;
-    color *= 255.0;
-    color = fminf(color, make_float4(255.0));
-
-    surf2Dwrite(to_uchar4(color), mipOutput, x * sizeof(uchar4), y);
-  }
-}
-
-void generateMipMaps(hipMipmappedArray_t mipmapArray, hipExtent size) {
-  size_t width = size.width;
-  size_t height = size.height;
-
-#ifdef SHOW_MIPMAPS
-  hipArray_t levelFirst;
-  HIPCHECK(hipGetMipmappedArrayLevel(&levelFirst, mipmapArray, 0));
-#endif
-
-  uint level = 0;
-
-  while (width != 1 || height != 1) {
-    width /= 2;
-    width = MAX((size_t)1, width);
-    height /= 2;
-    height = MAX((size_t)1, height);
-
-    hipArray_t levelFrom;
-    HIPCHECK(hipGetMipmappedArrayLevel(&levelFrom, mipmapArray, level));
-    hipArray_t levelTo;
-    HIPCHECK(
-        hipGetMipmappedArrayLevel(&levelTo, mipmapArray, level + 1));
-
-    hipExtent levelToSize;
-    HIPCHECK(cudaArrayGetInfo(NULL, &levelToSize, NULL, levelTo));
-    checkHost(levelToSize.width == width);
-    checkHost(levelToSize.height == height);
-    checkHost(levelToSize.depth == 0);
-
-    // generate texture object for reading
-    hipTextureObject_t texInput;
-    hipResourceDesc texRes;
-    memset(&texRes, 0, sizeof(hipResourceDesc));
-
-    texRes.resType = hipResourceTypeArray;
-    texRes.res.array.array = levelFrom;
-
-    hipTextureDesc texDescr;
-    memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-    texDescr.normalizedCoords = 1;
-    texDescr.filterMode = hipFilterModeLinear;
-
-    texDescr.addressMode[0] = hipAddressModeClamp;
-    texDescr.addressMode[1] = hipAddressModeClamp;
-    texDescr.addressMode[2] = hipAddressModeClamp;
-
-    texDescr.readMode = hipReadModeNormalizedFloat;
-
-    HIPCHECK(
-        hipCreateTextureObject(&texInput, &texRes, &texDescr, NULL));
-
-    // generate surface object for writing
-
-    hipSurfaceObject_t surfOutput;
-    hipResourceDesc surfRes;
-    memset(&surfRes, 0, sizeof(hipResourceDesc));
-    surfRes.resType = hipResourceTypeArray;
-    surfRes.res.array.array = levelTo;
-
-    HIPCHECK(hipCreateSurfaceObject(&surfOutput, &surfRes));
-
-    // run mipmap kernel
-    dim3 blockSize(16, 16, 1);
-    dim3 gridSize(((uint)width + blockSize.x - 1) / blockSize.x,
-                  ((uint)height + blockSize.y - 1) / blockSize.y, 1);
-
-    d_mipmap<<<gridSize, blockSize>>>(surfOutput, texInput, (uint)width,
-                                      (uint)height);
-
-    HIPCHECK(hipDeviceSynchronize());
-    HIPCHECK(hipGetLastError());
-
-    HIPCHECK(hipDestroySurfaceObject(surfOutput));
-
-    HIPCHECK(hipDestroyTextureObject(texInput));
-
-#ifdef SHOW_MIPMAPS
-    // we blit the current mipmap back into first level
-    hipMemcpy3DParms copyParams = {0};
-    copyParams.dstArray = levelFirst;
-    copyParams.srcArray = levelTo;
-    copyParams.extent = make_hipExtent(width, height, 1);
-    copyParams.kind = hipMemcpyDeviceToDevice;
-    HIPCHECK(hipMemcpy3D(&copyParams));
-#endif
-
-    level++;
-  }
-}
-
-uint getMipMapLevels(hipExtent size) {
-  size_t sz = MAX(MAX(size.width, size.height), size.depth);
-
-  uint levels = 0;
-
-  while (sz) {
-    sz /= 2;
-    levels++;
-  }
-
-  return levels;
-}
-
-//////////////////////////////////////////////////////////////////////////
-// Initalization
-
-extern "C" void randomizeAtlas() {
-  uint2 *h_data = (uint2 *)atlasImage.h_data;
-
-  // assign random texture object handles to our atlas image tiles
-  for (size_t i = 0; i < atlasImage.size.width * atlasImage.size.height; i++) {
-#ifdef SHOW_MIPMAPS
-    h_data[i] = encodeTextureObject(contentImages[0].textureObject);
-#else
-    h_data[i] = encodeTextureObject(
-        contentImages[rand() % contentImages.size()].textureObject);
-#endif
-  }
-
-  // copy data to atlas array
-  hipMemcpy3DParms copyParams = {0};
-  copyParams.srcPtr = make_hipPitchedPtr(
-      atlasImage.h_data, atlasImage.size.width * sizeof(uint2),
-      atlasImage.size.width, atlasImage.size.height);
-  copyParams.dstArray = atlasImage.dataArray;
-  copyParams.extent = atlasImage.size;
-  copyParams.extent.depth = 1;
-  copyParams.kind = hipMemcpyHostToDevice;
-  HIPCHECK(hipMemcpy3D(&copyParams));
-};
-
-extern "C" void deinitAtlasAndImages() {
-  for (size_t i = 0; i < contentImages.size(); i++) {
-    Image &image = contentImages[i];
-
-    if (image.h_data) {
-      free(image.h_data);
-    }
-
-    if (image.textureObject) {
-      HIPCHECK(hipDestroyTextureObject(image.textureObject));
-    }
-
-    if (image.mipmapArray) {
-      HIPCHECK(hipFreeMipmappedArray(image.mipmapArray));
-    }
-  }
-
-  if (atlasImage.h_data) {
-    free(atlasImage.h_data);
-  }
-
-  if (atlasImage.textureObject) {
-    HIPCHECK(hipDestroyTextureObject(atlasImage.textureObject));
-  }
-
-  if (atlasImage.dataArray) {
-    HIPCHECK(hipFreeArray(atlasImage.dataArray));
-  }
-}
-
-extern "C" void initAtlasAndImages(const Image *images, size_t numImages,
-                                   hipExtent atlasSize) {
-  // create individual textures
-  contentImages.resize(numImages);
-
-  for (size_t i = 0; i < numImages; i++) {
-    Image &image = contentImages[i];
-    image.size = images[i].size;
-    image.size.depth = 0;
-    image.type = hipResourceTypeMipmappedArray;
-
-    // how many mipmaps we need
-    uint levels = getMipMapLevels(image.size);
-    highestLod = MAX(highestLod, (float)levels - 1);
-
-    hipChannelFormatDesc desc = hipCreateChannelDesc<uchar4>();
-    HIPCHECK(hipMallocMipmappedArray(&image.mipmapArray, &desc,
-                                             image.size, levels));
-
-    // upload level 0
-    hipArray_t level0;
-    HIPCHECK(hipGetMipmappedArrayLevel(&level0, image.mipmapArray, 0));
-
-    hipMemcpy3DParms copyParams = {0};
-    copyParams.srcPtr =
-        make_hipPitchedPtr(images[i].h_data, image.size.width * sizeof(uchar4),
-                            image.size.width, image.size.height);
-    copyParams.dstArray = level0;
-    copyParams.extent = image.size;
-    copyParams.extent.depth = 1;
-    copyParams.kind = hipMemcpyHostToDevice;
-    HIPCHECK(hipMemcpy3D(&copyParams));
-
-    // compute rest of mipmaps based on level 0
-    generateMipMaps(image.mipmapArray, image.size);
-
-    // generate bindless texture object
-
-    hipResourceDesc resDescr;
-    memset(&resDescr, 0, sizeof(hipResourceDesc));
-
-    resDescr.resType = hipResourceTypeMipmappedArray;
-    resDescr.res.mipmap.mipmap = image.mipmapArray;
-
-    hipTextureDesc texDescr;
-    memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-    texDescr.normalizedCoords = 1;
-    texDescr.filterMode = hipFilterModeLinear;
-    texDescr.mipmapFilterMode = hipFilterModeLinear;
-
-    texDescr.addressMode[0] = hipAddressModeClamp;
-    texDescr.addressMode[1] = hipAddressModeClamp;
-    texDescr.addressMode[2] = hipAddressModeClamp;
-
-    texDescr.maxMipmapLevelClamp = float(levels - 1);
-
-    texDescr.readMode = hipReadModeNormalizedFloat;
-
-    HIPCHECK(hipCreateTextureObject(&image.textureObject, &resDescr,
-                                            &texDescr, NULL));
-  }
-
-  // create atlas array
-  hipChannelFormatDesc channelDesc = hipCreateChannelDesc<uint2>();
-  HIPCHECK(hipMallocArray(&atlasImage.dataArray, &channelDesc,
-                                  atlasSize.width, atlasSize.height));
-  atlasImage.h_data =
-      malloc(atlasSize.width * atlasSize.height * sizeof(uint2));
-  atlasImage.type = hipResourceTypeArray;
-  atlasImage.size = atlasSize;
-
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = atlasImage.dataArray;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = true;
-  texDescr.filterMode = hipFilterModePoint;
-  texDescr.addressMode[0] = hipAddressModeClamp;
-  texDescr.addressMode[1] = hipAddressModeClamp;
-  texDescr.addressMode[1] = hipAddressModeClamp;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(hipCreateTextureObject(&atlasImage.textureObject, &texRes,
-                                          &texDescr, NULL));
-
-  randomizeAtlas();
-}
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2017.sln b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2019.sln b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2022.sln b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/bindlessTexture/bindlessTexture_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/data/flower.ppm b/src/samples/Samples/3_CUDA_Features/bindlessTexture/data/flower.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/data/person.ppm b/src/samples/Samples/3_CUDA_Features/bindlessTexture/data/person.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/data/ref_bindlessTexture.bin b/src/samples/Samples/3_CUDA_Features/bindlessTexture/data/ref_bindlessTexture.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/data/sponge.ppm b/src/samples/Samples/3_CUDA_Features/bindlessTexture/data/sponge.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/doc/sshot_lg.JPG b/src/samples/Samples/3_CUDA_Features/bindlessTexture/doc/sshot_lg.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/doc/sshot_md.JPG b/src/samples/Samples/3_CUDA_Features/bindlessTexture/doc/sshot_md.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/doc/sshot_sm.JPG b/src/samples/Samples/3_CUDA_Features/bindlessTexture/doc/sshot_sm.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/bindlessTexture/findgllib.mk b/src/samples/Samples/3_CUDA_Features/bindlessTexture/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/Makefile b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/README.md b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort.cu b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort.cu.hip b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort.cu.hip
old mode 100644
new mode 100755
index 1c43585..e69de29
--- a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort.cu.hip
@@ -1,584 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-////////////////////////////////////////////////////////////////////////////////
-//
-//  cdpAdvancedQuicksort.cu
-//
-//  Implementation of a parallel quicksort in CUDA. It comes in
-//  several parts:
-//
-//  1. A small-set insertion sort. We do this on any set with <=32 elements
-//  2. A partitioning kernel, which - given a pivot - separates an input
-//     array into elements <=pivot, and >pivot. Two quicksorts will then
-//     be launched to resolve each of these.
-//  3. A quicksort co-ordinator, which figures out what kernels to launch
-//     and when.
-//
-////////////////////////////////////////////////////////////////////////////////
-#include <thrust/random.h>
-#include <thrust/device_vector.h>
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-
-#include "helper_cuda_hipified.h"
-#include <helper_string.h>
-#include "cdpQuicksort.h"
-
-////////////////////////////////////////////////////////////////////////////////
-// Inline PTX call to return index of highest non-zero bit in a word
-////////////////////////////////////////////////////////////////////////////////
-static __device__ __forceinline__ unsigned int __qsflo(unsigned int word) {
-  unsigned int ret;
-  asm volatile("bfind.u32 %0, %1;" : "=r"(ret) : "r"(word));
-  return ret;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//
-//  ringbufAlloc
-//
-//  Allocates from a ringbuffer. Allows for not failing when we run out
-//  of stack for tracking the offset counts for each sort subsection.
-//
-//  We use the atomicMax trick to allow out-of-order retirement. If we
-//  hit the size limit on the ringbuffer, then we spin-wait for people
-//  to complete.
-//
-////////////////////////////////////////////////////////////////////////////////
-template <typename T>
-static __device__ T *ringbufAlloc(qsortRingbuf *ringbuf) {
-  // Wait for there to be space in the ring buffer. We'll retry only a fixed
-  // number of times and then fail, to avoid an out-of-memory deadlock.
-  unsigned int loop = 10000;
-
-  while (((ringbuf->head - ringbuf->tail) >= ringbuf->stacksize) &&
-         (loop-- > 0))
-    ;
-
-  if (loop == 0) return NULL;
-
-  // Note that the element includes a little index book-keeping, for freeing
-  // later.
-  unsigned int index = atomicAdd((unsigned int *)&ringbuf->head, 1);
-  T *ret = (T *)(ringbuf->stackbase) + (index & (ringbuf->stacksize - 1));
-  ret->index = index;
-
-  return ret;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//
-//  ringBufFree
-//
-//  Releases an element from the ring buffer. If every element is released
-//  up to and including this one, we can advance the tail to indicate that
-//  space is now available.
-//
-////////////////////////////////////////////////////////////////////////////////
-template <typename T>
-static __device__ void ringbufFree(qsortRingbuf *ringbuf, T *data) {
-  unsigned int index = data->index;  // Non-wrapped index to free
-  unsigned int count = atomicAdd((unsigned int *)&(ringbuf->count), 1) + 1;
-  unsigned int max = atomicMax((unsigned int *)&(ringbuf->max), index + 1);
-
-  // Update the tail if need be. Note we update "max" to be the new value in
-  // ringbuf->max
-  if (max < (index + 1)) max = index + 1;
-
-  if (max == count) atomicMax((unsigned int *)&(ringbuf->tail), count);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//
-//  qsort_warp
-//
-//  Simplest possible implementation, does a per-warp quicksort with no
-//  inter-warp
-//  communication. This has a high atomic issue rate, but the rest should
-//  actually
-//  be fairly quick because of low work per thread.
-//
-//  A warp finds its section of the data, then writes all data <pivot to one
-//  buffer and all data >pivot to the other. Atomics are used to get a unique
-//  section of the buffer.
-//
-//  Obvious optimisation: do multiple chunks per warp, to increase in-flight
-//  loads
-//  and cover the instruction overhead.
-//
-////////////////////////////////////////////////////////////////////////////////
-__global__ void qsort_warp(unsigned *indata, unsigned *outdata,
-                           unsigned int offset, unsigned int len,
-                           qsortAtomicData *atomicData,
-                           qsortRingbuf *atomicDataStack,
-                           unsigned int source_is_indata, unsigned int depth) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  // Find my data offset, based on warp ID
-  unsigned int thread_id = threadIdx.x + (blockIdx.x << QSORT_BLOCKSIZE_SHIFT);
-  // unsigned int warp_id = threadIdx.x >> 5;   // Used for debug only
-  unsigned int lane_id = threadIdx.x & (warpSize - 1);
-
-  // Exit if I'm outside the range of sort to be done
-  if (thread_id >= len) return;
-
-  //
-  // First part of the algorithm. Each warp counts the number of elements that
-  // are
-  // greater/less than the pivot.
-  //
-  // When a warp knows its count, it updates an atomic counter.
-  //
-
-  // Read in the data and the pivot. Arbitrary pivot selection for now.
-  unsigned pivot = indata[offset + len / 2];
-  unsigned data = indata[offset + thread_id];
-
-  // Count how many are <= and how many are > pivot.
-  // If all are <= pivot then we adjust the comparison
-  // because otherwise the sort will move nothing and
-  // we'll iterate forever.
-  cg::coalesced_group active = cg::coalesced_threads();
-  unsigned int greater = (data > pivot);
-  unsigned int gt_mask = active.ballot(greater);
-
-  if (gt_mask == 0) {
-    greater = (data >= pivot);
-    gt_mask = active.ballot(greater);  // Must re-ballot for adjusted comparator
-  }
-
-  unsigned int lt_mask = active.ballot(!greater);
-  unsigned int gt_count = __popc(gt_mask);
-  unsigned int lt_count = __popc(lt_mask);
-
-  // Atomically adjust the lt_ and gt_offsets by this amount. Only one thread
-  // need do this. Share the result using shfl
-  unsigned int lt_offset, gt_offset;
-
-  if (lane_id == 0) {
-    if (lt_count > 0)
-      lt_offset = atomicAdd((unsigned int *)&atomicData->lt_offset, lt_count);
-
-    if (gt_count > 0)
-      gt_offset =
-          len - (atomicAdd((unsigned int *)&atomicData->gt_offset, gt_count) +
-                 gt_count);
-  }
-
-  lt_offset =
-      active.shfl((int)lt_offset, 0);  // Everyone pulls the offsets from lane 0
-  gt_offset = active.shfl((int)gt_offset, 0);
-
-  // Now compute my own personal offset within this. I need to know how many
-  // threads with a lane ID less than mine are going to write to the same buffer
-  // as me. We can use popc to implement a single-operation warp scan in this
-  // case.
-  unsigned lane_mask_lt;
-  asm("mov.u32 %0, %%lanemask_lt;" : "=r"(lane_mask_lt));
-  unsigned int my_mask = greater ? gt_mask : lt_mask;
-  unsigned int my_offset = __popc(my_mask & lane_mask_lt);
-
-  // Move data.
-  my_offset += greater ? gt_offset : lt_offset;
-  outdata[offset + my_offset] = data;
-
-  // Count up if we're the last warp in. If so, then Kepler will launch the next
-  // set of sorts directly from here.
-  if (lane_id == 0) {
-    // Count "elements written". If I wrote the last one, then trigger the next
-    // qsorts
-    unsigned int mycount = lt_count + gt_count;
-
-    if (atomicAdd((unsigned int *)&atomicData->sorted_count, mycount) +
-            mycount ==
-        len) {
-      // We're the last warp to do any sorting. Therefore it's up to us to
-      // launch the next stage.
-      unsigned int lt_len = atomicData->lt_offset;
-      unsigned int gt_len = atomicData->gt_offset;
-
-      hipStream_t lstream, rstream;
-      hipStreamCreateWithFlags(&lstream, hipStreamNonBlocking);
-      hipStreamCreateWithFlags(&rstream, hipStreamNonBlocking);
-
-      // Begin by freeing our atomicData storage. It's better for the ringbuffer
-      // algorithm
-      // if we free when we're done, rather than re-using (makes for less
-      // fragmentation).
-      ringbufFree<qsortAtomicData>(atomicDataStack, atomicData);
-
-      // Exceptional case: if "lt_len" is zero, then all values in the batch
-      // are equal. We are then done (may need to copy into correct buffer,
-      // though)
-      if (lt_len == 0) {
-        if (source_is_indata)
-          hipMemcpyAsync(indata + offset, outdata + offset,
-                          gt_len * sizeof(unsigned), hipMemcpyDeviceToDevice,
-                          lstream);
-
-        return;
-      }
-
-      // Start with lower half first
-      if (lt_len > BITONICSORT_LEN) {
-        // If we've exceeded maximum depth, fall through to backup
-        // big_bitonicsort
-        if (depth >= QSORT_MAXDEPTH) {
-          // The final bitonic stage sorts in-place in "outdata". We therefore
-          // re-use "indata" as the out-of-range tracking buffer. For (2^n)+1
-          // elements we need (2^(n+1)) bytes of oor buffer. The backup qsort
-          // buffer is at least this large when sizeof(QTYPE) >= 2.
-          big_bitonicsort<<<1, BITONICSORT_LEN, 0, lstream>>>(
-              outdata, source_is_indata ? indata : outdata, indata, offset,
-              lt_len);
-        } else {
-          // Launch another quicksort. We need to allocate more storage for the
-          // atomic data.
-          if ((atomicData = ringbufAlloc<qsortAtomicData>(atomicDataStack)) ==
-              NULL)
-            printf("Stack-allocation error. Failing left child launch.\n");
-          else {
-            atomicData->lt_offset = atomicData->gt_offset =
-                atomicData->sorted_count = 0;
-            unsigned int numblocks =
-                (unsigned int)(lt_len + (QSORT_BLOCKSIZE - 1)) >>
-                QSORT_BLOCKSIZE_SHIFT;
-            qsort_warp<<<numblocks, QSORT_BLOCKSIZE, 0, lstream>>>(
-                outdata, indata, offset, lt_len, atomicData, atomicDataStack,
-                !source_is_indata, depth + 1);
-          }
-        }
-      } else if (lt_len > 1) {
-        // Final stage uses a bitonic sort instead. It's important to
-        // make sure the final stage ends up in the correct (original) buffer.
-        // We launch the smallest power-of-2 number of threads that we can.
-        unsigned int bitonic_len = 1 << (__qsflo(lt_len - 1U) + 1);
-        bitonicsort<<<1, bitonic_len, 0, lstream>>>(
-            outdata, source_is_indata ? indata : outdata, offset, lt_len);
-      }
-      // Finally, if we sorted just one single element, we must still make
-      // sure that it winds up in the correct place.
-      else if (source_is_indata && (lt_len == 1))
-        indata[offset] = outdata[offset];
-
-      if (hipPeekAtLastError() != hipSuccess)
-        printf("Left-side launch fail: %s\n",
-               hipGetErrorString(hipGetLastError()));
-
-      // Now the upper half.
-      if (gt_len > BITONICSORT_LEN) {
-        // If we've exceeded maximum depth, fall through to backup
-        // big_bitonicsort
-        if (depth >= QSORT_MAXDEPTH)
-          big_bitonicsort<<<1, BITONICSORT_LEN, 0, rstream>>>(
-              outdata, source_is_indata ? indata : outdata, indata,
-              offset + lt_len, gt_len);
-        else {
-          // Allocate new atomic storage for this launch
-          if ((atomicData = ringbufAlloc<qsortAtomicData>(atomicDataStack)) ==
-              NULL)
-            printf("Stack allocation error! Failing right-side launch.\n");
-          else {
-            atomicData->lt_offset = atomicData->gt_offset =
-                atomicData->sorted_count = 0;
-            unsigned int numblocks =
-                (unsigned int)(gt_len + (QSORT_BLOCKSIZE - 1)) >>
-                QSORT_BLOCKSIZE_SHIFT;
-            qsort_warp<<<numblocks, QSORT_BLOCKSIZE, 0, rstream>>>(
-                outdata, indata, offset + lt_len, gt_len, atomicData,
-                atomicDataStack, !source_is_indata, depth + 1);
-          }
-        }
-      } else if (gt_len > 1) {
-        unsigned int bitonic_len = 1 << (__qsflo(gt_len - 1U) + 1);
-        bitonicsort<<<1, bitonic_len, 0, rstream>>>(
-            outdata, source_is_indata ? indata : outdata, offset + lt_len,
-            gt_len);
-      } else if (source_is_indata && (gt_len == 1))
-        indata[offset + lt_len] = outdata[offset + lt_len];
-
-      if (hipPeekAtLastError() != hipSuccess)
-        printf("Right-side launch fail: %s\n",
-               hipGetErrorString(hipGetLastError()));
-    }
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//
-//  run_quicksort
-//
-//  Host-side code to run the Kepler version of quicksort. It's pretty
-//  simple, because all launch control is handled on the device via CDP.
-//
-//  All parallel quicksorts require an equal-sized scratch buffer. This
-//  must be passed in ahead of time.
-//
-//  Returns the time elapsed for the sort.
-//
-////////////////////////////////////////////////////////////////////////////////
-float run_quicksort_cdp(unsigned *gpudata, unsigned *scratchdata,
-                        unsigned int count, hipStream_t stream) {
-  unsigned int stacksize = QSORT_STACK_ELEMS;
-
-  // This is the stack, for atomic tracking of each sort's status
-  qsortAtomicData *gpustack;
-  HIPCHECK(
-      hipMalloc((void **)&gpustack, stacksize * sizeof(qsortAtomicData)));
-  HIPCHECK(hipMemset(
-      gpustack, 0, sizeof(qsortAtomicData)));  // Only need set first entry to 0
-
-  // Create the memory ringbuffer used for handling the stack.
-  // Initialise everything to where it needs to be.
-  qsortRingbuf buf;
-  qsortRingbuf *ringbuf;
-  HIPCHECK(hipMalloc((void **)&ringbuf, sizeof(qsortRingbuf)));
-  buf.head = 1;  // We start with one allocation
-  buf.tail = 0;
-  buf.count = 0;
-  buf.max = 0;
-  buf.stacksize = stacksize;
-  buf.stackbase = gpustack;
-  HIPCHECK(
-      hipMemcpy(ringbuf, &buf, sizeof(buf), hipMemcpyHostToDevice));
-
-  // Timing events...
-  hipEvent_t ev1, ev2;
-  HIPCHECK(hipEventCreate(&ev1));
-  HIPCHECK(hipEventCreate(&ev2));
-  HIPCHECK(hipEventRecord(ev1));
-
-  // Now we trivially launch the qsort kernel
-  if (count > BITONICSORT_LEN) {
-    unsigned int numblocks =
-        (unsigned int)(count + (QSORT_BLOCKSIZE - 1)) >> QSORT_BLOCKSIZE_SHIFT;
-    qsort_warp<<<numblocks, QSORT_BLOCKSIZE, 0, stream>>>(
-        gpudata, scratchdata, 0U, count, gpustack, ringbuf, true, 0);
-  } else {
-    bitonicsort<<<1, BITONICSORT_LEN>>>(gpudata, gpudata, 0, count);
-  }
-
-  HIPCHECK(hipGetLastError());
-  HIPCHECK(hipEventRecord(ev2));
-  HIPCHECK(hipDeviceSynchronize());
-
-  float elapse = 0.0f;
-
-  if (hipPeekAtLastError() != hipSuccess)
-    printf("Launch failure: %s\n", hipGetErrorString(hipGetLastError()));
-  else
-    HIPCHECK(hipEventElapsedTime(&elapse, ev1, ev2));
-
-  // Sanity check that the stack allocator is doing the right thing
-  HIPCHECK(
-      hipMemcpy(&buf, ringbuf, sizeof(*ringbuf), hipMemcpyDeviceToHost));
-
-  if (count > BITONICSORT_LEN && buf.head != buf.tail) {
-    printf("Stack allocation error!\nRingbuf:\n");
-    printf("\t head = %u\n", buf.head);
-    printf("\t tail = %u\n", buf.tail);
-    printf("\tcount = %u\n", buf.count);
-    printf("\t  max = %u\n", buf.max);
-  }
-
-  // Release our stack data once we're done
-  HIPCHECK(hipFree(ringbuf));
-  HIPCHECK(hipFree(gpustack));
-
-  return elapse;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-////////////////////////////////////////////////////////////////////////////////
-int run_qsort(unsigned int size, int seed, int debug, int loop, int verbose) {
-  if (seed > 0) srand(seed);
-
-  // Create and set up our test
-  unsigned *gpudata, *scratchdata;
-  HIPCHECK(hipMalloc((void **)&gpudata, size * sizeof(unsigned)));
-  HIPCHECK(hipMalloc((void **)&scratchdata, size * sizeof(unsigned)));
-
-  // Create CPU data.
-  unsigned *data = new unsigned[size];
-  unsigned int min = loop ? loop : size;
-  unsigned int max = size;
-  loop = (loop == 0) ? 1 : loop;
-
-  for (size = min; size <= max; size += loop) {
-    if (verbose) printf(" Input: ");
-
-    for (unsigned int i = 0; i < size; i++) {
-      // Build data 8 bits at a time
-      data[i] = 0;
-      char *ptr = (char *)&(data[i]);
-
-      for (unsigned j = 0; j < sizeof(unsigned); j++) {
-        // Easy-to-read data in debug mode
-        if (debug) {
-          *ptr++ = (char)(rand() % 10);
-          break;
-        }
-
-        *ptr++ = (char)(rand() & 255);
-      }
-
-      if (verbose) {
-        if (i && !(i % 32)) printf("\n        ");
-
-        printf("%u ", data[i]);
-      }
-    }
-
-    if (verbose) printf("\n");
-
-    HIPCHECK(hipMemcpy(gpudata, data, size * sizeof(unsigned),
-                               hipMemcpyHostToDevice));
-
-    // So we're now populated and ready to go! We size our launch as
-    // blocks of up to BLOCKSIZE threads, and appropriate grid size.
-    // One thread is launched per element.
-    float elapse;
-    elapse = run_quicksort_cdp(gpudata, scratchdata, size, NULL);
-
-    // run_bitonicsort<SORTTYPE>(gpudata, scratchdata, size, verbose);
-    HIPCHECK(hipDeviceSynchronize());
-
-    // Copy back the data and verify correct sort
-    HIPCHECK(hipMemcpy(data, gpudata, size * sizeof(unsigned),
-                               hipMemcpyDeviceToHost));
-
-    if (verbose) {
-      printf("Output: ");
-
-      for (unsigned int i = 0; i < size; i++) {
-        if (i && !(i % 32)) printf("\n        ");
-
-        printf("%u ", data[i]);
-      }
-
-      printf("\n");
-    }
-
-    unsigned int check;
-
-    for (check = 1; check < size; check++) {
-      if (data[check] < data[check - 1]) {
-        printf("FAILED at element: %d\n", check);
-        break;
-      }
-    }
-
-    if (check != size) {
-      printf("    cdpAdvancedQuicksort FAILED\n");
-      exit(EXIT_FAILURE);
-    } else
-      printf("    cdpAdvancedQuicksort PASSED\n");
-
-    // Display the time between event recordings
-    printf("Sorted %u elems in %.3f ms (%.3f Melems/sec)\n", size, elapse,
-           (float)size / (elapse * 1000.0f));
-    fflush(stdout);
-  }
-
-  // Release everything and we're done
-  HIPCHECK(hipFree(scratchdata));
-  HIPCHECK(hipFree(gpudata));
-  delete (data);
-  return 0;
-}
-
-static void usage() {
-  printf(
-      "Syntax: cdpAdvancedQuicksort [-size=<num>] [-seed=<num>] [-debug] "
-      "[-loop-step=<num>] [-verbose]\n");
-  printf(
-      "If loop_step is non-zero, will run from 1->array_len in steps of "
-      "loop_step\n");
-}
-
-// Host side entry
-int main(int argc, char *argv[]) {
-  int size = 1000000;
-  unsigned int seed = 0;
-  int debug = 0;
-  int loop = 0;
-  int verbose = 0;
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "help") ||
-      checkCmdLineFlag(argc, (const char **)argv, "h")) {
-    usage();
-    printf("&&&& cdpAdvancedQuicksort WAIVED\n");
-    exit(EXIT_WAIVED);
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "size")) {
-    size = getCmdLineArgumentInt(argc, (const char **)argv, "size");
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "seed")) {
-    seed = getCmdLineArgumentInt(argc, (const char **)argv, "seed");
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "loop-step")) {
-    loop = getCmdLineArgumentInt(argc, (const char **)argv, "loop-step");
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "debug")) {
-    debug = 1;
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "verbose")) {
-    verbose = 1;
-  }
-
-  // Get device properties
-  int cuda_device = findCudaDevice(argc, (const char **)argv);
-  hipDeviceProp_t properties;
-  HIPCHECK(hipGetDeviceProperties(&properties, cuda_device));
-  int cdpCapable =
-      (properties.major == 3 && properties.minor >= 5) || properties.major >= 4;
-
-  printf("GPU device %s has compute capabilities (SM %d.%d)\n", properties.name,
-         properties.major, properties.minor);
-
-  if (!cdpCapable) {
-    printf(
-        "cdpAdvancedQuicksort requires SM 3.5 or higher to use CUDA Dynamic "
-        "Parallelism.  Exiting...\n");
-    exit(EXIT_WAIVED);
-  }
-
-  printf("Running qsort on %d elements with seed %d, on %s\n", size, seed,
-         properties.name);
-
-  run_qsort(size, seed, debug, loop, verbose);
-
-  exit(EXIT_SUCCESS);
-}
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2017.sln b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2019.sln b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2022.sln b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpAdvancedQuicksort_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpBitonicSort.cu b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpBitonicSort.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpBitonicSort.cu.hip b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpBitonicSort.cu.hip
old mode 100644
new mode 100755
index 117489d..e69de29
--- a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpBitonicSort.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpBitonicSort.cu.hip
@@ -1,289 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// This is a basic, recursive bitonic sort taken from
-// http://www.iti.fh-flensburg.de/lang/algorithmen/sortieren/bitonic/oddn.htm
-//
-// The parallel code is based on:
-// http://www.tools-of-computing.com/tc/CS/Sorts/bitonic_sort.htm
-//
-// The multithread code is from me.
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-
-#include "cdpQuicksort.h"
-
-// Inline PTX call to return index of highest non-zero bit in a word
-static __device__ __forceinline__ unsigned int __btflo(unsigned int word) {
-  unsigned int ret;
-  asm volatile("bfind.u32 %0, %1;" : "=r"(ret) : "r"(word));
-  return ret;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//
-//  qcompare
-//
-//  Comparison function. Note difference from libc standard in
-//  that we take by reference, not by pointer. I can't figure
-//  out how to get a template-to-pointer specialisation working.
-//  Perhaps it requires a class?
-//
-////////////////////////////////////////////////////////////////////////////////
-__device__ __forceinline__ int qcompare(unsigned &val1, unsigned &val2) {
-  return (val1 > val2) ? 1 : (val1 == val2) ? 0 : -1;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//
-//  Basic any-N bitonic sort. We sort "len" elements of "indata", starting
-//  from the "offset" elements into the input data array. Note that "outdata"
-//  can safely be the same as "indata" for an in-place sort (we stage through
-//  shared memory).
-//
-//  We handle non-power-of-2 sizes by padding out to the next largest power of
-//  2.
-//  This is the fully-generic version, for sorting arbitrary data which does not
-//  have a clear "maximum" value. We track "invalid" entries in a separate array
-//  to make sure that they always sorts as "max value" elements. A template
-//  parameter "OOR" allows specialisation to optimise away the invalid tracking.
-//
-//  We can do a more specialised version for int/longlong/flat/double, in which
-//  we pad out the array with max-value-of-type elements. That's another
-//  function.
-//
-//  The last step copies from indata -> outdata... the rest is done in-place.
-//  We use shared memory as temporary storage, which puts an upper limit on
-//  how much data we can sort per block.
-//
-////////////////////////////////////////////////////////////////////////////////
-static __device__ __forceinline__ void bitonicsort_kernel(
-    unsigned *indata, unsigned *outdata, unsigned int offset, unsigned int len,
-    cg::thread_block cta) {
-  __shared__ unsigned
-      sortbuf[1024];  // Max of 1024 elements - TODO: make this dynamic
-
-  // First copy data into shared memory.
-  unsigned int inside = (threadIdx.x < len);
-  sortbuf[threadIdx.x] = inside ? indata[threadIdx.x + offset] : 0xffffffffu;
-  cg::sync(cta);
-
-  // Now the sort loops
-  // Here, "k" is the sort level (remember bitonic does a multi-level butterfly
-  // style sort)
-  // and "j" is the partner element in the butterfly.
-  // Two threads each work on one butterfly, because the read/write needs to
-  // happen
-  // simultaneously
-  for (unsigned int k = 2; k <= blockDim.x;
-       k *= 2)  // Butterfly stride increments in powers of 2
-  {
-    for (unsigned int j = k >> 1; j > 0;
-         j >>= 1)  // Strides also in powers of to, up to <k
-    {
-      unsigned int swap_idx =
-          threadIdx.x ^ j;  // Index of element we're compare-and-swapping with
-      unsigned my_elem = sortbuf[threadIdx.x];
-      unsigned swap_elem = sortbuf[swap_idx];
-
-      cg::sync(cta);
-
-      // The k'th bit of my threadid (and hence my sort item ID)
-      // determines if we sort ascending or descending.
-      // However, since threads are reading from the top AND the bottom of
-      // the butterfly, if my ID is > swap_idx, then ascending means mine<swap.
-      // Finally, if either my_elem or swap_elem is out of range, then it
-      // ALWAYS acts like it's the largest number.
-      // Confusing? It saves us two writes though.
-      unsigned int ascend = k * (swap_idx < threadIdx.x);
-      unsigned int descend = k * (swap_idx > threadIdx.x);
-      bool swap = false;
-
-      if ((threadIdx.x & k) == ascend) {
-        if (my_elem > swap_elem) swap = true;
-      }
-
-      if ((threadIdx.x & k) == descend) {
-        if (my_elem < swap_elem) swap = true;
-      }
-
-      // If we had to swap, then write my data to the other element's position.
-      // Don't forget to track out-of-range status too!
-      if (swap) {
-        sortbuf[swap_idx] = my_elem;
-      }
-
-      cg::sync(cta);
-    }
-  }
-
-  // Copy the sorted data from shared memory back to the output buffer
-  if (threadIdx.x < len) outdata[threadIdx.x + offset] = sortbuf[threadIdx.x];
-}
-
-//////////////////////////////////////////////////////////////////////////////////
-//  This is an emergency-CTA sort, which sorts an arbitrary sized chunk
-//  using a single block. Useful for if qsort runs out of nesting depth.
-//
-//  Note that bitonic sort needs enough storage to pad up to the nearest
-//  power of 2. This means that the double-buffer is always large enough
-//  (when combined with the main buffer), but we do not get enough space
-//  to keep OOR information.
-//
-//  This in turn means that this sort does not work with a generic data
-//  type. It must be a directly-comparable (i.e. with max value) type.
-//
-////////////////////////////////////////////////////////////////////////////////
-static __device__ __forceinline__ void big_bitonicsort_kernel(
-    unsigned *indata, unsigned *outdata, unsigned *backbuf, unsigned int offset,
-    unsigned int len, cg::thread_block cta) {
-  unsigned int len2 =
-      1 << (__btflo(len - 1U) + 1);  // Round up len to nearest power-of-2
-
-  if (threadIdx.x >= len2)
-    return;  // Early out for case where more threads launched than there is
-             // data
-
-  // First, set up our unused values to be the max data type.
-  for (unsigned int i = len; i < len2; i += blockDim.x) {
-    unsigned int index = i + threadIdx.x;
-
-    if (index < len2) {
-      // Must split our index between two buffers
-      if (index < len)
-        indata[index + offset] = 0xffffffffu;
-      else
-        backbuf[index + offset - len] = 0xffffffffu;
-    }
-  }
-
-  cg::sync(cta);
-
-  // Now the sort loops
-  // Here, "k" is the sort level (remember bitonic does a multi-level butterfly
-  // style sort)
-  // and "j" is the partner element in the butterfly.
-  // Two threads each work on one butterfly, because the read/write needs to
-  // happen
-  // simultaneously
-  for (unsigned int k = 2; k <= len2;
-       k *= 2)  // Butterfly stride increments in powers of 2
-  {
-    for (unsigned int j = k >> 1; j > 0;
-         j >>= 1)  // Strides also in powers of to, up to <k
-    {
-      for (unsigned int i = 0; i < len2; i += blockDim.x) {
-        unsigned int index = threadIdx.x + i;
-        unsigned int swap_idx =
-            index ^ j;  // Index of element we're compare-and-swapping with
-
-        // Only do the swap for index<swap_idx (avoids collision between other
-        // threads)
-        if (swap_idx > index) {
-          unsigned my_elem, swap_elem;
-
-          if (index < len)
-            my_elem = indata[index + offset];
-          else
-            my_elem = backbuf[index + offset - len];
-
-          if (swap_idx < len)
-            swap_elem = indata[swap_idx + offset];
-          else
-            swap_elem = backbuf[swap_idx + offset - len];
-
-          // The k'th bit of my index (and hence my sort item ID)
-          // determines if we sort ascending or descending.
-          // Also, if either my_elem or swap_elem is out of range, then it
-          // ALWAYS acts like it's the largest number.
-          bool swap = false;
-
-          if ((index & k) == 0) {
-            if (my_elem > swap_elem) swap = true;
-          }
-
-          if ((index & k) == k) {
-            if (my_elem < swap_elem) swap = true;
-          }
-
-          // If we had to swap, then write my data to the other element's
-          // position.
-          if (swap) {
-            if (swap_idx < len)
-              indata[swap_idx + offset] = my_elem;
-            else
-              backbuf[swap_idx + offset - len] = my_elem;
-
-            if (index < len)
-              indata[index + offset] = swap_elem;
-            else
-              backbuf[index + offset - len] = swap_elem;
-          }
-        }
-      }
-
-      cg::sync(cta);  // Only need to sync for each "j" pass
-    }
-  }
-
-  // Copy the sorted data from the input to the output buffer, because we sort
-  // in-place
-  if (outdata != indata) {
-    for (unsigned int i = 0; i < len; i += blockDim.x) {
-      unsigned int index = i + threadIdx.x;
-
-      if (index < len) outdata[index + offset] = indata[index + offset];
-    }
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// KERNELS
-////////////////////////////////////////////////////////////////////////////////
-
-__global__ void bitonicsort(unsigned *indata, unsigned *outdata,
-                            unsigned int offset, unsigned int len) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  bitonicsort_kernel(indata, outdata, offset, len, cta);
-}
-
-__global__ void big_bitonicsort(unsigned *indata, unsigned *outdata,
-                                unsigned *backbuf, unsigned int offset,
-                                unsigned int len) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  big_bitonicsort_kernel(indata, outdata, backbuf, offset, len, cta);
-}
-
-////////////////////////////////////////////////////////////////////////////////
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpQuicksort.h b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpQuicksort.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpQuicksort_hipified.h b/src/samples/Samples/3_CUDA_Features/cdpAdvancedQuicksort/cdpQuicksort_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/BezierLineCDP.cu b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/BezierLineCDP.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/BezierLineCDP.cu.hip b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/BezierLineCDP.cu.hip
old mode 100644
new mode 100755
index 401f217..e69de29
--- a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/BezierLineCDP.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/BezierLineCDP.cu.hip
@@ -1,210 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <hip/hip_runtime_api.h>
-#include "helper_cuda_hipified.h"
-#include <string.h>
-
-__forceinline__ __device__ float2 operator+(float2 a, float2 b) {
-  float2 c;
-  c.x = a.x + b.x;
-  c.y = a.y + b.y;
-  return c;
-}
-
-__forceinline__ __device__ float2 operator-(float2 a, float2 b) {
-  float2 c;
-  c.x = a.x - b.x;
-  c.y = a.y - b.y;
-  return c;
-}
-
-__forceinline__ __device__ float2 operator*(float a, float2 b) {
-  float2 c;
-  c.x = a * b.x;
-  c.y = a * b.y;
-  return c;
-}
-
-__forceinline__ __device__ float length(float2 a) {
-  return sqrtf(a.x * a.x + a.y * a.y);
-}
-
-#define MAX_TESSELLATION 32
-struct BezierLine {
-  float2 CP[3];
-  float2 *vertexPos;
-  int nVertices;
-};
-
-__global__ void computeBezierLinePositions(int lidx, BezierLine *bLines,
-                                           int nTessPoints) {
-  int idx = threadIdx.x + blockDim.x * blockIdx.x;
-
-  if (idx < nTessPoints) {
-    float u = (float)idx / (float)(nTessPoints - 1);
-    float omu = 1.0f - u;
-
-    float B3u[3];
-
-    B3u[0] = omu * omu;
-    B3u[1] = 2.0f * u * omu;
-    B3u[2] = u * u;
-
-    float2 position = {0, 0};
-
-    for (int i = 0; i < 3; i++) {
-      position = position + B3u[i] * bLines[lidx].CP[i];
-    }
-
-    bLines[lidx].vertexPos[idx] = position;
-  }
-}
-
-__global__ void computeBezierLinesCDP(BezierLine *bLines, int nLines) {
-  int lidx = threadIdx.x + blockDim.x * blockIdx.x;
-
-  if (lidx < nLines) {
-    float curvature = length(bLines[lidx].CP[1] -
-                             0.5f * (bLines[lidx].CP[0] + bLines[lidx].CP[2])) /
-                      length(bLines[lidx].CP[2] - bLines[lidx].CP[0]);
-    int nTessPoints = min(max((int)(curvature * 16.0f), 4), MAX_TESSELLATION);
-
-    if (bLines[lidx].vertexPos == NULL) {
-      bLines[lidx].nVertices = nTessPoints;
-      hipMalloc((void **)&bLines[lidx].vertexPos,
-                 nTessPoints * sizeof(float2));
-    }
-
-    computeBezierLinePositions<<<ceilf((float)bLines[lidx].nVertices / 32.0f),
-                                 32>>>(lidx, bLines, bLines[lidx].nVertices);
-  }
-}
-
-__global__ void freeVertexMem(BezierLine *bLines, int nLines) {
-  int lidx = threadIdx.x + blockDim.x * blockIdx.x;
-
-  if (lidx < nLines) hipFree(bLines[lidx].vertexPos);
-}
-
-unsigned int checkCapableSM35Device(int argc, char **argv) {
-  // Get device properties
-  hipDeviceProp_t properties;
-  int device_count = 0, device = -1;
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "device")) {
-    device = getCmdLineArgumentInt(argc, (const char **)argv, "device");
-
-    hipDeviceProp_t properties;
-    HIPCHECK(hipGetDeviceProperties(&properties, device));
-
-    if (properties.major > 3 ||
-        (properties.major == 3 && properties.minor >= 5)) {
-      printf("Running on GPU  %d (%s)\n", device, properties.name);
-    } else {
-      printf(
-          "cdpBezierTessellation requires GPU devices with compute SM 3.5 or "
-          "higher.");
-      printf("Current GPU device has compute SM %d.%d. Exiting...\n",
-             properties.major, properties.minor);
-      return EXIT_FAILURE;
-    }
-
-  } else {
-    HIPCHECK(hipGetDeviceCount(&device_count));
-
-    for (int i = 0; i < device_count; ++i) {
-      HIPCHECK(hipGetDeviceProperties(&properties, i));
-
-      if (properties.major > 3 ||
-          (properties.major == 3 && properties.minor >= 5)) {
-        device = i;
-        printf("Running on GPU %d (%s)\n", i, properties.name);
-        break;
-      }
-
-      printf("GPU %d %s does not support CUDA Dynamic Parallelism\n", i,
-             properties.name);
-    }
-  }
-  if (device == -1) {
-    fprintf(stderr,
-            "cdpBezierTessellation requires GPU devices with compute SM 3.5 or "
-            "higher.  Exiting...\n");
-    return EXIT_WAIVED;
-  }
-
-  return EXIT_SUCCESS;
-}
-
-#define N_LINES 256
-#define BLOCK_DIM 64
-int main(int argc, char **argv) {
-  BezierLine *bLines_h = new BezierLine[N_LINES];
-
-  float2 last = {0, 0};
-
-  for (int i = 0; i < N_LINES; i++) {
-    bLines_h[i].CP[0] = last;
-
-    for (int j = 1; j < 3; j++) {
-      bLines_h[i].CP[j].x = (float)rand() / (float)RAND_MAX;
-      bLines_h[i].CP[j].y = (float)rand() / (float)RAND_MAX;
-    }
-
-    last = bLines_h[i].CP[2];
-    bLines_h[i].vertexPos = NULL;
-    bLines_h[i].nVertices = 0;
-  }
-
-  unsigned int sm35Ret = checkCapableSM35Device(argc, argv);
-  if (sm35Ret != EXIT_SUCCESS) {
-    exit(sm35Ret);
-  }
-
-  BezierLine *bLines_d;
-  HIPCHECK(hipMalloc((void **)&bLines_d, N_LINES * sizeof(BezierLine)));
-  HIPCHECK(hipMemcpy(bLines_d, bLines_h, N_LINES * sizeof(BezierLine),
-                             hipMemcpyHostToDevice));
-  printf("Computing Bezier Lines (CUDA Dynamic Parallelism Version) ... ");
-  computeBezierLinesCDP<<<(unsigned int)ceil((float)N_LINES / (float)BLOCK_DIM),
-                          BLOCK_DIM>>>(bLines_d, N_LINES);
-  printf("Done!\n");
-
-  // Do something to draw the lines here
-
-  freeVertexMem<<<(unsigned int)ceil((float)N_LINES / (float)BLOCK_DIM),
-                  BLOCK_DIM>>>(bLines_d, N_LINES);
-  HIPCHECK(hipFree(bLines_d));
-  delete[] bLines_h;
-
-  exit(EXIT_SUCCESS);
-}
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/Makefile b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/README.md b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2017.sln b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2019.sln b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2022.sln b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpBezierTessellation/cdpBezierTessellation_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/Makefile b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/README.md b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu.hip b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu.hip
old mode 100644
new mode 100755
index 3123b0f..5906937
--- a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree.cu.hip
@@ -32,7 +32,7 @@
 #include <hip/hip_cooperative_groups.h>
 
 namespace cg = cooperative_groups;
-#include "helper_cuda_hipified.h"
+#include <helper_cuda.h>
 
 ////////////////////////////////////////////////////////////////////////////////
 // A structure of 2D points (structure of arrays).
@@ -654,8 +654,8 @@ bool cdpQuadtree(int warp_size) {
 
   // Allocate memory to store points.
   Points *points;
-  HIPCHECK(hipMalloc((void **)&points, 2 * sizeof(Points)));
-  HIPCHECK(hipMemcpy(points, points_init, 2 * sizeof(Points),
+  checkCudaErrors(hipMalloc((void **)&points, 2 * sizeof(Points)));
+  checkCudaErrors(hipMemcpy(points, points_init, 2 * sizeof(Points),
                              hipMemcpyHostToDevice));
 
   // We could use a close form...
@@ -669,11 +669,14 @@ bool cdpQuadtree(int warp_size) {
   Quadtree_node root;
   root.set_range(0, num_points);
   Quadtree_node *nodes;
-  HIPCHECK(
+  checkCudaErrors(
       hipMalloc((void **)&nodes, max_nodes * sizeof(Quadtree_node)));
-  HIPCHECK(
+  checkCudaErrors(
       hipMemcpy(nodes, &root, sizeof(Quadtree_node), hipMemcpyHostToDevice));
 
+  // We set the recursion limit for CDP to max_depth.
+  hipDeviceSetLimit(cudaLimitDevRuntimeSyncDepth, max_depth);
+
   // Build the quadtree.
   Parameters params(max_depth, min_points_per_node);
   std::cout << "Launching CDP kernel to build the quadtree" << std::endl;
@@ -683,7 +686,7 @@ bool cdpQuadtree(int warp_size) {
   build_quadtree_kernel<
       NUM_THREADS_PER_BLOCK><<<1, NUM_THREADS_PER_BLOCK, smem_size>>>(
       nodes, points, params);
-  HIPCHECK(hipGetLastError());
+  checkCudaErrors(hipGetLastError());
 
   // Copy points to CPU.
   thrust::host_vector<float> x_h(x_d0);
@@ -694,7 +697,7 @@ bool cdpQuadtree(int warp_size) {
 
   // Copy nodes to CPU.
   Quadtree_node *host_nodes = new Quadtree_node[max_nodes];
-  HIPCHECK(hipMemcpy(host_nodes, nodes,
+  checkCudaErrors(hipMemcpy(host_nodes, nodes,
                              max_nodes * sizeof(Quadtree_node),
                              hipMemcpyDeviceToHost));
 
@@ -706,8 +709,8 @@ bool cdpQuadtree(int warp_size) {
   delete[] host_nodes;
 
   // Free memory.
-  HIPCHECK(hipFree(nodes));
-  HIPCHECK(hipFree(points));
+  checkCudaErrors(hipFree(nodes));
+  checkCudaErrors(hipFree(points));
 
   return ok;
 }
@@ -720,7 +723,7 @@ int main(int argc, char **argv) {
   // The test requires an architecture SM35 or greater (CDP capable).
   int cuda_device = findCudaDevice(argc, (const char **)argv);
   hipDeviceProp_t deviceProps;
-  HIPCHECK(hipGetDeviceProperties(&deviceProps, cuda_device));
+  checkCudaErrors(hipGetDeviceProperties(&deviceProps, cuda_device));
   int cdpCapable = (deviceProps.major == 3 && deviceProps.minor >= 5) ||
                    deviceProps.major >= 4;
 
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2017.sln b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2019.sln b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2022.sln b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpQuadtree/cdpQuadtree_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/Makefile b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/README.md b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu.hip b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu.hip
old mode 100644
new mode 100755
index 4df490f..e69de29
--- a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint.cu.hip
@@ -1,170 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "helper_cuda_hipified.h"
-#include <helper_string.h>
-
-#include <cstdio>
-#include <cstdlib>
-#include <iostream>
-
-////////////////////////////////////////////////////////////////////////////////
-// Variable on the GPU used to generate unique identifiers of blocks.
-////////////////////////////////////////////////////////////////////////////////
-__device__ int g_uids = 0;
-
-////////////////////////////////////////////////////////////////////////////////
-// Print a simple message to signal the block which is currently executing.
-////////////////////////////////////////////////////////////////////////////////
-__device__ void print_info(int depth, int thread, int uid, int parent_uid) {
-  if (threadIdx.x == 0) {
-    if (depth == 0)
-      printf("BLOCK %d launched by the host\n", uid);
-    else {
-      char buffer[32];
-
-      for (int i = 0; i < depth; ++i) {
-        buffer[3 * i + 0] = '|';
-        buffer[3 * i + 1] = ' ';
-        buffer[3 * i + 2] = ' ';
-      }
-
-      buffer[3 * depth] = '\0';
-      printf("%sBLOCK %d launched by thread %d of block %d\n", buffer, uid,
-             thread, parent_uid);
-    }
-  }
-
-  __syncthreads();
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// The kernel using CUDA dynamic parallelism.
-//
-// It generates a unique identifier for each block. Prints the information
-// about that block. Finally, if the 'max_depth' has not been reached, the
-// block launches new blocks directly from the GPU.
-////////////////////////////////////////////////////////////////////////////////
-__global__ void cdp_kernel(int max_depth, int depth, int thread,
-                           int parent_uid) {
-  // We create a unique ID per block. Thread 0 does that and shares the value
-  // with the other threads.
-  __shared__ int s_uid;
-
-  if (threadIdx.x == 0) {
-    s_uid = atomicAdd(&g_uids, 1);
-  }
-
-  __syncthreads();
-
-  // We print the ID of the block and information about its parent.
-  print_info(depth, thread, s_uid, parent_uid);
-
-  // We launch new blocks if we haven't reached the max_depth yet.
-  if (++depth >= max_depth) {
-    return;
-  }
-
-  cdp_kernel<<<gridDim.x, blockDim.x>>>(max_depth, depth, threadIdx.x, s_uid);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Main entry point.
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  printf("starting Simple Print (CUDA Dynamic Parallelism)\n");
-
-  // Parse a few command-line arguments.
-  int max_depth = 2;
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "help") ||
-      checkCmdLineFlag(argc, (const char **)argv, "h")) {
-    printf(
-        "Usage: %s depth=<max_depth>\t(where max_depth is a value between 1 "
-        "and 8).\n",
-        argv[0]);
-    exit(EXIT_SUCCESS);
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "depth")) {
-    max_depth = getCmdLineArgumentInt(argc, (const char **)argv, "depth");
-
-    if (max_depth < 1 || max_depth > 8) {
-      printf("depth parameter has to be between 1 and 8\n");
-      exit(EXIT_FAILURE);
-    }
-  }
-
-  // Find/set the device.
-  int device = -1;
-  hipDeviceProp_t deviceProp;
-  device = findCudaDevice(argc, (const char **)argv);
-  checkCudaErrors(hipGetDeviceProperties(&deviceProp, device));
-
-  if (!(deviceProp.major > 3 ||
-        (deviceProp.major == 3 && deviceProp.minor >= 5))) {
-    printf("GPU %d - %s  does not support CUDA Dynamic Parallelism\n Exiting.",
-           device, deviceProp.name);
-    exit(EXIT_WAIVED);
-  }
-
-  // Print a message describing what the sample does.
-  printf(
-      "*********************************************************************"
-      "******\n");
-  printf(
-      "The CPU launches 2 blocks of 2 threads each. On the device each thread "
-      "will\n");
-  printf(
-      "launch 2 blocks of 2 threads each. The GPU we will do that "
-      "recursively\n");
-  printf("until it reaches max_depth=%d\n\n", max_depth);
-  printf("In total 2");
-  int num_blocks = 2, sum = 2;
-
-  for (int i = 1; i < max_depth; ++i) {
-    num_blocks *= 4;
-    printf("+%d", num_blocks);
-    sum += num_blocks;
-  }
-
-  printf("=%d blocks are launched!!! (%d from the GPU)\n", sum, sum - 2);
-  printf(
-      "************************************************************************"
-      "***\n\n");
-
-  // Launch the kernel from the CPU.
-  printf("Launching cdp_kernel() with CUDA Dynamic Parallelism:\n\n");
-  cdp_kernel<<<2, 2>>>(max_depth, 0, 0, -1);
-  HIPCHECK(hipGetLastError());
-
-  // Finalize.
-  HIPCHECK(hipDeviceSynchronize());
-
-  exit(EXIT_SUCCESS);
-}
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2017.sln b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2019.sln b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2022.sln b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpSimplePrint/cdpSimplePrint_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/Makefile b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/README.md b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu.hip b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu.hip
old mode 100644
new mode 100755
index 6883698..e69de29
--- a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort.cu.hip
@@ -1,246 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <iostream>
-#include <cstdio>
-#include "helper_cuda_hipified.h"
-#include <helper_string.h>
-
-#define MAX_DEPTH 16
-#define INSERTION_SORT 32
-
-////////////////////////////////////////////////////////////////////////////////
-// Selection sort used when depth gets too big or the number of elements drops
-// below a threshold.
-////////////////////////////////////////////////////////////////////////////////
-__device__ void selection_sort(unsigned int *data, int left, int right) {
-  for (int i = left; i <= right; ++i) {
-    unsigned min_val = data[i];
-    int min_idx = i;
-
-    // Find the smallest value in the range [left, right].
-    for (int j = i + 1; j <= right; ++j) {
-      unsigned val_j = data[j];
-
-      if (val_j < min_val) {
-        min_idx = j;
-        min_val = val_j;
-      }
-    }
-
-    // Swap the values.
-    if (i != min_idx) {
-      data[min_idx] = data[i];
-      data[i] = min_val;
-    }
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Very basic quicksort algorithm, recursively launching the next level.
-////////////////////////////////////////////////////////////////////////////////
-__global__ void cdp_simple_quicksort(unsigned int *data, int left, int right,
-                                     int depth) {
-  // If we're too deep or there are few elements left, we use an insertion
-  // sort...
-  if (depth >= MAX_DEPTH || right - left <= INSERTION_SORT) {
-    selection_sort(data, left, right);
-    return;
-  }
-
-  unsigned int *lptr = data + left;
-  unsigned int *rptr = data + right;
-  unsigned int pivot = data[(left + right) / 2];
-
-  // Do the partitioning.
-  while (lptr <= rptr) {
-    // Find the next left- and right-hand values to swap
-    unsigned int lval = *lptr;
-    unsigned int rval = *rptr;
-
-    // Move the left pointer as long as the pointed element is smaller than the
-    // pivot.
-    while (lval < pivot) {
-      lptr++;
-      lval = *lptr;
-    }
-
-    // Move the right pointer as long as the pointed element is larger than the
-    // pivot.
-    while (rval > pivot) {
-      rptr--;
-      rval = *rptr;
-    }
-
-    // If the swap points are valid, do the swap!
-    if (lptr <= rptr) {
-      *lptr++ = rval;
-      *rptr-- = lval;
-    }
-  }
-
-  // Now the recursive part
-  int nright = rptr - data;
-  int nleft = lptr - data;
-
-  // Launch a new block to sort the left part.
-  if (left < (rptr - data)) {
-    hipStream_t s;
-    hipStreamCreateWithFlags(&s, hipStreamNonBlocking);
-    cdp_simple_quicksort<<<1, 1, 0, s>>>(data, left, nright, depth + 1);
-    hipStreamDestroy(s);
-  }
-
-  // Launch a new block to sort the right part.
-  if ((lptr - data) < right) {
-    hipStream_t s1;
-    hipStreamCreateWithFlags(&s1, hipStreamNonBlocking);
-    cdp_simple_quicksort<<<1, 1, 0, s1>>>(data, nleft, right, depth + 1);
-    hipStreamDestroy(s1);
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Call the quicksort kernel from the host.
-////////////////////////////////////////////////////////////////////////////////
-void run_qsort(unsigned int *data, unsigned int nitems) {
-  // Prepare CDP for the max depth 'MAX_DEPTH'.
-
-  // Launch on device
-  int left = 0;
-  int right = nitems - 1;
-  std::cout << "Launching kernel on the GPU" << std::endl;
-  cdp_simple_quicksort<<<1, 1>>>(data, left, right, 0);
-  HIPCHECK(hipDeviceSynchronize());
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Initialize data on the host.
-////////////////////////////////////////////////////////////////////////////////
-void initialize_data(unsigned int *dst, unsigned int nitems) {
-  // Fixed seed for illustration
-  srand(2047);
-
-  // Fill dst with random values
-  for (unsigned i = 0; i < nitems; i++) dst[i] = rand() % nitems;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Verify the results.
-////////////////////////////////////////////////////////////////////////////////
-void check_results(int n, unsigned int *results_d) {
-  unsigned int *results_h = new unsigned[n];
-  HIPCHECK(hipMemcpy(results_h, results_d, n * sizeof(unsigned),
-                             hipMemcpyDeviceToHost));
-
-  for (int i = 1; i < n; ++i)
-    if (results_h[i - 1] > results_h[i]) {
-      std::cout << "Invalid item[" << i - 1 << "]: " << results_h[i - 1]
-                << " greater than " << results_h[i] << std::endl;
-      exit(EXIT_FAILURE);
-    }
-
-  std::cout << "OK" << std::endl;
-  delete[] results_h;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Main entry point.
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  int num_items = 128;
-  bool verbose = false;
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "help") ||
-      checkCmdLineFlag(argc, (const char **)argv, "h")) {
-    std::cerr << "Usage: " << argv[0]
-              << " num_items=<num_items>\twhere num_items is the number of "
-                 "items to sort"
-              << std::endl;
-    exit(EXIT_SUCCESS);
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "v")) {
-    verbose = true;
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "num_items")) {
-    num_items = getCmdLineArgumentInt(argc, (const char **)argv, "num_items");
-
-    if (num_items < 1) {
-      std::cerr << "ERROR: num_items has to be greater than 1" << std::endl;
-      exit(EXIT_FAILURE);
-    }
-  }
-
-  // Find/set device and get device properties
-  int device = -1;
-  hipDeviceProp_t deviceProp;
-  device = findCudaDevice(argc, (const char **)argv);
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, device));
-
-  if (!(deviceProp.major > 3 ||
-        (deviceProp.major == 3 && deviceProp.minor >= 5))) {
-    printf("GPU %d - %s  does not support CUDA Dynamic Parallelism\n Exiting.",
-           device, deviceProp.name);
-    exit(EXIT_WAIVED);
-  }
-
-  // Create input data
-  unsigned int *h_data = 0;
-  unsigned int *d_data = 0;
-
-  // Allocate CPU memory and initialize data.
-  std::cout << "Initializing data:" << std::endl;
-  h_data = (unsigned int *)malloc(num_items * sizeof(unsigned int));
-  initialize_data(h_data, num_items);
-
-  if (verbose) {
-    for (int i = 0; i < num_items; i++)
-      std::cout << "Data [" << i << "]: " << h_data[i] << std::endl;
-  }
-
-  // Allocate GPU memory.
-  HIPCHECK(
-      hipMalloc((void **)&d_data, num_items * sizeof(unsigned int)));
-  HIPCHECK(hipMemcpy(d_data, h_data, num_items * sizeof(unsigned int),
-                             hipMemcpyHostToDevice));
-
-  // Execute
-  std::cout << "Running quicksort on " << num_items << " elements" << std::endl;
-  run_qsort(d_data, num_items);
-
-  // Check result
-  std::cout << "Validating results: ";
-  check_results(num_items, d_data);
-
-  free(h_data);
-  HIPCHECK(hipFree(d_data));
-
-  exit(EXIT_SUCCESS);
-}
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2017.sln b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2019.sln b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2022.sln b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/cdpSimpleQuicksort/cdpSimpleQuicksort_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/Makefile b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/README.md b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/compMalloc.cpp b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/compMalloc.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/compMalloc.h b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/compMalloc.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/compMalloc_hipified.cpp b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/compMalloc_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/compMalloc_hipified.h b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/compMalloc_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2017.sln b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2019.sln b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2022.sln b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/cudaCompressibleMemory_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/saxpy.cu b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/saxpy.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/saxpy.cu.hip b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/saxpy.cu.hip
old mode 100644
new mode 100755
index c248f1f..e69de29
--- a/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/saxpy.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/cudaCompressibleMemory/saxpy.cu.hip
@@ -1,174 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-//
-// This sample uses the compressible memory allocation if device supports it
-// and performs saxpy on it. 
-// Compressible memory may give better performance if the data is amenable to 
-// compression.
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <hip/hip_runtime.h>
-#define CUDA_DRIVER_API
-#include "helper_cuda_hipified.h"
-#include "compMalloc_hipified.h"
-
-__global__ void saxpy(const float a, const float4 *x, const float4 *y, float4 *z, const size_t n)
-{
-    for (size_t i = blockIdx.x * blockDim.x + threadIdx.x; i < n; i += gridDim.x * blockDim.x)
-    {
-        const float4 x4 = x[i];
-        const float4 y4 = y[i];
-        z[i] = make_float4(a * x4.x + y4.x, a * x4.y + y4.y,
-                            a * x4.z + y4.z, a * x4.w + y4.w);
-    }
-}
-
-__global__ void init(float4 *x, float4 *y, const float val, const size_t n)
-{
-    const float4 val4 = make_float4(val, val, val, val);
-    for (size_t i = blockIdx.x * blockDim.x + threadIdx.x; i < n; i += gridDim.x * blockDim.x)
-    {
-        x[i] = y[i] = val4;
-    }
-}
-
-void launchSaxpy(const float a, float4 *x, float4 *y, float4 *z, const size_t n, const float init_val, const bool compressibleZbuf)
-{
-    hipEvent_t start, stop;
-    float ms;
-    int blockSize;
-    int minGridSize;
-    dim3 threads, blocks; 
-
-    if (!compressibleZbuf)
-    {
-        // We are on config where compressible buffer can only be initialized through hipMemcpy
-        // hence, x & y buffers are allocated as compressible and initialized via hipMemcpy
-        // whereas z buffer is allocated as non-compressible.
-        float4 *h_x = (float4 *) malloc(sizeof(float4) * n);
-        float4 *h_y = (float4 *) malloc(sizeof(float4) * n);
-        for (int i = 0; i < n; i++)
-        {
-            h_x[i].x = h_x[i].y = h_x[i].z = h_x[i].w = init_val;
-            h_y[i].x = h_y[i].y = h_y[i].z = h_y[i].w = init_val;
-        }
-        checkCudaErrors(hipMemcpy(x, h_x, sizeof(float4) * n, hipMemcpyHostToDevice));
-        checkCudaErrors(hipMemcpy(y, h_y, sizeof(float4) * n, hipMemcpyHostToDevice));
-        free(h_x);
-        free(h_y);
-    }
-    else
-    {
-        checkCudaErrors(hipOccupancyMaxPotentialBlockSize(&minGridSize, &blockSize, (void*)init));
-        threads = dim3(blockSize, 1, 1);
-        blocks  = dim3(minGridSize, 1, 1);
-        init<<<blocks, threads>>>(x, y, init_val, n);
-    }
-
-    checkCudaErrors(hipOccupancyMaxPotentialBlockSize(&minGridSize, &blockSize, (void*)saxpy));
-    threads = dim3(blockSize, 1, 1);
-    blocks  = dim3(minGridSize, 1, 1);
-
-    checkCudaErrors(hipEventCreate(&start));
-    checkCudaErrors(hipEventCreate(&stop));
-    checkCudaErrors(hipEventRecord(start));
-    saxpy<<<blocks, threads>>>(a, x, y, z, n);
-    checkCudaErrors(hipEventRecord(stop));
-    checkCudaErrors(hipEventSynchronize(stop));
-    checkCudaErrors(hipEventElapsedTime(&ms, start, stop));
-
-    const size_t size = n * sizeof(float4);
-    printf("Running saxpy with %d blocks x %d threads = %.3f ms %.3f TB/s\n", blocks.x, threads.x, ms, (size*3)/ms/1e9);
-}
-
-int main(int argc, char **argv)
-{
-    const size_t n = 10485760;
-
-    if (checkCmdLineFlag(argc, (const char **)argv, "help") ||
-            checkCmdLineFlag(argc, (const char **)argv, "?")) {
-        printf("Usage -device=n (n >= 0 for deviceID)\n");
-        exit(EXIT_SUCCESS);
-    }
-
-    findCudaDevice(argc, (const char**)argv);
-    hipDevice_t currentDevice;
-    checkCudaErrors(hipCtxGetDevice(&currentDevice));
-
-    // Check that the selected device supports virtual memory management
-    int vmm_supported = -1;
-    checkCudaErrors(hipDeviceGetAttribute(&vmm_supported,
-                          CU_DEVICE_ATTRIBUTE_VIRTUAL_ADDRESS_MANAGEMENT_SUPPORTED,
-                          currentDevice));
-    if (vmm_supported == 0) {
-        printf("Device %d doesn't support Virtual Memory Management, waiving the execution.\n", currentDevice);
-        exit(EXIT_WAIVED);
-    }
-
-    int isCompressionAvailable;
-    checkCudaErrors(hipDeviceGetAttribute(&isCompressionAvailable,
-                             CU_DEVICE_ATTRIBUTE_GENERIC_COMPRESSION_SUPPORTED,
-                             currentDevice));
-    if (isCompressionAvailable == 0)
-    {
-        printf("Device %d doesn't support Generic memory compression, waiving the execution.\n", currentDevice);
-        exit(EXIT_WAIVED);
-    }
-
-    printf("Generic memory compression support is available\n");
-
-    int major, minor;
-    checkCudaErrors(hipDeviceGetAttribute(&major,
-                          hipDeviceAttributeComputeCapabilityMajor,
-                          currentDevice));
-    checkCudaErrors(hipDeviceGetAttribute(&minor,
-                          hipDeviceAttributeComputeCapabilityMinor,
-                          currentDevice));
-    float4 *x, *y, *z;
-    const size_t size = n * sizeof(float4);
-
-    // Allocating compressible memory
-    checkCudaErrors(allocateCompressible((void **)&x, size, true));
-    checkCudaErrors(allocateCompressible((void **)&y, size, true));
-    bool compressibleZbuf = 0;
-    if ((major == 8 && minor == 0) || (major == 8 && minor == 6))
-    {
-        // On SM 8.0 and 8.6 GPUs compressible buffer can only be initialized
-        // through hipMemcpy.
-        printf("allocating non-compressible Z buffer\n");
-        checkCudaErrors(allocateCompressible((void **)&z, size, false));
-        compressibleZbuf = 0;
-    }
-    else
-    {
-        checkCudaErrors(allocateCompressible((void **)&z, size, true));
-        compressibleZbuf = 1;
-    }
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/Makefile b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/README.md b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm.cu b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm.cu.hip b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm.cu.hip
old mode 100644
new mode 100755
index aefc88c..e69de29
--- a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm.cu.hip
@@ -1,651 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// CUDA sample demonstrating a GEMM computation using the Warp Matrix Multiply
-// and Accumulate API introduced in CUDA 9.
-
-// In this program, the compute_gemm kernel computes the result of a matrix
-// multiplication and addition: D = alpha * A * B + beta * C. The dimensions of
-// both C and D matrices are M_GLOBAL x N_GLOBAL. The A matrix is M_GLOBAL x
-// K_GLOBAL (row-major), the B matrix is K_GLOBAL x N_GLOBAL (column-major). In
-// that kernel, each CTA computes one 128 x 128 tile of the resulting matrix per
-// iteration. When the tile is computed, the CTA stores it to the global memory
-// and begins a new iteration, selecting a new 128 x 128 tile to compute.
-// Each CTA consists of eight warps. For the 128 x 128 tile, each warp computes
-// eight 16 x 16 subtiles, organized in a 2 x 4 two-dimensional array. Warps
-// compute the 16 x 16 subtiles using nvcuda::wmma::mma_sync operations by
-// moving through the K_GLOBAL dimension of the A and B matrices and
-// accumulating the intermediate result in the local thread state.
-
-// There are a number of simple optimizations used in the algorithm:
-// - The CTA copies the 128 x 128 tile of the C matrix from the global memory to
-//   shared memory. After that is done, each warp loads the C matrix fragments
-//   from shared memory, thus avoiding a random global memory access.
-// - On each internal iteration, the CTA copies a portion of the A and B
-//   matrices from global memory to shared memory. After that, all warps in the
-//   CTA reuse the A and B data from shared memory, thus reducing the number of
-//   data copies from global memory.
-// - The portions of the A and B matrices are stored in shared memory with an
-//   additional padding (skew) to reduce the number of shared memory access bank
-//   conflicts.
-//   (See a detailed explanation near the SKEW_HALF macro definition.)
-// - When the CTA finishes computing the tiles of the resulting matrix, each
-//   warp stores its subtiles to shared memory. The CTA then copies the shared
-//   memory contents to global memory, again avoiding redundant random global
-//   memory  accesses.
-// - Note that the CTA tile size is chosen to maximize the GPU register
-//   utilization, but carefully enough to avoid local memory use.
-
-#include <assert.h>
-#include <hip/hip_runtime.h>
-#include <mma.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-
-// helper functions and utilities to work with CUDA
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"
-
-// Externally configurable parameters.
-
-#ifndef CPU_DEBUG
-// Set this to 1 to verify the correctness of the GPU-computed matrix.
-#define CPU_DEBUG 0
-#endif
-
-#ifndef SHARED_MEMORY_LIMIT_64K
-// Set this to 0 to use more than 64 Kb of shared memory to cache data, to
-// improve the performance of the computations on GPU.
-// Note that you need a GPU that can have more than 64 Kb of shared memory
-// per multiprocessor.
-#define SHARED_MEMORY_LIMIT_64K 1
-#endif
-
-// GPU configuration.
-
-#define WARP_SIZE 32
-
-// MMA matrix tile dimensions.
-
-#define M 16
-#define N 16
-#define K 16
-
-#define WMMA_M 16
-#define WMMA_N 16
-#define WMMA_K 16
-
-// GEMM configuration.
-
-#define M_TILES 256
-#define N_TILES 256
-#define K_TILES 256
-
-#define M_GLOBAL (M * M_TILES)
-#define N_GLOBAL (N * N_TILES)
-#define K_GLOBAL (K * K_TILES)
-
-#define C_LAYOUT wmma::mem_row_major
-
-// Implementation constants.
-
-#define WARPS_PER_BLOCK 8
-#define THREADS_PER_BLOCK (WARP_SIZE * WARPS_PER_BLOCK)
-
-#if SHARED_MEMORY_LIMIT_64K
-// With only 64 Kb shared memory available, we can fit two 8-tile chunks of
-// the A and B matrix data, that are 16 * 16 * 8 * 8 * 2 = 32 Kb each
-// (i.e. two 8x8 arrays of tiles of 16x16 half-typed elements per CTA).
-// But we cannot account the 8 Kb total skew overhead, without which the
-// performance would be severely impacted. So we choose to reduce the chunk size
-// in half, i.e. the amount of A and B matrix data we cache in shared memory.
-// Accordingly, this doubles the number of outer iterations across the global K
-// dimension, which only slightly impacts the performance.
-#define CHUNK_K 4
-#else
-#define CHUNK_K 8
-#endif
-
-#define CHUNK_LINE_BYTES (CHUNK_K * K * sizeof(half))
-#define WARP_COPY_BYTES (WARP_SIZE * sizeof(int4))
-#define CHUNK_COPY_LINES_PER_WARP (WARP_COPY_BYTES / CHUNK_LINE_BYTES)
-#define CHUNK_COPY_LINE_LANES (WARP_SIZE / CHUNK_COPY_LINES_PER_WARP)
-
-#define BLOCK_ROW_WARPS 2
-#define BLOCK_COL_WARPS 4
-
-#define WARP_ROW_TILES 4
-#define WARP_COL_TILES 2
-
-#define BLOCK_ROW_TILES (WARP_ROW_TILES * BLOCK_ROW_WARPS)
-#define BLOCK_COL_TILES (WARP_COL_TILES * BLOCK_COL_WARPS)
-
-#define GLOBAL_MEM_STRIDE N_GLOBAL
-
-#define SHMEM_STRIDE (N * BLOCK_ROW_TILES)
-#define SHMEM_OFFSET (N * WARP_ROW_TILES)
-
-// The macro below is used to shift rows of the A matrix and columns of the B matrix
-// in shared memory to minimize possible bank conflicts.
-// Before performing the nvcuda::wmma::mma_sync operation, the warp must load the matrix
-// data using the nvcuda::wmma::load_matrix_sync operation. Although the memory access pattern
-// is not specified for that function, each lane in the warp can read one or multiple matrix
-// elements from different matrix rows or columns.
-// For shared memory, such access can result in bank conflicts if different rows / columns
-// of the matrix map to the same bank. By shifting each row and column by a few bytes, we
-// make sure that they map to different banks, thus reducing the number of possible bank
-// conflicts.
-// The number of 16 two-byte "half" elements is chosen as the minimum possible shift because
-// we must keep each row and column 256-bit aligned, as required by nvcuda::wmma::load_matrix_sync.
-#define SKEW_HALF 16
-
-#define checkKernelErrors(expr)                             \
-  do {                                                      \
-    expr;                                                   \
-                                                            \
-    hipError_t __err = hipGetLastError();                 \
-    if (__err != hipSuccess) {                             \
-      printf("Line %d: '%s' failed: %s\n", __LINE__, #expr, \
-             hipGetErrorString(__err));                    \
-      abort();                                              \
-    }                                                       \
-  } while (0)
-
-//using namespace nvcuda;
-using namespace rocwmma;
-__host__ void init_host_matrices(half *a, half *b, float *c) {
-  for (int i = 0; i < M_GLOBAL; i++) {
-    for (int j = 0; j < K_GLOBAL; j++) {
-      a[i * K_GLOBAL + j] = (half)(rand() % 3);
-    }
-  }
-
-  for (int i = 0; i < N_GLOBAL; i++) {
-    for (int j = 0; j < K_GLOBAL; j++) {
-      b[i * K_GLOBAL + j] = (half)(rand() % 3);
-    }
-  }
-
-  for (int t = 0; t < M_GLOBAL * N_GLOBAL; t++) {
-    c[t] = static_cast<float>(rand() % 3);
-  }
-}
-
-__global__ void compute_gemm(const half *A, const half *B, const float *C,
-                             float *D, float alpha, float beta) {
-  extern __shared__ half shmem[][CHUNK_K * K + SKEW_HALF];
-
-  // Warp and lane identification.
-  const unsigned int warpId = threadIdx.x / WARP_SIZE;
-  const unsigned int laneId = threadIdx.x % WARP_SIZE;
-
-  // Offset in shared memory from which the B matrix is stored.
-  const size_t shmem_idx_b_off = BLOCK_COL_TILES * M;
-
-  // This pointer is used to access the C and D matrix tiles this warp computes.
-  float *shmem_warp_tile_ptr = (float *)&shmem[0][0] +
-                               (warpId / 2) * SHMEM_STRIDE * K * 2 +
-                               (warpId % 2) * SHMEM_OFFSET;
-
-  // This pointer is used to stream the C and D matrices block-wide tile to and
-  // from shared memory.
-  float *shmem_warp_stream_ptr =
-      (float *)&shmem[0][0] + warpId * SHMEM_STRIDE * K;
-
-  // Adjust the beta scaler, as it'll be multiplied by alpha at the end of
-  // each tile computation. Technically this is not generally correct (may
-  // result in a loss of precision). Zero still needs to be specially handled
-  // though.
-  beta /= alpha;
-
-  // Each CTA slides along the 128 x 128 tiles from the top left corner of the
-  // matrix to the right and down, and selects the next tile to compute. Once
-  // there's no such tile, all warps in this CTA exit.
-  for (unsigned int block_pos = blockIdx.x;; block_pos += gridDim.x) {
-    const unsigned int block_tile_i =
-        ((block_pos * BLOCK_ROW_TILES) / N_TILES) * (BLOCK_COL_TILES);
-    const unsigned int block_tile_j = (block_pos * BLOCK_COL_TILES) % N_TILES;
-
-    // Stop when there are no more D matrix tiles to compute in this CTA.
-    if (block_tile_i >= M_TILES) {
-      break;
-    }
-
-    // This warp's pointer to the C matrix data to copy memory from to shared
-    // memory.
-    const size_t gmem_idx =
-        (block_tile_i + warpId) * M * GLOBAL_MEM_STRIDE + block_tile_j * N;
-    const float *src_gmem_warp_stream_ptr = &C[gmem_idx];
-
-    // Stream multiple C tiles to shared memory.
-#pragma unroll
-    for (int i = 0; i < K; i++) {
-      typedef int4 copy_t;
-
-      *((copy_t *)(shmem_warp_stream_ptr + SHMEM_STRIDE * i) + laneId) =
-          *((copy_t *)(src_gmem_warp_stream_ptr + GLOBAL_MEM_STRIDE * i) +
-            laneId);
-    }
-
-    __syncthreads();
-
-    // These fragments will accumulate the result of A and B matrix fragment
-    // multiplications along the K_GLOBAL dimension.
-    wmma::fragment<wmma::accumulator, M, N, K, float> c[WARP_COL_TILES]
-                                                       [WARP_ROW_TILES];
-
-    // Load the C matrix tiles into fragments from shared memory.
-#pragma unroll
-    for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-      for (int j = 0; j < WARP_ROW_TILES; j++) {
-        const float *tile_ptr =
-            shmem_warp_tile_ptr + i * SHMEM_STRIDE * K + j * N;
-
-        wmma::load_matrix_sync(c[i][j], tile_ptr, SHMEM_STRIDE, C_LAYOUT);
-      }
-    }
-
-    __syncthreads();
-
-    // Scale the C matrix.
-#pragma unroll
-    for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-      for (int j = 0; j < WARP_ROW_TILES; j++) {
-#pragma unroll
-        for (int t = 0; t < c[i][j].num_elements; t++) {
-          c[i][j].x[t] *= beta;
-        }
-      }
-    }
-
-    // Select what warp copies what matrix to shared memory.
-    // Warps 0-3 copy the A matrix, warps 4-7 copy the B matrix.
-    const half *warp_ptr = (warpId < 4) ? (&A[block_tile_i * M * K_GLOBAL] +
-                                           M * K_GLOBAL * (warpId % 4) * 2)
-                                        : (&B[block_tile_j * N * K_GLOBAL] +
-                                           N * K_GLOBAL * (warpId % 4) * 2);
-
-    // Go through the global K dimension by a fixed step at a time.
-#pragma unroll
-    for (int tile_k = 0; tile_k < K_TILES; tile_k += CHUNK_K) {
-      // Copy slices of the A and B matrices to shared memory.
-      // The first half of the warps in the CTA copy the A matrix, the rest copy
-      // the B matrix.
-      size_t shmem_idx =
-          warpId < (WARPS_PER_BLOCK / 2)
-              ? (M * (warpId % (WARPS_PER_BLOCK / 2)) * 2)
-              : (N * (warpId % (WARPS_PER_BLOCK / 2)) * 2 + shmem_idx_b_off);
-
-      // First half of the warp copies the first row / column of the matrix,
-      // the second half of the warp copies the next.
-      int4 *lane_ptr = (int4 *)(warp_ptr + tile_k * K +
-                                (laneId / CHUNK_COPY_LINE_LANES) * K_GLOBAL) +
-                       (laneId % CHUNK_COPY_LINE_LANES);
-
-      // Shift the second half of the warp to the next row / column in the
-      // shared memory.
-      shmem_idx += laneId / CHUNK_COPY_LINE_LANES;
-
-#pragma unroll
-      for (int i = 0; i < ((WARP_SIZE / 2) / CHUNK_COPY_LINES_PER_WARP) * 2;
-           i++) {
-        // Copy 16 bytes at once in each lane.
-        *((int4 *)&shmem[shmem_idx][0] + (laneId % CHUNK_COPY_LINE_LANES)) =
-            *lane_ptr;
-
-        // Advance the global memory pointer and the shared memory index.
-        lane_ptr =
-            (int4 *)((half *)lane_ptr + K_GLOBAL * CHUNK_COPY_LINES_PER_WARP);
-        shmem_idx += CHUNK_COPY_LINES_PER_WARP;
-      }
-
-      __syncthreads();
-
-      // Compute a grid of C matrix tiles in each warp.
-#pragma unroll
-      for (int k_step = 0; k_step < CHUNK_K; k_step++) {
-        wmma::fragment<wmma::matrix_a, M, N, K, half, wmma::row_major>
-            a[WARP_COL_TILES];
-        wmma::fragment<wmma::matrix_b, M, N, K, half, wmma::col_major>
-            b[WARP_ROW_TILES];
-
-#pragma unroll
-        for (int i = 0; i < WARP_COL_TILES; i++) {
-          size_t shmem_idx_a = (warpId / 2) * M * 2 + (i * M);
-          const half *tile_ptr = &shmem[shmem_idx_a][k_step * K];
-
-          wmma::load_matrix_sync(a[i], tile_ptr, K * CHUNK_K + SKEW_HALF);
-
-#pragma unroll
-          for (int j = 0; j < WARP_ROW_TILES; j++) {
-            if (i == 0) {
-              // Load the B matrix fragment once, because it is going to be
-              // reused against the other A matrix fragments.
-              size_t shmem_idx_b = shmem_idx_b_off +
-                                   (WARP_ROW_TILES * N) * (warpId % 2) +
-                                   (j * N);
-              const half *tile_ptr = &shmem[shmem_idx_b][k_step * K];
-
-              wmma::load_matrix_sync(b[j], tile_ptr, K * CHUNK_K + SKEW_HALF);
-            }
-
-            wmma::mma_sync(c[i][j], a[i], b[j], c[i][j]);
-          }
-        }
-      }
-
-      __syncthreads();
-    }
-
-      // Store the D fragments to shared memory.
-#pragma unroll
-    for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-      for (int j = 0; j < WARP_ROW_TILES; j++) {
-#pragma unroll
-        // Uniform, point-wise transformations of ALL fragment elements by ALL
-        // threads in the warp are well-defined even though element indices
-        // within fragment storage are not defined.
-        for (int t = 0; t < c[i][j].num_elements; t++) c[i][j].x[t] *= alpha;
-
-        float *tile_ptr = shmem_warp_tile_ptr + i * SHMEM_STRIDE * K + j * N;
-
-        wmma::store_matrix_sync(tile_ptr, c[i][j], SHMEM_STRIDE, C_LAYOUT);
-      }
-    }
-
-    __syncthreads();
-
-    // Now that shared memory contains all the D tiles, stream them to global
-    // memory.
-    float *dst_gmem_warp_stream_ptr = &D[gmem_idx];
-
-#pragma unroll
-    for (int i = 0; i < K; i++) {
-      *((int4 *)(dst_gmem_warp_stream_ptr + GLOBAL_MEM_STRIDE * i) + laneId) =
-          *((int4 *)(shmem_warp_stream_ptr + SHMEM_STRIDE * i) + laneId);
-    }
-
-    __syncthreads();
-  }
-}
-
-// Performs an MxNxK GEMM (C=alpha*A*B + beta*C) assuming:
-//  1) Matrices are packed in memory.
-//  2) M, N and K are multiples of 16.
-//  3) Neither A nor B are transposed.
-// Note: This is a less performant version of the compute_gemm kernel. It is
-// designed for
-//       demonstration purposes only to show the CUDA WMMA API use without
-//       relying on availability of the shared memory.
-__global__ void simple_wmma_gemm(half *a, half *b, float *c, float *d, int m_ld,
-                                 int n_ld, int k_ld, float alpha, float beta) {
-  // Leading dimensions. Packed with no transpositions.
-  int lda = k_ld;
-  int ldb = k_ld;
-  int ldc = n_ld;
-
-  // Tile using a 2D grid
-  int warpM = (blockIdx.x * blockDim.x + threadIdx.x) / warpSize;
-  int warpN = (blockIdx.y * blockDim.y + threadIdx.y);
-
-  // Declare the fragments
-  wmma::fragment<wmma::matrix_a, WMMA_M, WMMA_N, WMMA_K, half, wmma::row_major>
-      a_frag;
-  wmma::fragment<wmma::matrix_b, WMMA_M, WMMA_N, WMMA_K, half, wmma::col_major>
-      b_frag;
-  wmma::fragment<wmma::accumulator, WMMA_M, WMMA_N, WMMA_K, float> acc_frag;
-  wmma::fragment<wmma::accumulator, WMMA_M, WMMA_N, WMMA_K, float> c_frag;
-
-  wmma::fill_fragment(acc_frag, 0.0f);
-
-  // Loop over k
-  for (int i = 0; i < k_ld; i += WMMA_K) {
-    int aCol = i;
-    int aRow = warpM * WMMA_M;
-    int bCol = warpN * N;
-    int bRow = i;
-
-    // Bounds checking
-    if (aRow < m_ld && aCol < k_ld && bRow < k_ld && bCol < n_ld) {
-      // Load the inputs
-      wmma::load_matrix_sync(a_frag, a + aCol + aRow * lda, lda);
-      wmma::load_matrix_sync(b_frag, b + bRow + bCol * ldb, ldb);
-
-      // Perform the matrix multiplication
-      wmma::mma_sync(acc_frag, a_frag, b_frag, acc_frag);
-    }
-  }
-
-  // Load in the current value of c, scale it by beta, and add this our result
-  // scaled by alpha
-  int cCol = warpN * WMMA_N;
-  int cRow = warpM * WMMA_M;
-
-  if (cRow < m_ld && cCol < n_ld) {
-    wmma::load_matrix_sync(c_frag, c + cCol + cRow * ldc, ldc,
-                           wmma::mem_row_major);
-
-    for (int i = 0; i < c_frag.num_elements; i++) {
-      c_frag.x[i] = alpha * acc_frag.x[i] + beta * c_frag.x[i];
-    }
-
-    // Store the output
-    wmma::store_matrix_sync(d + cCol + cRow * ldc, c_frag, ldc,
-                            wmma::mem_row_major);
-  }
-}
-
-__host__ void matMultiplyOnHost(half *A, half *B, float *C, float alpha,
-                                float beta, int numARows, int numAColumns,
-                                int numBRows, int numBColumns, int numCRows,
-                                int numCColumns) {
-  for (int i = 0; i < numCRows; i++) {
-    for (int j = 0; j < numCColumns; j++) {
-      float temp = 0.0;
-
-      for (int k = 0; k < numAColumns; k++) {
-        temp += (float)A[i * numAColumns + k] * (float)B[j * numBRows + k];
-      }
-
-      C[i * numCColumns + j] = temp * alpha + beta * C[i * numCColumns + j];
-    }
-  }
-}
-
-int main(int argc, char **argv) {
-  printf("Initializing...\n");
-
-  int dev = findCudaDevice(argc, (const char **)argv);
-
-  hipDeviceProp_t deviceProp;
-  checkCudaErrors(hipGetDeviceProperties(&deviceProp, dev));
-
-  // Tensor cores require a GPU of Volta (SM7X) architecture or higher.
-  if (deviceProp.major < 7) {
-    printf(
-        "cudaTensorCoreGemm requires SM 7.0 or higher to use Tensor "
-        "Cores.  Exiting...\n");
-    exit(EXIT_WAIVED);
-  }
-
-  printf("M: %d (%d x %d)\n", M_GLOBAL, M, M_TILES);
-  printf("N: %d (%d x %d)\n", N_GLOBAL, N, N_TILES);
-  printf("K: %d (%d x %d)\n", K_GLOBAL, K, K_TILES);
-
-  half *A_h = NULL;
-  half *B_h = NULL;
-  float *C_h = NULL;
-#if CPU_DEBUG
-  float *result_hD = NULL;
-  float *result_host = NULL;
-#endif
-
-  A_h = (half *)malloc(sizeof(half) * M_GLOBAL * K_GLOBAL);
-  B_h = (half *)malloc(sizeof(half) * K_GLOBAL * N_GLOBAL);
-  C_h = (float *)malloc(sizeof(float) * M_GLOBAL * N_GLOBAL);
-#if CPU_DEBUG
-  result_hD = (float *)malloc(sizeof(float) * M_GLOBAL * N_GLOBAL);
-  result_host = (float *)malloc(sizeof(float) * M_GLOBAL * N_GLOBAL);
-#endif
-
-  half *A = NULL;
-  half *B = NULL;
-  float *C = NULL;
-  float *D = NULL;
-
-  checkCudaErrors(hipMalloc(reinterpret_cast<void **>(&A),
-                             sizeof(half) * M_GLOBAL * K_GLOBAL));
-  checkCudaErrors(hipMalloc(reinterpret_cast<void **>(&B),
-                             sizeof(half) * N_GLOBAL * K_GLOBAL));
-  checkCudaErrors(hipMalloc(reinterpret_cast<void **>(&C),
-                             sizeof(float) * M_GLOBAL * N_GLOBAL));
-  checkCudaErrors(hipMalloc(reinterpret_cast<void **>(&D),
-                             sizeof(float) * M_GLOBAL * N_GLOBAL));
-
-  assert(((unsigned long long)A) % 128 == 0);
-  assert(((unsigned long long)B) % 128 == 0);
-  assert(((unsigned long long)C) % 128 == 0);
-  assert(((unsigned long long)D) % 128 == 0);
-
-  init_host_matrices(A_h, B_h, C_h);
-
-  printf("Preparing data for GPU...\n");
-
-  checkCudaErrors(hipMemcpy(A, A_h, sizeof(half) * M_GLOBAL * K_GLOBAL,
-                             hipMemcpyHostToDevice));
-  checkCudaErrors(hipMemcpy(B, B_h, sizeof(half) * N_GLOBAL * K_GLOBAL,
-                             hipMemcpyHostToDevice));
-  checkCudaErrors(hipMemcpy(C, C_h, sizeof(float) * M_GLOBAL * N_GLOBAL,
-                             hipMemcpyHostToDevice));
-  checkCudaErrors(hipMemset(D, 0, sizeof(float) * M_GLOBAL * N_GLOBAL));
-
-  enum {
-    // Compute the right amount of shared memory to request.
-    // We need shared memory to hold per-CTA C and D matrix tiles, and to cache
-    // per-CTA chunks
-    // of the A and B matrices. Therefore, the right amount to request is the
-    // maximum of those
-    // two numbers.
-    SHMEM_SZ = MAX(
-        sizeof(half) * (BLOCK_COL_TILES * M) * (CHUNK_K * K + SKEW_HALF) * 2,
-        M * (BLOCK_ROW_WARPS * WARP_ROW_TILES) * N *
-            (BLOCK_COL_WARPS * WARP_COL_TILES) * sizeof(float))
-  };
-
-  printf("Required shared memory size: %lu Kb\n", SHMEM_SZ / 1024UL);
-
-  const float alpha = 1.1f;
-  const float beta = 1.2f;
-
-  hipEvent_t start, stop;
-
-  checkCudaErrors(hipEventCreate(&start));
-  checkCudaErrors(hipEventCreate(&stop));
-  checkCudaErrors(hipEventRecord(start));
-
-  // If enough shared memory available on the GPU use high performant kernel
-  if (deviceProp.sharedMemPerMultiprocessor >= SHMEM_SZ) {
-    printf("Computing... using high performance kernel compute_gemm \n");
-
-    checkCudaErrors(hipFuncSetAttribute(
-        compute_gemm, hipFuncAttributeMaxDynamicSharedMemorySize, SHMEM_SZ));
-    checkKernelErrors(
-        (compute_gemm<<<deviceProp.multiProcessorCount, THREADS_PER_BLOCK,
-                        SHMEM_SZ>>>(A, B, C, D, alpha, beta)));
-#if CPU_DEBUG
-    checkCudaErrors(hipMemcpy(result_hD, D,
-                               sizeof(float) * M_GLOBAL * N_GLOBAL,
-                               hipMemcpyDeviceToHost));
-#endif
-  } else {
-    dim3 gridDim;
-    dim3 blockDim;
-
-    // blockDim.x must be a multple of warpSize
-    // 128x4 means we have 16 warps and a block computes a 64x64 output tile
-    blockDim.x = 128;
-    blockDim.y = 4;
-
-    gridDim.x = (M_GLOBAL + (WMMA_M * blockDim.x / 32 - 1)) /
-                (WMMA_M * blockDim.x / 32);
-    gridDim.y = (N_GLOBAL + WMMA_N * blockDim.y - 1) / (WMMA_N * blockDim.y);
-
-    printf("Computing... using simple_wmma_gemm kernel\n");
-    simple_wmma_gemm<<<gridDim, blockDim>>>(A, B, C, D, M_GLOBAL, N_GLOBAL,
-                                            K_GLOBAL, alpha, beta);
-#if CPU_DEBUG
-    checkCudaErrors(hipMemcpy(result_hD, D,
-                               sizeof(float) * M_GLOBAL * N_GLOBAL,
-                               hipMemcpyDeviceToHost));
-#endif
-  }
-
-  checkCudaErrors(hipEventRecord(stop));
-  checkCudaErrors(hipEventSynchronize(stop));
-
-#if CPU_DEBUG
-  printf("Verifying correctness of the computations...\n");
-
-  memcpy(result_host, C_h, sizeof(float) * M_GLOBAL * N_GLOBAL);
-
-  matMultiplyOnHost(A_h, B_h, result_host, alpha, beta, M_GLOBAL, K_GLOBAL,
-                    K_GLOBAL, N_GLOBAL, M_GLOBAL, N_GLOBAL);
-
-  for (int i = 0; i < N_GLOBAL * M_GLOBAL; i++) {
-    if (fabs(result_hD[i] - result_host[i]) > 0.1f)
-      printf("mismatch i=%d result_hD=%f result_host=%f\n", i, result_hD[i],
-             result_host[i]);
-  }
-  free(result_hD);
-  free(result_host);
-#endif
-
-  float milliseconds = 0;
-
-  checkCudaErrors(hipEventElapsedTime(&milliseconds, start, stop));
-
-  printf("Time: %f ms\n", milliseconds);
-  printf("TFLOPS: %.2f\n", static_cast<double>((static_cast<double>(M_GLOBAL) *
-                                                N_GLOBAL * K_GLOBAL * 2) /
-                                               (milliseconds / 1000.)) /
-                               1e12);
-
-  free(A_h);
-  free(B_h);
-  free(C_h);
-  checkCudaErrors(hipFree(reinterpret_cast<void *>(A)));
-  checkCudaErrors(hipFree(reinterpret_cast<void *>(B)));
-  checkCudaErrors(hipFree(reinterpret_cast<void *>(C)));
-  checkCudaErrors(hipFree(reinterpret_cast<void *>(D)));
-
-  return 0;
-}
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2017.sln b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2019.sln b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2022.sln b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/cudaTensorCoreGemm/cudaTensorCoreGemm_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/Makefile b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/README.md b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm.cu b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm.cu.hip b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm.cu.hip
old mode 100644
new mode 100755
index 101d00b..e69de29
--- a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm.cu.hip
@@ -1,1023 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-
-// CUDA sample demonstrating a Double precision GEMM computation using the Warp
-//  Matrix Multiply and Accumulate API introduced in CUDA 11.0.
-
-// In this program, the compute_dgemm kernel computes the result of a matrix multiplication
-// and addition: D = alpha * A * B + beta * C. The dimensions of both C and D matrices
-// are M_GLOBAL x N_GLOBAL. The A matrix is M_GLOBAL x K_GLOBAL (row-major), the B matrix
-// is K_GLOBAL x N_GLOBAL (column-major).
-// In that kernel, each CTA computes one 64 x 64 tile of the resulting matrix
-// per iteration. When the tile is computed, the CTA stores it to the global memory
-// and begins a new iteration, selecting a new 64 x 64 tile to compute.
-// Each CTA consists of eight warps. For the 64 x 64 tile, each warp computes eight
-// 8 x 8 subtiles, organized in a 2 x 4 two-dimensional array.
-// Warps compute the 8 x 8 subtiles using nvcuda::wmma::mma_sync operations by
-// moving through the K_GLOBAL dimension of the A and B matrices and accumulating
-// the intermediate result in the local thread state.
-
-// There are a number of simple optimizations used in the algorithm:
-// - The CTA copies the 64 x 64 tile of the C matrix from the global memory to
-//   shared memory. After that is done, each warp loads the C matrix fragments from
-//   shared memory, thus avoiding a random global memory access.
-// - On each internal iteration, the CTA copies a portion of the A and B matrices from
-//   global memory to shared memory. After that, all warps in the CTA reuse the A and B
-//   data from shared memory, thus reducing the number of data copies from global memory.
-// - The portions of the A and B matrices are stored in shared memory with an additional
-//   padding (skew) to reduce the number of shared memory access bank conflicts.
-//   (See a detailed explanation near the SKEW_DOUBLE macro definition.)
-// - When the CTA finishes computing the tiles of the resulting matrix, each warp stores
-//   its subtiles to shared memory. The CTA then copies the shared memory contents to
-//   global memory, again avoiding redundant random global memory accesses.
-// - Note that the CTA tile size is chosen to maximize the GPU register utilization,
-//   but carefully enough to avoid local memory use.
-
-#include <assert.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <hip/hip_runtime.h>
-#include <mma.h>
-#include <hip/hip_cooperative_groups.h>
-#include "cooperative_groups/memcpy_async.h"
-#include <cuda/std/type_traits>
-#include <cuda/barrier>
-#include <cuda/pipeline>
-
-// helper functions and utilities to work with CUDA
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-
-// Externally configurable parameters.
-
-#ifndef CPU_DEBUG
-// Set this to 1 to verify the correctness of the GPU-computed matrix.
-#define CPU_DEBUG 0
-#endif
-
-#ifndef SHARED_MEMORY_LIMIT_64K
-// Set this to 0 to use more than 64 Kb of shared memory to cache data, to
-// improve the performance of the computations on GPU.
-// Note that you need a GPU that can have more than 64 Kb of shared memory
-// per multiprocessor.
-#define SHARED_MEMORY_LIMIT_64K 0
-#endif
-
-// GPU configuration.
-
-#define WARP_SIZE 32
-
-// MMA matrix tile dimensions.
-
-#define M 8
-#define N 8
-#define K 4
-
-// GEMM configuration.
-
-#define M_TILES 1024
-#define N_TILES 1024
-#define K_TILES 1024
-
-#define M_GLOBAL (M * M_TILES)
-#define N_GLOBAL (N * N_TILES)
-#define K_GLOBAL (K * K_TILES)
-
-#define C_LAYOUT wmma::mem_row_major
-
-// Implementation constants.
-
-#define WARPS_PER_BLOCK 8
-#define THREADS_PER_BLOCK (WARP_SIZE * WARPS_PER_BLOCK)
-
-#if SHARED_MEMORY_LIMIT_64K
-// With only 64 Kb shared memory available, we can fit 8x16-tile chunks of each
-// the A and B matrix data, that are (M = 8) * (K = 4) * 8 * (CHUNK_K = 16) * sizeof(double) = 32 Kb each
-// But we cannot account the 4 Kb total skew overhead, without which the performance
-// would be severely impacted. So we choose to reduce the chunk size in half,
-// i.e. the amount of A and B matrix data we cache in shared memory.
-// Accordingly, this doubles the number of outer iterations across the global K
-// dimension, which only slightly impacts the performance.
-#define CHUNK_K 8
-#else
-#define CHUNK_K 16
-#endif
-
-#define CHUNK_LINE_BYTES (CHUNK_K * K * sizeof(double))
-#define WARP_COPY_BYTES (WARP_SIZE * sizeof(int4))
-#define CHUNK_COPY_LINES_PER_WARP (WARP_COPY_BYTES / CHUNK_LINE_BYTES)
-#define CHUNK_COPY_LINE_LANES (WARP_SIZE / CHUNK_COPY_LINES_PER_WARP)
-
-#define BLOCK_ROW_WARPS 2
-#define BLOCK_COL_WARPS 4
-
-#define WARP_ROW_TILES 4
-#define WARP_COL_TILES 2
-
-#define BLOCK_ROW_TILES (WARP_ROW_TILES * BLOCK_ROW_WARPS)
-#define BLOCK_COL_TILES (WARP_COL_TILES * BLOCK_COL_WARPS)
-
-#define GLOBAL_MEM_STRIDE N_GLOBAL
-
-#define SHMEM_STRIDE (N * BLOCK_ROW_TILES)
-#define SHMEM_OFFSET (N * WARP_ROW_TILES)
-
-// The macro below is used to shift rows of the A matrix and columns of the B matrix
-// in shared memory to minimize possible bank conflicts.
-// Before performing the nvcuda::wmma::mma_sync operation, the warp must load the matrix
-// data using the nvcuda::wmma::load_matrix_sync operation. Although the memory access pattern
-// is not specified for that function, each lane in the warp can read one or multiple matrix
-// elements from different matrix rows or columns.
-// For shared memory, such access can result in bank conflicts if different rows / columns
-// of the matrix map to the same bank. By shifting each row and column by a few bytes, we
-// make sure that they map to different banks, thus reducing the number of possible bank
-// conflicts.
-// The number of 4 eight-byte "double" elements is chosen as the minimum possible shift because
-// we must keep each row and column 256-bit aligned, as required by nvcuda::wmma::load_matrix_sync.
-#define SKEW_DOUBLE 4
-
-#define checkKernelErrors(expr) do {                                                        \
-    expr;                                                                                   \
-                                                                                            \
-    hipError_t __err = hipGetLastError();                                                 \
-    if (__err != hipSuccess) {                                                             \
-        printf("Line %d: '%s' failed: %s\n", __LINE__, # expr, hipGetErrorString(__err));  \
-        abort();                                                                            \
-    }                                                                                       \
-} while(0)
-
-enum kernels
-{
-    dmma_shmem_gemm_async_copy      = 0, // DMMA shmem using kernel with async_copy
-    dmma_shmem_gemm_cg_async_copy   = 1, // DMMA shmem using kernel with cooperative groups async_copy
-    dmma_shmem_gemm                 = 2, // DMMA shmem using kernel normal copy (without async_copy).
-    simple_dmma_gemm                = 3  // DMMA non-shmem using simple kernel.
-};
-
-const char* kernelNames[] = {"compute_dgemm_async_copy", "compute_dgemm_cg_async_copy",
-                            "compute_dgemm", "simple_wmma_gemm"};
-
-using namespace nvcuda;
-namespace cg = cooperative_groups;
-
-__host__ void init_host_matrices(double *a, double *b, double *c)
-{
-    for (int i = 0; i < M_GLOBAL; i++) {
-        for (int j = 0; j < K_GLOBAL; j++) {
-            a[i*K_GLOBAL+j] = (double) (rand() % 3);
-        }
-    }
-
-    for (int i = 0; i < N_GLOBAL; i++) {
-        for (int j = 0; j < K_GLOBAL; j++) {
-            b[i*K_GLOBAL+j] = (double) (rand() % 3);
-        }
-    }
-
-    for (int t = 0; t < M_GLOBAL * N_GLOBAL; t++) {
-        c[t] =  (double) (rand() % 3);
-    }
-}
-
-__global__ void compute_dgemm(const double *A, const double *B, const double *C, double *D, double alpha, double beta)
-{
-#if __CUDA_ARCH__ >= 800
-    extern __shared__ double shmem[][CHUNK_K * K + SKEW_DOUBLE];
-
-    // Warp and lane identification.
-    const unsigned int warpId = threadIdx.x / WARP_SIZE;
-    const unsigned int laneId = threadIdx.x % WARP_SIZE;
-
-    // Offset in shared memory from which the B matrix is stored.
-    const size_t shmem_idx_b_off = BLOCK_COL_TILES * M;
-
-
-    // This pointer is used to access the C and D matrix tiles this warp computes.
-    double *shmem_warp_tile_ptr = (double*)&shmem[0][0] + (warpId / BLOCK_ROW_WARPS) * SHMEM_STRIDE * N * BLOCK_ROW_WARPS + (warpId % BLOCK_ROW_WARPS) * SHMEM_OFFSET;
-
-    // This pointer is used to stream the C and D matrices block-wide tile to and from shared memory.
-    double *shmem_warp_stream_ptr = (double*)&shmem[0][0] + warpId * SHMEM_STRIDE * N;
-
-    // Adjust the beta scaler, as it'll be multiplied by alpha at the end of
-    // each tile computation. Technically this is not generally correct (may result
-    // in a loss of precision). Zero still needs to be specially handled though.
-    beta /= alpha;
-
-    // Each CTA slides along the 64 x 64 tiles from the top left corner of the matrix to the
-    // right and down, and selects the next tile to compute. Once there's no such tile,
-    // all warps in this CTA exit.
-    for(unsigned int block_pos = blockIdx.x;; block_pos += gridDim.x) {
-        const unsigned int block_tile_i = ((block_pos * BLOCK_ROW_TILES) / N_TILES) * (BLOCK_COL_TILES);
-        const unsigned int block_tile_j = (block_pos * BLOCK_COL_TILES) % N_TILES;
-
-        // Stop when there are no more D matrix tiles to compute in this CTA.
-        if (block_tile_i >= M_TILES) {
-            break;
-        }
-
-        // This warp's pointer to the C matrix data to copy memory from to shared memory.
-        const size_t gmem_idx = (block_tile_i + warpId) * M * GLOBAL_MEM_STRIDE + block_tile_j * N;
-        const double *src_gmem_warp_stream_ptr = &C[gmem_idx];
-
-        // Stream multiple C tiles to shared memory.
-#pragma unroll
-        for (int i = 0; i < N; i++) {
-            *((int4 *)(shmem_warp_stream_ptr + SHMEM_STRIDE * i) + laneId) =
-                *((int4 *)(src_gmem_warp_stream_ptr + GLOBAL_MEM_STRIDE * i) + laneId);
-        }
-
-        __syncthreads();
-
-        // These fragments will accumulate the result of A and B matrix fragment multiplications
-        // along the K_GLOBAL dimension.
-        wmma::fragment<wmma::accumulator, M, N, K, double> c[WARP_COL_TILES][WARP_ROW_TILES];
-
-        // Load the C matrix tiles into fragments from shared memory.
-#pragma unroll
-        for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-            for (int j = 0; j < WARP_ROW_TILES; j++) {
-                const double *tile_ptr = shmem_warp_tile_ptr + i * SHMEM_STRIDE * N + j * N;
-
-                wmma::load_matrix_sync(c[i][j], tile_ptr, SHMEM_STRIDE, C_LAYOUT);
-            }
-        }
-
-        __syncthreads();
-
-        // Scale the C matrix.
-#pragma unroll
-       for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-            for (int j = 0; j < WARP_ROW_TILES; j++) {
-#pragma unroll
-                for (int t = 0; t < c[i][j].num_elements; t++) {
-                    c[i][j].x[t] *= beta;
-                }
-            }
-        }
-
-        // Select what warp copies what matrix to shared memory.
-        // Warps 0-3 copy the A matrix, warps 4-7 copy the B matrix.
-        const double *warp_ptr = (warpId < (WARPS_PER_BLOCK/2)) ? (&A[block_tile_i * M * K_GLOBAL] + M * K_GLOBAL * (warpId % (WARPS_PER_BLOCK/2)) * 2) :
-                                              (&B[block_tile_j * N * K_GLOBAL] + N * K_GLOBAL * (warpId % (WARPS_PER_BLOCK/2)) * 2);
-
-        // Go through the global K dimension by a fixed step at a time.
-#pragma unroll
-        for (int tile_k = 0; tile_k < K_TILES; tile_k += CHUNK_K) {
-            // Copy slices of the A and B matrices to shared memory.
-            // The first half of the warps in the CTA copy the A matrix, the rest copy the B matrix.
-            size_t shmem_idx = warpId < (WARPS_PER_BLOCK/2) ? (M * (warpId % (WARPS_PER_BLOCK/2)) * 2) :
-                                                              (N * (warpId % (WARPS_PER_BLOCK/2)) * 2 + shmem_idx_b_off);
-
-            // First half of the warp copies the first row / column of the matrix,
-            // the second half of the warp copies the next.
-            const double *lane_ptr = warp_ptr + tile_k * K + (laneId / CHUNK_COPY_LINE_LANES) * K_GLOBAL;
-
-            // Shift the second half of the warp to the next row / column in the shared memory.
-            shmem_idx += laneId / CHUNK_COPY_LINE_LANES;
-
-#pragma unroll
-            for(int i = 0; i < ((WARP_SIZE/2) / CHUNK_COPY_LINES_PER_WARP); i++) {
-                 // Copy 16 bytes at once in each lane.
-                *((int4*)&shmem[shmem_idx][0] + (laneId % CHUNK_COPY_LINE_LANES)) = *((int4*)lane_ptr +  (laneId % CHUNK_COPY_LINE_LANES));
-
-                // Advance the global memory pointer and the shared memory index.
-                lane_ptr = lane_ptr + K_GLOBAL * CHUNK_COPY_LINES_PER_WARP;
-                shmem_idx += CHUNK_COPY_LINES_PER_WARP;
-            }
-
-            __syncthreads();
-
-            // Compute a grid of C matrix tiles in each warp.
-#pragma unroll
-            for (int k_step = 0; k_step < CHUNK_K; k_step++) {
-                wmma::fragment<wmma::matrix_a, M, N, K, double, wmma::row_major> a[WARP_COL_TILES];
-                wmma::fragment<wmma::matrix_b, M, N, K, double, wmma::col_major> b[WARP_ROW_TILES];
-
-#pragma unroll
-                for (int i = 0; i < WARP_COL_TILES; i++) {
-                    size_t shmem_idx_a = (warpId/2) * M * 2 + (i * M);
-                    const double *tile_ptr = &shmem[shmem_idx_a][k_step * K];
-
-                    wmma::load_matrix_sync(a[i], tile_ptr, K * CHUNK_K + SKEW_DOUBLE);
-
-#pragma unroll
-                    for (int j = 0; j < WARP_ROW_TILES; j++) {
-                        if (i == 0) {
-                            // Load the B matrix fragment once, because it is going to be reused
-                            // against the other A matrix fragments.
-                            size_t shmem_idx_b = shmem_idx_b_off + (WARP_ROW_TILES * N) * (warpId%2) + (j * N);
-                            const double *tile_ptr = &shmem[shmem_idx_b][k_step * K];
-
-                            wmma::load_matrix_sync(b[j], tile_ptr, K * CHUNK_K + SKEW_DOUBLE);
-
-                        }
-
-                        wmma::mma_sync(c[i][j], a[i], b[j], c[i][j]);
-                    }
-                }
-            }
-
-            __syncthreads();
-        }
-
-        // Store the D fragments to shared memory.
-#pragma unroll
-        for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-            for (int j = 0; j < WARP_ROW_TILES; j++) {
-                // Uniform, point-wise transformations of ALL fragment elements by ALL threads in the
-                // warp are well-defined even though element indices within fragment storage are not defined.
-#pragma unroll
-                for (int t = 0; t < c[i][j].num_elements; t++)
-                    c[i][j].x[t] *= alpha;
-
-                double *tile_ptr = shmem_warp_tile_ptr + i * SHMEM_STRIDE * N + j * N;
-
-                wmma::store_matrix_sync(tile_ptr, c[i][j], SHMEM_STRIDE, C_LAYOUT);
-            }
-        }
-
-        __syncthreads();
-
-        // Now that shared memory contains all the D tiles, stream them to global memory.
-        double *dst_gmem_warp_stream_ptr = &D[gmem_idx];
-
-#pragma unroll
-        for (int i = 0; i < N; i++) {
-            *((int4*)(dst_gmem_warp_stream_ptr + GLOBAL_MEM_STRIDE * i) + laneId) =
-                *((int4*)(shmem_warp_stream_ptr + SHMEM_STRIDE * i) + laneId);
-        }
-
-        __syncthreads();
-    }
-#endif
-}
-
-__global__ void compute_dgemm_async_copy(const double *A, const double *B, const double *C, double *D, double alpha, double beta)
-{
-#if __CUDA_ARCH__ >= 800
-    extern __shared__ double shmem[][CHUNK_K * K + SKEW_DOUBLE];
-
-    // Warp and lane identification.
-    const unsigned int warpId = threadIdx.x / WARP_SIZE;
-    const unsigned int laneId = threadIdx.x % WARP_SIZE;
-
-    // Offset in shared memory from which the B matrix is stored.
-    constexpr size_t shmem_idx_b_off = BLOCK_COL_TILES * M;
-
-    // This pointer is used to access the C and D matrix tiles this warp computes.
-    double *shmem_warp_tile_ptr = &shmem[0][0] + (warpId/BLOCK_ROW_WARPS) * SHMEM_STRIDE * N * BLOCK_ROW_WARPS + (warpId % BLOCK_ROW_WARPS) * SHMEM_OFFSET;
-
-    // This pointer is used to stream the C and D matrices block-wide tile to and from shared memory.
-    double *shmem_warp_stream_ptr = &shmem[0][0] + warpId * SHMEM_STRIDE * N;
-
-    // Adjust the beta scaler, as it'll be multiplied by alpha at the end of
-    // each tile computation. Technically this is not generally correct (may result
-    // in a loss of precision). Zero still needs to be specially handled though.
-    beta /= alpha;
-
-    cuda::pipeline<cuda::thread_scope_thread> pipe = cuda::make_pipeline();
-
-    const auto shape2 = cuda::aligned_size_t<alignof(double2)>(sizeof(double2));
-    constexpr int loadStride = 1; // load 2 double, left-shift by 1.
-
-    // Each CTA slides along the 64 x 64 tiles from the top left corner of the matrix to the
-    // right and down, and selects the next tile to compute. Once there's no such tile,
-    // all warps in this CTA exit.
-    for(unsigned int block_pos = blockIdx.x;; block_pos += gridDim.x) {
-        const unsigned int block_tile_i = ((block_pos * BLOCK_ROW_TILES) / N_TILES) * (BLOCK_COL_TILES);
-        const unsigned int block_tile_j = (block_pos * BLOCK_COL_TILES) % N_TILES;
-
-        // Stop when there are no more D matrix tiles to compute in this CTA.
-        if (block_tile_i >= M_TILES) {
-            break;
-        }
-
-        // This warp's pointer to the C matrix data to copy memory from to shared memory.
-        const size_t gmem_idx = (block_tile_i + warpId) * M * GLOBAL_MEM_STRIDE + block_tile_j * N;
-        const double *src_gmem_warp_stream_ptr = &C[gmem_idx];
-
-        // Stream multiple C tiles to shared memory.
-#pragma unroll
-        for (int i = 0; i < N; i++) {
-            pipe.producer_acquire();
-            cuda::memcpy_async(&shmem_warp_stream_ptr[(SHMEM_STRIDE * i) + (laneId << loadStride)],
-                                &src_gmem_warp_stream_ptr[(GLOBAL_MEM_STRIDE * i) + (laneId << loadStride)],
-                                shape2, pipe);
-
-            pipe.producer_commit();
-        }
-        // Now wait for all the above issued 8 batches to complete.
-        cuda::pipeline_consumer_wait_prior<0>(pipe);
-        __syncthreads();
-
-        // These fragments will accumulate the result of A and B matrix fragment multiplications
-        // along the K_GLOBAL dimension.
-        wmma::fragment<wmma::accumulator, M, N, K, double> c[WARP_COL_TILES][WARP_ROW_TILES];
-
-        // Load the C matrix tiles into fragments from shared memory.
-#pragma unroll
-        for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-            for (int j = 0; j < WARP_ROW_TILES; j++) {
-                const double *tile_ptr = shmem_warp_tile_ptr + i * SHMEM_STRIDE * N + j * N;
-
-                wmma::load_matrix_sync(c[i][j], tile_ptr, SHMEM_STRIDE, C_LAYOUT);
-                // Scale the C matrix.
-#pragma unroll
-                for (int t = 0; t < c[i][j].num_elements; t++) {
-                    c[i][j].x[t] *= beta;
-                }
-            }
-        }
-
-        pipe.consumer_release();
-        // sync here so that shared memory can then be used for loading A & B matrices.
-        __syncthreads();
-
-        // Select what warp copies what matrix to shared memory.
-        // Warps 0-3 copy the A matrix, warps 4-7 copy the B matrix.
-        const double *warp_ptr = (warpId < (WARPS_PER_BLOCK/2)) ? (&A[block_tile_i * M * K_GLOBAL] + M * K_GLOBAL * (warpId % (WARPS_PER_BLOCK/2)) * 2) :
-                                              (&B[block_tile_j * N * K_GLOBAL] + N * K_GLOBAL * (warpId % (WARPS_PER_BLOCK/2)) * 2);
-
-        const int stridePerLaneCopy = (laneId / CHUNK_COPY_LINE_LANES);
-        constexpr int chunksPerLane = ((WARP_SIZE/2) / CHUNK_COPY_LINES_PER_WARP);
-        const int laneLoadElem = (laneId % CHUNK_COPY_LINE_LANES) << loadStride;
-
-        // Go through the global K dimension by a fixed step at a time.
-#pragma unroll
-        for (int tile_k = 0; tile_k < K_TILES; tile_k += CHUNK_K) {
-            // Copy slices of the A and B matrices to shared memory.
-            // The first half of the warps in the CTA copy the A matrix, the rest copy the B matrix.
-            // As for DMMA  M == N we use M for warp 4-7 + shmem_idx_b_off.
-            size_t shmem_idx = (M * (warpId % (WARPS_PER_BLOCK/2)) * 2) + (shmem_idx_b_off * (warpId/(WARPS_PER_BLOCK/2)));
-
-            // First half of the warp copies the first row / column of the matrix,
-            // the second half of the warp copies the next.
-            const double *lane_ptr = warp_ptr + tile_k * K + stridePerLaneCopy * K_GLOBAL + laneLoadElem;
-
-            // Shift the second half of the warp to the next row / column in the shared memory.
-            shmem_idx += stridePerLaneCopy;
-#pragma unroll
-            for(int i = 0; i < chunksPerLane; i++) {
-                 // Copy 16 bytes at once in each lane.
-                pipe.producer_acquire();
-
-                cuda::memcpy_async(&shmem[shmem_idx][laneLoadElem], lane_ptr, shape2, pipe);
-
-                pipe.producer_commit();
-
-                // Advance the global memory pointer and the shared memory index.
-                lane_ptr = lane_ptr + K_GLOBAL * CHUNK_COPY_LINES_PER_WARP;
-                shmem_idx += CHUNK_COPY_LINES_PER_WARP;
-            }
-
-            cuda::pipeline_consumer_wait_prior<0>(pipe);
-            __syncthreads();
-
-            // Compute a grid of C matrix tiles in each warp.
-#pragma unroll
-            for (int k_step = 0; k_step < CHUNK_K; k_step++) {
-                wmma::fragment<wmma::matrix_a, M, N, K, double, wmma::row_major> a[WARP_COL_TILES];
-                wmma::fragment<wmma::matrix_b, M, N, K, double, wmma::col_major> b[WARP_ROW_TILES];
-#pragma unroll
-                for (int i = 0; i < WARP_COL_TILES; i++) {
-                    size_t shmem_idx_a = (warpId/2) * M * 2 + (i * M);
-                    const double *tile_ptr = &shmem[shmem_idx_a][k_step * K];
-
-                    wmma::load_matrix_sync(a[i], tile_ptr, K * CHUNK_K + SKEW_DOUBLE);
-#pragma unroll
-                    for (int j = 0; j < WARP_ROW_TILES; j++) {
-                        if (i == 0) {
-                            // Load the B matrix fragment once, because it is going to be reused
-                            // against the other A matrix fragments.
-                            size_t shmem_idx_b = shmem_idx_b_off + (WARP_ROW_TILES * N) * (warpId%2) + (j * N);
-                            const double *tile_ptr = &shmem[shmem_idx_b][k_step * K];
-
-                            wmma::load_matrix_sync(b[j], tile_ptr, K * CHUNK_K + SKEW_DOUBLE);
-                        }
-                        wmma::mma_sync(c[i][j], a[i], b[j], c[i][j]);
-                    }
-                }
-            }
-            pipe.consumer_release();
-            __syncthreads();
-        }
-
-        // Store the D fragments to shared memory.
-#pragma unroll
-        for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-            for (int j = 0; j < WARP_ROW_TILES; j++) {
-                // Uniform, point-wise transformations of ALL fragment elements by ALL threads in the
-                // warp are well-defined even though element indices within fragment storage are not defined.
-#pragma unroll
-                for (int t = 0; t < c[i][j].num_elements; t++)
-                    c[i][j].x[t] *= alpha;
-
-                double *tile_ptr = shmem_warp_tile_ptr + i * SHMEM_STRIDE * N + j * N;
-
-                wmma::store_matrix_sync(tile_ptr, c[i][j], SHMEM_STRIDE, C_LAYOUT);
-            }
-        }
-
-        __syncthreads();
-
-        // Now that shared memory contains all the D tiles, stream them to global memory.
-        double *dst_gmem_warp_stream_ptr = &D[gmem_idx];
-
-#pragma unroll
-        for (int i = 0; i < N; i++) {
-            *((int4*)(dst_gmem_warp_stream_ptr + GLOBAL_MEM_STRIDE * i) + laneId) =
-                *((int4*)(shmem_warp_stream_ptr + SHMEM_STRIDE * i) + laneId);
-        }
-
-        __syncthreads();
-    }
-#endif
-}
-
- __global__ void compute_dgemm_cg_async_copy(const double *A, const double *B, const double *C, double *D, double alpha, double beta)
-{
-#if __CUDA_ARCH__ >= 800
-    extern __shared__ double shmem[][CHUNK_K * K + SKEW_DOUBLE];
-    auto cta = cg::this_thread_block();
-    auto tile32 = cg::tiled_partition<32>(cta);
-
-    constexpr int tileChunkCopySize = WARP_SIZE / CHUNK_COPY_LINES_PER_WARP;
-    auto tileChunkCopy = cg::tiled_partition<tileChunkCopySize>(cta);
-
-    // Warp and lane identification.
-    const unsigned int warpId = threadIdx.x / WARP_SIZE;
-    const unsigned int laneId = threadIdx.x % WARP_SIZE;
-
-    // Offset in shared memory from which the B matrix is stored.
-    constexpr size_t shmem_idx_b_off = BLOCK_COL_TILES * M;
-
-    // This pointer is used to access the C and D matrix tiles this warp computes.
-    double *shmem_warp_tile_ptr = (double*)&shmem[0][0] + (warpId/2) * SHMEM_STRIDE * N * 2 + (warpId%2) * SHMEM_OFFSET;
-
-    // This pointer is used to stream the C and D matrices block-wide tile to and from shared memory.
-    double *shmem_warp_stream_ptr = (double*)&shmem[0][0] + warpId * SHMEM_STRIDE * N;
-
-    // Adjust the beta scaler, as it'll be multiplied by alpha at the end of
-    // each tile computation. Technically this is not generally correct (may result
-    // in a loss of precision). Zero still needs to be specially handled though.
-    beta /= alpha;
-
-    // Each CTA slides along the 64 x 64 tiles from the top left corner of the matrix to the
-    // right and down, and selects the next tile to compute. Once there's no such tile,
-    // all warps in this CTA exit.
-    for(unsigned int block_pos = blockIdx.x;; block_pos += gridDim.x) {
-        const unsigned int block_tile_i = ((block_pos * BLOCK_ROW_TILES) / N_TILES) * (BLOCK_COL_TILES);
-        const unsigned int block_tile_j = (block_pos * BLOCK_COL_TILES) % N_TILES;
-
-        // Stop when there are no more D matrix tiles to compute in this CTA.
-        if (block_tile_i >= M_TILES) {
-            break;
-        }
-
-        // This warp's pointer to the C matrix data to copy memory from to shared memory.
-        const size_t gmem_idx = (block_tile_i + warpId) * M * GLOBAL_MEM_STRIDE + block_tile_j * N;
-        const double *src_gmem_warp_stream_ptr = &C[gmem_idx];
-
-        // Stream multiple C tiles to shared memory.
-#pragma unroll
-        for (int i = 0; i < N; i++) {
-            auto dst_ptr = &shmem_warp_stream_ptr[(SHMEM_STRIDE * i)];
-            auto src_ptr = &src_gmem_warp_stream_ptr[(GLOBAL_MEM_STRIDE * i)];
-            cg::memcpy_async(tile32, dst_ptr, src_ptr, cuda::aligned_size_t<alignof(double2)>{tile32.size() * sizeof(double2)});
-        }
-
-        cg::wait(cta);
-
-        // These fragments will accumulate the result of A and B matrix fragment multiplications
-        // along the K_GLOBAL dimension.
-        wmma::fragment<wmma::accumulator, M, N, K, double> c[WARP_COL_TILES][WARP_ROW_TILES];
-
-        // Load the C matrix tiles into fragments from shared memory.
-#pragma unroll
-        for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-            for (int j = 0; j < WARP_ROW_TILES; j++) {
-                const double *tile_ptr = shmem_warp_tile_ptr + i * SHMEM_STRIDE * N + j * N;
-                wmma::load_matrix_sync(c[i][j], tile_ptr, SHMEM_STRIDE, C_LAYOUT);
-            }
-        }
-
-        // Scale the C matrix.
-#pragma unroll
-        for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-            for (int j = 0; j < WARP_ROW_TILES; j++) {
-#pragma unroll
-                for (int t = 0; t < c[i][j].num_elements; t++) {
-                    c[i][j].x[t] *= beta;
-                }
-            }
-        }
-
-        // sync here so that shared memory can then be used for loading A & B matrices.
-        cg::wait(cta);
-        // Select what warp copies what matrix to shared memory.
-        // Warps 0-3 copy the A matrix, warps 4-7 copy the B matrix.
-        const double *warp_ptr = (warpId < 4) ? (&A[block_tile_i * M * K_GLOBAL] + M * K_GLOBAL * (warpId % (WARPS_PER_BLOCK/2)) * 2) :
-            (&B[block_tile_j * N * K_GLOBAL] + N * K_GLOBAL * (warpId % (WARPS_PER_BLOCK/2)) * 2);
-
-        const int stridePerLaneCopy = (laneId / CHUNK_COPY_LINE_LANES);
-        constexpr int chunksPerLane = ((WARP_SIZE/2) / CHUNK_COPY_LINES_PER_WARP);
-        // Go through the global K dimension by a fixed step at a time.
-#pragma unroll
-        for (int tile_k = 0; tile_k < K_TILES; tile_k += CHUNK_K) {
-            // Copy slices of the A and B matrices to shared memory.
-            // The first half of the warps in the CTA copy the A matrix, the rest copy the B matrix.
-            // As for DMMA  M == N we use M for warp 4-7 + shmem_idx_b_off.
-            size_t shmem_idx = (M * (warpId % (WARPS_PER_BLOCK/2)) * 2) + (shmem_idx_b_off * (warpId/(WARPS_PER_BLOCK/2)));
-
-            // First half of the warp copies the first row / column of the matrix,
-            // the second half of the warp copies the next.
-            auto lane_ptr = warp_ptr + tile_k * K + stridePerLaneCopy * K_GLOBAL;
-
-            // Shift the second half of the warp to the next row / column in the shared memory.
-            shmem_idx += stridePerLaneCopy;
-
-#pragma unroll
-            for(int i = 0; i < chunksPerLane; i++) {
-                // Copy 16 bytes at once in each lane.
-                auto dst_ptr = &shmem[shmem_idx][0];
-                auto src_ptr = lane_ptr;
-
-                cg::memcpy_async(tileChunkCopy, dst_ptr, src_ptr, 
-                                cuda::aligned_size_t<alignof(double2)>{tileChunkCopySize * sizeof(double2)});
-
-                // Advance the global memory pointer and the shared memory index.
-                lane_ptr = lane_ptr + K_GLOBAL * CHUNK_COPY_LINES_PER_WARP;
-                shmem_idx += CHUNK_COPY_LINES_PER_WARP;
-            }
-            cg::wait(cta);
-
-            // Compute a grid of C matrix tiles in each warp.
-#pragma unroll
-            for (int k_step = 0; k_step < CHUNK_K; k_step++) {
-                wmma::fragment<wmma::matrix_a, M, N, K, double, wmma::row_major> a[WARP_COL_TILES];
-                wmma::fragment<wmma::matrix_b, M, N, K, double, wmma::col_major> b[WARP_ROW_TILES];
-
-#pragma unroll
-                for (int i = 0; i < WARP_COL_TILES; i++) {
-                    size_t shmem_idx_a = (warpId/2) * M * 2 + (i * M);
-                    const double *tile_ptr = &shmem[shmem_idx_a][k_step * K];
-
-                    wmma::load_matrix_sync(a[i], tile_ptr, K * CHUNK_K + SKEW_DOUBLE);
-
-#pragma unroll
-                    for (int j = 0; j < WARP_ROW_TILES; j++) {
-                        if (i == 0) {
-                            // Load the B matrix fragment once, because it is going to be reused
-                            // against the other A matrix fragments.
-                            size_t shmem_idx_b = shmem_idx_b_off + (WARP_ROW_TILES * N) * (warpId%2) + (j * N);
-                            const double *tile_ptr = &shmem[shmem_idx_b][k_step * K];
-
-                            wmma::load_matrix_sync(b[j], tile_ptr, K * CHUNK_K + SKEW_DOUBLE);
-
-                        }
-
-                        wmma::mma_sync(c[i][j], a[i], b[j], c[i][j]);
-                    }
-                }
-            }
-            cg::sync(cta);
-        }
-
-        // Store the D fragments to shared memory.
-#pragma unroll
-        for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-            for (int j = 0; j < WARP_ROW_TILES; j++) {
-                // Uniform, point-wise transformations of ALL fragment elements by ALL threads in the
-                // warp are well-defined even though element indices within fragment storage are not defined.
-#pragma unroll
-                for (int t = 0; t < c[i][j].num_elements; t++)
-                    c[i][j].x[t] *= alpha;
-
-                double *tile_ptr = shmem_warp_tile_ptr + i * SHMEM_STRIDE * N + j * N;
-
-                wmma::store_matrix_sync(tile_ptr, c[i][j], SHMEM_STRIDE, C_LAYOUT);
-            }
-        }
-
-        cg::sync(cta);
-
-        // Now that shared memory contains all the D tiles, stream them to global memory.
-        double *dst_gmem_warp_stream_ptr = &D[gmem_idx];
-
-#pragma unroll
-        for (int i = 0; i < N; i++) {
-            *((int4*)(dst_gmem_warp_stream_ptr + GLOBAL_MEM_STRIDE * i) + laneId) =
-                *((int4*)(shmem_warp_stream_ptr + SHMEM_STRIDE * i) + laneId);
-        }
-        cg::sync(cta);
-    }
-#endif
-}
-
-// Performs an MxNxK DGEMM (C=alpha*A*B + beta*C) assuming:
-//  1) Matrices are packed in memory.
-//  2) M, N and K are multiples of 8, 8 and 4 respectively. 
-//  3) A is row major, B is column major matrix.
-// Note: This is a less performant version of the compute_dgemm kernel. It is designed for
-//       demonstration purposes only to show the CUDA WMMA API use without relying on
-//       availability of the shared memory.
-__global__ void simple_wmma_gemm(double *a, double *b, double *c, double *d, int m_ld, int n_ld, int k_ld, double alpha, double beta)
-{
-#if __CUDA_ARCH__ >= 800
-    // Leading dimensions. Packed with no transpositions.
-    int lda = k_ld;
-    int ldb = k_ld;
-    int ldc = n_ld;
-
-    // Tile using a 2D grid
-    int warpM = (blockIdx.x * blockDim.x + threadIdx.x) / warpSize;
-    int warpN = (blockIdx.y * blockDim.y + threadIdx.y);
-
-    // Declare the fragments
-    wmma::fragment<wmma::matrix_a, M, N, K, double, wmma::row_major> a_frag;
-    wmma::fragment<wmma::matrix_b, M, N, K, double, wmma::col_major> b_frag;
-    wmma::fragment<wmma::accumulator, M, N, K, double> acc_frag;
-    wmma::fragment<wmma::accumulator, M, N, K, double> c_frag;
-
-    wmma::fill_fragment(acc_frag, 0.0f);
-
-    // Loop over k
-    for (int i = 0; i < k_ld; i += K) {
-        int aCol = i;
-        int aRow = warpM * M;
-
-        int bCol = warpN * N;
-        int bRow = i;
-
-        // Bounds checking
-        if (aRow < m_ld && aCol < k_ld && bRow < k_ld && bCol < n_ld) {
-            // Load the inputs
-            wmma::load_matrix_sync(a_frag, a + aCol + aRow * lda, lda);
-            wmma::load_matrix_sync(b_frag, b + bRow + bCol * ldb, ldb);
-
-            // Perform the matrix multiplication
-            wmma::mma_sync(acc_frag, a_frag, b_frag, acc_frag);
-        }
-    }
-
-    // Load in the current value of c, scale it by beta, and add this our result scaled by alpha
-    int cCol = warpN * N;
-    int cRow = warpM * M;
-
-    if (cRow < m_ld && cCol < n_ld) {
-        wmma::load_matrix_sync(c_frag, c + cCol + cRow * ldc, ldc, wmma::mem_row_major);
-
-        for(int i=0; i < c_frag.num_elements; i++) {
-            c_frag.x[i] = alpha * acc_frag.x[i] + beta * c_frag.x[i];
-        }
-
-        // Store the output
-        wmma::store_matrix_sync(d + cCol + cRow * ldc, c_frag, ldc, wmma::mem_row_major);
-    }
-#endif
-}
-
-__host__ void matMultiplyOnHost(double *A, double *B, double *C,
-                                float alpha, float beta,
-                                int numARows, int numAColumns,
-                                int numBRows, int numBColumns,
-                                int numCRows, int numCColumns)
-{
-    for (int i = 0; i < numCRows; i++) {
-        for (int j = 0; j < numCColumns; j++) {
-            double temp = 0.0;
-
-            for (int k = 0; k < numAColumns; k++) {
-                // B matrix is column major. A matrix is row major.
-                temp += A[i * numAColumns + k] * B[j * numBRows + k];
-            }
-
-            C[i*numCColumns + j] = temp * alpha + beta * C[i * numCColumns + j];
-        }
-    }
-}
-
-int main(int argc, char **argv)
-{
-    printf("Initializing...\n");
-
-    int dev = findCudaDevice(argc, (const char **)argv);
-
-    hipDeviceProp_t deviceProp;
-    checkCudaErrors(hipGetDeviceProperties(&deviceProp, dev));
-
-    // Double precision Tensor cores require a GPU of Ampere (SM8X) architecture or higher.
-    if (deviceProp.major < 8) {
-        printf("dmmaTensorCoreGemm requires SM 8.0 or higher.  Exiting...\n");
-        exit(EXIT_WAIVED);
-    }
-
-    printf("M: %d (%d x %d)\n", M_GLOBAL, M, M_TILES);
-    printf("N: %d (%d x %d)\n", N_GLOBAL, N, N_TILES);
-    printf("K: %d (%d x %d)\n", K_GLOBAL, K, K_TILES);
-
-    double *A_h = NULL;
-    double *B_h = NULL;
-    double *C_h = NULL;
-#if CPU_DEBUG
-    double *result_hD = NULL;
-    double *result_host = NULL;
-#endif
-
-    A_h = (double*) malloc(sizeof(double) * M_GLOBAL * K_GLOBAL);
-    B_h = (double*) malloc(sizeof(double) * K_GLOBAL * N_GLOBAL);
-    C_h = (double*) malloc(sizeof(double) * M_GLOBAL * N_GLOBAL);
-#if CPU_DEBUG
-    result_hD   = (double*) malloc(sizeof(double) * M_GLOBAL * N_GLOBAL);
-    result_host = (double*) malloc(sizeof(double) * M_GLOBAL * N_GLOBAL);
-#endif
-
-    double *A = NULL;
-    double *B = NULL;
-    double *C = NULL;
-    double *D = NULL;
-
-    checkCudaErrors(hipMalloc((void**)&A, sizeof(double) * M_GLOBAL * K_GLOBAL));
-    checkCudaErrors(hipMalloc((void**)&B, sizeof(double) * N_GLOBAL * K_GLOBAL));
-    checkCudaErrors(hipMalloc((void**)&C, sizeof(double) * M_GLOBAL * N_GLOBAL));
-    checkCudaErrors(hipMalloc((void**)&D, sizeof(double) * M_GLOBAL * N_GLOBAL));
-
-    assert(((unsigned long long)A) % 128 == 0);
-    assert(((unsigned long long)B) % 128 == 0);
-    assert(((unsigned long long)C) % 128 == 0);
-    assert(((unsigned long long)D) % 128 == 0);
-
-    init_host_matrices(A_h, B_h, C_h);
-
-    printf("Preparing data for GPU...\n");
-
-    checkCudaErrors(hipMemcpy(A, A_h, sizeof(double) * M_GLOBAL * K_GLOBAL, hipMemcpyHostToDevice));
-    checkCudaErrors(hipMemcpy(B, B_h, sizeof(double) * N_GLOBAL * K_GLOBAL, hipMemcpyHostToDevice));
-    checkCudaErrors(hipMemcpy(C, C_h, sizeof(double) * M_GLOBAL * N_GLOBAL, hipMemcpyHostToDevice));
-    checkCudaErrors(hipMemset(D, 0, sizeof(double) * M_GLOBAL * N_GLOBAL));
-
-    enum {
-        // Compute the right amount of shared memory to request.
-        // We need shared memory to hold per-CTA C and D matrix tiles, and to cache per-CTA chunks
-        // of the A and B matrices. Therefore, the right amount to request is the maximum of those
-        // two numbers.
-        SHMEM_SZ = MAX(sizeof(double) * (BLOCK_COL_TILES * M) * (CHUNK_K * K + SKEW_DOUBLE) * 2,
-                       M * (BLOCK_ROW_WARPS * WARP_ROW_TILES) * N * (BLOCK_COL_WARPS * WARP_COL_TILES) * sizeof(double))
-    };
-
-    printf("Required shared memory size: %lu Kb\n", SHMEM_SZ / 1024UL);
-
-    const double alpha = 1.1f;
-    const double beta = 1.2f;
-
-    hipEvent_t start, stop;
-
-    checkCudaErrors(hipEventCreate(&start));
-    checkCudaErrors(hipEventCreate(&stop));
-    checkCudaErrors(hipEventRecord(start));
-
-    kernels selected_kernel = dmma_shmem_gemm_async_copy;
-
-    // kernel to run - default (dmma_shmem_gemm_async_copy == 0)
-    if (checkCmdLineFlag(argc, (const char **)argv, "kernel")) {
-        int kernel_number = getCmdLineArgumentInt(argc, (const char **)argv, "kernel");
-        if (kernel_number < 4)
-        {
-            selected_kernel = (kernels)kernel_number;
-        }
-        else
-        {
-            printf("Error: kernel number should be between 0 to 3, you have entered %d\n", kernel_number);
-            exit(EXIT_FAILURE);
-        }
-    }
-
-    // If enough shared memory available on the GPU use high performant kernel
-    if ((deviceProp.sharedMemPerMultiprocessor >= SHMEM_SZ) && (selected_kernel != simple_dmma_gemm))
-    {
-        printf("Computing using high performance kernel = %d - %s\n", selected_kernel, kernelNames[selected_kernel]);
-
-        switch (selected_kernel)
-        {
-            case dmma_shmem_gemm_async_copy :
-            default:
-                checkCudaErrors(hipFuncSetAttribute(compute_dgemm_async_copy, hipFuncAttributeMaxDynamicSharedMemorySize, SHMEM_SZ));
-                checkKernelErrors((compute_dgemm_async_copy<<<deviceProp.multiProcessorCount*3, THREADS_PER_BLOCK, SHMEM_SZ>>>(A, B, C, D, alpha, beta)));
-                break;
-            case dmma_shmem_gemm_cg_async_copy :
-                checkCudaErrors(hipFuncSetAttribute(compute_dgemm_cg_async_copy, hipFuncAttributeMaxDynamicSharedMemorySize, SHMEM_SZ));
-                checkKernelErrors((compute_dgemm_cg_async_copy<<<deviceProp.multiProcessorCount*3, THREADS_PER_BLOCK, SHMEM_SZ>>>(A, B, C, D, alpha, beta)));
-                break;
-            case dmma_shmem_gemm :
-                checkCudaErrors(hipFuncSetAttribute(compute_dgemm, hipFuncAttributeMaxDynamicSharedMemorySize, SHMEM_SZ));
-                checkKernelErrors((compute_dgemm<<<deviceProp.multiProcessorCount*2, THREADS_PER_BLOCK, SHMEM_SZ>>>(A, B, C, D, alpha, beta)));
-                break;
-        }
-
-#if CPU_DEBUG
-        checkCudaErrors(hipMemcpy(result_hD, D, sizeof(double)*M_GLOBAL*N_GLOBAL, hipMemcpyDeviceToHost));
-#endif
-    }
-    else
-    {
-        dim3 gridDim;
-        dim3 blockDim;
-
-        // blockDim.x must be a multple of warpSize
-        // 128x4 means we have 16 warps and a block computes a 64x64 output tile
-        blockDim.x = 128;
-        blockDim.y = 4;
-
-        gridDim.x = (M_GLOBAL + (M * blockDim.x / 32 - 1)) / (M * blockDim.x / 32);
-        gridDim.y = (N_GLOBAL + N * blockDim.y - 1) / (N * blockDim.y);
-
-        printf("Computing... using simple_wmma_gemm kernel\n");
-        simple_wmma_gemm<<<gridDim, blockDim>>>(A, B, C, D, M_GLOBAL, N_GLOBAL, K_GLOBAL, alpha, beta);
-#if CPU_DEBUG
-        checkCudaErrors(hipMemcpy(result_hD, D, sizeof(double) * M_GLOBAL * N_GLOBAL, hipMemcpyDeviceToHost));
-#endif
-    }
-
-    checkCudaErrors(hipEventRecord(stop));
-    checkCudaErrors(hipEventSynchronize(stop));
-
-#if CPU_DEBUG
-    printf("Verifying correctness of the computations...\n");
-
-    memcpy(result_host, C_h, sizeof(double) * M_GLOBAL * N_GLOBAL);
-
-    matMultiplyOnHost(A_h, B_h, result_host,
-                      alpha, beta,
-                      M_GLOBAL, K_GLOBAL,
-                      K_GLOBAL, N_GLOBAL,
-                      M_GLOBAL, N_GLOBAL);
-
-    size_t number_of_matches = 0;
-    for (int i = 0; i < N_GLOBAL*M_GLOBAL; i++) {
-        if  (fabs(result_hD[i] - result_host[i]) > 0.1f)
-        {
-            printf("mismatch i=%d result_hD=%f result_host=%f\n", i, result_hD[i], result_host[i]);
-            break;
-        }
-        else
-        {
-            number_of_matches++;
-        }
-    }
-    printf("number_of_matches = %zu out of = %d \n", number_of_matches, N_GLOBAL*M_GLOBAL);
-    free(result_hD);
-    free(result_host);
-#endif
-
-    float milliseconds = 0;
-
-    checkCudaErrors(hipEventElapsedTime(&milliseconds, start, stop));
-
-    printf("Time: %f ms\n", milliseconds);
-    printf("FP64 TFLOPS: %.2f\n", (((double)M_GLOBAL * N_GLOBAL * K_GLOBAL * 2)/(milliseconds/1000.)) / 1e12);
-
-    free(A_h);
-    free(B_h);
-    free(C_h);
-    HIPCHECK(hipFree((void*)A));
-    HIPCHECK(hipFree((void*)B));
-    HIPCHECK(hipFree((void*)C));
-    HIPCHECK(hipFree((void*)D));
-
-    return 0;
-}
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2017.sln b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2019.sln b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2022.sln b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/dmmaTensorCoreGemm/dmmaTensorCoreGemm_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/Makefile b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/README.md b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy.cu b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy.cu.hip b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy.cu.hip
old mode 100644
new mode 100755
index 1ee232b..bfc7c82
--- a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy.cu.hip
@@ -41,8 +41,6 @@
 
 // System includes
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <assert.h>
 
 // CUDA runtime
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2017.sln b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2019.sln b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2022.sln b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/globalToShmemAsyncCopy/globalToShmemAsyncCopy_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/Makefile b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/README.md b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint.cu b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint.cu.hip b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint.cu.hip
old mode 100644
new mode 100755
index 7d0f28f..e69de29
--- a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint.cu.hip
@@ -1,410 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// System includes
-#include <assert.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-
-// helper functions and utilities to work with CUDA
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"
-
-#define NUM_GRAPHS 8
-#define THREADS_PER_BLOCK 512
-
-void printMemoryFootprint(int device) {
-  size_t footprint;
-  HIPCHECK(hipDeviceGetGraphMemAttribute(
-      device, (hipGraphMemAttributeType)0, &footprint));
-  printf("    FOOTPRINT: %lu bytes\n", footprint);
-}
-
-void prepareAllocParams(cudaMemAllocNodeParams *allocParams, size_t bytes,
-                        int device) {
-  memset(allocParams, 0, sizeof(*allocParams));
-
-  allocParams->bytesize = bytes;
-  allocParams->poolProps.allocType = hipMemAllocationTypePinned;
-  allocParams->poolProps.location.id = device;
-  allocParams->poolProps.location.type = hipMemLocationTypeDevice;
-}
-
-void createVirtAddrReuseGraph(hipGraphExec_t *graphExec, size_t bytes,
-                              int device) {
-  hipGraph_t graph;
-  hipGraphNode_t allocNodeA, allocNodeB, freeNodeA, freeNodeB;
-  cudaMemAllocNodeParams allocParams;
-  float *d_a, *d_b;
-
-  HIPCHECK(hipGraphCreate(&graph, 0));
-  prepareAllocParams(&allocParams, bytes, device);
-
-  HIPCHECK(
-      cudaGraphAddMemAllocNode(&allocNodeA, graph, NULL, 0, &allocParams));
-  d_a = (float *)allocParams.dptr;
-  HIPCHECK(
-      cudaGraphAddMemFreeNode(&freeNodeA, graph, &allocNodeA, 1, (void *)d_a));
-
-  // The dependency between the allocation of d_b and the free of d_a allows d_b
-  // to reuse the same VA.
-  HIPCHECK(cudaGraphAddMemAllocNode(&allocNodeB, graph, &freeNodeA, 1,
-                                           &allocParams));
-  d_b = (float *)allocParams.dptr;
-
-  if (d_a == d_b) {
-    printf("Check confirms that d_a and d_b share a virtual address.\n");
-  } else {
-    printf("Check shows that d_a and d_b DO NOT share a virtual address.\n");
-  }
-
-  HIPCHECK(
-      cudaGraphAddMemFreeNode(&freeNodeB, graph, &allocNodeB, 1, (void *)d_b));
-
-  HIPCHECK(hipGraphInstantiate(graphExec, graph, NULL, NULL, 0));
-  HIPCHECK(hipGraphDestroy(graph));
-}
-
-void virtualAddressReuseSingleGraph(size_t bytes, int device) {
-  hipStream_t stream;
-  hipGraphExec_t graphExec;
-
-  printf("================================\n");
-  printf("Running virtual address reuse example.\n");
-  printf(
-      "Sequential allocations & frees within a single graph enable CUDA to "
-      "reuse virtual addresses.\n\n");
-
-  createVirtAddrReuseGraph(&graphExec, bytes, device);
-  HIPCHECK(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
-
-  HIPCHECK(hipGraphLaunch(graphExec, stream));
-  HIPCHECK(hipStreamSynchronize(stream));
-  printMemoryFootprint(device);
-
-  HIPCHECK(hipGraphExecDestroy(graphExec));
-  HIPCHECK(hipStreamDestroy(stream));
-}
-
-// This is a kernel that does no real work but runs at least for a specified
-// number of clocks
-__global__ void clockBlock(clock_t clock_count) {
-  unsigned int start_clock = (unsigned int)clock();
-
-  clock_t clock_offset = 0;
-
-  while (clock_offset < clock_count) {
-    unsigned int end_clock = (unsigned int)clock();
-
-    // The code below should work like
-    // this (thanks to modular arithmetics):
-    //
-    // clock_offset = (clock_t) (end_clock > start_clock ?
-    //                           end_clock - start_clock :
-    //                           end_clock + (0xffffffffu - start_clock));
-    //
-    // Indeed, let m = 2^32 then
-    // end - start = end + m - start (mod m).
-
-    clock_offset = (clock_t)(end_clock - start_clock);
-  }
-}
-
-// A pointer to the allocated device buffer is returned in dPtr so the caller
-// can compare virtual addresses. The kernel node is added to increase the
-// graph's runtime.
-void createSimpleAllocFreeGraph(hipGraphExec_t *graphExec, float **dPtr,
-                                size_t bytes, int device) {
-  hipGraph_t graph;
-  hipGraphNode_t allocNodeA, freeNodeA, blockDeviceNode;
-  cudaMemAllocNodeParams allocParams;
-  hipKernelNodeParams blockDeviceNodeParams = {0};
-  int numElements = bytes / sizeof(float);
-  float kernelTime = 5;  // time for each thread to run in microseconds
-
-  HIPCHECK(hipGraphCreate(&graph, 0));
-  prepareAllocParams(&allocParams, bytes, device);
-
-  HIPCHECK(
-      cudaGraphAddMemAllocNode(&allocNodeA, graph, NULL, 0, &allocParams));
-  *dPtr = (float *)allocParams.dptr;
-
-  hipDeviceProp_t deviceProp;
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, device));
-  clock_t time_clocks = (clock_t)((kernelTime / 1000.0) * deviceProp.clockRate);
-
-  void *blockDeviceArgs[1] = {(void *)&time_clocks};
-
-  size_t numBlocks = numElements / (size_t)THREADS_PER_BLOCK;
-  blockDeviceNodeParams.gridDim = dim3(numBlocks, 1, 1);
-  blockDeviceNodeParams.blockDim = dim3(THREADS_PER_BLOCK, 1, 1);
-  blockDeviceNodeParams.sharedMemBytes = 0;
-  blockDeviceNodeParams.extra = NULL;
-  blockDeviceNodeParams.func = (void *)clockBlock;
-  blockDeviceNodeParams.kernelParams = (void **)blockDeviceArgs;
-  HIPCHECK(hipGraphAddKernelNode(&blockDeviceNode, graph, &allocNodeA,
-                                         1, &blockDeviceNodeParams));
-
-  HIPCHECK(cudaGraphAddMemFreeNode(&freeNodeA, graph, &blockDeviceNode,
-                                          1, (void *)*dPtr));
-
-  HIPCHECK(hipGraphInstantiate(graphExec, graph, NULL, NULL, 0));
-  HIPCHECK(hipGraphDestroy(graph));
-}
-
-void physicalMemoryReuseSingleStream(size_t bytes, int device) {
-  hipStream_t stream;
-  hipGraphExec_t graphExecs[NUM_GRAPHS];
-  float *dPtrs[NUM_GRAPHS];
-  bool virtualAddrDiffer = true;
-
-  printf("================================\n");
-  printf("Running physical memory reuse example.\n");
-  printf(
-      "CUDA reuses the same physical memory for allocations from separate "
-      "graphs when the allocation lifetimes don't overlap.\n\n");
-
-  for (int i = 0; i < NUM_GRAPHS; i++) {
-    createSimpleAllocFreeGraph(&graphExecs[i], &dPtrs[i], bytes, device);
-  }
-
-  printf("Creating the graph execs does not reserve any physical memory.\n");
-  printMemoryFootprint(device);
-
-  HIPCHECK(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
-
-  HIPCHECK(hipGraphLaunch(graphExecs[0], stream));
-  printf("\nThe first graph launched reserves the memory it needs.\n");
-  printMemoryFootprint(device);
-
-  HIPCHECK(hipGraphLaunch(graphExecs[0], stream));
-  printf(
-      "A subsequent launch of the same graph in the same stream reuses the "
-      "same physical memory. ");
-  printf("Thus the memory footprint does not grow here.\n");
-  printMemoryFootprint(device);
-
-  printf(
-      "\nSubsequent launches of other graphs in the same stream also reuse the "
-      "physical memory. ");
-  printf("Thus the memory footprint does not grow here.\n");
-  for (int i = 1; i < NUM_GRAPHS; i++) {
-    HIPCHECK(hipGraphLaunch(graphExecs[i], stream));
-    printf("%02d: ", i);
-    printMemoryFootprint(device);
-  }
-
-  HIPCHECK(hipStreamSynchronize(stream));
-
-  for (int i = 0; i < NUM_GRAPHS; i++) {
-    for (int j = i + 1; j < NUM_GRAPHS; j++) {
-      if (dPtrs[i] == dPtrs[j]) {
-        virtualAddrDiffer = false;
-        printf("Error: Graph exec %d and %d have the same virtual address!\n",
-               i - 1, i);
-      }
-    }
-    HIPCHECK(hipGraphExecDestroy(graphExecs[i]));
-  }
-  if (virtualAddrDiffer) {
-    printf("\nCheck confirms all graphs use a different virtual address.\n");
-  } else {
-    printf(
-        "\nAll graphs do NOT use different virtual addresses. Exiting test.\n");
-    exit(EXIT_FAILURE);
-  }
-
-  HIPCHECK(hipStreamDestroy(stream));
-}
-
-void simultaneousStreams(size_t bytes, int device) {
-  hipStream_t streams[NUM_GRAPHS];
-  hipGraphExec_t graphExecs[NUM_GRAPHS];
-  float *dPtrs[NUM_GRAPHS];
-
-  printf("================================\n");
-  printf("Running simultaneous streams example.\n");
-  printf("Graphs that can run concurrently need separate physical memory. ");
-  printf(
-      "In this example, each graph launched in a separate stream increases the "
-      "total memory footprint.\n\n");
-
-  printf(
-      "When launching a new graph, CUDA may reuse physical memory from a graph "
-      "whose execution has already ");
-  printf(
-      "finished -- even if the new graph is being launched in a different "
-      "stream from the completed graph. ");
-  printf(
-      "Therefore, a kernel node is added to the graphs to increase "
-      "runtime.\n\n");
-
-  for (int i = 0; i < NUM_GRAPHS; i++) {
-    createSimpleAllocFreeGraph(&graphExecs[i], &dPtrs[i], bytes, device);
-    HIPCHECK(
-        hipStreamCreateWithFlags(&streams[i], hipStreamNonBlocking));
-  }
-
-  printf("Initial footprint:\n");
-  printMemoryFootprint(device);
-
-  printf(
-      "\nEach graph launch in a seperate stream grows the memory footprint:\n");
-  for (int i = 1; i < NUM_GRAPHS; i++) {
-    HIPCHECK(hipGraphLaunch(graphExecs[i], streams[i]));
-    printf("%02d: ", i);
-    printMemoryFootprint(device);
-  }
-
-  for (int i = 0; i < NUM_GRAPHS; i++) {
-    HIPCHECK(hipStreamSynchronize(streams[i]));
-    HIPCHECK(hipGraphExecDestroy(graphExecs[i]));
-    HIPCHECK(hipStreamDestroy(streams[i]));
-  }
-}
-
-void createSimpleAllocNoFreeGraph(hipGraphExec_t *graphExec, float **dPtr,
-                                  size_t bytes, int device) {
-  hipGraph_t graph;
-  hipGraphNode_t allocNodeA;
-  cudaMemAllocNodeParams allocParams;
-
-  HIPCHECK(hipGraphCreate(&graph, 0));
-  prepareAllocParams(&allocParams, bytes, device);
-
-  HIPCHECK(
-      cudaGraphAddMemAllocNode(&allocNodeA, graph, NULL, 0, &allocParams));
-  *dPtr = (float *)allocParams.dptr;
-
-  HIPCHECK(hipGraphInstantiate(graphExec, graph, NULL, NULL, 0));
-  HIPCHECK(hipGraphDestroy(graph));
-}
-
-void unfreedAllocations(size_t bytes, int device) {
-  hipStream_t stream;
-  hipGraphExec_t graphExecs[NUM_GRAPHS];
-  float *dPtrs[NUM_GRAPHS];
-
-  printf("================================\n");
-  printf("Running unfreed streams example.\n");
-  printf(
-      "CUDA cannot reuse phyiscal memory from graphs which do not free their "
-      "allocations.\n\n");
-
-  for (int i = 0; i < NUM_GRAPHS; i++) {
-    createSimpleAllocNoFreeGraph(&graphExecs[i], &dPtrs[i], bytes, device);
-  }
-
-  HIPCHECK(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
-
-  printf(
-      "Despite being launched in the same stream, each graph launch grows the "
-      "memory footprint. ");
-  printf(
-      "Since the allocation is not freed, CUDA keeps the memory valid for "
-      "use.\n");
-  for (int i = 0; i < NUM_GRAPHS; i++) {
-    HIPCHECK(hipGraphLaunch(graphExecs[i], stream));
-    printf("%02d: ", i);
-    printMemoryFootprint(device);
-  }
-
-  HIPCHECK(hipStreamSynchronize(stream));
-
-  HIPCHECK(hipDeviceGraphMemTrim(device));
-  printf(
-      "\nTrimming does not impact the memory footprint since the un-freed "
-      "allocations are still holding onto the memory.\n");
-  printMemoryFootprint(device);
-
-  for (int i = 0; i < NUM_GRAPHS; i++) {
-    HIPCHECK(hipFree(dPtrs[i]));
-  }
-  printf("\nFreeing the allocations does not shrink the footprint.\n");
-  printMemoryFootprint(device);
-
-  HIPCHECK(hipDeviceGraphMemTrim(device));
-  printf(
-      "\nSince the allocations are now freed, trimming does reduce the "
-      "footprint even when the graph execs are not yet destroyed.\n");
-  printMemoryFootprint(device);
-
-  for (int i = 0; i < NUM_GRAPHS; i++) {
-    HIPCHECK(hipGraphExecDestroy(graphExecs[i]));
-  }
-  HIPCHECK(hipStreamDestroy(stream));
-}
-
-void cleanupMemory(int device) {
-  HIPCHECK(hipDeviceGraphMemTrim(device));
-  printf("\nCleaning up example by trimming device memory.\n");
-  printMemoryFootprint(device);
-  printf("\n");
-}
-
-int main(int argc, char **argv) {
-  size_t bytes = 64 * 1024 * 1024;
-  int device = findCudaDevice(argc, (const char **)argv);
-
-  int driverVersion = 0;
-  int deviceSupportsMemoryPools = 0;
-
-  hipDriverGetVersion(&driverVersion);
-  printf("Driver version is: %d.%d\n", driverVersion / 1000,
-         (driverVersion % 100) / 10);
-
-  if (driverVersion < 11040) {
-    printf("Waiving execution as driver does not support Graph Memory Nodes\n");
-    exit(EXIT_WAIVED);
-  }
-
-  hipDeviceGetAttribute(&deviceSupportsMemoryPools,
-                         hipDeviceAttributeMemoryPoolsSupported, device);
-  if (!deviceSupportsMemoryPools) {
-    printf("Waiving execution as device does not support Memory Pools\n");
-    exit(EXIT_WAIVED);
-  } else {
-    printf("Running sample.\n");
-  }
-
-  virtualAddressReuseSingleGraph(bytes, device);
-  cleanupMemory(device);
-
-  physicalMemoryReuseSingleStream(bytes, device);
-  cleanupMemory(device);
-
-  simultaneousStreams(bytes, device);
-  cleanupMemory(device);
-
-  unfreedAllocations(bytes, device);
-  cleanupMemory(device);
-
-  printf("================================\n");
-  printf("Sample complete.\n");
-}
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2017.sln b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2019.sln b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2022.sln b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/graphMemoryFootprint/graphMemoryFootprint_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/Makefile b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/README.md b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes.cu b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes.cu.hip b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes.cu.hip
old mode 100644
new mode 100755
index e1d90f4..e69de29
--- a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes.cu.hip
@@ -1,555 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// System includes
-#include <assert.h>
-#include <stdio.h>
-
-#include <climits>
-#include <vector>
-
-// CUDA runtime
-#include <hip/hip_runtime.h>
-
-// helper functions and utilities to work with CUDA
-#include <helper_cuda.h>
-#include <helper_functions.h>
-
-#define THREADS_PER_BLOCK 512
-#define ALLOWABLE_VARIANCE 1.e-6f
-#define NUM_ELEMENTS 8000000
-
-// Stores the square of each input element in output array
-__global__ void squareArray(const float *input, float *output,
-                            int numElements) {
-  int idx = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (idx < numElements) {
-    output[idx] = input[idx] * input[idx];
-  }
-}
-
-// Stores the negative of each input element in output array
-__global__ void negateArray(const float *input, float *output,
-                            int numElements) {
-  int idx = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (idx < numElements) {
-    output[idx] = input[idx] * -1;
-  }
-}
-
-struct negSquareArrays {
-  float *input;
-  float *square;
-  float *negSquare;
-  int numElements;
-  size_t bytes;
-  size_t numBlocks;
-};
-
-void fillRandomly(float *array, int numElements) {
-  for (int n = 0; n < numElements; n++) {
-    array[n] = rand() / (float)RAND_MAX;
-  }
-}
-
-void resetOutputArrays(negSquareArrays *hostArrays) {
-  fillRandomly(hostArrays->square, hostArrays->numElements);
-  fillRandomly(hostArrays->negSquare, hostArrays->numElements);
-}
-
-void prepareHostArrays(negSquareArrays *hostArrays) {
-  hostArrays->numElements = NUM_ELEMENTS;
-  size_t bytes = hostArrays->numElements * sizeof(float);
-
-  size_t numBlocks = hostArrays->numElements / (size_t)THREADS_PER_BLOCK;
-  if ((numBlocks % (size_t)THREADS_PER_BLOCK) != 0) {
-    numBlocks++;
-  }
-
-  hostArrays->input = (float *)malloc(bytes);
-  hostArrays->square = (float *)malloc(bytes);
-  hostArrays->negSquare = (float *)malloc(bytes);
-  hostArrays->bytes = bytes;
-  hostArrays->numBlocks = numBlocks;
-
-  fillRandomly(hostArrays->input, hostArrays->numElements);
-  fillRandomly(hostArrays->square, hostArrays->numElements);
-  fillRandomly(hostArrays->negSquare, hostArrays->numElements);
-}
-
-void createFreeGraph(hipGraphExec_t *graphExec, float *dPtr) {
-  hipGraph_t graph;
-  hipGraphNode_t freeNode;
-
-  checkCudaErrors(hipGraphCreate(&graph, 0));
-
-  checkCudaErrors(
-      cudaGraphAddMemFreeNode(&freeNode, graph, NULL, 0, (void *)dPtr));
-
-  checkCudaErrors(hipGraphInstantiate(graphExec, graph, NULL, NULL, 0));
-  checkCudaErrors(hipGraphDestroy(graph));
-}
-
-/**
- * Demonstrates explicitly creating a CUDA graph including memory nodes.
- * createNegateSquaresGraphWithStreamCapture constructs an equivalent graph
- * using stream capture.
- *
- * If d_negSquare_out is non null, then:
- * 1) d_negSquare will not be freed;
- * 2) the value of d_negSquare_out will be set to d_negSquare.
- *
- * Diagram of the graph constructed by createNegateSquaresGraphExplicitly:
- *
- * alloc d_input
- *       |
- * alloc d_square
- *       |
- * Memcpy a to device
- *       |
- * launch kernel squareArray ------->---- Memcpy d_square to host
- *       |                                      |
- * free d_input                                 |
- *       |                                      |
- * allocate d_negSquare                         |
- *       |                                      |
- * launch kernel negateArray -------->--- free d_square
- *       |
- * Memcpy d_negSquare to host
- *       |
- * free d_negSquare
- */
-void createNegateSquaresGraphExplicitly(hipGraphExec_t *graphExec, int device,
-                                        negSquareArrays *hostArrays,
-                                        float **d_negSquare_out = NULL) {
-  // Array buffers on device
-  float *d_input, *d_square, *d_negSquare;
-
-  // Memory allocation parameters
-  cudaMemAllocNodeParams allocParams;
-  memset(&allocParams, 0, sizeof(allocParams));
-  allocParams.bytesize = hostArrays->bytes;
-  allocParams.poolProps.allocType = hipMemAllocationTypePinned;
-  allocParams.poolProps.location.id = device;
-  allocParams.poolProps.location.type = hipMemLocationTypeDevice;
-
-  // Kernel launch parameters
-  hipKernelNodeParams kernelNodeParams = {0};
-  kernelNodeParams.gridDim = dim3(hostArrays->numBlocks, 1, 1);
-  kernelNodeParams.blockDim = dim3(THREADS_PER_BLOCK, 1, 1);
-  kernelNodeParams.sharedMemBytes = 0;
-  kernelNodeParams.extra = NULL;
-
-  hipGraph_t graph;
-  hipGraphNode_t allocNodeInput, allocNodeSquare, allocNodeNegSquare;
-  hipGraphNode_t copyNodeInput, copyNodeSquare, copyNodeNegSquare;
-  hipGraphNode_t squareKernelNode, negateKernelNode;
-  hipGraphNode_t freeNodeInput, freeNodeSquare;
-
-  // Buffer for storing graph node dependencies
-  std::vector<hipGraphNode_t> nodeDependencies;
-
-  checkCudaErrors(hipGraphCreate(&graph, 0));
-
-  checkCudaErrors(
-      cudaGraphAddMemAllocNode(&allocNodeInput, graph, NULL, 0, &allocParams));
-  d_input = (float *)allocParams.dptr;
-
-  // To keep the graph structure simple (fewer branching dependencies),
-  // allocNodeSquare should depend on allocNodeInput
-  checkCudaErrors(cudaGraphAddMemAllocNode(&allocNodeSquare, graph,
-                                           &allocNodeInput, 1, &allocParams));
-  d_square = (float *)allocParams.dptr;
-
-  // copyNodeInput needs to depend on allocNodeInput because copyNodeInput
-  // writes to d_input. It does so here indirectly through allocNodeSquare.
-  checkCudaErrors(hipGraphAddMemcpyNode1D(
-      &copyNodeInput, graph, &allocNodeSquare, 1, d_input, hostArrays->input,
-      hostArrays->bytes, hipMemcpyHostToDevice));
-
-  void *squareKernelArgs[3] = {(void *)&d_input, (void *)&d_square,
-                               (void *)&(hostArrays->numElements)};
-  kernelNodeParams.func = (void *)squareArray;
-  kernelNodeParams.kernelParams = (void **)squareKernelArgs;
-
-  // Square kernel depends on copyNodeInput to ensure all data is on the device
-  // before kernel launch.
-  checkCudaErrors(hipGraphAddKernelNode(&squareKernelNode, graph,
-                                         &copyNodeInput, 1, &kernelNodeParams));
-
-  checkCudaErrors(hipGraphAddMemcpyNode1D(
-      &copyNodeSquare, graph, &squareKernelNode, 1, hostArrays->square,
-      d_square, hostArrays->bytes, hipMemcpyDeviceToHost));
-
-  // Free of d_input depends on the square kernel to ensure that d_input is not
-  // freed while being read by the kernel. It also depends on the alloc of
-  // d_input via squareKernelNode > copyNodeInput > allocNodeSquare >
-  // allocNodeInput.
-  checkCudaErrors(cudaGraphAddMemFreeNode(&freeNodeInput, graph,
-                                          &squareKernelNode, 1, d_input));
-
-  // Allocation of C depends on free of A so CUDA can reuse the virtual address.
-  checkCudaErrors(cudaGraphAddMemAllocNode(&allocNodeNegSquare, graph,
-                                           &freeNodeInput, 1, &allocParams));
-  d_negSquare = (float *)allocParams.dptr;
-
-  if (d_negSquare == d_input) {
-    printf(
-        "Check verified that d_negSquare and d_input share a virtual "
-        "address.\n");
-  }
-
-  void *negateKernelArgs[3] = {(void *)&d_square, (void *)&d_negSquare,
-                               (void *)&(hostArrays->numElements)};
-  kernelNodeParams.func = (void *)negateArray;
-  kernelNodeParams.kernelParams = (void **)negateKernelArgs;
-
-  checkCudaErrors(hipGraphAddKernelNode(
-      &negateKernelNode, graph, &allocNodeNegSquare, 1, &kernelNodeParams));
-
-  nodeDependencies.push_back(copyNodeSquare);
-  nodeDependencies.push_back(negateKernelNode);
-  checkCudaErrors(cudaGraphAddMemFreeNode(&freeNodeSquare, graph,
-                                          nodeDependencies.data(),
-                                          nodeDependencies.size(), d_square));
-  nodeDependencies.clear();
-
-  checkCudaErrors(hipGraphAddMemcpyNode1D(
-      &copyNodeNegSquare, graph, &negateKernelNode, 1, hostArrays->negSquare,
-      d_negSquare, hostArrays->bytes, hipMemcpyDeviceToHost));
-
-  if (d_negSquare_out == NULL) {
-    hipGraphNode_t freeNodeNegSquare;
-    checkCudaErrors(cudaGraphAddMemFreeNode(
-        &freeNodeNegSquare, graph, &copyNodeNegSquare, 1, d_negSquare));
-  } else {
-    *d_negSquare_out = d_negSquare;
-  }
-
-  checkCudaErrors(hipGraphInstantiate(graphExec, graph, NULL, NULL, 0));
-  checkCudaErrors(hipGraphDestroy(graph));
-}
-
-/**
- * Adds work to a CUDA stream which negates the square of values in the input
- * array.
- *
- * If d_negSquare_out is non null, then:
- * 1) d_negSquare will not be freed;
- * 2) the value of d_negSquare_out will be set to d_negSquare.
- *
- * Diagram of the stream operations in doNegateSquaresInStream
- * ---------------------------------------------------------------------
- * | STREAM                             | STREAM2                      |
- * ---------------------------------------------------------------------
- *
- * alloc d_input
- *       |
- * alloc d_square
- *       |
- * Memcpy a to device
- *       |
- * launch kernel squareArray
- *       |
- * record squareKernelCompleteEvent -->-- wait squareKernelCompleteEvent
- *       |                                      |
- * free d_input                                 |
- *       |                                      |
- * allocate d_negSquare                   Memcpy d_square to host
- *       |                                      |
- * launch kernel negateArray                    |
- *       |                                      |
- * record negateKernelCompleteEvent -->-- wait negateKernelCompleteEvent
- *       |                                      |
- * Memcpy d_negSquare to host                   |
- *       |                                free d_square
- * free d_negSquare                             |
- *       |                                      |
- * wait squareFreeEvent --------------<---- record squareFreeEvent
- */
-void doNegateSquaresInStream(hipStream_t stream1, negSquareArrays *hostArrays,
-                             float **d_negSquare_out = NULL) {
-  float *d_input, *d_square, *d_negSquare;
-  hipStream_t stream2;
-  hipEvent_t squareKernelCompleteEvent, negateKernelCompleteEvent,
-      squareFreeEvent;
-
-  checkCudaErrors(hipStreamCreateWithFlags(&stream2, hipStreamNonBlocking));
-
-  checkCudaErrors(hipEventCreate(&squareKernelCompleteEvent));
-  checkCudaErrors(hipEventCreate(&negateKernelCompleteEvent));
-  checkCudaErrors(hipEventCreate(&squareFreeEvent));
-
-  // Virtual addresses are assigned synchronously when hipMallocAsync is
-  // called, thus there is no performace benefit gained by separating the
-  // allocations into two streams.
-  checkCudaErrors(hipMallocAsync(&d_input, hostArrays->bytes, stream1));
-  checkCudaErrors(hipMallocAsync(&d_square, hostArrays->bytes, stream1));
-
-  checkCudaErrors(hipMemcpyAsync(d_input, hostArrays->input, hostArrays->bytes,
-                                  hipMemcpyHostToDevice, stream1));
-  squareArray<<<hostArrays->numBlocks, THREADS_PER_BLOCK, 0, stream1>>>(
-      d_input, d_square, hostArrays->numElements);
-  checkCudaErrors(hipEventRecord(squareKernelCompleteEvent, stream1));
-
-  checkCudaErrors(hipStreamWaitEvent(stream2, squareKernelCompleteEvent, 0));
-  checkCudaErrors(hipMemcpyAsync(hostArrays->square, d_square,
-                                  hostArrays->bytes, hipMemcpyDeviceToHost,
-                                  stream2));
-
-  checkCudaErrors(hipFreeAsync(d_input, stream1));
-  checkCudaErrors(hipMallocAsync(&d_negSquare, hostArrays->bytes, stream1));
-  negateArray<<<hostArrays->numBlocks, THREADS_PER_BLOCK, 0, stream1>>>(
-      d_square, d_negSquare, hostArrays->numElements);
-  checkCudaErrors(hipEventRecord(negateKernelCompleteEvent, stream1));
-  checkCudaErrors(hipMemcpyAsync(hostArrays->negSquare, d_negSquare,
-                                  hostArrays->bytes, hipMemcpyDeviceToHost,
-                                  stream1));
-  if (d_negSquare_out == NULL) {
-    checkCudaErrors(hipFreeAsync(d_negSquare, stream1));
-  } else {
-    *d_negSquare_out = d_negSquare;
-  }
-
-  checkCudaErrors(hipStreamWaitEvent(stream2, negateKernelCompleteEvent, 0));
-  checkCudaErrors(hipFreeAsync(d_square, stream2));
-  checkCudaErrors(hipEventRecord(squareFreeEvent, stream2));
-
-  checkCudaErrors(hipStreamWaitEvent(stream1, squareFreeEvent, 0));
-
-  checkCudaErrors(hipStreamDestroy(stream2));
-  checkCudaErrors(hipEventDestroy(squareKernelCompleteEvent));
-  checkCudaErrors(hipEventDestroy(negateKernelCompleteEvent));
-  checkCudaErrors(hipEventDestroy(squareFreeEvent));
-}
-
-/**
- * Demonstrates creating a CUDA graph including memory nodes using stream
- * capture. createNegateSquaresGraphExplicitly constructs an equivalent graph
- * without stream capture.
- */
-void createNegateSquaresGraphWithStreamCapture(hipGraphExec_t *graphExec,
-                                               negSquareArrays *hostArrays,
-                                               float **d_negSquare_out = NULL) {
-  hipGraph_t graph;
-  hipStream_t stream;
-
-  checkCudaErrors(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
-
-  checkCudaErrors(hipStreamBeginCapture(stream, hipStreamCaptureModeGlobal));
-  doNegateSquaresInStream(stream, hostArrays, d_negSquare_out);
-  checkCudaErrors(hipStreamEndCapture(stream, &graph));
-
-  checkCudaErrors(hipGraphInstantiate(graphExec, graph, NULL, NULL, 0));
-  checkCudaErrors(hipStreamDestroy(stream));
-  checkCudaErrors(hipGraphDestroy(graph));
-}
-
-void prepareRefArrays(negSquareArrays *hostArrays,
-                      negSquareArrays *deviceRefArrays,
-                      bool **foundValidationFailure) {
-  deviceRefArrays->bytes = hostArrays->bytes;
-  deviceRefArrays->numElements = hostArrays->numElements;
-
-  for (int i = 0; i < hostArrays->numElements; i++) {
-    hostArrays->square[i] = hostArrays->input[i] * hostArrays->input[i];
-    hostArrays->negSquare[i] = hostArrays->square[i] * -1;
-  }
-
-  checkCudaErrors(
-      hipMalloc((void **)&deviceRefArrays->negSquare, deviceRefArrays->bytes));
-  checkCudaErrors(hipMemcpy(deviceRefArrays->negSquare, hostArrays->negSquare,
-                             hostArrays->bytes, hipMemcpyHostToDevice));
-
-  checkCudaErrors(
-      hipMallocManaged((void **)foundValidationFailure, sizeof(bool)));
-}
-
-int checkValidationFailure(bool *foundValidationFailure) {
-  if (*foundValidationFailure) {
-    printf("Validation FAILURE!\n\n");
-    *foundValidationFailure = false;
-    return EXIT_FAILURE;
-  } else {
-    printf("Validation PASSED!\n\n");
-    return EXIT_SUCCESS;
-  }
-}
-
-__global__ void validateGPU(float *d_negSquare, negSquareArrays devRefArrays,
-                            bool *foundValidationFailure) {
-  int idx = blockIdx.x * blockDim.x + threadIdx.x;
-  float ref, diff;
-
-  if (idx < devRefArrays.numElements) {
-    ref = devRefArrays.negSquare[idx];
-    diff = d_negSquare[idx] - ref;
-    diff *= diff;
-    ref *= ref;
-    if (diff / ref > ALLOWABLE_VARIANCE) {
-      *foundValidationFailure = true;
-    }
-  }
-}
-
-void validateHost(negSquareArrays *hostArrays, bool *foundValidationFailure) {
-  float ref, diff;
-
-  for (int i = 0; i < hostArrays->numElements; i++) {
-    ref = hostArrays->input[i] * hostArrays->input[i] * -1;
-    diff = hostArrays->negSquare[i] - ref;
-    diff *= diff;
-    ref *= ref;
-    if (diff / ref > ALLOWABLE_VARIANCE) {
-      *foundValidationFailure = true;
-    }
-  }
-}
-
-int main(int argc, char **argv) {
-  negSquareArrays hostArrays, deviceRefArrays;
-  hipStream_t stream;
-  hipGraphExec_t graphExec, graphExecFreeC;
-
-  // Declare pointers for GPU buffers
-  float *d_negSquare = NULL;
-  bool *foundValidationFailure = NULL;
-
-  srand(time(0));
-  int device = findCudaDevice(argc, (const char **)argv);
-
-  int driverVersion = 0;
-  int deviceSupportsMemoryPools = 0;
-
-  hipDriverGetVersion(&driverVersion);
-  printf("Driver version is: %d.%d\n", driverVersion / 1000,
-         (driverVersion % 100) / 10);
-
-  if (driverVersion < 11040) {
-    printf("Waiving execution as driver does not support Graph Memory Nodes\n");
-    exit(EXIT_WAIVED);
-  }
-
-  hipDeviceGetAttribute(&deviceSupportsMemoryPools,
-                         hipDeviceAttributeMemoryPoolsSupported, device);
-  if (!deviceSupportsMemoryPools) {
-    printf("Waiving execution as device does not support Memory Pools\n");
-    exit(EXIT_WAIVED);
-  } else {
-    printf("Setting up sample.\n");
-  }
-
-  prepareHostArrays(&hostArrays);
-  prepareRefArrays(&hostArrays, &deviceRefArrays, &foundValidationFailure);
-  checkCudaErrors(hipStreamCreateWithFlags(&stream, hipStreamNonBlocking));
-  printf("Setup complete.\n\n");
-
-  printf("Running negateSquares in a stream.\n");
-  doNegateSquaresInStream(stream, &hostArrays);
-  checkCudaErrors(hipStreamSynchronize(stream));
-  printf("Validating negateSquares in a stream...\n");
-  validateHost(&hostArrays, foundValidationFailure);
-  checkValidationFailure(foundValidationFailure);
-  resetOutputArrays(&hostArrays);
-
-  printf("Running negateSquares in a stream-captured graph.\n");
-  createNegateSquaresGraphWithStreamCapture(&graphExec, &hostArrays);
-  checkCudaErrors(hipGraphLaunch(graphExec, stream));
-  checkCudaErrors(hipStreamSynchronize(stream));
-  printf("Validating negateSquares in a stream-captured graph...\n");
-  validateHost(&hostArrays, foundValidationFailure);
-  checkValidationFailure(foundValidationFailure);
-  resetOutputArrays(&hostArrays);
-
-  printf("Running negateSquares in an explicitly constructed graph.\n");
-  createNegateSquaresGraphExplicitly(&graphExec, device, &hostArrays);
-  checkCudaErrors(hipGraphLaunch(graphExec, stream));
-  checkCudaErrors(hipStreamSynchronize(stream));
-  printf("Validating negateSquares in an explicitly constructed graph...\n");
-  validateHost(&hostArrays, foundValidationFailure);
-  checkValidationFailure(foundValidationFailure);
-  resetOutputArrays(&hostArrays);
-
-  // Each of the three examples below free d_negSquare outside the graph. As
-  // demonstrated by validateGPU, d_negSquare can be accessed by outside the
-  // graph before d_negSquare is freed.
-
-  printf("Running negateSquares with d_negSquare freed outside the stream.\n");
-  createNegateSquaresGraphExplicitly(&graphExec, device, &hostArrays,
-                                     &d_negSquare);
-  checkCudaErrors(hipGraphLaunch(graphExec, stream));
-  validateGPU<<<hostArrays.numBlocks, THREADS_PER_BLOCK, 0, stream>>>(
-      d_negSquare, deviceRefArrays, foundValidationFailure);
-  // Since hipFree is synchronous, the stream must synchronize before freeing
-  // d_negSquare to ensure d_negSquare no longer being accessed.
-  checkCudaErrors(hipStreamSynchronize(stream));
-  checkCudaErrors(hipFree(d_negSquare));
-  printf(
-      "Validating negateSquares with d_negSquare freed outside the "
-      "stream...\n");
-  validateHost(&hostArrays, foundValidationFailure);
-  checkValidationFailure(foundValidationFailure);
-  resetOutputArrays(&hostArrays);
-
-  printf("Running negateSquares with d_negSquare freed outside the graph.\n");
-  checkCudaErrors(hipGraphLaunch(graphExec, stream));
-  validateGPU<<<hostArrays.numBlocks, THREADS_PER_BLOCK, 0, stream>>>(
-      d_negSquare, deviceRefArrays, foundValidationFailure);
-  checkCudaErrors(hipFreeAsync(d_negSquare, stream));
-  checkCudaErrors(hipStreamSynchronize(stream));
-  printf(
-      "Validating negateSquares with d_negSquare freed outside the graph...\n");
-  checkValidationFailure(foundValidationFailure);
-  resetOutputArrays(&hostArrays);
-
-  printf(
-      "Running negateSquares with d_negSquare freed in a different graph.\n");
-  createFreeGraph(&graphExecFreeC, d_negSquare);
-  checkCudaErrors(hipGraphLaunch(graphExec, stream));
-  validateGPU<<<hostArrays.numBlocks, THREADS_PER_BLOCK, 0, stream>>>(
-      d_negSquare, deviceRefArrays, foundValidationFailure);
-  checkCudaErrors(hipGraphLaunch(graphExecFreeC, stream));
-  checkCudaErrors(hipStreamSynchronize(stream));
-  printf(
-      "Validating negateSquares with d_negSquare freed in a different "
-      "graph...\n");
-  checkValidationFailure(foundValidationFailure);
-
-  printf("Cleaning up sample.\n");
-  checkCudaErrors(hipGraphExecDestroy(graphExec));
-  checkCudaErrors(hipGraphExecDestroy(graphExecFreeC));
-  checkCudaErrors(hipStreamDestroy(stream));
-  checkCudaErrors(hipFree(foundValidationFailure));
-  checkCudaErrors(hipFree(deviceRefArrays.negSquare));
-  free(hostArrays.input);
-  free(hostArrays.square);
-  free(hostArrays.negSquare);
-  printf("Cleanup complete. Exiting sample.\n");
-}
\ No newline at end of file
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2017.sln b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2019.sln b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2022.sln b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/graphMemoryNodes/graphMemoryNodes_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/Makefile b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/README.md b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm.cu b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm.cu.hip b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm.cu.hip
old mode 100644
new mode 100755
index 5f34cb9..e69de29
--- a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm.cu.hip
@@ -1,658 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// CUDA sample demonstrating a integer GEMM computation using the Warp Matrix
-// Multiply and Accumulate API.
-
-// In this program, the compute_gemm kernel computes the result of a matrix
-// multiplication and addition: D = alpha * A * B + beta * C. The dimensions of
-// both C and D matrices are M_GLOBAL x N_GLOBAL. The A matrix is M_GLOBAL x
-// K_GLOBAL (row-major), the B matrix is K_GLOBAL x N_GLOBAL (column-major). In
-// that kernel, each CTA computes one 128 x 128 tile of the resulting matrix per
-// iteration. When the tile is computed, the CTA stores it to the global memory
-// and begins a new iteration, selecting a new 128 x 128 tile to compute.
-// Each CTA consists of eight warps. For the 128 x 128 tile, each warp computes
-// eight 16 x 16 subtiles, organized in a 2 x 4 two-dimensional array. Warps
-// compute the 16 x 16 subtiles using nvcuda::wmma::mma_sync operations by
-// moving through the K_GLOBAL dimension of the A and B matrices and
-// accumulating the intermediate result in the local thread state.
-
-// There are a number of simple optimizations used in the algorithm:
-// - The CTA copies the 128 x 128 tile of the C matrix from the global memory to
-//   shared memory. After that is done, each warp loads the C matrix fragments
-//   from shared memory, thus avoiding a random global memory access.
-// - On each internal iteration, the CTA copies a portion of the A and B
-// matrices from
-//   global memory to shared memory. After that, all warps in the CTA reuse the
-//   A and B data from shared memory, thus reducing the number of data copies
-//   from global memory.
-// - The portions of the A and B matrices are stored in shared memory with an
-// additional
-//   padding (skew) to reduce the number of shared memory access bank conflicts.
-//   (See a detailed explanation near the SKEW_HALF macro definition.)
-// - When the CTA finishes computing the tiles of the resulting matrix, each
-// warp stores
-//   its subtiles to shared memory. The CTA then copies the shared memory
-//   contents to global memory, again avoiding redundant random global memory
-//   accesses.
-// - Note that the CTA tile size is chosen to maximize the GPU register
-// utilization,
-//   but carefully enough to avoid local memory use.
-
-#include <assert.h>
-#include <hip/hip_runtime.h>
-#include <mma.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-
-// helper functions and utilities to work with CUDA
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"
-
-// Externally configurable parameters.
-
-#ifndef CPU_DEBUG
-// Set this to 1 to verify the correctness of the GPU-computed matrix.
-#define CPU_DEBUG 0
-#endif
-
-#ifndef SHARED_MEMORY_LIMIT_64K
-// Set this to 0 to use more than 64 Kb of shared memory to cache data, to
-// improve the performance of the computations on GPU.
-// Note that you need a GPU that can have more than 64 Kb of shared memory
-// per multiprocessor.
-#define SHARED_MEMORY_LIMIT_64K 1
-#endif
-
-// GPU configuration.
-
-#define WARP_SIZE 32
-
-// MMA matrix tile dimensions.
-
-#define M 16
-#define N 16
-#define K 16
-
-#define WMMA_M 16
-#define WMMA_N 16
-#define WMMA_K 16
-
-// GEMM configuration.
-
-#define M_TILES 256
-#define N_TILES 256
-#define K_TILES 256
-
-#define M_GLOBAL (M * M_TILES)
-#define N_GLOBAL (N * N_TILES)
-#define K_GLOBAL (K * K_TILES)
-
-#define C_LAYOUT wmma::mem_row_major
-
-// Implementation constants.
-
-#define WARPS_PER_BLOCK 8
-#define THREADS_PER_BLOCK (WARP_SIZE * WARPS_PER_BLOCK)
-
-#if SHARED_MEMORY_LIMIT_64K
-// With only 64 Kb shared memory available, we can fit two 8-tile chunks of
-// the A and B matrix data, that are 16 * 16 * 8 * 8 * 2 = 32 Kb each
-// (i.e. two 8x8 arrays of tiles of 16x16 uint8_t-typed elements per CTA).
-// But we cannot account the 8 Kb total skew overhead, without which the
-// performance would be severely impacted. So we choose to reduce the chunk size
-// in half, i.e. the amount of A and B matrix data we cache in shared memory.
-// Accordingly, this doubles the number of outer iterations across the global K
-// dimension, which only slightly impacts the performance.
-#define CHUNK_K 8
-#else
-#define CHUNK_K 16
-#endif
-
-#define CHUNK_LINE_BYTES (CHUNK_K * K * sizeof(uint8_t))
-#define WARP_COPY_BYTES (WARP_SIZE * sizeof(int4))
-#define CHUNK_COPY_LINES_PER_WARP (WARP_COPY_BYTES / CHUNK_LINE_BYTES)
-#define CHUNK_COPY_LINE_LANES (WARP_SIZE / CHUNK_COPY_LINES_PER_WARP)
-
-#define BLOCK_ROW_WARPS 2
-#define BLOCK_COL_WARPS 4
-
-#define WARP_ROW_TILES 4
-#define WARP_COL_TILES 2
-
-#define BLOCK_ROW_TILES (WARP_ROW_TILES * BLOCK_ROW_WARPS)
-#define BLOCK_COL_TILES (WARP_COL_TILES * BLOCK_COL_WARPS)
-
-#define GLOBAL_MEM_STRIDE N_GLOBAL
-
-#define SHMEM_STRIDE (N * BLOCK_ROW_TILES)
-#define SHMEM_OFFSET (N * WARP_ROW_TILES)
-
-// The macro below is used to shift rows of the A matrix and columns of the B
-// matrix in shared memory to minimize possible bank conflicts. Before
-// performing the nvcuda::wmma::mma_sync operation, the warp must load the
-// matrix data using the nvcuda::wmma::load_matrix_sync operation. Although the
-// memory access pattern is not specified for that function, each lane in the
-// warp can read one or multiple matrix elements from different matrix rows or
-// columns. For shared memory, such access can result in bank conflicts if
-// different rows / columns of the matrix map to the same bank. By shifting each
-// row and column by a few bytes, we make sure that they map to different banks,
-// thus reducing the number of possible bank conflicts. The number of 32
-// one-byte "uint8_t" elements is chosen as the minimum possible shift because
-// we must keep each row and column 256-bit aligned, as required by
-// nvcuda::wmma::load_matrix_sync.
-#define SKEW_UINT8 32
-
-#define checkKernelErrors(expr)                             \
-  do {                                                      \
-    expr;                                                   \
-                                                            \
-    hipError_t __err = hipGetLastError();                 \
-    if (__err != hipSuccess) {                             \
-      printf("Line %d: '%s' failed: %s\n", __LINE__, #expr, \
-             hipGetErrorString(__err));                    \
-      abort();                                              \
-    }                                                       \
-  } while (0)
-
-using namespace nvcuda;
-
-__host__ void init_host_matrices(uint8_t *a, uint8_t *b, int *c) {
-  for (int i = 0; i < M_GLOBAL; i++) {
-    for (int j = 0; j < K_GLOBAL; j++) {
-      a[i * K_GLOBAL + j] = (uint8_t)(rand() % 3);
-    }
-  }
-
-  for (int i = 0; i < N_GLOBAL; i++) {
-    for (int j = 0; j < K_GLOBAL; j++) {
-      b[i * K_GLOBAL + j] = (uint8_t)(rand() % 3);
-    }
-  }
-
-  for (int t = 0; t < M_GLOBAL * N_GLOBAL; t++) {
-    c[t] = (rand() % 3);
-  }
-}
-
-__global__ void compute_gemm_imma(const uint8_t *A, const uint8_t *B,
-                                  const int *C, int *D, int alpha, int beta) {
-  extern __shared__ uint8_t shmem[][CHUNK_K * K + SKEW_UINT8];
-
-  // Warp and lane identification.
-  const unsigned int warpId = threadIdx.x / WARP_SIZE;
-  const unsigned int laneId = threadIdx.x % WARP_SIZE;
-
-  // Offset in shared memory from which the B matrix is stored.
-  const size_t shmem_idx_b_off = BLOCK_COL_TILES * M;
-
-  // This pointer is used to access the C and D matrix tiles this warp computes.
-  int *shmem_warp_tile_ptr = (int *)&shmem[0][0] +
-                             (warpId / 2) * SHMEM_STRIDE * K * 2 +
-                             (warpId % 2) * SHMEM_OFFSET;
-
-  // This pointer is used to stream the C and D matrices block-wide tile to and
-  // from shared memory.
-  int *shmem_warp_stream_ptr = (int *)&shmem[0][0] + warpId * SHMEM_STRIDE * K;
-
-  // Adjust the beta scaler, as it'll be multiplied by alpha at the end of
-  // each tile computation. Technically this is not generally correct (may
-  // result in a loss of precision). Zero still needs to be specially handled
-  // though.
-  beta /= alpha;
-
-  // Each CTA slides along the 128 x 128 tiles from the top left corner of the
-  // matrix to the right and down, and selects the next tile to compute. Once
-  // there's no such tile, all warps in this CTA exit.
-  for (unsigned int block_pos = blockIdx.x;; block_pos += gridDim.x) {
-    const unsigned int block_tile_i =
-        ((block_pos * BLOCK_ROW_TILES) / N_TILES) * (BLOCK_COL_TILES);
-    const unsigned int block_tile_j = (block_pos * BLOCK_COL_TILES) % N_TILES;
-
-    // Stop when there are no more D matrix tiles to compute in this CTA.
-    if (block_tile_i >= M_TILES) {
-      break;
-    }
-
-    // This warp's pointer to the C matrix data to copy memory from to shared
-    // memory.
-    const size_t gmem_idx =
-        (block_tile_i + warpId) * M * GLOBAL_MEM_STRIDE + block_tile_j * N;
-    const int *src_gmem_warp_stream_ptr = &C[gmem_idx];
-
-    // Stream multiple C tiles to shared memory.
-#pragma unroll
-    for (int i = 0; i < K; i++) {
-      typedef int4 copy_t;
-
-      *((copy_t *)(shmem_warp_stream_ptr + SHMEM_STRIDE * i) + laneId) =
-          *((copy_t *)(src_gmem_warp_stream_ptr + GLOBAL_MEM_STRIDE * i) +
-            laneId);
-    }
-
-    __syncthreads();
-
-    // These fragments will accumulate the result of A and B matrix fragment
-    // multiplications along the K_GLOBAL dimension.
-    wmma::fragment<wmma::accumulator, M, N, K, int> c[WARP_COL_TILES]
-                                                     [WARP_ROW_TILES];
-
-    // Load the C matrix tiles into fragments from shared memory.
-#pragma unroll
-    for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-      for (int j = 0; j < WARP_ROW_TILES; j++) {
-        const int *tile_ptr =
-            shmem_warp_tile_ptr + i * SHMEM_STRIDE * K + j * N;
-
-        wmma::load_matrix_sync(c[i][j], tile_ptr, SHMEM_STRIDE, C_LAYOUT);
-      }
-    }
-
-    __syncthreads();
-
-    // Scale the C matrix.
-#pragma unroll
-    for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-      for (int j = 0; j < WARP_ROW_TILES; j++) {
-#pragma unroll
-        for (int t = 0; t < c[i][j].num_elements; t++) {
-          c[i][j].x[t] *= beta;
-        }
-      }
-    }
-
-    // Select what warp copies what matrix to shared memory.
-    // Warps 0-3 copy the A matrix, warps 4-7 copy the B matrix.
-    const uint8_t *warp_ptr = (warpId < 4) ? (&A[block_tile_i * M * K_GLOBAL] +
-                                              M * K_GLOBAL * (warpId % 4) * 2)
-                                           : (&B[block_tile_j * N * K_GLOBAL] +
-                                              N * K_GLOBAL * (warpId % 4) * 2);
-
-    // Go through the global K dimension by a fixed step at a time.
-#pragma unroll
-    for (int tile_k = 0; tile_k < K_TILES; tile_k += CHUNK_K) {
-      // Copy slices of the A and B matrices to shared memory.
-      // The first half of the warps in the CTA copy the A matrix, the rest copy
-      // the B matrix.
-      size_t shmem_idx =
-          warpId < (WARPS_PER_BLOCK / 2)
-              ? (M * (warpId % (WARPS_PER_BLOCK / 2)) * 2)
-              : (N * (warpId % (WARPS_PER_BLOCK / 2)) * 2 + shmem_idx_b_off);
-
-      // First half of the warp copies the first row / column of the matrix,
-      // the second half of the warp copies the next.
-      int4 *lane_ptr = (int4 *)(warp_ptr + tile_k * K +
-                                (laneId / CHUNK_COPY_LINE_LANES) * K_GLOBAL) +
-                       (laneId % CHUNK_COPY_LINE_LANES);
-
-      // Shift the second half of the warp to the next row / column in the
-      // shared memory.
-      shmem_idx += laneId / CHUNK_COPY_LINE_LANES;
-
-#pragma unroll
-      for (int i = 0; i < ((WARP_SIZE / 2) / CHUNK_COPY_LINES_PER_WARP) * 2;
-           i++) {
-        // Copy 16 bytes at once in each lane.
-        *((int4 *)&shmem[shmem_idx][0] + (laneId % CHUNK_COPY_LINE_LANES)) =
-            *lane_ptr;
-
-        // Advance the global memory pointer and the shared memory index.
-        lane_ptr = (int4 *)((uint8_t *)lane_ptr +
-                            K_GLOBAL * CHUNK_COPY_LINES_PER_WARP);
-        shmem_idx += CHUNK_COPY_LINES_PER_WARP;
-      }
-
-      __syncthreads();
-
-      // Compute a grid of C matrix tiles in each warp.
-#pragma unroll
-      for (int k_step = 0; k_step < CHUNK_K; k_step++) {
-        wmma::fragment<wmma::matrix_a, M, N, K, uint8_t, wmma::row_major>
-            a[WARP_COL_TILES];
-        wmma::fragment<wmma::matrix_b, M, N, K, uint8_t, wmma::col_major>
-            b[WARP_ROW_TILES];
-
-#pragma unroll
-        for (int i = 0; i < WARP_COL_TILES; i++) {
-          size_t shmem_idx_a = (warpId / 2) * M * 2 + (i * M);
-          const uint8_t *tile_ptr = &shmem[shmem_idx_a][k_step * K];
-
-          wmma::load_matrix_sync(a[i], tile_ptr, K * CHUNK_K + SKEW_UINT8);
-
-#pragma unroll
-          for (int j = 0; j < WARP_ROW_TILES; j++) {
-            if (i == 0) {
-              // Load the B matrix fragment once, because it is going to be
-              // reused against the other A matrix fragments.
-              size_t shmem_idx_b = shmem_idx_b_off +
-                                   (WARP_ROW_TILES * N) * (warpId % 2) +
-                                   (j * N);
-              const uint8_t *tile_ptr = &shmem[shmem_idx_b][k_step * K];
-
-              wmma::load_matrix_sync(b[j], tile_ptr, K * CHUNK_K + SKEW_UINT8);
-            }
-
-            wmma::mma_sync(c[i][j], a[i], b[j], c[i][j]);
-          }
-        }
-      }
-
-      __syncthreads();
-    }
-
-      // Store the D fragments to shared memory.
-#pragma unroll
-    for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-      for (int j = 0; j < WARP_ROW_TILES; j++) {
-#pragma unroll
-        // Uniform, point-wise transformations of ALL fragment elements by ALL
-        // threads in the warp are well-defined even though element indices
-        // within fragment storage are not defined.
-        for (int t = 0; t < c[i][j].num_elements; t++) c[i][j].x[t] *= alpha;
-
-        int *tile_ptr = shmem_warp_tile_ptr + i * SHMEM_STRIDE * K + j * N;
-
-        wmma::store_matrix_sync(tile_ptr, c[i][j], SHMEM_STRIDE, C_LAYOUT);
-      }
-    }
-
-    __syncthreads();
-
-    // Now that shared memory contains all the D tiles, stream them to global
-    // memory.
-    int *dst_gmem_warp_stream_ptr = &D[gmem_idx];
-
-#pragma unroll
-    for (int i = 0; i < K; i++) {
-      *((int4 *)(dst_gmem_warp_stream_ptr + GLOBAL_MEM_STRIDE * i) + laneId) =
-          *((int4 *)(shmem_warp_stream_ptr + SHMEM_STRIDE * i) + laneId);
-    }
-
-    __syncthreads();
-  }
-}
-
-// Performs an MxNxK GEMM (C=alpha*A*B + beta*C) assuming:
-//  1) Matrices are packed in memory.
-//  2) M, N and K are multiples of 16.
-//  3) Neither A nor B are transposed.
-// Note: This is a less performant version of the compute_gemm_imma kernel. It
-// is designed for
-//       demonstration purposes only to show the CUDA WMMA API use without
-//       relying on availability of the shared memory.
-__global__ void simple_wmma_gemm_imma(const uint8_t *a, const uint8_t *b,
-                                      const int *c, int *d, int m_ld, int n_ld,
-                                      int k_ld, int alpha, int beta) {
-  // Leading dimensions. Packed with no transpositions.
-  int lda = m_ld;
-  int ldb = k_ld;
-  int ldc = n_ld;
-
-  // Tile using a 2D grid
-  int warpM = (blockIdx.x * blockDim.x + threadIdx.x) / warpSize;
-  int warpN = (blockIdx.y * blockDim.y + threadIdx.y);
-
-  // Declare the fragments
-  wmma::fragment<wmma::matrix_a, WMMA_M, WMMA_N, WMMA_K, uint8_t,
-                 wmma::row_major>
-      a_frag;
-  wmma::fragment<wmma::matrix_b, WMMA_M, WMMA_N, WMMA_K, uint8_t,
-                 wmma::col_major>
-      b_frag;
-  wmma::fragment<wmma::accumulator, WMMA_M, WMMA_N, WMMA_K, int> acc_frag;
-  wmma::fragment<wmma::accumulator, WMMA_M, WMMA_N, WMMA_K, int> c_frag;
-
-  wmma::fill_fragment(acc_frag, 0.0f);
-
-  // Loop over k
-  for (int i = 0; i < k_ld; i += WMMA_K) {
-    int aCol = i;
-    int aRow = warpM * WMMA_M;
-
-    int bCol = i;
-    int bRow = warpN * WMMA_N;
-
-    // Bounds checking
-    if (aRow < m_ld && aCol < k_ld && bRow < k_ld && bCol < n_ld) {
-      // Load the inputs
-      wmma::load_matrix_sync(a_frag, a + aCol + aRow * lda, lda);
-      wmma::load_matrix_sync(b_frag, b + bCol + bRow * ldb, ldb);
-
-      // Perform the matrix multiplication
-      wmma::mma_sync(acc_frag, a_frag, b_frag, acc_frag);
-    }
-  }
-
-  // Load in the current value of c, scale it by beta, and add this our result
-  // scaled by alpha
-  int cCol = warpN * WMMA_N;
-  int cRow = warpM * WMMA_M;
-
-  if (cRow < m_ld && cCol < n_ld) {
-    wmma::load_matrix_sync(c_frag, c + cCol + cRow * ldc, ldc,
-                           wmma::mem_row_major);
-
-    for (int i = 0; i < c_frag.num_elements; i++) {
-      c_frag.x[i] = alpha * acc_frag.x[i] + beta * c_frag.x[i];
-    }
-
-    // Store the output
-    wmma::store_matrix_sync(d + cCol + cRow * ldc, c_frag, ldc,
-                            wmma::mem_row_major);
-  }
-}
-
-__host__ void matMultiplyOnHost(uint8_t *A, uint8_t *B, int *C, int alpha,
-                                int beta, int numARows, int numAColumns,
-                                int numBRows, int numBColumns, int numCRows,
-                                int numCColumns) {
-  for (int i = 0; i < numCRows; i++) {
-    for (int j = 0; j < numCColumns; j++) {
-      int temp = 0;
-
-      for (int k = 0; k < numAColumns; k++) {
-        temp += A[i * numAColumns + k] * B[j * numBRows + k];
-      }
-
-      C[i * numCColumns + j] = temp * alpha + beta * C[i * numCColumns + j];
-    }
-  }
-}
-
-int main(int argc, char **argv) {
-  printf("Initializing...\n");
-
-  int dev = findCudaDevice(argc, (const char **)argv);
-
-  hipDeviceProp_t deviceProp;
-  checkCudaErrors(hipGetDeviceProperties(&deviceProp, dev));
-
-  // Tensor cores require a GPU of Volta (SM72) architecture or higher.
-  if (deviceProp.major < 7 || (deviceProp.major <= 7 && deviceProp.minor < 2)) {
-    printf(
-        "immaTensorCoreGemm requires SM 7.2 or higher to use Tensor Cores.  "
-        "Exiting...\n");
-    exit(EXIT_WAIVED);
-  }
-
-  printf("M: %d (%d x %d)\n", M_GLOBAL, M, M_TILES);
-  printf("N: %d (%d x %d)\n", N_GLOBAL, N, N_TILES);
-  printf("K: %d (%d x %d)\n", K_GLOBAL, K, K_TILES);
-
-  uint8_t *A_h = NULL;
-  uint8_t *B_h = NULL;
-  int *C_h = NULL;
-#if CPU_DEBUG
-  int *result_hD = NULL;
-  int *result_host = NULL;
-#endif
-
-  A_h = (uint8_t *)malloc(sizeof(uint8_t) * M_GLOBAL * K_GLOBAL);
-  B_h = (uint8_t *)malloc(sizeof(uint8_t) * K_GLOBAL * N_GLOBAL);
-  C_h = (int *)malloc(sizeof(int) * M_GLOBAL * N_GLOBAL);
-#if CPU_DEBUG
-  result_hD = (int *)malloc(sizeof(int) * M_GLOBAL * N_GLOBAL);
-  result_host = (int *)malloc(sizeof(int) * M_GLOBAL * N_GLOBAL);
-#endif
-
-  uint8_t *A = NULL;
-  uint8_t *B = NULL;
-  int *C = NULL;
-  int *D = NULL;
-
-  checkCudaErrors(
-      hipMalloc(reinterpret_cast<void **>(&A), sizeof(uint8_t) * M_GLOBAL * K_GLOBAL));
-  checkCudaErrors(
-      hipMalloc(reinterpret_cast<void **>(&B), sizeof(uint8_t) * N_GLOBAL * K_GLOBAL));
-  checkCudaErrors(hipMalloc(reinterpret_cast<void **>(&C), sizeof(int) * M_GLOBAL * N_GLOBAL));
-  checkCudaErrors(hipMalloc(reinterpret_cast<void **>(&D), sizeof(int) * M_GLOBAL * N_GLOBAL));
-
-  assert(((unsigned long long)A) % 128 == 0);
-  assert(((unsigned long long)B) % 128 == 0);
-  assert(((unsigned long long)C) % 128 == 0);
-  assert(((unsigned long long)D) % 128 == 0);
-
-  init_host_matrices(A_h, B_h, C_h);
-
-  checkCudaErrors(hipMemcpy(A, A_h, sizeof(uint8_t) * M_GLOBAL * K_GLOBAL,
-                             hipMemcpyHostToDevice));
-  checkCudaErrors(hipMemcpy(B, B_h, sizeof(uint8_t) * N_GLOBAL * K_GLOBAL,
-                             hipMemcpyHostToDevice));
-  checkCudaErrors(hipMemcpy(C, C_h, sizeof(int) * M_GLOBAL * N_GLOBAL,
-                             hipMemcpyHostToDevice));
-  checkCudaErrors(hipMemset(D, 0, sizeof(int) * M_GLOBAL * N_GLOBAL));
-
-  printf("Preparing data for GPU...\n");
-
-  assert(((unsigned long long)A) % 128 == 0);
-  assert(((unsigned long long)B) % 128 == 0);
-  assert(((unsigned long long)C) % 128 == 0);
-  assert(((unsigned long long)D) % 128 == 0);
-
-  enum {
-    // Compute the right amount of shared memory to request.
-    // We need shared memory to hold per-CTA C and D matrix tiles, and to cache
-    // per-CTA chunks
-    // of the A and B matrices. Therefore, the right amount to request is the
-    // maximum of those
-    // two numbers.
-    SHMEM_SZ = MAX(sizeof(uint8_t) * (BLOCK_COL_TILES * M) *
-                       (CHUNK_K * K + SKEW_UINT8) * 2,
-                   M * (BLOCK_ROW_WARPS * WARP_ROW_TILES) * N *
-                       (BLOCK_COL_WARPS * WARP_COL_TILES) * sizeof(int))
-  };
-
-  printf("Required shared memory size: %lu Kb\n", SHMEM_SZ / 1024UL);
-
-  int alpha = 1;
-  int beta = 1;
-
-  hipEvent_t start, stop;
-
-  checkCudaErrors(hipEventCreate(&start));
-  checkCudaErrors(hipEventCreate(&stop));
-  checkCudaErrors(hipEventRecord(start));
-
-  // If enough shared memory available on the GPU use high performant kernel
-  if (deviceProp.sharedMemPerMultiprocessor >= SHMEM_SZ) {
-    printf("Computing... using high performance kernel compute_gemm_imma \n");
-
-    checkCudaErrors(hipFuncSetAttribute(
-        compute_gemm_imma, hipFuncAttributeMaxDynamicSharedMemorySize,
-        SHMEM_SZ));
-    checkKernelErrors(
-        (compute_gemm_imma<<<deviceProp.multiProcessorCount, THREADS_PER_BLOCK,
-                             SHMEM_SZ>>>(A, B, C, D, alpha, beta)));
-#if CPU_DEBUG
-    checkCudaErrors(hipMemcpy(result_hD, D, sizeof(int) * M_GLOBAL * N_GLOBAL,
-                               hipMemcpyDeviceToHost));
-#endif
-  } else {
-    dim3 gridDim;
-    dim3 blockDim;
-
-    // blockDim.x must be a multiple of warpSize
-    // 128x4 means we have 16 warps and a block computes a 64x64 output tile
-    blockDim.x = 128;
-    blockDim.y = 4;
-
-    gridDim.x = (M_GLOBAL + (WMMA_M * blockDim.x / 32 - 1)) /
-                (WMMA_M * blockDim.x / 32);
-    gridDim.y = (N_GLOBAL + WMMA_N * blockDim.y - 1) / (WMMA_N * blockDim.y);
-
-    printf("Computing... using simple_wmma_gemm_imma kernel\n");
-    simple_wmma_gemm_imma<<<gridDim, blockDim>>>(A, B, C, D, M_GLOBAL, N_GLOBAL,
-                                                 K_GLOBAL, alpha, beta);
-#if CPU_DEBUG
-    checkCudaErrors(hipMemcpy(result_hD, D, sizeof(int) * M_GLOBAL * N_GLOBAL,
-                               hipMemcpyDeviceToHost));
-#endif
-  }
-
-  checkCudaErrors(hipEventRecord(stop));
-  checkCudaErrors(hipEventSynchronize(stop));
-
-#if CPU_DEBUG
-  printf("Verifying correctness of the computations...\n");
-
-  memcpy(result_host, C_h, sizeof(int) * M_GLOBAL * N_GLOBAL);
-
-  matMultiplyOnHost(A_h, B_h, result_host, alpha, beta, M_GLOBAL, K_GLOBAL,
-                    K_GLOBAL, N_GLOBAL, M_GLOBAL, N_GLOBAL);
-
-  for (int i = 0; i < N_GLOBAL * M_GLOBAL; i++) {
-    if (abs(result_hD[i] - result_host[i]) > 0) {
-      printf("mismatch i=%d result_hD=%d result_host=%d\n", i, result_hD[i],
-             result_host[i]);
-    }
-  }
-  free(result_host);
-  free(result_hD);
-#endif
-
-  float milliseconds = 0;
-
-  checkCudaErrors(hipEventElapsedTime(&milliseconds, start, stop));
-
-    printf("Time: %f ms\n", milliseconds);
-    printf("TOPS: %.2f\n", (((double)M_GLOBAL * N_GLOBAL * K_GLOBAL * 2)/(milliseconds/1000.)) / 1e12);
-
-  free(A_h);
-  free(B_h);
-  free(C_h);
-  HIPCHECK(hipFree(reinterpret_cast<void *>(A)));
-  HIPCHECK(hipFree(reinterpret_cast<void *>(B)));
-  HIPCHECK(hipFree(reinterpret_cast<void *>(C)));
-  HIPCHECK(hipFree(reinterpret_cast<void *>(D)));
-
-  return EXIT_SUCCESS;
-}
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2017.sln b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2019.sln b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2022.sln b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/immaTensorCoreGemm/immaTensorCoreGemm_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/Makefile b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/README.md b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobi.cu b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobi.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobi.cu.hip b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobi.cu.hip
old mode 100644
new mode 100755
index f8097e0..e69de29
--- a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobi.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobi.cu.hip
@@ -1,392 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <hip/hip_cooperative_groups.h>
-#include <hip/hip_runtime.h>
-#include "helper_cuda_hipified.h"
-#include <vector>
-#include "jacobi_hipified.h"
-#include "HIPCHECK.h"
-namespace cg = cooperative_groups;
-
-// 8 Rows of square-matrix A processed by each CTA.
-// This can be max 32 and only power of 2 (i.e., 2/4/8/16/32).
-#define ROWS_PER_CTA 8
-
-#if !defined(__CUDA_ARCH__) || __CUDA_ARCH__ >= 600
-#else
-__device__ double atomicAdd(double *address, double val) {
-  unsigned long long int *address_as_ull = (unsigned long long int *)address;
-  unsigned long long int old = *address_as_ull, assumed;
-
-  do {
-    assumed = old;
-    old = atomicCAS(address_as_ull, assumed,
-                    __double_as_longlong(val + __longlong_as_double(assumed)));
-
-    // Note: uses integer comparison to avoid hang in case of NaN (since NaN !=
-    // NaN)
-  } while (assumed != old);
-
-  return __longlong_as_double(old);
-}
-#endif
-
-static __global__ void JacobiMethod(const float *A, const double *b,
-                                    const float conv_threshold, double *x,
-                                    double *x_new, double *sum) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  __shared__ double x_shared[N_ROWS];  // N_ROWS == n
-  __shared__ double b_shared[ROWS_PER_CTA + 1];
-
-  for (int i = threadIdx.x; i < N_ROWS; i += blockDim.x) {
-    x_shared[i] = x[i];
-  }
-
-  if (threadIdx.x < ROWS_PER_CTA) {
-    int k = threadIdx.x;
-    for (int i = k + (blockIdx.x * ROWS_PER_CTA);
-         (k < ROWS_PER_CTA) && (i < N_ROWS);
-         k += ROWS_PER_CTA, i += ROWS_PER_CTA) {
-      b_shared[i % (ROWS_PER_CTA + 1)] = b[i];
-    }
-  }
-
-  cg::sync(cta);
-
-  cg::thread_block_tile<32> tile32 = cg::tiled_partition<32>(cta);
-
-  for (int k = 0, i = blockIdx.x * ROWS_PER_CTA;
-       (k < ROWS_PER_CTA) && (i < N_ROWS); k++, i++) {
-    double rowThreadSum = 0.0;
-    for (int j = threadIdx.x; j < N_ROWS; j += blockDim.x) {
-      rowThreadSum += (A[i * N_ROWS + j] * x_shared[j]);
-    }
-
-    for (int offset = tile32.size() / 2; offset > 0; offset /= 2) {
-      rowThreadSum += tile32.shfl_down(rowThreadSum, offset);
-    }
-
-    if (tile32.thread_rank() == 0) {
-      atomicAdd(&b_shared[i % (ROWS_PER_CTA + 1)], -rowThreadSum);
-    }
-  }
-
-  cg::sync(cta);
-
-  if (threadIdx.x < ROWS_PER_CTA) {
-    cg::thread_block_tile<ROWS_PER_CTA> tile8 =
-        cg::tiled_partition<ROWS_PER_CTA>(cta);
-    double temp_sum = 0.0;
-
-    int k = threadIdx.x;
-
-    for (int i = k + (blockIdx.x * ROWS_PER_CTA);
-         (k < ROWS_PER_CTA) && (i < N_ROWS);
-         k += ROWS_PER_CTA, i += ROWS_PER_CTA) {
-      double dx = b_shared[i % (ROWS_PER_CTA + 1)];
-      dx /= A[i * N_ROWS + i];
-
-      x_new[i] = (x_shared[i] + dx);
-      temp_sum += fabs(dx);
-    }
-
-    for (int offset = tile8.size() / 2; offset > 0; offset /= 2) {
-      temp_sum += tile8.shfl_down(temp_sum, offset);
-    }
-
-    if (tile8.thread_rank() == 0) {
-      atomicAdd(sum, temp_sum);
-    }
-  }
-}
-
-// Thread block size for finalError kernel should be multiple of 32
-static __global__ void finalError(double *x, double *g_sum) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  extern __shared__ double warpSum[];
-  double sum = 0.0;
-
-  int globalThreadId = blockIdx.x * blockDim.x + threadIdx.x;
-
-  for (int i = globalThreadId; i < N_ROWS; i += blockDim.x * gridDim.x) {
-    double d = x[i] - 1.0;
-    sum += fabs(d);
-  }
-
-  cg::thread_block_tile<32> tile32 = cg::tiled_partition<32>(cta);
-
-  for (int offset = tile32.size() / 2; offset > 0; offset /= 2) {
-    sum += tile32.shfl_down(sum, offset);
-  }
-
-  if (tile32.thread_rank() == 0) {
-    warpSum[threadIdx.x / warpSize] = sum;
-  }
-
-  cg::sync(cta);
-
-  double blockSum = 0.0;
-  if (threadIdx.x < (blockDim.x / warpSize)) {
-    blockSum = warpSum[threadIdx.x];
-  }
-
-  if (threadIdx.x < 32) {
-    for (int offset = tile32.size() / 2; offset > 0; offset /= 2) {
-      blockSum += tile32.shfl_down(blockSum, offset);
-    }
-    if (tile32.thread_rank() == 0) {
-      atomicAdd(g_sum, blockSum);
-    }
-  }
-}
-
-double JacobiMethodGpuCudaGraphExecKernelSetParams(
-    const float *A, const double *b, const float conv_threshold,
-    const int max_iter, double *x, double *x_new, hipStream_t stream) {
-  // CTA size
-  dim3 nthreads(256, 1, 1);
-  // grid size
-  dim3 nblocks((N_ROWS / ROWS_PER_CTA) + 2, 1, 1);
-  hipGraph_t graph;
-  hipGraphExec_t graphExec = NULL;
-
-  double sum = 0.0;
-  double *d_sum = NULL;
-  HIPCHECK(hipMalloc(&d_sum, sizeof(double)));
-
-  std::vector<hipGraphNode_t> nodeDependencies;
-  hipGraphNode_t memcpyNode, jacobiKernelNode, memsetNode;
-  hipMemcpy3DParms memcpyParams = {0};
-  hipMemsetParams memsetParams = {0};
-
-  memsetParams.dst = (void *)d_sum;
-  memsetParams.value = 0;
-  memsetParams.pitch = 0;
-  // elementSize can be max 4 bytes, so we take sizeof(float) and width=2
-  memsetParams.elementSize = sizeof(float);
-  memsetParams.width = 2;
-  memsetParams.height = 1;
-
-  HIPCHECK(hipGraphCreate(&graph, 0));
-  HIPCHECK(
-      hipGraphAddMemsetNode(&memsetNode, graph, NULL, 0, &memsetParams));
-  nodeDependencies.push_back(memsetNode);
-
-  hipKernelNodeParams NodeParams0, NodeParams1;
-  NodeParams0.func = (void *)JacobiMethod;
-  NodeParams0.gridDim = nblocks;
-  NodeParams0.blockDim = nthreads;
-  NodeParams0.sharedMemBytes = 0;
-  void *kernelArgs0[6] = {(void *)&A, (void *)&b,     (void *)&conv_threshold,
-                          (void *)&x, (void *)&x_new, (void *)&d_sum};
-  NodeParams0.kernelParams = kernelArgs0;
-  NodeParams0.extra = NULL;
-
-  HIPCHECK(
-      hipGraphAddKernelNode(&jacobiKernelNode, graph, nodeDependencies.data(),
-                             nodeDependencies.size(), &NodeParams0));
-
-  nodeDependencies.clear();
-  nodeDependencies.push_back(jacobiKernelNode);
-
-  memcpyParams.srcArray = NULL;
-  memcpyParams.srcPos = make_hipPos(0, 0, 0);
-  memcpyParams.srcPtr = make_hipPitchedPtr(d_sum, sizeof(double), 1, 1);
-  memcpyParams.dstArray = NULL;
-  memcpyParams.dstPos = make_hipPos(0, 0, 0);
-  memcpyParams.dstPtr = make_hipPitchedPtr(&sum, sizeof(double), 1, 1);
-  memcpyParams.extent = make_hipExtent(sizeof(double), 1, 1);
-  memcpyParams.kind = hipMemcpyDeviceToHost;
-
-  HIPCHECK(
-      hipGraphAddMemcpyNode(&memcpyNode, graph, nodeDependencies.data(),
-                             nodeDependencies.size(), &memcpyParams));
-
-  HIPCHECK(hipGraphInstantiate(&graphExec, graph, NULL, NULL, 0));
-
-  NodeParams1.func = (void *)JacobiMethod;
-  NodeParams1.gridDim = nblocks;
-  NodeParams1.blockDim = nthreads;
-  NodeParams1.sharedMemBytes = 0;
-  void *kernelArgs1[6] = {(void *)&A,     (void *)&b, (void *)&conv_threshold,
-                          (void *)&x_new, (void *)&x, (void *)&d_sum};
-  NodeParams1.kernelParams = kernelArgs1;
-  NodeParams1.extra = NULL;
-
-  int k = 0;
-  for (k = 0; k < max_iter; k++) {
-    HIPCHECK(hipGraphExecKernelNodeSetParams(
-        graphExec, jacobiKernelNode,
-        ((k & 1) == 0) ? &NodeParams0 : &NodeParams1));
-    HIPCHECK(hipGraphLaunch(graphExec, stream));
-    HIPCHECK(hipStreamSynchronize(stream));
-
-    if (sum <= conv_threshold) {
-      HIPCHECK(hipMemsetAsync(d_sum, 0, sizeof(double), stream));
-      nblocks.x = (N_ROWS / nthreads.x) + 1;
-      size_t sharedMemSize = ((nthreads.x / 32) + 1) * sizeof(double);
-      if ((k & 1) == 0) {
-        finalError<<<nblocks, nthreads, sharedMemSize, stream>>>(x_new, d_sum);
-      } else {
-        finalError<<<nblocks, nthreads, sharedMemSize, stream>>>(x, d_sum);
-      }
-
-      HIPCHECK(hipMemcpyAsync(&sum, d_sum, sizeof(double),
-                                      hipMemcpyDeviceToHost, stream));
-      HIPCHECK(hipStreamSynchronize(stream));
-      printf("GPU iterations : %d\n", k + 1);
-      printf("GPU error : %.3e\n", sum);
-      break;
-    }
-  }
-
-  HIPCHECK(hipFree(d_sum));
-  return sum;
-}
-
-double JacobiMethodGpuCudaGraphExecUpdate(const float *A, const double *b,
-                                          const float conv_threshold,
-                                          const int max_iter, double *x,
-                                          double *x_new, hipStream_t stream) {
-  // CTA size
-  dim3 nthreads(256, 1, 1);
-  // grid size
-  dim3 nblocks((N_ROWS / ROWS_PER_CTA) + 2, 1, 1);
-  hipGraph_t graph;
-  hipGraphExec_t graphExec = NULL;
-
-  double sum = 0.0;
-  double *d_sum;
-  HIPCHECK(hipMalloc(&d_sum, sizeof(double)));
-
-  int k = 0;
-  for (k = 0; k < max_iter; k++) {
-    HIPCHECK(
-        hipStreamBeginCapture(stream, hipStreamCaptureModeGlobal));
-    HIPCHECK(hipMemsetAsync(d_sum, 0, sizeof(double), stream));
-    if ((k & 1) == 0) {
-      JacobiMethod<<<nblocks, nthreads, 0, stream>>>(A, b, conv_threshold, x,
-                                                     x_new, d_sum);
-    } else {
-      JacobiMethod<<<nblocks, nthreads, 0, stream>>>(A, b, conv_threshold,
-                                                     x_new, x, d_sum);
-    }
-    HIPCHECK(hipMemcpyAsync(&sum, d_sum, sizeof(double),
-                                    hipMemcpyDeviceToHost, stream));
-    HIPCHECK(hipStreamEndCapture(stream, &graph));
-
-    if (graphExec == NULL) {
-      HIPCHECK(hipGraphInstantiate(&graphExec, graph, NULL, NULL, 0));
-    } else {
-      hipGraphExecUpdateResult updateResult_out;
-      HIPCHECK(
-          hipGraphExecUpdate(graphExec, graph, NULL, &updateResult_out));
-      if (updateResult_out != hipGraphExecUpdateSuccess) {
-        if (graphExec != NULL) {
-          HIPCHECK(hipGraphExecDestroy(graphExec));
-        }
-        printf("k = %d graph update failed with error - %d\n", k,
-               updateResult_out);
-        HIPCHECK(hipGraphInstantiate(&graphExec, graph, NULL, NULL, 0));
-      }
-    }
-    HIPCHECK(hipGraphLaunch(graphExec, stream));
-    HIPCHECK(hipStreamSynchronize(stream));
-
-    if (sum <= conv_threshold) {
-      HIPCHECK(hipMemsetAsync(d_sum, 0, sizeof(double), stream));
-      nblocks.x = (N_ROWS / nthreads.x) + 1;
-      size_t sharedMemSize = ((nthreads.x / 32) + 1) * sizeof(double);
-      if ((k & 1) == 0) {
-        finalError<<<nblocks, nthreads, sharedMemSize, stream>>>(x_new, d_sum);
-      } else {
-        finalError<<<nblocks, nthreads, sharedMemSize, stream>>>(x, d_sum);
-      }
-
-      HIPCHECK(hipMemcpyAsync(&sum, d_sum, sizeof(double),
-                                      hipMemcpyDeviceToHost, stream));
-      HIPCHECK(hipStreamSynchronize(stream));
-      printf("GPU iterations : %d\n", k + 1);
-      printf("GPU error : %.3e\n", sum);
-      break;
-    }
-  }
-
-  HIPCHECK(hipFree(d_sum));
-  return sum;
-}
-
-double JacobiMethodGpu(const float *A, const double *b,
-                       const float conv_threshold, const int max_iter,
-                       double *x, double *x_new, hipStream_t stream) {
-  // CTA size
-  dim3 nthreads(256, 1, 1);
-  // grid size
-  dim3 nblocks((N_ROWS / ROWS_PER_CTA) + 2, 1, 1);
-
-  double sum = 0.0;
-  double *d_sum;
-  HIPCHECK(hipMalloc(&d_sum, sizeof(double)));
-  int k = 0;
-
-  for (k = 0; k < max_iter; k++) {
-    HIPCHECK(hipMemsetAsync(d_sum, 0, sizeof(double), stream));
-    if ((k & 1) == 0) {
-      JacobiMethod<<<nblocks, nthreads, 0, stream>>>(A, b, conv_threshold, x,
-                                                     x_new, d_sum);
-    } else {
-      JacobiMethod<<<nblocks, nthreads, 0, stream>>>(A, b, conv_threshold,
-                                                     x_new, x, d_sum);
-    }
-    HIPCHECK(hipMemcpyAsync(&sum, d_sum, sizeof(double),
-                                    hipMemcpyDeviceToHost, stream));
-    HIPCHECK(hipStreamSynchronize(stream));
-
-    if (sum <= conv_threshold) {
-      HIPCHECK(hipMemsetAsync(d_sum, 0, sizeof(double), stream));
-      nblocks.x = (N_ROWS / nthreads.x) + 1;
-      size_t sharedMemSize = ((nthreads.x / 32) + 1) * sizeof(double);
-      if ((k & 1) == 0) {
-        finalError<<<nblocks, nthreads, sharedMemSize, stream>>>(x_new, d_sum);
-      } else {
-        finalError<<<nblocks, nthreads, sharedMemSize, stream>>>(x, d_sum);
-      }
-
-      HIPCHECK(hipMemcpyAsync(&sum, d_sum, sizeof(double),
-                                      hipMemcpyDeviceToHost, stream));
-      HIPCHECK(hipStreamSynchronize(stream));
-      printf("GPU iterations : %d\n", k + 1);
-      printf("GPU error : %.3e\n", sum);
-      break;
-    }
-  }
-}
-
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobi.h b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobi.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs.out b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2017.sln b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2019.sln b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2022.sln b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobiCudaGraphs_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobi_hipified.h b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/jacobi_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/main.cpp b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/main_hipified.cpp b/src/samples/Samples/3_CUDA_Features/jacobiCudaGraphs/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/Makefile b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/README.md b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2017.sln b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2019.sln b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2022.sln b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIPCDrv_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc.cpp b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_hipified.cpp b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_kernel.cu b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_kernel.cu.hip b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_kernel.cu.hip
old mode 100644
new mode 100755
index 41b1784..e69de29
--- a/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_kernel.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/memMapIPCDrv/memMapIpc_kernel.cu.hip
@@ -1,38 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-
-// Device code
-extern "C" __global__ void memMapIpc_kernel(char *ptr, int sz, char val)
-{
-    // Dummy kernel
-    int idx = blockIdx.x * blockDim.x + threadIdx.x;
-    for (; idx < sz; idx += (gridDim.x * blockDim.x)) {
-        ptr[idx] = val;
-    }
-}
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/newdelete/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/newdelete/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/newdelete/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/newdelete/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/Makefile b/src/samples/Samples/3_CUDA_Features/newdelete/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/newdelete/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/README.md b/src/samples/Samples/3_CUDA_Features/newdelete/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/container.hpp b/src/samples/Samples/3_CUDA_Features/newdelete/container.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete.cu b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete.cu.hip b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete.cu.hip
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete.out b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2017.sln b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2019.sln b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2022.sln b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/newdelete/newdelete_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/ptxjit/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/ptxjit/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/ptxjit/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/ptxjit/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/Makefile b/src/samples/Samples/3_CUDA_Features/ptxjit/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/ptxjit/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/README.md b/src/samples/Samples/3_CUDA_Features/ptxjit/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit.cpp b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_hipified.cpp b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_kernel.cu b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_kernel.cu.hip b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_kernel.cu.hip
old mode 100644
new mode 100755
index 6444402..e69de29
--- a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_kernel.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_kernel.cu.hip
@@ -1,37 +0,0 @@
-#include "hip/hip_runtime.h"
-#include <hip/hiprtc.h>
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Simple kernel for ptxjit demonstration.
- *
- */
-extern "C" __global__ void myKernel(int *data) {
-  int tid = blockIdx.x * blockDim.x + threadIdx.x;
-  data[tid] = tid;
-}
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2017.sln b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2019.sln b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2022.sln b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/ptxjit/ptxjit_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/Makefile b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/README.md b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/_temp_0_gfx908_sramecc+_xnack-_linked.bc b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/_temp_0_gfx908_sramecc+_xnack-_linked.bc
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.cu b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.cu.hip b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.cu.hip
old mode 100644
new mode 100755
index 317d45e..e69de29
--- a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.cu.hip
@@ -1,414 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <hip/hip_cooperative_groups.h>
-#include <hip/hip_runtime.h>
-#include "helper_cuda_hipified.h"
-#include <vector>
-#include "HIPCHECK.h"
-namespace cg = cooperative_groups;
-
-#define THREADS_PER_BLOCK 512
-#define GRAPH_LAUNCH_ITERATIONS 3
-
-typedef struct callBackData {
-  const char *fn_name;
-  double *data;
-} callBackData_t;
-
-__global__ void reduce(float *inputVec, double *outputVec, size_t inputSize,
-                       size_t outputSize) {
-  __shared__ double tmp[THREADS_PER_BLOCK];
-
-  cg::thread_block cta = cg::this_thread_block();
-  size_t globaltid = blockIdx.x * blockDim.x + threadIdx.x;
-
-  double temp_sum = 0.0;
-  for (int i = globaltid; i < inputSize; i += gridDim.x * blockDim.x) {
-    temp_sum += (double)inputVec[i];
-  }
-  tmp[cta.thread_rank()] = temp_sum;
-
-  cg::sync(cta);
-
-  cg::thread_block_tile<32> tile32 = cg::tiled_partition<32>(cta);
-
-  double beta = temp_sum;
-  double temp;
-
-  for (int i = tile32.size() / 2; i > 0; i >>= 1) {
-    if (tile32.thread_rank() < i) {
-      temp = tmp[cta.thread_rank() + i];
-      beta += temp;
-      tmp[cta.thread_rank()] = beta;
-    }
-    cg::sync(tile32);
-  }
-  cg::sync(cta);
-
-  if (cta.thread_rank() == 0 && blockIdx.x < outputSize) {
-    beta = 0.0;
-    for (int i = 0; i < cta.size(); i += tile32.size()) {
-      beta += tmp[i];
-    }
-    outputVec[blockIdx.x] = beta;
-  }
-}
-
-__global__ void reduceFinal(double *inputVec, double *result,
-                            size_t inputSize) {
-  __shared__ double tmp[THREADS_PER_BLOCK];
-
-  cg::thread_block cta = cg::this_thread_block();
-  size_t globaltid = blockIdx.x * blockDim.x + threadIdx.x;
-
-  double temp_sum = 0.0;
-  for (int i = globaltid; i < inputSize; i += gridDim.x * blockDim.x) {
-    temp_sum += (double)inputVec[i];
-  }
-  tmp[cta.thread_rank()] = temp_sum;
-
-  cg::sync(cta);
-
-  cg::thread_block_tile<32> tile32 = cg::tiled_partition<32>(cta);
-
-  // do reduction in shared mem
-  if ((blockDim.x >= 512) && (cta.thread_rank() < 256)) {
-    tmp[cta.thread_rank()] = temp_sum = temp_sum + tmp[cta.thread_rank() + 256];
-  }
-
-  cg::sync(cta);
-
-  if ((blockDim.x >= 256) && (cta.thread_rank() < 128)) {
-    tmp[cta.thread_rank()] = temp_sum = temp_sum + tmp[cta.thread_rank() + 128];
-  }
-
-  cg::sync(cta);
-
-  if ((blockDim.x >= 128) && (cta.thread_rank() < 64)) {
-    tmp[cta.thread_rank()] = temp_sum = temp_sum + tmp[cta.thread_rank() + 64];
-  }
-
-  cg::sync(cta);
-
-  if (cta.thread_rank() < 32) {
-    // Fetch final intermediate sum from 2nd warp
-    if (blockDim.x >= 64) temp_sum += tmp[cta.thread_rank() + 32];
-    // Reduce final warp using shuffle
-    for (int offset = tile32.size() / 2; offset > 0; offset /= 2) {
-      temp_sum += tile32.shfl_down(temp_sum, offset);
-    }
-  }
-  // write result for this block to global mem
-  if (cta.thread_rank() == 0) result[0] = temp_sum;
-}
-
-void init_input(float *a, size_t size) {
-  for (size_t i = 0; i < size; i++) a[i] = (rand() & 0xFF) / (float)RAND_MAX;
-}
-
-void  myHostNodeCallback(void *data) {
-  // Check status of GPU after stream operations are done
-  callBackData_t *tmp = (callBackData_t *)(data);
-  // HIPCHECK(tmp->status);
-
-  double *result = (double *)(tmp->data);
-  char *function = (char *)(tmp->fn_name);
-  printf("[%s] Host callback final reduced sum = %lf\n", function, *result);
-  *result = 0.0;  // reset the result
-}
-
-void cudaGraphsManual(float *inputVec_h, float *inputVec_d, double *outputVec_d,
-                      double *result_d, size_t inputSize, size_t numOfBlocks) {
-  hipStream_t streamForGraph;
-  hipGraph_t graph;
-  std::vector<hipGraphNode_t> nodeDependencies;
-  hipGraphNode_t memcpyNode, kernelNode, memsetNode;
-  double result_h = 0.0;
-
-  HIPCHECK(hipStreamCreate(&streamForGraph));
-
-  hipKernelNodeParams kernelNodeParams = {0};
-  hipMemcpy3DParms memcpyParams = {0};
-  hipMemsetParams memsetParams = {0};
-
-  memcpyParams.srcArray = NULL;
-  memcpyParams.srcPos = make_hipPos(0, 0, 0);
-  memcpyParams.srcPtr =
-      make_hipPitchedPtr(inputVec_h, sizeof(float) * inputSize, inputSize, 1);
-  memcpyParams.dstArray = NULL;
-  memcpyParams.dstPos = make_hipPos(0, 0, 0);
-  memcpyParams.dstPtr =
-      make_hipPitchedPtr(inputVec_d, sizeof(float) * inputSize, inputSize, 1);
-  memcpyParams.extent = make_hipExtent(sizeof(float) * inputSize, 1, 1);
-  memcpyParams.kind = hipMemcpyHostToDevice;
-
-  memsetParams.dst = (void *)outputVec_d;
-  memsetParams.value = 0;
-  memsetParams.pitch = 0;
-  memsetParams.elementSize = sizeof(float);  // elementSize can be max 4 bytes
-  memsetParams.width = numOfBlocks * 2;
-  memsetParams.height = 1;
-
-  HIPCHECK(hipGraphCreate(&graph, 0));
-  HIPCHECK(
-      hipGraphAddMemcpyNode(&memcpyNode, graph, NULL, 0, &memcpyParams));
-  HIPCHECK(
-      hipGraphAddMemsetNode(&memsetNode, graph, NULL, 0, &memsetParams));
-
-  nodeDependencies.push_back(memsetNode);
-  nodeDependencies.push_back(memcpyNode);
-
-  void *kernelArgs[4] = {(void *)&inputVec_d, (void *)&outputVec_d, &inputSize,
-                         &numOfBlocks};
-
-  kernelNodeParams.func = (void *)reduce;
-  kernelNodeParams.gridDim = dim3(numOfBlocks, 1, 1);
-  kernelNodeParams.blockDim = dim3(THREADS_PER_BLOCK, 1, 1);
-  kernelNodeParams.sharedMemBytes = 0;
-  kernelNodeParams.kernelParams = (void **)kernelArgs;
-  kernelNodeParams.extra = NULL;
-
-  HIPCHECK(
-      hipGraphAddKernelNode(&kernelNode, graph, nodeDependencies.data(),
-                             nodeDependencies.size(), &kernelNodeParams));
-
-  nodeDependencies.clear();
-  nodeDependencies.push_back(kernelNode);
-
-  memset(&memsetParams, 0, sizeof(memsetParams));
-  memsetParams.dst = result_d;
-  memsetParams.value = 0;
-  memsetParams.elementSize = sizeof(float);
-  memsetParams.width = 2;
-  memsetParams.height = 1;
-  HIPCHECK(
-      hipGraphAddMemsetNode(&memsetNode, graph, NULL, 0, &memsetParams));
-
-  nodeDependencies.push_back(memsetNode);
-
-  memset(&kernelNodeParams, 0, sizeof(kernelNodeParams));
-  kernelNodeParams.func = (void *)reduceFinal;
-  kernelNodeParams.gridDim = dim3(1, 1, 1);
-  kernelNodeParams.blockDim = dim3(THREADS_PER_BLOCK, 1, 1);
-  kernelNodeParams.sharedMemBytes = 0;
-  void *kernelArgs2[3] = {(void *)&outputVec_d, (void *)&result_d,
-                          &numOfBlocks};
-  kernelNodeParams.kernelParams = kernelArgs2;
-  kernelNodeParams.extra = NULL;
-
-  HIPCHECK(
-      hipGraphAddKernelNode(&kernelNode, graph, nodeDependencies.data(),
-                             nodeDependencies.size(), &kernelNodeParams));
-  nodeDependencies.clear();
-  nodeDependencies.push_back(kernelNode);
-
-  memset(&memcpyParams, 0, sizeof(memcpyParams));
-
-  memcpyParams.srcArray = NULL;
-  memcpyParams.srcPos = make_hipPos(0, 0, 0);
-  memcpyParams.srcPtr = make_hipPitchedPtr(result_d, sizeof(double), 1, 1);
-  memcpyParams.dstArray = NULL;
-  memcpyParams.dstPos = make_hipPos(0, 0, 0);
-  memcpyParams.dstPtr = make_hipPitchedPtr(&result_h, sizeof(double), 1, 1);
-  memcpyParams.extent = make_hipExtent(sizeof(double), 1, 1);
-  memcpyParams.kind = hipMemcpyDeviceToHost;
-  HIPCHECK(
-      hipGraphAddMemcpyNode(&memcpyNode, graph, nodeDependencies.data(),
-                             nodeDependencies.size(), &memcpyParams));
-  nodeDependencies.clear();
-  nodeDependencies.push_back(memcpyNode);
-
-  hipGraphNode_t hostNode;
-  hipHostNodeParams hostParams = {0};
-  hostParams.fn = myHostNodeCallback;
-  callBackData_t hostFnData;
-  hostFnData.data = &result_h;
-  hostFnData.fn_name = "cudaGraphsManual";
-  hostParams.userData = &hostFnData;
-
-  HIPCHECK(hipGraphAddHostNode(&hostNode, graph,
-                                       nodeDependencies.data(),
-                                       nodeDependencies.size(), &hostParams));
-
-  hipGraphNode_t *nodes = NULL;
-  size_t numNodes = 0;
-  HIPCHECK(hipGraphGetNodes(graph, nodes, &numNodes));
-  printf("\nNum of nodes in the graph created manually = %zu\n", numNodes);
-
-  hipGraphExec_t graphExec;
-  HIPCHECK(hipGraphInstantiate(&graphExec, graph, NULL, NULL, 0));
-
-  hipGraph_t clonedGraph;
-  hipGraphExec_t clonedGraphExec;
-  HIPCHECK(hipGraphClone(&clonedGraph, graph));
-  HIPCHECK(
-      hipGraphInstantiate(&clonedGraphExec, clonedGraph, NULL, NULL, 0));
-
-  for (int i = 0; i < GRAPH_LAUNCH_ITERATIONS; i++) {
-    HIPCHECK(hipGraphLaunch(graphExec, streamForGraph));
-  }
-
-  HIPCHECK(hipStreamSynchronize(streamForGraph));
-
-  printf("Cloned Graph Output.. \n");
-  for (int i = 0; i < GRAPH_LAUNCH_ITERATIONS; i++) {
-    HIPCHECK(hipGraphLaunch(clonedGraphExec, streamForGraph));
-  }
-  HIPCHECK(hipStreamSynchronize(streamForGraph));
-
-  HIPCHECK(hipGraphExecDestroy(graphExec));
-  HIPCHECK(hipGraphExecDestroy(clonedGraphExec));
-  HIPCHECK(hipGraphDestroy(graph));
-  HIPCHECK(hipGraphDestroy(clonedGraph));
-  HIPCHECK(hipStreamDestroy(streamForGraph));
-}
-
-void cudaGraphsUsingStreamCapture(float *inputVec_h, float *inputVec_d,
-                                  double *outputVec_d, double *result_d,
-                                  size_t inputSize, size_t numOfBlocks) {
-  hipStream_t stream1, stream2, stream3, streamForGraph;
-  hipEvent_t forkStreamEvent, memsetEvent1, memsetEvent2;
-  hipGraph_t graph;
-  double result_h = 0.0;
-
-  HIPCHECK(hipStreamCreate(&stream1));
-  HIPCHECK(hipStreamCreate(&stream2));
-  HIPCHECK(hipStreamCreate(&stream3));
-  HIPCHECK(hipStreamCreate(&streamForGraph));
-
-  HIPCHECK(hipEventCreate(&forkStreamEvent));
-  HIPCHECK(hipEventCreate(&memsetEvent1));
-  HIPCHECK(hipEventCreate(&memsetEvent2));
-
-  HIPCHECK(hipStreamBeginCapture(stream1, hipStreamCaptureModeGlobal));
-
-  HIPCHECK(hipEventRecord(forkStreamEvent, stream1));
-  HIPCHECK(hipStreamWaitEvent(stream2, forkStreamEvent, 0));
-  HIPCHECK(hipStreamWaitEvent(stream3, forkStreamEvent, 0));
-
-  HIPCHECK(hipMemcpyAsync(inputVec_d, inputVec_h,
-                                  sizeof(float) * inputSize, hipMemcpyDefault,
-                                  stream1));
-
-  HIPCHECK(
-      hipMemsetAsync(outputVec_d, 0, sizeof(double) * numOfBlocks, stream2));
-
-  HIPCHECK(hipEventRecord(memsetEvent1, stream2));
-
-  HIPCHECK(hipMemsetAsync(result_d, 0, sizeof(double), stream3));
-  HIPCHECK(hipEventRecord(memsetEvent2, stream3));
-
-  HIPCHECK(hipStreamWaitEvent(stream1, memsetEvent1, 0));
-
-  reduce<<<numOfBlocks, THREADS_PER_BLOCK, 0, stream1>>>(
-      inputVec_d, outputVec_d, inputSize, numOfBlocks);
-
-  HIPCHECK(hipStreamWaitEvent(stream1, memsetEvent2, 0));
-
-  reduceFinal<<<1, THREADS_PER_BLOCK, 0, stream1>>>(outputVec_d, result_d,
-                                                    numOfBlocks);
-  HIPCHECK(hipMemcpyAsync(&result_h, result_d, sizeof(double),
-                                  hipMemcpyDefault, stream1));
-
-  callBackData_t hostFnData = {0};
-  hostFnData.data = &result_h;
-  hostFnData.fn_name = "cudaGraphsUsingStreamCapture";
-  hipHostFn_t fn = myHostNodeCallback;
-  HIPCHECK(hipLaunchHostFunc(stream1, fn, &hostFnData));
-  HIPCHECK(hipStreamEndCapture(stream1, &graph));
-
-  hipGraphNode_t *nodes = NULL;
-  size_t numNodes = 0;
-  HIPCHECK(hipGraphGetNodes(graph, nodes, &numNodes));
-  printf("\nNum of nodes in the graph created using stream capture API = %zu\n",
-         numNodes);
-
-  hipGraphExec_t graphExec;
-  HIPCHECK(hipGraphInstantiate(&graphExec, graph, NULL, NULL, 0));
-
-  hipGraph_t clonedGraph;
-  hipGraphExec_t clonedGraphExec;
-  HIPCHECK(hipGraphClone(&clonedGraph, graph));
-  HIPCHECK(
-      hipGraphInstantiate(&clonedGraphExec, clonedGraph, NULL, NULL, 0));
-
-  for (int i = 0; i < GRAPH_LAUNCH_ITERATIONS; i++) {
-    HIPCHECK(hipGraphLaunch(graphExec, streamForGraph));
-  }
-
-  HIPCHECK(hipStreamSynchronize(streamForGraph));
-
-  printf("Cloned Graph Output.. \n");
-  for (int i = 0; i < GRAPH_LAUNCH_ITERATIONS; i++) {
-    HIPCHECK(hipGraphLaunch(clonedGraphExec, streamForGraph));
-  }
-
-  HIPCHECK(hipStreamSynchronize(streamForGraph));
-
-  HIPCHECK(hipGraphExecDestroy(graphExec));
-  HIPCHECK(hipGraphExecDestroy(clonedGraphExec));
-  HIPCHECK(hipGraphDestroy(graph));
-  HIPCHECK(hipGraphDestroy(clonedGraph));
-  HIPCHECK(hipStreamDestroy(stream1));
-  HIPCHECK(hipStreamDestroy(stream2));
-  HIPCHECK(hipStreamDestroy(streamForGraph));
-}
-
-int main(int argc, char **argv) {
-  size_t size = 1 << 24;  // number of elements to reduce
-  size_t maxBlocks = 512;
-
-  // This will pick the best possible CUDA capable device
-  int devID = findCudaDevice(argc, (const char **)argv);
-
-  printf("%zu elements\n", size);
-  printf("threads per block  = %d\n", THREADS_PER_BLOCK);
-  printf("Graph Launch iterations = %d\n", GRAPH_LAUNCH_ITERATIONS);
-
-  float *inputVec_d = NULL, *inputVec_h = NULL;
-  double *outputVec_d = NULL, *result_d;
-
-  HIPCHECK(hipHostMalloc(&inputVec_h, sizeof(float) * size));
-  HIPCHECK(hipMalloc(&inputVec_d, sizeof(float) * size));
-  HIPCHECK(hipMalloc(&outputVec_d, sizeof(double) * maxBlocks));
-  HIPCHECK(hipMalloc(&result_d, sizeof(double)));
-
-  init_input(inputVec_h, size);
-
-  cudaGraphsManual(inputVec_h, inputVec_d, outputVec_d, result_d, size,
-                   maxBlocks);
-  cudaGraphsUsingStreamCapture(inputVec_h, inputVec_d, outputVec_d, result_d,
-                               size, maxBlocks);
-
-  HIPCHECK(hipFree(inputVec_d));
-  HIPCHECK(hipFree(outputVec_d));
-  HIPCHECK(hipFree(result_d));
-  HIPCHECK(hipHostFree(inputVec_h));
-  return EXIT_SUCCESS;
-}
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.out b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2017.sln b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2019.sln b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2022.sln b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/simpleCudaGraphs/simpleCudaGraphs_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/Makefile b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/README.md b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm.cu b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm.cu.hip b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm.cu.hip
old mode 100644
new mode 100755
index 4d8576d..e69de29
--- a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm.cu.hip
@@ -1,840 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// CUDA sample demonstrating a tf32 (E8M10) GEMM computation using the Warp Matrix Multiply
-// and Accumulate API introduced in CUDA 11.0.
-
-// In this program, the compute_gemm kernel computes the result of a matrix multiplication
-// and addition: D = alpha * A * B + beta * C. The dimensions of both C and D matrices
-// are M_GLOBAL x N_GLOBAL. The A matrix is M_GLOBAL x K_GLOBAL (row-major), the B matrix
-// is K_GLOBAL x N_GLOBAL (column-major).
-// In that kernel, each CTA computes one 128 x 128 tile of the resulting matrix
-// per iteration. When the tile is computed, the CTA stores it to the global memory
-// and begins a new iteration, selecting a new 128 x 128 tile to compute.
-// Each CTA consists of eight warps. For the 128 x 128 tile, each warp computes eight
-// 16 x 16 subtiles, organized in a 2 x 4 two-dimensional array.
-// Warps compute the 16 x 16 subtiles using nvcuda::wmma::mma_sync operations by
-// moving through the K_GLOBAL dimension of the A and B matrices and accumulating
-// the intermediate result in the local thread state.
-
-// There are a number of simple optimizations used in the algorithm:
-// - The CTA copies the 128 x 128 tile of the C matrix from the global memory to
-//   shared memory. After that is done, each warp loads the C matrix fragments from
-//   shared memory, thus avoiding a random global memory access.
-// - On each internal iteration, the CTA copies a portion of the A and B matrices from
-//   global memory to shared memory. After that, all warps in the CTA reuse the A and B
-//   data from shared memory, thus reducing the number of data copies from global memory.
-// - The portions of the A and B matrices are stored in shared memory with an additional
-//   padding (skew) to reduce the number of shared memory access bank conflicts.
-//   (See a detailed explanation near the SKEW_FLOAT macro definition.)
-// - When the CTA finishes computing the tiles of the resulting matrix, each warp stores
-//   its subtiles to shared memory. The CTA then copies the shared memory contents to
-//   global memory, again avoiding redundant random global memory accesses.
-// - Note that the CTA tile size is chosen to maximize the GPU register utilization,
-//   but carefully enough to avoid local memory use.
-
-#include <assert.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <hip/hip_runtime.h>
-#include <mma.h>
-#include <cuda/pipeline>
-
-// helper functions and utilities to work with CUDA
-#include <helper_functions.h>
-#include <helper_cuda.h>
-#include "HIPCHECK.h"
-// Externally configurable parameters.
-
-#ifndef CPU_DEBUG
-// Set this to 1 to verify the correctness of the GPU-computed matrix.
-#define CPU_DEBUG 0
-#endif
-
-#ifndef SHARED_MEMORY_LIMIT_64K
-// Set this to 0 to use more than 64 Kb of shared memory to cache data, to
-// improve the performance of the computations on GPU.
-// Note that you need a GPU that can have more than 64 Kb of shared memory
-// per multiprocessor.
-#define SHARED_MEMORY_LIMIT_64K 0
-#endif
-
-// GPU configuration.
-
-#define WARP_SIZE 32
-
-// MMA matrix tile dimensions.
-
-#define M 16
-#define N 16
-#define K 8
-
-// GEMM configuration.
-
-#define M_TILES 512
-#define N_TILES 512
-#define K_TILES 512
-
-#define M_GLOBAL (M * M_TILES)
-#define N_GLOBAL (N * N_TILES)
-#define K_GLOBAL (K * K_TILES)
-
-#define C_LAYOUT wmma::mem_row_major
-
-// Implementation constants.
-
-#define WARPS_PER_BLOCK 8
-#define THREADS_PER_BLOCK (WARP_SIZE * WARPS_PER_BLOCK)
-
-#if SHARED_MEMORY_LIMIT_64K
-// With only 64 Kb shared memory available, we can fit two 8-tile chunks of
-// the A and B matrix data, that is (M = 16) * (K = 8) * 8 * (CHUNK_K = 8)
-// * sizeof(float) = 32 Kb each.
-// (i.e. two 8x8 arrays of tiles of 16x8 float-typed elements per CTA).
-// But we cannot account the 8 Kb total skew overhead, without which the performance
-// would be severely impacted. So we choose to reduce the chunk size in half,
-// i.e. the amount of A and B matrix data we cache in shared memory.
-// Accordingly, this doubles the number of outer iterations across the global K
-// dimension, which only slightly impacts the performance.
-#define CHUNK_K 4
-#else
-#define CHUNK_K 8
-#endif
-
-#define CHUNK_LINE_BYTES (CHUNK_K * K * sizeof(float))
-#define WARP_COPY_BYTES (WARP_SIZE * sizeof(int4))
-#define CHUNK_COPY_LINES_PER_WARP (WARP_COPY_BYTES / CHUNK_LINE_BYTES)
-#define CHUNK_COPY_LINE_LANES (WARP_SIZE / CHUNK_COPY_LINES_PER_WARP)
-
-#define BLOCK_ROW_WARPS 2
-#define BLOCK_COL_WARPS 4
-
-#define WARP_ROW_TILES 4
-#define WARP_COL_TILES 2
-
-#define BLOCK_ROW_TILES (WARP_ROW_TILES * BLOCK_ROW_WARPS)
-#define BLOCK_COL_TILES (WARP_COL_TILES * BLOCK_COL_WARPS)
-
-#define GLOBAL_MEM_STRIDE N_GLOBAL
-
-#define SHMEM_STRIDE (N * BLOCK_ROW_TILES)
-#define SHMEM_OFFSET (N * WARP_ROW_TILES)
-
-// The macro below is used to shift rows of the A matrix and columns of the B matrix
-// in shared memory to minimize possible bank conflicts.
-// Before performing the nvcuda::wmma::mma_sync operation, the warp must load the matrix
-// data using the nvcuda::wmma::load_matrix_sync operation. Although the memory access pattern
-// is not specified for that function, each lane in the warp can read one or multiple matrix
-// elements from different matrix rows or columns.
-// For shared memory, such access can result in bank conflicts if different rows / columns
-// of the matrix map to the same bank. By shifting each row and column by a few bytes, we
-// make sure that they map to different banks, thus reducing the number of possible bank
-// conflicts.
-// The number of 8 four-byte "float" elements is chosen as the minimum possible shift because
-// we must keep each row and column 256-bit aligned, as required by nvcuda::wmma::load_matrix_sync.
-#define SKEW_FLOAT 8
-
-#define checkKernelErrors(expr) do {                                                        \
-    expr;                                                                                   \
-                                                                                            \
-    hipError_t __err = hipGetLastError();                                                 \
-    if (__err != hipSuccess) {                                                             \
-        printf("Line %d: '%s' failed: %s\n", __LINE__, # expr, hipGetErrorString(__err));  \
-        abort();                                                                            \
-    }                                                                                       \
-} while(0)
-
-enum kernels
-{
-    tf32mma_shmem_gemm_async_copy  = 0, // tf32 MMA shmem using kernel with async_copy 
-    tf32mma_shmem_gemm             = 1, // tf32 MMA shmem using kernel normal copy (without async_copy).
-    simple_tf32mma_gemm            = 2  // tf32 MMA non-shmem using simple kernel.
-};
-
-const char* kernelNames[] = {"compute_tf32gemm_async_copy", "compute_tf32gemm", 
-                            "simple_wmma_tf32gemm"};
-
-using namespace nvcuda;
-
-__host__ void init_host_matrices(float *a, float *b, float *c)
-{
-    for (int i = 0; i < M_GLOBAL; i++) {
-        for (int j = 0; j < K_GLOBAL; j++) {
-            a[i*K_GLOBAL+j] = (float)(rand() % 3);
-        }
-    }
-
-    for (int i = 0; i < N_GLOBAL; i++) {
-        for (int j = 0; j < K_GLOBAL; j++) {
-            b[i*K_GLOBAL+j] = (float)(rand() % 3);
-        }
-    }
-
-    for (int t = 0; t < M_GLOBAL * N_GLOBAL; t++) {
-        c[t] =  (float)(rand() % 3);
-    }
-}
-
-__global__ void compute_tf32gemm(const float *A, const float *B, const float *C, float *D, float alpha, float beta)
-{
-#if __CUDA_ARCH__ >= 800
-    extern __shared__ float shmem[][CHUNK_K * K + SKEW_FLOAT];
-
-    // Warp and lane identification.
-    const unsigned int warpId = threadIdx.x / WARP_SIZE;
-    const unsigned int laneId = threadIdx.x % WARP_SIZE;
-
-    // Offset in shared memory from which the B matrix is stored.
-    const size_t shmem_idx_b_off = BLOCK_COL_TILES * M;
-
-    // This pointer is used to access the C and D matrix tiles this warp computes.
-    float *shmem_warp_tile_ptr = (float*)&shmem[0][0] + (warpId / BLOCK_ROW_WARPS) * SHMEM_STRIDE * N * BLOCK_ROW_WARPS + (warpId % BLOCK_ROW_WARPS) * SHMEM_OFFSET;
-
-    // This pointer is used to stream the C and D matrices block-wide tile to and from shared memory.
-    float *shmem_warp_stream_ptr = (float*)&shmem[0][0] + warpId * SHMEM_STRIDE * N;
-
-    // Adjust the beta scaler, as it'll be multiplied by alpha at the end of
-    // each tile computation. Technically this is not generally correct (may result
-    // in a loss of precision). Zero still needs to be specially handled though.
-    beta /= alpha;
-
-    // Each CTA slides along the 128 x 128 tiles from the top left corner of the matrix to the
-    // right and down, and selects the next tile to compute. Once there's no such tile,
-    // all warps in this CTA exit.
-    for(unsigned int block_pos = blockIdx.x;; block_pos += gridDim.x) {
-        const unsigned int block_tile_i = ((block_pos * BLOCK_ROW_TILES) / N_TILES) * (BLOCK_COL_TILES);
-        const unsigned int block_tile_j = (block_pos * BLOCK_COL_TILES) % N_TILES;
-
-        // Stop when there are no more D matrix tiles to compute in this CTA.
-        if (block_tile_i >= M_TILES) {
-            break;
-        }
-
-        // This warp's pointer to the C matrix data to copy memory from to shared memory.
-        const size_t gmem_idx = (block_tile_i + warpId) * M * GLOBAL_MEM_STRIDE + block_tile_j * N;
-        const float *src_gmem_warp_stream_ptr = &C[gmem_idx];
-
-        // Stream multiple C tiles to shared memory.
-#pragma unroll
-        for (int i = 0; i < N; i++) {
-            *((int4*)(shmem_warp_stream_ptr + SHMEM_STRIDE * i) + laneId) = 
-                *((int4*)(src_gmem_warp_stream_ptr + GLOBAL_MEM_STRIDE * i) + laneId);
-        }
-
-        __syncthreads();
-
-        // These fragments will accumulate the result of A and B matrix fragment multiplications
-        // along the K_GLOBAL dimension.
-        wmma::fragment<wmma::accumulator, M, N, K, float> c[WARP_COL_TILES][WARP_ROW_TILES];
-
-        // Load the C matrix tiles into fragments from shared memory.
-#pragma unroll
-        for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-            for (int j = 0; j < WARP_ROW_TILES; j++) {
-                const float *tile_ptr = shmem_warp_tile_ptr + i * SHMEM_STRIDE * N + j * N;
-
-                wmma::load_matrix_sync(c[i][j], tile_ptr, SHMEM_STRIDE, C_LAYOUT);
-            }
-        }
-
-        __syncthreads();
-
-        // Scale the C matrix.
-#pragma unroll
-       for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-            for (int j = 0; j < WARP_ROW_TILES; j++) {
-#pragma unroll
-                for (int t = 0; t < c[i][j].num_elements; t++) {
-                    c[i][j].x[t] *= beta;
-                }
-            }
-        }
-
-        // Select what warp copies what matrix to shared memory.
-        // Warps 0-3 copy the A matrix, warps 4-7 copy the B matrix.
-        const float *warp_ptr = (warpId < (WARPS_PER_BLOCK/2)) ? (&A[block_tile_i * M * K_GLOBAL] + M * K_GLOBAL * (warpId % (WARPS_PER_BLOCK/2)) * 2) :
-                                              (&B[block_tile_j * N * K_GLOBAL] + N * K_GLOBAL * (warpId % (WARPS_PER_BLOCK/2)) * 2);
-
-        // Go through the global K dimension by a fixed step at a time.
-#pragma unroll
-        for (int tile_k = 0; tile_k < K_TILES; tile_k += CHUNK_K) {
-            // Copy slices of the A and B matrices to shared memory.
-            // The first half of the warps in the CTA copy the A matrix, the rest copy the B matrix.
-            size_t shmem_idx = warpId < (WARPS_PER_BLOCK/2) ? (M * (warpId % (WARPS_PER_BLOCK/2)) * 2) : 
-                                                              (N * (warpId % (WARPS_PER_BLOCK/2)) * 2 + shmem_idx_b_off);
-
-            // First half of the warp copies the first row / column of the matrix,
-            // the second half of the warp copies the next.
-            const float *lane_ptr = (warp_ptr + tile_k * K + (laneId / CHUNK_COPY_LINE_LANES) * K_GLOBAL);
-
-            // Shift the second half of the warp to the next row / column in the shared memory.
-            shmem_idx += laneId / CHUNK_COPY_LINE_LANES;
-
-#pragma unroll
-            for(int i = 0; i < ((WARP_SIZE/2) / CHUNK_COPY_LINES_PER_WARP) * 2; i++) {
-                // Copy 16 bytes at once in each lane.
-                *((int4*)&shmem[shmem_idx][0] + (laneId % CHUNK_COPY_LINE_LANES)) = *((int4*)lane_ptr +  (laneId % CHUNK_COPY_LINE_LANES));
-
-                // Advance the global memory pointer and the shared memory index.
-                lane_ptr = lane_ptr + K_GLOBAL * CHUNK_COPY_LINES_PER_WARP;
-                shmem_idx += CHUNK_COPY_LINES_PER_WARP;
-            }
-
-            __syncthreads();
-
-            // Compute a grid of C matrix tiles in each warp.
-#pragma unroll
-            for (int k_step = 0; k_step < CHUNK_K; k_step++) {
-                wmma::fragment<wmma::matrix_a, M, N, K, wmma::precision::tf32, wmma::row_major> a[WARP_COL_TILES];
-                wmma::fragment<wmma::matrix_b, M, N, K, wmma::precision::tf32, wmma::col_major> b[WARP_ROW_TILES];
-
-#pragma unroll
-                for (int i = 0; i < WARP_COL_TILES; i++) {
-                    size_t shmem_idx_a = (warpId/BLOCK_ROW_WARPS) * M * BLOCK_ROW_WARPS + (i * M);
-                    const float *tile_ptr = &shmem[shmem_idx_a][k_step * K];
-
-                    wmma::load_matrix_sync(a[i], tile_ptr, K * CHUNK_K + SKEW_FLOAT);
-#pragma unroll
-                    for (int t = 0; t < a[i].num_elements; t++) {
-                        a[i].x[t] = wmma::__float_to_tf32(a[i].x[t]);
-                    }
-#pragma unroll
-                    for (int j = 0; j < WARP_ROW_TILES; j++) {
-                        if (i == 0) {
-                            // Load the B matrix fragment once, because it is going to be reused
-                            // against the other A matrix fragments.
-                            size_t shmem_idx_b = shmem_idx_b_off + (WARP_ROW_TILES * N) * (warpId%2) + (j * N);
-                            const float *tile_ptr = &shmem[shmem_idx_b][k_step * K];
-
-                            wmma::load_matrix_sync(b[j], tile_ptr, K * CHUNK_K + SKEW_FLOAT);
-#pragma unroll
-                            for (int t = 0; t < b[j].num_elements; t++) {
-                                b[j].x[t] = wmma::__float_to_tf32(b[j].x[t]);
-                            }
-                        }
-
-                        wmma::mma_sync(c[i][j], a[i], b[j], c[i][j]);
-                    }
-                }
-            }
-
-            __syncthreads();
-        }
-
-        // Store the D fragments to shared memory.
-#pragma unroll
-        for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-            for (int j = 0; j < WARP_ROW_TILES; j++) {
-#pragma unroll
-                // Uniform, point-wise transformations of ALL fragment elements by ALL threads in the
-                // warp are well-defined even though element indices within fragment storage are not defined.
-                for (int t = 0; t < c[i][j].num_elements; t++)
-                    c[i][j].x[t] *= alpha;
-
-                float *tile_ptr = shmem_warp_tile_ptr + i * SHMEM_STRIDE * N + j * N;
-
-                wmma::store_matrix_sync(tile_ptr, c[i][j], SHMEM_STRIDE, C_LAYOUT);
-            }
-        }
-
-        __syncthreads();
-
-        // Now that shared memory contains all the D tiles, stream them to global memory.
-        float *dst_gmem_warp_stream_ptr = &D[gmem_idx];
-
-#pragma unroll
-        for (int i = 0; i < N; i++) {
-            *((int4*)(dst_gmem_warp_stream_ptr + GLOBAL_MEM_STRIDE * i) + laneId) =
-                *((int4*)(shmem_warp_stream_ptr + SHMEM_STRIDE * i) + laneId);
-        }
-
-        __syncthreads();
-    }
-#endif
-}
-
-__global__ void compute_tf32gemm_async_copy(const float *A, const float *B, const float *C, float *D, const float alpha, float beta)
-{
-#if __CUDA_ARCH__ >= 800
-    extern __shared__ float shmem[][CHUNK_K * K + SKEW_FLOAT];
-
-    // Warp and lane identification.
-    const unsigned int warpId = threadIdx.x / WARP_SIZE;
-    const unsigned int laneId = threadIdx.x % WARP_SIZE;
-
-    // This pointer is used to access the C and D matrix tiles this warp computes.
-    float *shmem_warp_tile_ptr = (float*)&shmem[0][0] + (warpId / BLOCK_ROW_WARPS) * SHMEM_STRIDE * N * BLOCK_ROW_WARPS + (warpId % BLOCK_ROW_WARPS) * SHMEM_OFFSET;
-
-    // This pointer is used to stream the C and D matrices block-wide tile to and from shared memory.
-    float *shmem_warp_stream_ptr = (float*)&shmem[0][0] + warpId * SHMEM_STRIDE * N;
-
-    // Offset in shared memory from which the B matrix is stored.
-    constexpr size_t shmem_idx_b_off = BLOCK_COL_TILES * M;
-
-    // Adjust the beta scaler, as it'll be multiplied by alpha at the end of
-    // each tile computation. Technically this is not generally correct (may result
-    // in a loss of precision). Zero still needs to be specially handled though.
-    beta /= alpha;
-
-    cuda::pipeline<cuda::thread_scope_thread> pipe = cuda::make_pipeline();
-    const auto shape4 = cuda::aligned_size_t<alignof(float4)>(sizeof(float4));
-    constexpr int loadStride = 2; // load 4 floats, so left-shift by 2.
-
-    // Each CTA slides along the 128 x 128 tiles from the top left corner of the matrix to the
-    // right and down, and selects the next tile to compute. Once there's no such tile,
-    // all warps in this CTA exit.
-    for(unsigned int block_pos = blockIdx.x;; block_pos += gridDim.x) {
-        const unsigned int block_tile_i = ((block_pos * BLOCK_ROW_TILES) / N_TILES) * (BLOCK_COL_TILES);
-        const unsigned int block_tile_j = (block_pos * BLOCK_COL_TILES) % N_TILES;
-
-        // Stop when there are no more D matrix tiles to compute in this CTA.
-        if (block_tile_i >= M_TILES) {
-            break;
-        }
-
-        // This warp's pointer to the C matrix data to copy memory from to shared memory.
-        const size_t gmem_idx = (block_tile_i + warpId) * M * GLOBAL_MEM_STRIDE + block_tile_j * N;
-        const float *src_gmem_warp_stream_ptr = &C[gmem_idx];
-
-        // Stream multiple C tiles to shared memory.
-#pragma unroll
-        for (int i = 0; i < N; i++) {
-            pipe.producer_acquire();
-            cuda::memcpy_async(&shmem_warp_stream_ptr[(SHMEM_STRIDE * i) + (laneId << loadStride)],
-                                &src_gmem_warp_stream_ptr[(GLOBAL_MEM_STRIDE * i) + (laneId << loadStride)],
-                                shape4, pipe);
-            pipe.producer_commit();
-        }
-        // Now wait for all the above issued 8 batches to complete.
-        cuda::pipeline_consumer_wait_prior<0>(pipe);
-        __syncthreads();
-
-        // These fragments will accumulate the result of A and B matrix fragment multiplications
-        // along the K_GLOBAL dimension.
-        wmma::fragment<wmma::accumulator, M, N, K, float> c[WARP_COL_TILES][WARP_ROW_TILES];
-
-        // Load the C matrix tiles into fragments from shared memory.
-#pragma unroll
-        for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-            for (int j = 0; j < WARP_ROW_TILES; j++) {
-                const float *tile_ptr = shmem_warp_tile_ptr + i * SHMEM_STRIDE * N + j * N;
-
-                wmma::load_matrix_sync(c[i][j], tile_ptr, SHMEM_STRIDE, C_LAYOUT);
-                // Scale the C matrix.
-#pragma unroll
-                for (int t = 0; t < c[i][j].num_elements; t++) {
-                    c[i][j].x[t] *= beta;
-                }
-            }
-        }
-        pipe.consumer_release();
-
-        // sync here so that shared memory can then be used for loading A & B matrices.
-        __syncthreads();
-
-        // Select what warp copies what matrix to shared memory.
-        // Warps 0-3 copy the A matrix, warps 4-7 copy the B matrix.
-        const float *warp_ptr = (warpId < (WARPS_PER_BLOCK/2)) ? (&A[block_tile_i * M * K_GLOBAL] + M * K_GLOBAL * (warpId % (WARPS_PER_BLOCK/2)) * 2) :
-                                              (&B[block_tile_j * N * K_GLOBAL] + N * K_GLOBAL * (warpId % (WARPS_PER_BLOCK/2)) * 2);
-
-        constexpr int chunksPerLane = ((WARP_SIZE/2) / CHUNK_COPY_LINES_PER_WARP) * 2;
-        const int laneLoadElem = (laneId % CHUNK_COPY_LINE_LANES) << loadStride;
-        const int stridePerLaneCopy = (laneId / CHUNK_COPY_LINE_LANES);
-        // Go through the global K dimension by a fixed step at a time.
-#pragma unroll
-        for (int tile_k = 0; tile_k < K_TILES; tile_k += CHUNK_K) {
-            // Copy slices of the A and B matrices to shared memory.
-            // The first half of the warps in the CTA copy the A matrix, the rest copy the B matrix.
-            // As for tf32 MMA  M == N we use M for warp 4-7 + shmem_idx_b_off.
-            size_t shmem_idx =  (M * (warpId % (WARPS_PER_BLOCK/2)) * 2)  + ((warpId / (WARPS_PER_BLOCK/2)) * shmem_idx_b_off);
-            // First half of the warp copies the first row / column of the matrix,
-            // the second half of the warp copies the next.
-            const float *lane_ptr = (warp_ptr + tile_k * K + stridePerLaneCopy * K_GLOBAL + laneLoadElem);
-
-            // Shift the second half of the warp to the next row / column in the shared memory.
-            shmem_idx += stridePerLaneCopy;
-
-#pragma unroll
-            for(int i = 0; i < chunksPerLane; i++) {
-                // Copy 16 bytes at once in each lane.
-                pipe.producer_acquire();
-                cuda::memcpy_async(&shmem[shmem_idx][laneLoadElem], lane_ptr, shape4, pipe);
-                pipe.producer_commit();
-
-                // Advance the global memory pointer and the shared memory index.
-                lane_ptr = lane_ptr + K_GLOBAL * CHUNK_COPY_LINES_PER_WARP;
-                shmem_idx += CHUNK_COPY_LINES_PER_WARP;
-            }
-
-            cuda::pipeline_consumer_wait_prior<0>(pipe);
-            __syncthreads();
-
-            // Compute a grid of C matrix tiles in each warp.
-#pragma unroll
-            for (int k_step = 0; k_step < CHUNK_K; k_step++) {
-                wmma::fragment<wmma::matrix_a, M, N, K, wmma::precision::tf32, wmma::row_major> a[WARP_COL_TILES];
-                wmma::fragment<wmma::matrix_b, M, N, K, wmma::precision::tf32, wmma::col_major> b[WARP_ROW_TILES];
-
-#pragma unroll
-                for (int i = 0; i < WARP_COL_TILES; i++) {
-                    size_t shmem_idx_a = (warpId / BLOCK_ROW_WARPS) * M * BLOCK_ROW_WARPS + (i * M);
-                    const float *tile_ptr = &shmem[shmem_idx_a][k_step * K];
-
-                    wmma::load_matrix_sync(a[i], tile_ptr, K * CHUNK_K + SKEW_FLOAT);
-
-#pragma unroll
-                    for (int t = 0; t < a[i].num_elements; t++) {
-                        a[i].x[t] = wmma::__float_to_tf32(a[i].x[t]);
-                    }
-#pragma unroll
-                    for (int j = 0; j < WARP_ROW_TILES; j++) {
-                        if (i == 0) {
-                            // Load the B matrix fragment once, because it is going to be reused
-                            // against the other A matrix fragments.
-                            size_t shmem_idx_b = shmem_idx_b_off + (WARP_ROW_TILES * N) * (warpId%2) + (j * N);
-                            const float *tile_ptr = &shmem[shmem_idx_b][k_step * K];
-
-                            wmma::load_matrix_sync(b[j], tile_ptr, K * CHUNK_K + SKEW_FLOAT);
-#pragma unroll
-                            for (int t = 0; t < b[j].num_elements; t++) {
-                                b[j].x[t] =  wmma::__float_to_tf32(b[j].x[t]);
-                            }
-                        }
-
-                        wmma::mma_sync(c[i][j], a[i], b[j], c[i][j]);
-                    }
-                }
-            }
-            pipe.consumer_release();
-            __syncthreads();
-        }
-
-        // Store the D fragments to shared memory.
-#pragma unroll
-        for (int i = 0; i < WARP_COL_TILES; i++) {
-#pragma unroll
-            for (int j = 0; j < WARP_ROW_TILES; j++) {
-#pragma unroll
-                // Uniform, point-wise transformations of ALL fragment elements by ALL threads in the
-                // warp are well-defined even though element indices within fragment storage are not defined.
-                for (int t = 0; t < c[i][j].num_elements; t++)
-                    c[i][j].x[t] *= alpha;
-
-                float *tile_ptr = shmem_warp_tile_ptr + i * SHMEM_STRIDE * N + j * N;
-
-                wmma::store_matrix_sync(tile_ptr, c[i][j], SHMEM_STRIDE, C_LAYOUT);
-            }
-        }
-
-        __syncthreads();
-
-        // Now that shared memory contains all the D tiles, stream them to global memory.
-        float *dst_gmem_warp_stream_ptr = &D[gmem_idx];
-
-#pragma unroll
-        for (int i = 0; i < N; i++) {
-            *((float4*)(dst_gmem_warp_stream_ptr + GLOBAL_MEM_STRIDE * i) + laneId) =
-                *((float4*)(shmem_warp_stream_ptr + SHMEM_STRIDE * i) + laneId);
-        }
-
-        __syncthreads();
-    }
-#endif
-}
-
-// Performs an MxNxK tf32 GEMM (C=alpha*A*B + beta*C) assuming:
-//  1) Matrices are packed in memory.
-//  2) M, N and K are multiples of 16, 16 and 8 respectively. 
-//  3) A is row major, B is column major matrix.
-// Note: This is a less performant version of the compute_tf32gemm kernel. It is designed for
-//       demonstration purposes only to show the CUDA WMMA API use without relying on
-//       availability of the shared memory.
-__global__ void simple_wmma_tf32gemm(float *a, float *b, float *c, float *d, int m_ld, int n_ld, int k_ld, float alpha, float beta)
-{
-#if __CUDA_ARCH__ >= 800
-   // Leading dimensions. Packed with no transpositions.
-    int lda = k_ld;
-    int ldb = k_ld;
-    int ldc = n_ld;
-
-   // Tile using a 2D grid
-   int warpM = (blockIdx.x * blockDim.x + threadIdx.x) / warpSize;
-   int warpN = (blockIdx.y * blockDim.y + threadIdx.y);
- 
-   // Declare the fragments
-   wmma::fragment<wmma::matrix_a, M, N, K, wmma::precision::tf32, wmma::row_major> a_frag;
-   wmma::fragment<wmma::matrix_b, M, N, K, wmma::precision::tf32, wmma::col_major> b_frag;
-   wmma::fragment<wmma::accumulator, M, N, K, float> acc_frag;
-   wmma::fragment<wmma::accumulator, M, N, K, float> c_frag;
-
-   wmma::fill_fragment(acc_frag, 0.0f);
-
-   // Loop over k
-   for (int i = 0; i < k_ld; i += K) {
-      int aCol = i; 
-      int aRow = warpM * M;
-
-      //int bCol = i;
-      //int bRow = warpN * N;
-      int bCol = warpN * N;
-      int bRow = i;
-
-      // Bounds checking
-      if (aRow < m_ld && aCol < k_ld && bRow < k_ld && bCol < n_ld) {
-         // Load the inputs
-         wmma::load_matrix_sync(a_frag, a + aCol + aRow * lda, lda);
-         wmma::load_matrix_sync(b_frag, b + bRow + bCol * ldb, ldb);
- 
- #pragma unroll
-        for (int t = 0; t < a_frag.num_elements; t++) {
-                a_frag.x[t] =  wmma::__float_to_tf32(a_frag.x[t]);
-        }
-
- #pragma unroll
-        for (int t = 0; t < b_frag.num_elements; t++) {
-                b_frag.x[t] =  wmma::__float_to_tf32(b_frag.x[t]);
-        }
-         // Perform the matrix multiplication
-         wmma::mma_sync(acc_frag, a_frag, b_frag, acc_frag);
-
-      }
-   }
-
-   // Load in the current value of c, scale it by beta, and add this our result scaled by alpha
-   int cCol = warpN * N;
-   int cRow = warpM * M;
-
-   if (cRow < m_ld && cCol < n_ld) {
-      wmma::load_matrix_sync(c_frag, c + cCol + cRow * ldc, ldc, wmma::mem_row_major);
-
-      for(int i=0; i < c_frag.num_elements; i++) {
-         c_frag.x[i] = alpha * acc_frag.x[i] + beta * c_frag.x[i];
-      }
-
-      // Store the output
-      wmma::store_matrix_sync(d + cCol + cRow * ldc, c_frag, ldc, wmma::mem_row_major);
-   }
-#endif
-}
-
-__host__ void matMultiplyOnHost(float *A, float *B, float *C,
-                                float alpha, float beta,
-                                int numARows, int numAColumns,
-                                int numBRows, int numBColumns,
-                                int numCRows, int numCColumns)
-{
-    for (int i = 0; i < numCRows; i++) {
-        for (int j = 0; j < numCColumns; j++) {
-            float temp = 0.0;
-
-            for (int k = 0; k < numAColumns; k++) {
-                temp += A[i * numAColumns + k] * B[j * numBRows + k];
-            }
-
-            C[i*numCColumns + j] = temp * alpha + beta * C[i * numCColumns + j];
-        }
-    }
-}
-
-int main(int argc, char **argv)
-{
-    printf("Initializing...\n");
-
-    int dev = findCudaDevice(argc, (const char **)argv);
-
-    hipDeviceProp_t deviceProp;
-    HIPCHECK(hipGetDeviceProperties(&deviceProp, dev));
-
-    // Tensor cores require a GPU of Volta (SM8X) architecture or higher.
-    if (deviceProp.major < 8) {
-        printf("tf32TensorCoreGemm requires requires SM 8.0 or higher to use Tensor Cores.  Exiting...\n");
-        exit(EXIT_WAIVED);
-    }
-
-    printf("M: %d (%d x %d)\n", M_GLOBAL, M, M_TILES);
-    printf("N: %d (%d x %d)\n", N_GLOBAL, N, N_TILES);
-    printf("K: %d (%d x %d)\n", K_GLOBAL, K, K_TILES);
-
-    float *A_h = NULL;
-    float *B_h = NULL;
-    float *C_h = NULL;
-#if CPU_DEBUG
-    float *result_hD = NULL;
-    float *result_host = NULL;
-#endif
-
-    A_h = (float*) malloc(sizeof(float) * M_GLOBAL * K_GLOBAL);
-    B_h = (float*) malloc(sizeof(float) * K_GLOBAL * N_GLOBAL);
-    C_h = (float*) malloc(sizeof(float) * M_GLOBAL * N_GLOBAL);
-#if CPU_DEBUG
-    result_hD   = (float*) malloc(sizeof(float) * M_GLOBAL * N_GLOBAL);
-    result_host = (float*) malloc(sizeof(float) * M_GLOBAL * N_GLOBAL);
-#endif
-
-    float *A = NULL;
-    float *B = NULL;
-    float *C = NULL;
-    float *D = NULL;
-
-    HIPCHECK(hipMalloc((void**)&A, sizeof(float) * M_GLOBAL * K_GLOBAL));
-    HIPCHECK(hipMalloc((void**)&B, sizeof(float) * N_GLOBAL * K_GLOBAL));
-    HIPCHECK(hipMalloc((void**)&C, sizeof(float) * M_GLOBAL * N_GLOBAL));
-    HIPCHECK(hipMalloc((void**)&D, sizeof(float) * M_GLOBAL * N_GLOBAL));
-
-    assert(((unsigned long long)A) % 128 == 0);
-    assert(((unsigned long long)B) % 128 == 0);
-    assert(((unsigned long long)C) % 128 == 0);
-    assert(((unsigned long long)D) % 128 == 0);
-
-    init_host_matrices(A_h, B_h, C_h);
-
-    printf("Preparing data for GPU...\n");
-
-    HIPCHECK(hipMemcpy(A, A_h, sizeof(float) * M_GLOBAL * K_GLOBAL, hipMemcpyHostToDevice));
-    HIPCHECK(hipMemcpy(B, B_h, sizeof(float) * N_GLOBAL * K_GLOBAL, hipMemcpyHostToDevice));
-    HIPCHECK(hipMemcpy(C, C_h, sizeof(float) * M_GLOBAL * N_GLOBAL, hipMemcpyHostToDevice));
-    HIPCHECK(hipMemset(D, 0, sizeof(float) * M_GLOBAL * N_GLOBAL));
-
-    enum {
-        // Compute the right amount of shared memory to request.
-        // We need shared memory to hold per-CTA C and D matrix tiles, and to cache per-CTA chunks
-        // of the A and B matrices. Therefore, the right amount to request is the maximum of those
-        // two numbers.
-        SHMEM_SZ = MAX(sizeof(float) * (BLOCK_COL_TILES * M) * (CHUNK_K * K + SKEW_FLOAT) * 2,
-                       M * (BLOCK_ROW_WARPS * WARP_ROW_TILES) * N * (BLOCK_COL_WARPS * WARP_COL_TILES) * sizeof(float))
-    };
-
-    printf("Required shared memory size: %lu Kb\n", SHMEM_SZ / 1024UL);
-
-    const float alpha = 1.1f;
-    const float beta = 1.2f;
-
-    hipEvent_t start, stop;
-
-    HIPCHECK(hipEventCreate(&start));    
-    HIPCHECK(hipEventCreate(&stop));
-    HIPCHECK(hipEventRecord(start));
-
-    // kernel to run - default (tf32mma_shmem_gemm_async_copy == 0)
-    kernels selected_kernel = tf32mma_shmem_gemm_async_copy;
-
-    if (checkCmdLineFlag(argc, (const char **)argv, "kernel")) {
-        int kernel_number = getCmdLineArgumentInt(argc, (const char **)argv, "kernel");
-        if (kernel_number < 3) {
-            selected_kernel = (kernels)kernel_number;
-        }
-        else {
-            printf("Error: kernel number should be between 0 to 2, you have entered %d\n", kernel_number);
-            exit(EXIT_FAILURE);
-        }
-    }
-
-    // If enough shared memory available on the GPU use high performant kernel
-    if ((deviceProp.sharedMemPerMultiprocessor >= SHMEM_SZ) && (selected_kernel != simple_tf32mma_gemm)) {
-        printf("Computing using high performance kernel = %d - %s\n", selected_kernel, kernelNames[selected_kernel]);
-
-        switch (selected_kernel)
-        {
-            case tf32mma_shmem_gemm_async_copy :
-            default:
-                HIPCHECK(hipFuncSetAttribute(compute_tf32gemm_async_copy, hipFuncAttributeMaxDynamicSharedMemorySize, SHMEM_SZ));
-                checkKernelErrors((compute_tf32gemm_async_copy<<<deviceProp.multiProcessorCount*2, THREADS_PER_BLOCK, SHMEM_SZ>>>(A, B, C, D, alpha, beta)));
-                break;
-            case tf32mma_shmem_gemm :
-                HIPCHECK(hipFuncSetAttribute(compute_tf32gemm, hipFuncAttributeMaxDynamicSharedMemorySize, SHMEM_SZ));
-                checkKernelErrors((compute_tf32gemm<<<deviceProp.multiProcessorCount*2, THREADS_PER_BLOCK, SHMEM_SZ>>>(A, B, C, D, alpha, beta)));
-                break;
-        }
-#if CPU_DEBUG
-        HIPCHECK(hipMemcpy(result_hD, D, sizeof(float)*M_GLOBAL*N_GLOBAL, hipMemcpyDeviceToHost));
-#endif
-    }
-    else {
-        dim3 gridDim;
-        dim3 blockDim;
-     
-        // blockDim.x must be a multple of warpSize
-        // 128x4 means we have 16 warps and a block computes a 64x64 output tile
-        blockDim.x = 128;
-        blockDim.y = 4;
-
-        gridDim.x = (M_GLOBAL + (M * blockDim.x / 32 - 1)) / (M * blockDim.x / 32);
-        gridDim.y = (N_GLOBAL + N * blockDim.y - 1) / (N * blockDim.y);
-
-        printf("Computing... using simple_wmma_gemm kernel\n");
-        simple_wmma_tf32gemm<<<gridDim, blockDim>>>(A, B, C, D, M_GLOBAL, N_GLOBAL, K_GLOBAL, alpha, beta);
-#if CPU_DEBUG
-        HIPCHECK(hipMemcpy(result_hD, D, sizeof(float) * M_GLOBAL * N_GLOBAL, hipMemcpyDeviceToHost));
-#endif
-    }
-
-    HIPCHECK(hipEventRecord(stop));
-    HIPCHECK(hipEventSynchronize(stop));
-
-#if CPU_DEBUG
-    printf("Verifying correctness of the computations...\n");
-
-    memcpy(result_host, C_h, sizeof(float) * M_GLOBAL * N_GLOBAL);
-
-    matMultiplyOnHost(A_h, B_h, result_host,
-                      alpha, beta,
-                      M_GLOBAL, K_GLOBAL,
-                      K_GLOBAL, N_GLOBAL,
-                      M_GLOBAL, N_GLOBAL);
-
-    for (int i = 0; i < N_GLOBAL * M_GLOBAL; i++) {
-        if (fabs(result_hD[i] - result_host[i]) > 0.1f) {
-            printf("mismatch i=%d result_hD=%f result_host=%f\n", i, result_hD[i], result_host[i]);
-        }
-    }
-    free(result_hD);
-    free(result_host);
-#endif
-
-    float milliseconds = 0;
-
-    HIPCHECK(hipEventElapsedTime(&milliseconds, start, stop));
-
-    printf("Time: %f ms\n", milliseconds);
-    printf("TFLOPS: %.2f\n", (((double)M_GLOBAL * N_GLOBAL * K_GLOBAL * 2)/(milliseconds/1000.)) / 1e12);
-
-    free(A_h);
-    free(B_h);
-    free(C_h);
-    HIPCHECK(hipFree((void*)A));
-    HIPCHECK(hipFree((void*)B));
-    HIPCHECK(hipFree((void*)C));
-    HIPCHECK(hipFree((void*)D));
-
-    return 0;
-}
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2017.sln b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2019.sln b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2022.sln b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/tf32TensorCoreGemm/tf32TensorCoreGemm_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/.vscode/c_cpp_properties.json b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/.vscode/extensions.json b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/.vscode/launch.json b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/.vscode/tasks.json b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/Makefile b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/NsightEclipse.xml b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/README.md b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG.cu b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG.cu.hip b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG.cu.hip
old mode 100644
new mode 100755
index 65bc015..aec13fa
--- a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG.cu.hip
+++ b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG.cu.hip
@@ -27,11 +27,9 @@
  */
 
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 // includes, project
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"
+#include <helper_cuda.h>
+#include <helper_functions.h>
 
 #include <hip/hip_runtime.h>
 
@@ -199,7 +197,7 @@ int calculateMaxInBuckets(int *h_srcArr, int *d_srcArr, int numOfBuckets)
 
   memset(cpuBucketsMax, 0, sizeof(int) * numOfBuckets);
 
-  // Here we create values which is assumed to correspond to each 
+  // Here we create values which is assumed to correspond to each
   // buckets of srcArr at same array index.
   for (int i=0; i < NUM_ELEMS; i++)
   {
@@ -240,7 +238,7 @@ int calculateMaxInBuckets(int *h_srcArr, int *d_srcArr, int numOfBuckets)
   }
   if (allMatch)
   {
-    printf("CPU max matches GPU max\n"); 
+    printf("CPU max matches GPU max\n");
   }
 
   delete[] h_valueInBuckets;
@@ -318,12 +316,12 @@ int main(int argc, char **argv) {
   }
 
   printf("\nWarp Aggregated Atomics %s \n",
-         (host_flt_count == nres) && (mapIndicesToBucketsStatus == EXIT_SUCCESS) && 
+         (host_flt_count == nres) && (mapIndicesToBucketsStatus == EXIT_SUCCESS) &&
          (calculateMaxInBucketsStatus == EXIT_SUCCESS) ? "PASSED" : "FAILED");
 
-  HIPCHECK(hipFree(d_data_to_filter));
-  HIPCHECK(hipFree(d_filtered_data));
-  HIPCHECK(hipFree(d_nres));
+  checkCudaErrors(hipFree(d_data_to_filter));
+  checkCudaErrors(hipFree(d_filtered_data));
+  checkCudaErrors(hipFree(d_nres));
   free(data_to_filter);
   free(filtered_data);
   free(host_filtered_data);
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2017.sln b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2017.vcxproj b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2019.sln b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2019.vcxproj b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2022.sln b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2022.vcxproj b/src/samples/Samples/3_CUDA_Features/warpAggregatedAtomicsCG/warpAggregatedAtomicsCG_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP.cpp b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/FilterBorderControlNPP_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/Makefile b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/README.md b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/data/teapot512.pgm b/src/samples/Samples/4_CUDA_Libraries/FilterBorderControlNPP/data/teapot512.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/Makefile b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwister.cpp b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwister.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwisterGP11213_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwister_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/MersenneTwister_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/README.md b/src/samples/Samples/4_CUDA_Libraries/MersenneTwisterGP11213/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/README.md b/src/samples/Samples/4_CUDA_Libraries/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/Makefile b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/README.md b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS.cpp b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS.h b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_hipified.h b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/batchCUBLAS/batchCUBLAS_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/CT_skull_CompressedMarkerLabelsUFBatch_8Way_512x512_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/CT_skull_CompressedMarkerLabelsUFBatch_8Way_512x512_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/CT_skull_CompressedMarkerLabelsUF_8Way_512x512_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/CT_skull_CompressedMarkerLabelsUF_8Way_512x512_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/CT_skull_LabelMarkersUFBatch_8Way_512x512_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/CT_skull_LabelMarkersUFBatch_8Way_512x512_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/CT_skull_LabelMarkersUF_8Way_512x512_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/CT_skull_LabelMarkersUF_8Way_512x512_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/Makefile b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB2_CompressedMarkerLabelsUFBatch_8Way_1024x683_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB2_CompressedMarkerLabelsUFBatch_8Way_1024x683_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB2_CompressedMarkerLabelsUF_8Way_1024x683_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB2_CompressedMarkerLabelsUF_8Way_1024x683_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB2_LabelMarkersUFBatch_8Way_1024x683_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB2_LabelMarkersUFBatch_8Way_1024x683_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB2_LabelMarkersUF_8Way_1024x683_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB2_LabelMarkersUF_8Way_1024x683_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_CompressedMarkerLabelsUFBatch_8Way_1280x720_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_CompressedMarkerLabelsUFBatch_8Way_1280x720_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_CompressedMarkerLabelsUF_8Way_1280x720_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_CompressedMarkerLabelsUF_8Way_1280x720_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_LabelMarkersUFBatch_8Way_1280x720_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_LabelMarkersUFBatch_8Way_1280x720_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_LabelMarkersUF_8Way_1280x720_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_LabelMarkersUF_8Way_1280x720_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_METAL_CompressedMarkerLabelsUFBatch_8Way_509x335_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_METAL_CompressedMarkerLabelsUFBatch_8Way_509x335_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_METAL_CompressedMarkerLabelsUF_8Way_509x335_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_METAL_CompressedMarkerLabelsUF_8Way_509x335_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_METAL_LabelMarkersUFBatch_8Way_509x335_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_METAL_LabelMarkersUFBatch_8Way_509x335_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_METAL_LabelMarkersUF_8Way_509x335_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/PCB_METAL_LabelMarkersUF_8Way_509x335_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/README.md b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP.cpp b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/batchedLabelMarkersAndLabelCompressionNPP_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/teapot_CompressedMarkerLabelsUFBatch_8Way_512x512_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/teapot_CompressedMarkerLabelsUFBatch_8Way_512x512_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/teapot_CompressedMarkerLabelsUF_8Way_512x512_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/teapot_CompressedMarkerLabelsUF_8Way_512x512_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/teapot_LabelMarkersUFBatch_8Way_512x512_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/teapot_LabelMarkersUFBatch_8Way_512x512_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/teapot_LabelMarkersUF_8Way_512x512_32u.raw b/src/samples/Samples/4_CUDA_Libraries/batchedLabelMarkersAndLabelCompressionNPP/teapot_LabelMarkersUF_8Way_512x512_32u.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/Makefile b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/README.md b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP.cpp b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/boxFilterNPP_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/teapot512.pgm b/src/samples/Samples/4_CUDA_Libraries/boxFilterNPP/teapot512.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/Makefile b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/README.md b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP.cpp b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/cannyEdgeDetectorNPP_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/teapot512.pgm b/src/samples/Samples/4_CUDA_Libraries/cannyEdgeDetectorNPP/teapot512.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/Makefile b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/README.md b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/conjugateGradient_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/main.cpp b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/main_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/conjugateGradient/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/Makefile b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/README.md b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs.cu b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs.cu.hip b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs.cu.hip
old mode 100644
new mode 100755
index 6215cac..e69de29
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs.cu.hip
@@ -1,427 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This sample implements a conjugate gradient solver on GPU
- * using CUBLAS and CUSPARSE with CUDA Graphs
- *
- */
-
-// includes, system
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-/* Using updated (v2) interfaces to cublas */
-#include <hipblas.h>
-#include <hip/hip_runtime.h>
-#include <hipsparse.h>
-
-// Utilities and system includes
-#include "helper_cuda_hipified.h"  // helper function CUDA error checking and initialization
-#include "helper_functions.h"  // helper for shared functions common to CUDA Samples
-
-const char *sSDKname = "conjugateGradientCudaGraphs";
-
-#ifndef WITH_GRAPH
-#define WITH_GRAPH 1
-#endif
-
-/* genTridiag: generate a random tridiagonal symmetric matrix */
-void genTridiag(int *I, int *J, float *val, int N, int nz) {
-  I[0] = 0, J[0] = 0, J[1] = 1;
-  val[0] = (float)rand() / RAND_MAX + 10.0f;
-  val[1] = (float)rand() / RAND_MAX;
-  int start;
-
-  for (int i = 1; i < N; i++) {
-    if (i > 1) {
-      I[i] = I[i - 1] + 3;
-    } else {
-      I[1] = 2;
-    }
-
-    start = (i - 1) * 3 + 2;
-    J[start] = i - 1;
-    J[start + 1] = i;
-
-    if (i < N - 1) {
-      J[start + 2] = i + 1;
-    }
-
-    val[start] = val[start - 1];
-    val[start + 1] = (float)rand() / RAND_MAX + 10.0f;
-
-    if (i < N - 1) {
-      val[start + 2] = (float)rand() / RAND_MAX;
-    }
-  }
-
-  I[N] = nz;
-}
-
-__global__ void initVectors(float *rhs, float *x, int N) {
-  size_t gid = blockIdx.x * blockDim.x + threadIdx.x;
-
-  for (size_t i = gid; i < N; i += gridDim.x * blockDim.x) {
-    rhs[i] = 1.0;
-    x[i] = 0.0;
-  }
-}
-
-__global__ void r1_div_x(float *r1, float *r0, float *b) {
-  int gid = blockIdx.x * blockDim.x + threadIdx.x;
-  if (gid == 0) {
-    b[0] = r1[0] / r0[0];
-  }
-}
-
-__global__ void a_minus(float *a, float *na) {
-  int gid = blockIdx.x * blockDim.x + threadIdx.x;
-  if (gid == 0) {
-    na[0] = -(a[0]);
-  }
-}
-
-int main(int argc, char **argv) {
-  int N = 0, nz = 0, *I = NULL, *J = NULL;
-  float *val = NULL;
-  const float tol = 1e-5f;
-  const int max_iter = 10000;
-  float *x;
-  float *rhs;
-  float r1;
-
-  int *d_col, *d_row;
-  float *d_val, *d_x;
-  float *d_r, *d_p, *d_Ax;
-  int k;
-  float alpha, beta, alpham1;
-
-  hipStream_t stream1, streamForGraph;
-
-  // This will pick the best possible CUDA capable device
-  hipDeviceProp_t deviceProp;
-  int devID = findCudaDevice(argc, (const char **)argv);
-
-  if (devID < 0) {
-    printf("exiting...\n");
-    exit(EXIT_SUCCESS);
-  }
-
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, devID));
-
-  // Statistics about the GPU device
-  printf(
-      "> GPU device has %d Multi-Processors, SM %d.%d compute capabilities\n\n",
-      deviceProp.multiProcessorCount, deviceProp.major, deviceProp.minor);
-
-  /* Generate a random tridiagonal symmetric matrix in CSR format */
-  N = 1048576;
-  nz = (N - 2) * 3 + 4;
-  HIPCHECK(hipHostMalloc(&I, sizeof(int) * (N + 1)));
-  HIPCHECK(hipHostMalloc(&J, sizeof(int) * nz));
-  HIPCHECK(hipHostMalloc(&val, sizeof(float) * nz));
-  genTridiag(I, J, val, N, nz);
-
-  HIPCHECK(hipHostMalloc(&x, sizeof(float) * N));
-  rhs = (float *)malloc(sizeof(float) * N);
-
-  for (int i = 0; i < N; i++) {
-    rhs[i] = 1.0;
-    x[i] = 0.0;
-  }
-
-  /* Get handle to the CUBLAS context */
-  hipblasHandle_t cublasHandle = 0;
-  hipblasStatus_t hipblasStatus_t;
-  hipblasStatus_t = hipblasCreate(&cublasHandle);
-
-  HIPCHECK(hipblasStatus_t);
-
-  /* Get handle to the CUSPARSE context */
-  hipsparseHandle_t cusparseHandle = 0;
-  hipsparseStatus_t cusparseStatus;
-  cusparseStatus = hipsparseCreate(&cusparseHandle);
-
-  HIPCHECK(cusparseStatus);
-
-  HIPCHECK(hipStreamCreate(&stream1));
-
-  HIPCHECK(hipMalloc((void **)&d_col, nz * sizeof(int)));
-  HIPCHECK(hipMalloc((void **)&d_row, (N + 1) * sizeof(int)));
-  HIPCHECK(hipMalloc((void **)&d_val, nz * sizeof(float)));
-  HIPCHECK(hipMalloc((void **)&d_x, N * sizeof(float)));
-  HIPCHECK(hipMalloc((void **)&d_r, N * sizeof(float)));
-  HIPCHECK(hipMalloc((void **)&d_p, N * sizeof(float)));
-  HIPCHECK(hipMalloc((void **)&d_Ax, N * sizeof(float)));
-
-  float *d_r1, *d_r0, *d_dot, *d_a, *d_na, *d_b;
-  HIPCHECK(hipMalloc((void **)&d_r1, sizeof(float)));
-  HIPCHECK(hipMalloc((void **)&d_r0, sizeof(float)));
-  HIPCHECK(hipMalloc((void **)&d_dot, sizeof(float)));
-  HIPCHECK(hipMalloc((void **)&d_a, sizeof(float)));
-  HIPCHECK(hipMalloc((void **)&d_na, sizeof(float)));
-  HIPCHECK(hipMalloc((void **)&d_b, sizeof(float)));
-
-  /* Wrap raw data into cuSPARSE generic API objects */
-  hipsparseSpMatDescr_t matA = NULL;
-  HIPCHECK(hipsparseCreateCsr(&matA, N, N, nz, d_row, d_col, d_val,
-                                    HIPSPARSE_INDEX_32I, HIPSPARSE_INDEX_32I,
-                                    HIPSPARSE_INDEX_BASE_ZERO, HIPBLAS_R_32F));
-  hipsparseDnVecDescr_t vecx = NULL;
-  HIPCHECK(hipsparseCreateDnVec(&vecx, N, d_x, HIPBLAS_R_32F));
-  hipsparseDnVecDescr_t vecp = NULL;
-  HIPCHECK(hipsparseCreateDnVec(&vecp, N, d_p, HIPBLAS_R_32F));
-  hipsparseDnVecDescr_t vecAx = NULL;
-  HIPCHECK(hipsparseCreateDnVec(&vecAx, N, d_Ax, HIPBLAS_R_32F));
-
-  /* Allocate workspace for cuSPARSE */
-  size_t bufferSize = 0;
-  HIPCHECK(hipsparseSpMV_bufferSize(
-      cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, &alpha, matA, vecx,
-      &beta, vecAx, HIPBLAS_R_32F, HIPSPARSE_SPMV_ALG_DEFAULT, &bufferSize));
-  void *buffer = NULL;
-  HIPCHECK(hipMalloc(&buffer, bufferSize));
-
-  hipsparseMatDescr_t descr = 0;
-  HIPCHECK(hipsparseCreateMatDescr(&descr));
-
-  HIPCHECK(hipsparseSetMatType(descr, HIPSPARSE_MATRIX_TYPE_GENERAL));
-  HIPCHECK(hipsparseSetMatIndexBase(descr, HIPSPARSE_INDEX_BASE_ZERO));
-
-  int numBlocks = 0, blockSize = 0;
-  HIPCHECK(
-      hipOccupancyMaxPotentialBlockSize(&numBlocks, &blockSize, initVectors));
-
-  HIPCHECK(hipMemcpyAsync(d_col, J, nz * sizeof(int),
-                                  hipMemcpyHostToDevice, stream1));
-  HIPCHECK(hipMemcpyAsync(d_row, I, (N + 1) * sizeof(int),
-                                  hipMemcpyHostToDevice, stream1));
-  HIPCHECK(hipMemcpyAsync(d_val, val, nz * sizeof(float),
-                                  hipMemcpyHostToDevice, stream1));
-
-  initVectors<<<numBlocks, blockSize, 0, stream1>>>(d_r, d_x, N);
-
-  alpha = 1.0;
-  alpham1 = -1.0;
-  beta = 0.0;
-
-  HIPCHECK(hipsparseSetStream(cusparseHandle, stream1));
-  HIPCHECK(hipsparseSpMV(cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE,
-                               &alpha, matA, vecx, &beta, vecAx, HIPBLAS_R_32F,
-                               HIPSPARSE_SPMV_ALG_DEFAULT, buffer));
-
-  HIPCHECK(hipblasSetStream(cublasHandle, stream1));
-  HIPCHECK(hipblasSaxpy(cublasHandle, N, &alpham1, d_Ax, 1, d_r, 1));
-
-  HIPCHECK(
-      hipblasSetPointerMode(cublasHandle, HIPBLAS_POINTER_MODE_DEVICE));
-  HIPCHECK(hipblasSdot(cublasHandle, N, d_r, 1, d_r, 1, d_r1));
-
-  k = 1;
-  // First Iteration when k=1 starts
-  HIPCHECK(hipblasScopy(cublasHandle, N, d_r, 1, d_p, 1));
-  HIPCHECK(hipsparseSpMV(cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE,
-                               &alpha, matA, vecp, &beta, vecAx, HIPBLAS_R_32F,
-                               HIPSPARSE_SPMV_ALG_DEFAULT, buffer));
-
-  HIPCHECK(hipblasSdot(cublasHandle, N, d_p, 1, d_Ax, 1, d_dot));
-
-  r1_div_x<<<1, 1, 0, stream1>>>(d_r1, d_dot, d_a);
-
-  HIPCHECK(hipblasSaxpy(cublasHandle, N, d_a, d_p, 1, d_x, 1));
-
-  a_minus<<<1, 1, 0, stream1>>>(d_a, d_na);
-
-  HIPCHECK(hipblasSaxpy(cublasHandle, N, d_na, d_Ax, 1, d_r, 1));
-
-  HIPCHECK(hipMemcpyAsync(d_r0, d_r1, sizeof(float),
-                                  hipMemcpyDeviceToDevice, stream1));
-
-  HIPCHECK(hipblasSdot(cublasHandle, N, d_r, 1, d_r, 1, d_r1));
-
-  HIPCHECK(hipMemcpyAsync(&r1, d_r1, sizeof(float),
-                                  hipMemcpyDeviceToHost, stream1));
-  HIPCHECK(hipStreamSynchronize(stream1));
-  printf("iteration = %3d, residual = %e\n", k, sqrt(r1));
-  // First Iteration when k=1 ends
-  k++;
-
-#if WITH_GRAPH
-  hipGraph_t initGraph;
-  HIPCHECK(hipStreamCreate(&streamForGraph));
-  HIPCHECK(hipblasSetStream(cublasHandle, stream1));
-  HIPCHECK(hipsparseSetStream(cusparseHandle, stream1));
-  HIPCHECK(hipStreamBeginCapture(stream1, hipStreamCaptureModeGlobal));
-
-  r1_div_x<<<1, 1, 0, stream1>>>(d_r1, d_r0, d_b);
-  hipblasSetPointerMode(cublasHandle, HIPBLAS_POINTER_MODE_DEVICE);
-  HIPCHECK(hipblasSscal(cublasHandle, N, d_b, d_p, 1));
-  hipblasSetPointerMode(cublasHandle, HIPBLAS_POINTER_MODE_HOST);
-  HIPCHECK(hipblasSaxpy(cublasHandle, N, &alpha, d_r, 1, d_p, 1));
-  hipblasSetPointerMode(cublasHandle, HIPBLAS_POINTER_MODE_DEVICE);
-
-  HIPCHECK(
-      hipsparseSetPointerMode(cusparseHandle, HIPSPARSE_POINTER_MODE_HOST));
-  HIPCHECK(hipsparseSpMV(cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE,
-                               &alpha, matA, vecp, &beta, vecAx, HIPBLAS_R_32F,
-                               HIPSPARSE_SPMV_ALG_DEFAULT, buffer));
-
-  HIPCHECK(hipMemsetAsync(d_dot, 0, sizeof(float), stream1));
-  HIPCHECK(hipblasSdot(cublasHandle, N, d_p, 1, d_Ax, 1, d_dot));
-
-  r1_div_x<<<1, 1, 0, stream1>>>(d_r1, d_dot, d_a);
-
-  HIPCHECK(hipblasSaxpy(cublasHandle, N, d_a, d_p, 1, d_x, 1));
-
-  a_minus<<<1, 1, 0, stream1>>>(d_a, d_na);
-
-  HIPCHECK(hipblasSaxpy(cublasHandle, N, d_na, d_Ax, 1, d_r, 1));
-
-  HIPCHECK(hipMemcpyAsync(d_r0, d_r1, sizeof(float),
-                                  hipMemcpyDeviceToDevice, stream1));
-  HIPCHECK(hipMemsetAsync(d_r1, 0, sizeof(float), stream1));
-
-  HIPCHECK(hipblasSdot(cublasHandle, N, d_r, 1, d_r, 1, d_r1));
-
-  HIPCHECK(hipMemcpyAsync((float *)&r1, d_r1, sizeof(float),
-                                  hipMemcpyDeviceToHost, stream1));
-
-  HIPCHECK(hipStreamEndCapture(stream1, &initGraph));
-  hipGraphExec_t graphExec;
-  HIPCHECK(hipGraphInstantiate(&graphExec, initGraph, NULL, NULL, 0));
-#endif
-
-  HIPCHECK(hipblasSetStream(cublasHandle, stream1));
-  HIPCHECK(hipsparseSetStream(cusparseHandle, stream1));
-
-  while (r1 > tol * tol && k <= max_iter) {
-#if WITH_GRAPH
-    HIPCHECK(hipGraphLaunch(graphExec, streamForGraph));
-    HIPCHECK(hipStreamSynchronize(streamForGraph));
-#else
-    r1_div_x<<<1, 1, 0, stream1>>>(d_r1, d_r0, d_b);
-    hipblasSetPointerMode(cublasHandle, HIPBLAS_POINTER_MODE_DEVICE);
-    HIPCHECK(hipblasSscal(cublasHandle, N, d_b, d_p, 1));
-
-    hipblasSetPointerMode(cublasHandle, HIPBLAS_POINTER_MODE_HOST);
-    HIPCHECK(hipblasSaxpy(cublasHandle, N, &alpha, d_r, 1, d_p, 1));
-
-    HIPCHECK(hipsparseSpMV(
-        cusparseHandle, HIPSPARSE_OPERATION_NON_TRANSPOSE, &alpha, matA, vecp,
-        &beta, vecAx, HIPBLAS_R_32F, HIPSPARSE_SPMV_ALG_DEFAULT, buffer));
-
-    hipblasSetPointerMode(cublasHandle, HIPBLAS_POINTER_MODE_DEVICE);
-    HIPCHECK(hipblasSdot(cublasHandle, N, d_p, 1, d_Ax, 1, d_dot));
-
-    r1_div_x<<<1, 1, 0, stream1>>>(d_r1, d_dot, d_a);
-
-    HIPCHECK(hipblasSaxpy(cublasHandle, N, d_a, d_p, 1, d_x, 1));
-
-    a_minus<<<1, 1, 0, stream1>>>(d_a, d_na);
-    HIPCHECK(hipblasSaxpy(cublasHandle, N, d_na, d_Ax, 1, d_r, 1));
-
-    HIPCHECK(hipMemcpyAsync(d_r0, d_r1, sizeof(float),
-                                    hipMemcpyDeviceToDevice, stream1));
-
-    HIPCHECK(hipblasSdot(cublasHandle, N, d_r, 1, d_r, 1, d_r1));
-    HIPCHECK(hipMemcpyAsync((float *)&r1, d_r1, sizeof(float),
-                                    hipMemcpyDeviceToHost, stream1));
-    HIPCHECK(hipStreamSynchronize(stream1));
-#endif
-    printf("iteration = %3d, residual = %e\n", k, sqrt(r1));
-    k++;
-  }
-
-#if WITH_GRAPH
-  HIPCHECK(hipMemcpyAsync(x, d_x, N * sizeof(float),
-                                  hipMemcpyDeviceToHost, streamForGraph));
-  HIPCHECK(hipStreamSynchronize(streamForGraph));
-#else
-  HIPCHECK(hipMemcpyAsync(x, d_x, N * sizeof(float),
-                                  hipMemcpyDeviceToHost, stream1));
-  HIPCHECK(hipStreamSynchronize(stream1));
-#endif
-
-  float rsum, diff, err = 0.0;
-
-  for (int i = 0; i < N; i++) {
-    rsum = 0.0;
-
-    for (int j = I[i]; j < I[i + 1]; j++) {
-      rsum += val[j] * x[J[j]];
-    }
-
-    diff = fabs(rsum - rhs[i]);
-
-    if (diff > err) {
-      err = diff;
-    }
-  }
-
-#if WITH_GRAPH
-  HIPCHECK(hipGraphExecDestroy(graphExec));
-  HIPCHECK(hipGraphDestroy(initGraph));
-  HIPCHECK(hipStreamDestroy(streamForGraph));
-#endif
-  HIPCHECK(hipStreamDestroy(stream1));
-  hipsparseDestroy(cusparseHandle);
-  hipblasDestroy(cublasHandle);
-
-  if (matA) {
-    HIPCHECK(hipsparseDestroySpMat(matA));
-  }
-  if (vecx) {
-    HIPCHECK(hipsparseDestroyDnVec(vecx));
-  }
-  if (vecAx) {
-    HIPCHECK(hipsparseDestroyDnVec(vecAx));
-  }
-  if (vecp) {
-    HIPCHECK(hipsparseDestroyDnVec(vecp));
-  }
-
-  HIPCHECK(hipHostFree(I));
-  HIPCHECK(hipHostFree(J));
-  HIPCHECK(hipHostFree(val));
-  HIPCHECK(hipHostFree(x));
-  free(rhs);
-  HIPCHECK(hipFree(d_col));
-  HIPCHECK(hipFree(d_row));
-  HIPCHECK(hipFree(d_val));
-  HIPCHECK(hipFree(d_x));
-  HIPCHECK(hipFree(d_r));
-  HIPCHECK(hipFree(d_p));
-  HIPCHECK(hipFree(d_Ax));
-
-  printf("Test Summary:  Error amount = %f\n", err);
-  exit((k <= max_iter) ? 0 : 1);
-}
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientCudaGraphs/conjugateGradientCudaGraphs_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/Makefile b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/README.md b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG.cu b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG.cu.hip b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG.cu.hip
old mode 100644
new mode 100755
index 1fadaab..e69de29
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG.cu.hip
@@ -1,495 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This sample implements a conjugate gradient solver on GPU using
- * Multi Block Cooperative Groups, also uses Unified Memory.
- *
- */
-
-// includes, system
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-#include <hip/hip_runtime.h>
-
-// Utilities and system includes
-#include "helper_cuda_hipified.h"  // helper function CUDA error checking and initialization
-#include "helper_functions.h"  // helper for shared functions common to CUDA Samples
-
-#include <hip/hip_cooperative_groups.h>
-#include <cooperative_groups/reduce.h>
-
-namespace cg = cooperative_groups;
-
-const char *sSDKname = "conjugateGradientMultiBlockCG";
-
-#define ENABLE_CPU_DEBUG_CODE 0
-#define THREADS_PER_BLOCK 512
-
-/* genTridiag: generate a random tridiagonal symmetric matrix */
-void genTridiag(int *I, int *J, float *val, int N, int nz) {
-  I[0] = 0, J[0] = 0, J[1] = 1;
-  val[0] = static_cast<float>(rand()) / RAND_MAX + 10.0f;
-  val[1] = static_cast<float>(rand()) / RAND_MAX;
-  int start;
-
-  for (int i = 1; i < N; i++) {
-    if (i > 1) {
-      I[i] = I[i - 1] + 3;
-    } else {
-      I[1] = 2;
-    }
-
-    start = (i - 1) * 3 + 2;
-    J[start] = i - 1;
-    J[start + 1] = i;
-
-    if (i < N - 1) {
-      J[start + 2] = i + 1;
-    }
-
-    val[start] = val[start - 1];
-    val[start + 1] = static_cast<float>(rand()) / RAND_MAX + 10.0f;
-
-    if (i < N - 1) {
-      val[start + 2] = static_cast<float>(rand()) / RAND_MAX;
-    }
-  }
-
-  I[N] = nz;
-}
-
-// I - contains location of the given non-zero element in the row of the matrix
-// J - contains location of the given non-zero element in the column of the
-// matrix val - contains values of the given non-zero elements of the matrix
-// inputVecX - input vector to be multiplied
-// outputVecY - resultant vector
-void cpuSpMV(int *I, int *J, float *val, int nnz, int num_rows, float alpha,
-             float *inputVecX, float *outputVecY) {
-  for (int i = 0; i < num_rows; i++) {
-    int num_elems_this_row = I[i + 1] - I[i];
-
-    float output = 0.0;
-    for (int j = 0; j < num_elems_this_row; j++) {
-      output += alpha * val[I[i] + j] * inputVecX[J[I[i] + j]];
-    }
-    outputVecY[i] = output;
-  }
-
-  return;
-}
-
-double dotProduct(float *vecA, float *vecB, int size) {
-  double result = 0.0;
-
-  for (int i = 0; i < size; i++) {
-    result = result + (vecA[i] * vecB[i]);
-  }
-
-  return result;
-}
-
-void scaleVector(float *vec, float alpha, int size) {
-  for (int i = 0; i < size; i++) {
-    vec[i] = alpha * vec[i];
-  }
-}
-
-void saxpy(float *x, float *y, float a, int size) {
-  for (int i = 0; i < size; i++) {
-    y[i] = a * x[i] + y[i];
-  }
-}
-
-void cpuConjugateGrad(int *I, int *J, float *val, float *x, float *Ax, float *p,
-                      float *r, int nnz, int N, float tol) {
-  int max_iter = 10000;
-
-  float alpha = 1.0;
-  float alpham1 = -1.0;
-  float r0 = 0.0, b, a, na;
-
-  cpuSpMV(I, J, val, nnz, N, alpha, x, Ax);
-  saxpy(Ax, r, alpham1, N);
-
-  float r1 = dotProduct(r, r, N);
-
-  int k = 1;
-
-  while (r1 > tol * tol && k <= max_iter) {
-    if (k > 1) {
-      b = r1 / r0;
-      scaleVector(p, b, N);
-
-      saxpy(r, p, alpha, N);
-    } else {
-      for (int i = 0; i < N; i++) p[i] = r[i];
-    }
-
-    cpuSpMV(I, J, val, nnz, N, alpha, p, Ax);
-
-    float dot = dotProduct(p, Ax, N);
-    a = r1 / dot;
-
-    saxpy(p, x, a, N);
-    na = -a;
-    saxpy(Ax, r, na, N);
-
-    r0 = r1;
-    r1 = dotProduct(r, r, N);
-
-    printf("\nCPU code iteration = %3d, residual = %e\n", k, sqrt(r1));
-    k++;
-  }
-}
-
-__device__ void gpuSpMV(int *I, int *J, float *val, int nnz, int num_rows,
-                        float alpha, float *inputVecX, float *outputVecY,
-                        cg::thread_block &cta, const cg::grid_group &grid) {
-  for (int i = grid.thread_rank(); i < num_rows; i += grid.size()) {
-    int row_elem = I[i];
-    int next_row_elem = I[i + 1];
-    int num_elems_this_row = next_row_elem - row_elem;
-
-    float output = 0.0;
-    for (int j = 0; j < num_elems_this_row; j++) {
-      // I or J or val arrays - can be put in shared memory
-      // as the access is random and reused in next calls of gpuSpMV function.
-      output += alpha * val[row_elem + j] * inputVecX[J[row_elem + j]];
-    }
-
-    outputVecY[i] = output;
-  }
-}
-
-__device__ void gpuSaxpy(float *x, float *y, float a, int size,
-                         const cg::grid_group &grid) {
-  for (int i = grid.thread_rank(); i < size; i += grid.size()) {
-    y[i] = a * x[i] + y[i];
-  }
-}
-
-__device__ void gpuDotProduct(float *vecA, float *vecB, double *result,
-                              int size, const cg::thread_block &cta,
-                              const cg::grid_group &grid) {
-  extern __shared__ double tmp[];
-
-  double temp_sum = 0.0;
-  for (int i = grid.thread_rank(); i < size; i += grid.size()) {
-    temp_sum += static_cast<double>(vecA[i] * vecB[i]);
-  }
-
-  cg::thread_block_tile<32> tile32 = cg::tiled_partition<32>(cta);
-
-  temp_sum = cg::reduce(tile32, temp_sum, cg::plus<double>());
-
-  if (tile32.thread_rank() == 0) {
-    tmp[tile32.meta_group_rank()] = temp_sum;
-  }
-
-  cg::sync(cta);
-
-  if (tile32.meta_group_rank() == 0) {
-     temp_sum = tile32.thread_rank() < tile32.meta_group_size() ? tmp[tile32.thread_rank()] : 0.0;
-     temp_sum = cg::reduce(tile32, temp_sum, cg::plus<double>());
-
-    if (tile32.thread_rank() == 0) {
-      atomicAdd(result, temp_sum);
-    }
-  }
-}
-
-__device__ void gpuCopyVector(float *srcA, float *destB, int size,
-                              const cg::grid_group &grid) {
-  for (int i = grid.thread_rank(); i < size; i += grid.size()) {
-    destB[i] = srcA[i];
-  }
-}
-
-__device__ void gpuScaleVectorAndSaxpy(const float *x, float *y, float a, float scale, int size,
-                         const cg::grid_group &grid) {
-  for (int i = grid.thread_rank(); i < size; i += grid.size()) {
-    y[i] = a * x[i] + scale * y[i];
-  }
-}
-
-extern "C" __global__ void gpuConjugateGradient(int *I, int *J, float *val,
-                                                float *x, float *Ax, float *p,
-                                                float *r, double *dot_result,
-                                                int nnz, int N, float tol) {
-  cg::thread_block cta = cg::this_thread_block();
-  cg::grid_group grid = cg::this_grid();
-
-  int max_iter = 10000;
-
-  float alpha = 1.0;
-  float alpham1 = -1.0;
-  float r0 = 0.0, r1, b, a, na;
-
-  gpuSpMV(I, J, val, nnz, N, alpha, x, Ax, cta, grid);
-
-  cg::sync(grid);
-
-  gpuSaxpy(Ax, r, alpham1, N, grid);
-
-  cg::sync(grid);
-
-  gpuDotProduct(r, r, dot_result, N, cta, grid);
-
-  cg::sync(grid);
-
-  r1 = *dot_result;
-
-  int k = 1;
-  while (r1 > tol * tol && k <= max_iter) {
-    if (k > 1) {
-      b = r1 / r0;
-      gpuScaleVectorAndSaxpy(r, p, alpha, b, N, grid);
-    } else {
-      gpuCopyVector(r, p, N, grid);
-    }
-
-    cg::sync(grid);
-
-    gpuSpMV(I, J, val, nnz, N, alpha, p, Ax, cta, grid);
-
-    if (threadIdx.x == 0 && blockIdx.x == 0) *dot_result = 0.0;
-
-    cg::sync(grid);
-
-    gpuDotProduct(p, Ax, dot_result, N, cta, grid);
-
-    cg::sync(grid);
-
-    a = r1 / *dot_result;
-
-    gpuSaxpy(p, x, a, N, grid);
-    na = -a;
-    gpuSaxpy(Ax, r, na, N, grid);
-
-    r0 = r1;
-
-    cg::sync(grid);
-    if (threadIdx.x == 0 && blockIdx.x == 0) *dot_result = 0.0;
-
-    cg::sync(grid);
-
-    gpuDotProduct(r, r, dot_result, N, cta, grid);
-
-    cg::sync(grid);
-
-    r1 = *dot_result;
-    k++;
-  }
-}
-
-bool areAlmostEqual(float a, float b, float maxRelDiff) {
-  float diff = fabsf(a - b);
-  float abs_a = fabsf(a);
-  float abs_b = fabsf(b);
-  float largest = abs_a > abs_b ? abs_a : abs_b;
-
-  if (diff <= largest * maxRelDiff) {
-    return true;
-  } else {
-    printf("maxRelDiff = %.8e\n", maxRelDiff);
-    printf(
-        "diff %.8e > largest * maxRelDiff %.8e therefore %.8e and %.8e are not "
-        "same\n",
-        diff, largest * maxRelDiff, a, b);
-    return false;
-  }
-}
-
-int main(int argc, char **argv) {
-  int N = 0, nz = 0, *I = NULL, *J = NULL;
-  float *val = NULL;
-  const float tol = 1e-5f;
-  float *x;
-  float *rhs;
-  float r1;
-  float *r, *p, *Ax;
-  hipEvent_t start, stop;
-
-  printf("Starting [%s]...\n", sSDKname);
-
-  // This will pick the best possible CUDA capable device
-  hipDeviceProp_t deviceProp;
-  int devID = findCudaDevice(argc, (const char **)argv);
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, devID));
-
-  if (!deviceProp.managedMemory) {
-    // This sample requires being run on a device that supports Unified Memory
-    fprintf(stderr, "Unified Memory not supported on this device\n");
-    exit(EXIT_WAIVED);
-  }
-
-  // This sample requires being run on a device that supports Cooperative Kernel
-  // Launch
-  if (!deviceProp.cooperativeLaunch) {
-    printf(
-        "\nSelected GPU (%d) does not support Cooperative Kernel Launch, "
-        "Waiving the run\n",
-        devID);
-    exit(EXIT_WAIVED);
-  }
-
-  // Statistics about the GPU device
-  printf(
-      "> GPU device has %d Multi-Processors, SM %d.%d compute capabilities\n\n",
-      deviceProp.multiProcessorCount, deviceProp.major, deviceProp.minor);
-
-  /* Generate a random tridiagonal symmetric matrix in CSR format */
-  N = 1048576;
-  nz = (N - 2) * 3 + 4;
-
-  hipMallocManaged(reinterpret_cast<void **>(&I), sizeof(int) * (N + 1));
-  hipMallocManaged(reinterpret_cast<void **>(&J), sizeof(int) * nz);
-  hipMallocManaged(reinterpret_cast<void **>(&val), sizeof(float) * nz);
-
-  genTridiag(I, J, val, N, nz);
-
-  hipMallocManaged(reinterpret_cast<void **>(&x), sizeof(float) * N);
-  hipMallocManaged(reinterpret_cast<void **>(&rhs), sizeof(float) * N);
-
-  double *dot_result;
-
-  hipMallocManaged(reinterpret_cast<void **>(&dot_result), sizeof(double));
-
-  *dot_result = 0.0;
-
-  // temp memory for CG
-  HIPCHECK(
-      hipMallocManaged(reinterpret_cast<void **>(&r), N * sizeof(float)));
-  HIPCHECK(
-      hipMallocManaged(reinterpret_cast<void **>(&p), N * sizeof(float)));
-  HIPCHECK(
-      hipMallocManaged(reinterpret_cast<void **>(&Ax), N * sizeof(float)));
-
-  hipDeviceSynchronize();
-
-  HIPCHECK(hipEventCreate(&start));
-  HIPCHECK(hipEventCreate(&stop));
-
-#if ENABLE_CPU_DEBUG_CODE
-  float *Ax_cpu = reinterpret_cast<float *>(malloc(sizeof(float) * N));
-  float *r_cpu = reinterpret_cast<float *>(malloc(sizeof(float) * N));
-  float *p_cpu = reinterpret_cast<float *>(malloc(sizeof(float) * N));
-  float *x_cpu = reinterpret_cast<float *>(malloc(sizeof(float) * N));
-
-  for (int i = 0; i < N; i++) {
-    r_cpu[i] = 1.0;
-    Ax_cpu[i] = x_cpu[i] = 0.0;
-  }
-
-#endif
-
-  for (int i = 0; i < N; i++) {
-    r[i] = rhs[i] = 1.0;
-    x[i] = 0.0;
-  }
-
-  void *kernelArgs[] = {
-      (void *)&I,  (void *)&J, (void *)&val, (void *)&x,
-      (void *)&Ax, (void *)&p, (void *)&r,   (void *)&dot_result,
-      (void *)&nz, (void *)&N, (void *)&tol,
-  };
-
-  int sMemSize = sizeof(double) * ((THREADS_PER_BLOCK/32) + 1);
-  int numBlocksPerSm = 0;
-  int numThreads = THREADS_PER_BLOCK;
-
-  HIPCHECK(hipOccupancyMaxActiveBlocksPerMultiprocessor(
-      &numBlocksPerSm, gpuConjugateGradient, numThreads, sMemSize));
-
-  int numSms = deviceProp.multiProcessorCount;
-  dim3 dimGrid(numSms * numBlocksPerSm, 1, 1),
-      dimBlock(THREADS_PER_BLOCK, 1, 1);
-  HIPCHECK(hipEventRecord(start, 0));
-  HIPCHECK(hipLaunchCooperativeKernel((void *)gpuConjugateGradient,
-                                              dimGrid, dimBlock, kernelArgs,
-                                              sMemSize, NULL));
-  HIPCHECK(hipEventRecord(stop, 0));
-  HIPCHECK(hipDeviceSynchronize());
-
-  float time;
-  HIPCHECK(hipEventElapsedTime(&time, start, stop));
-
-  r1 = *dot_result;
-
-  printf("GPU Final, residual = %e, kernel execution time = %f ms\n", sqrt(r1),
-         time);
-
-#if ENABLE_CPU_DEBUG_CODE
-  cpuConjugateGrad(I, J, val, x_cpu, Ax_cpu, p_cpu, r_cpu, nz, N, tol);
-#endif
-
-  float rsum, diff, err = 0.0;
-
-  for (int i = 0; i < N; i++) {
-    rsum = 0.0;
-
-    for (int j = I[i]; j < I[i + 1]; j++) {
-      rsum += val[j] * x[J[j]];
-    }
-
-    diff = fabs(rsum - rhs[i]);
-
-    if (diff > err) {
-      err = diff;
-    }
-  }
-
-  HIPCHECK(hipFree(I));
-  HIPCHECK(hipFree(J));
-  HIPCHECK(hipFree(val));
-  HIPCHECK(hipFree(x));
-  HIPCHECK(hipFree(rhs));
-  HIPCHECK(hipFree(r));
-  HIPCHECK(hipFree(p));
-  HIPCHECK(hipFree(Ax));
-  HIPCHECK(hipFree(dot_result));
-  HIPCHECK(hipEventDestroy(start));
-  HIPCHECK(hipEventDestroy(stop));
-
-#if ENABLE_CPU_DEBUG_CODE
-  free(Ax_cpu);
-  free(r_cpu);
-  free(p_cpu);
-  free(x_cpu);
-#endif
-
-  printf("Test Summary:  Error amount = %f \n", err);
-  fprintf(stdout, "&&&& conjugateGradientMultiBlockCG %s\n",
-          (sqrt(r1) < tol) ? "PASSED" : "FAILED");
-  exit((sqrt(r1) < tol) ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiBlockCG/conjugateGradientMultiBlockCG_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/Makefile b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/README.md b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG.cu b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG.cu.hip b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG.cu.hip
old mode 100644
new mode 100755
index 050642e..94deed1
--- a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG.cu.hip
@@ -34,8 +34,6 @@
 
 // includes, system
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <stdlib.h>
 #include <string.h>
 #include <map>
@@ -46,8 +44,8 @@
 #include <hip/hip_runtime.h>
 
 // Utilities and system includes
-#include "helper_cuda_hipified.h"  // helper function CUDA error checking and initialization
-#include "helper_functions.h"  // helper for shared functions common to CUDA Samples
+#include <helper_cuda.h>  // helper function CUDA error checking and initialization
+#include <helper_functions.h>  // helper for shared functions common to CUDA Samples
 
 #include <hip/hip_cooperative_groups.h>
 #include <cooperative_groups/reduce.h>
@@ -434,13 +432,13 @@ extern "C" __global__ void multiGpuConjugateGradient(
 // Map of device version to device number
 std::multimap<std::pair<int, int>, int> getIdenticalGPUs() {
   int numGpus = 0;
-  HIPCHECK(hipGetDeviceCount(&numGpus));
+  checkCudaErrors(hipGetDeviceCount(&numGpus));
 
   std::multimap<std::pair<int, int>, int> identicalGpus;
 
   for (int i = 0; i < numGpus; i++) {
     hipDeviceProp_t deviceProp;
-    HIPCHECK(hipGetDeviceProperties(&deviceProp, i));
+    checkCudaErrors(hipGetDeviceProperties(&deviceProp, i));
 
     // Filter unsupported devices
     if (deviceProp.cooperativeLaunch && deviceProp.concurrentManagedAccess) {
@@ -499,7 +497,7 @@ int main(int argc, char **argv) {
   // access between participating GPUs gives better performance.
   for (auto itr = bestFit.first; itr != bestFit.second; itr++) {
     int deviceId = itr->second;
-    HIPCHECK(hipSetDevice(deviceId));
+    checkCudaErrors(hipSetDevice(deviceId));
 
     std::for_each(
         itr, bestFit.second,
@@ -507,7 +505,7 @@ int main(int argc, char **argv) {
          &kNumGpusRequired](decltype(*itr) mapPair) {
           if (deviceId != mapPair.second) {
             int access = 0;
-            HIPCHECK(
+            checkCudaErrors(
                 hipDeviceCanAccessPeer(&access, deviceId, mapPair.second));
             printf("Device=%d %s Access Peer Device=%d\n", deviceId,
                    access ? "CAN" : "CANNOT", mapPair.second);
@@ -553,12 +551,12 @@ int main(int argc, char **argv) {
     // participating devices.
     for (auto p1_itr = bestFitDeviceIds.begin();
          p1_itr != bestFitDeviceIds.end(); p1_itr++) {
-      HIPCHECK(hipSetDevice(*p1_itr));
+      checkCudaErrors(hipSetDevice(*p1_itr));
       for (auto p2_itr = bestFitDeviceIds.begin();
            p2_itr != bestFitDeviceIds.end(); p2_itr++) {
         if (*p1_itr != *p2_itr) {
-          HIPCHECK(hipDeviceEnablePeerAccess(*p2_itr, 0));
-          HIPCHECK(hipSetDevice(*p1_itr));
+          checkCudaErrors(hipDeviceEnablePeerAccess(*p2_itr, 0));
+          checkCudaErrors(hipSetDevice(*p1_itr));
         }
       }
     }
@@ -568,33 +566,33 @@ int main(int argc, char **argv) {
   N = 10485760 * 2;
   nz = (N - 2) * 3 + 4;
 
-  HIPCHECK(hipMallocManaged((void **)&I, sizeof(int) * (N + 1)));
-  HIPCHECK(hipMallocManaged((void **)&J, sizeof(int) * nz));
-  HIPCHECK(hipMallocManaged((void **)&val, sizeof(float) * nz));
+  checkCudaErrors(hipMallocManaged((void **)&I, sizeof(int) * (N + 1)));
+  checkCudaErrors(hipMallocManaged((void **)&J, sizeof(int) * nz));
+  checkCudaErrors(hipMallocManaged((void **)&val, sizeof(float) * nz));
 
   float *val_cpu = (float *)malloc(sizeof(float) * nz);
 
   genTridiag(I, J, val_cpu, N, nz);
 
   memcpy(val, val_cpu, sizeof(float) * nz);
-  HIPCHECK(
+  checkCudaErrors(
       hipMemAdvise(I, sizeof(int) * (N + 1), hipMemAdviseSetReadMostly, 0));
-  HIPCHECK(
+  checkCudaErrors(
       hipMemAdvise(J, sizeof(int) * nz, hipMemAdviseSetReadMostly, 0));
-  HIPCHECK(
+  checkCudaErrors(
       hipMemAdvise(val, sizeof(float) * nz, hipMemAdviseSetReadMostly, 0));
 
-  HIPCHECK(hipMallocManaged((void **)&x, sizeof(float) * N));
+  checkCudaErrors(hipMallocManaged((void **)&x, sizeof(float) * N));
 
   double *dot_result;
-  HIPCHECK(hipMallocManaged((void **)&dot_result, sizeof(double)));
+  checkCudaErrors(hipMallocManaged((void **)&dot_result, sizeof(double)));
 
-  HIPCHECK(hipMemset(dot_result, 0, sizeof(double)));
+  checkCudaErrors(hipMemset(dot_result, 0, sizeof(double)));
 
   // temp memory for ConjugateGradient
-  HIPCHECK(hipMallocManaged((void **)&r, N * sizeof(float)));
-  HIPCHECK(hipMallocManaged((void **)&p, N * sizeof(float)));
-  HIPCHECK(hipMallocManaged((void **)&Ax, N * sizeof(float)));
+  checkCudaErrors(hipMallocManaged((void **)&r, N * sizeof(float)));
+  checkCudaErrors(hipMallocManaged((void **)&p, N * sizeof(float)));
+  checkCudaErrors(hipMallocManaged((void **)&Ax, N * sizeof(float)));
 
   std::cout << "\nRunning on GPUs = " << kNumGpusRequired << std::endl;
   hipStream_t nStreams[kNumGpusRequired];
@@ -608,11 +606,11 @@ int main(int argc, char **argv) {
   // set numSms & numBlocksPerSm to be lowest of 2 devices
   while (deviceId != bestFitDeviceIds.end()) {
     hipDeviceProp_t deviceProp;
-    HIPCHECK(hipSetDevice(*deviceId));
-    HIPCHECK(hipGetDeviceProperties(&deviceProp, *deviceId));
+    checkCudaErrors(hipSetDevice(*deviceId));
+    checkCudaErrors(hipGetDeviceProperties(&deviceProp, *deviceId));
 
     int numBlocksPerSm_current = 0;
-    HIPCHECK(hipOccupancyMaxActiveBlocksPerMultiprocessor(
+    checkCudaErrors(hipOccupancyMaxActiveBlocksPerMultiprocessor(
         &numBlocksPerSm_current, multiGpuConjugateGradient, numThreads,
         sMemSize));
 
@@ -636,8 +634,8 @@ int main(int argc, char **argv) {
   int totalThreadsPerGPU = numSms * numBlocksPerSm * THREADS_PER_BLOCK;
   deviceId = bestFitDeviceIds.begin();
   while (deviceId != bestFitDeviceIds.end()) {
-    HIPCHECK(hipSetDevice(*deviceId));
-    HIPCHECK(hipStreamCreate(&nStreams[device_count]));
+    checkCudaErrors(hipSetDevice(*deviceId));
+    checkCudaErrors(hipStreamCreate(&nStreams[device_count]));
 
     int perGPUIter = N / (totalThreadsPerGPU * kNumGpusRequired);
     int offset_Ax = device_count * totalThreadsPerGPU;
@@ -645,11 +643,11 @@ int main(int argc, char **argv) {
     int offset_p = device_count * totalThreadsPerGPU;
     int offset_x = device_count * totalThreadsPerGPU;
 
-    HIPCHECK(hipMemPrefetchAsync(I, sizeof(int) * N, *deviceId,
+    checkCudaErrors(hipMemPrefetchAsync(I, sizeof(int) * N, *deviceId,
                                          nStreams[device_count]));
-    HIPCHECK(hipMemPrefetchAsync(val, sizeof(float) * nz, *deviceId,
+    checkCudaErrors(hipMemPrefetchAsync(val, sizeof(float) * nz, *deviceId,
                                          nStreams[device_count]));
-    HIPCHECK(hipMemPrefetchAsync(J, sizeof(float) * nz, *deviceId,
+    checkCudaErrors(hipMemPrefetchAsync(J, sizeof(float) * nz, *deviceId,
                                          nStreams[device_count]));
 
     if (offset_Ax <= N) {
@@ -706,7 +704,7 @@ int main(int argc, char **argv) {
 
   // Structure used for cross-grid synchronization.
   MultiDeviceData multi_device_data;
-  HIPCHECK(hipHostAlloc(
+  checkCudaErrors(hipHostAlloc(
       &multi_device_data.hostMemoryArrivedList,
       (kNumGpusRequired - 1) * sizeof(*multi_device_data.hostMemoryArrivedList),
       hipHostMallocPortable));
@@ -727,23 +725,23 @@ int main(int argc, char **argv) {
   deviceId = bestFitDeviceIds.begin();
   device_count = 0;
   while (deviceId != bestFitDeviceIds.end()) {
-    HIPCHECK(hipSetDevice(*deviceId));
-    HIPCHECK(hipLaunchCooperativeKernel(
+    checkCudaErrors(hipSetDevice(*deviceId));
+    checkCudaErrors(hipLaunchCooperativeKernel(
         (void *)multiGpuConjugateGradient, dimGrid, dimBlock, kernelArgs,
         sMemSize, nStreams[device_count++]));
     multi_device_data.deviceRank++;
     deviceId++;
   }
 
-  HIPCHECK(hipMemPrefetchAsync(x, sizeof(float) * N, hipCpuDeviceId));
-  HIPCHECK(
+  checkCudaErrors(hipMemPrefetchAsync(x, sizeof(float) * N, hipCpuDeviceId));
+  checkCudaErrors(
       hipMemPrefetchAsync(dot_result, sizeof(double), hipCpuDeviceId));
 
   deviceId = bestFitDeviceIds.begin();
   device_count = 0;
   while (deviceId != bestFitDeviceIds.end()) {
-    HIPCHECK(hipSetDevice(*deviceId));
-    HIPCHECK(hipStreamSynchronize(nStreams[device_count++]));
+    checkCudaErrors(hipSetDevice(*deviceId));
+    checkCudaErrors(hipStreamSynchronize(nStreams[device_count++]));
     deviceId++;
   }
 
@@ -771,15 +769,15 @@ int main(int argc, char **argv) {
     }
   }
 
-  HIPCHECK(hipHostFree(multi_device_data.hostMemoryArrivedList));
-  HIPCHECK(hipFree(I));
-  HIPCHECK(hipFree(J));
-  HIPCHECK(hipFree(val));
-  HIPCHECK(hipFree(x));
-  HIPCHECK(hipFree(r));
-  HIPCHECK(hipFree(p));
-  HIPCHECK(hipFree(Ax));
-  HIPCHECK(hipFree(dot_result));
+  checkCudaErrors(hipHostFree(multi_device_data.hostMemoryArrivedList));
+  checkCudaErrors(hipFree(I));
+  checkCudaErrors(hipFree(J));
+  checkCudaErrors(hipFree(val));
+  checkCudaErrors(hipFree(x));
+  checkCudaErrors(hipFree(r));
+  checkCudaErrors(hipFree(p));
+  checkCudaErrors(hipFree(Ax));
+  checkCudaErrors(hipFree(dot_result));
   free(val_cpu);
 
 #if ENABLE_CPU_DEBUG_CODE
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientMultiDeviceCG/conjugateGradientMultiDeviceCG_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/Makefile b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/README.md b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/conjugateGradientPrecond_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/main.cpp b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/main_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientPrecond/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/Makefile b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/README.md b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/conjugateGradientUM_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/main.cpp b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/main_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/conjugateGradientUM/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/README.md b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/main.cu b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/main.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/main.cu.hip b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/main.cu.hip
old mode 100644
new mode 100755
index c38223b..e69de29
--- a/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/main.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/cuDLAErrorReporting/main.cu.hip
@@ -1,431 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "cudla.h"
-#include "hip/hip_runtime.h"
-
-#include <cstdio>
-#include <cstdlib>
-#include <cstring>
-#include <sys/stat.h>
-#include <fstream>
-#include <sstream>
-
-#define DPRINTF(...) printf(__VA_ARGS__)
-
-static void printTensorDesc(cudlaModuleTensorDescriptor* tensorDesc) {
-  DPRINTF("\tTENSOR NAME : %s\n", tensorDesc->name);
-  DPRINTF("\tsize: %lu\n", tensorDesc->size);
-
-  DPRINTF("\tdims: [%lu, %lu, %lu, %lu]\n", tensorDesc->n, tensorDesc->c,
-          tensorDesc->h, tensorDesc->w);
-
-  DPRINTF("\tdata fmt: %d\n", tensorDesc->dataFormat);
-  DPRINTF("\tdata type: %d\n", tensorDesc->dataType);
-  DPRINTF("\tdata category: %d\n", tensorDesc->dataCategory);
-  DPRINTF("\tpixel fmt: %d\n", tensorDesc->pixelFormat);
-  DPRINTF("\tpixel mapping: %d\n", tensorDesc->pixelMapping);
-  DPRINTF("\tstride[0]: %d\n", tensorDesc->stride[0]);
-  DPRINTF("\tstride[1]: %d\n", tensorDesc->stride[1]);
-  DPRINTF("\tstride[2]: %d\n", tensorDesc->stride[2]);
-  DPRINTF("\tstride[3]: %d\n", tensorDesc->stride[3]);
-}
-
-typedef struct {
-  cudlaDevHandle devHandle;
-  cudlaModule moduleHandle;
-  unsigned char* loadableData;
-  hipStream_t stream;
-  unsigned char* inputBuffer;
-  unsigned char* outputBuffer;
-  void* inputBufferGPU;
-  void* outputBufferGPU;
-  cudlaModuleTensorDescriptor* inputTensorDesc;
-  cudlaModuleTensorDescriptor* outputTensorDesc;
-} ResourceList;
-
-void cleanUp(ResourceList* resourceList);
-
-void cleanUp(ResourceList* resourceList) {
-  if (resourceList->inputTensorDesc != NULL) {
-    free(resourceList->inputTensorDesc);
-    resourceList->inputTensorDesc = NULL;
-  }
-  if (resourceList->outputTensorDesc != NULL) {
-    free(resourceList->outputTensorDesc);
-    resourceList->outputTensorDesc = NULL;
-  }
-
-  if (resourceList->loadableData != NULL) {
-    free(resourceList->loadableData);
-    resourceList->loadableData = NULL;
-  }
-
-  if (resourceList->moduleHandle != NULL) {
-    cudlaModuleUnload(resourceList->moduleHandle, 0);
-    resourceList->moduleHandle = NULL;
-  }
-
-  if (resourceList->devHandle != NULL) {
-    cudlaDestroyDevice(resourceList->devHandle);
-    resourceList->devHandle = NULL;
-  }
-
-  if (resourceList->inputBufferGPU != 0) {
-    hipFree(resourceList->inputBufferGPU);
-    resourceList->inputBufferGPU = 0;
-  }
-  if (resourceList->outputBufferGPU != 0) {
-    hipFree(resourceList->outputBufferGPU);
-    resourceList->outputBufferGPU = 0;
-  }
-
-  if (resourceList->inputBuffer != NULL) {
-    free(resourceList->inputBuffer);
-    resourceList->inputBuffer = NULL;
-  }
-  if (resourceList->outputBuffer != NULL) {
-    free(resourceList->outputBuffer);
-    resourceList->outputBuffer = NULL;
-  }
-
-  if (resourceList->stream != NULL) {
-    hipStreamDestroy(resourceList->stream);
-    resourceList->stream = NULL;
-  }
-}
-
-int main(int argc, char** argv) {
-  cudlaDevHandle devHandle;
-  cudlaModule moduleHandle;
-  cudlaStatus err;
-  FILE* fp = NULL;
-  struct stat st;
-  size_t file_size;
-  size_t actually_read = 0;
-  unsigned char* loadableData = NULL;
-
-  hipStream_t stream;
-  hipError_t result;
-  const char* errPtr = NULL;
-
-  ResourceList resourceList;
-
-  memset(&resourceList, 0x00, sizeof(ResourceList));
-
-  if (argc != 2) {
-    DPRINTF("Usage : ./cuDLAErrorReporting <loadable>\n");
-    return 1;
-  }
-
-  // Read loadable into buffer.
-  fp = fopen(argv[1], "rb");
-  if (fp == NULL) {
-    DPRINTF("Cannot open file %s\n", argv[1]);
-    return 1;
-  }
-
-  if (stat(argv[1], &st) != 0) {
-    DPRINTF("Cannot stat file\n");
-    return 1;
-  }
-
-  file_size = st.st_size;
-  DPRINTF("The file size = %ld\n", file_size);
-
-  loadableData = (unsigned char*)malloc(file_size);
-  if (loadableData == NULL) {
-    DPRINTF("Cannot Allocate memory for loadable\n");
-    return 1;
-  }
-
-  actually_read = fread(loadableData, 1, file_size, fp);
-  if (actually_read != file_size) {
-    free(loadableData);
-    DPRINTF("Read wrong size\n");
-    return 1;
-  }
-  fclose(fp);
-
-  resourceList.loadableData = loadableData;
-
-  // Initialize CUDA.
-  result = hipFree(0);
-  if (result != hipSuccess) {
-    errPtr = hipGetErrorName(result);
-    DPRINTF("Error in creating hipFree = %s\n", errPtr);
-    cleanUp(&resourceList);
-    return 1;
-  }
-  result = hipSetDevice(0);
-  if (result != hipSuccess) {
-    errPtr = hipGetErrorName(result);
-    DPRINTF("Error in creating hipSetDevice = %s\n", errPtr);
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  err = cudlaCreateDevice(0, &devHandle, CUDLA_CUDA_DLA);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in cuDLA create device = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  DPRINTF("Device created successfully\n");
-  resourceList.devHandle = devHandle;
-
-  err = cudlaModuleLoadFromMemory(devHandle, loadableData, file_size,
-                                  &moduleHandle, 0);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in cudlaModuleLoadFromMemory = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  } else {
-    DPRINTF("Successfully loaded module\n");
-  }
-
-  resourceList.moduleHandle = moduleHandle;
-
-  // Create CUDA stream.
-  result = hipStreamCreateWithFlags(&stream, hipStreamNonBlocking);
-
-  if (result != hipSuccess) {
-    errPtr = hipGetErrorName(result);
-    DPRINTF("Error in creating cuda stream = %s\n", errPtr);
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  resourceList.stream = stream;
-
-  // Get tensor attributes.
-  uint32_t numInputTensors = 0;
-  uint32_t numOutputTensors = 0;
-  cudlaModuleAttribute attribute;
-
-  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_NUM_INPUT_TENSORS,
-                                 &attribute);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in getting numInputTensors = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-  numInputTensors = attribute.numInputTensors;
-  DPRINTF("numInputTensors = %d\n", numInputTensors);
-
-  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_NUM_OUTPUT_TENSORS,
-                                 &attribute);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in getting numOutputTensors = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-  numOutputTensors = attribute.numOutputTensors;
-  DPRINTF("numOutputTensors = %d\n", numOutputTensors);
-
-  cudlaModuleTensorDescriptor* inputTensorDesc =
-      (cudlaModuleTensorDescriptor*)malloc(sizeof(cudlaModuleTensorDescriptor) *
-                                           numInputTensors);
-  cudlaModuleTensorDescriptor* outputTensorDesc =
-      (cudlaModuleTensorDescriptor*)malloc(sizeof(cudlaModuleTensorDescriptor) *
-                                           numOutputTensors);
-
-  if ((inputTensorDesc == NULL) || (outputTensorDesc == NULL)) {
-    if (inputTensorDesc != NULL) {
-      free(inputTensorDesc);
-      inputTensorDesc = NULL;
-    }
-
-    if (outputTensorDesc != NULL) {
-      free(outputTensorDesc);
-      outputTensorDesc = NULL;
-    }
-
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  resourceList.inputTensorDesc = inputTensorDesc;
-  resourceList.outputTensorDesc = outputTensorDesc;
-
-  attribute.inputTensorDesc = inputTensorDesc;
-  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_INPUT_TENSOR_DESCRIPTORS,
-                                 &attribute);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in getting input tensor descriptor = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-  DPRINTF("Printing input tensor descriptor\n");
-  printTensorDesc(inputTensorDesc);
-
-  attribute.outputTensorDesc = outputTensorDesc;
-  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_OUTPUT_TENSOR_DESCRIPTORS,
-                                 &attribute);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in getting output tensor descriptor = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-  DPRINTF("Printing output tensor descriptor\n");
-  printTensorDesc(outputTensorDesc);
-
-  // Setup the input and output buffers which will be used as an input to CUDA.
-  unsigned char* inputBuffer = (unsigned char*)malloc(inputTensorDesc[0].size);
-  if (inputBuffer == NULL) {
-    DPRINTF("Error in allocating input memory\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  resourceList.inputBuffer = inputBuffer;
-
-  unsigned char* outputBuffer =
-      (unsigned char*)malloc(outputTensorDesc[0].size);
-  if (outputBuffer == NULL) {
-    DPRINTF("Error in allocating output memory\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  resourceList.outputBuffer = outputBuffer;
-
-  memset(inputBuffer, 0x01, inputTensorDesc[0].size);
-  memset(outputBuffer, 0x00, outputTensorDesc[0].size);
-
-  // Allocate memory on GPU.
-  void* inputBufferGPU;
-  void* outputBufferGPU;
-  result = hipMalloc(&inputBufferGPU, inputTensorDesc[0].size);
-  if (result != hipSuccess) {
-    DPRINTF("Error in allocating input memory on GPU\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  resourceList.inputBufferGPU = inputBufferGPU;
-
-  result = hipMalloc(&outputBufferGPU, outputTensorDesc[0].size);
-  if (result != hipSuccess) {
-    DPRINTF("Error in allocating output memory on GPU\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  resourceList.outputBufferGPU = outputBufferGPU;
-
-  // Register the CUDA-allocated buffers.
-  uint64_t* inputBufferRegisteredPtr = NULL;
-  uint64_t* outputBufferRegisteredPtr = NULL;
-
-  err = cudlaMemRegister(devHandle, (uint64_t*)inputBufferGPU,
-                         inputTensorDesc[0].size, &inputBufferRegisteredPtr, 0);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in registering input memory = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  err =
-      cudlaMemRegister(devHandle, (uint64_t*)outputBufferGPU,
-                       outputTensorDesc[0].size, &outputBufferRegisteredPtr, 0);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in registering output memory = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-  DPRINTF("ALL MEMORY REGISTERED SUCCESSFULLY\n");
-
-  // Copy data from CPU buffers to GPU buffers.
-  result = hipMemcpyAsync(inputBufferGPU, inputBuffer, inputTensorDesc[0].size,
-                           hipMemcpyHostToDevice, stream);
-  if (result != hipSuccess) {
-    DPRINTF("Error in enqueueing memcpy for input\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-  result =
-      hipMemsetAsync(outputBufferGPU, 0, outputTensorDesc[0].size, stream);
-  if (result != hipSuccess) {
-    DPRINTF("Error in enqueueing memset for output\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  // Enqueue a cuDLA task.
-  cudlaTask task;
-  task.moduleHandle = moduleHandle;
-  task.outputTensor = &outputBufferRegisteredPtr;
-  task.numOutputTensors = 1;
-  task.numInputTensors = 1;
-  task.inputTensor = &inputBufferRegisteredPtr;
-  task.waitEvents = NULL;
-  task.signalEvents = NULL;
-  err = cudlaSubmitTask(devHandle, &task, 1, stream, 0);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in submitting task\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-  DPRINTF("SUBMIT IS DONE !!!\n");
-
-  // Wait for stream operations to finish and bring output buffer to CPU.
-  result =
-      hipMemcpyAsync(outputBuffer, outputBufferGPU, outputTensorDesc[0].size,
-                      hipMemcpyDeviceToHost, stream);
-  if (result != hipSuccess) {
-    if (result != cudaErrorExternalDevice) {
-      DPRINTF("Error in bringing result back to CPU\n");
-      cleanUp(&resourceList);
-      return 1;
-    } else {
-      cudlaStatus hwStatus = cudlaGetLastError(devHandle);
-      if (hwStatus != cudlaSuccess) {
-        DPRINTF("Asynchronous error in HW = %u\n", hwStatus);
-      }
-    }
-  }
-
-  result = hipStreamSynchronize(stream);
-  if (result != hipSuccess) {
-    DPRINTF("Error in synchronizing stream = %s\n", hipGetErrorName(result));
-
-    if (result == cudaErrorExternalDevice) {
-      cudlaStatus hwStatus = cudlaGetLastError(devHandle);
-      if (hwStatus != cudlaSuccess) {
-        DPRINTF("Asynchronous error in HW = %u\n", hwStatus);
-      }
-    }
-  }
-
-  cleanUp(&resourceList);
-
-  DPRINTF("cuDLAErrorReporting DONE !!!\n");
-
-  return 0;
-}
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/README.md b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/main.cu b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/main.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/main.cu.hip b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/main.cu.hip
old mode 100644
new mode 100755
index ecaf605..e69de29
--- a/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/main.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/cuDLAHybridMode/main.cu.hip
@@ -1,496 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "cudla.h"
-#include "hip/hip_runtime.h"
-
-#include <cstdio>
-#include <cstdlib>
-#include <cstring>
-#include <sys/stat.h>
-#include <fstream>
-#include <sstream>
-
-#define DPRINTF(...) printf(__VA_ARGS__)
-
-static void printTensorDesc(cudlaModuleTensorDescriptor* tensorDesc) {
-  DPRINTF("\tTENSOR NAME : %s\n", tensorDesc->name);
-  DPRINTF("\tsize: %lu\n", tensorDesc->size);
-
-  DPRINTF("\tdims: [%lu, %lu, %lu, %lu]\n", tensorDesc->n, tensorDesc->c,
-          tensorDesc->h, tensorDesc->w);
-
-  DPRINTF("\tdata fmt: %d\n", tensorDesc->dataFormat);
-  DPRINTF("\tdata type: %d\n", tensorDesc->dataType);
-  DPRINTF("\tdata category: %d\n", tensorDesc->dataCategory);
-  DPRINTF("\tpixel fmt: %d\n", tensorDesc->pixelFormat);
-  DPRINTF("\tpixel mapping: %d\n", tensorDesc->pixelMapping);
-  DPRINTF("\tstride[0]: %d\n", tensorDesc->stride[0]);
-  DPRINTF("\tstride[1]: %d\n", tensorDesc->stride[1]);
-  DPRINTF("\tstride[2]: %d\n", tensorDesc->stride[2]);
-  DPRINTF("\tstride[3]: %d\n", tensorDesc->stride[3]);
-}
-
-static int initializeInputBuffers(char* filePath,
-                                  cudlaModuleTensorDescriptor* tensorDesc,
-                                  unsigned char* buf) {
-  // Read the file in filePath and fill up 'buf' according to format
-  // specified by the user.
-
-  return 0;
-}
-
-typedef struct {
-  cudlaDevHandle devHandle;
-  cudlaModule moduleHandle;
-  unsigned char* loadableData;
-  hipStream_t stream;
-  unsigned char* inputBuffer;
-  unsigned char* outputBuffer;
-  void* inputBufferGPU;
-  void* outputBufferGPU;
-  cudlaModuleTensorDescriptor* inputTensorDesc;
-  cudlaModuleTensorDescriptor* outputTensorDesc;
-} ResourceList;
-
-void cleanUp(ResourceList* resourceList);
-
-void cleanUp(ResourceList* resourceList) {
-  if (resourceList->inputTensorDesc != NULL) {
-    free(resourceList->inputTensorDesc);
-    resourceList->inputTensorDesc = NULL;
-  }
-  if (resourceList->outputTensorDesc != NULL) {
-    free(resourceList->outputTensorDesc);
-    resourceList->outputTensorDesc = NULL;
-  }
-
-  if (resourceList->loadableData != NULL) {
-    free(resourceList->loadableData);
-    resourceList->loadableData = NULL;
-  }
-
-  if (resourceList->moduleHandle != NULL) {
-    cudlaModuleUnload(resourceList->moduleHandle, 0);
-    resourceList->moduleHandle = NULL;
-  }
-
-  if (resourceList->devHandle != NULL) {
-    cudlaDestroyDevice(resourceList->devHandle);
-    resourceList->devHandle = NULL;
-  }
-
-  if (resourceList->inputBufferGPU != 0) {
-    hipFree(resourceList->inputBufferGPU);
-    resourceList->inputBufferGPU = 0;
-  }
-  if (resourceList->outputBufferGPU != 0) {
-    hipFree(resourceList->outputBufferGPU);
-    resourceList->outputBufferGPU = 0;
-  }
-
-  if (resourceList->inputBuffer != NULL) {
-    free(resourceList->inputBuffer);
-    resourceList->inputBuffer = NULL;
-  }
-  if (resourceList->outputBuffer != NULL) {
-    free(resourceList->outputBuffer);
-    resourceList->outputBuffer = NULL;
-  }
-
-  if (resourceList->stream != NULL) {
-    hipStreamDestroy(resourceList->stream);
-    resourceList->stream = NULL;
-  }
-}
-
-int main(int argc, char** argv) {
-  cudlaDevHandle devHandle;
-  cudlaModule moduleHandle;
-  cudlaStatus err;
-  FILE* fp = NULL;
-  struct stat st;
-  size_t file_size;
-  size_t actually_read = 0;
-  unsigned char* loadableData = NULL;
-
-  hipStream_t stream;
-  hipError_t result;
-  const char* errPtr = NULL;
-
-  ResourceList resourceList;
-
-  memset(&resourceList, 0x00, sizeof(ResourceList));
-
-  if (argc != 3) {
-    DPRINTF("Usage : ./cuDLAHybridMode <loadable> <imageFile>\n");
-    return 1;
-  }
-
-  // Read loadable into buffer.
-  fp = fopen(argv[1], "rb");
-  if (fp == NULL) {
-    DPRINTF("Cannot open file %s\n", argv[1]);
-    return 1;
-  }
-
-  if (stat(argv[1], &st) != 0) {
-    DPRINTF("Cannot stat file\n");
-    return 1;
-  }
-
-  file_size = st.st_size;
-  DPRINTF("The file size = %ld\n", file_size);
-
-  loadableData = (unsigned char*)malloc(file_size);
-  if (loadableData == NULL) {
-    DPRINTF("Cannot Allocate memory for loadable\n");
-    return 1;
-  }
-
-  actually_read = fread(loadableData, 1, file_size, fp);
-  if (actually_read != file_size) {
-    free(loadableData);
-    DPRINTF("Read wrong size\n");
-    return 1;
-  }
-  fclose(fp);
-
-  resourceList.loadableData = loadableData;
-
-  // Initialize CUDA.
-  result = hipFree(0);
-  if (result != hipSuccess) {
-    errPtr = hipGetErrorName(result);
-    DPRINTF("Error in creating hipFree = %s\n", errPtr);
-    cleanUp(&resourceList);
-    return 1;
-  }
-  result = hipSetDevice(0);
-  if (result != hipSuccess) {
-    errPtr = hipGetErrorName(result);
-    DPRINTF("Error in creating hipSetDevice = %s\n", errPtr);
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  err = cudlaCreateDevice(0, &devHandle, CUDLA_CUDA_DLA);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in cuDLA create device = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  DPRINTF("Device created successfully\n");
-  resourceList.devHandle = devHandle;
-
-  err = cudlaModuleLoadFromMemory(devHandle, loadableData, file_size,
-                                  &moduleHandle, 0);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in cudlaModuleLoadFromMemory = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  } else {
-    DPRINTF("Successfully loaded module\n");
-  }
-
-  resourceList.moduleHandle = moduleHandle;
-
-  // Create CUDA stream.
-  result = hipStreamCreateWithFlags(&stream, hipStreamNonBlocking);
-
-  if (result != hipSuccess) {
-    errPtr = hipGetErrorName(result);
-    DPRINTF("Error in creating cuda stream = %s\n", errPtr);
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  resourceList.stream = stream;
-
-  // Get tensor attributes.
-  uint32_t numInputTensors = 0;
-  uint32_t numOutputTensors = 0;
-  cudlaModuleAttribute attribute;
-
-  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_NUM_INPUT_TENSORS,
-                                 &attribute);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in getting numInputTensors = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-  numInputTensors = attribute.numInputTensors;
-  DPRINTF("numInputTensors = %d\n", numInputTensors);
-
-  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_NUM_OUTPUT_TENSORS,
-                                 &attribute);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in getting numOutputTensors = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-  numOutputTensors = attribute.numOutputTensors;
-  DPRINTF("numOutputTensors = %d\n", numOutputTensors);
-
-  cudlaModuleTensorDescriptor* inputTensorDesc =
-      (cudlaModuleTensorDescriptor*)malloc(sizeof(cudlaModuleTensorDescriptor) *
-                                           numInputTensors);
-  cudlaModuleTensorDescriptor* outputTensorDesc =
-      (cudlaModuleTensorDescriptor*)malloc(sizeof(cudlaModuleTensorDescriptor) *
-                                           numOutputTensors);
-
-  if ((inputTensorDesc == NULL) || (outputTensorDesc == NULL)) {
-    if (inputTensorDesc != NULL) {
-      free(inputTensorDesc);
-      inputTensorDesc = NULL;
-    }
-
-    if (outputTensorDesc != NULL) {
-      free(outputTensorDesc);
-      outputTensorDesc = NULL;
-    }
-
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  resourceList.inputTensorDesc = inputTensorDesc;
-  resourceList.outputTensorDesc = outputTensorDesc;
-
-  attribute.inputTensorDesc = inputTensorDesc;
-  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_INPUT_TENSOR_DESCRIPTORS,
-                                 &attribute);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in getting input tensor descriptor = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-  DPRINTF("Printing input tensor descriptor\n");
-  printTensorDesc(inputTensorDesc);
-
-  attribute.outputTensorDesc = outputTensorDesc;
-  err = cudlaModuleGetAttributes(moduleHandle, CUDLA_OUTPUT_TENSOR_DESCRIPTORS,
-                                 &attribute);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in getting output tensor descriptor = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-  DPRINTF("Printing output tensor descriptor\n");
-  printTensorDesc(outputTensorDesc);
-
-  // Setup the input and output buffers which will be used as an input to CUDA.
-  unsigned char* inputBuffer = (unsigned char*)malloc(inputTensorDesc[0].size);
-  if (inputBuffer == NULL) {
-    DPRINTF("Error in allocating input memory\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  resourceList.inputBuffer = inputBuffer;
-
-  unsigned char* outputBuffer =
-      (unsigned char*)malloc(outputTensorDesc[0].size);
-  if (outputBuffer == NULL) {
-    DPRINTF("Error in allocating output memory\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  resourceList.outputBuffer = outputBuffer;
-
-  memset(inputBuffer, 0x00, inputTensorDesc[0].size);
-  memset(outputBuffer, 0x00, outputTensorDesc[0].size);
-
-  // Fill up the buffers with data.
-  if (initializeInputBuffers(argv[2], inputTensorDesc, inputBuffer) != 0) {
-    DPRINTF("Error in initializing input buffer\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  // Allocate memory on GPU.
-  void* inputBufferGPU;
-  void* outputBufferGPU;
-  result = hipMalloc(&inputBufferGPU, inputTensorDesc[0].size);
-  if (result != hipSuccess) {
-    DPRINTF("Error in allocating input memory on GPU\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  resourceList.inputBufferGPU = inputBufferGPU;
-
-  result = hipMalloc(&outputBufferGPU, outputTensorDesc[0].size);
-  if (result != hipSuccess) {
-    DPRINTF("Error in allocating output memory on GPU\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  resourceList.outputBufferGPU = outputBufferGPU;
-
-  // Register the CUDA-allocated buffers.
-  uint64_t* inputBufferRegisteredPtr = NULL;
-  uint64_t* outputBufferRegisteredPtr = NULL;
-
-  err = cudlaMemRegister(devHandle, (uint64_t*)inputBufferGPU,
-                         inputTensorDesc[0].size, &inputBufferRegisteredPtr, 0);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in registering input memory = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  err =
-      cudlaMemRegister(devHandle, (uint64_t*)outputBufferGPU,
-                       outputTensorDesc[0].size, &outputBufferRegisteredPtr, 0);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in registering output memory = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-  DPRINTF("ALL MEMORY REGISTERED SUCCESSFULLY\n");
-
-  // Copy data from CPU buffers to GPU buffers.
-  result = hipMemcpyAsync(inputBufferGPU, inputBuffer, inputTensorDesc[0].size,
-                           hipMemcpyHostToDevice, stream);
-  if (result != hipSuccess) {
-    DPRINTF("Error in enqueueing memcpy for input\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-  result =
-      hipMemsetAsync(outputBufferGPU, 0, outputTensorDesc[0].size, stream);
-  if (result != hipSuccess) {
-    DPRINTF("Error in enqueueing memset for output\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  // Enqueue a cuDLA task.
-  cudlaTask task;
-  task.moduleHandle = moduleHandle;
-  task.outputTensor = &outputBufferRegisteredPtr;
-  task.numOutputTensors = 1;
-  task.numInputTensors = 1;
-  task.inputTensor = &inputBufferRegisteredPtr;
-  task.waitEvents = NULL;
-  task.signalEvents = NULL;
-  err = cudlaSubmitTask(devHandle, &task, 1, stream, 0);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in submitting task\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-  DPRINTF("SUBMIT IS DONE !!!\n");
-
-  // Wait for stream operations to finish and bring output buffer to CPU.
-  result =
-      hipMemcpyAsync(outputBuffer, outputBufferGPU, outputTensorDesc[0].size,
-                      hipMemcpyDeviceToHost, stream);
-  if (result != hipSuccess) {
-    DPRINTF("Error in bringing result back to CPU\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-  result = hipStreamSynchronize(stream);
-  if (result != hipSuccess) {
-    DPRINTF("Error in synchronizing stream\n");
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  // Output is available in outputBuffer.
-
-  // Teardown.
-  err = cudlaMemUnregister(devHandle, inputBufferRegisteredPtr);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in unregistering input memory = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  err = cudlaMemUnregister(devHandle, outputBufferRegisteredPtr);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in registering output memory = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  }
-  DPRINTF("ALL MEMORY UNREGISTERED SUCCESSFULLY\n");
-
-  free(inputTensorDesc);
-  free(outputTensorDesc);
-  free(loadableData);
-  free(inputBuffer);
-  free(outputBuffer);
-  hipFree(inputBufferGPU);
-  hipFree(outputBufferGPU);
-
-  resourceList.inputTensorDesc = NULL;
-  resourceList.outputTensorDesc = NULL;
-  resourceList.loadableData = NULL;
-  resourceList.inputBuffer = NULL;
-  resourceList.outputBuffer = NULL;
-  resourceList.inputBufferGPU = 0;
-  resourceList.outputBufferGPU = 0;
-
-  result = hipStreamDestroy(stream);
-  if (result != hipSuccess) {
-    errPtr = hipGetErrorName(result);
-    DPRINTF("Error in destroying cuda stream = %s\n", errPtr);
-    cleanUp(&resourceList);
-    return 1;
-  }
-
-  resourceList.stream = NULL;
-
-  err = cudlaModuleUnload(moduleHandle, 0);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in cudlaModuleUnload = %d\n", err);
-    cleanUp(&resourceList);
-    return 1;
-  } else {
-    DPRINTF("Successfully unloaded module\n");
-  }
-
-  resourceList.moduleHandle = NULL;
-
-  err = cudlaDestroyDevice(devHandle);
-  if (err != cudlaSuccess) {
-    DPRINTF("Error in cuDLA destroy device = %d\n", err);
-    return 1;
-  }
-  DPRINTF("Device destroyed successfully\n");
-
-  resourceList.devHandle = NULL;
-
-  DPRINTF("cuDLAHybridMode DONE !!!\n");
-
-  return 0;
-}
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/README.md b/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/findnvsci.mk b/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/findnvsci.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/main.cpp b/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/main_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cuDLAStandaloneMode/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/README.md b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/cuSolverDn_LinearSolver_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/gr_900_900_crg.mtx b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/gr_900_900_crg.mtx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/lap3D_7pt_n20.mtx b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/lap3D_7pt_n20.mtx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/mmio.c b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/mmio.c
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/mmio.h b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/mmio.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/mmio_hipified.h b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/mmio_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/mmio_wrapper.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/mmio_wrapper.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/mmio_wrapper_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverDn_LinearSolver/mmio_wrapper_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/README.md b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/cuSolverRf_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/lap2D_5pt_n100.mtx b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/lap2D_5pt_n100.mtx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/lap3D_7pt_n20.mtx b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/lap3D_7pt_n20.mtx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/mmio.c b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/mmio.c
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/mmio.h b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/mmio.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/mmio_hipified.h b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/mmio_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/mmio_wrapper.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/mmio_wrapper.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/mmio_wrapper_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverRf/mmio_wrapper_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/README.md b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/cuSolverSp_LinearSolver_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/lap2D_5pt_n100.mtx b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/lap2D_5pt_n100.mtx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/lap3D_7pt_n20.mtx b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/lap3D_7pt_n20.mtx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/mmio.c b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/mmio.c
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/mmio.h b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/mmio.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/mmio_hipified.h b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/mmio_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/mmio_wrapper.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/mmio_wrapper.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/mmio_wrapper_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LinearSolver/mmio_wrapper_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/README.md b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/cuSolverSp_LowlevelCholesky_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/lap2D_5pt_n100.mtx b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/lap2D_5pt_n100.mtx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/lap3D_7pt_n20.mtx b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/lap3D_7pt_n20.mtx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/mmio.c b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/mmio.c
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/mmio.h b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/mmio.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/mmio_hipified.h b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/mmio_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/mmio_wrapper.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/mmio_wrapper.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/mmio_wrapper_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelCholesky/mmio_wrapper_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/Makefile b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/README.md b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/cuSolverSp_LowlevelQR_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/lap2D_5pt_n100.mtx b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/lap2D_5pt_n100.mtx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/lap2D_5pt_n32.mtx b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/lap2D_5pt_n32.mtx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/lap3D_7pt_n20.mtx b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/lap3D_7pt_n20.mtx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/mmio.c b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/mmio.c
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/mmio.h b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/mmio.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/mmio_hipified.h b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/mmio_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/mmio_wrapper.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/mmio_wrapper.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/mmio_wrapper_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cuSolverSp_LowlevelQR/mmio_wrapper_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/Makefile b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/README.md b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/cudaNvSci.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/cudaNvSci.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/cudaNvSci.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/cudaNvSci.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/cudaNvSci_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/cudaNvSci_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/cudaNvSci_hipified.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/cudaNvSci_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/findnvsci.mk b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/findnvsci.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/imageKernels.cu b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/imageKernels.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/imageKernels.cu.hip b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/imageKernels.cu.hip
old mode 100644
new mode 100755
index 0e89211..e69de29
--- a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/imageKernels.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/imageKernels.cu.hip
@@ -1,121 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <hip/hip_runtime.h>
-#include "helper_cuda_hipified.h"
-#include <helper_image.h>
-
-// convert floating point rgba color to 32-bit integer
-__device__ unsigned int rgbaFloatToInt(float4 rgba) {
-  rgba.x = __saturatef(rgba.x);  // clamp to [0.0, 1.0]
-  rgba.y = __saturatef(rgba.y);
-  rgba.z = __saturatef(rgba.z);
-  rgba.w = __saturatef(rgba.w);
-  return ((unsigned int)(rgba.w * 255.0f) << 24) |
-         ((unsigned int)(rgba.z * 255.0f) << 16) |
-         ((unsigned int)(rgba.y * 255.0f) << 8) |
-         ((unsigned int)(rgba.x * 255.0f));
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Rotate an image using texture lookups
-//! @param outputData  output data in global memory
-////////////////////////////////////////////////////////////////////////////////
-static __global__ void transformKernel(unsigned int *outputData, int width,
-                                       int height, float theta,
-                                       hipTextureObject_t tex) {
-  // calculate normalized texture coordinates
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  float u = (float)x - (float)width / 2;
-  float v = (float)y - (float)height / 2;
-  float tu = u * cosf(theta) - v * sinf(theta);
-  float tv = v * cosf(theta) + u * sinf(theta);
-
-  tu /= (float)width;
-  tv /= (float)height;
-
-  // read from texture and write to global memory
-  float4 pix = tex2D<float4>(tex, tu + 0.5f, tv + 0.5f);
-  unsigned int pixelInt = rgbaFloatToInt(pix);
-  outputData[y * width + x] = pixelInt;
-}
-
-static __global__ void rgbToGrayscaleKernel(unsigned int *rgbaImage,
-                                            size_t imageWidth,
-                                            size_t imageHeight) {
-  size_t gidX = blockDim.x * blockIdx.x + threadIdx.x;
-
-  uchar4 *pixArray = (uchar4 *)rgbaImage;
-
-  for (int pixId = gidX; pixId < imageWidth * imageHeight;
-       pixId += gridDim.x * blockDim.x) {
-    uchar4 dataA = pixArray[pixId];
-    unsigned char grayscale =
-        (unsigned char)(dataA.x * 0.3 + dataA.y * 0.59 + dataA.z * 0.11);
-    uchar4 dataB = make_uchar4(grayscale, grayscale, grayscale, 0);
-    pixArray[pixId] = dataB;
-  }
-}
-
-void launchGrayScaleKernel(unsigned int *d_rgbaImage,
-                           std::string image_filename, size_t imageWidth,
-                           size_t imageHeight, hipStream_t stream) {
-  int numThreadsPerBlock = 1024;
-  int numOfBlocks = (imageWidth * imageHeight) / numThreadsPerBlock;
-
-  rgbToGrayscaleKernel<<<numOfBlocks, numThreadsPerBlock, 0, stream>>>(
-      d_rgbaImage, imageWidth, imageHeight);
-
-  unsigned int *outputData;
-  HIPCHECK(hipHostMalloc((void**)&outputData, sizeof(unsigned int) * imageWidth * imageHeight));
-  HIPCHECK(hipMemcpyAsync(
-      outputData, d_rgbaImage, sizeof(unsigned int) * imageWidth * imageHeight,
-      hipMemcpyDeviceToHost, stream));
-  HIPCHECK(hipStreamSynchronize(stream));
-
-  char outputFilename[1024];
-  strcpy(outputFilename, image_filename.c_str());
-  strcpy(outputFilename + image_filename.length() - 4, "_out.ppm");
-  sdkSavePPM4ub(outputFilename, (unsigned char *)outputData, imageWidth,
-                imageHeight);
-  printf("Wrote '%s'\n", outputFilename);
-
-  HIPCHECK(hipHostFree(outputData));
-}
-
-void rotateKernel(hipTextureObject_t &texObj, const float angle,
-                  unsigned int *d_outputData, const int imageWidth,
-                  const int imageHeight, hipStream_t stream) {
-  dim3 dimBlock(8, 8, 1);
-  dim3 dimGrid(imageWidth / dimBlock.x, imageHeight / dimBlock.y, 1);
-
-  transformKernel<<<dimGrid, dimBlock, 0, stream>>>(d_outputData, imageWidth,
-                                                    imageHeight, angle, texObj);
-}
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/main.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/main_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/teapot1024.ppm b/src/samples/Samples/4_CUDA_Libraries/cudaNvSci/teapot1024.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/Makefile b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/README.md b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cudaNvSciNvMedia_Readme.pdf b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cudaNvSciNvMedia_Readme.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer.cu b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer.cu.hip b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer.cu.hip
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer_hipified.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/cuda_consumer_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/findnvmedia.mk b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/findnvmedia.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/findnvsci.mk b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/findnvsci.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/main.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/main_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer_hipified.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_producer_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/cmdline.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/cmdline.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/cmdline.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/cmdline.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/cmdline_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/cmdline_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/cmdline_hipified.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/cmdline_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/config_parser.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/config_parser.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/config_parser.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/config_parser.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/config_parser_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/config_parser_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/config_parser_hipified.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/config_parser_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/image_utils.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/image_utils.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/image_utils.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/image_utils.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/image_utils_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/image_utils_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/image_utils_hipified.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/image_utils_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/log_utils.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/log_utils.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/log_utils.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/log_utils.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/log_utils_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/log_utils_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/log_utils_hipified.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/log_utils_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/misc_utils.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/misc_utils.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/misc_utils.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/misc_utils.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/misc_utils_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/misc_utils_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/misc_utils_hipified.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvmedia_utils/misc_utils_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvsci_setup.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvsci_setup.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvsci_setup.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvsci_setup.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvsci_setup_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvsci_setup_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvsci_setup_hipified.h b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/nvsci_setup_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/sample.cfg b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/sample.cfg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/teapot.rgba b/src/samples/Samples/4_CUDA_Libraries/cudaNvSciNvMedia/teapot.rgba
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/Makefile b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/README.md b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP.cpp b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/freeImageInteropNPP/freeImageInteropNPP_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/Makefile b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/README.md b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP.cpp b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/histEqualizationNPP/histEqualizationNPP_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/Makefile b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/README.md b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight.cu b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight.cu.hip b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight.cu.hip
old mode 100644
new mode 100755
index f1f9181..b9d0a43
--- a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight.cu.hip
@@ -41,8 +41,6 @@
 // includes, system
 #include <stdlib.h>
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <string.h>
 #include <math.h>
 #include <float.h>
@@ -154,11 +152,11 @@ int runTest(int argc, char **argv) {
   hipChannelFormatDesc channelDesc =
       hipCreateChannelDesc(32, 0, 0, 0, hipChannelFormatKindFloat);
   hipArray *heightFieldArray;
-  HIPCHECK(
+  checkCudaErrors(
       hipMallocArray(&heightFieldArray, &channelDesc, dim.x, dim.y));
 
   // Initialize device memory
-  HIPCHECK(hipMemcpy2DToArray(
+  checkCudaErrors(hipMemcpy2DToArray(
       heightFieldArray, 0, 0, heightField.height, dim.x * sizeof(float),
       dim.x * sizeof(float), dim.y, hipMemcpyHostToDevice));
 
@@ -177,7 +175,7 @@ int runTest(int argc, char **argv) {
   texDescr.addressMode[1] = hipAddressModeClamp;
   texDescr.readMode = hipReadModeElementType;
 
-  HIPCHECK(
+  checkCudaErrors(
       hipCreateTextureObject(&heightFieldTex, &texRes, &texDescr, NULL));
 
   //////////////////////////////////////////////////////////////////////////////
@@ -258,7 +256,7 @@ int runTest(int argc, char **argv) {
   sdkResetTimer(&timer);
 
   // Cleanup memory
-  HIPCHECK(hipFreeArray(heightFieldArray));
+  checkCudaErrors(hipFreeArray(heightFieldArray));
   return res;
 }
 
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/lineOfSight/lineOfSight_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/Makefile b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/README.md b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS.cpp b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/matrixMulCUBLAS_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/Makefile b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/README.md b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img1.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img1.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img2.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img2.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img3.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img3.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img4.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img4.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img5.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img5.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img6.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img6.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img7.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img7.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img8.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/images/img8.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG.cpp b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/nvJPEG/nvJPEG_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/Makefile b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/README.md b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img1.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img1.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img2.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img2.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img3.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img3.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img4.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img4.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img5.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img5.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img6.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img6.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img7.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img7.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img8.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/encode_output/img8.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img1.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img1.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img2.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img2.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img3.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img3.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img4.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img4.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img5.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img5.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img6.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img6.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img7.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img7.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img8.jpg b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/images/img8.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder.cpp b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/nvJPEG_encoder/nvJPEG_encoder_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/Makefile b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/README.md b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/data/ocean.frag b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/data/ocean.frag
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/data/ocean.vert b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/data/ocean.vert
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/data/ref_slopeShading.bin b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/data/ref_slopeShading.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/data/ref_spatialDomain.bin b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/data/ref_spatialDomain.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/data/reference.ppm b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/data/reference.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/doc/sshot_lg.png b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/doc/sshot_lg.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/doc/sshot_md.png b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/doc/sshot_md.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/doc/sshot_sm.png b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/doc/sshot_sm.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/findgllib.mk b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT.cpp b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_kernel.cu b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_kernel.cu.hip b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_kernel.cu.hip
old mode 100644
new mode 100755
index 16d309d..e69de29
--- a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_kernel.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_kernel.cu.hip
@@ -1,160 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-///////////////////////////////////////////////////////////////////////////////
-#include <hipfft.h>
-#include <math_constants.h>
-
-// Round a / b to nearest higher integer value
-int cuda_iDivUp(int a, int b) { return (a + (b - 1)) / b; }
-
-// complex math functions
-__device__ float2 conjugate(float2 arg) { return make_float2(arg.x, -arg.y); }
-
-__device__ float2 complex_exp(float arg) {
-  return make_float2(cosf(arg), sinf(arg));
-}
-
-__device__ float2 complex_add(float2 a, float2 b) {
-  return make_float2(a.x + b.x, a.y + b.y);
-}
-
-__device__ float2 complex_mult(float2 ab, float2 cd) {
-  return make_float2(ab.x * cd.x - ab.y * cd.y, ab.x * cd.y + ab.y * cd.x);
-}
-
-// generate wave heightfield at time t based on initial heightfield and
-// dispersion relationship
-__global__ void generateSpectrumKernel(float2 *h0, float2 *ht,
-                                       unsigned int in_width,
-                                       unsigned int out_width,
-                                       unsigned int out_height, float t,
-                                       float patchSize) {
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-  unsigned int in_index = y * in_width + x;
-  unsigned int in_mindex =
-      (out_height - y) * in_width + (out_width - x);  // mirrored
-  unsigned int out_index = y * out_width + x;
-
-  // calculate wave vector
-  float2 k;
-  k.x = (-(int)out_width / 2.0f + x) * (2.0f * CUDART_PI_F / patchSize);
-  k.y = (-(int)out_width / 2.0f + y) * (2.0f * CUDART_PI_F / patchSize);
-
-  // calculate dispersion w(k)
-  float k_len = sqrtf(k.x * k.x + k.y * k.y);
-  float w = sqrtf(9.81f * k_len);
-
-  if ((x < out_width) && (y < out_height)) {
-    float2 h0_k = h0[in_index];
-    float2 h0_mk = h0[in_mindex];
-
-    // output frequency-space complex values
-    ht[out_index] =
-        complex_add(complex_mult(h0_k, complex_exp(w * t)),
-                    complex_mult(conjugate(h0_mk), complex_exp(-w * t)));
-    // ht[out_index] = h0_k;
-  }
-}
-
-// update height map values based on output of FFT
-__global__ void updateHeightmapKernel(float *heightMap, float2 *ht,
-                                      unsigned int width) {
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-  unsigned int i = y * width + x;
-
-  // cos(pi * (m1 + m2))
-  float sign_correction = ((x + y) & 0x01) ? -1.0f : 1.0f;
-
-  heightMap[i] = ht[i].x * sign_correction;
-}
-
-// update height map values based on output of FFT
-__global__ void updateHeightmapKernel_y(float *heightMap, float2 *ht,
-                                        unsigned int width) {
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-  unsigned int i = y * width + x;
-
-  // cos(pi * (m1 + m2))
-  float sign_correction = ((x + y) & 0x01) ? -1.0f : 1.0f;
-
-  heightMap[i] = ht[i].y * sign_correction;
-}
-
-// generate slope by partial differences in spatial domain
-__global__ void calculateSlopeKernel(float *h, float2 *slopeOut,
-                                     unsigned int width, unsigned int height) {
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-  unsigned int i = y * width + x;
-
-  float2 slope = make_float2(0.0f, 0.0f);
-
-  if ((x > 0) && (y > 0) && (x < width - 1) && (y < height - 1)) {
-    slope.x = h[i + 1] - h[i - 1];
-    slope.y = h[i + width] - h[i - width];
-  }
-
-  slopeOut[i] = slope;
-}
-
-// wrapper functions
-extern "C" void cudaGenerateSpectrumKernel(float2 *d_h0, float2 *d_ht,
-                                           unsigned int in_width,
-                                           unsigned int out_width,
-                                           unsigned int out_height,
-                                           float animTime, float patchSize) {
-  dim3 block(8, 8, 1);
-  dim3 grid(cuda_iDivUp(out_width, block.x), cuda_iDivUp(out_height, block.y),
-            1);
-  generateSpectrumKernel<<<grid, block>>>(d_h0, d_ht, in_width, out_width,
-                                          out_height, animTime, patchSize);
-}
-
-extern "C" void cudaUpdateHeightmapKernel(float *d_heightMap, float2 *d_ht,
-                                          unsigned int width,
-                                          unsigned int height, bool autoTest) {
-  dim3 block(8, 8, 1);
-  dim3 grid(cuda_iDivUp(width, block.x), cuda_iDivUp(height, block.y), 1);
-  if (autoTest) {
-    updateHeightmapKernel_y<<<grid, block>>>(d_heightMap, d_ht, width);
-  } else {
-    updateHeightmapKernel<<<grid, block>>>(d_heightMap, d_ht, width);
-  }
-}
-
-extern "C" void cudaCalculateSlopeKernel(float *hptr, float2 *slopeOut,
-                                         unsigned int width,
-                                         unsigned int height) {
-  dim3 block(8, 8, 1);
-  dim3 grid2(cuda_iDivUp(width, block.x), cuda_iDivUp(height, block.y), 1);
-  calculateSlopeKernel<<<grid2, block>>>(hptr, slopeOut, width, height);
-}
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/oceanFFT/oceanFFT_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/randomFog/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/randomFog/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/randomFog/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/randomFog/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/Makefile b/src/samples/Samples/4_CUDA_Libraries/randomFog/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/randomFog/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/README.md b/src/samples/Samples/4_CUDA_Libraries/randomFog/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/data/ref_randomFog.bin b/src/samples/Samples/4_CUDA_Libraries/randomFog/data/ref_randomFog.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/findgllib.mk b/src/samples/Samples/4_CUDA_Libraries/randomFog/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog.cpp b/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/randomFog/randomFog_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/rng.cpp b/src/samples/Samples/4_CUDA_Libraries/randomFog/rng.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/rng.h b/src/samples/Samples/4_CUDA_Libraries/randomFog/rng.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/rng_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/randomFog/rng_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/randomFog/rng_hipified.h b/src/samples/Samples/4_CUDA_Libraries/randomFog/rng_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/Makefile b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/README.md b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS.cpp b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS/simpleCUBLAS_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/Makefile b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/README.md b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT.cpp b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLASXT/simpleCUBLASXT_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/Makefile b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/README.md b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU.cpp b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUBLAS_LU/simpleCUBLAS_LU_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/Makefile b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/README.md b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT.cu b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT.cu.hip b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT.cu.hip
old mode 100644
new mode 100755
index 06736ca..e69de29
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT.cu.hip
@@ -1,292 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* Example showing the use of CUFFT for fast 1D-convolution using FFT. */
-
-// includes, system
-#include <math.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-// includes, project
-#include <hip/hip_runtime.h>
-#include <hipfft.h>
-#include <hipfftXt.h>
-#include "helper_cuda_hipified.h"
-#include "helper_functions.h"
-
-// Complex data type
-typedef float2 Complex;
-static __device__ __host__ inline Complex ComplexAdd(Complex, Complex);
-static __device__ __host__ inline Complex ComplexScale(Complex, float);
-static __device__ __host__ inline Complex ComplexMul(Complex, Complex);
-static __global__ void ComplexPointwiseMulAndScale(Complex *, const Complex *,
-                                                   int, float);
-
-// Filtering functions
-void Convolve(const Complex *, int, const Complex *, int, Complex *);
-
-// Padding functions
-int PadData(const Complex *, Complex **, int, const Complex *, Complex **, int);
-
-////////////////////////////////////////////////////////////////////////////////
-// declaration, forward
-void runTest(int argc, char **argv);
-
-// The filter size is assumed to be a number smaller than the signal size
-#define SIGNAL_SIZE 50
-#define FILTER_KERNEL_SIZE 11
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) { runTest(argc, argv); }
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run a simple test for CUDA
-////////////////////////////////////////////////////////////////////////////////
-void runTest(int argc, char **argv) {
-  printf("[simpleCUFFT] is starting...\n");
-
-  findCudaDevice(argc, (const char **)argv);
-
-  // Allocate host memory for the signal
-  Complex *h_signal =
-      reinterpret_cast<Complex *>(malloc(sizeof(Complex) * SIGNAL_SIZE));
-
-  // Initialize the memory for the signal
-  for (unsigned int i = 0; i < SIGNAL_SIZE; ++i) {
-    h_signal[i].x = rand() / static_cast<float>(RAND_MAX);
-    h_signal[i].y = 0;
-  }
-
-  // Allocate host memory for the filter
-  Complex *h_filter_kernel =
-      reinterpret_cast<Complex *>(malloc(sizeof(Complex) * FILTER_KERNEL_SIZE));
-
-  // Initialize the memory for the filter
-  for (unsigned int i = 0; i < FILTER_KERNEL_SIZE; ++i) {
-    h_filter_kernel[i].x = rand() / static_cast<float>(RAND_MAX);
-    h_filter_kernel[i].y = 0;
-  }
-
-  // Pad signal and filter kernel
-  Complex *h_padded_signal;
-  Complex *h_padded_filter_kernel;
-  int new_size =
-      PadData(h_signal, &h_padded_signal, SIGNAL_SIZE, h_filter_kernel,
-              &h_padded_filter_kernel, FILTER_KERNEL_SIZE);
-  int mem_size = sizeof(Complex) * new_size;
-
-  // Allocate device memory for signal
-  Complex *d_signal;
-  HIPCHECK(hipMalloc(reinterpret_cast<void **>(&d_signal), mem_size));
-  // Copy host memory to device
-  HIPCHECK(
-      hipMemcpy(d_signal, h_padded_signal, mem_size, hipMemcpyHostToDevice));
-
-  // Allocate device memory for filter kernel
-  Complex *d_filter_kernel;
-  HIPCHECK(
-      hipMalloc(reinterpret_cast<void **>(&d_filter_kernel), mem_size));
-
-  // Copy host memory to device
-  HIPCHECK(hipMemcpy(d_filter_kernel, h_padded_filter_kernel, mem_size,
-                             hipMemcpyHostToDevice));
-
-  // CUFFT plan simple API
-  hipfftHandle plan;
-  HIPCHECK(hipfftPlan1d(&plan, new_size, HIPFFT_C2C, 1));
-
-  // CUFFT plan advanced API
-  hipfftHandle plan_adv;
-  size_t workSize;
-  long long int new_size_long = new_size;
-
-  HIPCHECK(hipfftCreate(&plan_adv));
-  HIPCHECK(cufftXtMakePlanMany(plan_adv, 1, &new_size_long, NULL, 1, 1,
-                                      HIPBLAS_C_32F, NULL, 1, 1, HIPBLAS_C_32F, 1,
-                                      &workSize, HIPBLAS_C_32F));
-  printf("Temporary buffer size %li bytes\n", workSize);
-
-  // Transform signal and kernel
-  printf("Transforming signal hipfftExecC2C\n");
-  HIPCHECK(hipfftExecC2C(plan, reinterpret_cast<hipfftComplex *>(d_signal),
-                               reinterpret_cast<hipfftComplex *>(d_signal),
-                               HIPFFT_FORWARD));
-  HIPCHECK(hipfftExecC2C(
-      plan_adv, reinterpret_cast<hipfftComplex *>(d_filter_kernel),
-      reinterpret_cast<hipfftComplex *>(d_filter_kernel), HIPFFT_FORWARD));
-
-  // Multiply the coefficients together and normalize the result
-  printf("Launching ComplexPointwiseMulAndScale<<< >>>\n");
-  ComplexPointwiseMulAndScale<<<32, 256>>>(d_signal, d_filter_kernel, new_size,
-                                           1.0f / new_size);
-
-  // Check if kernel execution generated and error
-  getLastCudaError("Kernel execution failed [ ComplexPointwiseMulAndScale ]");
-
-  // Transform signal back
-  printf("Transforming signal back hipfftExecC2C\n");
-  HIPCHECK(hipfftExecC2C(plan, reinterpret_cast<hipfftComplex *>(d_signal),
-                               reinterpret_cast<hipfftComplex *>(d_signal),
-                               HIPFFT_BACKWARD));
-
-  // Copy device memory to host
-  Complex *h_convolved_signal = h_padded_signal;
-  HIPCHECK(hipMemcpy(h_convolved_signal, d_signal, mem_size,
-                             hipMemcpyDeviceToHost));
-
-  // Allocate host memory for the convolution result
-  Complex *h_convolved_signal_ref =
-      reinterpret_cast<Complex *>(malloc(sizeof(Complex) * SIGNAL_SIZE));
-
-  // Convolve on the host
-  Convolve(h_signal, SIGNAL_SIZE, h_filter_kernel, FILTER_KERNEL_SIZE,
-           h_convolved_signal_ref);
-
-  // check result
-  bool bTestResult = sdkCompareL2fe(
-      reinterpret_cast<float *>(h_convolved_signal_ref),
-      reinterpret_cast<float *>(h_convolved_signal), 2 * SIGNAL_SIZE, 1e-5f);
-
-  // Destroy CUFFT context
-  HIPCHECK(hipfftDestroy(plan));
-  HIPCHECK(hipfftDestroy(plan_adv));
-
-  // cleanup memory
-  free(h_signal);
-  free(h_filter_kernel);
-  free(h_padded_signal);
-  free(h_padded_filter_kernel);
-  free(h_convolved_signal_ref);
-  HIPCHECK(hipFree(d_signal));
-  HIPCHECK(hipFree(d_filter_kernel));
-
-  exit(bTestResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-
-// Pad data
-int PadData(const Complex *signal, Complex **padded_signal, int signal_size,
-            const Complex *filter_kernel, Complex **padded_filter_kernel,
-            int filter_kernel_size) {
-  int minRadius = filter_kernel_size / 2;
-  int maxRadius = filter_kernel_size - minRadius;
-  int new_size = signal_size + maxRadius;
-
-  // Pad signal
-  Complex *new_data =
-      reinterpret_cast<Complex *>(malloc(sizeof(Complex) * new_size));
-  memcpy(new_data + 0, signal, signal_size * sizeof(Complex));
-  memset(new_data + signal_size, 0, (new_size - signal_size) * sizeof(Complex));
-  *padded_signal = new_data;
-
-  // Pad filter
-  new_data = reinterpret_cast<Complex *>(malloc(sizeof(Complex) * new_size));
-  memcpy(new_data + 0, filter_kernel + minRadius, maxRadius * sizeof(Complex));
-  memset(new_data + maxRadius, 0,
-         (new_size - filter_kernel_size) * sizeof(Complex));
-  memcpy(new_data + new_size - minRadius, filter_kernel,
-         minRadius * sizeof(Complex));
-  *padded_filter_kernel = new_data;
-
-  return new_size;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Filtering operations
-////////////////////////////////////////////////////////////////////////////////
-
-// Computes convolution on the host
-void Convolve(const Complex *signal, int signal_size,
-              const Complex *filter_kernel, int filter_kernel_size,
-              Complex *filtered_signal) {
-  int minRadius = filter_kernel_size / 2;
-  int maxRadius = filter_kernel_size - minRadius;
-
-  // Loop over output element indices
-  for (int i = 0; i < signal_size; ++i) {
-    filtered_signal[i].x = filtered_signal[i].y = 0;
-
-    // Loop over convolution indices
-    for (int j = -maxRadius + 1; j <= minRadius; ++j) {
-      int k = i + j;
-
-      if (k >= 0 && k < signal_size) {
-        filtered_signal[i] =
-            ComplexAdd(filtered_signal[i],
-                       ComplexMul(signal[k], filter_kernel[minRadius - j]));
-      }
-    }
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Complex operations
-////////////////////////////////////////////////////////////////////////////////
-
-// Complex addition
-static __device__ __host__ inline Complex ComplexAdd(Complex a, Complex b) {
-  Complex c;
-  c.x = a.x + b.x;
-  c.y = a.y + b.y;
-  return c;
-}
-
-// Complex scale
-static __device__ __host__ inline Complex ComplexScale(Complex a, float s) {
-  Complex c;
-  c.x = s * a.x;
-  c.y = s * a.y;
-  return c;
-}
-
-// Complex multiplication
-static __device__ __host__ inline Complex ComplexMul(Complex a, Complex b) {
-  Complex c;
-  c.x = a.x * b.x - a.y * b.y;
-  c.y = a.x * b.y + a.y * b.x;
-  return c;
-}
-
-// Complex pointwise multiplication
-static __global__ void ComplexPointwiseMulAndScale(Complex *a, const Complex *b,
-                                                   int size, float scale) {
-  const int numThreads = blockDim.x * gridDim.x;
-  const int threadID = blockIdx.x * blockDim.x + threadIdx.x;
-
-  for (int i = threadID; i < size; i += numThreads) {
-    a[i] = ComplexScale(ComplexMul(a[i], b[i]), scale);
-  }
-}
-i = threadID; i < size; i += numThreads) {
-    a[i] = ComplexScale(ComplexMul(a[i], b[i]), scale);
-  }
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT/simpleCUFFT_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/Makefile b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/README.md b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU.cu b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU.cu.hip b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU.cu.hip
old mode 100644
new mode 100755
index c4d24bf..e69de29
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU.cu.hip
@@ -1,381 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-////////////////////////////////////////////////////////////////////////////////
-//
-//  simpleCUFFT_2d_MGPU.cu
-//
-//  This sample code demonstrate the use of CUFFT library for 2D data on multiple GPU.
-//  Example showing the use of CUFFT for solving 2D-POISSON equation using FFT on multiple GPU.
-//  For reference we have used the equation given in http://www.bu.edu/pasi/files/2011/07/
-//  Lecture83.pdf
-//
-////////////////////////////////////////////////////////////////////////////////
-
-
-// System includes
-#include <stdlib.h>
-#include <stdio.h>
-
-#include <string.h>
-#include <math.h>
-
-// CUDA runtime
-#include <hip/hip_runtime.h>
-
-//CUFFT Header file
-#include <hipfftXt.h>
-
-// helper functions and utilities to work with CUDA
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-
-// Complex data type
-typedef float2 Complex;
-
-// Data configuration
-const int GPU_COUNT = 2;
-const int BSZ_Y = 4;
-const int BSZ_X = 4;
-
-// Forward Declaration
-void solvePoissonEquation(cudaLibXtDesc *, cudaLibXtDesc *, float **, int, int);
-
-__global__ void solvePoisson(hipfftComplex *, hipfftComplex *, float *, int, int,
-                             int n_gpu);
-
-///////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  printf(
-      "\nPoisson equation using CUFFT library on Multiple GPUs is "
-      "starting...\n\n");
-
-  int GPU_N;
-  checkCudaErrors(hipGetDeviceCount(&GPU_N));
-
-  if (GPU_N < GPU_COUNT) {
-    printf("No. of GPU on node %d\n", GPU_N);
-    printf("Two GPUs are required to run simpleCUFFT_2d_MGPU sample code\n");
-    exit(EXIT_WAIVED);
-  }
-
-  int *major_minor = (int *)malloc(sizeof(int) * GPU_N * 2);
-  int found2IdenticalGPUs = 0;
-  int nGPUs = 2;
-  int *whichGPUs;
-  whichGPUs = (int *)malloc(sizeof(int) * nGPUs);
-
-  for (int i = 0; i < GPU_N; i++) {
-    hipDeviceProp_t deviceProp;
-    checkCudaErrors(hipGetDeviceProperties(&deviceProp, i));
-    major_minor[i * 2] = deviceProp.major;
-    major_minor[i * 2 + 1] = deviceProp.minor;
-    printf("GPU Device %d: \"%s\" with compute capability %d.%d\n", i,
-           deviceProp.name, deviceProp.major, deviceProp.minor);
-  }
-
-  for (int i = 0; i < GPU_N; i++) {
-    for (int j = i + 1; j < GPU_N; j++) {
-      if ((major_minor[i * 2] == major_minor[j * 2]) &&
-          (major_minor[i * 2 + 1] == major_minor[j * 2 + 1])) {
-        whichGPUs[0] = i;
-        whichGPUs[1] = j;
-        found2IdenticalGPUs = 1;
-        break;
-      }
-    }
-    if (found2IdenticalGPUs) {
-      break;
-    }
-  }
-
-  free(major_minor);
-  if (!found2IdenticalGPUs) {
-    printf(
-        "No Two GPUs with same architecture found\nWaiving simpleCUFFT_2d_MGPU "
-        "sample\n");
-    exit(EXIT_WAIVED);
-  }
-
-  int N = 64;
-  float xMAX = 1.0f, xMIN = 0.0f, yMIN = 0.0f, h = (xMAX - xMIN) / ((float)N),
-        s = 0.1f, s2 = s * s;
-  float *x, *y, *f, *u_a, r2;
-
-  x = (float *)malloc(sizeof(float) * N * N);
-  y = (float *)malloc(sizeof(float) * N * N);
-  f = (float *)malloc(sizeof(float) * N * N);
-  u_a = (float *)malloc(sizeof(float) * N * N);
-
-  for (int j = 0; j < N; j++)
-    for (int i = 0; i < N; i++) {
-      x[N * j + i] = xMIN + i * h;
-      y[N * j + i] = yMIN + j * h;
-      r2 = (x[N * j + i] - 0.5f) * (x[N * j + i] - 0.5f) +
-           (y[N * j + i] - 0.5f) * (y[N * j + i] - 0.5f);
-      f[N * j + i] = (r2 - 2 * s2) / (s2 * s2) * exp(-r2 / (2 * s2));
-      u_a[N * j + i] = exp(-r2 / (2 * s2));  // analytical solution
-    }
-
-  float *k, *d_k[GPU_COUNT];
-  k = (float *)malloc(sizeof(float) * N);
-  for (int i = 0; i <= N / 2; i++) {
-    k[i] = i * 2 * (float)M_PI;
-  }
-  for (int i = N / 2 + 1; i < N; i++) {
-    k[i] = (i - N) * 2 * (float)M_PI;
-  }
-
-  // Create a complex variable on host
-  Complex *h_f = (Complex *)malloc(sizeof(Complex) * N * N);
-
-  // Initialize the memory for the signal
-  for (int i = 0; i < (N * N); i++) {
-    h_f[i].x = f[i];
-    h_f[i].y = 0.0f;
-  }
-
-  // hipfftCreate() - Create an empty plan
-  hipfftResult result;
-  hipfftHandle planComplex;
-  result = hipfftCreate(&planComplex);
-  if (result != HIPFFT_SUCCESS) {
-    printf("hipfftCreate failed\n");
-    exit(EXIT_FAILURE);
-  }
-
-  // cufftXtSetGPUs() - Define which GPUs to use
-  result = cufftXtSetGPUs(planComplex, nGPUs, whichGPUs);
-
-  if (result == HIPFFT_INVALID_DEVICE) {
-    printf("This sample requires two GPUs on the same board.\n");
-    printf("No such board was found. Waiving sample.\n");
-    exit(EXIT_WAIVED);
-  } else if (result != HIPFFT_SUCCESS) {
-    printf("cufftXtSetGPUs failed\n");
-    exit(EXIT_FAILURE);
-  }
-
-  // Print the device information to run the code
-  printf("\nRunning on GPUs\n");
-  for (int i = 0; i < 2; i++) {
-    hipDeviceProp_t deviceProp;
-    checkCudaErrors(hipGetDeviceProperties(&deviceProp, whichGPUs[i]));
-    printf("GPU Device %d: \"%s\" with compute capability %d.%d\n",
-           whichGPUs[i], deviceProp.name, deviceProp.major, deviceProp.minor);
-  }
-
-  size_t *worksize;
-  worksize = (size_t *)malloc(sizeof(size_t) * nGPUs);
-
-  // hipfftMakePlan2d() - Create the plan
-  result = hipfftMakePlan2d(planComplex, N, N, HIPFFT_C2C, worksize);
-  if (result != HIPFFT_SUCCESS) {
-    printf("*MakePlan* failed\n");
-    exit(EXIT_FAILURE);
-  }
-
-  for (int i = 0; i < nGPUs; i++) {
-    hipSetDevice(whichGPUs[i]);
-    hipMalloc((void **)&d_k[i], sizeof(float) * N);
-    hipMemcpy(d_k[i], k, sizeof(float) * N, hipMemcpyHostToDevice);
-  }
-
-  // Create a variable on device
-  // d_f - variable on device to store the input data
-  // d_d_f - variable that store the natural order of d_f data
-  // d_out - device output
-  cudaLibXtDesc *d_f, *d_d_f, *d_out;
-
-  // cufftXtMalloc() - Malloc data on multiple GPUs
-
-  result = cufftXtMalloc(planComplex, (cudaLibXtDesc **)&d_f,
-                         CUFFT_XT_FORMAT_INPLACE);
-  if (result != HIPFFT_SUCCESS) {
-    printf("*XtMalloc failed\n");
-    exit(EXIT_FAILURE);
-  }
-
-  result = cufftXtMalloc(planComplex, (cudaLibXtDesc **)&d_d_f,
-                         CUFFT_XT_FORMAT_INPLACE);
-  if (result != HIPFFT_SUCCESS) {
-    printf("*XtMalloc failed\n");
-    exit(EXIT_FAILURE);
-  }
-
-  result = cufftXtMalloc(planComplex, (cudaLibXtDesc **)&d_out,
-                         CUFFT_XT_FORMAT_INPLACE);
-  if (result != HIPFFT_SUCCESS) {
-    printf("*XtMalloc failed\n");
-    exit(EXIT_FAILURE);
-  }
-
-  // cufftXtMemcpy() - Copy the data from host to device
-  result = cufftXtMemcpy(planComplex, d_f, h_f, CUFFT_COPY_HOST_TO_DEVICE);
-  if (result != HIPFFT_SUCCESS) {
-    printf("*XtMemcpy failed\n");
-    exit(EXIT_FAILURE);
-  }
-
-  // cufftXtExecDescriptorC2C() - Execute FFT on data on multiple GPUs
-  printf("Forward 2d FFT on multiple GPUs\n");
-  result = cufftXtExecDescriptorC2C(planComplex, d_f, d_f, HIPFFT_FORWARD);
-  if (result != HIPFFT_SUCCESS) {
-    printf("*XtExecC2C  failed\n");
-    exit(EXIT_FAILURE);
-  }
-
-  // cufftXtMemcpy() - Copy the data to natural order on GPUs
-  result = cufftXtMemcpy(planComplex, d_d_f, d_f, CUFFT_COPY_DEVICE_TO_DEVICE);
-  if (result != HIPFFT_SUCCESS) {
-    printf("*XtMemcpy failed\n");
-    exit(EXIT_FAILURE);
-  }
-
-  printf("Solve Poisson Equation\n");
-  solvePoissonEquation(d_d_f, d_out, d_k, N, nGPUs);
-
-  printf("Inverse 2d FFT on multiple GPUs\n");
-  // cufftXtExecDescriptorC2C() - Execute inverse  FFT on data on multiple GPUs
-  result = cufftXtExecDescriptorC2C(planComplex, d_out, d_out, HIPFFT_BACKWARD);
-  if (result != HIPFFT_SUCCESS) {
-    printf("*XtExecC2C  failed\n");
-    exit(EXIT_FAILURE);
-  }
-
-  // Create a variable on host to copy the data from device
-  // h_d_out - variable store the output of device
-  Complex *h_d_out = (Complex *)malloc(sizeof(Complex) * N * N);
-
-  // cufftXtMemcpy() - Copy data from multiple GPUs to host
-  result =
-      cufftXtMemcpy(planComplex, h_d_out, d_out, CUFFT_COPY_DEVICE_TO_HOST);
-  if (result != HIPFFT_SUCCESS) {
-    printf("*XtMemcpy failed\n");
-    exit(EXIT_FAILURE);
-  }
-
-  float *out = (float *)malloc(sizeof(float) * N * N);
-  float constant = h_d_out[0].x / N * N;
-  for (int i = 0; i < N * N; i++) {
-    // subtract u[0] to force the arbitrary constant to be 0
-    out[i] = (h_d_out[i].x / (N * N)) - constant;
-  }
-
-  // cleanup memory
-
-  free(h_f);
-  free(k);
-  free(out);
-  free(h_d_out);
-  free(x);
-  free(whichGPUs);
-  free(y);
-  free(f);
-  free(u_a);
-  free(worksize);
-
-  // cudaXtFree() - Free GPU memory
-  for (int i = 0; i < GPU_COUNT; i++) {
-    hipFree(d_k[i]);
-  }
-  result = cufftXtFree(d_out);
-  if (result != HIPFFT_SUCCESS) {
-    printf("*XtFree failed\n");
-    exit(EXIT_FAILURE);
-  }
-  result = cufftXtFree(d_f);
-  if (result != HIPFFT_SUCCESS) {
-    printf("*XtFree failed\n");
-    exit(EXIT_FAILURE);
-  }
-  result = cufftXtFree(d_d_f);
-  if (result != HIPFFT_SUCCESS) {
-    printf("*XtFree failed\n");
-    exit(EXIT_FAILURE);
-  }
-
-  // hipfftDestroy() - Destroy FFT plan
-  result = hipfftDestroy(planComplex);
-  if (result != HIPFFT_SUCCESS) {
-    printf("hipfftDestroy failed: code %d\n", (int)result);
-    exit(EXIT_FAILURE);
-  }
-
-  exit(EXIT_SUCCESS);
-}
-
-////////////////////////////////////////////////////////////////////////////////////
-// Launch kernel on  multiple GPU
-///////////////////////////////////////////////////////////////////////////////////
-void solvePoissonEquation(cudaLibXtDesc *d_ft, cudaLibXtDesc *d_ft_k, float **k,
-                          int N, int nGPUs) {
-  int device;
-  dim3 dimGrid(int(N / BSZ_X), int((N / 2) / BSZ_Y));
-  dim3 dimBlock(BSZ_X, BSZ_Y);
-
-  for (int i = 0; i < nGPUs; i++) {
-    device = d_ft_k->descriptor->GPUs[i];
-    hipSetDevice(device);
-    solvePoisson<<<dimGrid, dimBlock>>>(
-        (hipfftComplex *)d_ft->descriptor->data[i],
-        (hipfftComplex *)d_ft_k->descriptor->data[i], k[i], N, i, nGPUs);
-  }
-
-  // Wait for device to finish all operation
-  for (int i = 0; i < nGPUs; i++) {
-    device = d_ft_k->descriptor->GPUs[i];
-    hipSetDevice(device);
-    hipDeviceSynchronize();
-
-    // Check if kernel execution generated and error
-    getLastCudaError("Kernel execution failed [ solvePoisson ]");
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Kernel for Solving Poisson equation on GPU
-////////////////////////////////////////////////////////////////////////////////
-__global__ void solvePoisson(hipfftComplex *ft, hipfftComplex *ft_k, float *k,
-                             int N, int gpu_id, int n_gpu) {
-  int i = threadIdx.x + blockIdx.x * blockDim.x;
-  int j = threadIdx.y + blockIdx.y * blockDim.y;
-  int index = j * N + i;
-  if (i < N && j < N / n_gpu) {
-    float k2 =
-        k[i] * k[i] + k[j + gpu_id * N / n_gpu] * k[j + gpu_id * N / n_gpu];
-    if (i == 0 && j == 0 && gpu_id == 0) {
-      k2 = 1.0f;
-    }
-
-    ft_k[index].x = -ft[index].x * 1 / k2;
-    ft_k[index].y = -ft[index].y * 1 / k2;
-  }
-}
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_2d_MGPU/simpleCUFFT_2d_MGPU_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/Makefile b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/README.md b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU.cu b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU.cu.hip b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU.cu.hip
old mode 100644
new mode 100755
index 914737e..e69de29
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU.cu.hip
@@ -1,401 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* Example showing the use of CUFFT for fast 1D-convolution using FFT. */
-
-// System includes
-#include <stdlib.h>
-#include <stdio.h>
-
-#include <string.h>
-#include <math.h>
-
-// CUDA runtime
-#include <hip/hip_runtime.h>
-
-//CUFFT Header file
-#include <hipfftXt.h>
-
-// helper functions and utilities to work with CUDA
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-
-// Complex data type
-typedef float2 Complex;
-
-static __device__ __host__ inline Complex ComplexAdd(Complex, Complex);
-static __device__ __host__ inline Complex ComplexScale(Complex, float);
-static __device__ __host__ inline Complex ComplexMul(Complex, Complex);
-static __global__ void ComplexPointwiseMulAndScale(hipfftComplex *,
-                                                   hipfftComplex *, int, float);
-
-// Kernel for GPU
-void multiplyCoefficient(cudaLibXtDesc *, cudaLibXtDesc *, int, float, int);
-
-// Filtering functions
-void Convolve(const Complex *, int, const Complex *, int, Complex *);
-
-// Padding functions
-int PadData(const Complex *, Complex **, int, const Complex *, Complex **, int);
-
-////////////////////////////////////////////////////////////////////////////////
-// Data configuration
-// The filter size is assumed to be a number smaller than the signal size
-///////////////////////////////////////////////////////////////////////////////
-const int SIGNAL_SIZE = 1018;
-const int FILTER_KERNEL_SIZE = 11;
-const int GPU_COUNT = 2;
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  printf("\n[simpleCUFFT_MGPU] is starting...\n\n");
-
-  int GPU_N;
-  checkCudaErrors(hipGetDeviceCount(&GPU_N));
-
-  if (GPU_N < GPU_COUNT) {
-    printf("No. of GPU on node %d\n", GPU_N);
-    printf("Two GPUs are required to run simpleCUFFT_MGPU sample code\n");
-    exit(EXIT_WAIVED);
-  }
-
-  int *major_minor = (int *)malloc(sizeof(int) * GPU_N * 2);
-  int found2IdenticalGPUs = 0;
-  int nGPUs = 2;
-  int *whichGPUs;
-  whichGPUs = (int *)malloc(sizeof(int) * nGPUs);
-
-  for (int i = 0; i < GPU_N; i++) {
-    hipDeviceProp_t deviceProp;
-    checkCudaErrors(hipGetDeviceProperties(&deviceProp, i));
-    major_minor[i * 2] = deviceProp.major;
-    major_minor[i * 2 + 1] = deviceProp.minor;
-    printf("GPU Device %d: \"%s\" with compute capability %d.%d\n", i,
-           deviceProp.name, deviceProp.major, deviceProp.minor);
-  }
-
-  for (int i = 0; i < GPU_N; i++) {
-    for (int j = i + 1; j < GPU_N; j++) {
-      if ((major_minor[i * 2] == major_minor[j * 2]) &&
-          (major_minor[i * 2 + 1] == major_minor[j * 2 + 1])) {
-        whichGPUs[0] = i;
-        whichGPUs[1] = j;
-        found2IdenticalGPUs = 1;
-        break;
-      }
-    }
-    if (found2IdenticalGPUs) {
-      break;
-    }
-  }
-
-  free(major_minor);
-  if (!found2IdenticalGPUs) {
-    printf(
-        "No Two GPUs with same architecture found\nWaiving simpleCUFFT_2d_MGPU "
-        "sample\n");
-    exit(EXIT_WAIVED);
-  }
-
-  // Allocate host memory for the signal
-  Complex *h_signal = (Complex *)malloc(sizeof(Complex) * SIGNAL_SIZE);
-
-  // Initialize the memory for the signal
-  for (int i = 0; i < SIGNAL_SIZE; ++i) {
-    h_signal[i].x = rand() / (float)RAND_MAX;
-    h_signal[i].y = 0;
-  }
-
-  // Allocate host memory for the filter
-  Complex *h_filter_kernel =
-      (Complex *)malloc(sizeof(Complex) * FILTER_KERNEL_SIZE);
-
-  // Initialize the memory for the filter
-  for (int i = 0; i < FILTER_KERNEL_SIZE; ++i) {
-    h_filter_kernel[i].x = rand() / (float)RAND_MAX;
-    h_filter_kernel[i].y = 0;
-  }
-
-  // Pad signal and filter kernel
-  Complex *h_padded_signal;
-  Complex *h_padded_filter_kernel;
-  int new_size =
-      PadData(h_signal, &h_padded_signal, SIGNAL_SIZE, h_filter_kernel,
-              &h_padded_filter_kernel, FILTER_KERNEL_SIZE);
-
-  // hipfftCreate() - Create an empty plan
-  hipfftResult result;
-  hipfftHandle plan_input;
-  HIPCHECK(hipfftCreate(&plan_input));
-
-  // cufftXtSetGPUs() - Define which GPUs to use
-  result = cufftXtSetGPUs(plan_input, nGPUs, whichGPUs);
-
-  if (result == HIPFFT_INVALID_DEVICE) {
-    printf("This sample requires two GPUs on the same board.\n");
-    printf("No such board was found. Waiving sample.\n");
-    exit(EXIT_WAIVED);
-  } else if (result != HIPFFT_SUCCESS) {
-    printf("cufftXtSetGPUs failed\n");
-    exit(EXIT_FAILURE);
-  }
-
-  // Print the device information to run the code
-  printf("\nRunning on GPUs\n");
-  for (int i = 0; i < nGPUs; i++) {
-    hipDeviceProp_t deviceProp;
-    checkCudaErrors(hipGetDeviceProperties(&deviceProp, whichGPUs[i]));
-    printf("GPU Device %d: \"%s\" with compute capability %d.%d\n",
-           whichGPUs[i], deviceProp.name, deviceProp.major, deviceProp.minor);
-  }
-
-  size_t *worksize;
-  worksize = (size_t *)malloc(sizeof(size_t) * nGPUs);
-
-  // hipfftMakePlan1d() - Create the plan
-  HIPCHECK(
-      hipfftMakePlan1d(plan_input, new_size, HIPFFT_C2C, 1, worksize));
-
-  // cufftXtMalloc() - Malloc data on multiple GPUs
-  cudaLibXtDesc *d_signal;
-  HIPCHECK(cufftXtMalloc(plan_input, (cudaLibXtDesc **)&d_signal,
-                                CUFFT_XT_FORMAT_INPLACE));
-  cudaLibXtDesc *d_out_signal;
-  HIPCHECK(cufftXtMalloc(plan_input, (cudaLibXtDesc **)&d_out_signal,
-                                CUFFT_XT_FORMAT_INPLACE));
-  cudaLibXtDesc *d_filter_kernel;
-  HIPCHECK(cufftXtMalloc(plan_input, (cudaLibXtDesc **)&d_filter_kernel,
-                                CUFFT_XT_FORMAT_INPLACE));
-  cudaLibXtDesc *d_out_filter_kernel;
-  HIPCHECK(cufftXtMalloc(plan_input,
-                                (cudaLibXtDesc **)&d_out_filter_kernel,
-                                CUFFT_XT_FORMAT_INPLACE));
-
-  // cufftXtMemcpy() - Copy data from host to multiple GPUs
-  HIPCHECK(cufftXtMemcpy(plan_input, d_signal, h_padded_signal,
-                                CUFFT_COPY_HOST_TO_DEVICE));
-  HIPCHECK(cufftXtMemcpy(plan_input, d_filter_kernel,
-                                h_padded_filter_kernel,
-                                CUFFT_COPY_HOST_TO_DEVICE));
-
-  // cufftXtExecDescriptorC2C() - Execute FFT on data on multiple GPUs
-  HIPCHECK(
-      cufftXtExecDescriptorC2C(plan_input, d_signal, d_signal, HIPFFT_FORWARD));
-  HIPCHECK(cufftXtExecDescriptorC2C(plan_input, d_filter_kernel,
-                                           d_filter_kernel, HIPFFT_FORWARD));
-
-  // cufftXtMemcpy() - Copy the data to natural order on GPUs
-  HIPCHECK(cufftXtMemcpy(plan_input, d_out_signal, d_signal,
-                                CUFFT_COPY_DEVICE_TO_DEVICE));
-  HIPCHECK(cufftXtMemcpy(plan_input, d_out_filter_kernel,
-                                d_filter_kernel, CUFFT_COPY_DEVICE_TO_DEVICE));
-
-  printf("\n\nValue of Library Descriptor\n");
-  printf("Number of GPUs %d\n", d_out_signal->descriptor->nGPUs);
-  printf("Device id  %d %d\n", d_out_signal->descriptor->GPUs[0],
-         d_out_signal->descriptor->GPUs[1]);
-  printf("Data size on GPU %ld %ld\n",
-         (long)(d_out_signal->descriptor->size[0] / sizeof(hipfftComplex)),
-         (long)(d_out_signal->descriptor->size[1] / sizeof(hipfftComplex)));
-
-  // Multiply the coefficients together and normalize the result
-  printf("Launching ComplexPointwiseMulAndScale<<< >>>\n");
-  multiplyCoefficient(d_out_signal, d_out_filter_kernel, new_size,
-                      1.0f / new_size, nGPUs);
-
-  // cufftXtExecDescriptorC2C() - Execute inverse  FFT on data on multiple GPUs
-  printf("Transforming signal back hipfftExecC2C\n");
-  HIPCHECK(cufftXtExecDescriptorC2C(plan_input, d_out_signal,
-                                           d_out_signal, HIPFFT_BACKWARD));
-
-  // Create host pointer pointing to padded signal
-  Complex *h_convolved_signal = h_padded_signal;
-
-  // Allocate host memory for the convolution result
-  Complex *h_convolved_signal_ref =
-      (Complex *)malloc(sizeof(Complex) * SIGNAL_SIZE);
-
-  // cufftXtMemcpy() - Copy data from multiple GPUs to host
-  checkCudaErrors(cufftXtMemcpy(plan_input, h_convolved_signal, d_out_signal,
-                                CUFFT_COPY_DEVICE_TO_HOST));
-
-  // Convolve on the host
-  Convolve(h_signal, SIGNAL_SIZE, h_filter_kernel, FILTER_KERNEL_SIZE,
-           h_convolved_signal_ref);
-
-  // Compare CPU and GPU result
-  bool bTestResult =
-      sdkCompareL2fe((float *)h_convolved_signal_ref,
-                     (float *)h_convolved_signal, 2 * SIGNAL_SIZE, 1e-5f);
-  printf("\nvalue of TestResult %d\n", bTestResult);
-
-  // Cleanup memory
-  free(whichGPUs);
-  free(worksize);
-  free(h_signal);
-  free(h_filter_kernel);
-  free(h_padded_signal);
-  free(h_padded_filter_kernel);
-  free(h_convolved_signal_ref);
-
-  // cudaXtFree() - Free GPU memory
-  HIPCHECK(cufftXtFree(d_signal));
-  HIPCHECK(cufftXtFree(d_filter_kernel));
-  HIPCHECK(cufftXtFree(d_out_signal));
-  HIPCHECK(cufftXtFree(d_out_filter_kernel));
-
-  // hipfftDestroy() - Destroy FFT plan
-  HIPCHECK(hipfftDestroy(plan_input));
-
-  exit(bTestResult ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-
-///////////////////////////////////////////////////////////////////////////////////
-// Function for padding original data
-//////////////////////////////////////////////////////////////////////////////////
-int PadData(const Complex *signal, Complex **padded_signal, int signal_size,
-            const Complex *filter_kernel, Complex **padded_filter_kernel,
-            int filter_kernel_size) {
-  int minRadius = filter_kernel_size / 2;
-  int maxRadius = filter_kernel_size - minRadius;
-  int new_size = signal_size + maxRadius;
-
-  // Pad signal
-  Complex *new_data = (Complex *)malloc(sizeof(Complex) * new_size);
-  memcpy(new_data + 0, signal, signal_size * sizeof(Complex));
-  memset(new_data + signal_size, 0, (new_size - signal_size) * sizeof(Complex));
-  *padded_signal = new_data;
-
-  // Pad filter
-  new_data = (Complex *)malloc(sizeof(Complex) * new_size);
-  memcpy(new_data + 0, filter_kernel + minRadius, maxRadius * sizeof(Complex));
-  memset(new_data + maxRadius, 0,
-         (new_size - filter_kernel_size) * sizeof(Complex));
-  memcpy(new_data + new_size - minRadius, filter_kernel,
-         minRadius * sizeof(Complex));
-  *padded_filter_kernel = new_data;
-
-  return new_size;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Filtering operations - Computing Convolution on the host
-////////////////////////////////////////////////////////////////////////////////
-void Convolve(const Complex *signal, int signal_size,
-              const Complex *filter_kernel, int filter_kernel_size,
-              Complex *filtered_signal) {
-  int minRadius = filter_kernel_size / 2;
-  int maxRadius = filter_kernel_size - minRadius;
-
-  // Loop over output element indices
-  for (int i = 0; i < signal_size; ++i) {
-    filtered_signal[i].x = filtered_signal[i].y = 0;
-
-    // Loop over convolution indices
-    for (int j = -maxRadius + 1; j <= minRadius; ++j) {
-      int k = i + j;
-
-      if (k >= 0 && k < signal_size) {
-        filtered_signal[i] =
-            ComplexAdd(filtered_signal[i],
-                       ComplexMul(signal[k], filter_kernel[minRadius - j]));
-      }
-    }
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//  Launch Kernel on multiple GPU
-////////////////////////////////////////////////////////////////////////////////
-void multiplyCoefficient(cudaLibXtDesc *d_signal,
-                         cudaLibXtDesc *d_filter_kernel, int new_size,
-                         float val, int nGPUs) {
-  int device;
-  // Launch the ComplexPointwiseMulAndScale<<< >>> kernel on multiple GPU
-  for (int i = 0; i < nGPUs; i++) {
-    device = d_signal->descriptor->GPUs[i];
-
-    // Set device
-    checkCudaErrors(hipSetDevice(device));
-
-    // Perform GPU computations
-    ComplexPointwiseMulAndScale<<<32, 256>>>(
-        (hipfftComplex *)d_signal->descriptor->data[i],
-        (hipfftComplex *)d_filter_kernel->descriptor->data[i],
-        int(d_signal->descriptor->size[i] / sizeof(hipfftComplex)), val);
-  }
-
-  // Wait for device to finish all operation
-  for (int i = 0; i < nGPUs; i++) {
-    device = d_signal->descriptor->GPUs[i];
-    checkCudaErrors(hipSetDevice(device));
-    hipDeviceSynchronize();
-    // Check if kernel execution generated and error
-    getLastCudaError("Kernel execution failed [ ComplexPointwiseMulAndScale ]");
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Complex operations
-////////////////////////////////////////////////////////////////////////////////
-
-// Complex addition
-static __device__ __host__ inline Complex ComplexAdd(Complex a, Complex b) {
-  Complex c;
-  c.x = a.x + b.x;
-  c.y = a.y + b.y;
-  return c;
-}
-
-// Complex scale
-static __device__ __host__ inline Complex ComplexScale(Complex a, float s) {
-  Complex c;
-  c.x = s * a.x;
-  c.y = s * a.y;
-  return c;
-}
-
-// Complex multiplication
-static __device__ __host__ inline Complex ComplexMul(Complex a, Complex b) {
-  Complex c;
-  c.x = a.x * b.x - a.y * b.y;
-  c.y = a.x * b.y + a.y * b.x;
-  return c;
-}
-// Complex pointwise multiplication
-static __global__ void ComplexPointwiseMulAndScale(hipfftComplex *a,
-                                                   hipfftComplex *b, int size,
-                                                   float scale) {
-  const int numThreads = blockDim.x * gridDim.x;
-  const int threadID = blockIdx.x * blockDim.x + threadIdx.x;
-  for (int i = threadID; i < size; i += numThreads) {
-    a[i] = ComplexScale(ComplexMul(a[i], b[i]), scale);
-  }
-}
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_MGPU/simpleCUFFT_MGPU_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/Makefile b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/README.md b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/simpleCUFFT_callback.cu b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/simpleCUFFT_callback.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/simpleCUFFT_callback.cu.hip b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/simpleCUFFT_callback.cu.hip
old mode 100644
new mode 100755
index bc09407..e69de29
--- a/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/simpleCUFFT_callback.cu.hip
+++ b/src/samples/Samples/4_CUDA_Libraries/simpleCUFFT_callback/simpleCUFFT_callback.cu.hip
@@ -1,344 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-
-/* 
- * Example showing the use of CUFFT for fast 1D-convolution using FFT. 
- * This sample is the same as simpleCUFFT, except that it uses a callback
- * function to perform the pointwise multiply and scale, on input to the
- * inverse transform.
- * 
-*/
-
-// includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-
-// includes, project
-#include <hip/hip_runtime.h>
-#include <hipfft.h>
-#include <hipfftXt.h>
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-
-// Complex data type
-typedef float2 Complex;
-static __device__ __host__ inline Complex ComplexAdd(Complex, Complex);
-static __device__ __host__ inline Complex ComplexScale(Complex, float);
-static __device__ __host__ inline Complex ComplexMul(Complex, Complex);
-
-// This is the callback routine prototype
-static __device__ hipfftComplex ComplexPointwiseMulAndScale(void *a,
-                                                           size_t index,
-                                                           void *cb_info,
-                                                           void *sharedmem);
-
-typedef struct _cb_params {
-  Complex *filter;
-  float scale;
-} cb_params;
-
-// This is the callback routine. It does complex pointwise multiplication with
-// scaling.
-static __device__ hipfftComplex ComplexPointwiseMulAndScale(void *a,
-                                                           size_t index,
-                                                           void *cb_info,
-                                                           void *sharedmem) {
-  cb_params *my_params = (cb_params *)cb_info;
-  return (hipfftComplex)ComplexScale(
-      ComplexMul(((Complex *)a)[index], (my_params->filter)[index]),
-      my_params->scale);
-}
-
-// Define the device pointer to the callback routine. The host code will fetch
-// this and pass it to CUFFT
-__device__ hipfftCallbackLoadC myOwnCallbackPtr = ComplexPointwiseMulAndScale;
-// Filtering functions
-void Convolve(const Complex *, int, const Complex *, int, Complex *);
-
-// Padding functions
-int PadData(const Complex *, Complex **, int, const Complex *, Complex **, int);
-
-////////////////////////////////////////////////////////////////////////////////
-// declaration, forward
-int runTest(int argc, char **argv);
-
-// The filter size is assumed to be a number smaller than the signal size
-#define SIGNAL_SIZE 50
-#define FILTER_KERNEL_SIZE 11
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  struct hipDeviceProp_t properties;
-  int device;
-  HIPCHECK(hipGetDevice(&device));
-  HIPCHECK(hipGetDeviceProperties(&properties, device));
-  if (!(properties.major >= 2)) {
-    printf("simpleCUFFT_callback requires CUDA architecture SM2.0 or higher\n");
-    return EXIT_WAIVED;
-  }
-
-  return runTest(argc, argv);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run a simple test for CUFFT callbacks
-////////////////////////////////////////////////////////////////////////////////
-int runTest(int argc, char **argv) {
-  printf("[simpleCUFFT_callback] is starting...\n");
-
-  findCudaDevice(argc, (const char **)argv);
-
-  // Allocate host memory for the signal
-  Complex *h_signal = (Complex *)malloc(sizeof(Complex) * SIGNAL_SIZE);
-
-  // Initialize the memory for the signal
-  for (unsigned int i = 0; i < SIGNAL_SIZE; ++i) {
-    h_signal[i].x = rand() / (float)RAND_MAX;
-    h_signal[i].y = 0;
-  }
-
-  // Allocate host memory for the filter
-  Complex *h_filter_kernel =
-      (Complex *)malloc(sizeof(Complex) * FILTER_KERNEL_SIZE);
-
-  // Initialize the memory for the filter
-  for (unsigned int i = 0; i < FILTER_KERNEL_SIZE; ++i) {
-    h_filter_kernel[i].x = rand() / (float)RAND_MAX;
-    h_filter_kernel[i].y = 0;
-  }
-
-  // Pad signal and filter kernel
-  Complex *h_padded_signal;
-  Complex *h_padded_filter_kernel;
-  int new_size =
-      PadData(h_signal, &h_padded_signal, SIGNAL_SIZE, h_filter_kernel,
-              &h_padded_filter_kernel, FILTER_KERNEL_SIZE);
-  int mem_size = sizeof(Complex) * new_size;
-
-  // Allocate device memory for signal
-  Complex *d_signal;
-  HIPCHECK(hipMalloc((void **)&d_signal, mem_size));
-  // Copy host memory to device
-  HIPCHECK(
-      hipMemcpy(d_signal, h_padded_signal, mem_size, hipMemcpyHostToDevice));
-
-  // Allocate device memory for filter kernel
-  Complex *d_filter_kernel;
-  HIPCHECK(hipMalloc((void **)&d_filter_kernel, mem_size));
-
-  // Copy host memory to device
-  HIPCHECK(hipMemcpy(d_filter_kernel, h_padded_filter_kernel, mem_size,
-                             hipMemcpyHostToDevice));
-
-  // Create one CUFFT plan for the forward transforms, and one for the reverse
-  // transform with load callback.
-  hipfftHandle plan, cb_plan;
-  size_t work_size;
-
-  HIPCHECK(hipfftCreate(&plan));
-  HIPCHECK(hipfftCreate(&cb_plan));
-
-  HIPCHECK(hipfftMakePlan1d(plan, new_size, HIPFFT_C2C, 1, &work_size));
-  HIPCHECK(hipfftMakePlan1d(cb_plan, new_size, HIPFFT_C2C, 1, &work_size));
-
-  // Define a structure used to pass in the device address of the filter kernel,
-  // and the scale factor
-  cb_params h_params;
-
-  h_params.filter = d_filter_kernel;
-  h_params.scale = 1.0f / new_size;
-
-  // Allocate device memory for parameters
-  cb_params *d_params;
-  HIPCHECK(hipMalloc((void **)&d_params, sizeof(cb_params)));
-
-  // Copy host memory to device
-  HIPCHECK(hipMemcpy(d_params, &h_params, sizeof(cb_params),
-                             hipMemcpyHostToDevice));
-
-  // The host needs to get a copy of the device pointer to the callback
-  hipfftCallbackLoadC hostCopyOfCallbackPtr;
-
-  HIPCHECK(hipMemcpyFromSymbol(&hostCopyOfCallbackPtr, HIP_SYMBOL(myOwnCallbackPtr),
-                                       sizeof(hostCopyOfCallbackPtr)));
-
-  // Now associate the load callback with the plan.
-  hipfftResult status =
-      hipfftXtSetCallback(cb_plan, (void **)&hostCopyOfCallbackPtr,
-                         HIPFFT_CB_LD_COMPLEX, (void **)&d_params);
-  if (status == CUFFT_LICENSE_ERROR) {
-    printf("This sample requires a valid license file.\n");
-    printf(
-        "The file was either not found, out of date, or otherwise invalid.\n");
-    return EXIT_WAIVED;
-  }
-
-  HIPCHECK(hipfftXtSetCallback(cb_plan, (void **)&hostCopyOfCallbackPtr,
-                                     HIPFFT_CB_LD_COMPLEX, (void **)&d_params));
-
-  // Transform signal and kernel
-  printf("Transforming signal hipfftExecC2C\n");
-  HIPCHECK(hipfftExecC2C(plan, (hipfftComplex *)d_signal,
-                               (hipfftComplex *)d_signal, HIPFFT_FORWARD));
-  HIPCHECK(hipfftExecC2C(plan, (hipfftComplex *)d_filter_kernel,
-                               (hipfftComplex *)d_filter_kernel, HIPFFT_FORWARD));
-
-  // Transform signal back, using the callback to do the pointwise multiply on
-  // the way in.
-  printf("Transforming signal back hipfftExecC2C\n");
-  HIPCHECK(hipfftExecC2C(cb_plan, (hipfftComplex *)d_signal,
-                               (hipfftComplex *)d_signal, HIPFFT_BACKWARD));
-
-  // Copy device memory to host
-  Complex *h_convolved_signal = h_padded_signal;
-  HIPCHECK(hipMemcpy(h_convolved_signal, d_signal, mem_size,
-                             hipMemcpyDeviceToHost));
-
-  // Allocate host memory for the convolution result
-  Complex *h_convolved_signal_ref =
-      (Complex *)malloc(sizeof(Complex) * SIGNAL_SIZE);
-
-  // Convolve on the host
-  Convolve(h_signal, SIGNAL_SIZE, h_filter_kernel, FILTER_KERNEL_SIZE,
-           h_convolved_signal_ref);
-
-  // check result
-  bool bTestResult =
-      sdkCompareL2fe((float *)h_convolved_signal_ref,
-                     (float *)h_convolved_signal, 2 * SIGNAL_SIZE, 1e-5f);
-
-  // Destroy CUFFT context
-  HIPCHECK(hipfftDestroy(plan));
-  HIPCHECK(hipfftDestroy(cb_plan));
-
-  // cleanup memory
-  free(h_signal);
-  free(h_filter_kernel);
-  free(h_padded_signal);
-  free(h_padded_filter_kernel);
-  free(h_convolved_signal_ref);
-  HIPCHECK(hipFree(d_signal));
-  HIPCHECK(hipFree(d_filter_kernel));
-  HIPCHECK(hipFree(d_params));
-
-  return bTestResult ? EXIT_SUCCESS : EXIT_FAILURE;
-}
-
-// Pad data
-int PadData(const Complex *signal, Complex **padded_signal, int signal_size,
-            const Complex *filter_kernel, Complex **padded_filter_kernel,
-            int filter_kernel_size) {
-  int minRadius = filter_kernel_size / 2;
-  int maxRadius = filter_kernel_size - minRadius;
-  int new_size = signal_size + maxRadius;
-
-  // Pad signal
-  Complex *new_data = (Complex *)malloc(sizeof(Complex) * new_size);
-  memcpy(new_data + 0, signal, signal_size * sizeof(Complex));
-  memset(new_data + signal_size, 0, (new_size - signal_size) * sizeof(Complex));
-  *padded_signal = new_data;
-
-  // Pad filter
-  new_data = (Complex *)malloc(sizeof(Complex) * new_size);
-  memcpy(new_data + 0, filter_kernel + minRadius, maxRadius * sizeof(Complex));
-  memset(new_data + maxRadius, 0,
-         (new_size - filter_kernel_size) * sizeof(Complex));
-  memcpy(new_data + new_size - minRadius, filter_kernel,
-         minRadius * sizeof(Complex));
-  *padded_filter_kernel = new_data;
-
-  return new_size;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Filtering operations
-////////////////////////////////////////////////////////////////////////////////
-
-// Computes convolution on the host
-void Convolve(const Complex *signal, int signal_size,
-              const Complex *filter_kernel, int filter_kernel_size,
-              Complex *filtered_signal) {
-  int minRadius = filter_kernel_size / 2;
-  int maxRadius = filter_kernel_size - minRadius;
-
-  // Loop over output element indices
-  for (int i = 0; i < signal_size; ++i) {
-    filtered_signal[i].x = filtered_signal[i].y = 0;
-
-    // Loop over convolution indices
-    for (int j = -maxRadius + 1; j <= minRadius; ++j) {
-      int k = i + j;
-
-      if (k >= 0 && k < signal_size) {
-        filtered_signal[i] =
-            ComplexAdd(filtered_signal[i],
-                       ComplexMul(signal[k], filter_kernel[minRadius - j]));
-      }
-    }
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Complex operations
-////////////////////////////////////////////////////////////////////////////////
-
-// Complex addition
-static __device__ __host__ inline Complex ComplexAdd(Complex a, Complex b) {
-  Complex c;
-  c.x = a.x + b.x;
-  c.y = a.y + b.y;
-  return c;
-}
-
-// Complex scale
-static __device__ __host__ inline Complex ComplexScale(Complex a, float s) {
-  Complex c;
-  c.x = s * a.x;
-  c.y = s * a.y;
-  return c;
-}
-
-// Complex multiplication
-static __device__ __host__ inline Complex ComplexMul(Complex a, Complex b) {
-  Complex c;
-  c.x = a.x * b.x - a.y * b.y;
-  c.y = a.x * b.y + a.y * b.x;
-  return c;
-}
-c __device__ __host__ inline Complex ComplexMul(Complex a, Complex b) {
-  Complex c;
-  c.x = a.x * b.x - a.y * b.y;
-  c.y = a.x * b.y + a.y * b.x;
-  return c;
-}
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/.vscode/c_cpp_properties.json b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/.vscode/extensions.json b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/.vscode/launch.json b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/.vscode/tasks.json b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/Makefile b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/NsightEclipse.xml b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/README.md b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP.cpp b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_hipified.cpp b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2017.sln b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2017.vcxproj b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2019.sln b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2019.vcxproj b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2022.sln b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2022.vcxproj b/src/samples/Samples/4_CUDA_Libraries/watershedSegmentationNPP/watershedSegmentationNPP_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/BlackScholes/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/BlackScholes/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/BlackScholes/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/BlackScholes/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.cu b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.cu.hip b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.cu.hip
old mode 100644
new mode 100755
index 15d8f01..e69de29
--- a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.cu.hip
@@ -1,243 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * This sample evaluates fair call and put prices for a
- * given set of European options by Black-Scholes formula.
- * See supplied whitepaper for more explanations.
- */
-
-#include "helper_functions.h"  // helper functions for string parsing
-#include "helper_cuda_hipified.h"  // helper functions CUDA error checking and initialization
-#include "HIPCHECK.h"
-////////////////////////////////////////////////////////////////////////////////
-// Process an array of optN options on CPU
-////////////////////////////////////////////////////////////////////////////////
-extern "C" void BlackScholesCPU(float *h_CallResult, float *h_PutResult,
-                                float *h_StockPrice, float *h_OptionStrike,
-                                float *h_OptionYears, float Riskfree,
-                                float Volatility, int optN);
-
-////////////////////////////////////////////////////////////////////////////////
-// Process an array of OptN options on GPU
-////////////////////////////////////////////////////////////////////////////////
-#include "BlackScholes_kernel.cuh"
-
-////////////////////////////////////////////////////////////////////////////////
-// Helper function, returning uniformly distributed
-// random float in [low, high] range
-////////////////////////////////////////////////////////////////////////////////
-float RandFloat(float low, float high) {
-  float t = (float)rand() / (float)RAND_MAX;
-  return (1.0f - t) * low + t * high;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Data configuration
-////////////////////////////////////////////////////////////////////////////////
-const int OPT_N = 4000000;
-const int NUM_ITERATIONS = 512;
-
-const int OPT_SZ = OPT_N * sizeof(float);
-const float RISKFREE = 0.02f;
-const float VOLATILITY = 0.30f;
-
-#define DIV_UP(a, b) (((a) + (b)-1) / (b))
-
-////////////////////////////////////////////////////////////////////////////////
-// Main program
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  // Start logs
-  printf("[%s] - Starting...\n", argv[0]);
-
-  //'h_' prefix - CPU (host) memory space
-  float
-      // Results calculated by CPU for reference
-      *h_CallResultCPU,
-      *h_PutResultCPU,
-      // CPU copy of GPU results
-      *h_CallResultGPU, *h_PutResultGPU,
-      // CPU instance of input data
-      *h_StockPrice, *h_OptionStrike, *h_OptionYears;
-
-  //'d_' prefix - GPU (device) memory space
-  float
-      // Results calculated by GPU
-      *d_CallResult,
-      *d_PutResult,
-      // GPU instance of input data
-      *d_StockPrice, *d_OptionStrike, *d_OptionYears;
-
-  double delta, ref, sum_delta, sum_ref, max_delta, L1norm, gpuTime;
-
-  StopWatchInterface *hTimer = NULL;
-  int i;
-
-  findCudaDevice(argc, (const char **)argv);
-
-  sdkCreateTimer(&hTimer);
-
-  printf("Initializing data...\n");
-  printf("...allocating CPU memory for options.\n");
-  h_CallResultCPU = (float *)malloc(OPT_SZ);
-  h_PutResultCPU = (float *)malloc(OPT_SZ);
-  h_CallResultGPU = (float *)malloc(OPT_SZ);
-  h_PutResultGPU = (float *)malloc(OPT_SZ);
-  h_StockPrice = (float *)malloc(OPT_SZ);
-  h_OptionStrike = (float *)malloc(OPT_SZ);
-  h_OptionYears = (float *)malloc(OPT_SZ);
-
-  printf("...allocating GPU memory for options.\n");
-  HIPCHECK(hipMalloc((void **)&d_CallResult, OPT_SZ));
-  HIPCHECK(hipMalloc((void **)&d_PutResult, OPT_SZ));
-  HIPCHECK(hipMalloc((void **)&d_StockPrice, OPT_SZ));
-  HIPCHECK(hipMalloc((void **)&d_OptionStrike, OPT_SZ));
-  HIPCHECK(hipMalloc((void **)&d_OptionYears, OPT_SZ));
-
-  printf("...generating input data in CPU mem.\n");
-  srand(5347);
-
-  // Generate options set
-  for (i = 0; i < OPT_N; i++) {
-    h_CallResultCPU[i] = 0.0f;
-    h_PutResultCPU[i] = -1.0f;
-    h_StockPrice[i] = RandFloat(5.0f, 30.0f);
-    h_OptionStrike[i] = RandFloat(1.0f, 100.0f);
-    h_OptionYears[i] = RandFloat(0.25f, 10.0f);
-  }
-
-  printf("...copying input data to GPU mem.\n");
-  // Copy options data to GPU memory for further processing
-  HIPCHECK(
-      hipMemcpy(d_StockPrice, h_StockPrice, OPT_SZ, hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy(d_OptionStrike, h_OptionStrike, OPT_SZ,
-                             hipMemcpyHostToDevice));
-  HIPCHECK(
-      hipMemcpy(d_OptionYears, h_OptionYears, OPT_SZ, hipMemcpyHostToDevice));
-  printf("Data init done.\n\n");
-
-  printf("Executing Black-Scholes GPU kernel (%i iterations)...\n",
-         NUM_ITERATIONS);
-  HIPCHECK(hipDeviceSynchronize());
-  sdkResetTimer(&hTimer);
-  sdkStartTimer(&hTimer);
-
-  for (i = 0; i < NUM_ITERATIONS; i++) {
-    BlackScholesGPU<<<DIV_UP((OPT_N / 2), 128), 128 /*480, 128*/>>>(
-        (float2 *)d_CallResult, (float2 *)d_PutResult, (float2 *)d_StockPrice,
-        (float2 *)d_OptionStrike, (float2 *)d_OptionYears, RISKFREE, VOLATILITY,
-        OPT_N);
-    getLastCudaError("BlackScholesGPU() execution failed\n");
-  }
-
-  HIPCHECK(hipDeviceSynchronize());
-  sdkStopTimer(&hTimer);
-  gpuTime = sdkGetTimerValue(&hTimer) / NUM_ITERATIONS;
-
-  // Both call and put is calculated
-  printf("Options count             : %i     \n", 2 * OPT_N);
-  printf("BlackScholesGPU() time    : %f msec\n", gpuTime);
-  printf("Effective memory bandwidth: %f GB/s\n",
-         ((double)(5 * OPT_N * sizeof(float)) * 1E-9) / (gpuTime * 1E-3));
-  printf("Gigaoptions per second    : %f     \n\n",
-         ((double)(2 * OPT_N) * 1E-9) / (gpuTime * 1E-3));
-
-  printf(
-      "BlackScholes, Throughput = %.4f GOptions/s, Time = %.5f s, Size = %u "
-      "options, NumDevsUsed = %u, Workgroup = %u\n",
-      (((double)(2.0 * OPT_N) * 1.0E-9) / (gpuTime * 1.0E-3)), gpuTime * 1e-3,
-      (2 * OPT_N), 1, 128);
-
-  printf("\nReading back GPU results...\n");
-  // Read back GPU results to compare them to CPU results
-  HIPCHECK(hipMemcpy(h_CallResultGPU, d_CallResult, OPT_SZ,
-                             hipMemcpyDeviceToHost));
-  HIPCHECK(
-      hipMemcpy(h_PutResultGPU, d_PutResult, OPT_SZ, hipMemcpyDeviceToHost));
-
-  printf("Checking the results...\n");
-  printf("...running CPU calculations.\n\n");
-  // Calculate options values on CPU
-  BlackScholesCPU(h_CallResultCPU, h_PutResultCPU, h_StockPrice, h_OptionStrike,
-                  h_OptionYears, RISKFREE, VOLATILITY, OPT_N);
-
-  printf("Comparing the results...\n");
-  // Calculate max absolute difference and L1 distance
-  // between CPU and GPU results
-  sum_delta = 0;
-  sum_ref = 0;
-  max_delta = 0;
-
-  for (i = 0; i < OPT_N; i++) {
-    ref = h_CallResultCPU[i];
-    delta = fabs(h_CallResultCPU[i] - h_CallResultGPU[i]);
-
-    if (delta > max_delta) {
-      max_delta = delta;
-    }
-
-    sum_delta += delta;
-    sum_ref += fabs(ref);
-  }
-
-  L1norm = sum_delta / sum_ref;
-  printf("L1 norm: %E\n", L1norm);
-  printf("Max absolute error: %E\n\n", max_delta);
-
-  printf("Shutting down...\n");
-  printf("...releasing GPU memory.\n");
-  HIPCHECK(hipFree(d_OptionYears));
-  HIPCHECK(hipFree(d_OptionStrike));
-  HIPCHECK(hipFree(d_StockPrice));
-  HIPCHECK(hipFree(d_PutResult));
-  HIPCHECK(hipFree(d_CallResult));
-
-  printf("...releasing CPU memory.\n");
-  free(h_OptionYears);
-  free(h_OptionStrike);
-  free(h_StockPrice);
-  free(h_PutResultGPU);
-  free(h_CallResultGPU);
-  free(h_PutResultCPU);
-  free(h_CallResultCPU);
-  sdkDeleteTimer(&hTimer);
-  printf("Shutdown done.\n");
-
-  printf("\n[BlackScholes] - Test Summary\n");
-
-  if (L1norm > 1e-6) {
-    printf("Test failed!\n");
-    exit(EXIT_FAILURE);
-  }
-
-  printf(
-      "\nNOTE: The CUDA Samples are not meant for performance measurements. "
-      "Results may vary when GPU Boost is enabled.\n\n");
-  printf("Test passed\n");
-  exit(EXIT_SUCCESS);
-}
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.out b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_gold.cpp b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_gold_hipified.cpp b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_kernel.cuh b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_kernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2017.sln b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2019.sln b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2022.sln b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/BlackScholes/BlackScholes_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/Makefile b/src/samples/Samples/5_Domain_Specific/BlackScholes/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/BlackScholes/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/README.md b/src/samples/Samples/5_Domain_Specific/BlackScholes/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/doc/BlackScholes.doc b/src/samples/Samples/5_Domain_Specific/BlackScholes/doc/BlackScholes.doc
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes/doc/BlackScholes.pdf b/src/samples/Samples/5_Domain_Specific/BlackScholes/doc/BlackScholes.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes.cpp b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_gold.cpp b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_gold_hipified.cpp b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_hipified.cpp b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_kernel.cuh b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_kernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2017.sln b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2019.sln b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2022.sln b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/BlackScholes_nvrtc_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/Makefile b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/README.md b/src/samples/Samples/5_Domain_Specific/BlackScholes_nvrtc/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/FDTD3d/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/FDTD3d/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/FDTD3d/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/FDTD3d/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2017.sln b/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2019.sln b/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2022.sln b/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/FDTD3d/FDTD3d_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/Makefile b/src/samples/Samples/5_Domain_Specific/FDTD3d/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/FDTD3d/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/README.md b/src/samples/Samples/5_Domain_Specific/FDTD3d/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3d.h b/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3d.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3dGPU.h b/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3dGPU.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3dGPUKernel.cuh b/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3dGPUKernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3dGPUKernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3dGPUKernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3dGPU_hipified.h b/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3dGPU_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3dReference.h b/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3dReference.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3dReference_hipified.h b/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3dReference_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3d_hipified.h b/src/samples/Samples/5_Domain_Specific/FDTD3d/inc/FDTD3d_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/src/FDTD3d.cpp b/src/samples/Samples/5_Domain_Specific/FDTD3d/src/FDTD3d.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/src/FDTD3dGPU.cu b/src/samples/Samples/5_Domain_Specific/FDTD3d/src/FDTD3dGPU.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/src/FDTD3dGPU.cu.hip b/src/samples/Samples/5_Domain_Specific/FDTD3d/src/FDTD3dGPU.cu.hip
old mode 100644
new mode 100755
index 9f8c019..e69de29
--- a/src/samples/Samples/5_Domain_Specific/FDTD3d/src/FDTD3dGPU.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/FDTD3d/src/FDTD3dGPU.cu.hip
@@ -1,265 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "FDTD3dGPU.h"
-
-#include <iostream>
-#include <algorithm>
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-
-#include "FDTD3dGPUKernel.cuh"
-
-bool getTargetDeviceGlobalMemSize(memsize_t *result, const int argc,
-                                  const char **argv) {
-  int deviceCount = 0;
-  int targetDevice = 0;
-  size_t memsize = 0;
-
-  // Get the number of CUDA enabled GPU devices
-  printf(" hipGetDeviceCount\n");
-  HIPCHECK(hipGetDeviceCount(&deviceCount));
-
-  // Select target device (device 0 by default)
-  targetDevice = findCudaDevice(argc, (const char **)argv);
-
-  // Query target device for maximum memory allocation
-  printf(" hipGetDeviceProperties\n");
-  struct hipDeviceProp_t deviceProp;
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, targetDevice));
-
-  memsize = deviceProp.totalGlobalMem;
-
-  // Save the result
-  *result = (memsize_t)memsize;
-  return true;
-}
-
-bool fdtdGPU(float *output, const float *input, const float *coeff,
-             const int dimx, const int dimy, const int dimz, const int radius,
-             const int timesteps, const int argc, const char **argv) {
-  const int outerDimx = dimx + 2 * radius;
-  const int outerDimy = dimy + 2 * radius;
-  const int outerDimz = dimz + 2 * radius;
-  const size_t volumeSize = outerDimx * outerDimy * outerDimz;
-  int deviceCount = 0;
-  int targetDevice = 0;
-  float *bufferOut = 0;
-  float *bufferIn = 0;
-  dim3 dimBlock;
-  dim3 dimGrid;
-
-  // Ensure that the inner data starts on a 128B boundary
-  const int padding = (128 / sizeof(float)) - radius;
-  const size_t paddedVolumeSize = volumeSize + padding;
-
-#ifdef GPU_PROFILING
-  hipEvent_t profileStart = 0;
-  hipEvent_t profileEnd = 0;
-  const int profileTimesteps = timesteps - 1;
-
-  if (profileTimesteps < 1) {
-    printf(
-        " cannot profile with fewer than two timesteps (timesteps=%d), "
-        "profiling is disabled.\n",
-        timesteps);
-  }
-
-#endif
-
-  // Check the radius is valid
-  if (radius != RADIUS) {
-    printf("radius is invalid, must be %d - see kernel for details.\n", RADIUS);
-    exit(EXIT_FAILURE);
-  }
-
-  // Get the number of CUDA enabled GPU devices
-  HIPCHECK(hipGetDeviceCount(&deviceCount));
-
-  // Select target device (device 0 by default)
-  targetDevice = findCudaDevice(argc, (const char **)argv);
-
-  HIPCHECK(hipSetDevice(targetDevice));
-
-  // Allocate memory buffers
-  HIPCHECK(
-      hipMalloc((void **)&bufferOut, paddedVolumeSize * sizeof(float)));
-  HIPCHECK(
-      hipMalloc((void **)&bufferIn, paddedVolumeSize * sizeof(float)));
-
-  // Check for a command-line specified block size
-  int userBlockSize;
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "block-size")) {
-    userBlockSize = getCmdLineArgumentInt(argc, argv, "block-size");
-    // Constrain to a multiple of k_blockDimX
-    userBlockSize = (userBlockSize / k_blockDimX * k_blockDimX);
-
-    // Constrain within allowed bounds
-    userBlockSize = MIN(MAX(userBlockSize, k_blockSizeMin), k_blockSizeMax);
-  } else {
-    userBlockSize = k_blockSizeMax;
-  }
-
-  // Check the device limit on the number of threads
-  struct hipFuncAttributes funcAttrib;
-  HIPCHECK(hipFuncGetAttributes(&funcAttrib, FiniteDifferencesKernel));
-
-  userBlockSize = MIN(userBlockSize, funcAttrib.maxThreadsPerBlock);
-
-  // Set the block size
-  dimBlock.x = k_blockDimX;
-  // Visual Studio 2005 does not like std::min
-  //    dimBlock.y = std::min<size_t>(userBlockSize / k_blockDimX,
-  //    (size_t)k_blockDimMaxY);
-  dimBlock.y = ((userBlockSize / k_blockDimX) < (size_t)k_blockDimMaxY)
-                   ? (userBlockSize / k_blockDimX)
-                   : (size_t)k_blockDimMaxY;
-  dimGrid.x = (unsigned int)ceil((float)dimx / dimBlock.x);
-  dimGrid.y = (unsigned int)ceil((float)dimy / dimBlock.y);
-  printf(" set block size to %dx%d\n", dimBlock.x, dimBlock.y);
-  printf(" set grid size to %dx%d\n", dimGrid.x, dimGrid.y);
-
-  // Check the block size is valid
-  if (dimBlock.x < RADIUS || dimBlock.y < RADIUS) {
-    printf("invalid block size, x (%d) and y (%d) must be >= radius (%d).\n",
-           dimBlock.x, dimBlock.y, RADIUS);
-    exit(EXIT_FAILURE);
-  }
-
-  // Copy the input to the device input buffer
-  HIPCHECK(hipMemcpy(bufferIn + padding, input,
-                             volumeSize * sizeof(float),
-                             hipMemcpyHostToDevice));
-
-  // Copy the input to the device output buffer (actually only need the halo)
-  HIPCHECK(hipMemcpy(bufferOut + padding, input,
-                             volumeSize * sizeof(float),
-                             hipMemcpyHostToDevice));
-
-  // Copy the coefficients to the device coefficient buffer
-  HIPCHECK(
-      hipMemcpyToSymbol(HIP_SYMBOL(stencil), (void *)coeff, (radius + 1) * sizeof(float)));
-
-#ifdef GPU_PROFILING
-
-  // Create the events
-  HIPCHECK(hipEventCreate(&profileStart));
-  HIPCHECK(hipEventCreate(&profileEnd));
-
-#endif
-
-  // Execute the FDTD
-  float *bufferSrc = bufferIn + padding;
-  float *bufferDst = bufferOut + padding;
-  printf(" GPU FDTD loop\n");
-
-#ifdef GPU_PROFILING
-  // Enqueue start event
-  HIPCHECK(hipEventRecord(profileStart, 0));
-#endif
-
-  for (int it = 0; it < timesteps; it++) {
-    printf("\tt = %d ", it);
-
-    // Launch the kernel
-    printf("launch kernel\n");
-    FiniteDifferencesKernel<<<dimGrid, dimBlock>>>(bufferDst, bufferSrc, dimx,
-                                                   dimy, dimz);
-
-    // Toggle the buffers
-    // Visual Studio 2005 does not like std::swap
-    //    std::swap<float *>(bufferSrc, bufferDst);
-    float *tmp = bufferDst;
-    bufferDst = bufferSrc;
-    bufferSrc = tmp;
-  }
-
-  printf("\n");
-
-#ifdef GPU_PROFILING
-  // Enqueue end event
-  HIPCHECK(hipEventRecord(profileEnd, 0));
-#endif
-
-  // Wait for the kernel to complete
-  HIPCHECK(hipDeviceSynchronize());
-
-  // Read the result back, result is in bufferSrc (after final toggle)
-  HIPCHECK(hipMemcpy(output, bufferSrc, volumeSize * sizeof(float),
-                             hipMemcpyDeviceToHost));
-
-// Report time
-#ifdef GPU_PROFILING
-  float elapsedTimeMS = 0;
-
-  if (profileTimesteps > 0) {
-    HIPCHECK(
-        hipEventElapsedTime(&elapsedTimeMS, profileStart, profileEnd));
-  }
-
-  if (profileTimesteps > 0) {
-    // Convert milliseconds to seconds
-    double elapsedTime = elapsedTimeMS * 1.0e-3;
-    double avgElapsedTime = elapsedTime / (double)profileTimesteps;
-    // Determine number of computations per timestep
-    size_t pointsComputed = dimx * dimy * dimz;
-    // Determine throughput
-    double throughputM = 1.0e-6 * (double)pointsComputed / avgElapsedTime;
-    printf(
-        "FDTD3d, Throughput = %.4f MPoints/s, Time = %.5f s, Size = %u Points, "
-        "NumDevsUsed = %u, Blocksize = %u\n",
-        throughputM, avgElapsedTime, pointsComputed, 1,
-        dimBlock.x * dimBlock.y);
-  }
-
-#endif
-
-  // Cleanup
-  if (bufferIn) {
-    HIPCHECK(hipFree(bufferIn));
-  }
-
-  if (bufferOut) {
-    HIPCHECK(hipFree(bufferOut));
-  }
-
-#ifdef GPU_PROFILING
-
-  if (profileStart) {
-    HIPCHECK(hipEventDestroy(profileStart));
-  }
-
-  if (profileEnd) {
-    HIPCHECK(hipEventDestroy(profileEnd));
-  }
-
-#endif
-  return true;
-}
-CudaErrors(hipEventDestroy(profileStart));
-  }
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/src/FDTD3dReference.cpp b/src/samples/Samples/5_Domain_Specific/FDTD3d/src/FDTD3dReference.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/src/FDTD3dReference_hipified.cpp b/src/samples/Samples/5_Domain_Specific/FDTD3d/src/FDTD3dReference_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/FDTD3d/src/FDTD3d_hipified.cpp b/src/samples/Samples/5_Domain_Specific/FDTD3d/src/FDTD3d_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/FlowCPU.flo b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/FlowCPU.flo
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/FlowGPU.flo b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/FlowGPU.flo
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow.out b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow_vs2017.sln b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow_vs2019.sln b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow_vs2022.sln b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/HSOpticalFlow_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/Makefile b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/README.md b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/_temp_0_gfx908_sramecc+_xnack-_linked.bc b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/_temp_0_gfx908_sramecc+_xnack-_linked.bc
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/addKernel.cuh b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/addKernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/addKernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/addKernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/common.h b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/common_hipified.h b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/data/frame10.ppm b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/data/frame10.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/data/frame11.ppm b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/data/frame11.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/derivativesKernel.cuh b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/derivativesKernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/derivativesKernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/derivativesKernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/doc/OpticalFlow.docx b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/doc/OpticalFlow.docx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/doc/OpticalFlow.pdf b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/doc/OpticalFlow.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/downscaleKernel.cuh b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/downscaleKernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/downscaleKernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/downscaleKernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowCUDA.cu b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowCUDA.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowCUDA.cu.hip b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowCUDA.cu.hip
old mode 100644
new mode 100755
index e0e1f31..e69de29
--- a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowCUDA.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowCUDA.cu.hip
@@ -1,218 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-
-#include <hip/hip_runtime.h>
-#include "common.h"
-#include "helper_cuda_hipified.h"
-// include kernels
-#include "downscaleKernel_hipified.cuh"
-#include "upscaleKernel_hipified.cuh"
-#include "warpingKernel_hipified.cuh"
-#include "derivativesKernel_hipified.cuh"
-#include "solverKernel_hipified.cuh"
-#include "addKernel_hipified.cuh"
-
-///////////////////////////////////////////////////////////////////////////////
-/// \brief method logic
-///
-/// handles memory allocations, control flow
-/// \param[in]  I0           source image
-/// \param[in]  I1           tracked image
-/// \param[in]  width        images width
-/// \param[in]  height       images height
-/// \param[in]  stride       images stride
-/// \param[in]  alpha        degree of displacement field smoothness
-/// \param[in]  nLevels      number of levels in a pyramid
-/// \param[in]  nWarpIters   number of warping iterations per pyramid level
-/// \param[in]  nSolverIters number of solver iterations (Jacobi iterations)
-/// \param[out] u            horizontal displacement
-/// \param[out] v            vertical displacement
-///////////////////////////////////////////////////////////////////////////////
-void ComputeFlowCUDA(const float *I0, const float *I1, int width, int height,
-                     int stride, float alpha, int nLevels, int nWarpIters,
-                     int nSolverIters, float *u, float *v) {
-  printf("Computing optical flow on GPU...\n");
-
-  // pI0 and pI1 will hold device pointers
-  const float **pI0 = new const float *[nLevels];
-  const float **pI1 = new const float *[nLevels];
-
-  int *pW = new int[nLevels];
-  int *pH = new int[nLevels];
-  int *pS = new int[nLevels];
-
-  // device memory pointers
-  float *d_tmp;
-  float *d_du0;
-  float *d_dv0;
-  float *d_du1;
-  float *d_dv1;
-
-  float *d_Ix;
-  float *d_Iy;
-  float *d_Iz;
-
-  float *d_u;
-  float *d_v;
-  float *d_nu;
-  float *d_nv;
-
-  const int dataSize = stride * height * sizeof(float);
-
-  HIPCHECK(hipMalloc(&d_tmp, dataSize));
-  HIPCHECK(hipMalloc(&d_du0, dataSize));
-  HIPCHECK(hipMalloc(&d_dv0, dataSize));
-  HIPCHECK(hipMalloc(&d_du1, dataSize));
-  HIPCHECK(hipMalloc(&d_dv1, dataSize));
-
-  HIPCHECK(hipMalloc(&d_Ix, dataSize));
-  HIPCHECK(hipMalloc(&d_Iy, dataSize));
-  HIPCHECK(hipMalloc(&d_Iz, dataSize));
-
-  HIPCHECK(hipMalloc(&d_u, dataSize));
-  HIPCHECK(hipMalloc(&d_v, dataSize));
-  HIPCHECK(hipMalloc(&d_nu, dataSize));
-  HIPCHECK(hipMalloc(&d_nv, dataSize));
-
-  // prepare pyramid
-
-  int currentLevel = nLevels - 1;
-  // allocate GPU memory for input images
-  HIPCHECK(hipMalloc(pI0 + currentLevel, dataSize));
-  HIPCHECK(hipMalloc(pI1 + currentLevel, dataSize));
-
-  HIPCHECK(hipMemcpy((void *)pI0[currentLevel], I0, dataSize,
-                             hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy((void *)pI1[currentLevel], I1, dataSize,
-                             hipMemcpyHostToDevice));
-
-  pW[currentLevel] = width;
-  pH[currentLevel] = height;
-  pS[currentLevel] = stride;
-
-  for (; currentLevel > 0; --currentLevel) {
-    int nw = pW[currentLevel] / 2;
-    int nh = pH[currentLevel] / 2;
-    int ns = iAlignUp(nw);
-
-    HIPCHECK(
-        hipMalloc(pI0 + currentLevel - 1, ns * nh * sizeof(float)));
-    HIPCHECK(
-        hipMalloc(pI1 + currentLevel - 1, ns * nh * sizeof(float)));
-
-    Downscale(pI0[currentLevel], pW[currentLevel], pH[currentLevel],
-              pS[currentLevel], nw, nh, ns, (float *)pI0[currentLevel - 1]);
-
-    Downscale(pI1[currentLevel], pW[currentLevel], pH[currentLevel],
-              pS[currentLevel], nw, nh, ns, (float *)pI1[currentLevel - 1]);
-
-    pW[currentLevel - 1] = nw;
-    pH[currentLevel - 1] = nh;
-    pS[currentLevel - 1] = ns;
-  }
-
-  HIPCHECK(hipMemset(d_u, 0, stride * height * sizeof(float)));
-  HIPCHECK(hipMemset(d_v, 0, stride * height * sizeof(float)));
-
-  // compute flow
-  for (; currentLevel < nLevels; ++currentLevel) {
-    for (int warpIter = 0; warpIter < nWarpIters; ++warpIter) {
-      HIPCHECK(hipMemset(d_du0, 0, dataSize));
-      HIPCHECK(hipMemset(d_dv0, 0, dataSize));
-
-      HIPCHECK(hipMemset(d_du1, 0, dataSize));
-      HIPCHECK(hipMemset(d_dv1, 0, dataSize));
-
-      // on current level we compute optical flow
-      // between frame 0 and warped frame 1
-      WarpImage(pI1[currentLevel], pW[currentLevel], pH[currentLevel],
-                pS[currentLevel], d_u, d_v, d_tmp);
-
-      ComputeDerivatives(pI0[currentLevel], d_tmp, pW[currentLevel],
-                         pH[currentLevel], pS[currentLevel], d_Ix, d_Iy, d_Iz);
-
-      for (int iter = 0; iter < nSolverIters; ++iter) {
-        SolveForUpdate(d_du0, d_dv0, d_Ix, d_Iy, d_Iz, pW[currentLevel],
-                       pH[currentLevel], pS[currentLevel], alpha, d_du1, d_dv1);
-
-        Swap(d_du0, d_du1);
-        Swap(d_dv0, d_dv1);
-      }
-
-      // update u, v
-      Add(d_u, d_du0, pH[currentLevel] * pS[currentLevel], d_u);
-      Add(d_v, d_dv0, pH[currentLevel] * pS[currentLevel], d_v);
-    }
-
-    if (currentLevel != nLevels - 1) {
-      // prolongate solution
-      float scaleX = (float)pW[currentLevel + 1] / (float)pW[currentLevel];
-
-      Upscale(d_u, pW[currentLevel], pH[currentLevel], pS[currentLevel],
-              pW[currentLevel + 1], pH[currentLevel + 1], pS[currentLevel + 1],
-              scaleX, d_nu);
-
-      float scaleY = (float)pH[currentLevel + 1] / (float)pH[currentLevel];
-
-      Upscale(d_v, pW[currentLevel], pH[currentLevel], pS[currentLevel],
-              pW[currentLevel + 1], pH[currentLevel + 1], pS[currentLevel + 1],
-              scaleY, d_nv);
-
-      Swap(d_u, d_nu);
-      Swap(d_v, d_nv);
-    }
-  }
-
-  HIPCHECK(hipMemcpy(u, d_u, dataSize, hipMemcpyDeviceToHost));
-  HIPCHECK(hipMemcpy(v, d_v, dataSize, hipMemcpyDeviceToHost));
-
-  // cleanup
-  for (int i = 0; i < nLevels; ++i) {
-    HIPCHECK(hipFree((void *)pI0[i]));
-    HIPCHECK(hipFree((void *)pI1[i]));
-  }
-
-  delete[] pI0;
-  delete[] pI1;
-  delete[] pW;
-  delete[] pH;
-  delete[] pS;
-
-  HIPCHECK(hipFree(d_tmp));
-  HIPCHECK(hipFree(d_du0));
-  HIPCHECK(hipFree(d_dv0));
-  HIPCHECK(hipFree(d_du1));
-  HIPCHECK(hipFree(d_dv1));
-  HIPCHECK(hipFree(d_Ix));
-  HIPCHECK(hipFree(d_Iy));
-  HIPCHECK(hipFree(d_Iz));
-  HIPCHECK(hipFree(d_nu));
-  HIPCHECK(hipFree(d_nv));
-  HIPCHECK(hipFree(d_u));
-  HIPCHECK(hipFree(d_v));
-}
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowCUDA.h b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowCUDA.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowCUDA_hipified.h b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowCUDA_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowGold.cpp b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowGold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowGold.h b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowGold.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowGold_hipified.cpp b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowGold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowGold_hipified.h b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/flowGold_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/main.cpp b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/main_hipified.cpp b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/solverKernel.cuh b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/solverKernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/solverKernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/solverKernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/upscaleKernel.cuh b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/upscaleKernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/upscaleKernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/upscaleKernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/warpingKernel.cuh b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/warpingKernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/warpingKernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/HSOpticalFlow/warpingKernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/Mandelbrot/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/Mandelbrot/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/Mandelbrot/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/Mandelbrot/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Makefile b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot.cpp b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_cuda.cu b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_cuda.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_cuda.cu.hip b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_cuda.cu.hip
old mode 100644
new mode 100755
index 38c3685..e69de29
--- a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_cuda.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_cuda.cu.hip
@@ -1,397 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include "helper_cuda.h"
-#include "Mandelbrot_kernel.h"
-#include "Mandelbrot_kernel.cuh"
-
-// The Mandelbrot CUDA GPU thread function
-
-template <class T>
-__global__ void Mandelbrot0(uchar4 *dst, const int imageW, const int imageH,
-                            const int crunch, const T xOff, const T yOff,
-                            const T xJP, const T yJP, const T scale,
-                            const uchar4 colors, const int frame,
-                            const int animationFrame, const int gridWidth,
-                            const int numBlocks, const bool isJ) {
-  // loop until all blocks completed
-  for (unsigned int blockIndex = blockIdx.x; blockIndex < numBlocks;
-       blockIndex += gridDim.x) {
-    unsigned int blockX = blockIndex % gridWidth;
-    unsigned int blockY = blockIndex / gridWidth;
-
-    // process this block
-    const int ix = blockDim.x * blockX + threadIdx.x;
-    const int iy = blockDim.y * blockY + threadIdx.y;
-
-    if ((ix < imageW) && (iy < imageH)) {
-      // Calculate the location
-      const T xPos = (T)ix * scale + xOff;
-      const T yPos = (T)iy * scale + yOff;
-
-      // Calculate the Mandelbrot index for the current location
-      int m = CalcMandelbrot<T>(xPos, yPos, xJP, yJP, crunch, isJ);
-      //            int m = blockIdx.x;         // uncomment to see scheduling
-      //            order
-      m = m > 0 ? crunch - m : 0;
-
-      // Convert the Mandelbrot index into a color
-      uchar4 color;
-
-      if (m) {
-        m += animationFrame;
-        color.x = m * colors.x;
-        color.y = m * colors.y;
-        color.z = m * colors.z;
-      } else {
-        color.x = 0;
-        color.y = 0;
-        color.z = 0;
-      }
-
-      // Output the pixel
-      int pixel = imageW * iy + ix;
-
-      if (frame == 0) {
-        color.w = 0;
-        dst[pixel] = color;
-      } else {
-        int frame1 = frame + 1;
-        int frame2 = frame1 / 2;
-        dst[pixel].x = (dst[pixel].x * frame + color.x + frame2) / frame1;
-        dst[pixel].y = (dst[pixel].y * frame + color.y + frame2) / frame1;
-        dst[pixel].z = (dst[pixel].z * frame + color.z + frame2) / frame1;
-      }
-    }
-  }
-
-}  // Mandelbrot0
-
-// The Mandelbrot CUDA GPU thread function (double single version)
-__global__ void MandelbrotDS0(uchar4 *dst, const int imageW, const int imageH,
-                              const int crunch, const float xOff0,
-                              const float xOff1, const float yOff0,
-                              const float yOff1, const float xJP,
-                              const float yJP, const float scale,
-                              const uchar4 colors, const int frame,
-                              const int animationFrame, const int gridWidth,
-                              const int numBlocks, const bool isJ) {
-  // loop until all blocks completed
-  for (unsigned int blockIndex = blockIdx.x; blockIndex < numBlocks;
-       blockIndex += gridDim.x) {
-    unsigned int blockX = blockIndex % gridWidth;
-    unsigned int blockY = blockIndex / gridWidth;
-
-    // process this block
-    const int ix = blockDim.x * blockX + threadIdx.x;
-    const int iy = blockDim.y * blockY + threadIdx.y;
-
-    if ((ix < imageW) && (iy < imageH)) {
-      // Calculate the location
-      float xPos0 = (float)ix * scale;
-      float xPos1 = 0.0f;
-      float yPos0 = (float)iy * scale;
-      float yPos1 = 0.0f;
-      dsadd(xPos0, xPos1, xPos0, xPos1, xOff0, xOff1);
-      dsadd(yPos0, yPos1, yPos0, yPos1, yOff0, yOff1);
-
-      // Calculate the Mandelbrot index for the current location
-      int m =
-          CalcMandelbrotDS(xPos0, xPos1, yPos0, yPos1, xJP, yJP, crunch, isJ);
-      m = m > 0 ? crunch - m : 0;
-
-      // Convert the Mandelbrot index into a color
-      uchar4 color;
-
-      if (m) {
-        m += animationFrame;
-        color.x = m * colors.x;
-        color.y = m * colors.y;
-        color.z = m * colors.z;
-      } else {
-        color.x = 0;
-        color.y = 0;
-        color.z = 0;
-      }
-
-      // Output the pixel
-      int pixel = imageW * iy + ix;
-
-      if (frame == 0) {
-        color.w = 0;
-        dst[pixel] = color;
-      } else {
-        int frame1 = frame + 1;
-        int frame2 = frame1 / 2;
-        dst[pixel].x = (dst[pixel].x * frame + color.x + frame2) / frame1;
-        dst[pixel].y = (dst[pixel].y * frame + color.y + frame2) / frame1;
-        dst[pixel].z = (dst[pixel].z * frame + color.z + frame2) / frame1;
-      }
-    }
-  }
-}  // MandelbrotDS0
-
-// The Mandelbrot secondary AA pass CUDA GPU thread function
-template <class T>
-__global__ void Mandelbrot1(uchar4 *dst, const int imageW, const int imageH,
-                            const int crunch, const T xOff, const T yOff,
-                            const T xJP, const T yJP, const T scale,
-                            const uchar4 colors, const int frame,
-                            const int animationFrame, const int gridWidth,
-                            const int numBlocks, const bool isJ) {
-  // loop until all blocks completed
-  for (unsigned int blockIndex = blockIdx.x; blockIndex < numBlocks;
-       blockIndex += gridDim.x) {
-    unsigned int blockX = blockIndex % gridWidth;
-    unsigned int blockY = blockIndex / gridWidth;
-
-    // process this block
-    const int ix = blockDim.x * blockX + threadIdx.x;
-    const int iy = blockDim.y * blockY + threadIdx.y;
-
-    if ((ix < imageW) && (iy < imageH)) {
-      // Get the current pixel color
-      int pixel = imageW * iy + ix;
-      uchar4 pixelColor = dst[pixel];
-      int count = 0;
-
-      // Search for pixels out of tolerance surrounding the current pixel
-      if (ix > 0) {
-        count += CheckColors(pixelColor, dst[pixel - 1]);
-      }
-
-      if (ix + 1 < imageW) {
-        count += CheckColors(pixelColor, dst[pixel + 1]);
-      }
-
-      if (iy > 0) {
-        count += CheckColors(pixelColor, dst[pixel - imageW]);
-      }
-
-      if (iy + 1 < imageH) {
-        count += CheckColors(pixelColor, dst[pixel + imageW]);
-      }
-
-      if (count) {
-        // Calculate the location
-        const T xPos = (T)ix * scale + xOff;
-        const T yPos = (T)iy * scale + yOff;
-
-        // Calculate the Mandelbrot index for the current location
-        int m = CalcMandelbrot(xPos, yPos, xJP, yJP, crunch, isJ);
-        m = m > 0 ? crunch - m : 0;
-
-        // Convert the Mandelbrot index into a color
-        uchar4 color;
-
-        if (m) {
-          m += animationFrame;
-          color.x = m * colors.x;
-          color.y = m * colors.y;
-          color.z = m * colors.z;
-        } else {
-          color.x = 0;
-          color.y = 0;
-          color.z = 0;
-        }
-
-        // Output the pixel
-        int frame1 = frame + 1;
-        int frame2 = frame1 / 2;
-        dst[pixel].x = (pixelColor.x * frame + color.x + frame2) / frame1;
-        dst[pixel].y = (pixelColor.y * frame + color.y + frame2) / frame1;
-        dst[pixel].z = (pixelColor.z * frame + color.z + frame2) / frame1;
-      }
-    }
-  }
-
-}  // Mandelbrot1
-
-// The Mandelbrot secondary AA pass CUDA GPU thread function (double single
-// version)
-__global__ void MandelbrotDS1(uchar4 *dst, const int imageW, const int imageH,
-                              const int crunch, const float xOff0,
-                              const float xOff1, const float yOff0,
-                              const float yOff1, const float xJP,
-                              const float yJP, const float scale,
-                              const uchar4 colors, const int frame,
-                              const int animationFrame, const int gridWidth,
-                              const int numBlocks, const bool isJ) {
-  // loop until all blocks completed
-  for (unsigned int blockIndex = blockIdx.x; blockIndex < numBlocks;
-       blockIndex += gridDim.x) {
-    unsigned int blockX = blockIndex % gridWidth;
-    unsigned int blockY = blockIndex / gridWidth;
-
-    // process this block
-    const int ix = blockDim.x * blockX + threadIdx.x;
-    const int iy = blockDim.y * blockY + threadIdx.y;
-
-    if ((ix < imageW) && (iy < imageH)) {
-      // Get the current pixel color
-      int pixel = imageW * iy + ix;
-      uchar4 pixelColor = dst[pixel];
-      int count = 0;
-
-      // Search for pixels out of tolerance surrounding the current pixel
-      if (ix > 0) {
-        count += CheckColors(pixelColor, dst[pixel - 1]);
-      }
-
-      if (ix + 1 < imageW) {
-        count += CheckColors(pixelColor, dst[pixel + 1]);
-      }
-
-      if (iy > 0) {
-        count += CheckColors(pixelColor, dst[pixel - imageW]);
-      }
-
-      if (iy + 1 < imageH) {
-        count += CheckColors(pixelColor, dst[pixel + imageW]);
-      }
-
-      if (count) {
-        // Calculate the location
-        float xPos0 = (float)ix * scale;
-        float xPos1 = 0.0f;
-        float yPos0 = (float)iy * scale;
-        float yPos1 = 0.0f;
-        dsadd(xPos0, xPos1, xPos0, xPos1, xOff0, xOff1);
-        dsadd(yPos0, yPos1, yPos0, yPos1, yOff0, yOff1);
-
-        // Calculate the Mandelbrot index for the current location
-        int m =
-            CalcMandelbrotDS(xPos0, xPos1, yPos0, yPos1, xJP, yJP, crunch, isJ);
-        m = m > 0 ? crunch - m : 0;
-
-        // Convert the Mandelbrot index into a color
-        uchar4 color;
-
-        if (m) {
-          m += animationFrame;
-          color.x = m * colors.x;
-          color.y = m * colors.y;
-          color.z = m * colors.z;
-        } else {
-          color.x = 0;
-          color.y = 0;
-          color.z = 0;
-        }
-
-        // Output the pixel
-        int frame1 = frame + 1;
-        int frame2 = frame1 / 2;
-        dst[pixel].x = (pixelColor.x * frame + color.x + frame2) / frame1;
-        dst[pixel].y = (pixelColor.y * frame + color.y + frame2) / frame1;
-        dst[pixel].z = (pixelColor.z * frame + color.z + frame2) / frame1;
-      }
-    }
-  }
-
-}  // MandelbrotDS1
-
-// The host CPU Mandelbrot thread spawner
-void RunMandelbrot0(uchar4 *dst, const int imageW, const int imageH,
-                    const int crunch, const double xOff, const double yOff,
-                    const double xjp, const double yjp, const double scale,
-                    const uchar4 colors, const int frame,
-                    const int animationFrame, const int mode, const int numSMs,
-                    const bool isJ, int version) {
-  dim3 threads(BLOCKDIM_X, BLOCKDIM_Y);
-  dim3 grid(iDivUp(imageW, BLOCKDIM_X), iDivUp(imageH, BLOCKDIM_Y));
-
-  int numWorkerBlocks = numSMs;
-
-  switch (mode) {
-    default:
-    case 0:
-      Mandelbrot0<float><<<numWorkerBlocks, threads>>>(
-          dst, imageW, imageH, crunch, (float)xOff, (float)yOff, (float)xjp,
-          (float)yjp, (float)scale, colors, frame, animationFrame, grid.x,
-          grid.x * grid.y, isJ);
-      break;
-    case 1:
-      float x0, x1, y0, y1;
-      dsdeq(x0, x1, xOff);
-      dsdeq(y0, y1, yOff);
-      MandelbrotDS0<<<numWorkerBlocks, threads>>>(
-          dst, imageW, imageH, crunch, x0, x1, y0, y1, (float)xjp, (float)yjp,
-          (float)scale, colors, frame, animationFrame, grid.x, grid.x * grid.y,
-          isJ);
-      break;
-    case 2:
-      Mandelbrot0<double><<<numWorkerBlocks, threads>>>(
-          dst, imageW, imageH, crunch, xOff, yOff, xjp, yjp, scale, colors,
-          frame, animationFrame, grid.x, grid.x * grid.y, isJ);
-      break;
-  }
-
-  getLastCudaError("Mandelbrot0 kernel execution failed.\n");
-}  // RunMandelbrot0
-
-// The host CPU Mandelbrot thread spawner
-void RunMandelbrot1(uchar4 *dst, const int imageW, const int imageH,
-                    const int crunch, const double xOff, const double yOff,
-                    const double xjp, const double yjp, const double scale,
-                    const uchar4 colors, const int frame,
-                    const int animationFrame, const int mode, const int numSMs,
-                    const bool isJ, int version) {
-  dim3 threads(BLOCKDIM_X, BLOCKDIM_Y);
-  dim3 grid(iDivUp(imageW, BLOCKDIM_X), iDivUp(imageH, BLOCKDIM_Y));
-
-  int numWorkerBlocks = numSMs;
-
-  switch (mode) {
-    default:
-    case 0:
-      Mandelbrot1<float><<<numWorkerBlocks, threads>>>(
-          dst, imageW, imageH, crunch, (float)xOff, (float)yOff, (float)xjp,
-          (float)yjp, (float)scale, colors, frame, animationFrame, grid.x,
-          grid.x * grid.y, isJ);
-      break;
-    case 1:
-      float x0, x1, y0, y1;
-      dsdeq(x0, x1, xOff);
-      dsdeq(y0, y1, yOff);
-      MandelbrotDS1<<<numWorkerBlocks, threads>>>(
-          dst, imageW, imageH, crunch, x0, x1, y0, y1, (float)xjp, (float)yjp,
-          (float)scale, colors, frame, animationFrame, grid.x, grid.x * grid.y,
-          isJ);
-      break;
-    case 2:
-      Mandelbrot1<double><<<numWorkerBlocks, threads>>>(
-          dst, imageW, imageH, crunch, xOff, yOff, xjp, yjp, scale, colors,
-          frame, animationFrame, grid.x, grid.x * grid.y, isJ);
-      break;
-  }
-
-  getLastCudaError("Mandelbrot1 kernel execution failed.\n");
-}  // RunMandelbrot1
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_gold.cpp b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_gold.h b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_gold.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_gold_hipified.cpp b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_gold_hipified.h b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_gold_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_hipified.cpp b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_kernel.cuh b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_kernel.h b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_kernel.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_kernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_kernel_hipified.h b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_kernel_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2017.sln b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2019.sln b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2022.sln b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/Mandelbrot/Mandelbrot_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/Mandelbrot/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/README.md b/src/samples/Samples/5_Domain_Specific/Mandelbrot/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/data/Mandelbrot_fp32.ppm b/src/samples/Samples/5_Domain_Specific/Mandelbrot/data/Mandelbrot_fp32.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/data/Mandelbrot_fp64.ppm b/src/samples/Samples/5_Domain_Specific/Mandelbrot/data/Mandelbrot_fp64.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/data/params.txt b/src/samples/Samples/5_Domain_Specific/Mandelbrot/data/params.txt
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/data/referenceJulia_fp32.ppm b/src/samples/Samples/5_Domain_Specific/Mandelbrot/data/referenceJulia_fp32.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/data/referenceJulia_fp64.ppm b/src/samples/Samples/5_Domain_Specific/Mandelbrot/data/referenceJulia_fp64.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/doc/sshot_lg.JPG b/src/samples/Samples/5_Domain_Specific/Mandelbrot/doc/sshot_lg.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/doc/sshot_md.JPG b/src/samples/Samples/5_Domain_Specific/Mandelbrot/doc/sshot_md.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/doc/sshot_sm.JPG b/src/samples/Samples/5_Domain_Specific/Mandelbrot/doc/sshot_sm.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/Mandelbrot/findgllib.mk b/src/samples/Samples/5_Domain_Specific/Mandelbrot/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/Makefile b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU.cpp b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_hipified.cpp b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2017.sln b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2019.sln b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2022.sln b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarloMultiGPU_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_common.h b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_common_hipified.h b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_gold.cpp b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_gold_hipified.cpp b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_kernel.cu b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_kernel.cu.hip
old mode 100644
new mode 100755
index 0d885a1..e69de29
--- a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_kernel.cu.hip
@@ -1,229 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-////////////////////////////////////////////////////////////////////////////////
-// Global types
-////////////////////////////////////////////////////////////////////////////////
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-#include "helper_cuda_hipified.h"
-#include <hiprand_kernel.h>
-#include "MonteCarlo_common.h"
-
-////////////////////////////////////////////////////////////////////////////////
-// Helper reduction template
-// Please see the "reduction" CUDA Sample for more information
-////////////////////////////////////////////////////////////////////////////////
-#include "MonteCarlo_reduction.cuh"
-
-////////////////////////////////////////////////////////////////////////////////
-// Internal GPU-side data structures
-////////////////////////////////////////////////////////////////////////////////
-#define MAX_OPTIONS (1024 * 1024)
-
-// Preprocessed input option data
-typedef struct {
-  real S;
-  real X;
-  real MuByT;
-  real VBySqrtT;
-} __TOptionData;
-
-////////////////////////////////////////////////////////////////////////////////
-// Overloaded shortcut payoff functions for different precision modes
-////////////////////////////////////////////////////////////////////////////////
-__device__ inline float endCallValue(float S, float X, float r, float MuByT,
-                                     float VBySqrtT) {
-  float callValue = S * __expf(MuByT + VBySqrtT * r) - X;
-  return (callValue > 0.0F) ? callValue : 0.0F;
-}
-
-__device__ inline double endCallValue(double S, double X, double r,
-                                      double MuByT, double VBySqrtT) {
-  double callValue = S * exp(MuByT + VBySqrtT * r) - X;
-  return (callValue > 0.0) ? callValue : 0.0;
-}
-
-#define THREAD_N 256
-
-////////////////////////////////////////////////////////////////////////////////
-// This kernel computes the integral over all paths using a single thread block
-// per option. It is fastest when the number of thread blocks times the work per
-// block is high enough to keep the GPU busy.
-////////////////////////////////////////////////////////////////////////////////
-static __global__ void MonteCarloOneBlockPerOption(
-    hiprandState *__restrict rngStates,
-    const __TOptionData *__restrict d_OptionData,
-    __TOptionValue *__restrict d_CallValue, int pathN, int optionN) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  cg::thread_block_tile<32> tile32 = cg::tiled_partition<32>(cta);
-
-  const int SUM_N = THREAD_N;
-  __shared__ real s_SumCall[SUM_N];
-  __shared__ real s_Sum2Call[SUM_N];
-
-  // determine global thread id
-  int tid = threadIdx.x + blockIdx.x * blockDim.x;
-
-  // Copy random number state to local memory for efficiency
-  hiprandState localState = rngStates[tid];
-  for (int optionIndex = blockIdx.x; optionIndex < optionN;
-       optionIndex += gridDim.x) {
-    const real S = d_OptionData[optionIndex].S;
-    const real X = d_OptionData[optionIndex].X;
-    const real MuByT = d_OptionData[optionIndex].MuByT;
-    const real VBySqrtT = d_OptionData[optionIndex].VBySqrtT;
-
-    // Cycle through the entire samples array:
-    // derive end stock price for each path
-    // accumulate partial integrals into intermediate shared memory buffer
-    for (int iSum = threadIdx.x; iSum < SUM_N; iSum += blockDim.x) {
-      __TOptionValue sumCall = {0, 0};
-
-#pragma unroll 8
-      for (int i = iSum; i < pathN; i += SUM_N) {
-        real r = hiprand_normal(&localState);
-        real callValue = endCallValue(S, X, r, MuByT, VBySqrtT);
-        sumCall.Expected += callValue;
-        sumCall.Confidence += callValue * callValue;
-      }
-
-      s_SumCall[iSum] = sumCall.Expected;
-      s_Sum2Call[iSum] = sumCall.Confidence;
-    }
-
-    // Reduce shared memory accumulators
-    // and write final result to global memory
-    cg::sync(cta);
-    sumReduce<real, SUM_N, THREAD_N>(s_SumCall, s_Sum2Call, cta, tile32,
-                                     &d_CallValue[optionIndex]);
-  }
-}
-
-static __global__ void rngSetupStates(hiprandState *rngState, int device_id) {
-  // determine global thread id
-  int tid = threadIdx.x + blockIdx.x * blockDim.x;
-  // Each threadblock gets different seed,
-  // Threads within a threadblock get different sequence numbers
-  hiprand_init(blockIdx.x + gridDim.x * device_id, threadIdx.x, 0,
-              &rngState[tid]);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Host-side interface to GPU Monte Carlo
-////////////////////////////////////////////////////////////////////////////////
-
-extern "C" void initMonteCarloGPU(TOptionPlan *plan) {
-  HIPCHECK(hipMalloc(&plan->d_OptionData,
-                             sizeof(__TOptionData) * (plan->optionCount)));
-  HIPCHECK(hipMalloc(&plan->d_CallValue,
-                             sizeof(__TOptionValue) * (plan->optionCount)));
-  HIPCHECK(hipHostMalloc(&plan->h_OptionData,
-                                 sizeof(__TOptionData) * (plan->optionCount)));
-  // Allocate internal device memory
-  HIPCHECK(hipHostMalloc(&plan->h_CallValue,
-                                 sizeof(__TOptionValue) * (plan->optionCount)));
-  // Allocate states for pseudo random number generators
-  HIPCHECK(hipMalloc((void **)&plan->rngStates,
-                             plan->gridSize * THREAD_N * sizeof(hiprandState)));
-  HIPCHECK(hipMemset(plan->rngStates, 0,
-                             plan->gridSize * THREAD_N * sizeof(hiprandState)));
-
-  // place each device pathN random numbers apart on the random number sequence
-  rngSetupStates<<<plan->gridSize, THREAD_N>>>(plan->rngStates, plan->device);
-  getLastCudaError("rngSetupStates kernel failed.\n");
-}
-
-// Compute statistics and deallocate internal device memory
-extern "C" void closeMonteCarloGPU(TOptionPlan *plan) {
-  for (int i = 0; i < plan->optionCount; i++) {
-    const double RT = plan->optionData[i].R * plan->optionData[i].T;
-    const double sum = plan->h_CallValue[i].Expected;
-    const double sum2 = plan->h_CallValue[i].Confidence;
-    const double pathN = plan->pathN;
-    // Derive average from the total sum and discount by riskfree rate
-    plan->callValue[i].Expected = (float)(exp(-RT) * sum / pathN);
-    // Standard deviation
-    double stdDev = sqrt((pathN * sum2 - sum * sum) / (pathN * (pathN - 1)));
-    // Confidence width; in 95% of all cases theoretical value lies within these
-    // borders
-    plan->callValue[i].Confidence =
-        (float)(exp(-RT) * 1.96 * stdDev / sqrt(pathN));
-  }
-
-  HIPCHECK(hipFree(plan->rngStates));
-  HIPCHECK(hipHostFree(plan->h_CallValue));
-  HIPCHECK(hipHostFree(plan->h_OptionData));
-  HIPCHECK(hipFree(plan->d_CallValue));
-  HIPCHECK(hipFree(plan->d_OptionData));
-}
-
-// Main computations
-extern "C" void MonteCarloGPU(TOptionPlan *plan, hipStream_t stream) {
-  __TOptionValue *h_CallValue = plan->h_CallValue;
-
-  if (plan->optionCount <= 0 || plan->optionCount > MAX_OPTIONS) {
-    printf("MonteCarloGPU(): bad option count.\n");
-    return;
-  }
-
-  __TOptionData *h_OptionData = (__TOptionData *)plan->h_OptionData;
-
-  for (int i = 0; i < plan->optionCount; i++) {
-    const double T = plan->optionData[i].T;
-    const double R = plan->optionData[i].R;
-    const double V = plan->optionData[i].V;
-    const double MuByT = (R - 0.5 * V * V) * T;
-    const double VBySqrtT = V * sqrt(T);
-    h_OptionData[i].S = (real)plan->optionData[i].S;
-    h_OptionData[i].X = (real)plan->optionData[i].X;
-    h_OptionData[i].MuByT = (real)MuByT;
-    h_OptionData[i].VBySqrtT = (real)VBySqrtT;
-  }
-
-  HIPCHECK(hipMemcpyAsync(plan->d_OptionData, h_OptionData,
-                                  plan->optionCount * sizeof(__TOptionData),
-                                  hipMemcpyHostToDevice, stream));
-
-  MonteCarloOneBlockPerOption<<<plan->gridSize, THREAD_N, 0, stream>>>(
-      plan->rngStates, (__TOptionData *)(plan->d_OptionData),
-      (__TOptionValue *)(plan->d_CallValue), plan->pathN, plan->optionCount);
-  getLastCudaError("MonteCarloOneBlockPerOption() execution failed\n");
-
-  HIPCHECK(hipMemcpyAsync(h_CallValue, plan->d_CallValue,
-                                  plan->optionCount * sizeof(__TOptionValue),
-                                  hipMemcpyDeviceToHost, stream));
-
-  // hipDeviceSynchronize();
-}
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_reduction.cuh b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_reduction.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_reduction_hipified.cuh b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/MonteCarlo_reduction_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/README.md b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/doc/MonteCarlo.doc b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/doc/MonteCarlo.doc
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/doc/MonteCarlo.pdf b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/doc/MonteCarlo.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/multithreading.cpp b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/multithreading.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/multithreading.h b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/multithreading.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/multithreading_hipified.cpp b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/multithreading_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/multithreading_hipified.h b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/multithreading_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/realtype.h b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/realtype.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/realtype_hipified.h b/src/samples/Samples/5_Domain_Specific/MonteCarloMultiGPU/realtype_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/Makefile b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize.out b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2017.sln b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2019.sln b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2022.sln b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NV12toBGRandResize_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/README.md b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/bgr_resize.cu b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/bgr_resize.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/bgr_resize.cu.hip b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/bgr_resize.cu.hip
old mode 100644
new mode 100755
index bdb1027..e69de29
--- a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/bgr_resize.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/bgr_resize.cu.hip
@@ -1,135 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-
-// Implements BGR 3 progressive planars frames batch resize
-
-#include <hip/hip_runtime.h>
-#include <hip/hip_runtime.h>
-#include "resize_convert_hipified.h"
-#include "HIPCHECK.h"
-__global__ void resizeBGRplanarBatchKernel(hipTextureObject_t texSrc,
-    float *pDst, int nDstPitch, int nDstHeight, int nSrcHeight,
-    int batch, float scaleX, float scaleY,
-    int cropX, int cropY, int cropW, int cropH) {
-    int x = threadIdx.x + blockIdx.x * blockDim.x;
-    int y = threadIdx.y + blockIdx.y * blockDim.y;
-
-    if (x >= (int)(cropW/scaleX) || y >= (int)(cropH/scaleY))
-        return;
-
-    int frameSize = nDstPitch*nDstHeight;
-    float *p = NULL;
-    for (int i = blockIdx.z; i < batch; i += gridDim.z) {
-        #pragma unroll
-        for (int channel=0; channel < 3; channel++){
-            p = pDst + i * 3 * frameSize + y * nDstPitch + x + channel * frameSize;
-            *p = tex2D<float>(texSrc, x * scaleX + cropX,
-                                ((3 * i + channel) * nSrcHeight + y * scaleY + cropY));
-        }
-    }
-}
-
-
-static void resizeBGRplanarBatchCore(
-        float *dpSrc, int nSrcPitch, int nSrcWidth, int nSrcHeight,
-        float *dpDst, int nDstPitch, int nDstWidth, int nDstHeight,
-        int nBatchSize, hipStream_t stream, bool whSameResizeRatio,
-        int cropX, int cropY, int cropW, int cropH) {
-    hipTextureObject_t texSrc[2];
-    int nTiles = 1, h, iTile;
-
-    h = nSrcHeight * 3 * nBatchSize;
-    while ((h + nTiles - 1) / nTiles > 65536)
-        nTiles++;
-
-    if (nTiles > 2)
-        return;
-
-    int batchTile = nBatchSize / nTiles;
-    int batchTileLast = nBatchSize - batchTile * (nTiles-1);
-
-    for (iTile = 0; iTile < nTiles; ++iTile) {
-        int bs = (iTile == nTiles - 1) ? batchTileLast : batchTile;
-        float *dpSrcNew = dpSrc +
-            iTile * (batchTile * 3 * nSrcHeight * nSrcPitch);
-
-        hipResourceDesc resDesc = {};
-        resDesc.resType = hipResourceTypePitch2D;
-        resDesc.res.pitch2D.devPtr = dpSrcNew;
-        resDesc.res.pitch2D.desc = hipCreateChannelDesc<float>();
-        resDesc.res.pitch2D.width = nSrcWidth;
-        resDesc.res.pitch2D.height = bs * 3 * nSrcHeight;
-        resDesc.res.pitch2D.pitchInBytes = nSrcPitch * sizeof(float);
-        hipTextureDesc texDesc = {};
-        texDesc.filterMode = hipFilterModeLinear;
-        texDesc.readMode = hipReadModeElementType;
-
-        HIPCHECK(hipCreateTextureObject(&texSrc[iTile], &resDesc, &texDesc, NULL));
-        float *dpDstNew = dpDst +
-            iTile * (batchTile * 3 * nDstHeight * nDstPitch);
-
-        if(cropW == 0 || cropH == 0) {
-            cropX = 0;
-            cropY = 0;
-            cropW = nSrcWidth;
-            cropH = nSrcHeight;
-        }
-
-        float scaleX = (cropW*1.0f / nDstWidth);
-        float scaleY = (cropH*1.0f / nDstHeight);
-
-        if(whSameResizeRatio == true)
-            scaleX = scaleY = scaleX > scaleY ? scaleX : scaleY;
-        dim3 block(32, 32, 1);
-
-        size_t blockDimZ = bs;
-        // Restricting blocks in Z-dim till 32 to not launch too many blocks
-        blockDimZ = (blockDimZ > 32) ? 32 : blockDimZ;
-        dim3 grid((cropW*1.0f/scaleX + block.x - 1) / block.x,
-                  (cropH*1.0f/scaleY + block.y - 1) / block.y, blockDimZ);
-
-        resizeBGRplanarBatchKernel<<<grid, block, 0, stream>>>
-                (texSrc[iTile], dpDstNew, nDstPitch, nDstHeight, nSrcHeight,
-                bs, scaleX, scaleY, cropX, cropY, cropW, cropH);
-
-    }
-
-    for (iTile = 0; iTile < nTiles; ++iTile)
-        HIPCHECK(hipDestroyTextureObject(texSrc[iTile]));
-}
-
-void resizeBGRplanarBatch(
-        float *dpSrc, int nSrcPitch, int nSrcWidth, int nSrcHeight,
-        float *dpDst, int nDstPitch, int nDstWidth, int nDstHeight,
-        int nBatchSize, hipStream_t stream,
-        int cropX, int cropY, int cropW, int cropH, bool whSameResizeRatio) {
-    resizeBGRplanarBatchCore(dpSrc, nSrcPitch, nSrcWidth, nSrcHeight,
-        dpDst, nDstPitch, nDstWidth, nDstHeight, nBatchSize, stream,
-        whSameResizeRatio, cropX, cropY, cropW, cropH);
-}
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/data/test1280x720.nv12 b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/data/test1280x720.nv12
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/data/test1920x1080.nv12 b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/data/test1920x1080.nv12
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/data/test640x480.nv12 b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/data/test640x480.nv12
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_resize.cu b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_resize.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_resize.cu.hip b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_resize.cu.hip
old mode 100644
new mode 100755
index 3a60747..e69de29
--- a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_resize.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_resize.cu.hip
@@ -1,111 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// Implements interlace NV12 frames batch resize
-
-#include "resize_convert_hipified.h"
-#include "HIPCHECK.h"
-__global__ static void resizeNV12BatchKernel(hipTextureObject_t texSrcLuma,
-                                             hipTextureObject_t texSrcChroma,
-                                             uint8_t *pDstNv12, int nSrcWidth,
-                                             int nSrcHeight, int nDstPitch,
-                                             int nDstWidth, int nDstHeight,
-                                             int nBatchSize) {
-  int x = threadIdx.x + blockIdx.x * blockDim.x;
-  int y = threadIdx.y + blockIdx.y * blockDim.y;
-
-  int px = x * 2, py = y * 2;
-
-  if ((px + 1) >= nDstWidth || (py + 1) >= nDstHeight) return;
-
-  float fxScale = 1.0f * nSrcWidth / nDstWidth;
-  float fyScale = 1.0f * nSrcHeight / nDstHeight;
-
-  uint8_t *p = pDstNv12 + px + py * nDstPitch;
-  int hh = nDstHeight * 3 / 2;
-  int nByte = nDstPitch * hh;
-  int px_fxScale = px * fxScale;
-  int px_fxScale_1 = (px + 1) * fxScale;
-  int py_fyScale = py * fyScale;
-  int py_fyScale_1 = (py + 1) * fyScale;
-
-  for (int i = blockIdx.z; i < nBatchSize; i+=gridDim.z) {
-    *(uchar2 *)p = make_uchar2(tex2D<uint8_t>(texSrcLuma, px_fxScale, py_fyScale),
-                          tex2D<uint8_t>(texSrcLuma, px_fxScale_1, py_fyScale));
-    *(uchar2 *)(p + nDstPitch) =
-        make_uchar2(tex2D<uint8_t>(texSrcLuma, px_fxScale, py_fyScale_1),
-               tex2D<uint8_t>(texSrcLuma, px_fxScale_1, py_fyScale_1));
-    *(uchar2 *)(p + (nDstHeight - y) * nDstPitch) = tex2D<uchar2>(
-        texSrcChroma, x * fxScale, (hh * i + nDstHeight + y) * fyScale);
-    p += nByte;
-    py += hh;
-  }
-}
-
-void resizeNV12Batch(uint8_t *dpSrc, int nSrcPitch, int nSrcWidth,
-                     int nSrcHeight, uint8_t *dpDst, int nDstPitch,
-                     int nDstWidth, int nDstHeight, int nBatchSize,
-                     hipStream_t stream) {
-  int hhSrc = ceilf(nSrcHeight * 3.0f / 2.0f);
-  hipResourceDesc resDesc = {};
-  resDesc.resType = hipResourceTypePitch2D;
-  resDesc.res.pitch2D.devPtr = dpSrc;
-  resDesc.res.pitch2D.desc = hipCreateChannelDesc<uint8_t>();
-  resDesc.res.pitch2D.width = nSrcWidth;
-  resDesc.res.pitch2D.height = hhSrc * nBatchSize;
-  resDesc.res.pitch2D.pitchInBytes = nSrcPitch;
-
-  hipTextureDesc texDesc = {};
-  texDesc.filterMode = hipFilterModePoint;
-  texDesc.readMode = hipReadModeElementType;
-
-  hipTextureObject_t texLuma = 0;
-  HIPCHECK(hipCreateTextureObject(&texLuma, &resDesc, &texDesc, NULL));
-
-  resDesc.res.pitch2D.desc = hipCreateChannelDesc<uchar2>();
-  resDesc.res.pitch2D.width /= 2;
-
-  hipTextureObject_t texChroma = 0;
-  HIPCHECK(hipCreateTextureObject(&texChroma, &resDesc, &texDesc, NULL));
-
-  dim3 block(32, 32, 1);
-
-  size_t blockDimZ = nBatchSize;
-
-  // Restricting blocks in Z-dim till 32 to not launch too many blocks
-  blockDimZ = (blockDimZ > 32) ? 32 : blockDimZ;
-
-  dim3 grid((nDstWidth / 2 + block.x) / block.x,
-            (nDstHeight / 2 + block.y) / block.y, blockDimZ);
-  resizeNV12BatchKernel<<<grid, block, 0, stream>>>(
-      texLuma, texChroma, dpDst, nSrcWidth, nSrcHeight, nDstPitch, nDstWidth,
-      nDstHeight, nBatchSize);
-
-  HIPCHECK(hipDestroyTextureObject(texLuma));
-  HIPCHECK(hipDestroyTextureObject(texChroma));
-}
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_to_bgr_planar.cu b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_to_bgr_planar.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_to_bgr_planar.cu.hip b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_to_bgr_planar.cu.hip
old mode 100644
new mode 100755
index d64fbb4..e69de29
--- a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_to_bgr_planar.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/nv12_to_bgr_planar.cu.hip
@@ -1,155 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-
-// Implements NV12 to BGR batch conversion
-
-#include <hip/hip_runtime.h>
-#include <hip/hip_runtime.h>
-
-#include "resize_convert_hipified.h"
-
-#define CONV_THREADS_X 64
-#define CONV_THREADS_Y 10
-
-__forceinline__ __device__ static float clampF(float x, float lower,
-                                               float upper) {
-  return x < lower ? lower : (x > upper ? upper : x);
-}
-
-__global__ static void nv12ToBGRplanarBatchKernel(const uint8_t *pNv12,
-                                                  int nNv12Pitch, float *pBgr,
-                                                  int nRgbPitch, int nWidth,
-                                                  int nHeight, int nBatchSize) {
-  int x = threadIdx.x + blockIdx.x * blockDim.x;
-  int y = threadIdx.y + blockIdx.y * blockDim.y;
-
-  if ((x << 2) + 1 > nWidth || (y << 1) + 1 > nHeight) return;
-
-  const uint8_t *__restrict__ pSrc = pNv12;
-
-  for (int i = blockIdx.z; i < nBatchSize; i += gridDim.z) {
-    pSrc = pNv12 + i * ((nHeight * nNv12Pitch * 3) >> 1) + (x << 2) +
-           (y << 1) * nNv12Pitch;
-    uchar4 luma2x01, luma2x23, uv2;
-    *(uint32_t *)&luma2x01 = *(uint32_t *)pSrc;
-    *(uint32_t *)&luma2x23 = *(uint32_t *)(pSrc + nNv12Pitch);
-    *(uint32_t *)&uv2 = *(uint32_t *)(pSrc + (nHeight - y) * nNv12Pitch);
-
-    float *pDstBlock = (pBgr + i * ((nHeight * nRgbPitch * 3) >> 2) +
-                        ((blockIdx.x * blockDim.x) << 2) +
-                        ((blockIdx.y * blockDim.y) << 1) * (nRgbPitch >> 2));
-
-    float2 add1;
-    float2 add2;
-    float2 add3;
-    float2 add00, add01, add02, add03;
-    float2 d, e;
-
-    add00.x = 1.1644f * luma2x01.x;
-    add01.x = 1.1644f * luma2x01.y;
-    add00.y = 1.1644f * luma2x01.z;
-    add01.y = 1.1644f * luma2x01.w;
-
-    add02.x = 1.1644f * luma2x23.x;
-    add03.x = 1.1644f * luma2x23.y;
-    add02.y = 1.1644f * luma2x23.z;
-    add03.y = 1.1644f * luma2x23.w;
-
-    d.x = uv2.x - 128.0f;
-    e.x = uv2.y - 128.0f;
-    d.y = uv2.z - 128.0f;
-    e.y = uv2.w - 128.0f;
-
-    add1.x = 2.0172f * d.x;
-    add1.y = 2.0172f * d.y;
-
-    add2.x = (-0.3918f) * d.x + (-0.8130f) * e.x;
-    add2.y = (-0.3918f) * d.y + (-0.8130f) * e.y;
-
-    add3.x = 1.5960f * e.x;
-    add3.y = 1.5960f * e.y;
-
-    int rowStride = (threadIdx.y << 1) * (nRgbPitch >> 2);
-    int nextRowStride = ((threadIdx.y << 1) + 1) * (nRgbPitch >> 2);
-    // B
-    *((float4 *)&pDstBlock[rowStride + (threadIdx.x << 2)]) =
-        make_float4(clampF(add00.x + add1.x, 0.0f, 255.0f),
-                    clampF(add01.x + add1.x, 0.0f, 255.0f),
-                    clampF(add00.y + add1.y, 0.0f, 255.0f),
-                    clampF(add01.y + add1.y, 0.0f, 255.0f));
-    *((float4 *)&pDstBlock[nextRowStride + (threadIdx.x << 2)]) =
-        make_float4(clampF(add02.x + add1.x, 0.0f, 255.0f),
-                    clampF(add03.x + add1.x, 0.0f, 255.0f),
-                    clampF(add02.y + add1.y, 0.0f, 255.0f),
-                    clampF(add03.y + add1.y, 0.0f, 255.0f));
-
-    int planeStride = nHeight * nRgbPitch >> 2;
-    // G
-    *((float4 *)&pDstBlock[planeStride + rowStride + (threadIdx.x << 2)]) =
-        make_float4(clampF(add00.x + add2.x, 0.0f, 255.0f),
-                    clampF(add01.x + add2.x, 0.0f, 255.0f),
-                    clampF(add00.y + add2.y, 0.0f, 255.0f),
-                    clampF(add01.y + add2.y, 0.0f, 255.0f));
-    *((float4 *)&pDstBlock[planeStride + nextRowStride + (threadIdx.x << 2)]) =
-        make_float4(clampF(add02.x + add2.x, 0.0f, 255.0f),
-                    clampF(add03.x + add2.x, 0.0f, 255.0f),
-                    clampF(add02.y + add2.y, 0.0f, 255.0f),
-                    clampF(add03.y + add2.y, 0.0f, 255.0f));
-
-    // R
-    *((float4
-           *)&pDstBlock[(planeStride << 1) + rowStride + (threadIdx.x << 2)]) =
-        make_float4(clampF(add00.x + add3.x, 0.0f, 255.0f),
-                    clampF(add01.x + add3.x, 0.0f, 255.0f),
-                    clampF(add00.y + add3.y, 0.0f, 255.0f),
-                    clampF(add01.y + add3.y, 0.0f, 255.0f));
-    *((float4 *)&pDstBlock[(planeStride << 1) + nextRowStride +
-                           (threadIdx.x << 2)]) =
-        make_float4(clampF(add02.x + add3.x, 0.0f, 255.0f),
-                    clampF(add03.x + add3.x, 0.0f, 255.0f),
-                    clampF(add02.y + add3.y, 0.0f, 255.0f),
-                    clampF(add03.y + add3.y, 0.0f, 255.0f));
-  }
-}
-
-void nv12ToBGRplanarBatch(uint8_t *pNv12, int nNv12Pitch, float *pBgr,
-                          int nRgbPitch, int nWidth, int nHeight,
-                          int nBatchSize, hipStream_t stream) {
-  dim3 threads(CONV_THREADS_X, CONV_THREADS_Y);
-
-  size_t blockDimZ = nBatchSize;
-
-  // Restricting blocks in Z-dim till 32 to not launch too many blocks
-  blockDimZ = (blockDimZ > 32) ? 32 : blockDimZ;
-
-  dim3 blocks((nWidth / 4 - 1) / threads.x + 1,
-              (nHeight / 2 - 1) / threads.y + 1, blockDimZ);
-  nv12ToBGRplanarBatchKernel<<<blocks, threads, 0, stream>>>(
-      pNv12, nNv12Pitch, pBgr, nRgbPitch, nWidth, nHeight, nBatchSize);
-}
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/resize_convert.h b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/resize_convert.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/resize_convert_hipified.h b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/resize_convert_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/resize_convert_main.cpp b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/resize_convert_main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/resize_convert_main_hipified.cpp b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/resize_convert_main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/utils.cu b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/utils.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/utils.cu.hip b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/utils.cu.hip
old mode 100644
new mode 100755
index fa4561d..e69de29
--- a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/utils.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/utils.cu.hip
@@ -1,153 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdlib.h>
-#include <sys/stat.h>
-#include <sys/types.h>
-#include <fstream>
-#include <iostream>
-#include "HIPCHECK.h"
-#include <hip/hip_runtime.h>
-#include <hip/hip_runtime.h>
-
-#include "resize_convert_hipified.h"
-#include "utils_hipified.h"
-
-__global__ void floatToChar(float *src, unsigned char *dst, int height,
-                            int width, int batchSize) {
-  int x = threadIdx.x + blockIdx.x * blockDim.x;
-
-  if (x >= height * width) return;
-
-  int offset = height * width * 3;
-
-  for (int j = 0; j < batchSize; j++) {
-    // b
-    *(dst + j * offset + x * 3 + 0) =
-        (unsigned char)*(src + j * offset + height * width * 0 + x);
-    // g
-    *(dst + j * offset + x * 3 + 1) =
-        (unsigned char)*(src + j * offset + height * width * 1 + x);
-    // r
-    *(dst + j * offset + x * 3 + 2) =
-        (unsigned char)*(src + j * offset + height * width * 2 + x);
-  }
-}
-
-void floatPlanarToChar(float *src, unsigned char *dst, int height, int width,
-                       int batchSize) {
-  floatToChar<<<(height * width - 1) / 1024 + 1, 1024, 0, NULL>>>(
-      src, dst, height, width, batchSize);
-}
-
-void dumpRawBGR(float *d_srcBGR, int pitch, int width, int height,
-                int batchSize, char *folder, char *tag) {
-  float *bgr, *d_bgr;
-  int frameSize;
-  char directory[120];
-  char mkdir_cmd[256];
-#if !defined(_WIN32)
-  sprintf(directory, "output/%s", folder);
-  sprintf(mkdir_cmd, "mkdir -p %s 2> /dev/null", directory);
-#else
-  sprintf(directory, "output\\%s", folder);
-  sprintf(mkdir_cmd, "mkdir %s 2> nul", directory);
-#endif
-
-  int ret = system(mkdir_cmd);
-
-  frameSize = width * height * 3 * sizeof(float);
-  bgr = (float *)malloc(frameSize);
-  if (bgr == NULL) {
-    std::cerr << "Failed malloc for bgr\n";
-    return;
-  }
-
-  d_bgr = d_srcBGR;
-  for (int i = 0; i < batchSize; i++) {
-    char filename[120];
-    std::ofstream *outputFile;
-
-    HIPCHECK(hipMemcpy((void *)bgr, (void *)d_bgr, frameSize,
-                               hipMemcpyDeviceToHost));
-    sprintf(filename, "%s/%s_%d.raw", directory, tag, (i + 1));
-
-    outputFile = new std::ofstream(filename);
-    if (outputFile) {
-      outputFile->write((char *)bgr, frameSize);
-      delete outputFile;
-    }
-
-    d_bgr += pitch * height * 3;
-  }
-
-  free(bgr);
-}
-
-void dumpBGR(float *d_srcBGR, int pitch, int width, int height, int batchSize,
-             char *folder, char *tag) {
-  dumpRawBGR(d_srcBGR, pitch, width, height, batchSize, folder, tag);
-}
-
-void dumpYUV(unsigned char *d_nv12, int size, char *folder, char *tag) {
-  unsigned char *nv12Data;
-  std::ofstream *nv12File;
-  char filename[120];
-  char directory[60];
-  char mkdir_cmd[256];
-#if !defined(_WIN32)
-  sprintf(directory, "output/%s", folder);
-  sprintf(mkdir_cmd, "mkdir -p %s 2> /dev/null", directory);
-#else
-  sprintf(directory, "output\\%s", folder);
-  sprintf(mkdir_cmd, "mkdir %s 2> nul", directory);
-#endif
-
-  int ret = system(mkdir_cmd);
-
-  sprintf(filename, "%s/%s.nv12", directory, tag);
-
-  nv12File = new std::ofstream(filename);
-  if (nv12File == NULL) {
-    std::cerr << "Failed to new " << filename;
-    return;
-  }
-
-  nv12Data = (unsigned char *)malloc(size * (sizeof(char)));
-  if (nv12Data == NULL) {
-    std::cerr << "Failed to allcoate memory\n";
-    return;
-  }
-
-  hipMemcpy((void *)nv12Data, (void *)d_nv12, size, hipMemcpyDeviceToHost);
-
-  nv12File->write((const char *)nv12Data, size);
-
-  free(nv12Data);
-  delete nv12File;
-}
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/utils.h b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/utils.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/utils_hipified.h b/src/samples/Samples/5_Domain_Specific/NV12toBGRandResize/utils_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/README.md b/src/samples/Samples/5_Domain_Specific/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/Makefile b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/README.md b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture.cpp b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_hipified.cpp b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2017.sln b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2019.sln b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2022.sln b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/SLID3D10Texture_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/data/ref_SLID3D10Texture.ppm b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/data/ref_SLID3D10Texture.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/texture_2d.cu b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/texture_2d.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/texture_2d.cu.hip b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/texture_2d.cu.hip
old mode 100644
new mode 100755
index e3fbb51..e69de29
--- a/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/texture_2d.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/SLID3D10Texture/texture_2d.cu.hip
@@ -1,91 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-//
-// Paint a 2D texture with a moving red/green hatch pattern on a
-// strobing blue background.  Note that this kernel reads to and
-// writes from the texture, hence why this texture was not mapped
-// as WriteDiscard.
-//
-__global__ void cuda_kernel_texture_2d(unsigned char *surface, int width,
-                                       int height, size_t pitch, float t) {
-  int x = blockIdx.x * blockDim.x + threadIdx.x;
-  int y = blockIdx.y * blockDim.y + threadIdx.y;
-  float *pixel;
-
-  // in the case where, due to quantization into grids, we have
-  // more threads than pixels, skip the threads which don't
-  // correspond to valid pixels
-  if (x >= width || y >= height) return;
-
-  // get a pointer to the pixel at (x,y)
-  pixel = (float *)(surface + y * pitch) + 4 * x;
-
-  // populate it
-  float value_x = 0.5f + 0.5f * cos(t + 10.0f * ((2.0f * x) / width - 1.0f));
-  float value_y = 0.5f + 0.5f * cos(t + 10.0f * ((2.0f * y) / height - 1.0f));
-  pixel[0] = value_x > 0.5 ? 1 : 0;
-  pixel[1] = value_y > 0.5 ? 1 : 0;
-  pixel[2] = 0.5f + 0.5f * cos(t);
-  pixel[3] = 1;  // alpha
-
-  for (int i = 0; i < 6; ++i) {
-    for (int j = 0; j < 4; ++j) {
-      pixel[j] = sqrt(pixel[j]);
-    }
-  }
-
-  for (int i = 0; i < 6; ++i) {
-    for (int j = 0; j < 4; ++j) {
-      pixel[j] *= pixel[j];
-    }
-  }
-}
-
-extern "C" void cuda_texture_2d(void *surface, int width, int height,
-                                size_t pitch, float t) {
-  hipError_t error = hipSuccess;
-
-  dim3 Db = dim3(16, 16);  // block dimensions are fixed to be 256 threads
-  dim3 Dg = dim3((width + Db.x - 1) / Db.x, (height + Db.y - 1) / Db.y);
-
-  cuda_kernel_texture_2d<<<Dg, Db>>>((unsigned char *)surface, width, height,
-                                     pitch, t);
-
-  error = hipGetLastError();
-
-  if (error != hipSuccess) {
-    printf("cuda_kernel_texture_2d() failed to launch error = %d\n", error);
-  }
-}
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/SobelFilter/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/SobelFilter/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/SobelFilter/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/SobelFilter/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/Makefile b/src/samples/Samples/5_Domain_Specific/SobelFilter/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/SobelFilter/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/README.md b/src/samples/Samples/5_Domain_Specific/SobelFilter/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter.cpp b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_hipified.cpp b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_kernels.cu b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_kernels.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_kernels.cu.hip b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_kernels.cu.hip
old mode 100644
new mode 100755
index 5f6a4ee..19a887e
--- a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_kernels.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_kernels.cu.hip
@@ -293,3 +293,6 @@ extern "C" void sobelFilter(Pixel *odata, int iw, int ih,
     } break;
   }
 }
+         iw, ih, fScale, texObject);
+    } break;
+  }
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_kernels.h b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_kernels.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_kernels_hipified.h b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_kernels_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2017.sln b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2019.sln b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2022.sln b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/SobelFilter/SobelFilter_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/data/ref_orig.pgm b/src/samples/Samples/5_Domain_Specific/SobelFilter/data/ref_orig.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/data/ref_shared.pgm b/src/samples/Samples/5_Domain_Specific/SobelFilter/data/ref_shared.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/data/ref_tex.pgm b/src/samples/Samples/5_Domain_Specific/SobelFilter/data/ref_tex.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/data/teapot.pgm b/src/samples/Samples/5_Domain_Specific/SobelFilter/data/teapot.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/doc/sshot_lg.JPG b/src/samples/Samples/5_Domain_Specific/SobelFilter/doc/sshot_lg.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/doc/sshot_md.JPG b/src/samples/Samples/5_Domain_Specific/SobelFilter/doc/sshot_md.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/doc/sshot_sm.JPG b/src/samples/Samples/5_Domain_Specific/SobelFilter/doc/sshot_sm.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobelFilter/findgllib.mk b/src/samples/Samples/5_Domain_Specific/SobelFilter/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/SobolQRNG/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/SobolQRNG/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/SobolQRNG/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/SobolQRNG/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/Makefile b/src/samples/Samples/5_Domain_Specific/SobolQRNG/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/SobolQRNG/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/README.md b/src/samples/Samples/5_Domain_Specific/SobolQRNG/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG.out b/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2017.sln b/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2019.sln b/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2022.sln b/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/SobolQRNG/SobolQRNG_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol.cpp b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol.h b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gold.cpp b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gold.h b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gold.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gold_hipified.cpp b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gold_hipified.h b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gold_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gpu.cu b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gpu.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gpu.cu.hip b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gpu.cu.hip
old mode 100644
new mode 100755
index 388ff07..e69de29
--- a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gpu.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gpu.cu.hip
@@ -1,208 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Portions Copyright (c) 2009 Mike Giles, Oxford University.  All rights
- * reserved.
- * Portions Copyright (c) 2008 Frances Y. Kuo and Stephen Joe.  All rights
- * reserved.
- *
- * Sobol Quasi-random Number Generator example
- *
- * Based on CUDA code submitted by Mike Giles, Oxford University, United Kingdom
- * http://people.maths.ox.ac.uk/~gilesm/
- *
- * and C code developed by Stephen Joe, University of Waikato, New Zealand
- * and Frances Kuo, University of New South Wales, Australia
- * http://web.maths.unsw.edu.au/~fkuo/sobol/
- *
- * For theoretical background see:
- *
- * P. Bratley and B.L. Fox.
- * Implementing Sobol's quasirandom sequence generator
- * http://portal.acm.org/citation.cfm?id=42288
- * ACM Trans. on Math. Software, 14(1):88-100, 1988
- *
- * S. Joe and F. Kuo.
- * Remark on algorithm 659: implementing Sobol's quasirandom sequence generator.
- * http://portal.acm.org/citation.cfm?id=641879
- * ACM Trans. on Math. Software, 29(1):49-57, 2003
- *
- */
-
-#include "sobol.h"
-#include "sobol_gpu.h"
-#include <hip/hip_cooperative_groups.h>
-#include "HIPCHECK.h"
-namespace cg = cooperative_groups;
-#include "helper_cuda_hipified.h"
-
-#define k_2powneg32 2.3283064E-10F
-
-__global__ void sobolGPU_kernel(unsigned n_vectors, unsigned n_dimensions,
-                                unsigned *d_directions, float *d_output) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  __shared__ unsigned int v[n_directions];
-
-  // Offset into the correct dimension as specified by the
-  // block y coordinate
-  d_directions = d_directions + n_directions * blockIdx.y;
-  d_output = d_output + n_vectors * blockIdx.y;
-
-  // Copy the direction numbers for this dimension into shared
-  // memory - there are only 32 direction numbers so only the
-  // first 32 (n_directions) threads need participate.
-  if (threadIdx.x < n_directions) {
-    v[threadIdx.x] = d_directions[threadIdx.x];
-  }
-
-  cg::sync(cta);
-
-  // Set initial index (i.e. which vector this thread is
-  // computing first) and stride (i.e. step to the next vector
-  // for this thread)
-  int i0 = threadIdx.x + blockIdx.x * blockDim.x;
-  int stride = gridDim.x * blockDim.x;
-
-  // Get the gray code of the index
-  // c.f. Numerical Recipes in C, chapter 20
-  // http://www.nrbook.com/a/bookcpdf/c20-2.pdf
-  unsigned int g = i0 ^ (i0 >> 1);
-
-  // Initialisation for first point x[i0]
-  // In the Bratley and Fox paper this is equation (*), where
-  // we are computing the value for x[n] without knowing the
-  // value of x[n-1].
-  unsigned int X = 0;
-  unsigned int mask;
-
-  for (unsigned int k = 0; k < __ffs(stride) - 1; k++) {
-    // We want X ^= g_k * v[k], where g_k is one or zero.
-    // We do this by setting a mask with all bits equal to
-    // g_k. In reality we keep shifting g so that g_k is the
-    // LSB of g. This way we avoid multiplication.
-    mask = -(g & 1);
-    X ^= mask & v[k];
-    g = g >> 1;
-  }
-
-  if (i0 < n_vectors) {
-    d_output[i0] = (float)X * k_2powneg32;
-  }
-
-  // Now do rest of points, using the stride
-  // Here we want to generate x[i] from x[i-stride] where we
-  // don't have any of the x in between, therefore we have to
-  // revisit the equation (**), this is easiest with an example
-  // so assume stride is 16.
-  // From x[n] to x[n+16] there will be:
-  //   8 changes in the first bit
-  //   4 changes in the second bit
-  //   2 changes in the third bit
-  //   1 change in the fourth
-  //   1 change in one of the remaining bits
-  //
-  // What this means is that in the equation:
-  //   x[n+1] = x[n] ^ v[p]
-  //   x[n+2] = x[n+1] ^ v[q] = x[n] ^ v[p] ^ v[q]
-  //   ...
-  // We will apply xor with v[1] eight times, v[2] four times,
-  // v[3] twice, v[4] once and one other direction number once.
-  // Since two xors cancel out, we can skip even applications
-  // and just apply xor with v[4] (i.e. log2(16)) and with
-  // the current applicable direction number.
-  // Note that all these indices count from 1, so we need to
-  // subtract 1 from them all to account for C arrays counting
-  // from zero.
-  unsigned int v_log2stridem1 = v[__ffs(stride) - 2];
-  unsigned int v_stridemask = stride - 1;
-
-  for (unsigned int i = i0 + stride; i < n_vectors; i += stride) {
-    // x[i] = x[i-stride] ^ v[b] ^ v[c]
-    //  where b is log2(stride) minus 1 for C array indexing
-    //  where c is the index of the rightmost zero bit in i,
-    //  not including the bottom log2(stride) bits, minus 1
-    //  for C array indexing
-    // In the Bratley and Fox paper this is equation (**)
-    X ^= v_log2stridem1 ^ v[__ffs(~((i - stride) | v_stridemask)) - 1];
-    d_output[i] = (float)X * k_2powneg32;
-  }
-}
-
-extern "C" void sobolGPU(int n_vectors, int n_dimensions,
-                         unsigned int *d_directions, float *d_output) {
-  const int threadsperblock = 64;
-
-  // Set up the execution configuration
-  dim3 dimGrid;
-  dim3 dimBlock;
-
-  int device;
-  hipDeviceProp_t prop;
-  HIPCHECK(hipGetDevice(&device));
-  HIPCHECK(hipGetDeviceProperties(&prop, device));
-
-  // This implementation of the generator outputs all the draws for
-  // one dimension in a contiguous region of memory, followed by the
-  // next dimension and so on.
-  // Therefore all threads within a block will be processing different
-  // vectors from the same dimension. As a result we want the total
-  // number of blocks to be a multiple of the number of dimensions.
-  dimGrid.y = n_dimensions;
-
-  // If the number of dimensions is large then we will set the number
-  // of blocks to equal the number of dimensions (i.e. dimGrid.x = 1)
-  // but if the number of dimensions is small (e.g. less than four per
-  // multiprocessor) then we'll partition the vectors across blocks
-  // (as well as threads).
-  if (n_dimensions < (4 * prop.multiProcessorCount)) {
-    dimGrid.x = 4 * prop.multiProcessorCount;
-  } else {
-    dimGrid.x = 1;
-  }
-
-  // Cap the dimGrid.x if the number of vectors is small
-  if (dimGrid.x > (unsigned int)(n_vectors / threadsperblock)) {
-    dimGrid.x = (n_vectors + threadsperblock - 1) / threadsperblock;
-  }
-
-  // Round up to a power of two, required for the algorithm so that
-  // stride is a power of two.
-  unsigned int targetDimGridX = dimGrid.x;
-
-  for (dimGrid.x = 1; dimGrid.x < targetDimGridX; dimGrid.x *= 2)
-    ;
-
-  // Fix the number of threads
-  dimBlock.x = threadsperblock;
-
-  // Execute GPU kernel
-  sobolGPU_kernel<<<dimGrid, dimBlock>>>(n_vectors, n_dimensions, d_directions,
-                                         d_output);
-}
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gpu.h b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gpu.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gpu_hipified.h b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_gpu_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_hipified.cpp b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_hipified.h b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_primitives.cpp b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_primitives.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_primitives.h b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_primitives.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_primitives_hipified.cpp b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_primitives_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_primitives_hipified.h b/src/samples/Samples/5_Domain_Specific/SobolQRNG/sobol_primitives_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/Makefile b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/README.md b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10.cpp b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10.h b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_hipified.cpp b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_hipified.h b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2017.sln b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2019.sln b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2022.sln b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlockingD3D10_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlocking_kernel.cu b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlocking_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlocking_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlocking_kernel.cu.hip
old mode 100644
new mode 100755
index db11cd0..e69de29
--- a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlocking_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/VFlocking_kernel.cu.hip
@@ -1,291 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-#include "helper_cuda_hipified.h"
-#include <helper_math.h>
-#include <VFlockingD3D10.h>
-
-#define PI 3.1415926536f
-
-typedef unsigned int uint;
-
-__device__ bool isInsideQuad_D(float2 pos0, float2 pos1, float width,
-                               float height) {
-  if (fabs(pos0.x - pos1.x) < 0.5f * width &&
-      fabs(pos0.y - pos1.y) < 0.5f * height) {
-    return true;
-  } else {
-    return false;
-  }
-}
-
-__device__ bool isInsideBird(float2 pixel, float2 pos, float width,
-                             float height, float radius) {
-  if (abs(pixel.x - pos.x) < 0.5f * width &&
-          abs(pixel.y - pos.y) < 0.5f * height ||
-      (pixel.x - pos.x) * (pixel.x - pos.x) +
-              (pixel.y - pos.y) * (pixel.y - pos.y) <
-          radius * radius) {
-    return true;
-  } else {
-    return false;
-  }
-}
-
-__global__ void cuda_kernel_update(float2 *newPos, float2 *curPos,
-                                   uint numBirds, bool *hasproxy,
-                                   bool *neighbors, bool *rightgoals,
-                                   bool *leftgoals, Params *params) {
-  uint i = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (i >= numBirds) {
-    return;
-  }
-
-  float minDist = 50000.f;
-  float2 dij = make_float2(0.f);
-
-  if (!hasproxy[i]) {
-    for (uint j = 0; j < numBirds; j++) {
-      if (j == i) {
-        continue;
-      }
-
-      if (leftgoals[i * numBirds + j]) {
-        dij = params->dX * normalize(curPos[j] - curPos[i]);
-        break;
-      }
-    }
-  } else {
-    bool collision = false;
-
-    for (uint j = 0; j < numBirds; j++) {
-      float d;
-
-      if (leftgoals[i * numBirds + j]) {
-        d = curPos[j].x - (params->wingspan + params->lambda) - curPos[i].x;
-
-        if (fabs(d) < fabs(minDist)) {
-          minDist = d;
-        }
-      }
-
-      if (rightgoals[i * numBirds + j]) {
-        d = curPos[j].x + (params->wingspan + params->lambda) - curPos[i].x;
-
-        if (fabs(d) < fabs(minDist)) {
-          minDist = d;
-        }
-      }
-
-      if (neighbors[i * numBirds + j] && !collision) {
-        if (curPos[j].y >= curPos[i].y &&
-            curPos[j].y < curPos[i].y + params->epsilon) {
-          dij.y = -params->dY;
-          collision = true;
-        }
-      }
-    }
-
-    if (fabs(minDist) <= params->dX) {
-      return;
-    }
-
-    dij.x = minDist > 0 ? params->dX : -params->dX;
-  }
-
-  newPos[i].x = curPos[i].x + dij.x;
-  newPos[i].y = curPos[i].y + dij.y;
-}
-
-__global__ void cuda_kernel_checktriples(float2 *pos, uint numBirds,
-                                         bool *hasproxy, bool *neighbors,
-                                         bool *rightgoals, bool *leftgoals,
-                                         uint3 *triples, Params *params) {
-  uint ith = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (ith >= numBirds * (numBirds - 1) * (numBirds - 2) / 6) {
-    return;
-  }
-
-  uint a[3];
-  a[0] = triples[ith].x;
-  a[1] = triples[ith].y;
-  a[2] = triples[ith].z;
-
-  uint i, j, x;
-
-  for (i = 0; i < 3; i++) {
-    for (j = 2; j > i; j--) {
-      if (pos[a[j - 1]].y > pos[a[j]].y) {
-        x = a[j - 1];
-        a[j - 1] = a[j];
-        a[j] = x;
-      }
-    }
-  }
-
-  if (hasproxy[a[0]]) {
-    float a2a1 = pos[a[2]].x - pos[a[1]].x;
-
-    if (fabs(a2a1) < 2.f * (params->wingspan + params->lambda))
-      if (a2a1 >= 0) {
-        if (leftgoals[a[0] * numBirds + a[2]]) {
-          leftgoals[a[0] * numBirds + a[2]] = false;
-        }
-
-        if (rightgoals[a[0] * numBirds + a[1]]) {
-          rightgoals[a[0] * numBirds + a[1]] = false;
-        }
-      } else {
-        if (leftgoals[a[0] * numBirds + a[1]]) {
-          leftgoals[a[0] * numBirds + a[1]] = false;
-        }
-
-        if (rightgoals[a[0] * numBirds + a[2]]) {
-          rightgoals[a[0] * numBirds + a[2]] = false;
-        }
-      }
-  } else {
-    if ((leftgoals[a[0] * numBirds + a[2]]) &&
-        (leftgoals[a[0] * numBirds + a[1]]))
-      if ((length(pos[a[1]] - pos[a[0]]) < length(pos[a[2]] - pos[a[0]]))) {
-        leftgoals[a[0] * numBirds + a[2]] = false;
-      } else {
-        leftgoals[a[0] * numBirds + a[1]] = false;
-      }
-  }
-}
-
-__global__ void cuda_kernel_checkpairs(float2 *pos, uint numBirds,
-                                       bool *hasproxy, bool *neighbors,
-                                       bool *rightgoals, bool *leftgoals,
-                                       uint2 *pairs, Params *params) {
-  uint i = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (i >= numBirds * (numBirds - 1) / 2) {
-    return;
-  }
-
-  uint front, back;
-
-  if (pos[pairs[i].y].y > pos[pairs[i].x].y) {
-    front = pairs[i].y;
-    back = pairs[i].x;
-  } else {
-    front = pairs[i].x;
-    back = pairs[i].y;
-  }
-
-  leftgoals[back * numBirds + front] = true;
-  rightgoals[back * numBirds + front] = true;
-
-  float2 stepback;
-  stepback.x = pos[front].x;
-  stepback.y = pos[front].y - 0.5f * params->upwashY;
-
-  if (isInsideQuad_D(
-          pos[back], stepback,
-          2.f * (params->wingspan + params->lambda + params->upwashX),
-          params->upwashY)) {
-    neighbors[back * numBirds + front] = true;
-
-    if (!hasproxy[back]) {
-      hasproxy[back] = true;
-    }
-  }
-}
-
-extern "C" void cuda_simulate(float2 *newPos, float2 *curPos, uint numBirds,
-                              bool *d_hasproxy, bool *d_neighbors,
-                              bool *d_leftgoals, bool *d_rightgoals,
-                              uint2 *d_pairs, uint3 *d_triples,
-                              Params *d_params) {
-  hipError_t error = hipSuccess;
-  float tempms;
-  static float ms = 0.f;
-  static uint step = 0;
-  int smallblockSize = 32, midblockSize = 128, bigblockSize = 32;
-
-  hipEvent_t e_start, e_stop;
-  hipEventCreate(&e_start);
-  hipEventCreate(&e_stop);
-  hipEventRecord(e_start, 0);
-
-  hipMemset(d_leftgoals, 0, numBirds * numBirds * sizeof(bool));
-  hipMemset(d_rightgoals, 0, numBirds * numBirds * sizeof(bool));
-  hipMemset(d_hasproxy, 0, numBirds * sizeof(bool));
-  hipMemset(d_neighbors, 0, numBirds * numBirds * sizeof(bool));
-
-  dim3 Db = dim3(bigblockSize);
-  dim3 Dg =
-      dim3((numBirds * (numBirds - 1) / 2 + bigblockSize - 1) / bigblockSize);
-  cuda_kernel_checkpairs<<<Dg, Db>>>(curPos, numBirds, d_hasproxy, d_neighbors,
-                                     d_rightgoals, d_leftgoals, d_pairs,
-                                     d_params);
-
-  Db = dim3(midblockSize);
-  Dg =
-      dim3((numBirds * (numBirds - 1) * (numBirds - 2) / 6 + bigblockSize - 1) /
-           bigblockSize);
-  cuda_kernel_checktriples<<<Dg, Db>>>(curPos, numBirds, d_hasproxy,
-                                       d_neighbors, d_rightgoals, d_leftgoals,
-                                       d_triples, d_params);
-
-  Db = dim3(smallblockSize);
-  Dg = dim3((numBirds + smallblockSize - 1) / smallblockSize);
-  cuda_kernel_update<<<Dg, Db>>>(newPos, curPos, numBirds, d_hasproxy,
-                                 d_neighbors, d_rightgoals, d_leftgoals,
-                                 d_params /*, d_pWingTips */);
-
-  hipDeviceSynchronize();
-
-  hipEventRecord(e_stop, 0);
-  hipEventSynchronize(e_stop);
-  hipEventElapsedTime(&tempms, e_start, e_stop);
-  ms += tempms;
-
-  if (!(step % 100) && step) {
-    printf("GPU, step %d \ntime per step %6.3f ms \n", step, ms / 100.f);
-    ms = 0.f;
-  }
-
-  step++;
-
-  error = hipGetLastError();
-
-  if (error != hipSuccess) {
-    printf("one of the cuda kernels failed to launch, error = %d\n", error);
-  }
-}
diff --git a/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/data/ref_VFlockingD3D10.ppm b/src/samples/Samples/5_Domain_Specific/VFlockingD3D10/data/ref_VFlockingD3D10.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/bicubicTexture/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/bicubicTexture/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/bicubicTexture/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/bicubicTexture/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/Makefile b/src/samples/Samples/5_Domain_Specific/bicubicTexture/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/bicubicTexture/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/README.md b/src/samples/Samples/5_Domain_Specific/bicubicTexture/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture.cpp b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_cuda.cu b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_cuda.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_cuda.cu.hip b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_cuda.cu.hip
old mode 100644
new mode 100755
index e286e31..e69de29
--- a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_cuda.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_cuda.cu.hip
@@ -1,128 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef _BICUBICTEXTURE_CU_
-#define _BICUBICTEXTURE_CU_
-
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-
-#include <helper_math.h>
-
-// includes, cuda
-#include "helper_cuda_hipified.h"
-
-typedef unsigned int uint;
-typedef unsigned char uchar;
-
-#include "bicubicTexture_kernel.cuh"
-
-hipArray *d_imageArray = 0;
-
-extern "C" void initTexture(int imageWidth, int imageHeight, uchar *h_data) {
-  // allocate array and copy image data
-  hipChannelFormatDesc channelDesc =
-      hipCreateChannelDesc(8, 0, 0, 0, hipChannelFormatKindUnsigned);
-  HIPCHECK(
-      hipMallocArray(&d_imageArray, &channelDesc, imageWidth, imageHeight));
-  HIPCHECK(hipMemcpy2DToArray(
-      d_imageArray, 0, 0, h_data, imageWidth * sizeof(uchar),
-      imageWidth * sizeof(uchar), imageHeight, hipMemcpyHostToDevice));
-  free(h_data);
-
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = d_imageArray;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeClamp;
-  texDescr.addressMode[1] = hipAddressModeClamp;
-  texDescr.readMode = hipReadModeNormalizedFloat;
-
-  HIPCHECK(
-      hipCreateTextureObject(&texObjLinear, &texRes, &texDescr, NULL));
-
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModePoint;
-  texDescr.addressMode[0] = hipAddressModeClamp;
-  texDescr.addressMode[1] = hipAddressModeClamp;
-  texDescr.readMode = hipReadModeNormalizedFloat;
-
-  HIPCHECK(
-      hipCreateTextureObject(&texObjPoint, &texRes, &texDescr, NULL));
-}
-
-extern "C" void freeTexture() {
-  HIPCHECK(hipDestroyTextureObject(texObjPoint));
-  HIPCHECK(hipDestroyTextureObject(texObjLinear));
-  HIPCHECK(hipFreeArray(d_imageArray));
-}
-
-// render image using CUDA
-extern "C" void render(int width, int height, float tx, float ty, float scale,
-                       float cx, float cy, dim3 blockSize, dim3 gridSize,
-                       int filter_mode, uchar4 *output) {
-  // call CUDA kernel, writing results to PBO memory
-  switch (filter_mode) {
-    case MODE_NEAREST:
-      d_render<<<gridSize, blockSize>>>(output, width, height, tx, ty, scale,
-                                        cx, cy, texObjPoint);
-      break;
-
-    case MODE_BILINEAR:
-      d_render<<<gridSize, blockSize>>>(output, width, height, tx, ty, scale,
-                                        cx, cy, texObjLinear);
-      break;
-
-    case MODE_BICUBIC:
-      d_renderBicubic<<<gridSize, blockSize>>>(output, width, height, tx, ty,
-                                               scale, cx, cy, texObjPoint);
-      break;
-
-    case MODE_FAST_BICUBIC:
-      d_renderFastBicubic<<<gridSize, blockSize>>>(
-          output, width, height, tx, ty, scale, cx, cy, texObjLinear);
-      break;
-
-    case MODE_CATROM:
-      d_renderCatRom<<<gridSize, blockSize>>>(output, width, height, tx, ty,
-                                              scale, cx, cy, texObjPoint);
-      break;
-  }
-
-  getLastCudaError("kernel failed");
-}
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_hipified.cpp b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_kernel.cuh b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_kernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2017.sln b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2019.sln b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2022.sln b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/bicubicTexture/bicubicTexture_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/data/0_nearest.ppm b/src/samples/Samples/5_Domain_Specific/bicubicTexture/data/0_nearest.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/data/1_bilinear.ppm b/src/samples/Samples/5_Domain_Specific/bicubicTexture/data/1_bilinear.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/data/2_bicubic.ppm b/src/samples/Samples/5_Domain_Specific/bicubicTexture/data/2_bicubic.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/data/3_fastbicubic.ppm b/src/samples/Samples/5_Domain_Specific/bicubicTexture/data/3_fastbicubic.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/data/4_catmull-rom.ppm b/src/samples/Samples/5_Domain_Specific/bicubicTexture/data/4_catmull-rom.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/data/teapot512.pgm b/src/samples/Samples/5_Domain_Specific/bicubicTexture/data/teapot512.pgm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bicubicTexture/findgllib.mk b/src/samples/Samples/5_Domain_Specific/bicubicTexture/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/bilateralFilter/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/bilateralFilter/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/bilateralFilter/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/bilateralFilter/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/Makefile b/src/samples/Samples/5_Domain_Specific/bilateralFilter/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/bilateralFilter/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/README.md b/src/samples/Samples/5_Domain_Specific/bilateralFilter/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter.cpp b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_cpu.cpp b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_cpu.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_cpu_hipified.cpp b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_cpu_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_hipified.cpp b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2017.sln b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2019.sln b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2022.sln b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateralFilter_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateral_kernel.cu b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateral_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateral_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateral_kernel.cu.hip
old mode 100644
new mode 100755
index 448b22b..e69de29
--- a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateral_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bilateral_kernel.cu.hip
@@ -1,264 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <helper_math.h>
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"  // CUDA device initialization helper functions
-
-__constant__ float cGaussian[64];  // gaussian array in device side
-
-hipTextureObject_t rgbaTexdImage;
-hipTextureObject_t rgbaTexdTemp;
-
-uint *dImage = NULL;  // original image
-uint *dTemp = NULL;  // temp array for iterations
-size_t pitch;
-
-/*
-    Perform a simple bilateral filter.
-
-    Bilateral filter is a nonlinear filter that is a mixture of range
-    filter and domain filter, the previous one preserves crisp edges and
-    the latter one filters noise. The intensity value at each pixel in
-    an image is replaced by a weighted average of intensity values from
-    nearby pixels.
-
-    The weight factor is calculated by the product of domain filter
-    component(using the gaussian distribution as a spatial distance) as
-    well as range filter component(Euclidean distance between center pixel
-    and the current neighbor pixel). Because this process is nonlinear,
-    the sample just uses a simple pixel by pixel step.
-
-    Texture fetches automatically clamp to edge of image. 1D gaussian array
-    is mapped to a 1D texture instead of using shared memory, which may
-    cause severe bank conflict.
-
-    Threads are y-pass(column-pass), because the output is coalesced.
-
-    Parameters
-    od - pointer to output data in global memory
-    d_f - pointer to the 1D gaussian array
-    e_d - euclidean delta
-    w  - image width
-    h  - image height
-    r  - filter radius
-*/
-
-// Euclidean Distance (x, y, d) = exp((|x - y| / d)^2 / 2)
-__device__ float euclideanLen(float4 a, float4 b, float d) {
-  float mod = (b.x - a.x) * (b.x - a.x) + (b.y - a.y) * (b.y - a.y) +
-              (b.z - a.z) * (b.z - a.z);
-
-  return __expf(-mod / (2.f * d * d));
-}
-
-__device__ uint rgbaFloatToInt(float4 rgba) {
-  rgba.x = __saturatef(fabs(rgba.x));  // clamp to [0.0, 1.0]
-  rgba.y = __saturatef(fabs(rgba.y));
-  rgba.z = __saturatef(fabs(rgba.z));
-  rgba.w = __saturatef(fabs(rgba.w));
-  return (uint(rgba.w * 255.0f) << 24) | (uint(rgba.z * 255.0f) << 16) |
-         (uint(rgba.y * 255.0f) << 8) | uint(rgba.x * 255.0f);
-}
-
-__device__ float4 rgbaIntToFloat(uint c) {
-  float4 rgba;
-  rgba.x = (c & 0xff) * 0.003921568627f;          //  /255.0f;
-  rgba.y = ((c >> 8) & 0xff) * 0.003921568627f;   //  /255.0f;
-  rgba.z = ((c >> 16) & 0xff) * 0.003921568627f;  //  /255.0f;
-  rgba.w = ((c >> 24) & 0xff) * 0.003921568627f;  //  /255.0f;
-  return rgba;
-}
-
-// column pass using coalesced global memory reads
-__global__ void d_bilateral_filter(uint *od, int w, int h, float e_d, int r,
-                                   hipTextureObject_t rgbaTex) {
-  int x = blockIdx.x * blockDim.x + threadIdx.x;
-  int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  if (x >= w || y >= h) {
-    return;
-  }
-
-  float sum = 0.0f;
-  float factor;
-  float4 t = {0.f, 0.f, 0.f, 0.f};
-  float4 center = tex2D<float4>(rgbaTex, x, y);
-
-  for (int i = -r; i <= r; i++) {
-    for (int j = -r; j <= r; j++) {
-      float4 curPix = tex2D<float4>(rgbaTex, x + j, y + i);
-      factor = cGaussian[i + r] * cGaussian[j + r] *  // domain factor
-               euclideanLen(curPix, center, e_d);  // range factor
-
-      t += factor * curPix;
-      sum += factor;
-    }
-  }
-
-  od[y * w + x] = rgbaFloatToInt(t / sum);
-}
-
-extern "C" void initTexture(int width, int height, uint *hImage) {
-  // copy image data to array
-  HIPCHECK(
-      hipMallocPitch(&dImage, &pitch, sizeof(uint) * width, height));
-  HIPCHECK(
-      hipMallocPitch(&dTemp, &pitch, sizeof(uint) * width, height));
-  HIPCHECK(hipMemcpy2D(dImage, pitch, hImage, sizeof(uint) * width,
-                               sizeof(uint) * width, height,
-                               hipMemcpyHostToDevice));
-
-  // texture<uchar4, 2, hipReadModeNormalizedFloat> rgbaTex;
-  hipChannelFormatDesc desc = hipCreateChannelDesc<uchar4>();
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypePitch2D;
-  texRes.res.pitch2D.devPtr = dImage;
-  texRes.res.pitch2D.desc = desc;
-  texRes.res.pitch2D.width = width;
-  texRes.res.pitch2D.height = height;
-  texRes.res.pitch2D.pitchInBytes = pitch;
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModePoint;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeNormalizedFloat;
-
-  HIPCHECK(
-      hipCreateTextureObject(&rgbaTexdImage, &texRes, &texDescr, NULL));
-
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypePitch2D;
-  texRes.res.pitch2D.devPtr = dTemp;
-  texRes.res.pitch2D.desc = desc;
-  texRes.res.pitch2D.width = width;
-  texRes.res.pitch2D.height = height;
-  texRes.res.pitch2D.pitchInBytes = pitch;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeNormalizedFloat;
-
-  HIPCHECK(
-      hipCreateTextureObject(&rgbaTexdTemp, &texRes, &texDescr, NULL));
-}
-
-extern "C" void freeTextures() {
-  HIPCHECK(hipDestroyTextureObject(rgbaTexdImage));
-  HIPCHECK(hipDestroyTextureObject(rgbaTexdTemp));
-  HIPCHECK(hipFree(dImage));
-  HIPCHECK(hipFree(dTemp));
-}
-
-/*
-    Because a 2D gaussian mask is symmetry in row and column,
-    here only generate a 1D mask, and use the product by row
-    and column index later.
-
-    1D gaussian distribution :
-        g(x, d) -- C * exp(-x^2/d^2), C is a constant amplifier
-
-    parameters:
-    og - output gaussian array in global memory
-    delta - the 2nd parameter 'd' in the above function
-    radius - half of the filter size
-             (total filter size = 2 * radius + 1)
-*/
-extern "C" void updateGaussian(float delta, int radius) {
-  float fGaussian[64];
-
-  for (int i = 0; i < 2 * radius + 1; ++i) {
-    float x = (float)(i - radius);
-    fGaussian[i] = expf(-(x * x) / (2 * delta * delta));
-  }
-
-  HIPCHECK(hipMemcpyToSymbol(HIP_SYMBOL(cGaussian), fGaussian,
-                                     sizeof(float) * (2 * radius + 1)));
-}
-
-/*
-    Perform 2D bilateral filter on image using CUDA
-
-    Parameters:
-    d_dest - pointer to destination image in device memory
-    width  - image width
-    height - image height
-    e_d    - euclidean delta
-    radius - filter radius
-    iterations - number of iterations
-*/
-
-// RGBA version
-extern "C" double bilateralFilterRGBA(uint *dDest, int width, int height,
-                                      float e_d, int radius, int iterations,
-                                      StopWatchInterface *timer) {
-  // var for kernel computation timing
-  double dKernelTime;
-
-  for (int i = 0; i < iterations; i++) {
-    // sync host and start kernel computation timer
-    dKernelTime = 0.0;
-    HIPCHECK(hipDeviceSynchronize());
-    sdkResetTimer(&timer);
-
-    dim3 gridSize((width + 16 - 1) / 16, (height + 16 - 1) / 16);
-    dim3 blockSize(16, 16);
-
-    if (iterations > 1) {
-      d_bilateral_filter<<<gridSize, blockSize>>>(dDest, width, height, e_d,
-                                                  radius, rgbaTexdTemp);
-    } else {
-      d_bilateral_filter<<<gridSize, blockSize>>>(dDest, width, height, e_d,
-                                                  radius, rgbaTexdImage);
-    }
-
-    // sync host and stop computation timer
-    HIPCHECK(hipDeviceSynchronize());
-    dKernelTime += sdkGetTimerValue(&timer);
-
-    if (iterations > 1) {
-      // copy result back from global memory to array
-      HIPCHECK(hipMemcpy2D(dTemp, pitch, dDest, sizeof(int) * width,
-                                   sizeof(int) * width, height,
-                                   hipMemcpyDeviceToDevice));
-    }
-  }
-
-  return ((dKernelTime / 1000.) / (double)iterations);
-}
-emcpyDeviceToDevice));
-    }
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bmploader.cpp b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bmploader.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/bmploader_hipified.cpp b/src/samples/Samples/5_Domain_Specific/bilateralFilter/bmploader_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/data/nature_monte.bmp b/src/samples/Samples/5_Domain_Specific/bilateralFilter/data/nature_monte.bmp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/data/ref_05.ppm b/src/samples/Samples/5_Domain_Specific/bilateralFilter/data/ref_05.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/data/ref_06.ppm b/src/samples/Samples/5_Domain_Specific/bilateralFilter/data/ref_06.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/data/ref_07.ppm b/src/samples/Samples/5_Domain_Specific/bilateralFilter/data/ref_07.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/data/ref_08.ppm b/src/samples/Samples/5_Domain_Specific/bilateralFilter/data/ref_08.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/bilateralFilter/findgllib.mk b/src/samples/Samples/5_Domain_Specific/bilateralFilter/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/binomialOptions/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/binomialOptions/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/binomialOptions/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/binomialOptions/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/Makefile b/src/samples/Samples/5_Domain_Specific/binomialOptions/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/binomialOptions/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/README.md b/src/samples/Samples/5_Domain_Specific/binomialOptions/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions.cpp b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions.out b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_common.h b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_common_hipified.h b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_gold.cpp b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_gold_hipified.cpp b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_hipified.cpp b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_kernel.cu b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_kernel.cu.hip
old mode 100644
new mode 100755
index f397019..ee61764
--- a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_kernel.cu.hip
@@ -30,8 +30,6 @@
 // Global types and parameters
 ////////////////////////////////////////////////////////////////////////////////
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <stdlib.h>
 #include <hip/hip_cooperative_groups.h>
 
@@ -151,10 +149,10 @@ extern "C" void binomialOptionsGPU(real *callValue, TOptionData *optionData,
     h_OptionData[i].pdByDf = (real)pdByDf;
   }
 
-  HIPCHECK(hipMemcpyToSymbol(HIP_SYMBOL(d_OptionData), h_OptionData,
+  checkCudaErrors(hipMemcpyToSymbol(HIP_SYMBOL(d_OptionData), h_OptionData,
                                      optN * sizeof(__TOptionData)));
   binomialOptionsKernel<<<optN, THREADBLOCK_SIZE>>>();
   getLastCudaError("binomialOptionsKernel() execution failed.\n");
-  HIPCHECK(
+  checkCudaErrors(
       hipMemcpyFromSymbol(callValue, HIP_SYMBOL(d_CallValue), optN * sizeof(real)));
 }
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2017.sln b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2019.sln b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2022.sln b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/binomialOptions/binomialOptions_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/doc/binomialOptions.doc b/src/samples/Samples/5_Domain_Specific/binomialOptions/doc/binomialOptions.doc
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/doc/binomialOptions.pdf b/src/samples/Samples/5_Domain_Specific/binomialOptions/doc/binomialOptions.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/realtype.h b/src/samples/Samples/5_Domain_Specific/binomialOptions/realtype.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions/realtype_hipified.h b/src/samples/Samples/5_Domain_Specific/binomialOptions/realtype_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/Makefile b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/README.md b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions.cpp b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_common.h b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_common_hipified.h b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_gold.cpp b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_gold_hipified.cpp b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_gpu.cpp b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_gpu.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_gpu_hipified.cpp b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_gpu_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_hipified.cpp b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_kernel.cu b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_kernel.cu.hip
old mode 100644
new mode 100755
index 24fd6b5..e69de29
--- a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_kernel.cu.hip
@@ -1,108 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "common_gpu_header.h"
-#include "binomialOptions_common.h"
-#include "realtype.h"
-
-// Preprocessed input option data
-typedef struct {
-  real S;
-  real X;
-  real vDt;
-  real puByDf;
-  real pdByDf;
-} __TOptionData;
-static __constant__ __TOptionData d_OptionData[MAX_OPTIONS];
-__device__ real d_CallValue[MAX_OPTIONS];
-
-#define THREADBLOCK_SIZE 128
-#define ELEMS_PER_THREAD (NUM_STEPS / THREADBLOCK_SIZE)
-#if NUM_STEPS % THREADBLOCK_SIZE
-#error Bad constants
-#endif
-
-////////////////////////////////////////////////////////////////////////////////
-// Overloaded shortcut functions for different precision modes
-////////////////////////////////////////////////////////////////////////////////
-
-#ifndef DOUBLE_PRECISION
-__device__ inline float expiryCallValue(float S, float X, float vDt, int i) {
-  float d = S * __expf(vDt * (2.0f * i - NUM_STEPS)) - X;
-  return (d > 0.0F) ? d : 0.0F;
-}
-
-#else
-__device__ inline double expiryCallValue(double S, double X, double vDt,
-                                         int i) {
-  double d = S * exp(vDt * (2.0 * i - NUM_STEPS)) - X;
-  return (d > 0.0) ? d : 0.0;
-}
-#endif
-
-////////////////////////////////////////////////////////////////////////////////
-// GPU kernel
-////////////////////////////////////////////////////////////////////////////////
-extern "C" __global__ void binomialOptionsKernel() {
-  __shared__ real call_exchange[THREADBLOCK_SIZE + 1];
-
-  const int tid = threadIdx.x;
-  const real S = d_OptionData[blockIdx.x].S;
-  const real X = d_OptionData[blockIdx.x].X;
-  const real vDt = d_OptionData[blockIdx.x].vDt;
-  const real puByDf = d_OptionData[blockIdx.x].puByDf;
-  const real pdByDf = d_OptionData[blockIdx.x].pdByDf;
-
-  real call[ELEMS_PER_THREAD + 1];
-#pragma unroll
-  for (int i = 0; i < ELEMS_PER_THREAD; ++i)
-    call[i] = expiryCallValue(S, X, vDt, tid * ELEMS_PER_THREAD + i);
-
-  if (tid == 0)
-    call_exchange[THREADBLOCK_SIZE] = expiryCallValue(S, X, vDt, NUM_STEPS);
-
-  int final_it = max(0, tid * ELEMS_PER_THREAD - 1);
-
-#pragma unroll 16
-  for (int i = NUM_STEPS; i > 0; --i) {
-    call_exchange[tid] = call[0];
-    __syncthreads();
-    call[ELEMS_PER_THREAD] = call_exchange[tid + 1];
-    __syncthreads();
-
-    if (i > final_it) {
-#pragma unroll
-      for (int j = 0; j < ELEMS_PER_THREAD; ++j)
-        call[j] = puByDf * call[j + 1] + pdByDf * call[j];
-    }
-  }
-
-  if (tid == 0) {
-    d_CallValue[blockIdx.x] = call[0];
-  }
-}
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2017.sln b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2019.sln b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2022.sln b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/binomialOptions_nvrtc_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/common_gpu_header.h b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/common_gpu_header.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/common_gpu_header_hipified.h b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/common_gpu_header_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/realtype.h b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/realtype.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/realtype_hipified.h b/src/samples/Samples/5_Domain_Specific/binomialOptions_nvrtc/realtype_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/Makefile b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/README.md b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D.cu b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D.cu.hip b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D.cu.hip
old mode 100644
new mode 100755
index 25f8f07..e69de29
--- a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D.cu.hip
@@ -1,321 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <assert.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-#include "helper_cuda_hipified.h"
-#include "convolutionFFT2D_common.h"
-#include "convolutionFFT2D.cuh"
-
-////////////////////////////////////////////////////////////////////////////////
-/// Position convolution kernel center at (0, 0) in the image
-////////////////////////////////////////////////////////////////////////////////
-extern "C" void padKernel(float *d_Dst, float *d_Src, int fftH, int fftW,
-                          int kernelH, int kernelW, int kernelY, int kernelX) {
-  assert(d_Src != d_Dst);
-  dim3 threads(32, 8);
-  dim3 grid(iDivUp(kernelW, threads.x), iDivUp(kernelH, threads.y));
-
-  SET_FLOAT_BASE;
-#if (USE_TEXTURE)
-  hipTextureObject_t texFloat;
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeLinear;
-  texRes.res.linear.devPtr = d_Src;
-  texRes.res.linear.sizeInBytes = sizeof(float) * kernelH * kernelW;
-  texRes.res.linear.desc = hipCreateChannelDesc<float>();
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  checkCudaErrors(hipCreateTextureObject(&texFloat, &texRes, &texDescr, NULL));
-#endif
-
-  padKernel_kernel<<<grid, threads>>>(d_Dst, d_Src, fftH, fftW, kernelH,
-                                      kernelW, kernelY, kernelX
-#if (USE_TEXTURE)
-                                      ,
-                                      texFloat
-#endif
-                                      );
-  getLastCudaError("padKernel_kernel<<<>>> execution failed\n");
-
-#if (USE_TEXTURE)
-  checkCudaErrors(hipDestroyTextureObject(texFloat));
-#endif
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Prepare data for "pad to border" addressing mode
-////////////////////////////////////////////////////////////////////////////////
-extern "C" void padDataClampToBorder(float *d_Dst, float *d_Src, int fftH,
-                                     int fftW, int dataH, int dataW,
-                                     int kernelW, int kernelH, int kernelY,
-                                     int kernelX) {
-  assert(d_Src != d_Dst);
-  dim3 threads(32, 8);
-  dim3 grid(iDivUp(fftW, threads.x), iDivUp(fftH, threads.y));
-
-#if (USE_TEXTURE)
-  hipTextureObject_t texFloat;
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeLinear;
-  texRes.res.linear.devPtr = d_Src;
-  texRes.res.linear.sizeInBytes = sizeof(float) * dataH * dataW;
-  texRes.res.linear.desc = hipCreateChannelDesc<float>();
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  checkCudaErrors(hipCreateTextureObject(&texFloat, &texRes, &texDescr, NULL));
-#endif
-
-  padDataClampToBorder_kernel<<<grid, threads>>>(
-      d_Dst, d_Src, fftH, fftW, dataH, dataW, kernelH, kernelW, kernelY, kernelX
-#if (USE_TEXTURE)
-      ,
-      texFloat
-#endif
-      );
-  getLastCudaError("padDataClampToBorder_kernel<<<>>> execution failed\n");
-
-#if (USE_TEXTURE)
-  checkCudaErrors(hipDestroyTextureObject(texFloat));
-#endif
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Modulate Fourier image of padded data by Fourier image of padded kernel
-// and normalize by FFT size
-////////////////////////////////////////////////////////////////////////////////
-extern "C" void modulateAndNormalize(fComplex *d_Dst, fComplex *d_Src, int fftH,
-                                     int fftW, int padding) {
-  assert(fftW % 2 == 0);
-  const int dataSize = fftH * (fftW / 2 + padding);
-
-  modulateAndNormalize_kernel<<<iDivUp(dataSize, 256), 256>>>(
-      d_Dst, d_Src, dataSize, 1.0f / (float)(fftW * fftH));
-  getLastCudaError("modulateAndNormalize() execution failed\n");
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// 2D R2C / C2R post/preprocessing kernels
-////////////////////////////////////////////////////////////////////////////////
-static const double PI = 3.1415926535897932384626433832795;
-static const uint BLOCKDIM = 256;
-
-extern "C" void spPostprocess2D(void *d_Dst, void *d_Src, uint DY, uint DX,
-                                uint padding, int dir) {
-  assert(d_Src != d_Dst);
-  assert(DX % 2 == 0);
-
-#if (POWER_OF_TWO)
-  uint log2DX, log2DY;
-  uint factorizationRemX = factorRadix2(log2DX, DX);
-  uint factorizationRemY = factorRadix2(log2DY, DY);
-  assert(factorizationRemX == 1 && factorizationRemY == 1);
-#endif
-
-  const uint threadCount = DY * (DX / 2);
-  const double phaseBase = dir * PI / (double)DX;
-
-#if (USE_TEXTURE)
-  hipTextureObject_t texComplex;
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeLinear;
-  texRes.res.linear.devPtr = d_Src;
-  texRes.res.linear.sizeInBytes = sizeof(fComplex) * DY * (DX + padding);
-  texRes.res.linear.desc = hipCreateChannelDesc<fComplex>();
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  checkCudaErrors(
-      hipCreateTextureObject(&texComplex, &texRes, &texDescr, NULL));
-#endif
-
-  spPostprocess2D_kernel<<<iDivUp(threadCount, BLOCKDIM), BLOCKDIM>>>(
-      (fComplex *)d_Dst, (fComplex *)d_Src, DY, DX, threadCount, padding,
-      (float)phaseBase
-#if (USE_TEXTURE)
-      ,
-      texComplex
-#endif
-      );
-  getLastCudaError("spPostprocess2D_kernel<<<>>> execution failed\n");
-
-#if (USE_TEXTURE)
-  checkCudaErrors(hipDestroyTextureObject(texComplex));
-#endif
-}
-
-extern "C" void spPreprocess2D(void *d_Dst, void *d_Src, uint DY, uint DX,
-                               uint padding, int dir) {
-  assert(d_Src != d_Dst);
-  assert(DX % 2 == 0);
-
-#if (POWER_OF_TWO)
-  uint log2DX, log2DY;
-  uint factorizationRemX = factorRadix2(log2DX, DX);
-  uint factorizationRemY = factorRadix2(log2DY, DY);
-  assert(factorizationRemX == 1 && factorizationRemY == 1);
-#endif
-
-  const uint threadCount = DY * (DX / 2);
-  const double phaseBase = -dir * PI / (double)DX;
-
-#if (USE_TEXTURE)
-  hipTextureObject_t texComplex;
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeLinear;
-  texRes.res.linear.devPtr = d_Src;
-  texRes.res.linear.sizeInBytes = sizeof(fComplex) * DY * (DX + padding);
-  texRes.res.linear.desc = hipCreateChannelDesc<fComplex>();
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  checkCudaErrors(
-      hipCreateTextureObject(&texComplex, &texRes, &texDescr, NULL));
-#endif
-  spPreprocess2D_kernel<<<iDivUp(threadCount, BLOCKDIM), BLOCKDIM>>>(
-      (fComplex *)d_Dst, (fComplex *)d_Src, DY, DX, threadCount, padding,
-      (float)phaseBase
-#if (USE_TEXTURE)
-      ,
-      texComplex
-#endif
-      );
-  getLastCudaError("spPreprocess2D_kernel<<<>>> execution failed\n");
-
-#if (USE_TEXTURE)
-  checkCudaErrors(hipDestroyTextureObject(texComplex));
-#endif
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Combined spPostprocess2D + modulateAndNormalize + spPreprocess2D
-////////////////////////////////////////////////////////////////////////////////
-extern "C" void spProcess2D(void *d_Dst, void *d_SrcA, void *d_SrcB, uint DY,
-                            uint DX, int dir) {
-  assert(DY % 2 == 0);
-
-#if (POWER_OF_TWO)
-  uint log2DX, log2DY;
-  uint factorizationRemX = factorRadix2(log2DX, DX);
-  uint factorizationRemY = factorRadix2(log2DY, DY);
-  assert(factorizationRemX == 1 && factorizationRemY == 1);
-#endif
-
-  const uint threadCount = (DY / 2) * DX;
-  const double phaseBase = dir * PI / (double)DX;
-
-#if (USE_TEXTURE)
-  hipTextureObject_t texComplexA, texComplexB;
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeLinear;
-  texRes.res.linear.devPtr = d_SrcA;
-  texRes.res.linear.sizeInBytes = sizeof(fComplex) * DY * DX;
-  texRes.res.linear.desc = hipCreateChannelDesc<fComplex>();
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  checkCudaErrors(
-      hipCreateTextureObject(&texComplexA, &texRes, &texDescr, NULL));
-
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeLinear;
-  texRes.res.linear.devPtr = d_SrcB;
-  texRes.res.linear.sizeInBytes = sizeof(fComplex) * DY * DX;
-  texRes.res.linear.desc = hipCreateChannelDesc<fComplex>();
-
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  checkCudaErrors(
-      hipCreateTextureObject(&texComplexB, &texRes, &texDescr, NULL));
-#endif
-  spProcess2D_kernel<<<iDivUp(threadCount, BLOCKDIM), BLOCKDIM>>>(
-      (fComplex *)d_Dst, (fComplex *)d_SrcA, (fComplex *)d_SrcB, DY, DX,
-      threadCount, (float)phaseBase, 0.5f / (float)(DY * DX)
-#if (USE_TEXTURE)
-                                         ,
-      texComplexA, texComplexB
-#endif
-      );
-  getLastCudaError("spProcess2D_kernel<<<>>> execution failed\n");
-
-#if (USE_TEXTURE)
-  checkCudaErrors(hipDestroyTextureObject(texComplexA));
-  checkCudaErrors(hipDestroyTextureObject(texComplexB));
-#endif
-}
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D.cuh b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_common.h b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_common_hipified.h b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_gold.cpp b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_gold_hipified.cpp b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_hipified.cuh b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2017.sln b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2019.sln b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2022.sln b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/convolutionFFT2D_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/main.cpp b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/main_hipified.cpp b/src/samples/Samples/5_Domain_Specific/convolutionFFT2D/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/Makefile b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/README.md b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/data/regression.gold.dat b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/data/regression.gold.dat
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/data/regression_2_14.gold.dat b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/data/regression_2_14.gold.dat
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/data/regression_2_18.gold.dat b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/data/regression_2_18.gold.dat
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/data/signal.dat b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/data/signal.dat
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/data/signal_2_14.dat b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/data/signal_2_14.dat
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/data/signal_2_18.dat b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/data/signal_2_18.dat
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.cu b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.cu.hip b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.cu.hip
old mode 100644
new mode 100755
index 79d9421..e69de29
--- a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.cu.hip
@@ -1,391 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
-* 1D DWT for Haar wavelet and signals with a length which is a power of 2.
-* The code reduces bank conflicts and non-coalesced reads / writes as
-* appropriate but does not fully remove them because the computational
-* overhead to achieve this would outweighs the benefit (see inline comments
-* for more details).
-* Large signals are subdivided into sub-signals with 512 elements and the
-* wavelet transform for these is computed with one block over 10 decomposition
-* levels. The resulting signal consisting of the approximation coefficients at
-* level X is then processed in a subsequent step on the device. This requires
-* interblock synchronization which is only possible on host side.
-* Detail coefficients which have been computed are not further referenced
-* during the decomposition so that they can be stored directly in their final
-* position in global memory. The transform and its storing scheme preserve
-* locality in the coefficients so that these writes are coalesced.
-* Approximation coefficients are stored in shared memory because they are
-* needed to compute the subsequent decomposition step. The top most
-* approximation coefficient for a sub-signal processed by one block is stored
-* in a special global memory location to simplify the processing after the
-* interblock synchronization.
-* Most books on wavelets explain the Haar wavelet decomposition. A good freely
-* available resource is the Wavelet primer by Stollnitz et al.
-* http://grail.cs.washington.edu/projects/wavelets/article/wavelet1.pdf
-* http://grail.cs.washington.edu/projects/wavelets/article/wavelet2.pdf
-* The basic of all Wavelet transforms is to decompose a signal into
-* approximation (a) and detail (d) coefficients where the detail tends to be
-* small or zero which allows / simplifies compression. The following "graphs"
-* demonstrate the transform for a signal
-* of length eight. The index always describes the decomposition level where
-* a coefficient arises. The input signal is interpreted as approximation signal
-* at level 0. The coefficients computed on the device are stored in the same
-* scheme as in the example. This data structure is particularly well suited for
-* compression and also preserves the hierarchical structure of the
-decomposition.
-
--------------------------------------------------
-| a_0 | a_0 | a_0 | a_0 | a_0 | a_0 | a_0 | a_0 |
--------------------------------------------------
-
--------------------------------------------------
-| a_1 | a_1 | a_1 | a_1 | d_1 | d_1 | d_1 | d_1 |
--------------------------------------------------
-
--------------------------------------------------
-| a_2 | a_2 | d_2 | d_2 | d_1 | d_1 | d_1 | d_1 |
--------------------------------------------------
-
--------------------------------------------------
-| a_3 | d_3 | d_2 | d_2 | d_1 | d_1 | d_1 | d_1 |
--------------------------------------------------
-
-* Host code.
-*/
-
-#ifdef _WIN32
-#define NOMINMAX
-#endif
-
-// includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-#include <assert.h>
-
-// includes, project
-#include "helper_functions.h"
-#include "helper_cuda_hipified.h"
-
-// constants which are used in host and device code
-#define INV_SQRT_2 0.70710678118654752440f;
-const unsigned int LOG_NUM_BANKS = 4;
-const unsigned int NUM_BANKS = 16;
-
-////////////////////////////////////////////////////////////////////////////////
-// includes, kernels
-#include "dwtHaar1D_kernel.cuh"
-
-////////////////////////////////////////////////////////////////////////////////
-// declaration, forward
-void runTest(int argc, char **argv);
-bool getLevels(unsigned int len, unsigned int *levels);
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  // run test
-  runTest(argc, argv);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Perform the wavelet decomposition
-////////////////////////////////////////////////////////////////////////////////
-void runTest(int argc, char **argv) {
-  bool bResult = false;  // flag for final validation of the results
-
-  char *s_fname = NULL, *r_gold_fname = NULL;
-  char r_fname[256];
-  const char usage[] = {
-      "\nUsage:\n"
-      "  dwtHaar1D --signal=<signal_file> --result=<result_file> "
-      "--gold=<gold_file>\n\n"
-      "  <signal_file> Input file containing the signal\n"
-      "  <result_file> Output file storing the result of the wavelet "
-      "decomposition\n"
-      "  <gold_file>   Input file containing the reference result of the "
-      "wavelet decomposition\n"
-      "\nExample:\n"
-      "  ./dwtHaar1D\n"
-      "       --signal=signal.dat\n"
-      "       --result=result.dat\n"
-      "       --gold=regression.gold.dat\n"};
-
-  printf("%s Starting...\n\n", argv[0]);
-
-  // use command-line specified CUDA device, otherwise use device with highest
-  // Gflops/s
-  findCudaDevice(argc, (const char **)argv);
-
-  // file names, either specified as cmd line args or use default
-  if (argc == 4) {
-    char *tmp_sfname, *tmp_rfname, *tmp_goldfname;
-
-    if ((getCmdLineArgumentString(argc, (const char **)argv, "signal",
-                                  &tmp_sfname) != true) ||
-        (getCmdLineArgumentString(argc, (const char **)argv, "result",
-                                  &tmp_rfname) != true) ||
-        (getCmdLineArgumentString(argc, (const char **)argv, "gold",
-                                  &tmp_goldfname) != true)) {
-      fprintf(stderr, "Invalid input syntax.\n%s", usage);
-      exit(EXIT_FAILURE);
-    }
-
-    s_fname = sdkFindFilePath(tmp_sfname, argv[0]);
-    r_gold_fname = sdkFindFilePath(tmp_goldfname, argv[0]);
-    strcpy(r_fname, tmp_rfname);
-  } else {
-    s_fname = sdkFindFilePath("signal.dat", argv[0]);
-    r_gold_fname = sdkFindFilePath("regression.gold.dat", argv[0]);
-    strcpy(r_fname, "result.dat");
-  }
-
-  printf("source file    = \"%s\"\n", s_fname);
-  printf("reference file = \"%s\"\n", r_fname);
-  printf("gold file      = \"%s\"\n", r_gold_fname);
-
-  // read in signal
-  unsigned int slength = 0;
-  float *signal = NULL;
-
-  if (s_fname == NULL) {
-    fprintf(stderr, "Cannot find the file containing the signal.\n%s", usage);
-
-    exit(EXIT_FAILURE);
-  }
-
-  if (sdkReadFile(s_fname, &signal, &slength, false) == true) {
-    printf("Reading signal from \"%s\"\n", s_fname);
-  } else {
-    exit(EXIT_FAILURE);
-  }
-
-  // get the number of decompositions necessary to perform a full decomposition
-  unsigned int dlevels_complete = 0;
-
-  if (true != getLevels(slength, &dlevels_complete)) {
-    // error message
-    fprintf(stderr, "Signal length not supported.\n");
-    // cleanup and abort
-    free(signal);
-    exit(EXIT_FAILURE);
-  }
-
-  // device in data
-  float *d_idata = NULL;
-  // device out data
-  float *d_odata = NULL;
-  // device approx_final data
-  float *approx_final = NULL;
-  // The very final approximation coefficient has to be written to the output
-  // data, all others are reused as input data in the next global step and
-  // therefore have to be written to the input data again.
-  // The following flag indicates where to copy approx_final data
-  //   - 0 is input, 1 is output
-  int approx_is_input;
-
-  // allocate device mem
-  const unsigned int smem_size = sizeof(float) * slength;
-  HIPCHECK(hipMalloc((void **)&d_idata, smem_size));
-  HIPCHECK(hipMalloc((void **)&d_odata, smem_size));
-  HIPCHECK(hipMalloc((void **)&approx_final, smem_size));
-  // copy input data to device
-  HIPCHECK(
-      hipMemcpy(d_idata, signal, smem_size, hipMemcpyHostToDevice));
-
-  // total number of threads
-  // in the first decomposition step always one thread computes the average and
-  // detail signal for one pair of adjacent values
-  unsigned int num_threads_total_left = slength / 2;
-  // decomposition levels performed in the current / next step
-  unsigned int dlevels_step = dlevels_complete;
-
-  // 1D signal so the arrangement of elements is also 1D
-  dim3 block_size;
-  dim3 grid_size;
-
-  // number of decomposition levels left after one iteration on the device
-  unsigned int dlevels_left = dlevels_complete;
-
-  // if less or equal 1k elements, then the data can be processed in one block,
-  // this avoids the Wait-For-Idle (WFI) on host side which is necessary if the
-  // computation is split across multiple SM's if enough input data
-  if (dlevels_complete <= 10) {
-    // decomposition can be performed at once
-    block_size.x = num_threads_total_left;
-    approx_is_input = 0;
-  } else {
-    // 512 threads per block
-    grid_size.x = (num_threads_total_left / 512);
-    block_size.x = 512;
-
-    // 512 threads corresponds to 10 decomposition steps
-    dlevels_step = 10;
-    dlevels_left -= 10;
-
-    approx_is_input = 1;
-  }
-
-  // Initialize d_odata to 0.0f
-  initValue<<<grid_size, block_size>>>(d_odata, 0.0f);
-
-  // do until full decomposition is accomplished
-  while (0 != num_threads_total_left) {
-    // double the number of threads as bytes
-    unsigned int mem_shared = (2 * block_size.x) * sizeof(float);
-    // extra memory requirements to avoid bank conflicts
-    mem_shared += ((2 * block_size.x) / NUM_BANKS) * sizeof(float);
-
-    // run kernel
-    dwtHaar1D<<<grid_size, block_size, mem_shared>>>(
-        d_idata, d_odata, approx_final, dlevels_step, num_threads_total_left,
-        block_size.x);
-
-    // Copy approx_final to appropriate location
-    if (approx_is_input) {
-      HIPCHECK(hipMemcpy(d_idata, approx_final, grid_size.x * 4,
-                                 hipMemcpyDeviceToDevice));
-    } else {
-      HIPCHECK(hipMemcpy(d_odata, approx_final, grid_size.x * 4,
-                                 hipMemcpyDeviceToDevice));
-    }
-
-    // update level variables
-    if (dlevels_left < 10) {
-      // approx_final = d_odata;
-      approx_is_input = 0;
-    }
-
-    // more global steps necessary
-    dlevels_step = (dlevels_left > 10) ? dlevels_left - 10 : dlevels_left;
-    dlevels_left -= 10;
-
-    // after each step only half the threads are used any longer
-    // therefore after 10 steps 2^10 less threads
-    num_threads_total_left = num_threads_total_left >> 10;
-
-    // update block and grid size
-    grid_size.x =
-        (num_threads_total_left / 512) + (0 != (num_threads_total_left % 512))
-            ? 1
-            : 0;
-
-    if (grid_size.x <= 1) {
-      block_size.x = num_threads_total_left;
-    }
-  }
-
-  // get the result back from the server
-  // allocate mem for the result
-  float *odata = (float *)malloc(smem_size);
-  HIPCHECK(
-      hipMemcpy(odata, d_odata, smem_size, hipMemcpyDeviceToHost));
-
-  // post processing
-  // write file for regression test
-  if (r_fname == NULL) {
-    fprintf(stderr,
-            "Cannot write the output file storing the result of the wavelet "
-            "decomposition.\n%s",
-            usage);
-    exit(EXIT_FAILURE);
-  }
-
-  if (sdkWriteFile(r_fname, odata, slength, 0.001f, false) == true) {
-    printf("Writing result to \"%s\"\n", r_fname);
-  } else {
-    exit(EXIT_FAILURE);
-  }
-
-  // load the reference solution
-  unsigned int len_reference = 0;
-  float *reference = NULL;
-
-  if (r_gold_fname == NULL) {
-    fprintf(stderr,
-            "Cannot read the file containing the reference result of the "
-            "wavelet decomposition.\n%s",
-            usage);
-
-    exit(EXIT_FAILURE);
-  }
-
-  if (sdkReadFile(r_gold_fname, &reference, &len_reference, false) == true) {
-    printf("Reading reference result from \"%s\"\n", r_gold_fname);
-  } else {
-    exit(EXIT_FAILURE);
-  }
-
-  assert(slength == len_reference);
-
-  // compare the computed solution and the reference
-  bResult = (bool)sdkCompareL2fe(reference, odata, slength, 0.001f);
-  free(reference);
-
-  // free allocated host and device memory
-  HIPCHECK(hipFree(d_odata));
-  HIPCHECK(hipFree(d_idata));
-  HIPCHECK(hipFree(approx_final));
-
-  free(signal);
-  free(odata);
-  free(s_fname);
-  free(r_gold_fname);
-
-  printf(bResult ? "Test success!\n" : "Test failure!\n");
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Get number of decomposition levels to perform a full decomposition
-//! Also check if the input signal size is suitable
-//! @return  true if the number of decomposition levels could be determined
-//!          and the signal length is supported by the implementation,
-//!          otherwise false
-//! @param   len  length of input signal
-//! @param   levels  number of decomposition levels necessary to perform a full
-//!           decomposition
-////////////////////////////////////////////////////////////////////////////////
-bool getLevels(unsigned int len, unsigned int *levels) {
-  bool retval = false;
-
-  // currently signals up to a length of 2^20 supported
-  for (unsigned int i = 0; i < 20; ++i) {
-    if (len == (1 << i)) {
-      *levels = i;
-      retval = true;
-      break;
-    }
-  }
-
-  return retval;
-}
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.out b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_kernel.cuh b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_kernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2017.sln b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2019.sln b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2022.sln b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/dwtHaar1D/dwtHaar1D_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/dxtc/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/dxtc/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/dxtc/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/dxtc/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/CudaMath.h b/src/samples/Samples/5_Domain_Specific/dxtc/CudaMath.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/CudaMath_hipified.h b/src/samples/Samples/5_Domain_Specific/dxtc/CudaMath_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/Makefile b/src/samples/Samples/5_Domain_Specific/dxtc/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/dxtc/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/README.md b/src/samples/Samples/5_Domain_Specific/dxtc/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/data/teapot512_ref.dds b/src/samples/Samples/5_Domain_Specific/dxtc/data/teapot512_ref.dds
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/data/teapot512_std.ppm b/src/samples/Samples/5_Domain_Specific/dxtc/data/teapot512_std.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/dds.h b/src/samples/Samples/5_Domain_Specific/dxtc/dds.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/dds_hipified.h b/src/samples/Samples/5_Domain_Specific/dxtc/dds_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/doc/cuda_dxtc.doc b/src/samples/Samples/5_Domain_Specific/dxtc/doc/cuda_dxtc.doc
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/doc/cuda_dxtc.pdf b/src/samples/Samples/5_Domain_Specific/dxtc/doc/cuda_dxtc.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc.cu b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc.cu.hip b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc.cu.hip
old mode 100644
new mode 100755
index d6101be..7bc32a0
--- a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc.cu.hip
@@ -37,9 +37,9 @@ namespace cg = cooperative_groups;
 #include <helper_math.h>
 #include <float.h>  // for FLT_MAX
 
-#include "CudaMath.h"
-#include "dds.h"
-#include "permutations.h"
+#include "CudaMath_hipified.h"
+#include "dds_hipified.h"
+#include "permutations_hipified.h"
 
 // Definitions
 #define INPUT_IMAGE "teapot512_std.ppm"
@@ -611,12 +611,12 @@ int main(int argc, char **argv) {
 
   // copy into global mem
   uint *d_data = NULL;
-  HIPCHECK(hipMalloc((void **)&d_data, memSize));
+  checkCudaErrors(hipMalloc((void **)&d_data, memSize));
 
   // Result
   uint *d_result = NULL;
   const uint compressedSize = (w / 4) * (h / 4) * 8;
-  HIPCHECK(hipMalloc((void **)&d_result, compressedSize));
+  checkCudaErrors(hipMalloc((void **)&d_result, compressedSize));
   uint *h_result = (uint *)malloc(compressedSize);
 
   // Compute permutations.
@@ -625,8 +625,8 @@ int main(int argc, char **argv) {
 
   // Copy permutations host to devie.
   uint *d_permutations = NULL;
-  HIPCHECK(hipMalloc((void **)&d_permutations, 1024 * sizeof(uint)));
-  HIPCHECK(hipMemcpy(d_permutations, permutations, 1024 * sizeof(uint),
+  checkCudaErrors(hipMalloc((void **)&d_permutations, 1024 * sizeof(uint)));
+  checkCudaErrors(hipMemcpy(d_permutations, permutations, 1024 * sizeof(uint),
                              hipMemcpyHostToDevice));
 
   // create a timer
@@ -634,7 +634,7 @@ int main(int argc, char **argv) {
   sdkCreateTimer(&timer);
 
   // Copy image from host to device
-  HIPCHECK(
+  checkCudaErrors(
       hipMemcpy(d_data, block_image, memSize, hipMemcpyHostToDevice));
 
   // Determine launch configuration and run timed computation numIterations
@@ -646,8 +646,8 @@ int main(int argc, char **argv) {
   hipDeviceProp_t deviceProp;
 
   // get number of SMs on this GPU
-  HIPCHECK(hipGetDevice(&devID));
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, devID));
+  checkCudaErrors(hipGetDevice(&devID));
+  checkCudaErrors(hipGetDeviceProperties(&deviceProp, devID));
 
   // Restrict the numbers of blocks to launch on low end GPUs to avoid kernel
   // timeout
@@ -660,7 +660,7 @@ int main(int argc, char **argv) {
 
   for (int i = -1; i < numIterations; ++i) {
     if (i == 0) {
-      HIPCHECK(hipDeviceSynchronize());
+      checkCudaErrors(hipDeviceSynchronize());
       sdkStartTimer(&timer);
     }
 
@@ -673,7 +673,7 @@ int main(int argc, char **argv) {
   getLastCudaError("compress");
 
   // sync to host, stop timer, record perf
-  HIPCHECK(hipDeviceSynchronize());
+  checkCudaErrors(hipDeviceSynchronize());
   sdkStopTimer(&timer);
   double dAvgTime = 1.0e-3 * sdkGetTimerValue(&timer) / (double)numIterations;
   printf(
@@ -682,7 +682,7 @@ int main(int argc, char **argv) {
       (1.0e-6 * (double)(W * H) / dAvgTime), dAvgTime, (W * H), 1, NUM_THREADS);
 
   // copy result data from device to host
-  HIPCHECK(
+  checkCudaErrors(
       hipMemcpy(h_result, d_result, compressedSize, hipMemcpyDeviceToHost));
 
   // Write out result data to DDS file
@@ -770,9 +770,9 @@ int main(int argc, char **argv) {
   rms /= w * h * 3;
 
   // Free allocated resources and exit
-  HIPCHECK(hipFree(d_permutations));
-  HIPCHECK(hipFree(d_data));
-  HIPCHECK(hipFree(d_result));
+  checkCudaErrors(hipFree(d_permutations));
+  checkCudaErrors(hipFree(d_data));
+  checkCudaErrors(hipFree(d_result));
   free(image_path);
   free(data);
   free(block_image);
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2017.sln b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2019.sln b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2022.sln b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/dxtc/dxtc_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/permutations.h b/src/samples/Samples/5_Domain_Specific/dxtc/permutations.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/dxtc/permutations_hipified.h b/src/samples/Samples/5_Domain_Specific/dxtc/permutations_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/Makefile b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/README.md b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/doc/FWT.doc b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/doc/FWT.doc
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.cu b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.cu.hip b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.cu.hip
old mode 100644
new mode 100755
index c67b9bf..22e32a2
--- a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.cu.hip
@@ -39,13 +39,11 @@
  */
 
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <stdlib.h>
 #include <string.h>
 #include "helper_functions.h"
 #include "helper_cuda_hipified.h"
-
+#include "HIPCHECK.h"
 ////////////////////////////////////////////////////////////////////////////////
 // Reference CPU FWT
 ////////////////////////////////////////////////////////////////////////////////
@@ -58,7 +56,7 @@ extern "C" void dyadicConvolutionCPU(float *h_Result, float *h_Data,
 ////////////////////////////////////////////////////////////////////////////////
 // GPU FWT
 ////////////////////////////////////////////////////////////////////////////////
-#include "fastWalshTransform_kernel.cuh"
+#include "fastWalshTransform_kernel_hipified.cuh"
 
 ////////////////////////////////////////////////////////////////////////////////
 // Data configuration
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.out b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.out
old mode 100644
new mode 100755
index 113d3ae..facac71
Binary files a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.out and b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform.out differ
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_gold.cpp b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_gold_hipified.cpp b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_kernel.cuh b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_kernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2017.sln b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2019.sln b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2022.sln b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/fastWalshTransform/fastWalshTransform_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/Makefile b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/README.md b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/data/ref_fluidsD3D9.ppm b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/data/ref_fluidsD3D9.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/doc/fluidsD3D9_lg.gif b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/doc/fluidsD3D9_lg.gif
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/doc/fluidsD3D9_md.gif b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/doc/fluidsD3D9_md.gif
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/doc/fluidsD3D9_sm.gif b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/doc/fluidsD3D9_sm.gif
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9.cpp b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_hipified.cpp b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_kernels.cu b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_kernels.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_kernels.cu.hip b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_kernels.cu.hip
old mode 100644
new mode 100755
index 4add01d..e69de29
--- a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_kernels.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_kernels.cu.hip
@@ -1,336 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <hip/hip_runtime.h>
-#include <builtin_types.h>
-#include <hipfft.h>
-#include <hip/hip_runtime.h>
-#include "helper_cuda_hipified.h"
-#include "fluidsD3D9_kernels.h"
-
-// Texture object for reading velocity field
-hipTextureObject_t texObj;
-static hipArray *array = NULL;
-
-void setupTexture(int x, int y) {
-  hipChannelFormatDesc desc = hipCreateChannelDesc<float2>();
-
-  hipMallocArray(&array, &desc, y, x);
-  getLastCudaError("hipMalloc failed");
-
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = array;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(hipCreateTextureObject(&texObj, &texRes, &texDescr, NULL));
-}
-
-void updateTexture(cData *data, size_t wib, size_t h, size_t pitch) {
-  HIPCHECK(hipMemcpy2DToArray(array, 0, 0, data, pitch, wib, h,
-                                      hipMemcpyDeviceToDevice));
-}
-
-void deleteTexture(void) {
-  HIPCHECK(hipDestroyTextureObject(texObj));
-  HIPCHECK(hipFreeArray(array));
-}
-
-// Note that these kernels are designed to work with arbitrary
-// domain sizes, not just domains that are multiples of the tile
-// size. Therefore, we have extra code that checks to make sure
-// a given thread location falls within the domain boundaries in
-// both X and Y. Also, the domain is covered by looping over
-// multiple elements in the Y direction, while there is a one-to-one
-// mapping between threads in X and the tile size in X.
-// Nolan Goodnight 9/22/06
-
-// This method adds constant force vectors to the velocity field
-// stored in 'v' according to v(x,t+1) = v(x,t) + dt * f.
-__global__ void addForces_k(cData *v, int dx, int dy, int spx, int spy,
-                            float fx, float fy, int r, size_t pitch) {
-  int tx = threadIdx.x;
-  int ty = threadIdx.y;
-  cData *fj = (cData *)((char *)v + (ty + spy) * pitch) + tx + spx;
-
-  cData vterm = *fj;
-  tx -= r;
-  ty -= r;
-  float s = 1.f / (1.f + tx * tx * tx * tx + ty * ty * ty * ty);
-  vterm.x += s * fx;
-  vterm.y += s * fy;
-  *fj = vterm;
-}
-
-// This method performs the velocity advection step, where we
-// trace velocity vectors back in time to update each grid cell.
-// That is, v(x,t+1) = v(p(x,-dt),t). Here we perform bilinear
-// interpolation in the velocity space.
-__global__ void advectVelocity_k(cData *v, float *vx, float *vy, int dx,
-                                 int pdx, int dy, float dt, int lb,
-                                 hipTextureObject_t texObject) {
-  int gtidx = blockIdx.x * blockDim.x + threadIdx.x;
-  int gtidy = blockIdx.y * (lb * blockDim.y) + threadIdx.y * lb;
-  int p;
-
-  cData vterm, ploc;
-  float vxterm, vyterm;
-
-  // gtidx is the domain location in x for this thread
-  if (gtidx < dx) {
-    for (p = 0; p < lb; p++) {
-      // fi is the domain location in y for this thread
-      int fi = gtidy + p;
-
-      if (fi < dy) {
-        int fj = fi * pdx + gtidx;
-        vterm = tex2D<cData>(texObject, (float)gtidx, (float)fi);
-        ploc.x = (gtidx + 0.5f) - (dt * vterm.x * dx);
-        ploc.y = (fi + 0.5f) - (dt * vterm.y * dy);
-        vterm = tex2D<cData>(texObject, ploc.x, ploc.y);
-        vxterm = vterm.x;
-        vyterm = vterm.y;
-        vx[fj] = vxterm;
-        vy[fj] = vyterm;
-      }
-    }
-  }
-}
-
-// This method performs velocity diffusion and forces mass conservation
-// in the frequency domain. The inputs 'vx' and 'vy' are complex-valued
-// arrays holding the Fourier coefficients of the velocity field in
-// X and Y. Diffusion in this space takes a simple form described as:
-// v(k,t) = v(k,t) / (1 + visc * dt * k^2), where visc is the viscosity,
-// and k is the wavenumber. The projection step forces the Fourier
-// velocity vectors to be orthogonal to the vectors for each
-// wavenumber: v(k,t) = v(k,t) - ((k dot v(k,t) * k) / k^2.
-__global__ void diffuseProject_k(cData *vx, cData *vy, int dx, int dy, float dt,
-                                 float visc, int lb) {
-  int gtidx = blockIdx.x * blockDim.x + threadIdx.x;
-  int gtidy = blockIdx.y * (lb * blockDim.y) + threadIdx.y * lb;
-  int p;
-
-  cData xterm, yterm;
-
-  // gtidx is the domain location in x for this thread
-  if (gtidx < dx) {
-    for (p = 0; p < lb; p++) {
-      // fi is the domain location in y for this thread
-      int fi = gtidy + p;
-
-      if (fi < dy) {
-        int fj = fi * dx + gtidx;
-        xterm = vx[fj];
-        yterm = vy[fj];
-
-        // Compute the index of the wavenumber based on the
-        // data order produced by a standard NN FFT.
-        int iix = gtidx;
-        int iiy = (fi > dy / 2) ? (fi - (dy)) : fi;
-
-        // Velocity diffusion
-        float kk = (float)(iix * iix + iiy * iiy);  // k^2
-        float diff = 1.f / (1.f + visc * dt * kk);
-        xterm.x *= diff;
-        xterm.y *= diff;
-        yterm.x *= diff;
-        yterm.y *= diff;
-
-        // Velocity projection
-        if (kk > 0.f) {
-          float rkk = 1.f / kk;
-          // Real portion of velocity projection
-          float rkp = (iix * xterm.x + iiy * yterm.x);
-          // Imaginary portion of velocity projection
-          float ikp = (iix * xterm.y + iiy * yterm.y);
-          xterm.x -= rkk * rkp * iix;
-          xterm.y -= rkk * ikp * iix;
-          yterm.x -= rkk * rkp * iiy;
-          yterm.y -= rkk * ikp * iiy;
-        }
-
-        vx[fj] = xterm;
-        vy[fj] = yterm;
-      }
-    }
-  }
-}
-
-// This method updates the velocity field 'v' using the two complex
-// arrays from the previous step: 'vx' and 'vy'. Here we scale the
-// real components by 1/(dx*dy) to account for an unnormalized FFT.
-__global__ void updateVelocity_k(cData *v, float *vx, float *vy, int dx,
-                                 int pdx, int dy, int lb, size_t pitch) {
-  int gtidx = blockIdx.x * blockDim.x + threadIdx.x;
-  int gtidy = blockIdx.y * (lb * blockDim.y) + threadIdx.y * lb;
-  int p;
-
-  float vxterm, vyterm;
-  cData nvterm;
-
-  // gtidx is the domain location in x for this thread
-  if (gtidx < dx) {
-    for (p = 0; p < lb; p++) {
-      // fi is the domain location in y for this thread
-      int fi = gtidy + p;
-
-      if (fi < dy) {
-        int fjr = fi * pdx + gtidx;
-        vxterm = vx[fjr];
-        vyterm = vy[fjr];
-
-        // Normalize the result of the inverse FFT
-        float scale = 1.f / (dx * dy);
-        nvterm.x = vxterm * scale;
-        nvterm.y = vyterm * scale;
-
-        cData *fj = (cData *)((char *)v + fi * pitch) + gtidx;
-        *fj = nvterm;
-      }
-    }  // If this thread is inside the domain in Y
-  }    // If this thread is inside the domain in X
-}
-
-// This method updates the particles by moving particle positions
-// according to the velocity field and time step. That is, for each
-// particle: p(t+1) = p(t) + dt * v(p(t)).
-__global__ void advectParticles_k(Vertex *part, cData *v, int dx, int dy,
-                                  float dt, int lb, size_t pitch) {
-  int gtidx = blockIdx.x * blockDim.x + threadIdx.x;
-  int gtidy = blockIdx.y * (lb * blockDim.y) + threadIdx.y * lb;
-  int p;
-
-  // gtidx is the domain location in x for this thread
-  cData vterm;
-  Vertex pterm;
-
-  if (gtidx < dx) {
-    for (p = 0; p < lb; p++) {
-      // fi is the domain location in y for this thread
-      int fi = gtidy + p;
-
-      if (fi < dy) {
-        int fj = fi * dx + gtidx;
-        pterm = part[fj];
-
-        int xvi = ((int)(pterm.x * dx));
-        int yvi = ((int)(pterm.y * dy));
-        vterm = *((cData *)((char *)v + yvi * pitch) + xvi);
-
-        pterm.x += dt * vterm.x;
-        pterm.x = pterm.x - (int)pterm.x;
-        pterm.x += 1.f;
-        pterm.x = pterm.x - (int)pterm.x;
-        pterm.y += dt * vterm.y;
-        pterm.y = pterm.y - (int)pterm.y;
-        pterm.y += 1.f;
-        pterm.y = pterm.y - (int)pterm.y;
-
-        part[fj] = pterm;
-      }
-    }  // If this thread is inside the domain in Y
-  }    // If this thread is inside the domain in X
-}
-
-extern "C" void addForces(cData *v, int dx, int dy, int spx, int spy, float fx,
-                          float fy, int r, size_t tPitch) {
-  dim3 tids(2 * r + 1, 2 * r + 1);
-
-  addForces_k<<<1, tids>>>(v, dx, dy, spx, spy, fx, fy, r, tPitch);
-  getLastCudaError("addForces_k failed.");
-}
-
-extern "C" void advectVelocity(cData *v, float *vx, float *vy, int dx, int pdx,
-                               int dy, float dt, size_t tPitch) {
-  dim3 grid((dx / TILEX) + (!(dx % TILEX) ? 0 : 1),
-            (dy / TILEY) + (!(dy % TILEY) ? 0 : 1));
-
-  dim3 tids(TIDSX, TIDSY);
-
-  updateTexture(v, DIM * sizeof(cData), DIM, tPitch);
-  advectVelocity_k<<<grid, tids>>>(v, vx, vy, dx, pdx, dy, dt, TILEY / TIDSY,
-                                   texObj);
-
-  getLastCudaError("advectVelocity_k failed.");
-}
-
-extern "C" void diffuseProject(cData *vx, cData *vy, int dx, int dy, float dt,
-                               float visc, size_t tPitch) {
-  // Forward FFT
-  //    hipfftExecR2C(planr2c, (hipfftReal*)vx, (hipfftComplex*)vx);
-  //    hipfftExecR2C(planr2c, (hipfftReal*)vy, (hipfftComplex*)vy);
-
-  uint3 grid = make_uint3((dx / TILEX) + (!(dx % TILEX) ? 0 : 1),
-                          (dy / TILEY) + (!(dy % TILEY) ? 0 : 1), 1);
-
-  uint3 tids = make_uint3(TIDSX, TIDSY, 1);
-
-  diffuseProject_k<<<grid, tids>>>(vx, vy, dx, dy, dt, visc, TILEY / TIDSY);
-  getLastCudaError("diffuseProject_k failed.");
-
-  // Inverse FFT
-  //    hipfftExecC2R(planc2r, (hipfftComplex*)vx, (hipfftReal*)vx);
-  //    hipfftExecC2R(planc2r, (hipfftComplex*)vy, (hipfftReal*)vy);
-}
-
-extern "C" void updateVelocity(cData *v, float *vx, float *vy, int dx, int pdx,
-                               int dy, size_t tPitch) {
-  dim3 grid((dx / TILEX) + (!(dx % TILEX) ? 0 : 1),
-            (dy / TILEY) + (!(dy % TILEY) ? 0 : 1));
-
-  dim3 tids(TIDSX, TIDSY);
-
-  updateVelocity_k<<<grid, tids>>>(v, vx, vy, dx, pdx, dy, TILEY / TIDSY,
-                                   tPitch);
-  getLastCudaError("updateVelocity_k failed.");
-}
-
-extern "C" void advectParticles(Vertex *p, cData *v, int dx, int dy, float dt,
-                                size_t tPitch) {
-  dim3 grid((dx / TILEX) + (!(dx % TILEX) ? 0 : 1),
-            (dy / TILEY) + (!(dy % TILEY) ? 0 : 1));
-
-  dim3 tids(TIDSX, TIDSY);
-
-  advectParticles_k<<<grid, tids>>>(p, v, dx, dy, dt, TILEY / TIDSY, tPitch);
-  getLastCudaError("advectParticles_k failed.");
-}
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_kernels.h b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_kernels.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_kernels_hipified.h b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_kernels_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2017.sln b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2019.sln b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2022.sln b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/fluidsD3D9/fluidsD3D9_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/fluidsGL/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/fluidsGL/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/fluidsGL/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/fluidsGL/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/Makefile b/src/samples/Samples/5_Domain_Specific/fluidsGL/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/fluidsGL/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/README.md b/src/samples/Samples/5_Domain_Specific/fluidsGL/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/data/ref_fluidsGL.ppm b/src/samples/Samples/5_Domain_Specific/fluidsGL/data/ref_fluidsGL.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/defines.h b/src/samples/Samples/5_Domain_Specific/fluidsGL/defines.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/defines_hipified.h b/src/samples/Samples/5_Domain_Specific/fluidsGL/defines_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/doc/fluidsGL.doc b/src/samples/Samples/5_Domain_Specific/fluidsGL/doc/fluidsGL.doc
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/doc/fluidsGL.pdf b/src/samples/Samples/5_Domain_Specific/fluidsGL/doc/fluidsGL.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/doc/fluidsGL_lg.gif b/src/samples/Samples/5_Domain_Specific/fluidsGL/doc/fluidsGL_lg.gif
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/doc/fluidsGL_md.gif b/src/samples/Samples/5_Domain_Specific/fluidsGL/doc/fluidsGL_md.gif
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/doc/fluidsGL_sm.gif b/src/samples/Samples/5_Domain_Specific/fluidsGL/doc/fluidsGL_sm.gif
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/findgllib.mk b/src/samples/Samples/5_Domain_Specific/fluidsGL/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL.cpp b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_hipified.cpp b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_kernels.cu b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_kernels.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_kernels.cu.hip b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_kernels.cu.hip
old mode 100644
new mode 100755
index edb8902..e69de29
--- a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_kernels.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_kernels.cu.hip
@@ -1,363 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-
-#include <hip/hip_runtime.h>
-#include <hipfft.h>        // CUDA FFT Libraries
-#include "helper_cuda_hipified.h"  // Helper functions for CUDA Error handling
-
-// OpenGL Graphics includes
-#define HELPERGL_EXTERN_GL_FUNC_IMPLEMENTATION
-#include <helper_gl.h>
-
-// FluidsGL CUDA kernel definitions
-#include "fluidsGL_kernels.cuh"
-
-// Texture object for reading velocity field
-hipTextureObject_t texObj;
-static hipArray *array = NULL;
-
-// Particle data
-extern GLuint vbo;  // OpenGL vertex buffer object
-extern struct hipGraphicsResource
-    *cuda_vbo_resource;  // handles OpenGL-CUDA exchange
-
-// Texture pitch
-extern size_t tPitch;
-extern hipfftHandle planr2c;
-extern hipfftHandle planc2r;
-cData *vxfield = NULL;
-cData *vyfield = NULL;
-
-void setupTexture(int x, int y) {
-  hipChannelFormatDesc desc = hipCreateChannelDesc<float2>();
-
-  hipMallocArray(&array, &desc, y, x);
-  getLastCudaError("hipMalloc failed");
-
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = array;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(hipCreateTextureObject(&texObj, &texRes, &texDescr, NULL));
-}
-
-void updateTexture(cData *data, size_t wib, size_t h, size_t pitch) {
-  HIPCHECK(hipMemcpy2DToArray(array, 0, 0, data, pitch, wib, h,
-                                      hipMemcpyDeviceToDevice));
-}
-
-void deleteTexture(void) {
-  HIPCHECK(hipDestroyTextureObject(texObj));
-  HIPCHECK(hipFreeArray(array));
-}
-
-// Note that these kernels are designed to work with arbitrary
-// domain sizes, not just domains that are multiples of the tile
-// size. Therefore, we have extra code that checks to make sure
-// a given thread location falls within the domain boundaries in
-// both X and Y. Also, the domain is covered by looping over
-// multiple elements in the Y direction, while there is a one-to-one
-// mapping between threads in X and the tile size in X.
-// Nolan Goodnight 9/22/06
-
-// This method adds constant force vectors to the velocity field
-// stored in 'v' according to v(x,t+1) = v(x,t) + dt * f.
-__global__ void addForces_k(cData *v, int dx, int dy, int spx, int spy,
-                            float fx, float fy, int r, size_t pitch) {
-  int tx = threadIdx.x;
-  int ty = threadIdx.y;
-  cData *fj = (cData *)((char *)v + (ty + spy) * pitch) + tx + spx;
-
-  cData vterm = *fj;
-  tx -= r;
-  ty -= r;
-  float s = 1.f / (1.f + tx * tx * tx * tx + ty * ty * ty * ty);
-  vterm.x += s * fx;
-  vterm.y += s * fy;
-  *fj = vterm;
-}
-
-// This method performs the velocity advection step, where we
-// trace velocity vectors back in time to update each grid cell.
-// That is, v(x,t+1) = v(p(x,-dt),t). Here we perform bilinear
-// interpolation in the velocity space.
-__global__ void advectVelocity_k(cData *v, float *vx, float *vy, int dx,
-                                 int pdx, int dy, float dt, int lb,
-                                 hipTextureObject_t texObject) {
-  int gtidx = blockIdx.x * blockDim.x + threadIdx.x;
-  int gtidy = blockIdx.y * (lb * blockDim.y) + threadIdx.y * lb;
-  int p;
-
-  cData vterm, ploc;
-  float vxterm, vyterm;
-
-  // gtidx is the domain location in x for this thread
-  if (gtidx < dx) {
-    for (p = 0; p < lb; p++) {
-      // fi is the domain location in y for this thread
-      int fi = gtidy + p;
-
-      if (fi < dy) {
-        int fj = fi * pdx + gtidx;
-        vterm = tex2D<cData>(texObject, (float)gtidx, (float)fi);
-        ploc.x = (gtidx + 0.5f) - (dt * vterm.x * dx);
-        ploc.y = (fi + 0.5f) - (dt * vterm.y * dy);
-        vterm = tex2D<cData>(texObject, ploc.x, ploc.y);
-        vxterm = vterm.x;
-        vyterm = vterm.y;
-        vx[fj] = vxterm;
-        vy[fj] = vyterm;
-      }
-    }
-  }
-}
-
-// This method performs velocity diffusion and forces mass conservation
-// in the frequency domain. The inputs 'vx' and 'vy' are complex-valued
-// arrays holding the Fourier coefficients of the velocity field in
-// X and Y. Diffusion in this space takes a simple form described as:
-// v(k,t) = v(k,t) / (1 + visc * dt * k^2), where visc is the viscosity,
-// and k is the wavenumber. The projection step forces the Fourier
-// velocity vectors to be orthogonal to the vectors for each
-// wavenumber: v(k,t) = v(k,t) - ((k dot v(k,t) * k) / k^2.
-__global__ void diffuseProject_k(cData *vx, cData *vy, int dx, int dy, float dt,
-                                 float visc, int lb) {
-  int gtidx = blockIdx.x * blockDim.x + threadIdx.x;
-  int gtidy = blockIdx.y * (lb * blockDim.y) + threadIdx.y * lb;
-  int p;
-
-  cData xterm, yterm;
-
-  // gtidx is the domain location in x for this thread
-  if (gtidx < dx) {
-    for (p = 0; p < lb; p++) {
-      // fi is the domain location in y for this thread
-      int fi = gtidy + p;
-
-      if (fi < dy) {
-        int fj = fi * dx + gtidx;
-        xterm = vx[fj];
-        yterm = vy[fj];
-
-        // Compute the index of the wavenumber based on the
-        // data order produced by a standard NN FFT.
-        int iix = gtidx;
-        int iiy = (fi > dy / 2) ? (fi - (dy)) : fi;
-
-        // Velocity diffusion
-        float kk = (float)(iix * iix + iiy * iiy);  // k^2
-        float diff = 1.f / (1.f + visc * dt * kk);
-        xterm.x *= diff;
-        xterm.y *= diff;
-        yterm.x *= diff;
-        yterm.y *= diff;
-
-        // Velocity projection
-        if (kk > 0.f) {
-          float rkk = 1.f / kk;
-          // Real portion of velocity projection
-          float rkp = (iix * xterm.x + iiy * yterm.x);
-          // Imaginary portion of velocity projection
-          float ikp = (iix * xterm.y + iiy * yterm.y);
-          xterm.x -= rkk * rkp * iix;
-          xterm.y -= rkk * ikp * iix;
-          yterm.x -= rkk * rkp * iiy;
-          yterm.y -= rkk * ikp * iiy;
-        }
-
-        vx[fj] = xterm;
-        vy[fj] = yterm;
-      }
-    }
-  }
-}
-
-// This method updates the velocity field 'v' using the two complex
-// arrays from the previous step: 'vx' and 'vy'. Here we scale the
-// real components by 1/(dx*dy) to account for an unnormalized FFT.
-__global__ void updateVelocity_k(cData *v, float *vx, float *vy, int dx,
-                                 int pdx, int dy, int lb, size_t pitch) {
-  int gtidx = blockIdx.x * blockDim.x + threadIdx.x;
-  int gtidy = blockIdx.y * (lb * blockDim.y) + threadIdx.y * lb;
-  int p;
-
-  float vxterm, vyterm;
-  cData nvterm;
-
-  // gtidx is the domain location in x for this thread
-  if (gtidx < dx) {
-    for (p = 0; p < lb; p++) {
-      // fi is the domain location in y for this thread
-      int fi = gtidy + p;
-
-      if (fi < dy) {
-        int fjr = fi * pdx + gtidx;
-        vxterm = vx[fjr];
-        vyterm = vy[fjr];
-
-        // Normalize the result of the inverse FFT
-        float scale = 1.f / (dx * dy);
-        nvterm.x = vxterm * scale;
-        nvterm.y = vyterm * scale;
-
-        cData *fj = (cData *)((char *)v + fi * pitch) + gtidx;
-        *fj = nvterm;
-      }
-    }  // If this thread is inside the domain in Y
-  }    // If this thread is inside the domain in X
-}
-
-// This method updates the particles by moving particle positions
-// according to the velocity field and time step. That is, for each
-// particle: p(t+1) = p(t) + dt * v(p(t)).
-__global__ void advectParticles_k(cData *part, cData *v, int dx, int dy,
-                                  float dt, int lb, size_t pitch) {
-  int gtidx = blockIdx.x * blockDim.x + threadIdx.x;
-  int gtidy = blockIdx.y * (lb * blockDim.y) + threadIdx.y * lb;
-  int p;
-
-  // gtidx is the domain location in x for this thread
-  cData pterm, vterm;
-
-  if (gtidx < dx) {
-    for (p = 0; p < lb; p++) {
-      // fi is the domain location in y for this thread
-      int fi = gtidy + p;
-
-      if (fi < dy) {
-        int fj = fi * dx + gtidx;
-        pterm = part[fj];
-
-        int xvi = ((int)(pterm.x * dx));
-        int yvi = ((int)(pterm.y * dy));
-        vterm = *((cData *)((char *)v + yvi * pitch) + xvi);
-
-        pterm.x += dt * vterm.x;
-        pterm.x = pterm.x - (int)pterm.x;
-        pterm.x += 1.f;
-        pterm.x = pterm.x - (int)pterm.x;
-        pterm.y += dt * vterm.y;
-        pterm.y = pterm.y - (int)pterm.y;
-        pterm.y += 1.f;
-        pterm.y = pterm.y - (int)pterm.y;
-
-        part[fj] = pterm;
-      }
-    }  // If this thread is inside the domain in Y
-  }    // If this thread is inside the domain in X
-}
-
-// These are the external function calls necessary for launching fluid
-// simulation
-extern "C" void addForces(cData *v, int dx, int dy, int spx, int spy, float fx,
-                          float fy, int r) {
-  dim3 tids(2 * r + 1, 2 * r + 1);
-
-  addForces_k<<<1, tids>>>(v, dx, dy, spx, spy, fx, fy, r, tPitch);
-  getLastCudaError("addForces_k failed.");
-}
-
-extern "C" void advectVelocity(cData *v, float *vx, float *vy, int dx, int pdx,
-                               int dy, float dt) {
-  dim3 grid((dx / TILEX) + (!(dx % TILEX) ? 0 : 1),
-            (dy / TILEY) + (!(dy % TILEY) ? 0 : 1));
-
-  dim3 tids(TIDSX, TIDSY);
-
-  updateTexture(v, DIM * sizeof(cData), DIM, tPitch);
-  advectVelocity_k<<<grid, tids>>>(v, vx, vy, dx, pdx, dy, dt, TILEY / TIDSY,
-                                   texObj);
-
-  getLastCudaError("advectVelocity_k failed.");
-}
-
-extern "C" void diffuseProject(cData *vx, cData *vy, int dx, int dy, float dt,
-                               float visc) {
-  // Forward FFT
-  HIPCHECK(hipfftExecR2C(planr2c, (hipfftReal *)vx, (hipfftComplex *)vx));
-  HIPCHECK(hipfftExecR2C(planr2c, (hipfftReal *)vy, (hipfftComplex *)vy));
-
-  uint3 grid = make_uint3((dx / TILEX) + (!(dx % TILEX) ? 0 : 1),
-                          (dy / TILEY) + (!(dy % TILEY) ? 0 : 1), 1);
-  uint3 tids = make_uint3(TIDSX, TIDSY, 1);
-
-  diffuseProject_k<<<grid, tids>>>(vx, vy, dx, dy, dt, visc, TILEY / TIDSY);
-  getLastCudaError("diffuseProject_k failed.");
-
-  // Inverse FFT
-  HIPCHECK(hipfftExecC2R(planc2r, (hipfftComplex *)vx, (hipfftReal *)vx));
-  HIPCHECK(hipfftExecC2R(planc2r, (hipfftComplex *)vy, (hipfftReal *)vy));
-}
-
-extern "C" void updateVelocity(cData *v, float *vx, float *vy, int dx, int pdx,
-                               int dy) {
-  dim3 grid((dx / TILEX) + (!(dx % TILEX) ? 0 : 1),
-            (dy / TILEY) + (!(dy % TILEY) ? 0 : 1));
-  dim3 tids(TIDSX, TIDSY);
-
-  updateVelocity_k<<<grid, tids>>>(v, vx, vy, dx, pdx, dy, TILEY / TIDSY,
-                                   tPitch);
-  getLastCudaError("updateVelocity_k failed.");
-}
-
-extern "C" void advectParticles(GLuint vbo, cData *v, int dx, int dy,
-                                float dt) {
-  dim3 grid((dx / TILEX) + (!(dx % TILEX) ? 0 : 1),
-            (dy / TILEY) + (!(dy % TILEY) ? 0 : 1));
-  dim3 tids(TIDSX, TIDSY);
-
-  cData *p;
-  hipGraphicsMapResources(1, &cuda_vbo_resource, 0);
-  getLastCudaError("hipGraphicsMapResources failed");
-
-  size_t num_bytes;
-  hipGraphicsResourceGetMappedPointer((void **)&p, &num_bytes,
-                                       cuda_vbo_resource);
-  getLastCudaError("hipGraphicsResourceGetMappedPointer failed");
-
-  advectParticles_k<<<grid, tids>>>(p, v, dx, dy, dt, TILEY / TIDSY, tPitch);
-  getLastCudaError("advectParticles_k failed.");
-
-  hipGraphicsUnmapResources(1, &cuda_vbo_resource, 0);
-  getLastCudaError("hipGraphicsUnmapResources failed");
-}
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_kernels.cuh b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_kernels.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_kernels.h b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_kernels.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_kernels_hipified.cuh b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_kernels_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_kernels_hipified.h b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_kernels_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2017.sln b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2019.sln b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2022.sln b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/fluidsGL/fluidsGL_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/fluidsGLES/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/fluidsGLES/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/fluidsGLES/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/fluidsGLES/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/Makefile b/src/samples/Samples/5_Domain_Specific/fluidsGLES/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/fluidsGLES/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/README.md b/src/samples/Samples/5_Domain_Specific/fluidsGLES/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/data/ref_fluidsGLES.ppm b/src/samples/Samples/5_Domain_Specific/fluidsGLES/data/ref_fluidsGLES.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/defines.h b/src/samples/Samples/5_Domain_Specific/fluidsGLES/defines.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/defines_hipified.h b/src/samples/Samples/5_Domain_Specific/fluidsGLES/defines_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/findgleslib.mk b/src/samples/Samples/5_Domain_Specific/fluidsGLES/findgleslib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES.cpp b/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_hipified.cpp b/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_kernels.cu b/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_kernels.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_kernels.cu.hip b/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_kernels.cu.hip
old mode 100644
new mode 100755
index d9dcd28..e69de29
--- a/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_kernels.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_kernels.cu.hip
@@ -1,359 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-
-#include <hip/hip_runtime.h>
-#include <hipfft.h>        // CUDA FFT Libraries
-#include "helper_cuda_hipified.h"  // Helper functions for CUDA Error handling
-
-// OpenGL Graphics includes
-#include <GLES3/gl31.h>
-
-// FluidsGLES CUDA kernel definitions
-#include "fluidsGLES_kernels.cuh"
-
-// Texture object for reading velocity field
-hipTextureObject_t texObj;
-static hipArray *array = NULL;
-
-// Particle data
-extern GLuint vbo;  // OpenGL vertex buffer object
-extern struct hipGraphicsResource
-    *cuda_vbo_resource;  // handles OpenGL-CUDA exchange
-
-// Texture pitch
-extern size_t tPitch;
-extern hipfftHandle planr2c;
-extern hipfftHandle planc2r;
-cData *vxfield = NULL;
-cData *vyfield = NULL;
-
-void setupTexture(int x, int y) {
-  hipChannelFormatDesc desc = hipCreateChannelDesc<float2>();
-
-  hipMallocArray(&array, &desc, y, x);
-  getLastCudaError("hipMalloc failed");
-
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = array;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(hipCreateTextureObject(&texObj, &texRes, &texDescr, NULL));
-}
-
-void updateTexture(cData *data, size_t wib, size_t h, size_t pitch) {
-  HIPCHECK(hipMemcpy2DToArray(array, 0, 0, data, pitch, wib, h,
-                                      hipMemcpyDeviceToDevice));
-}
-
-void deleteTexture(void) {
-  HIPCHECK(hipDestroyTextureObject(texObj));
-  HIPCHECK(hipFreeArray(array));
-}
-
-// Note that these kernels are designed to work with arbitrary
-// domain sizes, not just domains that are multiples of the tile
-// size. Therefore, we have extra code that checks to make sure
-// a given thread location falls within the domain boundaries in
-// both X and Y. Also, the domain is covered by looping over
-// multiple elements in the Y direction, while there is a one-to-one
-// mapping between threads in X and the tile size in X.
-// Nolan Goodnight 9/22/06
-
-// This method adds constant force vectors to the velocity field
-// stored in 'v' according to v(x,t+1) = v(x,t) + dt * f.
-__global__ void addForces_k(cData *v, int dx, int dy, int spx, int spy,
-                            float fx, float fy, int r, size_t pitch) {
-  int tx = threadIdx.x;
-  int ty = threadIdx.y;
-  cData *fj = (cData *)((char *)v + (ty + spy) * pitch) + tx + spx;
-
-  cData vterm = *fj;
-  tx -= r;
-  ty -= r;
-  float s = 1.f / (1.f + tx * tx * tx * tx + ty * ty * ty * ty);
-  vterm.x += s * fx;
-  vterm.y += s * fy;
-  *fj = vterm;
-}
-
-// This method performs the velocity advection step, where we
-// trace velocity vectors back in time to update each grid cell.
-// That is, v(x,t+1) = v(p(x,-dt),t). Here we perform bilinear
-// interpolation in the velocity space.
-__global__ void advectVelocity_k(cData *v, float *vx, float *vy, int dx,
-                                 int pdx, int dy, float dt, int lb,
-                                 hipTextureObject_t texObject) {
-  int gtidx = blockIdx.x * blockDim.x + threadIdx.x;
-  int gtidy = blockIdx.y * (lb * blockDim.y) + threadIdx.y * lb;
-  int p;
-
-  cData vterm, ploc;
-  float vxterm, vyterm;
-
-  // gtidx is the domain location in x for this thread
-  if (gtidx < dx) {
-    for (p = 0; p < lb; p++) {
-      // fi is the domain location in y for this thread
-      int fi = gtidy + p;
-
-      if (fi < dy) {
-        int fj = fi * pdx + gtidx;
-        vterm = tex2D<cData>(texObject, (float)gtidx, (float)fi);
-        ploc.x = (gtidx + 0.5f) - (dt * vterm.x * dx);
-        ploc.y = (fi + 0.5f) - (dt * vterm.y * dy);
-        vterm = tex2D<cData>(texObject, ploc.x, ploc.y);
-        vxterm = vterm.x;
-        vyterm = vterm.y;
-        vx[fj] = vxterm;
-        vy[fj] = vyterm;
-      }
-    }
-  }
-}
-
-// This method performs velocity diffusion and forces mass conservation
-// in the frequency domain. The inputs 'vx' and 'vy' are complex-valued
-// arrays holding the Fourier coefficients of the velocity field in
-// X and Y. Diffusion in this space takes a simple form described as:
-// v(k,t) = v(k,t) / (1 + visc * dt * k^2), where visc is the viscosity,
-// and k is the wavenumber. The projection step forces the Fourier
-// velocity vectors to be orthogonal to the vectors for each
-// wavenumber: v(k,t) = v(k,t) - ((k dot v(k,t) * k) / k^2.
-__global__ void diffuseProject_k(cData *vx, cData *vy, int dx, int dy, float dt,
-                                 float visc, int lb) {
-  int gtidx = blockIdx.x * blockDim.x + threadIdx.x;
-  int gtidy = blockIdx.y * (lb * blockDim.y) + threadIdx.y * lb;
-  int p;
-
-  cData xterm, yterm;
-
-  // gtidx is the domain location in x for this thread
-  if (gtidx < dx) {
-    for (p = 0; p < lb; p++) {
-      // fi is the domain location in y for this thread
-      int fi = gtidy + p;
-
-      if (fi < dy) {
-        int fj = fi * dx + gtidx;
-        xterm = vx[fj];
-        yterm = vy[fj];
-
-        // Compute the index of the wavenumber based on the
-        // data order produced by a standard NN FFT.
-        int iix = gtidx;
-        int iiy = (fi > dy / 2) ? (fi - (dy)) : fi;
-
-        // Velocity diffusion
-        float kk = (float)(iix * iix + iiy * iiy);  // k^2
-        float diff = 1.f / (1.f + visc * dt * kk);
-        xterm.x *= diff;
-        xterm.y *= diff;
-        yterm.x *= diff;
-        yterm.y *= diff;
-
-        // Velocity projection
-        if (kk > 0.f) {
-          float rkk = 1.f / kk;
-          // Real portion of velocity projection
-          float rkp = (iix * xterm.x + iiy * yterm.x);
-          // Imaginary portion of velocity projection
-          float ikp = (iix * xterm.y + iiy * yterm.y);
-          xterm.x -= rkk * rkp * iix;
-          xterm.y -= rkk * ikp * iix;
-          yterm.x -= rkk * rkp * iiy;
-          yterm.y -= rkk * ikp * iiy;
-        }
-
-        vx[fj] = xterm;
-        vy[fj] = yterm;
-      }
-    }
-  }
-}
-
-// This method updates the velocity field 'v' using the two complex
-// arrays from the previous step: 'vx' and 'vy'. Here we scale the
-// real components by 1/(dx*dy) to account for an unnormalized FFT.
-__global__ void updateVelocity_k(cData *v, float *vx, float *vy, int dx,
-                                 int pdx, int dy, int lb, size_t pitch) {
-  int gtidx = blockIdx.x * blockDim.x + threadIdx.x;
-  int gtidy = blockIdx.y * (lb * blockDim.y) + threadIdx.y * lb;
-  int p;
-
-  float vxterm, vyterm;
-  cData nvterm;
-
-  // gtidx is the domain location in x for this thread
-  if (gtidx < dx) {
-    for (p = 0; p < lb; p++) {
-      // fi is the domain location in y for this thread
-      int fi = gtidy + p;
-
-      if (fi < dy) {
-        int fjr = fi * pdx + gtidx;
-        vxterm = vx[fjr];
-        vyterm = vy[fjr];
-
-        // Normalize the result of the inverse FFT
-        float scale = 1.f / (dx * dy);
-        nvterm.x = vxterm * scale;
-        nvterm.y = vyterm * scale;
-
-        cData *fj = (cData *)((char *)v + fi * pitch) + gtidx;
-        *fj = nvterm;
-      }
-    }  // If this thread is inside the domain in Y
-  }    // If this thread is inside the domain in X
-}
-
-// This method updates the particles by moving particle positions
-// according to the velocity field and time step. That is, for each
-// particle: p(t+1) = p(t) + dt * v(p(t)).
-__global__ void advectParticles_k(cData *part, cData *v, int dx, int dy,
-                                  float dt, int lb, size_t pitch) {
-  int gtidx = blockIdx.x * blockDim.x + threadIdx.x;
-  int gtidy = blockIdx.y * (lb * blockDim.y) + threadIdx.y * lb;
-  int p;
-
-  // gtidx is the domain location in x for this thread
-  cData pterm, vterm;
-
-  if (gtidx < dx) {
-    for (p = 0; p < lb; p++) {
-      // fi is the domain location in y for this thread
-      int fi = gtidy + p;
-
-      if (fi < dy) {
-        int fj = fi * dx + gtidx;
-        pterm = part[fj];
-
-        int xvi = ((int)(pterm.x * dx));
-        int yvi = ((int)(pterm.y * dy));
-        vterm = *((cData *)((char *)v + yvi * pitch) + xvi);
-
-        pterm.x += dt * vterm.x;
-        pterm.x = pterm.x - (int)pterm.x;
-        pterm.x += 1.f;
-        pterm.x = pterm.x - (int)pterm.x;
-        pterm.y += dt * vterm.y;
-        pterm.y = pterm.y - (int)pterm.y;
-        pterm.y += 1.f;
-        pterm.y = pterm.y - (int)pterm.y;
-
-        part[fj] = pterm;
-      }
-    }  // If this thread is inside the domain in Y
-  }    // If this thread is inside the domain in X
-}
-
-// These are the external function calls necessary for launching fluid simuation
-extern "C" void addForces(cData *v, int dx, int dy, int spx, int spy, float fx,
-                          float fy, int r) {
-  dim3 tids(2 * r + 1, 2 * r + 1);
-
-  addForces_k<<<1, tids>>>(v, dx, dy, spx, spy, fx, fy, r, tPitch);
-  getLastCudaError("addForces_k failed.");
-}
-
-extern "C" void advectVelocity(cData *v, float *vx, float *vy, int dx, int pdx,
-                               int dy, float dt) {
-  dim3 grid((dx / TILEX) + (!(dx % TILEX) ? 0 : 1),
-            (dy / TILEY) + (!(dy % TILEY) ? 0 : 1));
-
-  dim3 tids(TIDSX, TIDSY);
-
-  updateTexture(v, DIM * sizeof(cData), DIM, tPitch);
-  advectVelocity_k<<<grid, tids>>>(v, vx, vy, dx, pdx, dy, dt, TILEY / TIDSY,
-                                   texObj);
-  getLastCudaError("advectVelocity_k failed.");
-}
-
-extern "C" void diffuseProject(cData *vx, cData *vy, int dx, int dy, float dt,
-                               float visc) {
-  // Forward FFT
-  HIPCHECK(hipfftExecR2C(planr2c, (hipfftReal *)vx, (hipfftComplex *)vx));
-  HIPCHECK(hipfftExecR2C(planr2c, (hipfftReal *)vy, (hipfftComplex *)vy));
-
-  uint3 grid = make_uint3((dx / TILEX) + (!(dx % TILEX) ? 0 : 1),
-                          (dy / TILEY) + (!(dy % TILEY) ? 0 : 1), 1);
-  uint3 tids = make_uint3(TIDSX, TIDSY, 1);
-
-  diffuseProject_k<<<grid, tids>>>(vx, vy, dx, dy, dt, visc, TILEY / TIDSY);
-  getLastCudaError("diffuseProject_k failed.");
-
-  // Inverse FFT
-  HIPCHECK(hipfftExecC2R(planc2r, (hipfftComplex *)vx, (hipfftReal *)vx));
-  HIPCHECK(hipfftExecC2R(planc2r, (hipfftComplex *)vy, (hipfftReal *)vy));
-}
-
-extern "C" void updateVelocity(cData *v, float *vx, float *vy, int dx, int pdx,
-                               int dy) {
-  dim3 grid((dx / TILEX) + (!(dx % TILEX) ? 0 : 1),
-            (dy / TILEY) + (!(dy % TILEY) ? 0 : 1));
-  dim3 tids(TIDSX, TIDSY);
-
-  updateVelocity_k<<<grid, tids>>>(v, vx, vy, dx, pdx, dy, TILEY / TIDSY,
-                                   tPitch);
-  getLastCudaError("updateVelocity_k failed.");
-}
-
-extern "C" void advectParticles(GLuint vbo, cData *v, int dx, int dy,
-                                float dt) {
-  dim3 grid((dx / TILEX) + (!(dx % TILEX) ? 0 : 1),
-            (dy / TILEY) + (!(dy % TILEY) ? 0 : 1));
-  dim3 tids(TIDSX, TIDSY);
-
-  cData *p;
-  HIPCHECK(hipGraphicsMapResources(1, &cuda_vbo_resource, 0));
-  getLastCudaError("hipGraphicsMapResources failed");
-
-  size_t num_bytes;
-  HIPCHECK(hipGraphicsResourceGetMappedPointer((void **)&p, &num_bytes,
-                                                       cuda_vbo_resource));
-  getLastCudaError("hipGraphicsResourceGetMappedPointer failed");
-
-  advectParticles_k<<<grid, tids>>>(p, v, dx, dy, dt, TILEY / TIDSY, tPitch);
-  getLastCudaError("advectParticles_k failed.");
-
-  HIPCHECK(hipGraphicsUnmapResources(1, &cuda_vbo_resource, 0));
-}
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_kernels.cuh b/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_kernels.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_kernels.h b/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_kernels.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_kernels_hipified.cuh b/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_kernels_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_kernels_hipified.h b/src/samples/Samples/5_Domain_Specific/fluidsGLES/fluidsGLES_kernels_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/graphics_interface.h b/src/samples/Samples/5_Domain_Specific/fluidsGLES/graphics_interface.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/graphics_interface_hipified.h b/src/samples/Samples/5_Domain_Specific/fluidsGLES/graphics_interface_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/mesh.frag.glsl b/src/samples/Samples/5_Domain_Specific/fluidsGLES/mesh.frag.glsl
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/fluidsGLES/mesh.vert.glsl b/src/samples/Samples/5_Domain_Specific/fluidsGLES/mesh.vert.glsl
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/marchingCubes/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/marchingCubes/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/marchingCubes/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/marchingCubes/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/Makefile b/src/samples/Samples/5_Domain_Specific/marchingCubes/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/marchingCubes/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/README.md b/src/samples/Samples/5_Domain_Specific/marchingCubes/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/data/Bucky.raw b/src/samples/Samples/5_Domain_Specific/marchingCubes/data/Bucky.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/data/compVoxelArray.bin b/src/samples/Samples/5_Domain_Specific/marchingCubes/data/compVoxelArray.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/data/normalArray.bin b/src/samples/Samples/5_Domain_Specific/marchingCubes/data/normalArray.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/data/posArray.bin b/src/samples/Samples/5_Domain_Specific/marchingCubes/data/posArray.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/data/ref_march_cubes.ppm b/src/samples/Samples/5_Domain_Specific/marchingCubes/data/ref_march_cubes.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/defines.h b/src/samples/Samples/5_Domain_Specific/marchingCubes/defines.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/defines_hipified.h b/src/samples/Samples/5_Domain_Specific/marchingCubes/defines_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/doc/screenshot_lg.png b/src/samples/Samples/5_Domain_Specific/marchingCubes/doc/screenshot_lg.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/doc/screenshot_md.png b/src/samples/Samples/5_Domain_Specific/marchingCubes/doc/screenshot_md.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/doc/screenshot_sm.png b/src/samples/Samples/5_Domain_Specific/marchingCubes/doc/screenshot_sm.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/findgllib.mk b/src/samples/Samples/5_Domain_Specific/marchingCubes/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes.cpp b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_hipified.cpp b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_kernel.cu b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_kernel.cu.hip
old mode 100644
new mode 100755
index 57561c4..e69de29
--- a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_kernel.cu.hip
@@ -1,668 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef _MARCHING_CUBES_KERNEL_CU_
-#define _MARCHING_CUBES_KERNEL_CU_
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include "helper_cuda_hipified.h"  // includes for helper CUDA functions
-#include <helper_math.h>
-#include <hip/hip_runtime_api.h>
-#include <thrust/device_vector.h>
-#include <thrust/scan.h>
-
-#include "defines.h"
-#include "tables.h"
-
-// textures containing look-up tables
-hipTextureObject_t triTex;
-hipTextureObject_t numVertsTex;
-
-// volume data
-hipTextureObject_t volumeTex;
-
-extern "C" void allocateTextures(uint **d_edgeTable, uint **d_triTable,
-                                 uint **d_numVertsTable) {
-  HIPCHECK(hipMalloc((void **)d_edgeTable, 256 * sizeof(uint)));
-  HIPCHECK(hipMemcpy((void *)*d_edgeTable, (void *)edgeTable,
-                             256 * sizeof(uint), hipMemcpyHostToDevice));
-  hipChannelFormatDesc channelDesc =
-      hipCreateChannelDesc(32, 0, 0, 0, hipChannelFormatKindUnsigned);
-
-  HIPCHECK(hipMalloc((void **)d_triTable, 256 * 16 * sizeof(uint)));
-  HIPCHECK(hipMemcpy((void *)*d_triTable, (void *)triTable,
-                             256 * 16 * sizeof(uint), hipMemcpyHostToDevice));
-
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeLinear;
-  texRes.res.linear.devPtr = *d_triTable;
-  texRes.res.linear.sizeInBytes = 256 * 16 * sizeof(uint);
-  texRes.res.linear.desc = channelDesc;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModePoint;
-  texDescr.addressMode[0] = hipAddressModeClamp;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(hipCreateTextureObject(&triTex, &texRes, &texDescr, NULL));
-
-  HIPCHECK(hipMalloc((void **)d_numVertsTable, 256 * sizeof(uint)));
-  HIPCHECK(hipMemcpy((void *)*d_numVertsTable, (void *)numVertsTable,
-                             256 * sizeof(uint), hipMemcpyHostToDevice));
-
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeLinear;
-  texRes.res.linear.devPtr = *d_numVertsTable;
-  texRes.res.linear.sizeInBytes = 256 * sizeof(uint);
-  texRes.res.linear.desc = channelDesc;
-
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModePoint;
-  texDescr.addressMode[0] = hipAddressModeClamp;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(
-      hipCreateTextureObject(&numVertsTex, &texRes, &texDescr, NULL));
-}
-
-extern "C" void createVolumeTexture(uchar *d_volume, size_t buffSize) {
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeLinear;
-  texRes.res.linear.devPtr = d_volume;
-  texRes.res.linear.sizeInBytes = buffSize;
-  texRes.res.linear.desc =
-      hipCreateChannelDesc(8, 0, 0, 0, hipChannelFormatKindUnsigned);
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModePoint;
-  texDescr.addressMode[0] = hipAddressModeClamp;
-  texDescr.readMode = hipReadModeNormalizedFloat;
-
-  HIPCHECK(
-      hipCreateTextureObject(&volumeTex, &texRes, &texDescr, NULL));
-}
-
-extern "C" void destroyAllTextureObjects() {
-  HIPCHECK(hipDestroyTextureObject(triTex));
-  HIPCHECK(hipDestroyTextureObject(numVertsTex));
-  HIPCHECK(hipDestroyTextureObject(volumeTex));
-}
-
-// an interesting field function
-__device__ float tangle(float x, float y, float z) {
-  x *= 3.0f;
-  y *= 3.0f;
-  z *= 3.0f;
-  return (x * x * x * x - 5.0f * x * x + y * y * y * y - 5.0f * y * y +
-          z * z * z * z - 5.0f * z * z + 11.8f) * 0.2f + 0.5f;
-}
-
-// evaluate field function at point
-__device__ float fieldFunc(float3 p) { return tangle(p.x, p.y, p.z); }
-
-// evaluate field function at a point
-// returns value and gradient in float4
-__device__ float4 fieldFunc4(float3 p) {
-  float v = tangle(p.x, p.y, p.z);
-  const float d = 0.001f;
-  float dx = tangle(p.x + d, p.y, p.z) - v;
-  float dy = tangle(p.x, p.y + d, p.z) - v;
-  float dz = tangle(p.x, p.y, p.z + d) - v;
-  return make_float4(dx, dy, dz, v);
-}
-
-// sample volume data set at a point
-__device__ float sampleVolume(hipTextureObject_t volumeTex, uchar *data,
-                              uint3 p, uint3 gridSize) {
-  p.x = min(p.x, gridSize.x - 1);
-  p.y = min(p.y, gridSize.y - 1);
-  p.z = min(p.z, gridSize.z - 1);
-  uint i = (p.z * gridSize.x * gridSize.y) + (p.y * gridSize.x) + p.x;
-  //    return (float) data[i] / 255.0f;
-  return tex1Dfetch<float>(volumeTex, i);
-}
-
-// compute position in 3d grid from 1d index
-// only works for power of 2 sizes
-__device__ uint3 calcGridPos(uint i, uint3 gridSizeShift, uint3 gridSizeMask) {
-  uint3 gridPos;
-  gridPos.x = i & gridSizeMask.x;
-  gridPos.y = (i >> gridSizeShift.y) & gridSizeMask.y;
-  gridPos.z = (i >> gridSizeShift.z) & gridSizeMask.z;
-  return gridPos;
-}
-
-// classify voxel based on number of vertices it will generate
-// one thread per voxel
-__global__ void classifyVoxel(uint *voxelVerts, uint *voxelOccupied,
-                              uchar *volume, uint3 gridSize,
-                              uint3 gridSizeShift, uint3 gridSizeMask,
-                              uint numVoxels, float3 voxelSize, float isoValue,
-                              hipTextureObject_t numVertsTex,
-                              hipTextureObject_t volumeTex) {
-  uint blockId = __mul24(blockIdx.y, gridDim.x) + blockIdx.x;
-  uint i = __mul24(blockId, blockDim.x) + threadIdx.x;
-
-  uint3 gridPos = calcGridPos(i, gridSizeShift, gridSizeMask);
-
-// read field values at neighbouring grid vertices
-#if SAMPLE_VOLUME
-  float field[8];
-  field[0] = sampleVolume(volumeTex, volume, gridPos, gridSize);
-  field[1] =
-      sampleVolume(volumeTex, volume, gridPos + make_uint3(1, 0, 0), gridSize);
-  field[2] =
-      sampleVolume(volumeTex, volume, gridPos + make_uint3(1, 1, 0), gridSize);
-  field[3] =
-      sampleVolume(volumeTex, volume, gridPos + make_uint3(0, 1, 0), gridSize);
-  field[4] =
-      sampleVolume(volumeTex, volume, gridPos + make_uint3(0, 0, 1), gridSize);
-  field[5] =
-      sampleVolume(volumeTex, volume, gridPos + make_uint3(1, 0, 1), gridSize);
-  field[6] =
-      sampleVolume(volumeTex, volume, gridPos + make_uint3(1, 1, 1), gridSize);
-  field[7] =
-      sampleVolume(volumeTex, volume, gridPos + make_uint3(0, 1, 1), gridSize);
-#else
-  float3 p;
-  p.x = -1.0f + (gridPos.x * voxelSize.x);
-  p.y = -1.0f + (gridPos.y * voxelSize.y);
-  p.z = -1.0f + (gridPos.z * voxelSize.z);
-
-  float field[8];
-  field[0] = fieldFunc(p);
-  field[1] = fieldFunc(p + make_float3(voxelSize.x, 0, 0));
-  field[2] = fieldFunc(p + make_float3(voxelSize.x, voxelSize.y, 0));
-  field[3] = fieldFunc(p + make_float3(0, voxelSize.y, 0));
-  field[4] = fieldFunc(p + make_float3(0, 0, voxelSize.z));
-  field[5] = fieldFunc(p + make_float3(voxelSize.x, 0, voxelSize.z));
-  field[6] = fieldFunc(p + make_float3(voxelSize.x, voxelSize.y, voxelSize.z));
-  field[7] = fieldFunc(p + make_float3(0, voxelSize.y, voxelSize.z));
-#endif
-
-  // calculate flag indicating if each vertex is inside or outside isosurface
-  uint cubeindex;
-  cubeindex = uint(field[0] < isoValue);
-  cubeindex += uint(field[1] < isoValue) * 2;
-  cubeindex += uint(field[2] < isoValue) * 4;
-  cubeindex += uint(field[3] < isoValue) * 8;
-  cubeindex += uint(field[4] < isoValue) * 16;
-  cubeindex += uint(field[5] < isoValue) * 32;
-  cubeindex += uint(field[6] < isoValue) * 64;
-  cubeindex += uint(field[7] < isoValue) * 128;
-
-  // read number of vertices from texture
-  uint numVerts = tex1Dfetch<uint>(numVertsTex, cubeindex);
-
-  if (i < numVoxels) {
-    voxelVerts[i] = numVerts;
-    voxelOccupied[i] = (numVerts > 0);
-  }
-}
-
-extern "C" void launch_classifyVoxel(dim3 grid, dim3 threads, uint *voxelVerts,
-                                     uint *voxelOccupied, uchar *volume,
-                                     uint3 gridSize, uint3 gridSizeShift,
-                                     uint3 gridSizeMask, uint numVoxels,
-                                     float3 voxelSize, float isoValue) {
-  // calculate number of vertices need per voxel
-  classifyVoxel<<<grid, threads>>>(voxelVerts, voxelOccupied, volume, gridSize,
-                                   gridSizeShift, gridSizeMask, numVoxels,
-                                   voxelSize, isoValue, numVertsTex, volumeTex);
-  getLastCudaError("classifyVoxel failed");
-}
-
-// compact voxel array
-__global__ void compactVoxels(uint *compactedVoxelArray, uint *voxelOccupied,
-                              uint *voxelOccupiedScan, uint numVoxels) {
-  uint blockId = __mul24(blockIdx.y, gridDim.x) + blockIdx.x;
-  uint i = __mul24(blockId, blockDim.x) + threadIdx.x;
-
-  if (voxelOccupied[i] && (i < numVoxels)) {
-    compactedVoxelArray[voxelOccupiedScan[i]] = i;
-  }
-}
-
-extern "C" void launch_compactVoxels(dim3 grid, dim3 threads,
-                                     uint *compactedVoxelArray,
-                                     uint *voxelOccupied,
-                                     uint *voxelOccupiedScan, uint numVoxels) {
-  compactVoxels<<<grid, threads>>>(compactedVoxelArray, voxelOccupied,
-                                   voxelOccupiedScan, numVoxels);
-  getLastCudaError("compactVoxels failed");
-}
-
-// compute interpolated vertex along an edge
-__device__ float3 vertexInterp(float isolevel, float3 p0, float3 p1, float f0,
-                               float f1) {
-  float t = (isolevel - f0) / (f1 - f0);
-  return lerp(p0, p1, t);
-}
-
-// compute interpolated vertex position and normal along an edge
-__device__ void vertexInterp2(float isolevel, float3 p0, float3 p1, float4 f0,
-                              float4 f1, float3 &p, float3 &n) {
-  float t = (isolevel - f0.w) / (f1.w - f0.w);
-  p = lerp(p0, p1, t);
-  n.x = lerp(f0.x, f1.x, t);
-  n.y = lerp(f0.y, f1.y, t);
-  n.z = lerp(f0.z, f1.z, t);
-  //    n = normalize(n);
-}
-
-// generate triangles for each voxel using marching cubes
-// interpolates normals from field function
-__global__ void generateTriangles(
-    float4 *pos, float4 *norm, uint *compactedVoxelArray, uint *numVertsScanned,
-    uint3 gridSize, uint3 gridSizeShift, uint3 gridSizeMask, float3 voxelSize,
-    float isoValue, uint activeVoxels, uint maxVerts,
-    hipTextureObject_t triTex, hipTextureObject_t numVertsTex) {
-  uint blockId = __mul24(blockIdx.y, gridDim.x) + blockIdx.x;
-  uint i = __mul24(blockId, blockDim.x) + threadIdx.x;
-
-  if (i > activeVoxels - 1) {
-    // can't return here because of syncthreads()
-    i = activeVoxels - 1;
-  }
-
-#if SKIP_EMPTY_VOXELS
-  uint voxel = compactedVoxelArray[i];
-#else
-  uint voxel = i;
-#endif
-
-  // compute position in 3d grid
-  uint3 gridPos = calcGridPos(voxel, gridSizeShift, gridSizeMask);
-
-  float3 p;
-  p.x = -1.0f + (gridPos.x * voxelSize.x);
-  p.y = -1.0f + (gridPos.y * voxelSize.y);
-  p.z = -1.0f + (gridPos.z * voxelSize.z);
-
-  // calculate cell vertex positions
-  float3 v[8];
-  v[0] = p;
-  v[1] = p + make_float3(voxelSize.x, 0, 0);
-  v[2] = p + make_float3(voxelSize.x, voxelSize.y, 0);
-  v[3] = p + make_float3(0, voxelSize.y, 0);
-  v[4] = p + make_float3(0, 0, voxelSize.z);
-  v[5] = p + make_float3(voxelSize.x, 0, voxelSize.z);
-  v[6] = p + make_float3(voxelSize.x, voxelSize.y, voxelSize.z);
-  v[7] = p + make_float3(0, voxelSize.y, voxelSize.z);
-
-  // evaluate field values
-  float4 field[8];
-  field[0] = fieldFunc4(v[0]);
-  field[1] = fieldFunc4(v[1]);
-  field[2] = fieldFunc4(v[2]);
-  field[3] = fieldFunc4(v[3]);
-  field[4] = fieldFunc4(v[4]);
-  field[5] = fieldFunc4(v[5]);
-  field[6] = fieldFunc4(v[6]);
-  field[7] = fieldFunc4(v[7]);
-
-  // recalculate flag
-  // (this is faster than storing it in global memory)
-  uint cubeindex;
-  cubeindex = uint(field[0].w < isoValue);
-  cubeindex += uint(field[1].w < isoValue) * 2;
-  cubeindex += uint(field[2].w < isoValue) * 4;
-  cubeindex += uint(field[3].w < isoValue) * 8;
-  cubeindex += uint(field[4].w < isoValue) * 16;
-  cubeindex += uint(field[5].w < isoValue) * 32;
-  cubeindex += uint(field[6].w < isoValue) * 64;
-  cubeindex += uint(field[7].w < isoValue) * 128;
-
-// find the vertices where the surface intersects the cube
-
-#if USE_SHARED
-  // use partioned shared memory to avoid using local memory
-  __shared__ float3 vertlist[12 * NTHREADS];
-  __shared__ float3 normlist[12 * NTHREADS];
-
-  vertexInterp2(isoValue, v[0], v[1], field[0], field[1], vertlist[threadIdx.x],
-                normlist[threadIdx.x]);
-  vertexInterp2(isoValue, v[1], v[2], field[1], field[2],
-                vertlist[threadIdx.x + NTHREADS],
-                normlist[threadIdx.x + NTHREADS]);
-  vertexInterp2(isoValue, v[2], v[3], field[2], field[3],
-                vertlist[threadIdx.x + (NTHREADS * 2)],
-                normlist[threadIdx.x + (NTHREADS * 2)]);
-  vertexInterp2(isoValue, v[3], v[0], field[3], field[0],
-                vertlist[threadIdx.x + (NTHREADS * 3)],
-                normlist[threadIdx.x + (NTHREADS * 3)]);
-  vertexInterp2(isoValue, v[4], v[5], field[4], field[5],
-                vertlist[threadIdx.x + (NTHREADS * 4)],
-                normlist[threadIdx.x + (NTHREADS * 4)]);
-  vertexInterp2(isoValue, v[5], v[6], field[5], field[6],
-                vertlist[threadIdx.x + (NTHREADS * 5)],
-                normlist[threadIdx.x + (NTHREADS * 5)]);
-  vertexInterp2(isoValue, v[6], v[7], field[6], field[7],
-                vertlist[threadIdx.x + (NTHREADS * 6)],
-                normlist[threadIdx.x + (NTHREADS * 6)]);
-  vertexInterp2(isoValue, v[7], v[4], field[7], field[4],
-                vertlist[threadIdx.x + (NTHREADS * 7)],
-                normlist[threadIdx.x + (NTHREADS * 7)]);
-  vertexInterp2(isoValue, v[0], v[4], field[0], field[4],
-                vertlist[threadIdx.x + (NTHREADS * 8)],
-                normlist[threadIdx.x + (NTHREADS * 8)]);
-  vertexInterp2(isoValue, v[1], v[5], field[1], field[5],
-                vertlist[threadIdx.x + (NTHREADS * 9)],
-                normlist[threadIdx.x + (NTHREADS * 9)]);
-  vertexInterp2(isoValue, v[2], v[6], field[2], field[6],
-                vertlist[threadIdx.x + (NTHREADS * 10)],
-                normlist[threadIdx.x + (NTHREADS * 10)]);
-  vertexInterp2(isoValue, v[3], v[7], field[3], field[7],
-                vertlist[threadIdx.x + (NTHREADS * 11)],
-                normlist[threadIdx.x + (NTHREADS * 11)]);
-  __syncthreads();
-
-#else
-  float3 vertlist[12];
-  float3 normlist[12];
-
-  vertexInterp2(isoValue, v[0], v[1], field[0], field[1], vertlist[0],
-                normlist[0]);
-  vertexInterp2(isoValue, v[1], v[2], field[1], field[2], vertlist[1],
-                normlist[1]);
-  vertexInterp2(isoValue, v[2], v[3], field[2], field[3], vertlist[2],
-                normlist[2]);
-  vertexInterp2(isoValue, v[3], v[0], field[3], field[0], vertlist[3],
-                normlist[3]);
-
-  vertexInterp2(isoValue, v[4], v[5], field[4], field[5], vertlist[4],
-                normlist[4]);
-  vertexInterp2(isoValue, v[5], v[6], field[5], field[6], vertlist[5],
-                normlist[5]);
-  vertexInterp2(isoValue, v[6], v[7], field[6], field[7], vertlist[6],
-                normlist[6]);
-  vertexInterp2(isoValue, v[7], v[4], field[7], field[4], vertlist[7],
-                normlist[7]);
-
-  vertexInterp2(isoValue, v[0], v[4], field[0], field[4], vertlist[8],
-                normlist[8]);
-  vertexInterp2(isoValue, v[1], v[5], field[1], field[5], vertlist[9],
-                normlist[9]);
-  vertexInterp2(isoValue, v[2], v[6], field[2], field[6], vertlist[10],
-                normlist[10]);
-  vertexInterp2(isoValue, v[3], v[7], field[3], field[7], vertlist[11],
-                normlist[11]);
-#endif
-
-  // output triangle vertices
-  uint numVerts = tex1Dfetch<uint>(numVertsTex, cubeindex);
-
-  for (int i = 0; i < numVerts; i++) {
-    uint edge = tex1Dfetch<uint>(triTex, cubeindex * 16 + i);
-
-    uint index = numVertsScanned[voxel] + i;
-
-    if (index < maxVerts) {
-#if USE_SHARED
-      pos[index] = make_float4(vertlist[(edge * NTHREADS) + threadIdx.x], 1.0f);
-      norm[index] =
-          make_float4(normlist[(edge * NTHREADS) + threadIdx.x], 0.0f);
-#else
-      pos[index] = make_float4(vertlist[edge], 1.0f);
-      norm[index] = make_float4(normlist[edge], 0.0f);
-#endif
-    }
-  }
-}
-
-extern "C" void launch_generateTriangles(
-    dim3 grid, dim3 threads, float4 *pos, float4 *norm,
-    uint *compactedVoxelArray, uint *numVertsScanned, uint3 gridSize,
-    uint3 gridSizeShift, uint3 gridSizeMask, float3 voxelSize, float isoValue,
-    uint activeVoxels, uint maxVerts) {
-  generateTriangles<<<grid, NTHREADS>>>(
-      pos, norm, compactedVoxelArray, numVertsScanned, gridSize, gridSizeShift,
-      gridSizeMask, voxelSize, isoValue, activeVoxels, maxVerts, triTex,
-      numVertsTex);
-  getLastCudaError("generateTriangles failed");
-}
-
-// calculate triangle normal
-__device__ float3 calcNormal(float3 *v0, float3 *v1, float3 *v2) {
-  float3 edge0 = *v1 - *v0;
-  float3 edge1 = *v2 - *v0;
-  // note - it's faster to perform normalization in vertex shader rather than
-  // here
-  return cross(edge0, edge1);
-}
-
-// version that calculates flat surface normal for each triangle
-__global__ void generateTriangles2(
-    float4 *pos, float4 *norm, uint *compactedVoxelArray, uint *numVertsScanned,
-    uchar *volume, uint3 gridSize, uint3 gridSizeShift, uint3 gridSizeMask,
-    float3 voxelSize, float isoValue, uint activeVoxels, uint maxVerts,
-    hipTextureObject_t triTex, hipTextureObject_t numVertsTex,
-    hipTextureObject_t volumeTex) {
-  uint blockId = __mul24(blockIdx.y, gridDim.x) + blockIdx.x;
-  uint i = __mul24(blockId, blockDim.x) + threadIdx.x;
-
-  if (i > activeVoxels - 1) {
-    i = activeVoxels - 1;
-  }
-
-#if SKIP_EMPTY_VOXELS
-  uint voxel = compactedVoxelArray[i];
-#else
-  uint voxel = i;
-#endif
-
-  // compute position in 3d grid
-  uint3 gridPos = calcGridPos(voxel, gridSizeShift, gridSizeMask);
-
-  float3 p;
-  p.x = -1.0f + (gridPos.x * voxelSize.x);
-  p.y = -1.0f + (gridPos.y * voxelSize.y);
-  p.z = -1.0f + (gridPos.z * voxelSize.z);
-
-  // calculate cell vertex positions
-  float3 v[8];
-  v[0] = p;
-  v[1] = p + make_float3(voxelSize.x, 0, 0);
-  v[2] = p + make_float3(voxelSize.x, voxelSize.y, 0);
-  v[3] = p + make_float3(0, voxelSize.y, 0);
-  v[4] = p + make_float3(0, 0, voxelSize.z);
-  v[5] = p + make_float3(voxelSize.x, 0, voxelSize.z);
-  v[6] = p + make_float3(voxelSize.x, voxelSize.y, voxelSize.z);
-  v[7] = p + make_float3(0, voxelSize.y, voxelSize.z);
-
-#if SAMPLE_VOLUME
-  float field[8];
-  field[0] = sampleVolume(volumeTex, volume, gridPos, gridSize);
-  field[1] =
-      sampleVolume(volumeTex, volume, gridPos + make_uint3(1, 0, 0), gridSize);
-  field[2] =
-      sampleVolume(volumeTex, volume, gridPos + make_uint3(1, 1, 0), gridSize);
-  field[3] =
-      sampleVolume(volumeTex, volume, gridPos + make_uint3(0, 1, 0), gridSize);
-  field[4] =
-      sampleVolume(volumeTex, volume, gridPos + make_uint3(0, 0, 1), gridSize);
-  field[5] =
-      sampleVolume(volumeTex, volume, gridPos + make_uint3(1, 0, 1), gridSize);
-  field[6] =
-      sampleVolume(volumeTex, volume, gridPos + make_uint3(1, 1, 1), gridSize);
-  field[7] =
-      sampleVolume(volumeTex, volume, gridPos + make_uint3(0, 1, 1), gridSize);
-#else
-  // evaluate field values
-  float field[8];
-  field[0] = fieldFunc(v[0]);
-  field[1] = fieldFunc(v[1]);
-  field[2] = fieldFunc(v[2]);
-  field[3] = fieldFunc(v[3]);
-  field[4] = fieldFunc(v[4]);
-  field[5] = fieldFunc(v[5]);
-  field[6] = fieldFunc(v[6]);
-  field[7] = fieldFunc(v[7]);
-#endif
-
-  // recalculate flag
-  uint cubeindex;
-  cubeindex = uint(field[0] < isoValue);
-  cubeindex += uint(field[1] < isoValue) * 2;
-  cubeindex += uint(field[2] < isoValue) * 4;
-  cubeindex += uint(field[3] < isoValue) * 8;
-  cubeindex += uint(field[4] < isoValue) * 16;
-  cubeindex += uint(field[5] < isoValue) * 32;
-  cubeindex += uint(field[6] < isoValue) * 64;
-  cubeindex += uint(field[7] < isoValue) * 128;
-
-// find the vertices where the surface intersects the cube
-
-#if USE_SHARED
-  // use shared memory to avoid using local
-  __shared__ float3 vertlist[12 * NTHREADS];
-
-  vertlist[threadIdx.x] =
-      vertexInterp(isoValue, v[0], v[1], field[0], field[1]);
-  vertlist[NTHREADS + threadIdx.x] =
-      vertexInterp(isoValue, v[1], v[2], field[1], field[2]);
-  vertlist[(NTHREADS * 2) + threadIdx.x] =
-      vertexInterp(isoValue, v[2], v[3], field[2], field[3]);
-  vertlist[(NTHREADS * 3) + threadIdx.x] =
-      vertexInterp(isoValue, v[3], v[0], field[3], field[0]);
-  vertlist[(NTHREADS * 4) + threadIdx.x] =
-      vertexInterp(isoValue, v[4], v[5], field[4], field[5]);
-  vertlist[(NTHREADS * 5) + threadIdx.x] =
-      vertexInterp(isoValue, v[5], v[6], field[5], field[6]);
-  vertlist[(NTHREADS * 6) + threadIdx.x] =
-      vertexInterp(isoValue, v[6], v[7], field[6], field[7]);
-  vertlist[(NTHREADS * 7) + threadIdx.x] =
-      vertexInterp(isoValue, v[7], v[4], field[7], field[4]);
-  vertlist[(NTHREADS * 8) + threadIdx.x] =
-      vertexInterp(isoValue, v[0], v[4], field[0], field[4]);
-  vertlist[(NTHREADS * 9) + threadIdx.x] =
-      vertexInterp(isoValue, v[1], v[5], field[1], field[5]);
-  vertlist[(NTHREADS * 10) + threadIdx.x] =
-      vertexInterp(isoValue, v[2], v[6], field[2], field[6]);
-  vertlist[(NTHREADS * 11) + threadIdx.x] =
-      vertexInterp(isoValue, v[3], v[7], field[3], field[7]);
-  __syncthreads();
-#else
-
-  float3 vertlist[12];
-
-  vertlist[0] = vertexInterp(isoValue, v[0], v[1], field[0], field[1]);
-  vertlist[1] = vertexInterp(isoValue, v[1], v[2], field[1], field[2]);
-  vertlist[2] = vertexInterp(isoValue, v[2], v[3], field[2], field[3]);
-  vertlist[3] = vertexInterp(isoValue, v[3], v[0], field[3], field[0]);
-
-  vertlist[4] = vertexInterp(isoValue, v[4], v[5], field[4], field[5]);
-  vertlist[5] = vertexInterp(isoValue, v[5], v[6], field[5], field[6]);
-  vertlist[6] = vertexInterp(isoValue, v[6], v[7], field[6], field[7]);
-  vertlist[7] = vertexInterp(isoValue, v[7], v[4], field[7], field[4]);
-
-  vertlist[8] = vertexInterp(isoValue, v[0], v[4], field[0], field[4]);
-  vertlist[9] = vertexInterp(isoValue, v[1], v[5], field[1], field[5]);
-  vertlist[10] = vertexInterp(isoValue, v[2], v[6], field[2], field[6]);
-  vertlist[11] = vertexInterp(isoValue, v[3], v[7], field[3], field[7]);
-#endif
-
-  // output triangle vertices
-  uint numVerts = tex1Dfetch<uint>(numVertsTex, cubeindex);
-
-  for (int i = 0; i < numVerts; i += 3) {
-    uint index = numVertsScanned[voxel] + i;
-
-    float3 *v[3];
-    uint edge;
-    edge = tex1Dfetch<uint>(triTex, (cubeindex * 16) + i);
-#if USE_SHARED
-    v[0] = &vertlist[(edge * NTHREADS) + threadIdx.x];
-#else
-    v[0] = &vertlist[edge];
-#endif
-
-    edge = tex1Dfetch<uint>(triTex, (cubeindex * 16) + i + 1);
-#if USE_SHARED
-    v[1] = &vertlist[(edge * NTHREADS) + threadIdx.x];
-#else
-    v[1] = &vertlist[edge];
-#endif
-
-    edge = tex1Dfetch<uint>(triTex, (cubeindex * 16) + i + 2);
-#if USE_SHARED
-    v[2] = &vertlist[(edge * NTHREADS) + threadIdx.x];
-#else
-    v[2] = &vertlist[edge];
-#endif
-
-    // calculate triangle surface normal
-    float3 n = calcNormal(v[0], v[1], v[2]);
-
-    if (index < (maxVerts - 3)) {
-      pos[index] = make_float4(*v[0], 1.0f);
-      norm[index] = make_float4(n, 0.0f);
-
-      pos[index + 1] = make_float4(*v[1], 1.0f);
-      norm[index + 1] = make_float4(n, 0.0f);
-
-      pos[index + 2] = make_float4(*v[2], 1.0f);
-      norm[index + 2] = make_float4(n, 0.0f);
-    }
-  }
-}
-
-extern "C" void launch_generateTriangles2(
-    dim3 grid, dim3 threads, float4 *pos, float4 *norm,
-    uint *compactedVoxelArray, uint *numVertsScanned, uchar *volume,
-    uint3 gridSize, uint3 gridSizeShift, uint3 gridSizeMask, float3 voxelSize,
-    float isoValue, uint activeVoxels, uint maxVerts) {
-  generateTriangles2<<<grid, NTHREADS>>>(
-      pos, norm, compactedVoxelArray, numVertsScanned, volume, gridSize,
-      gridSizeShift, gridSizeMask, voxelSize, isoValue, activeVoxels, maxVerts,
-      triTex, numVertsTex, volumeTex);
-  getLastCudaError("generateTriangles2 failed");
-}
-
-extern "C" void ThrustScanWrapper(unsigned int *output, unsigned int *input,
-                                  unsigned int numElements) {
-  thrust::exclusive_scan(thrust::device_ptr<unsigned int>(input),
-                         thrust::device_ptr<unsigned int>(input + numElements),
-                         thrust::device_ptr<unsigned int>(output));
-}
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2017.sln b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2019.sln b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2022.sln b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/marchingCubes/marchingCubes_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/tables.h b/src/samples/Samples/5_Domain_Specific/marchingCubes/tables.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/marchingCubes/tables_hipified.h b/src/samples/Samples/5_Domain_Specific/marchingCubes/tables_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/nbody/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/nbody/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/nbody/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/nbody/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/Makefile b/src/samples/Samples/5_Domain_Specific/nbody/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/nbody/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/README.md b/src/samples/Samples/5_Domain_Specific/nbody/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/bodysystem.h b/src/samples/Samples/5_Domain_Specific/nbody/bodysystem.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/bodysystem_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody/bodysystem_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcpu.h b/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcpu.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcpu_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcpu_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcpu_impl.h b/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcpu_impl.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcpu_impl_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcpu_impl_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda.cu b/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda.cu.hip b/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda.cu.hip
old mode 100644
new mode 100755
index 8823fdd..e69de29
--- a/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda.cu.hip
@@ -1,288 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "helper_cuda_hipified.h"
-#include <math.h>
-
-#if defined(__APPLE__) || defined(MACOSX)
-#pragma clang diagnostic ignored "-Wdeprecated-declarations"
-#include <GLUT/glut.h>
-#else
-#include <GL/freeglut.h>
-#endif
-
-// CUDA standard includes
-#include <hip/hip_runtime.h>
-#include <cuda_gl_interop.h>
-
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-
-#include "bodysystem.h"
-
-__constant__ float softeningSquared;
-__constant__ double softeningSquared_fp64;
-
-hipError_t setSofteningSquared(float softeningSq) {
-  return hipMemcpyToSymbol(HIP_SYMBOL(softeningSquared), &softeningSq, sizeof(float), 0,
-                            hipMemcpyHostToDevice);
-}
-
-hipError_t setSofteningSquared(double softeningSq) {
-  return hipMemcpyToSymbol(HIP_SYMBOL(softeningSquared_fp64), &softeningSq, sizeof(double),
-                            0, hipMemcpyHostToDevice);
-}
-
-template <class T>
-struct SharedMemory {
-  __device__ inline operator T *() {
-    extern __shared__ int __smem[];
-    return (T *)__smem;
-  }
-
-  __device__ inline operator const T *() const {
-    extern __shared__ int __smem[];
-    return (T *)__smem;
-  }
-};
-
-template <typename T>
-__device__ T rsqrt_T(T x) {
-  return rsqrt(x);
-}
-
-template <>
-__device__ float rsqrt_T<float>(float x) {
-  return rsqrtf(x);
-}
-
-template <>
-__device__ double rsqrt_T<double>(double x) {
-  return rsqrt(x);
-}
-
-// Macros to simplify shared memory addressing
-#define SX(i) sharedPos[i + blockDim.x * threadIdx.y]
-// This macro is only used when multithreadBodies is true (below)
-#define SX_SUM(i, j) sharedPos[i + blockDim.x * j]
-
-template <typename T>
-__device__ T getSofteningSquared() {
-  return softeningSquared;
-}
-template <>
-__device__ double getSofteningSquared<double>() {
-  return softeningSquared_fp64;
-}
-
-template <typename T>
-struct DeviceData {
-  T *dPos[2];  // mapped host pointers
-  T *dVel;
-  hipEvent_t event;
-  unsigned int offset;
-  unsigned int numBodies;
-};
-
-template <typename T>
-__device__ typename vec3<T>::Type bodyBodyInteraction(
-    typename vec3<T>::Type ai, typename vec4<T>::Type bi,
-    typename vec4<T>::Type bj) {
-  typename vec3<T>::Type r;
-
-  // r_ij  [3 FLOPS]
-  r.x = bj.x - bi.x;
-  r.y = bj.y - bi.y;
-  r.z = bj.z - bi.z;
-
-  // distSqr = dot(r_ij, r_ij) + EPS^2  [6 FLOPS]
-  T distSqr = r.x * r.x + r.y * r.y + r.z * r.z;
-  distSqr += getSofteningSquared<T>();
-
-  // invDistCube =1/distSqr^(3/2)  [4 FLOPS (2 mul, 1 sqrt, 1 inv)]
-  T invDist = rsqrt_T(distSqr);
-  T invDistCube = invDist * invDist * invDist;
-
-  // s = m_j * invDistCube [1 FLOP]
-  T s = bj.w * invDistCube;
-
-  // a_i =  a_i + s * r_ij [6 FLOPS]
-  ai.x += r.x * s;
-  ai.y += r.y * s;
-  ai.z += r.z * s;
-
-  return ai;
-}
-
-template <typename T>
-__device__ typename vec3<T>::Type computeBodyAccel(
-    typename vec4<T>::Type bodyPos, typename vec4<T>::Type *positions,
-    int numTiles, cg::thread_block cta) {
-  typename vec4<T>::Type *sharedPos = SharedMemory<typename vec4<T>::Type>();
-
-  typename vec3<T>::Type acc = {0.0f, 0.0f, 0.0f};
-
-  for (int tile = 0; tile < numTiles; tile++) {
-    sharedPos[threadIdx.x] = positions[tile * blockDim.x + threadIdx.x];
-
-    cg::sync(cta);
-
-// This is the "tile_calculation" from the GPUG3 article.
-#pragma unroll 128
-
-    for (unsigned int counter = 0; counter < blockDim.x; counter++) {
-      acc = bodyBodyInteraction<T>(acc, bodyPos, sharedPos[counter]);
-    }
-
-    cg::sync(cta);
-  }
-
-  return acc;
-}
-
-template <typename T>
-__global__ void integrateBodies(typename vec4<T>::Type *__restrict__ newPos,
-                                typename vec4<T>::Type *__restrict__ oldPos,
-                                typename vec4<T>::Type *vel,
-                                unsigned int deviceOffset,
-                                unsigned int deviceNumBodies, float deltaTime,
-                                float damping, int numTiles) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  int index = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (index >= deviceNumBodies) {
-    return;
-  }
-
-  typename vec4<T>::Type position = oldPos[deviceOffset + index];
-
-  typename vec3<T>::Type accel =
-      computeBodyAccel<T>(position, oldPos, numTiles, cta);
-
-  // acceleration = force / mass;
-  // new velocity = old velocity + acceleration * deltaTime
-  // note we factor out the body's mass from the equation, here and in
-  // bodyBodyInteraction
-  // (because they cancel out).  Thus here force == acceleration
-  typename vec4<T>::Type velocity = vel[deviceOffset + index];
-
-  velocity.x += accel.x * deltaTime;
-  velocity.y += accel.y * deltaTime;
-  velocity.z += accel.z * deltaTime;
-
-  velocity.x *= damping;
-  velocity.y *= damping;
-  velocity.z *= damping;
-
-  // new position = old position + velocity * deltaTime
-  position.x += velocity.x * deltaTime;
-  position.y += velocity.y * deltaTime;
-  position.z += velocity.z * deltaTime;
-
-  // store new position and velocity
-  newPos[deviceOffset + index] = position;
-  vel[deviceOffset + index] = velocity;
-}
-
-template <typename T>
-void integrateNbodySystem(DeviceData<T> *deviceData,
-                          hipGraphicsResource **pgres,
-                          unsigned int currentRead, float deltaTime,
-                          float damping, unsigned int numBodies,
-                          unsigned int numDevices, int blockSize,
-                          bool bUsePBO) {
-  if (bUsePBO) {
-    HIPCHECK(cudaGraphicsResourceSetMapFlags(
-        pgres[currentRead], cudaGraphicsMapFlagsReadOnly));
-    HIPCHECK(cudaGraphicsResourceSetMapFlags(
-        pgres[1 - currentRead], cudaGraphicsMapFlagsWriteDiscard));
-    HIPCHECK(hipGraphicsMapResources(2, pgres, 0));
-    size_t bytes;
-    HIPCHECK(hipGraphicsResourceGetMappedPointer(
-        (void **)&(deviceData[0].dPos[currentRead]), &bytes,
-        pgres[currentRead]));
-    HIPCHECK(hipGraphicsResourceGetMappedPointer(
-        (void **)&(deviceData[0].dPos[1 - currentRead]), &bytes,
-        pgres[1 - currentRead]));
-  }
-
-  for (unsigned int dev = 0; dev != numDevices; dev++) {
-    if (numDevices > 1) {
-      hipSetDevice(dev);
-    }
-
-    int numBlocks = (deviceData[dev].numBodies + blockSize - 1) / blockSize;
-    int numTiles = (numBodies + blockSize - 1) / blockSize;
-    int sharedMemSize = blockSize * 4 * sizeof(T);  // 4 floats for pos
-
-    integrateBodies<T><<<numBlocks, blockSize, sharedMemSize>>>(
-        (typename vec4<T>::Type *)deviceData[dev].dPos[1 - currentRead],
-        (typename vec4<T>::Type *)deviceData[dev].dPos[currentRead],
-        (typename vec4<T>::Type *)deviceData[dev].dVel, deviceData[dev].offset,
-        deviceData[dev].numBodies, deltaTime, damping, numTiles);
-
-    if (numDevices > 1) {
-      HIPCHECK(hipEventRecord(deviceData[dev].event));
-      // MJH: Hack on older driver versions to force kernel launches to flush!
-      hipStreamQuery(0);
-    }
-
-    // check if kernel invocation generated an error
-    getLastCudaError("Kernel execution failed");
-  }
-
-  if (numDevices > 1) {
-    for (unsigned int dev = 0; dev < numDevices; dev++) {
-      HIPCHECK(hipEventSynchronize(deviceData[dev].event));
-    }
-  }
-
-  if (bUsePBO) {
-    HIPCHECK(hipGraphicsUnmapResources(2, pgres, 0));
-  }
-}
-
-// Explicit specializations needed to generate code
-template void integrateNbodySystem<float>(DeviceData<float> *deviceData,
-                                          hipGraphicsResource **pgres,
-                                          unsigned int currentRead,
-                                          float deltaTime, float damping,
-                                          unsigned int numBodies,
-                                          unsigned int numDevices,
-                                          int blockSize, bool bUsePBO);
-
-template void integrateNbodySystem<double>(DeviceData<double> *deviceData,
-                                           hipGraphicsResource **pgres,
-                                           unsigned int currentRead,
-                                           float deltaTime, float damping,
-                                           unsigned int numBodies,
-                                           unsigned int numDevices,
-                                           int blockSize, bool bUsePBO);
-                          int blockSize, bool bUsePBO);
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda.h b/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda_impl.h b/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda_impl.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda_impl_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody/bodysystemcuda_impl_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/doc/nbody_gems3_ch31.pdf b/src/samples/Samples/5_Domain_Specific/nbody/doc/nbody_gems3_ch31.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/doc/screenshot_lg.jpg b/src/samples/Samples/5_Domain_Specific/nbody/doc/screenshot_lg.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/doc/screenshot_md.jpg b/src/samples/Samples/5_Domain_Specific/nbody/doc/screenshot_md.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/doc/screenshot_sm.jpg b/src/samples/Samples/5_Domain_Specific/nbody/doc/screenshot_sm.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/findgllib.mk b/src/samples/Samples/5_Domain_Specific/nbody/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/nbody.cpp b/src/samples/Samples/5_Domain_Specific/nbody/nbody.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/nbody_hipified.cpp b/src/samples/Samples/5_Domain_Specific/nbody/nbody_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2017.sln b/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2019.sln b/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2022.sln b/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/nbody/nbody_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/render_particles.cpp b/src/samples/Samples/5_Domain_Specific/nbody/render_particles.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/render_particles.h b/src/samples/Samples/5_Domain_Specific/nbody/render_particles.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/render_particles_hipified.cpp b/src/samples/Samples/5_Domain_Specific/nbody/render_particles_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/render_particles_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody/render_particles_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/tipsy.h b/src/samples/Samples/5_Domain_Specific/nbody/tipsy.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody/tipsy_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody/tipsy_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/nbody_opengles/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/nbody_opengles/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/nbody_opengles/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/nbody_opengles/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/Makefile b/src/samples/Samples/5_Domain_Specific/nbody_opengles/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/nbody_opengles/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/README.md b/src/samples/Samples/5_Domain_Specific/nbody_opengles/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystem.h b/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystem.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystem_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystem_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcpu.h b/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcpu.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcpu_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcpu_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcpu_impl.h b/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcpu_impl.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcpu_impl_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcpu_impl_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda.cu b/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda.cu.hip b/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda.cu.hip
old mode 100644
new mode 100755
index 986ac9a..e69de29
--- a/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda.cu.hip
@@ -1,278 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "helper_cuda_hipified.h"
-#include <math.h>
-
-//#include <GL/glew.h>
-//#include <GL/freeglut.h>
-
-// CUDA standard includes
-#include <hip/hip_runtime.h>
-//#include <cuda_gl_interop.h>
-
-#include "bodysystem.h"
-
-__constant__ float softeningSquared;
-__constant__ double softeningSquared_fp64;
-
-hipError_t setSofteningSquared(float softeningSq) {
-  return hipMemcpyToSymbol(HIP_SYMBOL(softeningSquared), &softeningSq, sizeof(float), 0,
-                            hipMemcpyHostToDevice);
-}
-
-hipError_t setSofteningSquared(double softeningSq) {
-  return hipMemcpyToSymbol(HIP_SYMBOL(softeningSquared_fp64), &softeningSq, sizeof(double),
-                            0, hipMemcpyHostToDevice);
-}
-
-template <class T>
-struct SharedMemory {
-  __device__ inline operator T *() {
-    extern __shared__ int __smem[];
-    return (T *)__smem;
-  }
-
-  __device__ inline operator const T *() const {
-    extern __shared__ int __smem[];
-    return (T *)__smem;
-  }
-};
-
-template <typename T>
-__device__ T rsqrt_T(T x) {
-  return rsqrt(x);
-}
-
-template <>
-__device__ float rsqrt_T<float>(float x) {
-  return rsqrtf(x);
-}
-
-template <>
-__device__ double rsqrt_T<double>(double x) {
-  return rsqrt(x);
-}
-
-// Macros to simplify shared memory addressing
-#define SX(i) sharedPos[i + blockDim.x * threadIdx.y]
-// This macro is only used when multithreadBodies is true (below)
-#define SX_SUM(i, j) sharedPos[i + blockDim.x * j]
-
-template <typename T>
-__device__ T getSofteningSquared() {
-  return softeningSquared;
-}
-template <>
-__device__ double getSofteningSquared<double>() {
-  return softeningSquared_fp64;
-}
-
-template <typename T>
-struct DeviceData {
-  T *dPos[2];  // mapped host pointers
-  T *dVel;
-  hipEvent_t event;
-  unsigned int offset;
-  unsigned int numBodies;
-};
-
-template <typename T>
-__device__ typename vec3<T>::Type bodyBodyInteraction(
-    typename vec3<T>::Type ai, typename vec4<T>::Type bi,
-    typename vec4<T>::Type bj) {
-  typename vec3<T>::Type r;
-
-  // r_ij  [3 FLOPS]
-  r.x = bj.x - bi.x;
-  r.y = bj.y - bi.y;
-  r.z = bj.z - bi.z;
-
-  // distSqr = dot(r_ij, r_ij) + EPS^2  [6 FLOPS]
-  T distSqr = r.x * r.x + r.y * r.y + r.z * r.z;
-  distSqr += getSofteningSquared<T>();
-
-  // invDistCube =1/distSqr^(3/2)  [4 FLOPS (2 mul, 1 sqrt, 1 inv)]
-  T invDist = rsqrt_T(distSqr);
-  T invDistCube = invDist * invDist * invDist;
-
-  // s = m_j * invDistCube [1 FLOP]
-  T s = bj.w * invDistCube;
-
-  // a_i =  a_i + s * r_ij [6 FLOPS]
-  ai.x += r.x * s;
-  ai.y += r.y * s;
-  ai.z += r.z * s;
-
-  return ai;
-}
-
-template <typename T>
-__device__ typename vec3<T>::Type computeBodyAccel(
-    typename vec4<T>::Type bodyPos, typename vec4<T>::Type *positions,
-    int numTiles) {
-  typename vec4<T>::Type *sharedPos = SharedMemory<typename vec4<T>::Type>();
-
-  typename vec3<T>::Type acc = {0.0f, 0.0f, 0.0f};
-
-  for (int tile = 0; tile < numTiles; tile++) {
-    sharedPos[threadIdx.x] = positions[tile * blockDim.x + threadIdx.x];
-
-    __syncthreads();
-
-    // This is the "tile_calculation" from the GPUG3 article.
-#pragma unroll 128
-
-    for (unsigned int counter = 0; counter < blockDim.x; counter++) {
-      acc = bodyBodyInteraction<T>(acc, bodyPos, sharedPos[counter]);
-    }
-
-    __syncthreads();
-  }
-
-  return acc;
-}
-
-template <typename T>
-__global__ void integrateBodies(typename vec4<T>::Type *__restrict__ newPos,
-                                typename vec4<T>::Type *__restrict__ oldPos,
-                                typename vec4<T>::Type *vel,
-                                unsigned int deviceOffset,
-                                unsigned int deviceNumBodies, float deltaTime,
-                                float damping, int numTiles) {
-  int index = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (index >= deviceNumBodies) {
-    return;
-  }
-
-  typename vec4<T>::Type position = oldPos[deviceOffset + index];
-
-  typename vec3<T>::Type accel =
-      computeBodyAccel<T>(position, oldPos, numTiles);
-
-  // acceleration = force / mass;
-  // new velocity = old velocity + acceleration * deltaTime
-  // note we factor out the body's mass from the equation, here and in
-  // bodyBodyInteraction (because they cancel out).  Thus here force ==
-  // acceleration
-  typename vec4<T>::Type velocity = vel[deviceOffset + index];
-
-  velocity.x += accel.x * deltaTime;
-  velocity.y += accel.y * deltaTime;
-  velocity.z += accel.z * deltaTime;
-
-  velocity.x *= damping;
-  velocity.y *= damping;
-  velocity.z *= damping;
-
-  // new position = old position + velocity * deltaTime
-  position.x += velocity.x * deltaTime;
-  position.y += velocity.y * deltaTime;
-  position.z += velocity.z * deltaTime;
-
-  // store new position and velocity
-  newPos[deviceOffset + index] = position;
-  vel[deviceOffset + index] = velocity;
-}
-
-template <typename T>
-void integrateNbodySystem(DeviceData<T> *deviceData,
-                          hipGraphicsResource **pgres,
-                          unsigned int currentRead, float deltaTime,
-                          float damping, unsigned int numBodies,
-                          unsigned int numDevices, int blockSize,
-                          bool bUsePBO) {
-  if (bUsePBO) {
-    HIPCHECK(cudaGraphicsResourceSetMapFlags(
-        pgres[currentRead], cudaGraphicsMapFlagsReadOnly));
-    HIPCHECK(cudaGraphicsResourceSetMapFlags(
-        pgres[1 - currentRead], cudaGraphicsMapFlagsWriteDiscard));
-    HIPCHECK(hipGraphicsMapResources(2, pgres, 0));
-    size_t bytes;
-    HIPCHECK(hipGraphicsResourceGetMappedPointer(
-        (void **)&(deviceData[0].dPos[currentRead]), &bytes,
-        pgres[currentRead]));
-    HIPCHECK(hipGraphicsResourceGetMappedPointer(
-        (void **)&(deviceData[0].dPos[1 - currentRead]), &bytes,
-        pgres[1 - currentRead]));
-  }
-
-  for (unsigned int dev = 0; dev != numDevices; dev++) {
-    if (numDevices > 1) {
-      hipSetDevice(dev);
-    }
-
-    int numBlocks = (deviceData[dev].numBodies + blockSize - 1) / blockSize;
-    int numTiles = (numBodies + blockSize - 1) / blockSize;
-    int sharedMemSize = blockSize * 4 * sizeof(T);  // 4 floats for pos
-
-    integrateBodies<T><<<numBlocks, blockSize, sharedMemSize>>>(
-        (typename vec4<T>::Type *)deviceData[dev].dPos[1 - currentRead],
-        (typename vec4<T>::Type *)deviceData[dev].dPos[currentRead],
-        (typename vec4<T>::Type *)deviceData[dev].dVel, deviceData[dev].offset,
-        deviceData[dev].numBodies, deltaTime, damping, numTiles);
-
-    if (numDevices > 1) {
-      HIPCHECK(hipEventRecord(deviceData[dev].event));
-      // MJH: Hack on older driver versions to force kernel launches to flush!
-      hipStreamQuery(0);
-    }
-
-    // check if kernel invocation generated an error
-    getLastCudaError("Kernel execution failed");
-  }
-
-  if (numDevices > 1) {
-    for (unsigned int dev = 0; dev < numDevices; dev++) {
-      HIPCHECK(hipEventSynchronize(deviceData[dev].event));
-    }
-  }
-
-  if (bUsePBO) {
-    HIPCHECK(hipGraphicsUnmapResources(2, pgres, 0));
-  }
-}
-
-// Explicit specializations needed to generate code
-template void integrateNbodySystem<float>(DeviceData<float> *deviceData,
-                                          hipGraphicsResource **pgres,
-                                          unsigned int currentRead,
-                                          float deltaTime, float damping,
-                                          unsigned int numBodies,
-                                          unsigned int numDevices,
-                                          int blockSize, bool bUsePBO);
-
-template void integrateNbodySystem<double>(DeviceData<double> *deviceData,
-                                           hipGraphicsResource **pgres,
-                                           unsigned int currentRead,
-                                           float deltaTime, float damping,
-                                           unsigned int numBodies,
-                                           unsigned int numDevices,
-                                           int blockSize, bool bUsePBO);
-                          int blockSize, bool bUsePBO);
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda.h b/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda_impl.h b/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda_impl.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda_impl_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody_opengles/bodysystemcuda_impl_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/findgleslib.mk b/src/samples/Samples/5_Domain_Specific/nbody_opengles/findgleslib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/galaxy_20K.bin b/src/samples/Samples/5_Domain_Specific/nbody_opengles/galaxy_20K.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/nbody_opengles.cpp b/src/samples/Samples/5_Domain_Specific/nbody_opengles/nbody_opengles.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/nbody_opengles_hipified.cpp b/src/samples/Samples/5_Domain_Specific/nbody_opengles/nbody_opengles_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/render_particles.cpp b/src/samples/Samples/5_Domain_Specific/nbody_opengles/render_particles.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/render_particles.h b/src/samples/Samples/5_Domain_Specific/nbody_opengles/render_particles.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/render_particles_hipified.cpp b/src/samples/Samples/5_Domain_Specific/nbody_opengles/render_particles_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/render_particles_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody_opengles/render_particles_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/tipsy.h b/src/samples/Samples/5_Domain_Specific/nbody_opengles/tipsy.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_opengles/tipsy_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody_opengles/tipsy_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/nbody_screen/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/nbody_screen/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/nbody_screen/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/nbody_screen/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/Makefile b/src/samples/Samples/5_Domain_Specific/nbody_screen/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/nbody_screen/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/README.md b/src/samples/Samples/5_Domain_Specific/nbody_screen/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystem.h b/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystem.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystem_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystem_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcpu.h b/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcpu.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcpu_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcpu_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcpu_impl.h b/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcpu_impl.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcpu_impl_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcpu_impl_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda.cu b/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda.cu.hip b/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda.cu.hip
old mode 100644
new mode 100755
index 986ac9a..e69de29
--- a/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda.cu.hip
@@ -1,278 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "helper_cuda_hipified.h"
-#include <math.h>
-
-//#include <GL/glew.h>
-//#include <GL/freeglut.h>
-
-// CUDA standard includes
-#include <hip/hip_runtime.h>
-//#include <cuda_gl_interop.h>
-
-#include "bodysystem.h"
-
-__constant__ float softeningSquared;
-__constant__ double softeningSquared_fp64;
-
-hipError_t setSofteningSquared(float softeningSq) {
-  return hipMemcpyToSymbol(HIP_SYMBOL(softeningSquared), &softeningSq, sizeof(float), 0,
-                            hipMemcpyHostToDevice);
-}
-
-hipError_t setSofteningSquared(double softeningSq) {
-  return hipMemcpyToSymbol(HIP_SYMBOL(softeningSquared_fp64), &softeningSq, sizeof(double),
-                            0, hipMemcpyHostToDevice);
-}
-
-template <class T>
-struct SharedMemory {
-  __device__ inline operator T *() {
-    extern __shared__ int __smem[];
-    return (T *)__smem;
-  }
-
-  __device__ inline operator const T *() const {
-    extern __shared__ int __smem[];
-    return (T *)__smem;
-  }
-};
-
-template <typename T>
-__device__ T rsqrt_T(T x) {
-  return rsqrt(x);
-}
-
-template <>
-__device__ float rsqrt_T<float>(float x) {
-  return rsqrtf(x);
-}
-
-template <>
-__device__ double rsqrt_T<double>(double x) {
-  return rsqrt(x);
-}
-
-// Macros to simplify shared memory addressing
-#define SX(i) sharedPos[i + blockDim.x * threadIdx.y]
-// This macro is only used when multithreadBodies is true (below)
-#define SX_SUM(i, j) sharedPos[i + blockDim.x * j]
-
-template <typename T>
-__device__ T getSofteningSquared() {
-  return softeningSquared;
-}
-template <>
-__device__ double getSofteningSquared<double>() {
-  return softeningSquared_fp64;
-}
-
-template <typename T>
-struct DeviceData {
-  T *dPos[2];  // mapped host pointers
-  T *dVel;
-  hipEvent_t event;
-  unsigned int offset;
-  unsigned int numBodies;
-};
-
-template <typename T>
-__device__ typename vec3<T>::Type bodyBodyInteraction(
-    typename vec3<T>::Type ai, typename vec4<T>::Type bi,
-    typename vec4<T>::Type bj) {
-  typename vec3<T>::Type r;
-
-  // r_ij  [3 FLOPS]
-  r.x = bj.x - bi.x;
-  r.y = bj.y - bi.y;
-  r.z = bj.z - bi.z;
-
-  // distSqr = dot(r_ij, r_ij) + EPS^2  [6 FLOPS]
-  T distSqr = r.x * r.x + r.y * r.y + r.z * r.z;
-  distSqr += getSofteningSquared<T>();
-
-  // invDistCube =1/distSqr^(3/2)  [4 FLOPS (2 mul, 1 sqrt, 1 inv)]
-  T invDist = rsqrt_T(distSqr);
-  T invDistCube = invDist * invDist * invDist;
-
-  // s = m_j * invDistCube [1 FLOP]
-  T s = bj.w * invDistCube;
-
-  // a_i =  a_i + s * r_ij [6 FLOPS]
-  ai.x += r.x * s;
-  ai.y += r.y * s;
-  ai.z += r.z * s;
-
-  return ai;
-}
-
-template <typename T>
-__device__ typename vec3<T>::Type computeBodyAccel(
-    typename vec4<T>::Type bodyPos, typename vec4<T>::Type *positions,
-    int numTiles) {
-  typename vec4<T>::Type *sharedPos = SharedMemory<typename vec4<T>::Type>();
-
-  typename vec3<T>::Type acc = {0.0f, 0.0f, 0.0f};
-
-  for (int tile = 0; tile < numTiles; tile++) {
-    sharedPos[threadIdx.x] = positions[tile * blockDim.x + threadIdx.x];
-
-    __syncthreads();
-
-    // This is the "tile_calculation" from the GPUG3 article.
-#pragma unroll 128
-
-    for (unsigned int counter = 0; counter < blockDim.x; counter++) {
-      acc = bodyBodyInteraction<T>(acc, bodyPos, sharedPos[counter]);
-    }
-
-    __syncthreads();
-  }
-
-  return acc;
-}
-
-template <typename T>
-__global__ void integrateBodies(typename vec4<T>::Type *__restrict__ newPos,
-                                typename vec4<T>::Type *__restrict__ oldPos,
-                                typename vec4<T>::Type *vel,
-                                unsigned int deviceOffset,
-                                unsigned int deviceNumBodies, float deltaTime,
-                                float damping, int numTiles) {
-  int index = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (index >= deviceNumBodies) {
-    return;
-  }
-
-  typename vec4<T>::Type position = oldPos[deviceOffset + index];
-
-  typename vec3<T>::Type accel =
-      computeBodyAccel<T>(position, oldPos, numTiles);
-
-  // acceleration = force / mass;
-  // new velocity = old velocity + acceleration * deltaTime
-  // note we factor out the body's mass from the equation, here and in
-  // bodyBodyInteraction (because they cancel out).  Thus here force ==
-  // acceleration
-  typename vec4<T>::Type velocity = vel[deviceOffset + index];
-
-  velocity.x += accel.x * deltaTime;
-  velocity.y += accel.y * deltaTime;
-  velocity.z += accel.z * deltaTime;
-
-  velocity.x *= damping;
-  velocity.y *= damping;
-  velocity.z *= damping;
-
-  // new position = old position + velocity * deltaTime
-  position.x += velocity.x * deltaTime;
-  position.y += velocity.y * deltaTime;
-  position.z += velocity.z * deltaTime;
-
-  // store new position and velocity
-  newPos[deviceOffset + index] = position;
-  vel[deviceOffset + index] = velocity;
-}
-
-template <typename T>
-void integrateNbodySystem(DeviceData<T> *deviceData,
-                          hipGraphicsResource **pgres,
-                          unsigned int currentRead, float deltaTime,
-                          float damping, unsigned int numBodies,
-                          unsigned int numDevices, int blockSize,
-                          bool bUsePBO) {
-  if (bUsePBO) {
-    HIPCHECK(cudaGraphicsResourceSetMapFlags(
-        pgres[currentRead], cudaGraphicsMapFlagsReadOnly));
-    HIPCHECK(cudaGraphicsResourceSetMapFlags(
-        pgres[1 - currentRead], cudaGraphicsMapFlagsWriteDiscard));
-    HIPCHECK(hipGraphicsMapResources(2, pgres, 0));
-    size_t bytes;
-    HIPCHECK(hipGraphicsResourceGetMappedPointer(
-        (void **)&(deviceData[0].dPos[currentRead]), &bytes,
-        pgres[currentRead]));
-    HIPCHECK(hipGraphicsResourceGetMappedPointer(
-        (void **)&(deviceData[0].dPos[1 - currentRead]), &bytes,
-        pgres[1 - currentRead]));
-  }
-
-  for (unsigned int dev = 0; dev != numDevices; dev++) {
-    if (numDevices > 1) {
-      hipSetDevice(dev);
-    }
-
-    int numBlocks = (deviceData[dev].numBodies + blockSize - 1) / blockSize;
-    int numTiles = (numBodies + blockSize - 1) / blockSize;
-    int sharedMemSize = blockSize * 4 * sizeof(T);  // 4 floats for pos
-
-    integrateBodies<T><<<numBlocks, blockSize, sharedMemSize>>>(
-        (typename vec4<T>::Type *)deviceData[dev].dPos[1 - currentRead],
-        (typename vec4<T>::Type *)deviceData[dev].dPos[currentRead],
-        (typename vec4<T>::Type *)deviceData[dev].dVel, deviceData[dev].offset,
-        deviceData[dev].numBodies, deltaTime, damping, numTiles);
-
-    if (numDevices > 1) {
-      HIPCHECK(hipEventRecord(deviceData[dev].event));
-      // MJH: Hack on older driver versions to force kernel launches to flush!
-      hipStreamQuery(0);
-    }
-
-    // check if kernel invocation generated an error
-    getLastCudaError("Kernel execution failed");
-  }
-
-  if (numDevices > 1) {
-    for (unsigned int dev = 0; dev < numDevices; dev++) {
-      HIPCHECK(hipEventSynchronize(deviceData[dev].event));
-    }
-  }
-
-  if (bUsePBO) {
-    HIPCHECK(hipGraphicsUnmapResources(2, pgres, 0));
-  }
-}
-
-// Explicit specializations needed to generate code
-template void integrateNbodySystem<float>(DeviceData<float> *deviceData,
-                                          hipGraphicsResource **pgres,
-                                          unsigned int currentRead,
-                                          float deltaTime, float damping,
-                                          unsigned int numBodies,
-                                          unsigned int numDevices,
-                                          int blockSize, bool bUsePBO);
-
-template void integrateNbodySystem<double>(DeviceData<double> *deviceData,
-                                           hipGraphicsResource **pgres,
-                                           unsigned int currentRead,
-                                           float deltaTime, float damping,
-                                           unsigned int numBodies,
-                                           unsigned int numDevices,
-                                           int blockSize, bool bUsePBO);
-                          int blockSize, bool bUsePBO);
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda.h b/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda_impl.h b/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda_impl.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda_impl_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody_screen/bodysystemcuda_impl_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/findgleslib.mk b/src/samples/Samples/5_Domain_Specific/nbody_screen/findgleslib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/galaxy_20K.bin b/src/samples/Samples/5_Domain_Specific/nbody_screen/galaxy_20K.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/nbody_screen.cpp b/src/samples/Samples/5_Domain_Specific/nbody_screen/nbody_screen.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/nbody_screen_hipified.cpp b/src/samples/Samples/5_Domain_Specific/nbody_screen/nbody_screen_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/render_particles.cpp b/src/samples/Samples/5_Domain_Specific/nbody_screen/render_particles.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/render_particles.h b/src/samples/Samples/5_Domain_Specific/nbody_screen/render_particles.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/render_particles_hipified.cpp b/src/samples/Samples/5_Domain_Specific/nbody_screen/render_particles_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/render_particles_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody_screen/render_particles_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/tipsy.h b/src/samples/Samples/5_Domain_Specific/nbody_screen/tipsy.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/nbody_screen/tipsy_hipified.h b/src/samples/Samples/5_Domain_Specific/nbody_screen/tipsy_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/Makefile b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/README.md b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.cu b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.cu.hip b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.cu.hip
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.out b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2017.sln b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2019.sln b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2022.sln b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/p2pBandwidthLatencyTest_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/postProcessGL/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/postProcessGL/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/postProcessGL/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/postProcessGL/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/Makefile b/src/samples/Samples/5_Domain_Specific/postProcessGL/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/postProcessGL/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/README.md b/src/samples/Samples/5_Domain_Specific/postProcessGL/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/data/teapot_2.ppm b/src/samples/Samples/5_Domain_Specific/postProcessGL/data/teapot_2.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/data/teapot_4.ppm b/src/samples/Samples/5_Domain_Specific/postProcessGL/data/teapot_4.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/data/teapot_8.ppm b/src/samples/Samples/5_Domain_Specific/postProcessGL/data/teapot_8.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/data/teapot_orig.ppm b/src/samples/Samples/5_Domain_Specific/postProcessGL/data/teapot_orig.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/doc/postProcessGL_lg.gif b/src/samples/Samples/5_Domain_Specific/postProcessGL/doc/postProcessGL_lg.gif
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/doc/postProcessGL_md.gif b/src/samples/Samples/5_Domain_Specific/postProcessGL/doc/postProcessGL_md.gif
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/doc/postProcessGL_sm.gif b/src/samples/Samples/5_Domain_Specific/postProcessGL/doc/postProcessGL_sm.gif
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/findgllib.mk b/src/samples/Samples/5_Domain_Specific/postProcessGL/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/main.cpp b/src/samples/Samples/5_Domain_Specific/postProcessGL/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/main_hipified.cpp b/src/samples/Samples/5_Domain_Specific/postProcessGL/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL.cu b/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL.cu.hip b/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL.cu.hip
old mode 100644
new mode 100755
index f08354a..e69de29
--- a/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL.cu.hip
@@ -1,257 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// Utilities and system includes
-
-#include <hip/hip_cooperative_groups.h>
-
-namespace cg = cooperative_groups;
-
-#include "helper_cuda_hipified.h"
-
-hipTextureObject_t inTexObject;
-
-// clamp x to range [a, b]
-__device__ float clamp(float x, float a, float b) { return max(a, min(b, x)); }
-
-__device__ int clamp(int x, int a, int b) { return max(a, min(b, x)); }
-
-// convert floating point rgb color to 8-bit integer
-__device__ int rgbToInt(float r, float g, float b) {
-  r = clamp(r, 0.0f, 255.0f);
-  g = clamp(g, 0.0f, 255.0f);
-  b = clamp(b, 0.0f, 255.0f);
-  return (int(b) << 16) | (int(g) << 8) | int(r);
-}
-
-// get pixel from 2D image, with clamping to border
-__device__ uchar4 getPixel(int x, int y, hipTextureObject_t inTex) {
-#ifndef USE_TEXTURE_RGBA8UI
-  float4 res = tex2D<float4>(inTex, x, y);
-  uchar4 ucres = make_uchar4(res.x * 255.0f, res.y * 255.0f, res.z * 255.0f,
-                             res.w * 255.0f);
-#else
-  uchar4 ucres = tex2D<uchar4>(inTex, x, y);
-#endif
-  return ucres;
-}
-
-// macros to make indexing shared memory easier
-#define SMEM(X, Y) sdata[(Y)*tilew + (X)]
-
-/*
-    2D convolution using shared memory
-    - operates on 8-bit RGB data stored in 32-bit int
-    - assumes kernel radius is less than or equal to block size
-    - not optimized for performance
-     _____________
-    |   :     :   |
-    |_ _:_____:_ _|
-    |   |     |   |
-    |   |     |   |
-    |_ _|_____|_ _|
-  r |   :     :   |
-    |___:_____:___|
-      r    bw   r
-    <----tilew---->
-*/
-
-__global__ void cudaProcess(unsigned int *g_odata, int imgw, int imgh,
-                            int tilew, int r, float threshold, float highlight,
-                            hipTextureObject_t inTex) {
-  // Handle to thread block group
-  cg::thread_block cta = cg::this_thread_block();
-  extern __shared__ uchar4 sdata[];
-
-  int tx = threadIdx.x;
-  int ty = threadIdx.y;
-  int bw = blockDim.x;
-  int bh = blockDim.y;
-  int x = blockIdx.x * bw + tx;
-  int y = blockIdx.y * bh + ty;
-
-#if 0
-    uchar4 c4 = getPixel(x, y);
-    g_odata[y*imgw+x] = rgbToInt(c4.z, c4.y, c4.x);
-#else
-  // copy tile to shared memory
-  // center region
-  SMEM(r + tx, r + ty) = getPixel(x, y, inTex);
-
-  // borders
-  if (threadIdx.x < r) {
-    // left
-    SMEM(tx, r + ty) = getPixel(x - r, y, inTex);
-    // right
-    SMEM(r + bw + tx, r + ty) = getPixel(x + bw, y, inTex);
-  }
-
-  if (threadIdx.y < r) {
-    // top
-    SMEM(r + tx, ty) = getPixel(x, y - r, inTex);
-    // bottom
-    SMEM(r + tx, r + bh + ty) = getPixel(x, y + bh, inTex);
-  }
-
-  // load corners
-  if ((threadIdx.x < r) && (threadIdx.y < r)) {
-    // tl
-    SMEM(tx, ty) = getPixel(x - r, y - r, inTex);
-    // bl
-    SMEM(tx, r + bh + ty) = getPixel(x - r, y + bh, inTex);
-    // tr
-    SMEM(r + bw + tx, ty) = getPixel(x + bh, y - r, inTex);
-    // br
-    SMEM(r + bw + tx, r + bh + ty) = getPixel(x + bw, y + bh, inTex);
-  }
-
-  // wait for loads to complete
-  cg::sync(cta);
-
-  // perform convolution
-  float rsum = 0.0f;
-  float gsum = 0.0f;
-  float bsum = 0.0f;
-  float samples = 0.0f;
-
-  for (int dy = -r; dy <= r; dy++) {
-    for (int dx = -r; dx <= r; dx++) {
-#if 0
-            // try this to see the benefit of using shared memory
-            uchar4 pixel = getPixel(x+dx, y+dy);
-#else
-      uchar4 pixel = SMEM(r + tx + dx, r + ty + dy);
-#endif
-
-      // only sum pixels within disc-shaped kernel
-      float l = dx * dx + dy * dy;
-
-      if (l <= r * r) {
-        float r = float(pixel.x);
-        float g = float(pixel.y);
-        float b = float(pixel.z);
-#if 1
-        // brighten highlights
-        float lum = (r + g + b) / (255 * 3);
-
-        if (lum > threshold) {
-          r *= highlight;
-          g *= highlight;
-          b *= highlight;
-        }
-
-#endif
-        rsum += r;
-        gsum += g;
-        bsum += b;
-        samples += 1.0f;
-      }
-    }
-  }
-
-  rsum /= samples;
-  gsum /= samples;
-  bsum /= samples;
-  // ABGR
-  g_odata[y * imgw + x] = rgbToInt(rsum, gsum, bsum);
-// g_odata[y*imgw+x] = rgbToInt(x,y,0);
-#endif
-}
-
-extern "C" void launch_cudaProcess(dim3 grid, dim3 block, int sbytes,
-                                   hipArray *g_data_array,
-                                   unsigned int *g_odata, int imgw, int imgh,
-                                   int tilew, int radius, float threshold,
-                                   float highlight) {
-  struct hipChannelFormatDesc desc;
-  HIPCHECK(hipGetChannelDesc(&desc, g_data_array));
-
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = g_data_array;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModePoint;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(
-      hipCreateTextureObject(&inTexObject, &texRes, &texDescr, NULL));
-
-#if 0
-    printf("CUDA Array channel descriptor, bits per component:\n");
-    printf("X %d Y %d Z %d W %d, kind %d\n",
-           desc.x,desc.y,desc.z,desc.w,desc.f);
-
-    printf("Possible values for channel format kind: i %d, u%d, f%d:\n",
-           hipChannelFormatKindSigned, hipChannelFormatKindUnsigned,
-           hipChannelFormatKindFloat);
-#endif
-
-// printf("\n");
-#ifdef GPU_PROFILING
-  StopWatchInterface *timer = 0;
-  sdkCreateTimer(&timer);
-
-  int nIter = 30;
-
-  for (int i = -1; i < nIter; ++i) {
-    if (i == 0) {
-      sdkStartTimer(&timer);
-    }
-
-#endif
-
-    cudaProcess<<<grid, block, sbytes>>>(g_odata, imgw, imgh,
-                                         block.x + (2 * radius), radius, 0.8f,
-                                         4.0f, inTexObject);
-
-#ifdef GPU_PROFILING
-  }
-
-  hipDeviceSynchronize();
-  sdkStopTimer(&timer);
-  double dSeconds = sdkGetTimerValue(&timer) / ((double)nIter * 1000.0);
-  double dNumTexels = (double)imgw * (double)imgh;
-  double mtexps = 1.0e-6 * dNumTexels / dSeconds;
-
-  if (radius == 4) {
-    printf("\n");
-    printf(
-        "postprocessGL, Throughput = %.4f MTexels/s, Time = %.5f s, Size = "
-        "%.0f Texels, NumDevsUsed = %d, Workgroup = %u\n",
-        mtexps, dSeconds, dNumTexels, 1, block.x * block.y);
-  }
-
-#endif
-}
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2017.sln b/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2019.sln b/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2022.sln b/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/postProcessGL/postProcessGL_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/Makefile b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/README.md b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator.cpp b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator.out b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_common.h b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_common_hipified.h b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_gold.cpp b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_gold_hipified.cpp b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_hipified.cpp b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_kernel.cu b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_kernel.cu.hip
old mode 100644
new mode 100755
index dde1cb8..e69de29
--- a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_kernel.cu.hip
@@ -1,180 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef QUASIRANDOMGENERATOR_KERNEL_CUH
-#define QUASIRANDOMGENERATOR_KERNEL_CUH
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include "helper_cuda_hipified.h"
-#include "quasirandomGenerator_common.h"
-
-// Fast integer multiplication
-#define MUL(a, b) __umul24(a, b)
-
-////////////////////////////////////////////////////////////////////////////////
-// Niederreiter quasirandom number generation kernel
-////////////////////////////////////////////////////////////////////////////////
-static __constant__ unsigned int c_Table[QRNG_DIMENSIONS][QRNG_RESOLUTION];
-
-static __global__ void quasirandomGeneratorKernel(float *d_Output,
-                                                  unsigned int seed,
-                                                  unsigned int N) {
-  unsigned int *dimBase = &c_Table[threadIdx.y][0];
-  unsigned int tid = MUL(blockDim.x, blockIdx.x) + threadIdx.x;
-  unsigned int threadN = MUL(blockDim.x, gridDim.x);
-
-  for (unsigned int pos = tid; pos < N; pos += threadN) {
-    unsigned int result = 0;
-    unsigned int data = seed + pos;
-
-    for (int bit = 0; bit < QRNG_RESOLUTION; bit++, data >>= 1)
-      if (data & 1) {
-        result ^= dimBase[bit];
-      }
-
-    d_Output[MUL(threadIdx.y, N) + pos] = (float)(result + 1) * INT_SCALE;
-  }
-}
-
-// Table initialization routine
-extern "C" void initTableGPU(
-    unsigned int tableCPU[QRNG_DIMENSIONS][QRNG_RESOLUTION]) {
-  HIPCHECK(hipMemcpyToSymbol(HIP_SYMBOL(
-      c_Table), tableCPU,
-      QRNG_DIMENSIONS * QRNG_RESOLUTION * sizeof(unsigned int)));
-}
-
-// Host-side interface
-extern "C" void quasirandomGeneratorGPU(float *d_Output, unsigned int seed,
-                                        unsigned int N) {
-  dim3 threads(128, QRNG_DIMENSIONS);
-  quasirandomGeneratorKernel<<<128, threads>>>(d_Output, seed, N);
-  getLastCudaError("quasirandomGeneratorKernel() execution failed.\n");
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Moro's Inverse Cumulative Normal Distribution function approximation
-////////////////////////////////////////////////////////////////////////////////
-__device__ inline float MoroInvCNDgpu(unsigned int x) {
-  const float a1 = 2.50662823884f;
-  const float a2 = -18.61500062529f;
-  const float a3 = 41.39119773534f;
-  const float a4 = -25.44106049637f;
-  const float b1 = -8.4735109309f;
-  const float b2 = 23.08336743743f;
-  const float b3 = -21.06224101826f;
-  const float b4 = 3.13082909833f;
-  const float c1 = 0.337475482272615f;
-  const float c2 = 0.976169019091719f;
-  const float c3 = 0.160797971491821f;
-  const float c4 = 2.76438810333863E-02f;
-  const float c5 = 3.8405729373609E-03f;
-  const float c6 = 3.951896511919E-04f;
-  const float c7 = 3.21767881768E-05f;
-  const float c8 = 2.888167364E-07f;
-  const float c9 = 3.960315187E-07f;
-
-  float z;
-
-  bool negate = false;
-
-  // Ensure the conversion to floating point will give a value in the
-  // range (0,0.5] by restricting the input to the bottom half of the
-  // input domain. We will later reflect the result if the input was
-  // originally in the top half of the input domain
-  if (x >= 0x80000000UL) {
-    x = 0xffffffffUL - x;
-    negate = true;
-  }
-
-  // x is now in the range [0,0x80000000) (i.e. [0,0x7fffffff])
-  // Convert to floating point in (0,0.5]
-  const float x1 = 1.0f / static_cast<float>(0xffffffffUL);
-  const float x2 = x1 / 2.0f;
-  float p1 = x * x1 + x2;
-  // Convert to floating point in (-0.5,0]
-  float p2 = p1 - 0.5f;
-
-  // The input to the Moro inversion is p2 which is in the range
-  // (-0.5,0]. This means that our output will be the negative side
-  // of the bell curve (which we will reflect if "negate" is true).
-
-  // Main body of the bell curve for |p| < 0.42
-  if (p2 > -0.42f) {
-    z = p2 * p2;
-    z = p2 * (((a4 * z + a3) * z + a2) * z + a1) /
-        ((((b4 * z + b3) * z + b2) * z + b1) * z + 1.0f);
-  }
-  // Special case (Chebychev) for tail
-  else {
-    z = __logf(-__logf(p1));
-    z = -(c1 + z * (c2 + z * (c3 + z * (c4 + z * (c5 + z * (c6 + z * (c7 + z 
-        * (c8 + z * c9))))))));
-  }
-
-  // If the original input (x) was in the top half of the range, reflect
-  // to get the positive side of the bell curve
-  return negate ? -z : z;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Main kernel. Choose between transforming
-// input sequence and uniform ascending (0, 1) sequence
-////////////////////////////////////////////////////////////////////////////////
-static __global__ void inverseCNDKernel(float *d_Output, unsigned int *d_Input,
-                                        unsigned int pathN) {
-  unsigned int distance = ((unsigned int)-1) / (pathN + 1);
-  unsigned int tid = MUL(blockDim.x, blockIdx.x) + threadIdx.x;
-  unsigned int threadN = MUL(blockDim.x, gridDim.x);
-
-  // Transform input number sequence if it's supplied
-  if (d_Input) {
-    for (unsigned int pos = tid; pos < pathN; pos += threadN) {
-      unsigned int d = d_Input[pos];
-      d_Output[pos] = (float)MoroInvCNDgpu(d);
-    }
-  }
-  // Else generate input uniformly placed samples on the fly
-  // and write to destination
-  else {
-    for (unsigned int pos = tid; pos < pathN; pos += threadN) {
-      unsigned int d = (pos + 1) * distance;
-      d_Output[pos] = (float)MoroInvCNDgpu(d);
-    }
-  }
-}
-
-extern "C" void inverseCNDgpu(float *d_Output, unsigned int *d_Input,
-                              unsigned int N) {
-  inverseCNDKernel<<<128, 128>>>(d_Output, d_Input, N);
-  getLastCudaError("inverseCNDKernel() execution failed.\n");
-}
-#endif
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2017.sln b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2019.sln b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2022.sln b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator/quasirandomGenerator_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/Makefile b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/README.md b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator.cpp b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_common.h b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_common.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_common_hipified.h b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_common_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_gold.cpp b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_gold.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_gold_hipified.cpp b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_gold_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_gpu.cuh b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_gpu.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_gpu_hipified.cuh b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_gpu_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_hipified.cpp b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_kernel.cu b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_kernel.cu.hip
old mode 100644
new mode 100755
index 1e51076..e69de29
--- a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_kernel.cu.hip
@@ -1,160 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef QUASIRANDOMGENERATOR_KERNEL_CUH
-#define QUASIRANDOMGENERATOR_KERNEL_CUH
-
-#include "quasirandomGenerator_common.h"
-
-// Fast integer multiplication
-#define MUL(a, b) __umul24(a, b)
-
-////////////////////////////////////////////////////////////////////////////////
-// Niederreiter quasirandom number generation kernel
-////////////////////////////////////////////////////////////////////////////////
-__constant__ unsigned int c_Table[QRNG_DIMENSIONS][QRNG_RESOLUTION];
-
-extern "C" __global__ void quasirandomGeneratorKernel(float *d_Output,
-                                                      unsigned int seed,
-                                                      unsigned int N) {
-  unsigned int *dimBase = &c_Table[threadIdx.y][0];
-  unsigned int tid = MUL(blockDim.x, blockIdx.x) + threadIdx.x;
-  unsigned int threadN = MUL(blockDim.x, gridDim.x);
-
-  for (unsigned int pos = tid; pos < N; pos += threadN) {
-    unsigned int result = 0;
-    unsigned int data = seed + pos;
-
-    for (int bit = 0; bit < QRNG_RESOLUTION; bit++, data >>= 1)
-      if (data & 1) {
-        result ^= dimBase[bit];
-      }
-
-    d_Output[MUL(threadIdx.y, N) + pos] = (float)(result + 1) * INT_SCALE;
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Moro's Inverse Cumulative Normal Distribution function approximation
-////////////////////////////////////////////////////////////////////////////////
-__device__ inline float MoroInvCNDgpu(unsigned int x) {
-  const float a1 = 2.50662823884f;
-  const float a2 = -18.61500062529f;
-  const float a3 = 41.39119773534f;
-  const float a4 = -25.44106049637f;
-  const float b1 = -8.4735109309f;
-  const float b2 = 23.08336743743f;
-  const float b3 = -21.06224101826f;
-  const float b4 = 3.13082909833f;
-  const float c1 = 0.337475482272615f;
-  const float c2 = 0.976169019091719f;
-  const float c3 = 0.160797971491821f;
-  const float c4 = 2.76438810333863E-02f;
-  const float c5 = 3.8405729373609E-03f;
-  const float c6 = 3.951896511919E-04f;
-  const float c7 = 3.21767881768E-05f;
-  const float c8 = 2.888167364E-07f;
-  const float c9 = 3.960315187E-07f;
-
-  float z;
-
-  bool negate = false;
-
-  // Ensure the conversion to floating point will give a value in the
-  // range (0,0.5] by restricting the input to the bottom half of the
-  // input domain. We will later reflect the result if the input was
-  // originally in the top half of the input domain
-  if (x >= 0x80000000UL) {
-    x = 0xffffffffUL - x;
-    negate = true;
-  }
-
-  // x is now in the range [0,0x80000000) (i.e. [0,0x7fffffff])
-  // Convert to floating point in (0,0.5]
-  const float x1 = 1.0f / static_cast<float>(0xffffffffUL);
-  const float x2 = x1 / 2.0f;
-  float p1 = x * x1 + x2;
-  // Convert to floating point in (-0.5,0]
-  float p2 = p1 - 0.5f;
-
-  // The input to the Moro inversion is p2 which is in the range
-  // (-0.5,0]. This means that our output will be the negative side
-  // of the bell curve (which we will reflect if "negate" is true).
-
-  // Main body of the bell curve for |p| < 0.42
-  if (p2 > -0.42f) {
-    z = p2 * p2;
-    z = p2 * (((a4 * z + a3) * z + a2) * z + a1) /
-        ((((b4 * z + b3) * z + b2) * z + b1) * z + 1.0f);
-  }
-  // Special case (Chebychev) for tail
-  else {
-    z = __logf(-__logf(p1));
-    z = -(c1 + z * (c2 + z * (c3 + z * (c4 + z * (c5 + z * (c6 + z * 
-        (c7 + z * (c8 + z * c9))))))));
-  }
-
-  // If the original input (x) was in the top half of the range, reflect
-  // to get the positive side of the bell curve
-
-  return negate ? -z : z;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Main kernel. Choose between transforming
-// input sequence and uniform ascending (0, 1) sequence
-////////////////////////////////////////////////////////////////////////////////
-
-extern "C" __global__ void inverseCNDKernel(float *d_Output,
-                                            unsigned int pathN) {
-  unsigned int distance = ((unsigned int)-1) / (pathN + 1);
-  unsigned int tid = MUL(blockDim.x, blockIdx.x) + threadIdx.x;
-  unsigned int threadN = MUL(blockDim.x, gridDim.x);
-
-  // Transform input number sequence if it's supplied
-  if (0)  // d_Input)
-  {
-    /*
-      for (unsigned int pos = tid; pos < pathN; pos += threadN)
-      {
-          unsigned int d = d_Input[pos];
-          d_Output[pos] = (float)MoroInvCNDgpu(d);
-      }
-      */
-  }
-  // Else generate input uniformly placed samples on the fly
-  // and write to destination
-  else {
-    for (unsigned int pos = tid; pos < pathN; pos += threadN) {
-      unsigned int d = (pos + 1) * distance;
-      d_Output[pos] = (float)MoroInvCNDgpu(d);
-    }
-  }
-}
-
-#endif
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2017.sln b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2019.sln b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2022.sln b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/quasirandomGenerator_nvrtc/quasirandomGenerator_nvrtc_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/Makefile b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/README.md b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/data/ref_10.ppm b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/data/ref_10.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/data/ref_14.ppm b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/data/ref_14.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/data/ref_18.ppm b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/data/ref_18.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/data/ref_22.ppm b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/data/ref_22.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/data/teapot512.ppm b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/data/teapot512.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/findgllib.mk b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian.cpp b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_cuda.cu b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_cuda.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_cuda.cu.hip b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_cuda.cu.hip
old mode 100644
new mode 100755
index 4d9f443..e69de29
--- a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_cuda.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_cuda.cu.hip
@@ -1,162 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
-  Recursive Gaussian filter
-  sgreen 8/1/08
-
-  This code sample implements a Gaussian blur using Deriche's recursive method:
-  http://citeseer.ist.psu.edu/deriche93recursively.html
-
-  This is similar to the box filter sample in the SDK, but it uses the previous
-  outputs of the filter as well as the previous inputs. This is also known as an
-  IIR (infinite impulse response) filter, since its response to an input impulse
-  can last forever.
-
-  The main advantage of this method is that the execution time is independent of
-  the filter width.
-
-  The GPU processes columns of the image in parallel. To avoid uncoalesced reads
-  for the row pass we transpose the image and then transpose it back again
-  afterwards.
-
-  The implementation is based on code from the CImg library:
-  http://cimg.sourceforge.net/
-  Thanks to David Tschumperl and all the CImg contributors!
-*/
-
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-
-#include <hip/hip_runtime.h>
-#include "helper_cuda_hipified.h"
-#include <helper_math.h>
-
-#include "recursiveGaussian_kernel.cuh"
-
-#define USE_SIMPLE_FILTER 0
-
-// Round a / b to nearest higher integer value
-int iDivUp(int a, int b) { return (a % b != 0) ? (a / b + 1) : (a / b); }
-
-/*
-  Transpose a 2D array (see SDK transpose example)
-*/
-extern "C" void transpose(uint *d_src, uint *d_dest, uint width, int height) {
-  dim3 grid(iDivUp(width, BLOCK_DIM), iDivUp(height, BLOCK_DIM), 1);
-  dim3 threads(BLOCK_DIM, BLOCK_DIM, 1);
-  d_transpose<<<grid, threads>>>(d_dest, d_src, width, height);
-  getLastCudaError("Kernel execution failed");
-}
-
-/*
-  Perform Gaussian filter on a 2D image using CUDA
-
-  Parameters:
-  d_src  - pointer to input image in device memory
-  d_dest - pointer to destination image in device memory
-  d_temp - pointer to temporary storage in device memory
-  width  - image width
-  height - image height
-  sigma  - sigma of Gaussian
-  order  - filter order (0, 1 or 2)
-*/
-
-// 8-bit RGBA version
-extern "C" void gaussianFilterRGBA(uint *d_src, uint *d_dest, uint *d_temp,
-                                   int width, int height, float sigma,
-                                   int order, int nthreads) {
-  // compute filter coefficients
-  const float nsigma = sigma < 0.1f ? 0.1f : sigma, alpha = 1.695f / nsigma,
-              ema = (float)std::exp(-alpha), ema2 = (float)std::exp(-2 * alpha),
-              b1 = -2 * ema, b2 = ema2;
-
-  float a0 = 0, a1 = 0, a2 = 0, a3 = 0, coefp = 0, coefn = 0;
-
-  switch (order) {
-    case 0: {
-      const float k = (1 - ema) * (1 - ema) / (1 + 2 * alpha * ema - ema2);
-      a0 = k;
-      a1 = k * (alpha - 1) * ema;
-      a2 = k * (alpha + 1) * ema;
-      a3 = -k * ema2;
-    } break;
-
-    case 1: {
-      const float k = (1 - ema) * (1 - ema) / ema;
-      a0 = k * ema;
-      a1 = a3 = 0;
-      a2 = -a0;
-    } break;
-
-    case 2: {
-      const float ea = (float)std::exp(-alpha),
-                  k = -(ema2 - 1) / (2 * alpha * ema),
-                  kn = (-2 * (-1 + 3 * ea - 3 * ea * ea + ea * ea * ea) /
-                        (3 * ea + 1 + 3 * ea * ea + ea * ea * ea));
-      a0 = kn;
-      a1 = -kn * (1 + k * alpha) * ema;
-      a2 = kn * (1 - k * alpha) * ema;
-      a3 = -kn * ema2;
-    } break;
-
-    default:
-      fprintf(stderr, "gaussianFilter: invalid order parameter!\n");
-      return;
-  }
-
-  coefp = (a0 + a1) / (1 + b1 + b2);
-  coefn = (a2 + a3) / (1 + b1 + b2);
-
-// process columns
-#if USE_SIMPLE_FILTER
-  d_simpleRecursive_rgba<<<iDivUp(width, nthreads), nthreads>>>(
-      d_src, d_temp, width, height, ema);
-#else
-  d_recursiveGaussian_rgba<<<iDivUp(width, nthreads), nthreads>>>(
-      d_src, d_temp, width, height, a0, a1, a2, a3, b1, b2, coefp, coefn);
-#endif
-  getLastCudaError("Kernel execution failed");
-
-  transpose(d_temp, d_dest, width, height);
-  getLastCudaError("transpose: Kernel execution failed");
-
-// process rows
-#if USE_SIMPLE_FILTER
-  d_simpleRecursive_rgba<<<iDivUp(height, nthreads), nthreads>>>(
-      d_dest, d_temp, height, width, ema);
-#else
-  d_recursiveGaussian_rgba<<<iDivUp(height, nthreads), nthreads>>>(
-      d_dest, d_temp, height, width, a0, a1, a2, a3, b1, b2, coefp, coefn);
-#endif
-  getLastCudaError("Kernel execution failed");
-
-  transpose(d_temp, d_dest, height, width);
-}
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_hipified.cpp b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_kernel.cuh b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_kernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2017.sln b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2019.sln b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2022.sln b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/recursiveGaussian/recursiveGaussian_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/Makefile b/src/samples/Samples/5_Domain_Specific/simpleD3D10/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D10/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/data/ref_simpleD3D10.ppm b/src/samples/Samples/5_Domain_Specific/simpleD3D10/data/ref_simpleD3D10.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_kernel.cu b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_kernel.cu.hip
old mode 100644
new mode 100755
index da44e81..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_kernel.cu.hip
@@ -1,88 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* This example demonstrates how to use the CUDA Direct3D bindings with the
- * runtime API.
- * Device code.
- */
-
-#ifndef _SIMPLED3D_KERNEL_CU_
-#define _SIMPLED3D_KERNEL_CU_
-
-// includes, C string library
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-// includes, cuda
-#include <hip/hip_runtime.h>
-#include <builtin_types.h>
-#include <hip/hip_runtime_api.h>
-
-///////////////////////////////////////////////////////////////////////////////
-//! Simple kernel to modify vertex positions in sine wave pattern
-//! @param pos  pos in global memory
-///////////////////////////////////////////////////////////////////////////////
-__global__ void kernel(float4 *pos, unsigned int width, unsigned int height,
-                       float time) {
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  // calculate uv coordinates
-  float u = x / (float)width;
-  float v = y / (float)height;
-  u = u * 2.0f - 1.0f;
-  v = v * 2.0f - 1.0f;
-
-  // calculate simple sine wave pattern
-  float freq = 4.0f;
-  float w = sinf(u * freq + time) * cosf(v * freq + time) * 0.5f;
-
-  // write output vertex
-  pos[y * width + x] = make_float4(u, w, v, __int_as_float(0xff00ff00));
-}
-
-extern "C" void simpleD3DKernel(float4 *pos, unsigned int width,
-                                unsigned int height, float time) {
-  hipError_t error = hipSuccess;
-
-  dim3 block(8, 8, 1);
-  dim3 grid(width / block.x, height / block.y, 1);
-
-  kernel<<<grid, block>>>(pos, width, height, time);
-
-  error = hipGetLastError();
-
-  if (error != hipSuccess) {
-    printf("kernel() failed to launch error = %d\n", error);
-  }
-}
-
-#endif  // #ifndef _SIMPLED3D_KERNEL_CU_
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2017.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2019.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2022.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10/simpleD3D10_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/Makefile b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/data/ref_simpleD3D10RenderTarget.ppm b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/data/ref_simpleD3D10RenderTarget.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_kernel.cu b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_kernel.cu.hip
old mode 100644
new mode 100755
index 76cc8a8..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_kernel.cu.hip
@@ -1,227 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* This example demonstrates how to use the CUDA Direct3D bindings with the
- * runtime API.
- * Device code.
- */
-
-#ifndef SIMPLED3D10RENDERTARGET_KERNEL_CU
-#define SIMPLED3D10RENDERTARGET_KERNEL_CU
-
-// includes, C string library
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-// includes, cuda
-#include <hip/hip_runtime.h>
-#include <builtin_types.h>
-#include <hip/hip_runtime_api.h>
-
-// includes, project
-#include "helper_cuda_hipified.h"  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
-//#include "HIPCHECK"
-
-#define BIN_COUNT 256
-#define HISTOGRAM_SIZE (BIN_COUNT * sizeof(unsigned int))
-
-texture<uchar4, 2, hipReadModeElementType> colorTex;
-
-////////////////////////////////////////////////////////////////////////////////
-// GPU-specific definitions
-////////////////////////////////////////////////////////////////////////////////
-// Fast mul on G8x / G9x / G100
-#define IMUL(a, b) __mul24(a, b)
-
-// Machine warp size
-// G80's warp size is 32 threads
-#define WARP_LOG2SIZE 5
-
-// Warps in thread block for histogram256Kernel()
-#define WARP_N 6
-
-// Corresponding thread block size in threads for histogram256Kernel()
-#define THREAD_N (WARP_N << WARP_LOG2SIZE)
-
-// Total histogram size (in counters) per thread block for histogram256Kernel()
-#define BLOCK_MEMORY (WARP_N * BIN_COUNT)
-
-// Thread block count for histogram256Kernel()
-#define BLOCK_N 64
-
-////////////////////////////////////////////////////////////////////////////////
-// If threadPos == threadIdx.x, there are always  4-way bank conflicts,
-// since each group of 16 threads (half-warp) accesses different bytes,
-// but only within 4 shared memory banks. Having shuffled bits of threadIdx.x
-// as in histogram64GPU(), each half-warp accesses different shared memory banks
-// avoiding any bank conflicts at all.
-// Refer to the supplied whitepaper for detailed explanations.
-////////////////////////////////////////////////////////////////////////////////
-__device__ inline void addData256(volatile unsigned int *s_WarpHist,
-                                  unsigned int data, unsigned int threadTag) {
-  unsigned int count;
-
-  do {
-    count = s_WarpHist[data] & 0x07FFFFFFU;
-    count = threadTag | (count + 1);
-    s_WarpHist[data] = count;
-  } while (s_WarpHist[data] != count);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Main histogram calculation kernel
-////////////////////////////////////////////////////////////////////////////////
-static __global__ void histogramTex256Kernel(unsigned int *d_Result,
-                                             unsigned int width,
-                                             unsigned int height, int dataN) {
-  // Current global thread index
-  const int globalTid = IMUL(blockIdx.x, blockDim.x) + threadIdx.x;
-  // Total number of threads in the compute grid
-  const int numThreads = IMUL(blockDim.x, gridDim.x);
-
-  // Thread tag for addData256()
-  // WARP_LOG2SIZE higher bits of counter values are tagged
-  // by lower WARP_LOG2SIZE threadID bits
-  const unsigned int threadTag = threadIdx.x << (32 - WARP_LOG2SIZE);
-
-  // Shared memory storage for each warp
-  volatile __shared__ unsigned int s_Hist[BLOCK_MEMORY];
-
-  // Current warp shared memory base
-  const int warpBase = (threadIdx.x >> WARP_LOG2SIZE) * BIN_COUNT;
-
-  // Clear shared memory buffer for current thread block before processing
-  for (int pos = threadIdx.x; pos < BLOCK_MEMORY; pos += blockDim.x)
-    s_Hist[pos] = 0;
-
-  // Cycle through the entire data set, update subhistograms for each warp
-  __syncthreads();
-
-  for (int pos = globalTid; pos < dataN; pos += numThreads) {
-    // NOTE: check this... Not sure this is what needs to be done
-    int py = pos / width;
-    int px = pos - (py * width);
-    uchar4 data4 = tex2D(colorTex, px, py);
-
-    addData256(s_Hist + warpBase, (data4.x), threadTag);
-    addData256(s_Hist + warpBase, (data4.y), threadTag);
-    addData256(s_Hist + warpBase, (data4.z), threadTag);
-    addData256(s_Hist + warpBase, (data4.w), threadTag);
-  }
-
-  __syncthreads();
-
-  // Merge per-warp histograms into per-block and write to global memory
-  for (int pos = threadIdx.x; pos < BIN_COUNT; pos += blockDim.x) {
-    unsigned int sum = 0;
-
-    for (int base = 0; base < BLOCK_MEMORY; base += BIN_COUNT)
-      sum += s_Hist[base + pos] & 0x07FFFFFFU;
-
-    d_Result[blockIdx.x * BIN_COUNT + pos] = sum;
-  }
-}
-
-///////////////////////////////////////////////////////////////////////////////
-// Merge BLOCK_N subhistograms of BIN_COUNT bins into final histogram
-///////////////////////////////////////////////////////////////////////////////
-// gridDim.x   == BIN_COUNT
-// blockDim.x  == BLOCK_N
-// blockIdx.x  == bin counter processed by current block
-// threadIdx.x == subhistogram index
-static __global__ void mergeHistogramTex256Kernel(unsigned int *d_Result) {
-  __shared__ unsigned int data[BLOCK_N];
-
-  // Reads are uncoalesced, but this final stage takes
-  // only a fraction of total processing time
-  data[threadIdx.x] = d_Result[threadIdx.x * BIN_COUNT + blockIdx.x];
-
-  for (int stride = BLOCK_N / 2; stride > 0; stride >>= 1) {
-    __syncthreads();
-
-    if (threadIdx.x < stride) data[threadIdx.x] += data[threadIdx.x + stride];
-  }
-
-  if (threadIdx.x == 0) d_Result[blockIdx.x] = data[0];
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Host interface to GPU histogram
-////////////////////////////////////////////////////////////////////////////////
-
-extern "C" void checkCudaError() {
-  hipError_t err = hipGetLastError();
-
-  if (hipSuccess != err) {
-    fprintf(stderr, "Cuda error: %s.\n", hipGetErrorString(err));
-    exit(2);
-  }
-}
-
-// Maximum block count for histogram64kernel()
-// Limits input data size to 756MB
-// const int MAX_BLOCK_N = 16384;
-
-// Internal memory allocation
-// const int BLOCK_N2 = 32;
-
-extern "C" void createHistogramTex(unsigned int *h_Result, unsigned int width,
-                                   unsigned int height, hipArray *colorArray) {
-  hipBindTextureToArray(colorTex, colorArray);
-  checkCudaError();
-
-  histogramTex256Kernel<<<BLOCK_N, THREAD_N>>>(h_Result, width, height,
-                                               width * height / 4);
-  checkCudaError();
-
-  mergeHistogramTex256Kernel<<<BIN_COUNT, BLOCK_N>>>(h_Result);
-  checkCudaError();
-
-  hipUnbindTexture(colorTex);
-  checkCudaError();
-
-#if 0
-    // Dummy fill test
-    unsigned int toto[256];
-
-    for (int i=0; i<256; i++)
-    {
-        toto[i] = i * 100;
-    }
-    hipMemcpy(h_Result, toto, HISTOGRAM_SIZE, hipMemcpyHostToDevice);
-#endif
-  checkCudaError();
-}
-
-extern "C" void bindArrayToTexture(hipArray *pArray) {}
-
-#endif  // #ifndef SIMPLED3D10RENDERTARGET_KERNEL_CU
-NEL_CU
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2017.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2019.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2022.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10RenderTarget/simpleD3D10RenderTarget_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/Makefile b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/data/ref_simpleD3D10Texture.ppm b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/data/ref_simpleD3D10Texture.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2017.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2019.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2022.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/simpleD3D10Texture_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_2d.cu b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_2d.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_2d.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_2d.cu.hip
old mode 100644
new mode 100755
index 325f74a..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_2d.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_2d.cu.hip
@@ -1,81 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-#define PI 3.1415926536f
-
-/*
- * Paint a 2D texture with a moving red/green hatch pattern on a
- * strobing blue background.  Note that this kernel reads to and
- * writes from the texture, hence why this texture was not mapped
- * as WriteDiscard.
- */
-__global__ void cuda_kernel_texture_2d(unsigned char *surface, int width,
-                                       int height, size_t pitch, float t) {
-  int x = blockIdx.x * blockDim.x + threadIdx.x;
-  int y = blockIdx.y * blockDim.y + threadIdx.y;
-  float *pixel;
-
-  // in the case where, due to quantization into grids, we have
-  // more threads than pixels, skip the threads which don't
-  // correspond to valid pixels
-  if (x >= width || y >= height) return;
-
-  // get a pointer to the pixel at (x,y)
-  pixel = (float *)(surface + y * pitch) + 4 * x;
-
-  // populate it
-  float value_x = 0.5f + 0.5f * cos(t + 10.0f * ((2.0f * x) / width - 1.0f));
-  float value_y = 0.5f + 0.5f * cos(t + 10.0f * ((2.0f * y) / height - 1.0f));
-  pixel[0] = 0.5 * pixel[0] + 0.5 * pow(value_x, 3.0f);  // red
-  pixel[1] = 0.5 * pixel[1] + 0.5 * pow(value_y, 3.0f);  // green
-  pixel[2] = 0.5f + 0.5f * cos(t);                       // blue
-  pixel[3] = 1;                                          // alpha
-}
-
-extern "C" void cuda_texture_2d(void *surface, int width, int height,
-                                size_t pitch, float t) {
-  hipError_t error = hipSuccess;
-
-  dim3 Db = dim3(16, 16);  // block dimensions are fixed to be 256 threads
-  dim3 Dg = dim3((width + Db.x - 1) / Db.x, (height + Db.y - 1) / Db.y);
-
-  cuda_kernel_texture_2d<<<Dg, Db>>>((unsigned char *)surface, width, height,
-                                     pitch, t);
-
-  error = hipGetLastError();
-
-  if (error != hipSuccess) {
-    printf("cuda_kernel_texture_2d() failed to launch error = %d\n", error);
-  }
-}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_3d.cu b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_3d.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_3d.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_3d.cu.hip
old mode 100644
new mode 100755
index e6c2341..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_3d.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_3d.cu.hip
@@ -1,79 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-/*
- * Paint a 3D texture with a gradient in X (blue) and Z (green), and have every
- * other Z slice have full red.
- */
-__global__ void cuda_kernel_texture_3d(unsigned char *surface, int width,
-                                       int height, int depth, size_t pitch,
-                                       size_t pitchSlice, float t) {
-  int x = blockIdx.x * blockDim.x + threadIdx.x;
-  int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  // in the case where, due to quantization into grids, we have
-  // more threads than pixels, skip the threads which don't
-  // correspond to valid pixels
-  if (x >= width || y >= height) return;
-
-  // walk across the Z slices of this texture.  it should be noted that
-  // this is far from optimal data access.
-  for (int z = 0; z < depth; ++z) {
-    // get a pointer to this pixel
-    unsigned char *pixel = surface + z * pitchSlice + y * pitch + 4 * x;
-    pixel[0] = (unsigned char)(255.f * (0.5f + 0.5f * 
-        cos(t + (x * x + y * y + z * z) * 0.0001f * 3.14f)));  // red
-    pixel[1] = (unsigned char)(255.f * (0.5f + 0.5f * 
-        sin(t + (x * x + y * y + z * z) * 0.0001f * 3.14f)));  // green
-    pixel[2] = (unsigned char)0;                               // blue
-    pixel[3] = 255;                                            // alpha
-  }
-}
-
-extern "C" void cuda_texture_3d(void *surface, int width, int height, int depth,
-                                size_t pitch, size_t pitchSlice, float t) {
-  hipError_t error = hipSuccess;
-
-  dim3 Db = dim3(16, 16);  // block dimensions are fixed to be 256 threads
-  dim3 Dg = dim3((width + Db.x - 1) / Db.x, (height + Db.y - 1) / Db.y);
-
-  cuda_kernel_texture_3d<<<Dg, Db>>>((unsigned char *)surface, width, height,
-                                     depth, pitch, pitchSlice, t);
-
-  error = hipGetLastError();
-
-  if (error != hipSuccess) {
-    printf("cuda_kernel_texture_3d() failed to launch error = %d\n", error);
-  }
-}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_cube.cu b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_cube.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_cube.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleD3D10Texture/texture_cube.cu.hip
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/Makefile b/src/samples/Samples/5_Domain_Specific/simpleD3D11/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D11/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/ShaderStructs.h b/src/samples/Samples/5_Domain_Specific/simpleD3D11/ShaderStructs.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/ShaderStructs_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleD3D11/ShaderStructs_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/data/ref_simpleD3D11.ppm b/src/samples/Samples/5_Domain_Specific/simpleD3D11/data/ref_simpleD3D11.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2017.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2019.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2022.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D11/simpleD3D11_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/sinewave_cuda.cu b/src/samples/Samples/5_Domain_Specific/simpleD3D11/sinewave_cuda.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/sinewave_cuda.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleD3D11/sinewave_cuda.cu.hip
old mode 100644
new mode 100755
index 8574be7..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D11/sinewave_cuda.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D11/sinewave_cuda.cu.hip
@@ -1,134 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include "ShaderStructs.h"
-#include "helper_cuda.h"
-#include "sinewave_cuda.h"
-
-__global__ void sinewave_gen_kernel(Vertex *vertices, unsigned int width, unsigned int height, float time)
-{
-    unsigned int x = blockIdx.x*blockDim.x + threadIdx.x;
-    unsigned int y = blockIdx.y*blockDim.y + threadIdx.y;
-
-    // calculate uv coordinates
-    float u = x / (float) width;
-    float v = y / (float) height;
-    u = u*2.0f - 1.0f;
-    v = v*2.0f - 1.0f;
-
-    // calculate simple sine wave pattern
-    float freq = 4.0f;
-    float w = sinf(u*freq + time) * cosf(v*freq + time) * 0.5f;
-
-    if (y < height && x < width)
-    {
-        // write output vertex
-        vertices[y*width+x].position.x = u;
-        vertices[y*width+x].position.y = w;
-        vertices[y*width+x].position.z = v;
-        vertices[y*width+x].color.x = 1.0f;
-        vertices[y*width+x].color.y = 0.0f;
-        vertices[y*width+x].color.z = 0.0f;
-        vertices[y*width + x].color.w = 0.0f;
-    }
-}
-
-Vertex* cudaImportVertexBuffer(void*sharedHandle, hipExternalMemory_t &externalMemory, int meshWidth, int meshHeight)
-{
-    hipExternalMemoryHandleDesc externalMemoryHandleDesc;
-    memset(&externalMemoryHandleDesc, 0, sizeof(externalMemoryHandleDesc));
-
-    externalMemoryHandleDesc.type = hipExternalMemoryHandleTypeD3D11ResourceKmt;
-    externalMemoryHandleDesc.size = sizeof(Vertex) * meshHeight * meshWidth;
-    externalMemoryHandleDesc.flags = cudaExternalMemoryDedicated;
-    externalMemoryHandleDesc.handle.win32.handle = sharedHandle;
-
-    HIPCHECK(hipImportExternalMemory(&externalMemory, &externalMemoryHandleDesc));
-
-    hipExternalMemoryBufferDesc externalMemoryBufferDesc;
-    memset(&externalMemoryBufferDesc, 0, sizeof(externalMemoryBufferDesc));
-    externalMemoryBufferDesc.offset = 0;
-    externalMemoryBufferDesc.size = sizeof(Vertex) * meshHeight * meshWidth;
-    externalMemoryBufferDesc.flags = 0;
-
-    Vertex* cudaDevVertptr = NULL;
-    HIPCHECK(hipExternalMemoryGetMappedBuffer((void**)&cudaDevVertptr, externalMemory, &externalMemoryBufferDesc));
-
-    return cudaDevVertptr;
-}
-
-void cudaImportKeyedMutex(void*sharedHandle, hipExternalSemaphore_t &extSemaphore)
-{
-    hipExternalSemaphoreHandleDesc extSemaDesc;
-    memset(&extSemaDesc, 0, sizeof(extSemaDesc));
-    extSemaDesc.type = cudaExternalSemaphoreHandleTypeKeyedMutexKmt;
-    extSemaDesc.handle.win32.handle = sharedHandle;
-    extSemaDesc.flags = 0;
-
-    HIPCHECK(hipImportExternalSemaphore(&extSemaphore, &extSemaDesc));
-}
-
-void cudaAcquireSync(hipExternalSemaphore_t &extSemaphore, uint64_t key, unsigned int timeoutMs, hipStream_t streamToRun)
-{
-    hipExternalSemaphoreWaitParams extSemWaitParams;
-    memset(&extSemWaitParams, 0, sizeof(extSemWaitParams));
-    extSemWaitParams.params.keyedMutex.key = key;
-    extSemWaitParams.params.keyedMutex.timeoutMs = timeoutMs;
-
-    HIPCHECK(hipWaitExternalSemaphoresAsync(&extSemaphore, &extSemWaitParams, 1, streamToRun));
-}
-
-void cudaReleaseSync(hipExternalSemaphore_t &extSemaphore, uint64_t key, hipStream_t streamToRun)
-{
-    hipExternalSemaphoreSignalParams extSemSigParams;
-    memset(&extSemSigParams, 0, sizeof(extSemSigParams));
-    extSemSigParams.params.keyedMutex.key = key;
-
-    HIPCHECK(hipSignalExternalSemaphoresAsync(&extSemaphore, &extSemSigParams, 1, streamToRun));
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run the Cuda part of the computation
-////////////////////////////////////////////////////////////////////////////////
-void RunSineWaveKernel(hipExternalSemaphore_t &extSemaphore, uint64_t &key, unsigned int timeoutMs, 
-                        size_t mesh_width, size_t mesh_height, Vertex *cudaDevVertptr, hipStream_t streamToRun)
-{
-    static float t = 0.0f;
-    cudaAcquireSync(extSemaphore, key++, timeoutMs, streamToRun);
-
-    dim3 block(16, 16, 1);
-    dim3 grid(mesh_width / 16, mesh_height / 16, 1);
-    sinewave_gen_kernel<<< grid, block, 0, streamToRun >>>(cudaDevVertptr, mesh_width, mesh_height, t);
-    getLastCudaError("sinewave_gen_kernel execution failed.\n");
-
-    cudaReleaseSync(extSemaphore, key, streamToRun);
-    t += 0.01f;
-}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/sinewave_cuda.h b/src/samples/Samples/5_Domain_Specific/simpleD3D11/sinewave_cuda.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11/sinewave_cuda_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleD3D11/sinewave_cuda_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/Makefile b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/d3dx11effect/d3dx11effect.h b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/d3dx11effect/d3dx11effect.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/d3dx11effect/d3dx11effect_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/d3dx11effect/d3dx11effect_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/data/ref_simpleD3D11Texture.ppm b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/data/ref_simpleD3D11Texture.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2017.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2019.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2022.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/simpleD3D11Texture_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_2d.cu b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_2d.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_2d.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_2d.cu.hip
old mode 100644
new mode 100755
index 325f74a..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_2d.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_2d.cu.hip
@@ -1,81 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-#define PI 3.1415926536f
-
-/*
- * Paint a 2D texture with a moving red/green hatch pattern on a
- * strobing blue background.  Note that this kernel reads to and
- * writes from the texture, hence why this texture was not mapped
- * as WriteDiscard.
- */
-__global__ void cuda_kernel_texture_2d(unsigned char *surface, int width,
-                                       int height, size_t pitch, float t) {
-  int x = blockIdx.x * blockDim.x + threadIdx.x;
-  int y = blockIdx.y * blockDim.y + threadIdx.y;
-  float *pixel;
-
-  // in the case where, due to quantization into grids, we have
-  // more threads than pixels, skip the threads which don't
-  // correspond to valid pixels
-  if (x >= width || y >= height) return;
-
-  // get a pointer to the pixel at (x,y)
-  pixel = (float *)(surface + y * pitch) + 4 * x;
-
-  // populate it
-  float value_x = 0.5f + 0.5f * cos(t + 10.0f * ((2.0f * x) / width - 1.0f));
-  float value_y = 0.5f + 0.5f * cos(t + 10.0f * ((2.0f * y) / height - 1.0f));
-  pixel[0] = 0.5 * pixel[0] + 0.5 * pow(value_x, 3.0f);  // red
-  pixel[1] = 0.5 * pixel[1] + 0.5 * pow(value_y, 3.0f);  // green
-  pixel[2] = 0.5f + 0.5f * cos(t);                       // blue
-  pixel[3] = 1;                                          // alpha
-}
-
-extern "C" void cuda_texture_2d(void *surface, int width, int height,
-                                size_t pitch, float t) {
-  hipError_t error = hipSuccess;
-
-  dim3 Db = dim3(16, 16);  // block dimensions are fixed to be 256 threads
-  dim3 Dg = dim3((width + Db.x - 1) / Db.x, (height + Db.y - 1) / Db.y);
-
-  cuda_kernel_texture_2d<<<Dg, Db>>>((unsigned char *)surface, width, height,
-                                     pitch, t);
-
-  error = hipGetLastError();
-
-  if (error != hipSuccess) {
-    printf("cuda_kernel_texture_2d() failed to launch error = %d\n", error);
-  }
-}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_3d.cu b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_3d.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_3d.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_3d.cu.hip
old mode 100644
new mode 100755
index 78fd055..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_3d.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_3d.cu.hip
@@ -1,81 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-/*
- * Paint a 3D texture with a gradient in X (blue) and Z (green), and have every
- * other Z slice have full red.
- */
-__global__ void cuda_kernel_texture_3d(unsigned char *surface, int width,
-                                       int height, int depth, size_t pitch,
-                                       size_t pitchSlice, float t) {
-  int x = blockIdx.x * blockDim.x + threadIdx.x;
-  int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  // in the case where, due to quantization into grids, we have
-  // more threads than pixels, skip the threads which don't
-  // correspond to valid pixels
-  if (x >= width || y >= height) return;
-
-  // walk across the Z slices of this texture.  it should be noted that
-  // this is far from optimal data access.
-  for (int z = 0; z < depth; ++z) {
-    // get a pointer to this pixel
-    unsigned char *pixel = surface + z * pitchSlice + y * pitch + 4 * x;
-    pixel[0] =
-        (unsigned char)(255.f * (0.5f + 0.5f * 
-        cos(t + (x * x + y * y + z * z) * 0.0001f * 3.14f)));  // red
-    pixel[1] =
-        (unsigned char)(255.f * (0.5f + 0.5f * 
-        sin(t + (x * x + y * y + z * z) * 0.0001f * 3.14f)));  // green
-    pixel[2] = (unsigned char)0;                               // blue
-    pixel[3] = 255;                                            // alpha
-  }
-}
-
-extern "C" void cuda_texture_3d(void *surface, int width, int height, int depth,
-                                size_t pitch, size_t pitchSlice, float t) {
-  hipError_t error = hipSuccess;
-
-  dim3 Db = dim3(16, 16);  // block dimensions are fixed to be 256 threads
-  dim3 Dg = dim3((width + Db.x - 1) / Db.x, (height + Db.y - 1) / Db.y);
-
-  cuda_kernel_texture_3d<<<Dg, Db>>>((unsigned char *)surface, width, height,
-                                     depth, pitch, pitchSlice, t);
-
-  error = hipGetLastError();
-
-  if (error != hipSuccess) {
-    printf("cuda_kernel_texture_3d() failed to launch error = %d\n", error);
-  }
-}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_cube.cu b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_cube.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_cube.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_cube.cu.hip
old mode 100644
new mode 100755
index 39ef766..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_cube.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D11Texture/texture_cube.cu.hip
@@ -1,94 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-#define PI 3.1415926536f
-
-/*
- * Paint a 2D surface with a moving bulls-eye pattern.  The "face" parameter
- * selects
- * between 6 different colors to use.  We will use a different color on each
- * face of a
- * cube map.
- */
-__global__ void cuda_kernel_texture_cube(char *surface, int width, int height,
-                                         size_t pitch, int face, float t) {
-  int x = blockIdx.x * blockDim.x + threadIdx.x;
-  int y = blockIdx.y * blockDim.y + threadIdx.y;
-  unsigned char *pixel;
-
-  // in the case where, due to quantization into grids, we have
-  // more threads than pixels, skip the threads which don't
-  // correspond to valid pixels
-  if (x >= width || y >= height) return;
-
-  // get a pointer to this pixel
-  pixel = (unsigned char *)(surface + y * pitch) + 4 * x;
-
-  // populate it
-  float theta_x = (2.0f * x) / width - 1.0f;
-  float theta_y = (2.0f * y) / height - 1.0f;
-  float theta = 2.0f * PI * sqrt(theta_x * theta_x + theta_y * theta_y);
-  unsigned char value = 255 * (0.6f + 0.4f * cos(theta + t));
-
-  pixel[3] = 255;  // alpha
-
-  if (face % 2) {
-    pixel[0] =           // blue
-        pixel[1] =       // green
-        pixel[2] = 0.5;  // red
-    pixel[face / 2] = value;
-  } else {
-    pixel[0] =             // blue
-        pixel[1] =         // green
-        pixel[2] = value;  // red
-    pixel[face / 2] = 0.5;
-  }
-}
-
-extern "C" void cuda_texture_cube(void *surface, int width, int height,
-                                  size_t pitch, int face, float t) {
-  hipError_t error = hipSuccess;
-
-  dim3 Db = dim3(16, 16);  // block dimensions are fixed to be 256 threads
-  dim3 Dg = dim3((width + Db.x - 1) / Db.x, (height + Db.y - 1) / Db.y);
-
-  cuda_kernel_texture_cube<<<Dg, Db>>>((char *)surface, width, height, pitch,
-                                       face, t);
-
-  error = hipGetLastError();
-
-  if (error != hipSuccess) {
-    printf("cuda_kernel_texture_cube() failed to launch error = %d\n", error);
-  }
-}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/DX12CudaSample_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D12/DX12CudaSample_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/DX12CudaSample_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleD3D12/DX12CudaSample_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/DXSampleHelper_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleD3D12/DXSampleHelper_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/Main_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D12/Main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/Makefile b/src/samples/Samples/5_Domain_Specific/simpleD3D12/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/simpleD3D12/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D12/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/ShaderStructs_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleD3D12/ShaderStructs_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/Win32Application_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D12/Win32Application_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/Win32Application_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleD3D12/Win32Application_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/d3dx12_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleD3D12/d3dx12_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2017.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2019.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2022.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D12/simpleD3D12_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/sinewave_cuda.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleD3D12/sinewave_cuda.cu.hip
old mode 100644
new mode 100755
index 7220a2e..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D12/sinewave_cuda.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D12/sinewave_cuda.cu.hip
@@ -1,70 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "ShaderStructs.h"
-
-__global__ void sinewave_gen_kernel(Vertex *vertices, unsigned int width,
-                                    unsigned int height, float time) {
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  // calculate uv coordinates
-  float u = x / (float)width;
-  float v = y / (float)height;
-  u = u * 2.0f - 1.0f;
-  v = v * 2.0f - 1.0f;
-
-  // calculate simple sine wave pattern
-  float freq = 4.0f;
-  float w = sinf(u * freq + time) * cosf(v * freq + time) * 0.5f;
-
-  if (y < height && x < width) {
-    // write output vertex
-    vertices[y * width + x].position.x = u;
-    vertices[y * width + x].position.y = w;
-    vertices[y * width + x].position.z = v;
-    // vertices[y*width+x].position[3] = 1.0f;
-    vertices[y * width + x].color.x = 1.0f;
-    vertices[y * width + x].color.y = 0.0f;
-    vertices[y * width + x].color.z = 0.0f;
-    vertices[y * width + x].color.w = 0.0f;
-  }
-}
-
-// The host CPU Sinewave thread spawner
-void RunSineWaveKernel(size_t mesh_width, size_t mesh_height,
-                       Vertex *cudaDevVertptr, hipStream_t streamToRun,
-                       float AnimTime) {
-  dim3 block(16, 16, 1);
-  dim3 grid(mesh_width / 16, mesh_height / 16, 1);
-  Vertex *vertices = (Vertex *)cudaDevVertptr;
-  sinewave_gen_kernel<<<grid, block, 0, streamToRun>>>(vertices, mesh_width,
-                                                       mesh_height, AnimTime);
-
-  getLastCudaError("sinewave_gen_kernel execution failed.\n");
-}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/stdafx_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D12/stdafx_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D12/stdafx_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleD3D12/stdafx_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/Makefile b/src/samples/Samples/5_Domain_Specific/simpleD3D9/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D9/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/data/ref_simpleD3D9.ppm b/src/samples/Samples/5_Domain_Specific/simpleD3D9/data/ref_simpleD3D9.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/doc/sshot_lg.JPG b/src/samples/Samples/5_Domain_Specific/simpleD3D9/doc/sshot_lg.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/doc/sshot_md.JPG b/src/samples/Samples/5_Domain_Specific/simpleD3D9/doc/sshot_md.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/doc/sshot_sm.JPG b/src/samples/Samples/5_Domain_Specific/simpleD3D9/doc/sshot_sm.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9.ppm b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_kernel.cu b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_kernel.cu.hip
old mode 100644
new mode 100755
index fb714af..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_kernel.cu.hip
@@ -1,82 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// This example demonstrates how to use the CUDA Direct3D bindings with the
-// runtime API.
-// Device code.
-
-#ifndef _SIMPLED3D_KERNEL_CU_
-#define _SIMPLED3D_KERNEL_CU_
-
-// includes, C string library
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-///////////////////////////////////////////////////////////////////////////////
-//! Simple kernel to modify vertex positions in sine wave pattern
-//! @param pos  pos in global memory
-///////////////////////////////////////////////////////////////////////////////
-__global__ void kernel(float4 *pos, unsigned int width, unsigned int height,
-                       float time) {
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  // calculate uv coordinates
-  float u = x / (float)width;
-  float v = y / (float)height;
-  u = u * 2.0f - 1.0f;
-  v = v * 2.0f - 1.0f;
-
-  // calculate simple sine wave pattern
-  float freq = 4.0f;
-  float w = sinf(u * freq + time) * cosf(v * freq + time) * 0.5f;
-
-  // write output vertex
-  pos[y * width + x] = make_float4(u, w, v, __int_as_float(0xff00ff00));
-}
-
-extern "C" void simpleD3DKernel(float4 *pos, unsigned int width,
-                                unsigned int height, float time) {
-  hipError_t error = hipSuccess;
-
-  dim3 block(8, 8, 1);
-  dim3 grid(width / block.x, height / block.y, 1);
-
-  kernel<<<grid, block>>>(pos, width, height, time);
-
-  error = hipGetLastError();
-
-  if (error != hipSuccess) {
-    printf("kernel() failed to launch error = %d\n", error);
-  }
-}
-
-#endif  // #ifndef _SIMPLED3D_KERNEL_CU_
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2017.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2019.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2022.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D9/simpleD3D9_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/Makefile b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/README.md b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/data/ref_simpleD3D9Texture.ppm b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/data/ref_simpleD3D9Texture.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/doc/sshot_lg.jpg b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/doc/sshot_lg.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/doc/sshot_md.jpg b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/doc/sshot_md.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/doc/sshot_sm.jpg b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/doc/sshot_sm.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2017.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2019.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2022.sln b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/simpleD3D9Texture_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_2d.cu b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_2d.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_2d.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_2d.cu.hip
old mode 100644
new mode 100755
index 325f74a..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_2d.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_2d.cu.hip
@@ -1,81 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-#define PI 3.1415926536f
-
-/*
- * Paint a 2D texture with a moving red/green hatch pattern on a
- * strobing blue background.  Note that this kernel reads to and
- * writes from the texture, hence why this texture was not mapped
- * as WriteDiscard.
- */
-__global__ void cuda_kernel_texture_2d(unsigned char *surface, int width,
-                                       int height, size_t pitch, float t) {
-  int x = blockIdx.x * blockDim.x + threadIdx.x;
-  int y = blockIdx.y * blockDim.y + threadIdx.y;
-  float *pixel;
-
-  // in the case where, due to quantization into grids, we have
-  // more threads than pixels, skip the threads which don't
-  // correspond to valid pixels
-  if (x >= width || y >= height) return;
-
-  // get a pointer to the pixel at (x,y)
-  pixel = (float *)(surface + y * pitch) + 4 * x;
-
-  // populate it
-  float value_x = 0.5f + 0.5f * cos(t + 10.0f * ((2.0f * x) / width - 1.0f));
-  float value_y = 0.5f + 0.5f * cos(t + 10.0f * ((2.0f * y) / height - 1.0f));
-  pixel[0] = 0.5 * pixel[0] + 0.5 * pow(value_x, 3.0f);  // red
-  pixel[1] = 0.5 * pixel[1] + 0.5 * pow(value_y, 3.0f);  // green
-  pixel[2] = 0.5f + 0.5f * cos(t);                       // blue
-  pixel[3] = 1;                                          // alpha
-}
-
-extern "C" void cuda_texture_2d(void *surface, int width, int height,
-                                size_t pitch, float t) {
-  hipError_t error = hipSuccess;
-
-  dim3 Db = dim3(16, 16);  // block dimensions are fixed to be 256 threads
-  dim3 Dg = dim3((width + Db.x - 1) / Db.x, (height + Db.y - 1) / Db.y);
-
-  cuda_kernel_texture_2d<<<Dg, Db>>>((unsigned char *)surface, width, height,
-                                     pitch, t);
-
-  error = hipGetLastError();
-
-  if (error != hipSuccess) {
-    printf("cuda_kernel_texture_2d() failed to launch error = %d\n", error);
-  }
-}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_cube.cu b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_cube.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_cube.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_cube.cu.hip
old mode 100644
new mode 100755
index c6205e0..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_cube.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_cube.cu.hip
@@ -1,92 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-#define PI 3.1415926536f
-
-/*
- * Paint a 2D surface with a moving bulls-eye pattern.  The "face" parameter
- * selects  between 6 different colors to use.  We will use a different color on
- * each face of a  cube map.
- */
-__global__ void cuda_kernel_texture_cube(char *surface, int width, int height,
-                                         size_t pitch, int face, float t) {
-  int x = blockIdx.x * blockDim.x + threadIdx.x;
-  int y = blockIdx.y * blockDim.y + threadIdx.y;
-  unsigned char *pixel;
-
-  // in the case where, due to quantization into grids, we have
-  // more threads than pixels, skip the threads which don't
-  // correspond to valid pixels
-  if (x >= width || y >= height) return;
-
-  // get a pointer to this pixel
-  pixel = (unsigned char *)(surface + y * pitch) + 4 * x;
-
-  // populate it
-  float theta_x = (2.0f * x) / width - 1.0f;
-  float theta_y = (2.0f * y) / height - 1.0f;
-  float theta = 2.0f * PI * sqrt(theta_x * theta_x + theta_y * theta_y);
-  unsigned char value = 255 * (0.6f + 0.4f * cos(theta + t));
-
-  pixel[3] = 255;  // alpha
-
-  if (face % 2) {
-    pixel[0] =         // blue
-        pixel[1] =     // green
-        pixel[2] = 0;  // red
-    pixel[face / 2] = value;
-  } else {
-    pixel[0] =             // blue
-        pixel[1] =         // green
-        pixel[2] = value;  // red
-    pixel[face / 2] = 0;
-  }
-}
-
-extern "C" void cuda_texture_cube(void *surface, int width, int height,
-                                  size_t pitch, int face, float t) {
-  hipError_t error = hipSuccess;
-
-  dim3 Db = dim3(16, 16);  // block dimensions are fixed to be 256 threads
-  dim3 Dg = dim3((width + Db.x - 1) / Db.x, (height + Db.y - 1) / Db.y);
-
-  cuda_kernel_texture_cube<<<Dg, Db>>>((char *)surface, width, height, pitch,
-                                       face, t);
-
-  error = hipGetLastError();
-
-  if (error != hipSuccess) {
-    printf("cuda_kernel_texture_cube() failed to launch error = %d\n", error);
-  }
-}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_volume.cu b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_volume.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_volume.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_volume.cu.hip
old mode 100644
new mode 100755
index cb60ec7..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_volume.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleD3D9Texture/texture_volume.cu.hip
@@ -1,78 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-/*
- * Paint a 3D texture with a gradient in X (blue) and Z (green), and have every
- * other Z slice have full red.
- */
-__global__ void cuda_kernel_texture_volume(unsigned char *surface, int width,
-                                           int height, int depth, size_t pitch,
-                                           size_t pitchSlice) {
-  int x = blockIdx.x * blockDim.x + threadIdx.x;
-  int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  // in the case where, due to quantization into grids, we have
-  // more threads than pixels, skip the threads which don't
-  // correspond to valid pixels
-  if (x >= width || y >= height) return;
-
-  // walk across the Z slices of this texture.  it should be noted that
-  // this is far from optimal data access.
-  for (int z = 0; z < depth; ++z) {
-    // get a pointer to this pixel
-    unsigned char *pixel = surface + z * pitchSlice + y * pitch + 4 * x;
-    pixel[0] = 255 * x / (width - 1);  // blue
-    pixel[1] = 255 * z / (depth - 1);  // green
-    pixel[2] = 255 * (z % 2);          // red
-    pixel[3] = 255;                    // alpha
-  }
-}
-
-extern "C" void cuda_texture_volume(void *surface, int width, int height,
-                                    int depth, size_t pitch, size_t pitchSlice,
-                                    float t) {
-  hipError_t error = hipSuccess;
-
-  dim3 Db = dim3(16, 16);  // block dimensions are fixed to be 256 threads
-  dim3 Dg = dim3((width + Db.x - 1) / Db.x, (height + Db.y - 1) / Db.y);
-
-  cuda_kernel_texture_volume<<<Dg, Db>>>((unsigned char *)surface, width,
-                                         height, depth, pitch, pitchSlice);
-
-  error = hipGetLastError();
-
-  if (error != hipSuccess) {
-    printf("cuda_kernel_texture_volume() failed to launch error = %d\n", error);
-  }
-}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/simpleGL/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/simpleGL/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/simpleGL/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/simpleGL/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/Makefile b/src/samples/Samples/5_Domain_Specific/simpleGL/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/simpleGL/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/README.md b/src/samples/Samples/5_Domain_Specific/simpleGL/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/data/ref_simpleGL.bin b/src/samples/Samples/5_Domain_Specific/simpleGL/data/ref_simpleGL.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/findgllib.mk b/src/samples/Samples/5_Domain_Specific/simpleGL/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL.cu b/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL.cu.hip
old mode 100644
new mode 100755
index 40c265a..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL.cu.hip
@@ -1,589 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
-    This example demonstrates how to use the Cuda OpenGL bindings to
-    dynamically modify a vertex buffer using a Cuda kernel.
-
-    The steps are:
-    1. Create an empty vertex buffer object (VBO)
-    2. Register the VBO with Cuda
-    3. Map the VBO for writing from Cuda
-    4. Run Cuda kernel to modify the vertex positions
-    5. Unmap the VBO
-    6. Render the results using OpenGL
-
-    Host code
-*/
-
-// includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-
-#ifdef _WIN32
-#  define WINDOWS_LEAN_AND_MEAN
-#  define NOMINMAX
-#  include <windows.h>
-#endif
-
-// OpenGL Graphics includes
-#include <helper_gl.h>
-#if defined (__APPLE__) || defined(MACOSX)
-  #pragma clang diagnostic ignored "-Wdeprecated-declarations"
-  #include <GLUT/glut.h>
-  #ifndef glutCloseFunc
-  #define glutCloseFunc glutWMCloseFunc
-  #endif
-#else
-#include <GL/freeglut.h>
-#endif
-
-// includes, cuda
-#include <hip/hip_runtime.h>
-#include <cuda_gl_interop.h>
-
-// Utilities and timing functions
-#include "helper_functions.h"    // includes hip/hip_runtime.h and hip/hip_runtime_api.h
-
-// CUDA helper functions
-#include "helper_cuda_hipified.h"         // helper functions for CUDA error check
-
-#include <hip/hip_vector_types.h>
-
-#define MAX_EPSILON_ERROR 10.0f
-#define THRESHOLD          0.30f
-#define REFRESH_DELAY     10 //ms
-
-////////////////////////////////////////////////////////////////////////////////
-// constants
-const unsigned int window_width  = 512;
-const unsigned int window_height = 512;
-
-const unsigned int mesh_width    = 256;
-const unsigned int mesh_height   = 256;
-
-// vbo variables
-GLuint vbo;
-struct hipGraphicsResource *cuda_vbo_resource;
-void *d_vbo_buffer = NULL;
-
-float g_fAnim = 0.0;
-
-// mouse controls
-int mouse_old_x, mouse_old_y;
-int mouse_buttons = 0;
-float rotate_x = 0.0, rotate_y = 0.0;
-float translate_z = -3.0;
-
-StopWatchInterface *timer = NULL;
-
-// Auto-Verification Code
-int fpsCount = 0;        // FPS count for averaging
-int fpsLimit = 1;        // FPS limit for sampling
-int g_Index = 0;
-float avgFPS = 0.0f;
-unsigned int frameCount = 0;
-unsigned int g_TotalErrors = 0;
-bool g_bQAReadback = false;
-
-int *pArgc = NULL;
-char **pArgv = NULL;
-
-#define MAX(a,b) ((a > b) ? a : b)
-
-////////////////////////////////////////////////////////////////////////////////
-// declaration, forward
-bool runTest(int argc, char **argv, char *ref_file);
-void cleanup();
-
-// GL functionality
-bool initGL(int *argc, char **argv);
-void createVBO(GLuint *vbo, struct hipGraphicsResource **vbo_res,
-               unsigned int vbo_res_flags);
-void deleteVBO(GLuint *vbo, struct hipGraphicsResource *vbo_res);
-
-// rendering callbacks
-void display();
-void keyboard(unsigned char key, int x, int y);
-void mouse(int button, int state, int x, int y);
-void motion(int x, int y);
-void timerEvent(int value);
-
-// Cuda functionality
-void runCuda(struct hipGraphicsResource **vbo_resource);
-void runAutoTest(int devID, char **argv, char *ref_file);
-void checkResultCuda(int argc, char **argv, const GLuint &vbo);
-
-const char *sSDKsample = "simpleGL (VBO)";
-
-///////////////////////////////////////////////////////////////////////////////
-//! Simple kernel to modify vertex positions in sine wave pattern
-//! @param data  data in global memory
-///////////////////////////////////////////////////////////////////////////////
-__global__ void simple_vbo_kernel(float4 *pos, unsigned int width, unsigned int height, float time)
-{
-    unsigned int x = blockIdx.x*blockDim.x + threadIdx.x;
-    unsigned int y = blockIdx.y*blockDim.y + threadIdx.y;
-
-    // calculate uv coordinates
-    float u = x / (float) width;
-    float v = y / (float) height;
-    u = u*2.0f - 1.0f;
-    v = v*2.0f - 1.0f;
-
-    // calculate simple sine wave pattern
-    float freq = 4.0f;
-    float w = sinf(u*freq + time) * cosf(v*freq + time) * 0.5f;
-
-    // write output vertex
-    pos[y*width+x] = make_float4(u, w, v, 1.0f);
-}
-
-
-void launch_kernel(float4 *pos, unsigned int mesh_width,
-                   unsigned int mesh_height, float time)
-{
-    // execute the kernel
-    dim3 block(8, 8, 1);
-    dim3 grid(mesh_width / block.x, mesh_height / block.y, 1);
-    simple_vbo_kernel<<< grid, block>>>(pos, mesh_width, mesh_height, time);
-}
-
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv)
-{
-    char *ref_file = NULL;
-
-    pArgc = &argc;
-    pArgv = argv;
-
-#if defined(__linux__)
-    setenv ("DISPLAY", ":0", 0);
-#endif
-
-    printf("%s starting...\n", sSDKsample);
-
-    if (argc > 1)
-    {
-        if (checkCmdLineFlag(argc, (const char **)argv, "file"))
-        {
-            // In this mode, we are running non-OpenGL and doing a compare of the VBO was generated correctly
-            getCmdLineArgumentString(argc, (const char **)argv, "file", (char **)&ref_file);
-        }
-    }
-
-    printf("\n");
-
-    runTest(argc, argv, ref_file);
-
-    printf("%s completed, returned %s\n", sSDKsample, (g_TotalErrors == 0) ? "OK" : "ERROR!");
-    exit(g_TotalErrors == 0 ? EXIT_SUCCESS : EXIT_FAILURE);
-}
-
-void computeFPS()
-{
-    frameCount++;
-    fpsCount++;
-
-    if (fpsCount == fpsLimit)
-    {
-        avgFPS = 1.f / (sdkGetAverageTimerValue(&timer) / 1000.f);
-        fpsCount = 0;
-        fpsLimit = (int)MAX(avgFPS, 1.f);
-
-        sdkResetTimer(&timer);
-    }
-
-    char fps[256];
-    sprintf(fps, "Cuda GL Interop (VBO): %3.1f fps (Max 100Hz)", avgFPS);
-    glutSetWindowTitle(fps);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Initialize GL
-////////////////////////////////////////////////////////////////////////////////
-bool initGL(int *argc, char **argv)
-{
-    glutInit(argc, argv);
-    glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE);
-    glutInitWindowSize(window_width, window_height);
-    glutCreateWindow("Cuda GL Interop (VBO)");
-    glutDisplayFunc(display);
-    glutKeyboardFunc(keyboard);
-    glutMotionFunc(motion);
-    glutTimerFunc(REFRESH_DELAY, timerEvent,0);
-
-    // initialize necessary OpenGL extensions
-    if (! isGLVersionSupported(2,0))
-    {
-        fprintf(stderr, "ERROR: Support for necessary OpenGL extensions missing.");
-        fflush(stderr);
-        return false;
-    }
-
-    // default initialization
-    glClearColor(0.0, 0.0, 0.0, 1.0);
-    glDisable(GL_DEPTH_TEST);
-
-    // viewport
-    glViewport(0, 0, window_width, window_height);
-
-    // projection
-    glMatrixMode(GL_PROJECTION);
-    glLoadIdentity();
-    gluPerspective(60.0, (GLfloat)window_width / (GLfloat) window_height, 0.1, 10.0);
-
-    SDK_CHECK_ERROR_GL();
-
-    return true;
-}
-
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run a simple test for CUDA
-////////////////////////////////////////////////////////////////////////////////
-bool runTest(int argc, char **argv, char *ref_file)
-{
-    // Create the CUTIL timer
-    sdkCreateTimer(&timer);
-
-    // use command-line specified CUDA device, otherwise use device with highest Gflops/s
-    int devID = findCudaDevice(argc, (const char **)argv);
-
-    // command line mode only
-    if (ref_file != NULL)
-    {
-        // create VBO
-        HIPCHECK(hipMalloc((void **)&d_vbo_buffer, mesh_width*mesh_height*4*sizeof(float)));
-
-        // run the cuda part
-        runAutoTest(devID, argv, ref_file);
-
-        // check result of Cuda step
-        checkResultCuda(argc, argv, vbo);
-
-        hipFree(d_vbo_buffer);
-        d_vbo_buffer = NULL;
-    }
-    else
-    {
-        // First initialize OpenGL context, so we can properly set the GL for CUDA.
-        // This is necessary in order to achieve optimal performance with OpenGL/CUDA interop.
-        if (false == initGL(&argc, argv))
-        {
-            return false;
-        }
-
-        // register callbacks
-        glutDisplayFunc(display);
-        glutKeyboardFunc(keyboard);
-        glutMouseFunc(mouse);
-        glutMotionFunc(motion);
-#if defined (__APPLE__) || defined(MACOSX)
-        atexit(cleanup);
-#else
-        glutCloseFunc(cleanup);
-#endif
-
-        // create VBO
-        createVBO(&vbo, &cuda_vbo_resource, cudaGraphicsMapFlagsWriteDiscard);
-
-        // run the cuda part
-        runCuda(&cuda_vbo_resource);
-
-        // start rendering mainloop
-        glutMainLoop();
-    }
-
-    return true;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run the Cuda part of the computation
-////////////////////////////////////////////////////////////////////////////////
-void runCuda(struct hipGraphicsResource **vbo_resource)
-{
-    // map OpenGL buffer object for writing from CUDA
-    float4 *dptr;
-    HIPCHECK(hipGraphicsMapResources(1, vbo_resource, 0));
-    size_t num_bytes;
-    HIPCHECK(hipGraphicsResourceGetMappedPointer((void **)&dptr, &num_bytes,
-                                                         *vbo_resource));
-    //printf("CUDA mapped VBO: May access %ld bytes\n", num_bytes);
-
-    // execute the kernel
-    //    dim3 block(8, 8, 1);
-    //    dim3 grid(mesh_width / block.x, mesh_height / block.y, 1);
-    //    kernel<<< grid, block>>>(dptr, mesh_width, mesh_height, g_fAnim);
-
-    launch_kernel(dptr, mesh_width, mesh_height, g_fAnim);
-
-    // unmap buffer object
-    HIPCHECK(hipGraphicsUnmapResources(1, vbo_resource, 0));
-}
-
-#ifdef _WIN32
-#ifndef FOPEN
-#define FOPEN(fHandle,filename,mode) fopen_s(&fHandle, filename, mode)
-#endif
-#else
-#ifndef FOPEN
-#define FOPEN(fHandle,filename,mode) (fHandle = fopen(filename, mode))
-#endif
-#endif
-
-void sdkDumpBin2(void *data, unsigned int bytes, const char *filename)
-{
-    printf("sdkDumpBin: <%s>\n", filename);
-    FILE *fp;
-    FOPEN(fp, filename, "wb");
-    fwrite(data, bytes, 1, fp);
-    fflush(fp);
-    fclose(fp);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run the Cuda part of the computation
-////////////////////////////////////////////////////////////////////////////////
-void runAutoTest(int devID, char **argv, char *ref_file)
-{
-    char *reference_file = NULL;
-    void *imageData = malloc(mesh_width*mesh_height*sizeof(float));
-
-    // execute the kernel
-    launch_kernel((float4 *)d_vbo_buffer, mesh_width, mesh_height, g_fAnim);
-
-    hipDeviceSynchronize();
-    getLastCudaError("launch_kernel failed");
-
-    HIPCHECK(hipMemcpy(imageData, d_vbo_buffer, mesh_width*mesh_height*sizeof(float), hipMemcpyDeviceToHost));
-
-    sdkDumpBin2(imageData, mesh_width*mesh_height*sizeof(float), "simpleGL.bin");
-    reference_file = sdkFindFilePath(ref_file, argv[0]);
-
-    if (reference_file &&
-        !sdkCompareBin2BinFloat("simpleGL.bin", reference_file,
-                                mesh_width*mesh_height*sizeof(float),
-                                MAX_EPSILON_ERROR, THRESHOLD, pArgv[0]))
-    {
-        g_TotalErrors++;
-    }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Create VBO
-////////////////////////////////////////////////////////////////////////////////
-void createVBO(GLuint *vbo, struct hipGraphicsResource **vbo_res,
-               unsigned int vbo_res_flags)
-{
-    assert(vbo);
-
-    // create buffer object
-    glGenBuffers(1, vbo);
-    glBindBuffer(GL_ARRAY_BUFFER, *vbo);
-
-    // initialize buffer object
-    unsigned int size = mesh_width * mesh_height * 4 * sizeof(float);
-    glBufferData(GL_ARRAY_BUFFER, size, 0, GL_DYNAMIC_DRAW);
-
-    glBindBuffer(GL_ARRAY_BUFFER, 0);
-
-    // register this buffer object with CUDA
-    HIPCHECK(hipGraphicsGLRegisterBuffer(vbo_res, *vbo, vbo_res_flags));
-
-    SDK_CHECK_ERROR_GL();
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Delete VBO
-////////////////////////////////////////////////////////////////////////////////
-void deleteVBO(GLuint *vbo, struct hipGraphicsResource *vbo_res)
-{
-
-    // unregister this buffer object with CUDA
-    HIPCHECK(hipGraphicsUnregisterResource(vbo_res));
-
-    glBindBuffer(1, *vbo);
-    glDeleteBuffers(1, vbo);
-
-    *vbo = 0;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Display callback
-////////////////////////////////////////////////////////////////////////////////
-void display()
-{
-    sdkStartTimer(&timer);
-
-    // run CUDA kernel to generate vertex positions
-    runCuda(&cuda_vbo_resource);
-
-    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
-
-    // set view matrix
-    glMatrixMode(GL_MODELVIEW);
-    glLoadIdentity();
-    glTranslatef(0.0, 0.0, translate_z);
-    glRotatef(rotate_x, 1.0, 0.0, 0.0);
-    glRotatef(rotate_y, 0.0, 1.0, 0.0);
-
-    // render from the vbo
-    glBindBuffer(GL_ARRAY_BUFFER, vbo);
-    glVertexPointer(4, GL_FLOAT, 0, 0);
-
-    glEnableClientState(GL_VERTEX_ARRAY);
-    glColor3f(1.0, 0.0, 0.0);
-    glDrawArrays(GL_POINTS, 0, mesh_width * mesh_height);
-    glDisableClientState(GL_VERTEX_ARRAY);
-
-    glutSwapBuffers();
-
-    g_fAnim += 0.01f;
-
-    sdkStopTimer(&timer);
-    computeFPS();
-}
-
-void timerEvent(int value)
-{
-    if (glutGetWindow())
-    {
-        glutPostRedisplay();
-        glutTimerFunc(REFRESH_DELAY, timerEvent,0);
-    }
-}
-
-void cleanup()
-{
-    sdkDeleteTimer(&timer);
-
-    if (vbo)
-    {
-        deleteVBO(&vbo, cuda_vbo_resource);
-    }
-}
-
-
-////////////////////////////////////////////////////////////////////////////////
-//! Keyboard events handler
-////////////////////////////////////////////////////////////////////////////////
-void keyboard(unsigned char key, int /*x*/, int /*y*/)
-{
-    switch (key)
-    {
-        case (27) :
-            #if defined(__APPLE__) || defined(MACOSX)
-                exit(EXIT_SUCCESS);
-            #else
-                glutDestroyWindow(glutGetWindow());
-                return;
-            #endif
-    }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Mouse event handlers
-////////////////////////////////////////////////////////////////////////////////
-void mouse(int button, int state, int x, int y)
-{
-    if (state == GLUT_DOWN)
-    {
-        mouse_buttons |= 1<<button;
-    }
-    else if (state == GLUT_UP)
-    {
-        mouse_buttons = 0;
-    }
-
-    mouse_old_x = x;
-    mouse_old_y = y;
-}
-
-void motion(int x, int y)
-{
-    float dx, dy;
-    dx = (float)(x - mouse_old_x);
-    dy = (float)(y - mouse_old_y);
-
-    if (mouse_buttons & 1)
-    {
-        rotate_x += dy * 0.2f;
-        rotate_y += dx * 0.2f;
-    }
-    else if (mouse_buttons & 4)
-    {
-        translate_z += dy * 0.01f;
-    }
-
-    mouse_old_x = x;
-    mouse_old_y = y;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Check if the result is correct or write data to file for external
-//! regression testing
-////////////////////////////////////////////////////////////////////////////////
-void checkResultCuda(int argc, char **argv, const GLuint &vbo)
-{
-    if (!d_vbo_buffer)
-    {
-        HIPCHECK(hipGraphicsUnregisterResource(cuda_vbo_resource));
-
-        // map buffer object
-        glBindBuffer(GL_ARRAY_BUFFER, vbo);
-        float *data = (float *) glMapBuffer(GL_ARRAY_BUFFER, GL_READ_ONLY);
-
-        // check result
-        if (checkCmdLineFlag(argc, (const char **) argv, "regression"))
-        {
-            // write file for regression test
-            sdkWriteFile<float>("./data/regression.dat",
-                                data, mesh_width * mesh_height * 3, 0.0, false);
-        }
-
-        // unmap GL buffer object
-        if (!glUnmapBuffer(GL_ARRAY_BUFFER))
-        {
-            fprintf(stderr, "Unmap buffer failed.\n");
-            fflush(stderr);
-        }
-
-        HIPCHECK(hipGraphicsGLRegisterBuffer(&cuda_vbo_resource, vbo,
-                                                     cudaGraphicsMapFlagsWriteDiscard));
-
-        SDK_CHECK_ERROR_GL();
-    }
-}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2017.sln b/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2019.sln b/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2022.sln b/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleGL/simpleGL_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/simpleGLES/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/simpleGLES/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/simpleGLES/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/simpleGLES/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/Makefile b/src/samples/Samples/5_Domain_Specific/simpleGLES/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/simpleGLES/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/README.md b/src/samples/Samples/5_Domain_Specific/simpleGLES/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/data/ref_simpleGL.bin b/src/samples/Samples/5_Domain_Specific/simpleGLES/data/ref_simpleGL.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/findgleslib.mk b/src/samples/Samples/5_Domain_Specific/simpleGLES/findgleslib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/graphics_interface.c b/src/samples/Samples/5_Domain_Specific/simpleGLES/graphics_interface.c
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/mesh.frag.glsl b/src/samples/Samples/5_Domain_Specific/simpleGLES/mesh.frag.glsl
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/mesh.vert.glsl b/src/samples/Samples/5_Domain_Specific/simpleGLES/mesh.vert.glsl
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/simpleGLES.cu b/src/samples/Samples/5_Domain_Specific/simpleGLES/simpleGLES.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES/simpleGLES.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleGLES/simpleGLES.cu.hip
old mode 100644
new mode 100755
index 4e4f62b..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES/simpleGLES.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES/simpleGLES.cu.hip
@@ -1,630 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
-    This example demonstrates how to use the CUDA C bindings to OpenGL ES to
-    dynamically modify a vertex buffer using a CUDA C kernel.
-
-    The steps are:
-    1. Create an empty vertex buffer object (VBO)
-    2. Register the VBO with CUDA C
-    3. Map the VBO for writing from CUDA C
-    4. Run CUDA C kernel to modify the vertex positions
-    5. Unmap the VBO
-    6. Render the results using OpenGL ES
-
-    Host code
-*/
-
-// includes, system
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-
-#include <stdarg.h>
-#include <unistd.h>
-#include <X11/Xlib.h>
-#include <X11/Xutil.h>
-
-void error_exit(const char *format, ...) {
-  va_list args;
-  va_start(args, format);
-  vfprintf(stderr, format, args);
-  va_end(args);
-  exit(1);
-}
-
-#include "graphics_interface.c"
-
-#ifdef _WIN32
-#define WINDOWS_LEAN_AND_MEAN
-#define NOMINMAX
-#include <windows.h>
-#endif
-
-// includes, cuda
-#include <hip/hip_runtime.h>
-#include <cuda_gl_interop.h>
-
-// Utilities and timing functions
-#include "helper_functions.h"  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
-
-// CUDA helper functions
-#include "helper_cuda_hipified.h"  // helper functions for CUDA error check
-//#include <helper_cuda_gl.h>      // helper functions for CUDA/GL interop
-
-#include <hip/hip_vector_types.h>
-
-#define MAX_EPSILON_ERROR 0.0f
-#define THRESHOLD 0.0f
-#define REFRESH_DELAY 1  // ms
-
-#define GUI_IDLE 0x100
-#define GUI_ROTATE 0x101
-#define GUI_TRANSLATE 0x102
-
-int gui_mode;
-
-////////////////////////////////////////////////////////////////////////////////
-// constants
-const unsigned int window_width = 512;
-const unsigned int window_height = 512;
-
-const unsigned int mesh_width = 256;
-const unsigned int mesh_height = 256;
-
-// OpenGL ES variables and interop with CUDA C
-GLuint mesh_vao, mesh_vbo;
-struct hipGraphicsResource *cuda_vbo_resource;
-void *d_vbo_buffer = NULL;
-
-float g_fAnim = 0.0;
-
-// UI / mouse controls
-int mouse_old_x, mouse_old_y;
-int mouse_buttons = 0;
-float rotate_x = 0.0, rotate_y = 0.0;
-float translate_z = -3.0;
-
-StopWatchInterface *timer = NULL;
-
-// Frame statistics
-int frame;
-int fpsCount = 0;  // FPS count for averaging
-int fpsLimit = 1;  // FPS limit for sampling
-int g_Index = 0;
-float avgFPS = 0.0f;
-unsigned int frameCount = 0;
-unsigned int g_TotalErrors = 0;
-
-// Auto-Verification Code
-bool g_bQAReadback = false;
-
-int *pArgc = NULL;
-char **pArgv = NULL;
-
-#define MAX(a, b) ((a > b) ? a : b)
-
-////////////////////////////////////////////////////////////////////////////////
-// declaration, forward
-
-// CUDA functionality
-void runCuda(struct hipGraphicsResource **vbo_resource);
-void runAutoTest(int devID, char **argv, char *ref_file);
-void checkResultCuda(int argc, char **argv, const GLuint &vbo);
-
-const char *sSDKsample = "simpleGLES (VBO)";
-
-void computeFPS() {
-  frameCount++;
-  fpsCount++;
-
-  if (fpsCount == fpsLimit) {
-    avgFPS = 1.f / (sdkGetAverageTimerValue(&timer) / 1000.f);
-    fpsCount = 0;
-    fpsLimit = (int)MAX(avgFPS, 1.f);
-
-    sdkResetTimer(&timer);
-  }
-
-  char fps[256];
-  sprintf(fps, "Cuda/OpenGL ES Interop (VBO): %3.1f fps (Max 1000 fps)",
-          avgFPS);
-  graphics_set_windowtitle(fps);
-}
-
-///////////////////////////////////////////////////////////////////////////////
-//! Simple kernel to modify vertex positions in sine wave pattern
-//! @param data  data in global memory
-///////////////////////////////////////////////////////////////////////////////
-__global__ void simple_vbo_kernel(float4 *pos, unsigned int width,
-                                  unsigned int height, float time) {
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  // calculate uv coordinates
-  float u = x / (float)width;
-  float v = y / (float)height;
-  u = u * 2.0f - 1.0f;
-  v = v * 2.0f - 1.0f;
-
-  // calculate simple sine wave pattern
-  float freq = 4.0f;
-  float w = sinf(u * freq + time) * cosf(v * freq + time) * 0.5f;
-
-  // write output vertex
-  pos[y * width + x] = make_float4(u, w, v, 1.0f);
-}
-
-void launch_kernel(float4 *pos, unsigned int mesh_width,
-                   unsigned int mesh_height, float time) {
-  // execute the kernel
-  dim3 block(8, 8, 1);
-  dim3 grid(mesh_width / block.x, mesh_height / block.y, 1);
-  simple_vbo_kernel<<<grid, block>>>(pos, mesh_width, mesh_height, time);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run the Cuda part of the computation
-////////////////////////////////////////////////////////////////////////////////
-void runCuda(struct hipGraphicsResource **vbo_resource) {
-  // map OpenGL buffer object for writing from CUDA
-  float4 *dptr;
-  hipGraphicsMapResources(1, vbo_resource, 0);
-  size_t num_bytes;
-  hipGraphicsResourceGetMappedPointer((void **)&dptr, &num_bytes,
-                                       *vbo_resource);
-  // printf("Sample CUDA mapped VBO: May access %ld bytes\n", num_bytes);
-
-  // execute the kernel
-  //    dim3 block(8, 8, 1);
-  //    dim3 grid(mesh_width / block.x, mesh_height / block.y, 1);
-  //    kernel<<< grid, block>>>(dptr, mesh_width, mesh_height, g_fAnim);
-
-  launch_kernel(dptr, mesh_width, mesh_height, g_fAnim);
-
-  // unmap buffer object
-  hipGraphicsUnmapResources(1, vbo_resource, 0);
-}
-
-#ifdef _WIN32
-#ifndef FOPEN
-#define FOPEN(fHandle, filename, mode) fopen_s(&fHandle, filename, mode)
-#endif
-#else
-#ifndef FOPEN
-#define FOPEN(fHandle, filename, mode) (fHandle = fopen(filename, mode))
-#endif
-#endif
-
-void sdkDumpBin2(void *data, unsigned int bytes, const char *filename) {
-  printf("sdkDumpBin: <%s>\n", filename);
-  FILE *fp;
-  FOPEN(fp, filename, "wb");
-  fwrite(data, bytes, 1, fp);
-  fflush(fp);
-  fclose(fp);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run the Cuda part of the computation
-////////////////////////////////////////////////////////////////////////////////
-void runAutoTest(int devID, char **argv, char *ref_file) {
-  char *reference_file = NULL;
-  void *imageData = malloc(mesh_width * mesh_height * sizeof(float));
-
-  // execute the kernel
-  launch_kernel((float4 *)d_vbo_buffer, mesh_width, mesh_height, g_fAnim);
-
-  hipDeviceSynchronize();
-  getLastCudaError("launch_kernel failed");
-
-  hipMemcpy(imageData, d_vbo_buffer, mesh_width * mesh_height * sizeof(float),
-             hipMemcpyDeviceToHost);
-
-  sdkDumpBin2(imageData, mesh_width * mesh_height * sizeof(float),
-              "simpleGL.bin");
-  reference_file = sdkFindFilePath(ref_file, argv[0]);
-
-  if (reference_file &&
-      !sdkCompareBin2BinFloat("simpleGL.bin", reference_file,
-                              mesh_width * mesh_height * sizeof(float),
-                              MAX_EPSILON_ERROR, THRESHOLD, pArgv[0])) {
-    g_TotalErrors++;
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Display callback
-////////////////////////////////////////////////////////////////////////////////
-void display_thisframe(float time_delta) {
-  sdkStartTimer(&timer);
-
-  // run CUDA kernel to generate vertex positions
-  runCuda(&cuda_vbo_resource);
-
-  glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
-  // GET_GLERROR(0);
-
-  // set view matrix: broken, it doesn't work in OpenGL ES! Must put into shader
-  // glMatrixMode(GL_MODELVIEW);
-  // glLoadIdentity();
-  // glTranslatef(0.0, 0.0, translate_z);
-  // glRotatef(rotate_x, 1.0, 0.0, 0.0);
-  // glRotatef(rotate_y, 0.0, 1.0, 0.0);
-
-  glDrawArrays(GL_POINTS, 0, mesh_width * mesh_height);
-
-  // GET_GLERROR(0);
-  glFinish();
-  // GET_GLERROR(0);
-
-  g_fAnim += time_delta;
-
-  sdkStopTimer(&timer);
-  computeFPS();
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Check if the result is correct or write data to file for external
-//! regression testing
-////////////////////////////////////////////////////////////////////////////////
-void checkResultCuda(int argc, char **argv, const GLuint &vbo) {
-  if (!d_vbo_buffer) {
-    printf("%s: Mapping result buffer from OpenGL ES\n", __FUNCTION__);
-
-    hipGraphicsUnregisterResource(cuda_vbo_resource);
-
-    // map buffer object
-    glBindBuffer(GL_ARRAY_BUFFER, vbo);
-    float *data = (float *)glMapBufferRange(
-        GL_ARRAY_BUFFER, 0, mesh_width * mesh_height * 4 * sizeof(float),
-        GL_READ_ONLY);
-
-    // check result
-    if (checkCmdLineFlag(argc, (const char **)argv, "regression")) {
-      // write file for regression test
-      sdkWriteFile<float>("./data/regression.dat", data,
-                          mesh_width * mesh_height * 3, 0.0, false);
-    }
-
-    // unmap GL buffer object
-    if (!glUnmapBuffer(GL_ARRAY_BUFFER)) {
-      fprintf(stderr, "Unmap buffer failed.\n");
-      fflush(stderr);
-    }
-
-    HIPCHECK(hipGraphicsGLRegisterBuffer(
-        &cuda_vbo_resource, vbo, cudaGraphicsMapFlagsWriteDiscard));
-
-    GET_GLERROR(0);
-  }
-}
-
-GLuint mesh_shader = 0;
-
-void readAndCompileShaderFromGLSLFile(GLuint new_shaderprogram,
-                                      const char *filename, GLenum shaderType) {
-  FILE *file = fopen(filename, "rb");  // open shader text file
-  if (!file) error_exit("Filename %s does not exist\n", filename);
-
-  /* get the size of the file and read it */
-  fseek(file, 0, SEEK_END);
-  GLint size = ftell(file);
-  char *data = (char *)malloc(sizeof(char) * (size + 1));
-  memset(data, 0, sizeof(char) * (size + 1));
-  fseek(file, 0, SEEK_SET);
-  size_t res = fread(data, 1, size, file);
-  fclose(file);
-
-  GLuint shader = glCreateShader(shaderType);
-  glShaderSource(shader, 1, (const GLchar **)&data, &size);
-  glCompileShader(shader);
-
-  GET_GLERROR(0);
-  GLint compile_success = 0;
-  glGetShaderiv(shader, GL_COMPILE_STATUS, &compile_success);
-  GET_GLERROR(0);
-
-  if (compile_success == GL_FALSE) {
-    printf("Compilation of %s failed!\n Reason:\n", filename);
-
-    GLint maxLength = 0;
-    glGetShaderiv(shader, GL_INFO_LOG_LENGTH, &maxLength);
-
-    char errorLog[maxLength];
-    glGetShaderInfoLog(shader, maxLength, &maxLength, &errorLog[0]);
-
-    printf("%s", errorLog);
-
-    glDeleteShader(shader);
-    exit(1);
-  }
-
-  glAttachShader(new_shaderprogram, shader);
-  glDeleteShader(shader);  // good to do?
-
-  free(data);
-}
-
-GLuint ShaderCreate(const char *vshader_filename,
-                    const char *fshader_filename) {
-  printf("Loading GLSL shaders %s %s\n", vshader_filename, fshader_filename);
-
-  GLuint new_shaderprogram = glCreateProgram();
-
-  GET_GLERROR(0);
-  if (vshader_filename)
-    readAndCompileShaderFromGLSLFile(new_shaderprogram, vshader_filename,
-                                     GL_VERTEX_SHADER);
-
-  GET_GLERROR(0);
-  if (fshader_filename)
-    readAndCompileShaderFromGLSLFile(new_shaderprogram, fshader_filename,
-                                     GL_FRAGMENT_SHADER);
-
-  GET_GLERROR(0);
-
-  glLinkProgram(new_shaderprogram);
-
-  GET_GLERROR(0);
-  GLint link_success;
-  glGetProgramiv(new_shaderprogram, GL_LINK_STATUS, &link_success);
-
-  if (link_success == GL_FALSE) {
-    printf("Linking of %s with %s failed!\n Reason:\n", vshader_filename,
-           fshader_filename);
-
-    GLint maxLength = 0;
-    glGetShaderiv(new_shaderprogram, GL_INFO_LOG_LENGTH, &maxLength);
-
-    char errorLog[maxLength];
-    glGetShaderInfoLog(new_shaderprogram, maxLength, &maxLength, &errorLog[0]);
-
-    printf("%s", errorLog);
-
-    exit(EXIT_FAILURE);
-  }
-
-  return new_shaderprogram;
-}
-
-//===========================================================================
-// InitGraphicsState() - initialize OpenGL
-//===========================================================================
-static void InitGraphicsState(void) {
-  char *GL_version = (char *)glGetString(GL_VERSION);
-  char *GL_vendor = (char *)glGetString(GL_VENDOR);
-  char *GL_renderer = (char *)glGetString(GL_RENDERER);
-
-  printf("Version: %s\n", GL_version);
-  printf("Vendor: %s\n", GL_vendor);
-  printf("Renderer: %s\n", GL_renderer);
-
-  // RENDERING SETUP (OpenGL ES or OpenGL Core Profile!)
-  glGenVertexArrays(1, &mesh_vao);  // Features' Vertex Array Object allocation
-  glBindVertexArray(mesh_vao);      // bind VAO
-
-  // initialize buffer object
-  glGenBuffers(1, &mesh_vbo);
-  glBindBuffer(GL_ARRAY_BUFFER, mesh_vbo);
-
-  unsigned int size = mesh_width * mesh_height * 4 * sizeof(float);
-  glBufferData(GL_ARRAY_BUFFER, size, NULL, GL_DYNAMIC_DRAW);
-  glVertexAttribPointer((GLuint)0, 4, GL_FLOAT, GL_FALSE, 0, 0);
-  glEnableVertexAttribArray(0);
-
-  HIPCHECK(hipGraphicsGLRegisterBuffer(&cuda_vbo_resource, mesh_vbo,
-                                               cudaGraphicsMapFlagsNone));
-  // glBindVertexArray(0); // keep above Vertex Array Object bound (it's the
-  // only one throughout)
-
-  // GLSL stuff
-  char *vertex_shader_path = sdkFindFilePath("mesh.vert.glsl", pArgv[0]);
-  char *fragment_shader_path = sdkFindFilePath("mesh.frag.glsl", pArgv[0]);
-
-  if (vertex_shader_path == NULL || fragment_shader_path == NULL) {
-    printf("Error finding shader file\n");
-    exit(EXIT_FAILURE);
-  }
-
-  mesh_shader = ShaderCreate(vertex_shader_path, fragment_shader_path);
-  GET_GLERROR(0);
-
-  free(vertex_shader_path);
-  free(fragment_shader_path);
-
-  glUseProgram(mesh_shader);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run a simple test for CUDA
-////////////////////////////////////////////////////////////////////////////////
-bool runTest(int argc, char **argv, char *ref_file) {
-  // Create the CUTIL timer
-  sdkCreateTimer(&timer);
-
-  int devID = 0;
-#if defined(__aarch64__) || defined(__arm__)
-  // find iGPU on the system which is compute capable which will perform
-  // GLES-CUDA interop
-  devID = findIntegratedGPU();
-#else
-  // use command-line specified CUDA device, otherwise use device with highest
-  // Gflops/s
-  devID = findCudaDevice(argc, (const char **)argv);
-#endif
-
-  // command line mode only
-  if (ref_file != NULL) {
-    // create VBO
-    HIPCHECK(hipMalloc((void **)&d_vbo_buffer,
-                               mesh_width * mesh_height * 4 * sizeof(float)));
-
-    // run the cuda part
-    runAutoTest(devID, argv, ref_file);
-
-    // check result of Cuda step
-    checkResultCuda(argc, argv, mesh_vbo);
-
-    hipFree(d_vbo_buffer);
-    d_vbo_buffer = NULL;
-  } else {
-    // this would use command-line specified CUDA device, note that CUDA
-    // defaults to highest Gflops/s device
-    if (checkCmdLineFlag(argc, (const char **)argv, "device"))
-      error_exit("Device setting not yet implemented!\n");
-
-    // create X11 window and set up associated OpenGL ES context
-    graphics_setup_window(0, 0, window_width, window_height, sSDKsample);
-
-    InitGraphicsState();  // set up GLES stuff
-
-    glClearColor(0, 0.5, 1, 1);  // blue-ish background
-    glClear(GL_COLOR_BUFFER_BIT);
-
-    // printf("WP%d\n", __LINE__);
-    graphics_swap_buffers();
-
-    XEvent event;
-    KeySym key;
-    char text[255];
-
-    int frame = 0;
-
-    while (frame < 100000) {
-      if (XPending(display)) {
-        XNextEvent(display, &event);
-
-        if (event.type == Expose && event.xexpose.count == 0) {
-          printf("Redraw requested!\n");
-        }
-        if (event.type == KeyPress &&
-            XLookupString(&event.xkey, text, 255, &key, 0) == 1) {
-          if (text[0] == 27) goto label_stop_x;
-
-          printf("You pressed the %c key!\n", text[0]);
-        }
-
-        if (event.type == ButtonPress) {
-          printf("Mouse button %d press at (%d,%d)\n", event.xbutton.button,
-                 event.xbutton.x, event.xbutton.y);
-
-          if (event.xbutton.button == Button1) gui_mode = GUI_TRANSLATE;
-          if (event.xbutton.button == Button3) gui_mode = GUI_ROTATE;
-          mouse_old_x = event.xbutton.x;
-          mouse_old_y = event.xbutton.y;
-        }
-
-        if (event.type == ButtonRelease) {
-          printf("Mouse button %d released at (%d,%d)\n", event.xbutton.button,
-                 event.xbutton.x, event.xbutton.y);
-
-          gui_mode = GUI_IDLE;
-          mouse_old_x = event.xbutton.x;
-          mouse_old_y = event.xbutton.y;
-        }
-
-        if (event.type == MotionNotify) {
-          // printf("Mouse motion towards %d %d, GUI mode is 0x%x\n",
-          //	   event.xmotion.x, event.xmotion.y, gui_mode);
-          float dx, dy;
-          dx = (float)(event.xmotion.x - mouse_old_x);
-          dy = (float)(event.xmotion.y - mouse_old_y);
-
-          if (gui_mode == GUI_ROTATE) {
-            rotate_x += dy * 0.2f;
-            rotate_y += dx * 0.2f;
-            printf("rot x %f y %f\n", rotate_x, rotate_y);
-          }
-          if (gui_mode == GUI_TRANSLATE) {
-            translate_z += dy * 0.01f;
-            printf("translate z %f\n", translate_z);
-          }
-
-          mouse_old_x = event.xmotion.x;
-          mouse_old_y = event.xmotion.y;
-        }
-      }
-
-      display_thisframe(0.010);
-      usleep(1000);  // need not take full CPU and GPU
-
-      graphics_swap_buffers();
-      // printf("frame %d\n",frame++);
-    }
-
-  label_stop_x:
-    // NOTE: Before destroying OpenGL ES context, must unregister all shared
-    // resources from CUDA !
-    hipGraphicsUnregisterResource(cuda_vbo_resource);
-
-    graphics_close_window();  // close window and destroy OpenGL ES context
-
-    sdkDeleteTimer(&timer);
-  }
-
-  return true;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  char *ref_file = NULL;
-
-  pArgc = &argc;
-  pArgv = argv;
-
-#if defined(__linux__)
-  setenv("DISPLAY", ":0", 0);
-#endif
-
-  printf("%s starting...\n", sSDKsample);
-
-  if (argc > 1) {
-    if (checkCmdLineFlag(argc, (const char **)argv, "file")) {
-      // In this mode, we run without OpenGL and see if VBO is generated
-      // correctly
-      getCmdLineArgumentString(argc, (const char **)argv, "file",
-                               (char **)&ref_file);
-    }
-  }
-
-  printf("\n");
-
-  runTest(argc, argv, ref_file);
-
-  printf("%s completed, returned %s\n", sSDKsample,
-         (g_TotalErrors == 0) ? "OK" : "ERROR!");
-
-  exit(g_TotalErrors == 0 ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/Makefile b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/README.md b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/data/ref_simpleGLES_EGLOutput.bin b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/data/ref_simpleGLES_EGLOutput.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/findgleslib.mk b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/findgleslib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/graphics_interface_egloutput_via_egl.c b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/graphics_interface_egloutput_via_egl.c
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/mesh.frag.glsl b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/mesh.frag.glsl
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/mesh.vert.glsl b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/mesh.vert.glsl
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/simpleGLES_EGLOutput.cu b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/simpleGLES_EGLOutput.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/simpleGLES_EGLOutput.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/simpleGLES_EGLOutput.cu.hip
old mode 100644
new mode 100755
index 6e73321..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/simpleGLES_EGLOutput.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES_EGLOutput/simpleGLES_EGLOutput.cu.hip
@@ -1,574 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
-    This example demonstrates how to use the CUDA C bindings to OpenGL ES to
-    dynamically modify a vertex buffer using a CUDA C kernel.
-
-    The steps are:
-    1. Create an empty vertex buffer object (VBO)
-    2. Register the VBO with CUDA C
-    3. Map the VBO for writing from CUDA C
-    4. Run CUDA C kernel to modify the vertex positions
-    5. Unmap the VBO
-    6. Render the results using OpenGL ES
-
-    Host code
-*/
-
-// includes, system
-#include <math.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <stdlib.h>
-#include <string.h>
-
-#include <stdarg.h>
-#include <unistd.h>
-
-void error_exit(const char *format, ...) {
-  va_list args;
-  va_start(args, format);
-  vfprintf(stderr, format, args);
-  va_end(args);
-  exit(1);
-}
-
-#if 0
-#include "graphics_interface.c"
-#else
-#include "graphics_interface_egloutput_via_egl.c"
-#endif
-
-#ifdef _WIN32
-#define WINDOWS_LEAN_AND_MEAN
-#define NOMINMAX
-#include <windows.h>
-#endif
-
-// includes, cuda
-#include <cuda_gl_interop.h>
-#include <hip/hip_runtime.h>
-
-// Utilities and timing functions
-#include "helper_functions.h"  // includes hip/hip_runtime.h and hip/hip_runtime_api.h
-
-// CUDA helper functions
-#include "helper_cuda_hipified.h"  // helper functions for CUDA error check
-  //#include <helper_cuda_gl.h>      // helper functions for CUDA/GL interop
-
-#include <hip/hip_vector_types.h>
-
-#define MAX_EPSILON_ERROR 0.0f
-#define THRESHOLD 0.0f
-#define REFRESH_DELAY 1  // ms
-
-#define GUI_IDLE 0x100
-#define GUI_ROTATE 0x101
-#define GUI_TRANSLATE 0x102
-
-int gui_mode;
-
-////////////////////////////////////////////////////////////////////////////////
-// constants
-const unsigned int window_width = 512;
-const unsigned int window_height = 512;
-
-const unsigned int mesh_width = 256;
-const unsigned int mesh_height = 256;
-
-// OpenGL ES variables and interop with CUDA C
-GLuint mesh_vao, mesh_vbo;
-struct hipGraphicsResource *cuda_vbo_resource;
-void *d_vbo_buffer = NULL;
-
-float g_fAnim = 0.0;
-
-// UI / mouse controls
-int mouse_old_x, mouse_old_y;
-int mouse_buttons = 0;
-float rotate_x = 0.0, rotate_y = 0.0;
-float translate_z = -3.0;
-
-StopWatchInterface *timer = NULL;
-
-// Frame statistics
-int frame;
-int fpsCount = 0;  // FPS count for averaging
-int fpsLimit = 1;  // FPS limit for sampling
-int g_Index = 0;
-float avgFPS = 0.0f;
-unsigned int frameCount = 0;
-unsigned int g_TotalErrors = 0;
-
-// Auto-Verification Code
-bool g_bQAReadback = false;
-
-int *pArgc = NULL;
-char **pArgv = NULL;
-
-#define MAX(a, b) ((a > b) ? a : b)
-
-////////////////////////////////////////////////////////////////////////////////
-// declaration, forward
-
-// CUDA functionality
-void runCuda(struct hipGraphicsResource **vbo_resource);
-void runAutoTest(int devID, char **argv, char *ref_file);
-void checkResultCuda(int argc, char **argv, const GLuint &vbo);
-
-const char *sSDKsample = "simpleGLES (VBO)";
-
-void computeFPS() {
-  frameCount++;
-  fpsCount++;
-
-  if (fpsCount == fpsLimit) {
-    avgFPS = 1.f / (sdkGetAverageTimerValue(&timer) / 1000.f);
-    fpsCount = 0;
-    fpsLimit = (int)MAX(avgFPS, 1.f);
-
-    sdkResetTimer(&timer);
-  }
-
-  char fps[256];
-  sprintf(fps, "Cuda/OpenGL ES Interop (VBO): %3.1f fps (Max 1000 fps)",
-          avgFPS);
-  graphics_set_windowtitle(fps);
-}
-
-///////////////////////////////////////////////////////////////////////////////
-//! Simple kernel to modify vertex positions in sine wave pattern
-//! @param data  data in global memory
-///////////////////////////////////////////////////////////////////////////////
-__global__ void simple_vbo_kernel(float4 *pos, unsigned int width,
-                                  unsigned int height, float time) {
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  // calculate uv coordinates
-  float u = x / (float)width;
-  float v = y / (float)height;
-  u = u * 2.0f - 1.0f;
-  v = v * 2.0f - 1.0f;
-
-  // calculate simple sine wave pattern
-  float freq = 4.0f;
-  float w = sinf(u * freq + time) * cosf(v * freq + time) * 0.5f;
-
-  // write output vertex
-  pos[y * width + x] = make_float4(u, w, v, 1.0f);
-}
-
-void launch_kernel(float4 *pos, unsigned int mesh_width,
-                   unsigned int mesh_height, float time) {
-  // execute the kernel
-  dim3 block(8, 8, 1);
-  dim3 grid(mesh_width / block.x, mesh_height / block.y, 1);
-  simple_vbo_kernel<<<grid, block>>>(pos, mesh_width, mesh_height, time);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run the Cuda part of the computation
-////////////////////////////////////////////////////////////////////////////////
-void runCuda(struct hipGraphicsResource **vbo_resource) {
-  // map OpenGL buffer object for writing from CUDA
-  float4 *dptr;
-  hipGraphicsMapResources(1, vbo_resource, 0);
-  size_t num_bytes;
-  hipGraphicsResourceGetMappedPointer((void **)&dptr, &num_bytes,
-                                       *vbo_resource);
-  // printf("Sample CUDA mapped VBO: May access %ld bytes\n", num_bytes);
-
-  // execute the kernel
-  //    dim3 block(8, 8, 1);
-  //    dim3 grid(mesh_width / block.x, mesh_height / block.y, 1);
-  //    kernel<<< grid, block>>>(dptr, mesh_width, mesh_height, g_fAnim);
-
-  launch_kernel(dptr, mesh_width, mesh_height, g_fAnim);
-
-  // unmap buffer object
-  hipGraphicsUnmapResources(1, vbo_resource, 0);
-}
-
-#ifdef _WIN32
-#ifndef FOPEN
-#define FOPEN(fHandle, filename, mode) fopen_s(&fHandle, filename, mode)
-#endif
-#else
-#ifndef FOPEN
-#define FOPEN(fHandle, filename, mode) (fHandle = fopen(filename, mode))
-#endif
-#endif
-
-void sdkDumpBin2(void *data, unsigned int bytes, const char *filename) {
-  printf("sdkDumpBin: <%s>\n", filename);
-  FILE *fp;
-  FOPEN(fp, filename, "wb");
-  fwrite(data, bytes, 1, fp);
-  fflush(fp);
-  fclose(fp);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run the Cuda part of the computation
-////////////////////////////////////////////////////////////////////////////////
-void runAutoTest(int devID, char **argv, char *ref_file) {
-  char *reference_file = NULL;
-  void *imageData = malloc(mesh_width * mesh_height * sizeof(float));
-
-  // execute the kernel
-  launch_kernel((float4 *)d_vbo_buffer, mesh_width, mesh_height, g_fAnim);
-
-  hipDeviceSynchronize();
-  getLastCudaError("launch_kernel failed");
-
-  hipMemcpy(imageData, d_vbo_buffer, mesh_width * mesh_height * sizeof(float),
-             hipMemcpyDeviceToHost);
-
-  sdkDumpBin2(imageData, mesh_width * mesh_height * sizeof(float),
-              "simpleGL.bin");
-  reference_file = sdkFindFilePath(ref_file, argv[0]);
-
-  if (reference_file &&
-      !sdkCompareBin2BinFloat("simpleGL.bin", reference_file,
-                              mesh_width * mesh_height * sizeof(float),
-                              MAX_EPSILON_ERROR, THRESHOLD, pArgv[0])) {
-    g_TotalErrors++;
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Display callback
-////////////////////////////////////////////////////////////////////////////////
-void display_thisframe(float time_delta) {
-  sdkStartTimer(&timer);
-
-  // run CUDA kernel to generate vertex positions
-  runCuda(&cuda_vbo_resource);
-
-  glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
-  // GET_GLERROR(0);
-
-  // set view matrix: broken, it doesn't work in OpenGL ES! Must put into shader
-  // glMatrixMode(GL_MODELVIEW);
-  // glLoadIdentity();
-  // glTranslatef(0.0, 0.0, translate_z);
-  // glRotatef(rotate_x, 1.0, 0.0, 0.0);
-  // glRotatef(rotate_y, 0.0, 1.0, 0.0);
-
-  glDrawArrays(GL_POINTS, 0, mesh_width * mesh_height);
-
-  // GET_GLERROR(0);
-  glFinish();
-  // GET_GLERROR(0);
-
-  g_fAnim += time_delta;
-
-  sdkStopTimer(&timer);
-  computeFPS();
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Check if the result is correct or write data to file for external
-//! regression testing
-////////////////////////////////////////////////////////////////////////////////
-void checkResultCuda(int argc, char **argv, const GLuint &vbo) {
-  if (!d_vbo_buffer) {
-    printf("%s: Mapping result buffer from OpenGL ES\n", __FUNCTION__);
-
-    hipGraphicsUnregisterResource(cuda_vbo_resource);
-
-    // map buffer object
-    glBindBuffer(GL_ARRAY_BUFFER, vbo);
-    float *data = (float *)glMapBufferRange(
-        GL_ARRAY_BUFFER, 0, mesh_width * mesh_height * 4 * sizeof(float),
-        GL_READ_ONLY);
-
-    // check result
-    if (checkCmdLineFlag(argc, (const char **)argv, "regression")) {
-      // write file for regression test
-      sdkWriteFile<float>("./data/regression.dat", data,
-                          mesh_width * mesh_height * 3, 0.0, false);
-    }
-
-    // unmap GL buffer object
-    if (!glUnmapBuffer(GL_ARRAY_BUFFER)) {
-      fprintf(stderr, "Unmap buffer failed.\n");
-      fflush(stderr);
-    }
-
-    HIPCHECK(hipGraphicsGLRegisterBuffer(
-        &cuda_vbo_resource, vbo, cudaGraphicsMapFlagsWriteDiscard));
-
-    GET_GLERROR(0);
-  }
-}
-
-GLuint mesh_shader = 0;
-
-void readAndCompileShaderFromGLSLFile(GLuint new_shaderprogram,
-                                      const char *filename, GLenum shaderType) {
-  FILE *file = fopen(filename, "rb");  // open shader text file
-  if (!file) error_exit("Filename %s does not exist\n", filename);
-
-  /* get the size of the file and read it */
-  fseek(file, 0, SEEK_END);
-  GLint size = ftell(file);
-  char *data = (char *)malloc(sizeof(char) * (size + 1));
-  memset(data, 0, sizeof(char) * (size + 1));
-  fseek(file, 0, SEEK_SET);
-  size_t res = fread(data, 1, size, file);
-  fclose(file);
-
-  GLuint shader = glCreateShader(shaderType);
-  glShaderSource(shader, 1, (const GLchar **)&data, &size);
-  glCompileShader(shader);
-
-  GET_GLERROR(0);
-  GLint compile_success = 0;
-  glGetShaderiv(shader, GL_COMPILE_STATUS, &compile_success);
-  GET_GLERROR(0);
-
-  if (compile_success == GL_FALSE) {
-    printf("Compilation of %s failed!\n Reason:\n", filename);
-
-    GLint maxLength = 0;
-    glGetShaderiv(shader, GL_INFO_LOG_LENGTH, &maxLength);
-
-    char errorLog[maxLength];
-    glGetShaderInfoLog(shader, maxLength, &maxLength, &errorLog[0]);
-
-    printf("%s", errorLog);
-
-    glDeleteShader(shader);
-    exit(1);
-  }
-
-  glAttachShader(new_shaderprogram, shader);
-  glDeleteShader(shader);  // good to do?
-
-  free(data);
-}
-
-GLuint ShaderCreate(const char *vshader_filename,
-                    const char *fshader_filename) {
-  printf("Loading GLSL shaders %s %s\n", vshader_filename, fshader_filename);
-
-  GLuint new_shaderprogram = glCreateProgram();
-
-  GET_GLERROR(0);
-  if (vshader_filename)
-    readAndCompileShaderFromGLSLFile(new_shaderprogram, vshader_filename,
-                                     GL_VERTEX_SHADER);
-
-  GET_GLERROR(0);
-  if (fshader_filename)
-    readAndCompileShaderFromGLSLFile(new_shaderprogram, fshader_filename,
-                                     GL_FRAGMENT_SHADER);
-
-  GET_GLERROR(0);
-
-  glLinkProgram(new_shaderprogram);
-
-  GET_GLERROR(0);
-  GLint link_success;
-  glGetProgramiv(new_shaderprogram, GL_LINK_STATUS, &link_success);
-
-  if (link_success == GL_FALSE) {
-    printf("Linking of %s with %s failed!\n Reason:\n", vshader_filename,
-           fshader_filename);
-
-    GLint maxLength = 0;
-    glGetShaderiv(new_shaderprogram, GL_INFO_LOG_LENGTH, &maxLength);
-
-    char errorLog[maxLength];
-    glGetShaderInfoLog(new_shaderprogram, maxLength, &maxLength, &errorLog[0]);
-
-    printf("%s", errorLog);
-
-    exit(EXIT_FAILURE);
-  }
-
-  return new_shaderprogram;
-}
-
-//===========================================================================
-// InitGraphicsState() - initialize OpenGL
-//===========================================================================
-static void InitGraphicsState(char **argv) {
-  char *GL_version = (char *)glGetString(GL_VERSION);
-  char *GL_vendor = (char *)glGetString(GL_VENDOR);
-  char *GL_renderer = (char *)glGetString(GL_RENDERER);
-
-  printf("Version: %s\n", GL_version);
-  printf("Vendor: %s\n", GL_vendor);
-  printf("Renderer: %s\n", GL_renderer);
-
-  // RENDERING SETUP (OpenGL ES or OpenGL Core Profile!)
-  glGenVertexArrays(1, &mesh_vao);  // Features' Vertex Array Object allocation
-  glBindVertexArray(mesh_vao);      // bind VAO
-
-  // initialize buffer object
-  glGenBuffers(1, &mesh_vbo);
-  glBindBuffer(GL_ARRAY_BUFFER, mesh_vbo);
-
-  unsigned int size = mesh_width * mesh_height * 4 * sizeof(float);
-  glBufferData(GL_ARRAY_BUFFER, size, NULL, GL_DYNAMIC_DRAW);
-  glVertexAttribPointer((GLuint)0, 4, GL_FLOAT, GL_FALSE, 0, 0);
-  glEnableVertexAttribArray(0);
-
-  HIPCHECK(hipGraphicsGLRegisterBuffer(&cuda_vbo_resource, mesh_vbo,
-                                               cudaGraphicsMapFlagsNone));
-
-  // glBindVertexArray(0); // keep above Vertex Array Object bound (it's the
-  // only one throughout)
-
-  // GLSL stuff
-  char *vertex_shader_path = sdkFindFilePath("mesh.vert.glsl", argv[0]);
-  char *fragment_shader_path = sdkFindFilePath("mesh.frag.glsl", argv[0]);
-
-  if (vertex_shader_path == NULL || fragment_shader_path == NULL) {
-    printf("Error finding shader file\n");
-    exit(EXIT_FAILURE);
-  }
-
-  mesh_shader = ShaderCreate(vertex_shader_path, fragment_shader_path);
-  GET_GLERROR(0);
-
-  free(vertex_shader_path);
-  free(fragment_shader_path);
-
-  glUseProgram(mesh_shader);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run a simple test for CUDA
-////////////////////////////////////////////////////////////////////////////////
-bool runTest(int argc, char **argv, char *ref_file) {
-  // Create the CUTIL timer
-  sdkCreateTimer(&timer);
-
-  int devID = 0;
-#if defined(__aarch64__) || defined(__arm__)
-  // find iGPU on the system which is compute capable which will perform
-  // GLES-CUDA interop
-  devID = findIntegratedGPU();
-#else
-  // use command-line specified CUDA device, otherwise use device with highest
-  // Gflops/s
-  devID = findCudaDevice(argc, (const char **)argv);
-#endif
-
-  // command line mode only
-  if (ref_file != NULL) {
-    // create VBO
-    HIPCHECK(hipMalloc((void **)&d_vbo_buffer,
-                               mesh_width * mesh_height * 4 * sizeof(float)));
-
-    // run the cuda part
-    runAutoTest(devID, argv, ref_file);
-
-    // check result of Cuda step
-    checkResultCuda(argc, argv, mesh_vbo);
-
-    hipFree(d_vbo_buffer);
-    d_vbo_buffer = NULL;
-  } else {
-    // this would use command-line specified CUDA device, note that CUDA
-    // defaults to highest Gflops/s device
-    if (checkCmdLineFlag(argc, (const char **)argv, "device"))
-      error_exit("Device setting not yet implemented!\n");
-
-    // create X11 window and set up associated OpenGL ES context
-    graphics_setup_window(0, 0, window_width, window_height, sSDKsample);
-
-    InitGraphicsState(argv);  // set up GLES stuff
-
-    glClearColor(0, 0.5, 1, 1);  // blue-ish background
-    glClear(GL_COLOR_BUFFER_BIT);
-
-    // printf("WP%d\n", __LINE__);
-    graphics_swap_buffers();
-
-    int frame = 0;
-
-    while (frame < 1000) {
-      display_thisframe(0.010);
-      usleep(1000);  // need not take full CPU and GPU
-
-      graphics_swap_buffers();
-      // printf("frame %d\n",frame++);
-    }
-
-    // NOTE: Before destroying OpenGL ES context, must unregister all shared
-    // resources from CUDA !
-    hipGraphicsUnregisterResource(cuda_vbo_resource);
-
-    graphics_close_window();  // close window and destroy OpenGL ES context
-
-    sdkDeleteTimer(&timer);
-  }
-
-  return true;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  char *ref_file = NULL;
-
-  pArgc = &argc;
-  pArgv = argv;
-
-#if defined(__linux__)
-  setenv("DISPLAY", ":0", 0);
-#endif
-
-  printf("%s starting...\n", sSDKsample);
-
-  if (argc > 1) {
-    if (checkCmdLineFlag(argc, (const char **)argv, "file")) {
-      // In this mode, we run without OpenGL and see if VBO is generated
-      // correctly
-      getCmdLineArgumentString(argc, (const char **)argv, "file",
-                               (char **)&ref_file);
-    }
-  }
-
-  printf("\n");
-
-  runTest(argc, argv, ref_file);
-
-  printf("%s completed, returned %s\n", sSDKsample,
-         (g_TotalErrors == 0) ? "OK" : "ERROR!");
-
-  exit(g_TotalErrors == 0 ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/Makefile b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/README.md b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/data/ref_simpleGLES_screen.bin b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/data/ref_simpleGLES_screen.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/findgleslib.mk b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/findgleslib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/graphics_interface.c b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/graphics_interface.c
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/mesh.frag.glsl b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/mesh.frag.glsl
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/mesh.vert.glsl b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/mesh.vert.glsl
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/simpleGLES_screen.cu b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/simpleGLES_screen.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/simpleGLES_screen.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/simpleGLES_screen.cu.hip
old mode 100644
new mode 100755
index 1afeb77..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/simpleGLES_screen.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleGLES_screen/simpleGLES_screen.cu.hip
@@ -1,604 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
-   This example demonstrates how to use the CUDA C bindings to OpenGL ES to
-   dynamically modify a vertex buffer using a CUDA C kernel.
-
-   The steps are:
-   1. Create an empty vertex buffer object (VBO)
-   2. Register the VBO with CUDA C
-   3. Map the VBO for writing from CUDA C
-   4. Run CUDA C kernel to modify the vertex positions
-   5. Unmap the VBO
-   6. Render the results using OpenGL ES
-
-   Host code
- */
-
-#include <stdlib.h>
-#include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-
-#include <stdarg.h>
-#include <unistd.h>
-#include <screen/screen.h>
-
-#include "graphics_interface.c"
-
-// includes, cuda
-#include <hip/hip_runtime.h>
-#include <cuda_gl_interop.h>
-
-// Utilities and timing functions
-#include "helper_functions.h"    // includes hip/hip_runtime.h and hip/hip_runtime_api.h
-
-// CUDA helper functions
-#include "helper_cuda_hipified.h"         // helper functions for CUDA error check
-
-#include <hip/hip_vector_types.h>
-
-#define MAX_EPSILON_ERROR 0.0f
-#define THRESHOLD 0.0f
-#define REFRESH_DELAY 1  // ms
-
-#define GUI_IDLE 0x100
-#define GUI_ROTATE 0x101
-#define GUI_TRANSLATE 0x102
-
-int gui_mode;
-
-////////////////////////////////////////////////////////////////////////////////
-// Default configuration
-unsigned int window_width = 512;
-unsigned int window_height = 512;
-unsigned int dispno = 0;
-
-// constants
-const unsigned int mesh_width = 256;
-const unsigned int mesh_height = 256;
-
-// OpenGL ES variables and interop with CUDA C
-GLuint mesh_vao, mesh_vbo;
-struct hipGraphicsResource *cuda_vbo_resource;
-void *d_vbo_buffer = NULL;
-
-float g_fAnim = 0.0;
-
-// UI / mouse controls
-int mouse_old_x, mouse_old_y;
-int mouse_buttons = 0;
-float rotate_x = 0.0, rotate_y = 0.0;
-float translate_z = -3.0;
-
-StopWatchInterface *timer = NULL;
-
-// Frame statistics
-int frame;
-int fpsCount = 0;  // FPS count for averaging
-int fpsLimit = 1;  // FPS limit for sampling
-int g_Index = 0;
-float avgFPS = 0.0f;
-unsigned int frameCount = 0;
-unsigned int g_TotalErrors = 0;
-
-// The default number of seconds after which the test will end.
-#define TIME_LIMIT 10.0  // 10 secs
-
-// Flag indicating it is time to shut down
-static GLboolean shutdown = GL_FALSE;
-
-// Callback to close window
-static void closeCB_app(void) { shutdown = GL_TRUE; }
-
-// Callback to handle key presses
-static void keyCB_app(char key, int state) {
-  // Ignoring releases
-  if (!state) return;
-
-  if ((key == 'q') || (key == 'Q') || (key == NvGlDemoKeyCode_Escape))
-    shutdown = GL_TRUE;
-}
-
-// Auto-Verification Code
-bool g_bQAReadback = false;
-
-int *pArgc = NULL;
-char **pArgv = NULL;
-
-#define MAX(a, b) ((a > b) ? a : b)
-
-////////////////////////////////////////////////////////////////////////////////
-// declaration, forward
-
-// CUDA functionality
-void runCuda(struct hipGraphicsResource **vbo_resource);
-void runAutoTest(int devID, char **argv, char *ref_file);
-void checkResultCuda(int argc, char **argv, const GLuint &vbo);
-
-const char *sSDKsample = "simpleGLES on Screen (VBO)";
-
-void computeFPS() {
-  frameCount++;
-  fpsCount++;
-
-  if (fpsCount == fpsLimit) {
-    avgFPS = 1.f / (sdkGetAverageTimerValue(&timer) / 1000.f);
-    fpsCount = 0;
-    fpsLimit = (int)MAX(avgFPS, 1.f);
-
-    sdkResetTimer(&timer);
-  }
-
-  char fps[256];
-  sprintf(fps, "Cuda/OpenGL ES Interop (VBO): %3.1f fps (Max 1000 fps)",
-          avgFPS);
-  graphics_set_windowtitle(fps);
-}
-
-///////////////////////////////////////////////////////////////////////////////
-//! Simple kernel to modify vertex positions in sine wave pattern
-//! @param data  data in global memory
-///////////////////////////////////////////////////////////////////////////////
-__global__ void simple_vbo_kernel(float4 *pos, unsigned int width,
-                                  unsigned int height, float time) {
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  // calculate uv coordinates
-  float u = x / (float)width;
-  float v = y / (float)height;
-  u = u * 2.0f - 1.0f;
-  v = v * 2.0f - 1.0f;
-
-  // calculate simple sine wave pattern
-  float freq = 4.0f;
-  float w = sinf(u * freq + time) * cosf(v * freq + time) * 0.5f;
-
-  // write output vertex
-  pos[y * width + x] = make_float4(u, w, v, 1.0f);
-}
-
-void launch_kernel(float4 *pos, unsigned int mesh_width,
-                   unsigned int mesh_height, float time) {
-  // execute the kernel
-  dim3 block(8, 8, 1);
-  dim3 grid(mesh_width / block.x, mesh_height / block.y, 1);
-  simple_vbo_kernel<<<grid, block>>>(pos, mesh_width, mesh_height, time);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run the Cuda part of the computation
-////////////////////////////////////////////////////////////////////////////////
-void runCuda(struct hipGraphicsResource **vbo_resource) {
-  // map OpenGL buffer object for writing from CUDA
-  float4 *dptr;
-  hipGraphicsMapResources(1, vbo_resource, 0);
-  size_t num_bytes;
-  hipGraphicsResourceGetMappedPointer((void **)&dptr, &num_bytes,
-                                       *vbo_resource);
-
-  launch_kernel(dptr, mesh_width, mesh_height, g_fAnim);
-
-  // unmap buffer object
-  hipGraphicsUnmapResources(1, vbo_resource, 0);
-}
-
-#ifndef FOPEN
-#define FOPEN(fHandle, filename, mode) (fHandle = fopen(filename, mode))
-#endif
-
-void sdkDumpBin2(void *data, unsigned int bytes, const char *filename) {
-  printf("sdkDumpBin: <%s>\n", filename);
-  FILE *fp;
-  FOPEN(fp, filename, "wb");
-  fwrite(data, bytes, 1, fp);
-  fflush(fp);
-  fclose(fp);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run the Cuda part of the computation
-////////////////////////////////////////////////////////////////////////////////
-void runAutoTest(int devID, char **argv, char *ref_file) {
-  char *reference_file = NULL;
-  void *imageData = malloc(mesh_width * mesh_height * sizeof(float));
-
-  // execute the kernel
-  launch_kernel((float4 *)d_vbo_buffer, mesh_width, mesh_height, g_fAnim);
-
-  hipDeviceSynchronize();
-  getLastCudaError("launch_kernel failed");
-
-  hipMemcpy(imageData, d_vbo_buffer, mesh_width * mesh_height * sizeof(float),
-             hipMemcpyDeviceToHost);
-
-  sdkDumpBin2(imageData, mesh_width * mesh_height * sizeof(float),
-              "simpleGLES_screen.bin");
-  reference_file = sdkFindFilePath(ref_file, argv[0]);
-
-  if (reference_file &&
-      !sdkCompareBin2BinFloat("simpleGLES_screen.bin", reference_file,
-                              mesh_width * mesh_height * sizeof(float),
-                              MAX_EPSILON_ERROR, THRESHOLD, pArgv[0])) {
-    g_TotalErrors++;
-  }
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Display callback
-////////////////////////////////////////////////////////////////////////////////
-void display_thisframe(float time_delta) {
-  sdkStartTimer(&timer);
-
-  // run CUDA kernel to generate vertex positions
-  runCuda(&cuda_vbo_resource);
-
-  glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
-
-  glDrawArrays(GL_POINTS, 0, mesh_width * mesh_height);
-
-  glFinish();
-
-  g_fAnim += time_delta;
-
-  sdkStopTimer(&timer);
-  computeFPS();
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Check if the result is correct or write data to file for external
-//! regression testing
-////////////////////////////////////////////////////////////////////////////////
-void checkResultCuda(int argc, char **argv, const GLuint &vbo) {
-  if (!d_vbo_buffer) {
-    printf("%s: Mapping result buffer from OpenGL ES\n", __FUNCTION__);
-
-    hipGraphicsUnregisterResource(cuda_vbo_resource);
-
-    // map buffer object
-    glBindBuffer(GL_ARRAY_BUFFER, vbo);
-    float *data = (float *)glMapBufferRange(
-        GL_ARRAY_BUFFER, 0, mesh_width * mesh_height * 4 * sizeof(float),
-        GL_READ_ONLY);
-
-    // check result
-    if (checkCmdLineFlag(argc, (const char **)argv, "regression")) {
-      // write file for regression test
-      sdkWriteFile<float>("./data/regression.dat", data,
-                          mesh_width * mesh_height * 3, 0.0, false);
-    }
-
-    // unmap GL buffer object
-    if (!glUnmapBuffer(GL_ARRAY_BUFFER)) {
-      fprintf(stderr, "Unmap buffer failed.\n");
-      fflush(stderr);
-    }
-
-    HIPCHECK(hipGraphicsGLRegisterBuffer(
-        &cuda_vbo_resource, vbo, cudaGraphicsMapFlagsWriteDiscard));
-
-    CHECK_GLERROR();
-  }
-}
-
-GLuint mesh_shader = 0;
-
-void readAndCompileShaderFromGLSLFile(GLuint new_shaderprogram,
-                                      const char *filename, GLenum shaderType) {
-  FILE *file = fopen(filename, "rb");  // open shader text file
-  if (!file) {
-    error_exit("Filename %s does not exist\n", filename);
-  }
-
-  // get the size of the file and read it
-  fseek(file, 0, SEEK_END);
-  GLint size = ftell(file);
-  char *data = (char *)malloc(sizeof(char) * (size + 1));
-  memset(data, 0, sizeof(char) * (size + 1));
-  fseek(file, 0, SEEK_SET);
-  size_t res = fread(data, 1, size, file);
-  fclose(file);
-
-  GLuint shader = glCreateShader(shaderType);
-  glShaderSource(shader, 1, (const GLchar **)&data, &size);
-  glCompileShader(shader);
-
-  CHECK_GLERROR();
-  GLint compile_success = 0;
-  glGetShaderiv(shader, GL_COMPILE_STATUS, &compile_success);
-  CHECK_GLERROR();
-
-  if (compile_success == GL_FALSE) {
-    printf("Compilation of %s failed!\n Reason:\n", filename);
-
-    GLint maxLength = 0;
-    glGetShaderiv(shader, GL_INFO_LOG_LENGTH, &maxLength);
-
-    char errorLog[maxLength];
-    glGetShaderInfoLog(shader, maxLength, &maxLength, &errorLog[0]);
-
-    printf("%s", errorLog);
-
-    glDeleteShader(shader);
-    exit(1);
-  }
-
-  glAttachShader(new_shaderprogram, shader);
-  glDeleteShader(shader);
-
-  free(data);
-}
-
-GLuint ShaderCreate(const char *vshader_filename,
-                    const char *fshader_filename) {
-  printf("Loading GLSL shaders %s %s\n", vshader_filename, fshader_filename);
-
-  GLuint new_shaderprogram = glCreateProgram();
-
-  CHECK_GLERROR();
-  if (vshader_filename) {
-    readAndCompileShaderFromGLSLFile(new_shaderprogram, vshader_filename,
-                                     GL_VERTEX_SHADER);
-  }
-
-  CHECK_GLERROR();
-  if (fshader_filename) {
-    readAndCompileShaderFromGLSLFile(new_shaderprogram, fshader_filename,
-                                     GL_FRAGMENT_SHADER);
-  }
-
-  CHECK_GLERROR();
-
-  glLinkProgram(new_shaderprogram);
-
-  CHECK_GLERROR();
-  GLint link_success;
-  glGetProgramiv(new_shaderprogram, GL_LINK_STATUS, &link_success);
-
-  if (link_success == GL_FALSE) {
-    printf("Linking of %s with %s failed!\n Reason:\n", vshader_filename,
-           fshader_filename);
-
-    GLint maxLength = 0;
-    glGetShaderiv(new_shaderprogram, GL_INFO_LOG_LENGTH, &maxLength);
-
-    char errorLog[maxLength];
-    glGetShaderInfoLog(new_shaderprogram, maxLength, &maxLength, &errorLog[0]);
-
-    printf("%s", errorLog);
-
-    exit(EXIT_FAILURE);
-  }
-
-  return new_shaderprogram;
-}
-
-//===========================================================================
-// InitGraphicsState() - initialize OpenGL
-//===========================================================================
-static void InitGraphicsState(void) {
-  char *GL_version = (char *)glGetString(GL_VERSION);
-  char *GL_vendor = (char *)glGetString(GL_VENDOR);
-  char *GL_renderer = (char *)glGetString(GL_RENDERER);
-
-  printf("Version: %s\n", GL_version);
-  printf("Vendor: %s\n", GL_vendor);
-  printf("Renderer: %s\n", GL_renderer);
-
-  // RENDERING SETUP (OpenGL ES or OpenGL Core Profile!)
-  glGenVertexArrays(1, &mesh_vao);  // Features' Vertex Array Object allocation
-  glBindVertexArray(mesh_vao);      // bind VAO
-
-  // initialize buffer object
-  glGenBuffers(1, &mesh_vbo);
-  glBindBuffer(GL_ARRAY_BUFFER, mesh_vbo);
-
-  unsigned int size = mesh_width * mesh_height * 4 * sizeof(float);
-  glBufferData(GL_ARRAY_BUFFER, size, NULL, GL_DYNAMIC_DRAW);
-  glVertexAttribPointer((GLuint)0, 4, GL_FLOAT, GL_FALSE, 0, 0);
-  glEnableVertexAttribArray(0);
-
-  HIPCHECK(hipGraphicsGLRegisterBuffer(&cuda_vbo_resource, mesh_vbo,
-                                               cudaGraphicsMapFlagsNone));
-
-  // GLSL stuff
-  char *vertex_shader_path = sdkFindFilePath("mesh.vert.glsl", pArgv[0]);
-  char *fragment_shader_path = sdkFindFilePath("mesh.frag.glsl", pArgv[0]);
-
-  if (vertex_shader_path == NULL || fragment_shader_path == NULL) {
-    printf("Error finding shader file\n");
-    exit(EXIT_FAILURE);
-  }
-
-  mesh_shader = ShaderCreate(vertex_shader_path, fragment_shader_path);
-  CHECK_GLERROR();
-
-  free(vertex_shader_path);
-  free(fragment_shader_path);
-
-  glUseProgram(mesh_shader);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! Run a simple test for CUDA
-////////////////////////////////////////////////////////////////////////////////
-bool runTest(int argc, char **argv, char *ref_file) {
-  // command line mode only
-  if (ref_file != NULL) {
-    // This will pick the best possible CUDA capable device
-    // int devID = findCudaDevice(argc, (const char **)argv);
-#if defined(__aarch64__) || defined(__arm__)
-    // find iGPU on the system which is compute capable which will perform
-    // GLES-CUDA interop
-    int devID = findIntegratedGPU();
-#else
-    // use command-line specified CUDA device, otherwise use device with highest
-    // Gflops/s
-    int devID = findCudaDevice(argc, (const char **)argv);
-#endif
-
-    // create VBO
-    HIPCHECK(hipMalloc((void **)&d_vbo_buffer,
-                               mesh_width * mesh_height * 4 * sizeof(float)));
-
-    // run the cuda part
-    runAutoTest(devID, argv, ref_file);
-
-    // check result of Cuda step
-    checkResultCuda(argc, argv, mesh_vbo);
-
-    hipFree(d_vbo_buffer);
-    d_vbo_buffer = NULL;
-  } else {
-    double endTime = TIME_LIMIT;
-
-    // this would use command-line specified CUDA device, note that CUDA
-    // defaults to highest Gflops/s device
-    if (checkCmdLineFlag(argc, (const char **)argv, "device")) {
-      error_exit("Device setting not yet implemented!\n");
-    }
-
-    // display selection
-    if (checkCmdLineFlag(argc, (const char **)argv, "dispno")) {
-      dispno = getCmdLineArgumentInt(argc, (const char **)argv, "dispno");
-    }
-
-    // Window width
-    if (checkCmdLineFlag(argc, (const char **)argv, "width")) {
-      window_width = getCmdLineArgumentInt(argc, (const char **)argv, "width");
-    }
-
-    // Window Height
-    if (checkCmdLineFlag(argc, (const char **)argv, "height")) {
-      window_height =
-          getCmdLineArgumentInt(argc, (const char **)argv, "height");
-    }
-
-    // Determine how long to run for in secs: default is 10s
-    if (checkCmdLineFlag(argc, (const char **)argv, "runtime")) {
-      endTime = getCmdLineArgumentInt(argc, (const char **)argv, "runtime");
-    }
-
-    SetCloseCB(closeCB_app);
-    SetKeyCB(keyCB_app);
-
-    // create QNX screen window and set up associated OpenGL ES context
-    graphics_setup_window(0, 0, window_width, window_height, sSDKsample,
-                          dispno);
-
-#if defined(__aarch64__) || defined(__arm__)
-    // find iGPU on the system which is compute capable which will perform
-    // GLES-CUDA interop
-    int devID = findIntegratedGPU();
-#else
-    // use command-line specified CUDA device, otherwise use device with highest
-    // Gflops/s
-    int devID = findCudaDevice(argc, (const char **)argv);
-#endif
-    InitGraphicsState();  // set up GLES stuff
-
-    glClearColor(0, 0.5, 1, 1);  // blue-ish background
-    glClear(GL_COLOR_BUFFER_BIT);
-
-    graphics_swap_buffers();
-
-    int frame = 0;
-
-    struct timeval begin, end;
-    gettimeofday(&begin, NULL);
-
-    // Print runtime
-    if (endTime < 0.0) {
-      endTime = TIME_LIMIT;
-      printf(" running forever...\n");
-    } else {
-      printf(" running for %f seconds...\n", endTime);
-    }
-
-    while (!shutdown) {
-      frame++;
-      display_thisframe(0.010);
-      usleep(1000);
-      graphics_swap_buffers();
-      CheckEvents();
-
-      gettimeofday(&end, 0);
-      double elapsed = (end.tv_sec - begin.tv_sec) +
-                       ((end.tv_usec - begin.tv_usec) / 1000000.0);
-
-      // Check whether time limit has been exceeded
-      if (!shutdown) shutdown = (endTime <= elapsed);
-    }
-
-    // NOTE: Before destroying OpenGL ES context, must unregister all shared
-    // resources from CUDA !
-    HIPCHECK(hipGraphicsUnregisterResource(cuda_vbo_resource));
-
-    graphics_close_window();  // close window and destroy OpenGL ES context
-  }
-
-  return true;
-}
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  char *ref_file = NULL;
-
-  pArgc = &argc;
-  pArgv = argv;
-
-#if defined(__linux__)
-  setenv("DISPLAY", ":0", 0);
-#endif
-
-  printf("%s starting...\n", sSDKsample);
-
-  if (argc > 1) {
-    if (checkCmdLineFlag(argc, (const char **)argv, "file")) {
-      // In this mode, we run without OpenGL and see if VBO is generated
-      // correctly
-      getCmdLineArgumentString(argc, (const char **)argv, "file",
-                               (char **)&ref_file);
-    }
-  }
-
-  printf("\n");
-
-  runTest(argc, argv, ref_file);
-
-  printf("%s completed, returned %s\n", sSDKsample,
-         (g_TotalErrors == 0) ? "OK" : "ERROR!");
-
-  exit(g_TotalErrors == 0 ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/simpleVulkan/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/simpleVulkan/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/simpleVulkan/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/simpleVulkan/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/Build_instructions.txt b/src/samples/Samples/5_Domain_Specific/simpleVulkan/Build_instructions.txt
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/Makefile b/src/samples/Samples/5_Domain_Specific/simpleVulkan/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/simpleVulkan/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/README.md b/src/samples/Samples/5_Domain_Specific/simpleVulkan/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/SineWaveSimulation.cu b/src/samples/Samples/5_Domain_Specific/simpleVulkan/SineWaveSimulation.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/SineWaveSimulation.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleVulkan/SineWaveSimulation.cu.hip
old mode 100644
new mode 100755
index f160b0b..e69de29
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkan/SineWaveSimulation.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkan/SineWaveSimulation.cu.hip
@@ -1,135 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "SineWaveSimulation.h"
-#include <algorithm>
-#include "helper_cuda_hipified.h"
-
-__global__ void sinewave(float *heightMap, unsigned int width,
-                         unsigned int height, float time) {
-  const float freq = 4.0f;
-  const size_t stride = gridDim.x * blockDim.x;
-
-  // Iterate through the entire array in a way that is
-  // independent of the grid configuration
-  for (size_t tid = blockIdx.x * blockDim.x + threadIdx.x; tid < width * height;
-       tid += stride) {
-    // Calculate the x, y coordinates
-    const size_t y = tid / width;
-    const size_t x = tid - y * width;
-    // Normalize x, y to [0,1]
-    const float u = ((2.0f * x) / width) - 1.0f;
-    const float v = ((2.0f * y) / height) - 1.0f;
-    // Calculate the new height value
-    const float w = 0.5f * sinf(u * freq + time) * cosf(v * freq + time);
-    // Store this new height value
-    heightMap[tid] = w;
-  }
-}
-
-SineWaveSimulation::SineWaveSimulation(size_t width, size_t height)
-    : m_heightMap(nullptr), m_width(width), m_height(height) {}
-
-void SineWaveSimulation::initCudaLaunchConfig(int device) {
-  hipDeviceProp_t prop = {};
-  HIPCHECK(hipSetDevice(device));
-  HIPCHECK(hipGetDeviceProperties(&prop, device));
-
-  // We don't need large block sizes, since there's not much inter-thread
-  // communication
-  m_threads = prop.warpSize;
-
-  // Use the occupancy calculator and fill the gpu as best as we can
-  HIPCHECK(hipOccupancyMaxActiveBlocksPerMultiprocessor(
-      &m_blocks, sinewave, prop.warpSize, 0));
-  m_blocks *= prop.multiProcessorCount;
-
-  // Go ahead and the clamp the blocks to the minimum needed for this
-  // height/width
-  m_blocks = std::min(m_blocks,
-                      (int)((m_width * m_height + m_threads - 1) / m_threads));
-}
-
-int SineWaveSimulation::initCuda(uint8_t *vkDeviceUUID, size_t UUID_SIZE) {
-  int current_device = 0;
-  int device_count = 0;
-  int devices_prohibited = 0;
-
-  hipDeviceProp_t deviceProp;
-  HIPCHECK(hipGetDeviceCount(&device_count));
-
-  if (device_count == 0) {
-    fprintf(stderr, "CUDA error: no devices supporting CUDA.\n");
-    exit(EXIT_FAILURE);
-  }
-
-  // Find the GPU which is selected by Vulkan
-  while (current_device < device_count) {
-    hipGetDeviceProperties(&deviceProp, current_device);
-
-    if ((deviceProp.computeMode != hipComputeModeProhibited)) {
-      // Compare the cuda device UUID with vulkan UUID
-      int ret = memcmp((void *)&deviceProp.uuid, vkDeviceUUID, UUID_SIZE);
-      if (ret == 0) {
-        HIPCHECK(hipSetDevice(current_device));
-        HIPCHECK(hipGetDeviceProperties(&deviceProp, current_device));
-        printf("GPU Device %d: \"%s\" with compute capability %d.%d\n\n",
-               current_device, deviceProp.name, deviceProp.major,
-               deviceProp.minor);
-
-        return current_device;
-      }
-
-    } else {
-      devices_prohibited++;
-    }
-
-    current_device++;
-  }
-
-  if (devices_prohibited == device_count) {
-    fprintf(stderr,
-            "CUDA error:"
-            " No Vulkan-CUDA Interop capable GPU found.\n");
-    exit(EXIT_FAILURE);
-  }
-
-  return -1;
-}
-
-SineWaveSimulation::~SineWaveSimulation() { m_heightMap = NULL; }
-
-void SineWaveSimulation::initSimulation(float *heights) {
-  m_heightMap = heights;
-}
-
-void SineWaveSimulation::stepSimulation(float time, hipStream_t stream) {
-  sinewave<<<m_blocks, m_threads, 0, stream>>>(m_heightMap, m_width, m_height,
-                                               time);
-  getLastCudaError("Failed to launch CUDA simulation");
-}
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/SineWaveSimulation.h b/src/samples/Samples/5_Domain_Specific/simpleVulkan/SineWaveSimulation.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/SineWaveSimulation_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleVulkan/SineWaveSimulation_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/VulkanBaseApp.cpp b/src/samples/Samples/5_Domain_Specific/simpleVulkan/VulkanBaseApp.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/VulkanBaseApp.h b/src/samples/Samples/5_Domain_Specific/simpleVulkan/VulkanBaseApp.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/VulkanBaseApp_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleVulkan/VulkanBaseApp_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/VulkanBaseApp_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleVulkan/VulkanBaseApp_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/findvulkan.mk b/src/samples/Samples/5_Domain_Specific/simpleVulkan/findvulkan.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/frag.spv b/src/samples/Samples/5_Domain_Specific/simpleVulkan/frag.spv
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/linmath.h b/src/samples/Samples/5_Domain_Specific/simpleVulkan/linmath.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/linmath_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleVulkan/linmath_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/main.cpp b/src/samples/Samples/5_Domain_Specific/simpleVulkan/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/main_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleVulkan/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2017.sln b/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2019.sln b/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2022.sln b/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleVulkan/simpleVulkan_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/sinewave.frag b/src/samples/Samples/5_Domain_Specific/simpleVulkan/sinewave.frag
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/sinewave.vert b/src/samples/Samples/5_Domain_Specific/simpleVulkan/sinewave.vert
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkan/vert.spv b/src/samples/Samples/5_Domain_Specific/simpleVulkan/vert.spv
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/Build_instructions.txt b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/Build_instructions.txt
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/Makefile b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/MonteCarloPi.cu b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/MonteCarloPi.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/MonteCarloPi.cu.hip b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/MonteCarloPi.cu.hip
old mode 100644
new mode 100755
index 9f5a330..0e359ed
--- a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/MonteCarloPi.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/MonteCarloPi.cu.hip
@@ -300,3 +300,9 @@ void MonteCarloPiSimulation::cleanupSimulationAllocations() {
     m_pointsInsideCircle = nullptr;
   }
 }
+   checkCudaErrors(
+        hipMemAddressFree((hipDeviceptr_t)m_xyVector, m_totalAllocationSize));
+
+    m_xyVector = nullptr;
+    m_pointsInsideCircle = nullptr;
+  }
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/MonteCarloPi.h b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/MonteCarloPi.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/MonteCarloPi_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/MonteCarloPi_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/README.md b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/VulkanBaseApp.cpp b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/VulkanBaseApp.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/VulkanBaseApp.h b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/VulkanBaseApp.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/VulkanBaseApp_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/VulkanBaseApp_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/VulkanBaseApp_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/VulkanBaseApp_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/VulkanCudaInterop.h b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/VulkanCudaInterop.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/VulkanCudaInterop_hipified.h b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/VulkanCudaInterop_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/findvulkan.mk b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/findvulkan.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/frag.spv b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/frag.spv
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/main.cpp b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/main.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/main_hipified.cpp b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/main_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/montecarlo.frag b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/montecarlo.frag
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/montecarlo.vert b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/montecarlo.vert
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2017.sln b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2019.sln b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2022.sln b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/simpleVulkanMMAP_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/vert.spv b/src/samples/Samples/5_Domain_Specific/simpleVulkanMMAP/vert.spv
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/smokeParticles/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/smokeParticles/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/smokeParticles/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/smokeParticles/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/GLSLProgram.cpp b/src/samples/Samples/5_Domain_Specific/smokeParticles/GLSLProgram.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/GLSLProgram.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/GLSLProgram.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/GLSLProgram_hipified.cpp b/src/samples/Samples/5_Domain_Specific/smokeParticles/GLSLProgram_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/GLSLProgram_hipified.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/GLSLProgram_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/GpuArray.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/GpuArray.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/GpuArray_hipified.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/GpuArray_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/Makefile b/src/samples/Samples/5_Domain_Specific/smokeParticles/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/smokeParticles/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem.cpp b/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem.cuh b/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem_cuda.cu b/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem_cuda.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem_cuda.cu.hip b/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem_cuda.cu.hip
old mode 100644
new mode 100755
index bb31d3d..e69de29
--- a/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem_cuda.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem_cuda.cu.hip
@@ -1,149 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
-This file contains simple wrapper functions that call the CUDA kernels
-*/
-#define HELPERGL_EXTERN_GL_FUNC_IMPLEMENTATION
-#include <helper_gl.h>
-#include "helper_cuda_hipified.h"
-#include <cstdlib>
-#include <cstdio>
-#include <string.h>
-#include <cuda_gl_interop.h>
-
-#include "thrust/device_ptr.h"
-#include "thrust/for_each.h"
-#include "thrust/iterator/zip_iterator.h"
-#include "thrust/sort.h"
-
-#include "particles_kernel_device.cuh"
-#include "ParticleSystem.cuh"
-
-extern "C" {
-
-hipArray *noiseArray;
-
-void setParameters(SimParams *hostParams) {
-  // copy parameters to constant memory
-  HIPCHECK(hipMemcpyToSymbol(HIP_SYMBOL(params), hostParams, sizeof(SimParams)));
-}
-
-// Round a / b to nearest higher integer value
-int iDivUp(int a, int b) { return (a % b != 0) ? (a / b + 1) : (a / b); }
-
-// compute grid and thread block size for a given number of elements
-void computeGridSize(int n, int blockSize, int &numBlocks, int &numThreads) {
-  numThreads = min(blockSize, n);
-  numBlocks = iDivUp(n, numThreads);
-}
-
-inline float frand() { return rand() / (float)RAND_MAX; }
-
-// create 3D texture containing random values
-void createNoiseTexture(int w, int h, int d) {
-  hipExtent size = make_hipExtent(w, h, d);
-  size_t elements = size.width * size.height * size.depth;
-
-  float *volumeData = (float *)malloc(elements * 4 * sizeof(float));
-  float *ptr = volumeData;
-
-  for (size_t i = 0; i < elements; i++) {
-    *ptr++ = frand() * 2.0f - 1.0f;
-    *ptr++ = frand() * 2.0f - 1.0f;
-    *ptr++ = frand() * 2.0f - 1.0f;
-    *ptr++ = frand() * 2.0f - 1.0f;
-  }
-
-  hipChannelFormatDesc channelDesc = hipCreateChannelDesc<float4>();
-  HIPCHECK(hipMalloc3DArray(&noiseArray, &channelDesc, size));
-
-  hipMemcpy3DParms copyParams = {0};
-  copyParams.srcPtr = make_hipPitchedPtr(
-      (void *)volumeData, size.width * sizeof(float4), size.width, size.height);
-  copyParams.dstArray = noiseArray;
-  copyParams.extent = size;
-  copyParams.kind = hipMemcpyHostToDevice;
-  HIPCHECK(hipMemcpy3D(&copyParams));
-
-  free(volumeData);
-
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = noiseArray;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = true;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.addressMode[2] = hipAddressModeWrap;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(hipCreateTextureObject(&noiseTex, &texRes, &texDescr, NULL));
-}
-
-void integrateSystem(float4 *oldPos, float4 *newPos, float4 *oldVel,
-                     float4 *newVel, float deltaTime, int numParticles) {
-  thrust::device_ptr<float4> d_newPos(newPos);
-  thrust::device_ptr<float4> d_newVel(newVel);
-  thrust::device_ptr<float4> d_oldPos(oldPos);
-  thrust::device_ptr<float4> d_oldVel(oldVel);
-
-  thrust::for_each(thrust::make_zip_iterator(thrust::make_tuple(
-                       d_newPos, d_newVel, d_oldPos, d_oldVel)),
-                   thrust::make_zip_iterator(thrust::make_tuple(
-                       d_newPos + numParticles, d_newVel + numParticles,
-                       d_oldPos + numParticles, d_oldVel + numParticles)),
-                   integrate_functor(deltaTime, noiseTex));
-}
-
-void calcDepth(float4 *pos,
-               float *keys,    // output
-               uint *indices,  // output
-               float3 sortVector, int numParticles) {
-  thrust::device_ptr<float4> d_pos(pos);
-  thrust::device_ptr<float> d_keys(keys);
-  thrust::device_ptr<uint> d_indices(indices);
-
-  thrust::for_each(thrust::make_zip_iterator(thrust::make_tuple(d_pos, d_keys)),
-                   thrust::make_zip_iterator(thrust::make_tuple(
-                       d_pos + numParticles, d_keys + numParticles)),
-                   calcDepth_functor(sortVector));
-
-  thrust::sequence(d_indices, d_indices + numParticles);
-}
-
-void sortParticles(float *sortKeys, uint *indices, uint numParticles) {
-  thrust::sort_by_key(thrust::device_ptr<float>(sortKeys),
-                      thrust::device_ptr<float>(sortKeys + numParticles),
-                      thrust::device_ptr<uint>(indices));
-}
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem_hipified.cpp b/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem_hipified.cuh b/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem_hipified.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/ParticleSystem_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/README.md b/src/samples/Samples/5_Domain_Specific/smokeParticles/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeRenderer.cpp b/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeRenderer.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeRenderer.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeRenderer.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeRenderer_hipified.cpp b/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeRenderer_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeRenderer_hipified.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeRenderer_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeShaders.cpp b/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeShaders.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeShaders.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeShaders.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeShaders_hipified.cpp b/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeShaders_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeShaders_hipified.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/SmokeShaders_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/data/floortile.ppm b/src/samples/Samples/5_Domain_Specific/smokeParticles/data/floortile.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/data/ref_smokePart_pos.bin b/src/samples/Samples/5_Domain_Specific/smokeParticles/data/ref_smokePart_pos.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/data/ref_smokePart_vel.bin b/src/samples/Samples/5_Domain_Specific/smokeParticles/data/ref_smokePart_vel.bin
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/doc/screenshot_lg.png b/src/samples/Samples/5_Domain_Specific/smokeParticles/doc/screenshot_lg.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/doc/screenshot_md.png b/src/samples/Samples/5_Domain_Specific/smokeParticles/doc/screenshot_md.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/doc/screenshot_sm.png b/src/samples/Samples/5_Domain_Specific/smokeParticles/doc/screenshot_sm.png
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/doc/smokeParticles.doc b/src/samples/Samples/5_Domain_Specific/smokeParticles/doc/smokeParticles.doc
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/doc/smokeParticles.pdf b/src/samples/Samples/5_Domain_Specific/smokeParticles/doc/smokeParticles.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/findgllib.mk b/src/samples/Samples/5_Domain_Specific/smokeParticles/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/framebufferObject.cpp b/src/samples/Samples/5_Domain_Specific/smokeParticles/framebufferObject.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/framebufferObject.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/framebufferObject.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/framebufferObject_hipified.cpp b/src/samples/Samples/5_Domain_Specific/smokeParticles/framebufferObject_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/framebufferObject_hipified.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/framebufferObject_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/nvMath.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/nvMath.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/nvMath_hipified.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/nvMath_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/nvMatrix.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/nvMatrix.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/nvMatrix_hipified.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/nvMatrix_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/nvQuaternion.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/nvQuaternion.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/nvQuaternion_hipified.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/nvQuaternion_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/nvVector.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/nvVector.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/nvVector_hipified.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/nvVector_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/particleDemo.cpp b/src/samples/Samples/5_Domain_Specific/smokeParticles/particleDemo.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/particleDemo_hipified.cpp b/src/samples/Samples/5_Domain_Specific/smokeParticles/particleDemo_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/particles_kernel.cuh b/src/samples/Samples/5_Domain_Specific/smokeParticles/particles_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/particles_kernel_device.cuh b/src/samples/Samples/5_Domain_Specific/smokeParticles/particles_kernel_device.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/particles_kernel_device_hipified.cuh b/src/samples/Samples/5_Domain_Specific/smokeParticles/particles_kernel_device_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/particles_kernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/smokeParticles/particles_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/renderbuffer.cpp b/src/samples/Samples/5_Domain_Specific/smokeParticles/renderbuffer.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/renderbuffer.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/renderbuffer.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/renderbuffer_hipified.cpp b/src/samples/Samples/5_Domain_Specific/smokeParticles/renderbuffer_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/renderbuffer_hipified.h b/src/samples/Samples/5_Domain_Specific/smokeParticles/renderbuffer_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2017.sln b/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2019.sln b/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2022.sln b/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/smokeParticles/smokeParticles_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/stereoDisparity/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/stereoDisparity/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/stereoDisparity/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/stereoDisparity/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/Makefile b/src/samples/Samples/5_Domain_Specific/stereoDisparity/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/stereoDisparity/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/README.md b/src/samples/Samples/5_Domain_Specific/stereoDisparity/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/data/stereo.im0.640x533.ppm b/src/samples/Samples/5_Domain_Specific/stereoDisparity/data/stereo.im0.640x533.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/data/stereo.im1.640x533.ppm b/src/samples/Samples/5_Domain_Specific/stereoDisparity/data/stereo.im1.640x533.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity.cu b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity.cu.hip b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity.cu.hip
old mode 100644
new mode 100755
index 308188c..e69de29
--- a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity.cu.hip
@@ -1,284 +0,0 @@
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/* A CUDA program that demonstrates how to compute a stereo disparity map using
- * SIMD SAD (Sum of Absolute Difference) intrinsics
- */
-
-// includes, system
-#include <stdlib.h>
-#include <stdio.h>
-//#include "rocprofiler.h"
-#include "HIPCHECK.h"
-#include <string.h>
-#include <math.h>
-
-// includes, kernels
-#include <hip/hip_runtime.h>
-#include "stereoDisparity_kernel.cuh"
-
-// includes, project
-#include "helper_functions.h"  // helper for shared that are common to CUDA Samples
-#include "helper_cuda_hipified.h"  // helper for checking cuda initialization and error checking
-#include <helper_string.h>  // helper functions for string parsing
-
-static const char *sSDKsample = "[stereoDisparity]\0";
-
-int iDivUp(int a, int b) { return ((a % b) != 0) ? (a / b + 1) : (a / b); }
-
-////////////////////////////////////////////////////////////////////////////////
-// declaration, forward
-void runTest(int argc, char **argv);
-
-////////////////////////////////////////////////////////////////////////////////
-// Program main
-////////////////////////////////////////////////////////////////////////////////
-int main(int argc, char **argv) {
-  printf("%s Starting...\n\n", sSDKsample);
-  runTest(argc, argv);
-}
-
-////////////////////////////////////////////////////////////////////////////////
-//! CUDA Sample for calculating depth maps
-////////////////////////////////////////////////////////////////////////////////
-void runTest(int argc, char **argv) {
-  hipDeviceProp_t deviceProp;
-  deviceProp.major = 0;
-  deviceProp.minor = 0;
-  int dev = 0;
-
-  // This will pick the best possible CUDA capable device
-  dev = findCudaDevice(argc, (const char **)argv);
-
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, dev));
-
-  // Statistics about the GPU device
-  printf(
-      "> GPU device has %d Multi-Processors, SM %d.%d compute capabilities\n\n",
-      deviceProp.multiProcessorCount, deviceProp.major, deviceProp.minor);
-
-  StopWatchInterface *timer;
-  sdkCreateTimer(&timer);
-
-  // Search parameters
-  int minDisp = -16;
-  int maxDisp = 0;
-
-  // Load image data
-  // allocate mem for the images on host side
-  // initialize pointers to NULL to request lib call to allocate as needed
-  // PPM images are loaded into 4 byte/pixel memory (RGBX)
-  unsigned char *h_img0 = NULL;
-  unsigned char *h_img1 = NULL;
-  unsigned int w, h;
-  char *fname0 = sdkFindFilePath("stereo.im0.640x533.ppm", argv[0]);
-  char *fname1 = sdkFindFilePath("stereo.im1.640x533.ppm", argv[0]);
-
-  printf("Loaded <%s> as image 0\n", fname0);
-
-  if (!sdkLoadPPM4ub(fname0, &h_img0, &w, &h)) {
-    fprintf(stderr, "Failed to load <%s>\n", fname0);
-  }
-
-  printf("Loaded <%s> as image 1\n", fname1);
-
-  if (!sdkLoadPPM4ub(fname1, &h_img1, &w, &h)) {
-    fprintf(stderr, "Failed to load <%s>\n", fname1);
-  }
-
-  dim3 numThreads = dim3(blockSize_x, blockSize_y, 1);
-  dim3 numBlocks = dim3(iDivUp(w, numThreads.x), iDivUp(h, numThreads.y));
-  unsigned int numData = w * h;
-  unsigned int memSize = sizeof(int) * numData;
-
-  // allocate mem for the result on host side
-  unsigned int *h_odata = (unsigned int *)malloc(memSize);
-
-  // initialize the memory
-  for (unsigned int i = 0; i < numData; i++) h_odata[i] = 0;
-
-  // allocate device memory for result
-  unsigned int *d_odata, *d_img0, *d_img1;
-
-  HIPCHECK(hipMalloc((void **)&d_odata, memSize));
-  HIPCHECK(hipMalloc((void **)&d_img0, memSize));
-  HIPCHECK(hipMalloc((void **)&d_img1, memSize));
-
-  // copy host memory to device to initialize to zeros
-  HIPCHECK(hipMemcpy(d_img0, h_img0, memSize, hipMemcpyHostToDevice));
-  HIPCHECK(hipMemcpy(d_img1, h_img1, memSize, hipMemcpyHostToDevice));
-  HIPCHECK(
-      hipMemcpy(d_odata, h_odata, memSize, hipMemcpyHostToDevice));
-
-  hipChannelFormatDesc ca_desc0 = hipCreateChannelDesc<unsigned int>();
-  hipChannelFormatDesc ca_desc1 = hipCreateChannelDesc<unsigned int>();
-
-  hipTextureObject_t tex2Dleft, tex2Dright;
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypePitch2D;
-  texRes.res.pitch2D.devPtr = d_img0;
-  texRes.res.pitch2D.desc = ca_desc0;
-  texRes.res.pitch2D.width = w;
-  texRes.res.pitch2D.height = h;
-  texRes.res.pitch2D.pitchInBytes = w * 4;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModePoint;
-  texDescr.addressMode[0] = hipAddressModeClamp;
-  texDescr.addressMode[1] = hipAddressModeClamp;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(
-      hipCreateTextureObject(&tex2Dleft, &texRes, &texDescr, NULL));
-
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypePitch2D;
-  texRes.res.pitch2D.devPtr = d_img1;
-  texRes.res.pitch2D.desc = ca_desc1;
-  texRes.res.pitch2D.width = w;
-  texRes.res.pitch2D.height = h;
-  texRes.res.pitch2D.pitchInBytes = w * 4;
-
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = false;
-  texDescr.filterMode = hipFilterModePoint;
-  texDescr.addressMode[0] = hipAddressModeClamp;
-  texDescr.addressMode[1] = hipAddressModeClamp;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(
-      hipCreateTextureObject(&tex2Dright, &texRes, &texDescr, NULL));
-
-  // First run the warmup kernel (which we'll use to get the GPU in the correct
-  // max power state
-  stereoDisparityKernel<<<numBlocks, numThreads>>>(
-      d_img0, d_img1, d_odata, w, h, minDisp, maxDisp, tex2Dleft, tex2Dright);
-  hipDeviceSynchronize();
-
-  // Allocate CUDA events that we'll use for timing
-  hipEvent_t start, stop;
-  HIPCHECK(hipEventCreate(&start));
-  HIPCHECK(hipEventCreate(&stop));
-
-  printf("Launching CUDA stereoDisparityKernel()\n");
-
-  // Record the start event
-  HIPCHECK(hipEventRecord(start, NULL));
-
-  // launch the stereoDisparity kernel
-  stereoDisparityKernel<<<numBlocks, numThreads>>>(
-      d_img0, d_img1, d_odata, w, h, minDisp, maxDisp, tex2Dleft, tex2Dright);
-
-  // Record the stop event
-  HIPCHECK(hipEventRecord(stop, NULL));
-
-  // Wait for the stop event to complete
-  HIPCHECK(hipEventSynchronize(stop));
-
-  // Check to make sure the kernel didn't fail
-  getLastCudaError("Kernel execution failed");
-
-  float msecTotal = 0.0f;
-  HIPCHECK(hipEventElapsedTime(&msecTotal, start, stop));
-
-  // Copy result from device to host for verification
-  HIPCHECK(
-      hipMemcpy(h_odata, d_odata, memSize, hipMemcpyDeviceToHost));
-
-  printf("Input Size  [%dx%d], ", w, h);
-  printf("Kernel size [%dx%d], ", (2 * RAD + 1), (2 * RAD + 1));
-  printf("Disparities [%d:%d]\n", minDisp, maxDisp);
-
-  printf("GPU processing time : %.4f (ms)\n", msecTotal);
-  printf("Pixel throughput    : %.3f Mpixels/sec\n",
-         ((float)(w * h * 1000.f) / msecTotal) / 1000000);
-
-  // calculate sum of resultant GPU image
-  unsigned int checkSum = 0;
-
-  for (unsigned int i = 0; i < w * h; i++) {
-    checkSum += h_odata[i];
-  }
-
-  printf("GPU Checksum = %u, ", checkSum);
-
-  // write out the resulting disparity image.
-  unsigned char *dispOut = (unsigned char *)malloc(numData);
-  int mult = 20;
-  const char *fnameOut = "output_GPU.pgm";
-
-  for (unsigned int i = 0; i < numData; i++) {
-    dispOut[i] = (int)h_odata[i] * mult;
-  }
-
-  printf("GPU image: <%s>\n", fnameOut);
-  sdkSavePGM(fnameOut, dispOut, w, h);
-
-  // compute reference solution
-  printf("Computing CPU reference...\n");
-  cpu_gold_stereo((unsigned int *)h_img0, (unsigned int *)h_img1,
-                  (unsigned int *)h_odata, w, h, minDisp, maxDisp);
-  unsigned int cpuCheckSum = 0;
-
-  for (unsigned int i = 0; i < w * h; i++) {
-    cpuCheckSum += h_odata[i];
-  }
-
-  printf("CPU Checksum = %u, ", cpuCheckSum);
-  const char *cpuFnameOut = "output_CPU.pgm";
-
-  for (unsigned int i = 0; i < numData; i++) {
-    dispOut[i] = (int)h_odata[i] * mult;
-  }
-
-  printf("CPU image: <%s>\n", cpuFnameOut);
-  sdkSavePGM(cpuFnameOut, dispOut, w, h);
-
-  // cleanup memory
-  HIPCHECK(hipFree(d_odata));
-  HIPCHECK(hipFree(d_img0));
-  HIPCHECK(hipFree(d_img1));
-
-  if (h_odata != NULL) free(h_odata);
-
-  if (h_img0 != NULL) free(h_img0);
-
-  if (h_img1 != NULL) free(h_img1);
-
-  if (dispOut != NULL) free(dispOut);
-
-  sdkDeleteTimer(&timer);
-
-  exit((checkSum == cpuCheckSum) ? EXIT_SUCCESS : EXIT_FAILURE);
-}
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_kernel.cuh b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_kernel.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_kernel_hipified.cuh b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_kernel_hipified.cuh
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2017.sln b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2019.sln b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2022.sln b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/stereoDisparity/stereoDisparity_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/volumeFiltering/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/volumeFiltering/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/volumeFiltering/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/volumeFiltering/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/Makefile b/src/samples/Samples/5_Domain_Specific/volumeFiltering/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/volumeFiltering/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/README.md b/src/samples/Samples/5_Domain_Specific/volumeFiltering/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/data/Bucky.raw b/src/samples/Samples/5_Domain_Specific/volumeFiltering/data/Bucky.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/data/ref_volumefilter.ppm b/src/samples/Samples/5_Domain_Specific/volumeFiltering/data/ref_volumefilter.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/doc/sshot_lg.JPG b/src/samples/Samples/5_Domain_Specific/volumeFiltering/doc/sshot_lg.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/doc/sshot_md.JPG b/src/samples/Samples/5_Domain_Specific/volumeFiltering/doc/sshot_md.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/doc/sshot_sm.JPG b/src/samples/Samples/5_Domain_Specific/volumeFiltering/doc/sshot_sm.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/findgllib.mk b/src/samples/Samples/5_Domain_Specific/volumeFiltering/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume.cpp b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume.h b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFilter.h b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFilter.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFilter_hipified.h b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFilter_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFilter_kernel.cu b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFilter_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFilter_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFilter_kernel.cu.hip
old mode 100644
new mode 100755
index c397a84..e69de29
--- a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFilter_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFilter_kernel.cu.hip
@@ -1,117 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef _VOLUMEFILTER_KERNEL_CU_
-#define _VOLUMEFILTER_KERNEL_CU_
-
-#include "helper_cuda_hipified.h"
-#include <helper_math.h>
-#include "volumeFilter.h"
-
-typedef unsigned int uint;
-typedef unsigned char uchar;
-typedef unsigned short ushort;
-
-__constant__ float4 c_filterData[VOLUMEFILTER_MAXWEIGHTS];
-
-__global__ void d_filter_surface3d(int filterSize, float filter_offset,
-                                   hipExtent volumeSize,
-                                   hipTextureObject_t volumeTexIn,
-                                   hipSurfaceObject_t volumeTexOut) {
-  int x = blockIdx.x * blockDim.x + threadIdx.x;
-  int y = blockIdx.y * blockDim.y + threadIdx.y;
-  int z = blockIdx.z * blockDim.z + threadIdx.z;
-
-  if (x >= volumeSize.width || y >= volumeSize.height ||
-      z >= volumeSize.depth) {
-    return;
-  }
-
-  float filtered = 0;
-  float4 basecoord = make_float4(x, y, z, 0);
-
-  for (int i = 0; i < filterSize; i++) {
-    float4 coord = basecoord + c_filterData[i];
-    filtered += tex3D<float>(volumeTexIn, coord.x, coord.y, coord.z) *
-                c_filterData[i].w;
-  }
-
-  filtered += filter_offset;
-
-  VolumeType output = VolumeTypeInfo<VolumeType>::convert(filtered);
-
-  // surface writes need byte offsets for x!
-  surf3Dwrite(output, volumeTexOut, x * sizeof(VolumeType), y, z);
-}
-
-static unsigned int iDivUp(size_t a, size_t b) {
-  size_t val = (a % b != 0) ? (a / b + 1) : (a / b);
-  if (val > UINT_MAX) {
-    fprintf(stderr, "\nUINT_MAX limit exceeded in iDivUp() exiting.....\n");
-    exit(EXIT_FAILURE);  // val exceeds limit
-  }
-
-  return static_cast<unsigned int>(val);
-}
-
-extern "C" Volume *VolumeFilter_runFilter(Volume *input, Volume *output0,
-                                          Volume *output1, int iterations,
-                                          int numWeights, float4 *weights,
-                                          float postWeightOffset) {
-  Volume *swap = 0;
-  hipExtent size = input->size;
-  unsigned int dim = 32 / sizeof(VolumeType);
-  dim3 blockSize(dim, dim, 1);
-  dim3 gridSize(iDivUp(size.width, blockSize.x),
-                iDivUp(size.height, blockSize.y),
-                iDivUp(size.depth, blockSize.z));
-
-  // set weights
-  HIPCHECK(
-      hipMemcpyToSymbol(HIP_SYMBOL(c_filterData), weights, sizeof(float4) * numWeights));
-
-  for (int i = 0; i < iterations; i++) {
-    d_filter_surface3d<<<gridSize, blockSize>>>(numWeights, postWeightOffset,
-                                                size, input->volumeTex,
-                                                output0->volumeSurf);
-
-    getLastCudaError("filter kernel failed");
-
-    swap = input;
-    input = output0;
-    output0 = swap;
-
-    if (i == 0) {
-      output0 = output1;
-    }
-  }
-
-  return input;
-}
-#endif
-#endif
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering.cpp b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_hipified.cpp b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2017.sln b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2019.sln b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2022.sln b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeFiltering_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeRender.h b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeRender.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeRender_hipified.h b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeRender_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeRender_kernel.cu b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeRender_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeRender_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeRender_kernel.cu.hip
old mode 100644
new mode 100755
index 2c8953a..e69de29
--- a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeRender_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volumeRender_kernel.cu.hip
@@ -1,568 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-// Simple 3D volume renderer
-
-#ifndef _VOLUMERENDER_KERNEL_CU_
-#define _VOLUMERENDER_KERNEL_CU_
-
-#include "helper_cuda_hipified.h"
-#include <helper_math.h>
-#include "volumeRender.h"
-
-#define VOLUMERENDER_TFS 2
-#define VOLUMERENDER_TF_PREINTSIZE 1024
-#define VOLUMERENDER_TF_PREINTSTEPS 1024
-#define VOLUMERENDER_TF_PREINTRAY 4
-
-enum TFMode {
-  TF_SINGLE_1D = 0,          // single 1D TF for everything
-  TF_LAYERED_2D_PREINT = 1,  // layered 2D TF uses pre-integration
-  TF_LAYERED_2D = 2,         // layered 2D TF without pre-integration behavior
-};
-
-typedef unsigned int uint;
-typedef unsigned char uchar;
-
-static bool usePreInt = true;
-static hipArray *d_transferIntegrate = 0;
-static hipArray *d_transferFunc = 0;
-static hipArray *d_transferArray = 0;
-
-// 1D transfer function texture
-hipTextureObject_t transferTex;
-// 1D transfer integration texture
-hipTextureObject_t transferIntegrateTex;
-hipSurfaceObject_t transferIntegrateSurf;
-// 2D layered preintegrated transfer function texture
-hipTextureObject_t transferLayerPreintTex;
-hipSurfaceObject_t transferLayerPreintSurf;
-
-typedef struct { float4 m[3]; } float3x4;
-
-__constant__ float3x4 c_invViewMatrix;  // inverse view matrix
-
-struct Ray {
-  float3 o;  // origin
-  float3 d;  // direction
-};
-
-// intersect ray with a box
-// http://www.siggraph.org/education/materials/HyperGraph/raytrace/rtinter3.htm
-
-__device__ int intersectBox(Ray r, float3 boxmin, float3 boxmax, float *tnear,
-                            float *tfar) {
-  // compute intersection of ray with all six bbox planes
-  float3 invR = make_float3(1.0f) / r.d;
-  float3 tbot = invR * (boxmin - r.o);
-  float3 ttop = invR * (boxmax - r.o);
-
-  // re-order intersections to find smallest and largest on each axis
-  float3 tmin = fminf(ttop, tbot);
-  float3 tmax = fmaxf(ttop, tbot);
-
-  // find the largest tmin and the smallest tmax
-  float largest_tmin = fmaxf(fmaxf(tmin.x, tmin.y), fmaxf(tmin.x, tmin.z));
-  float smallest_tmax = fminf(fminf(tmax.x, tmax.y), fminf(tmax.x, tmax.z));
-
-  *tnear = largest_tmin;
-  *tfar = smallest_tmax;
-
-  return smallest_tmax > largest_tmin;
-}
-
-// transform vector by matrix (no translation)
-__device__ float3 mul(const float3x4 &M, const float3 &v) {
-  float3 r;
-  r.x = dot(v, make_float3(M.m[0]));
-  r.y = dot(v, make_float3(M.m[1]));
-  r.z = dot(v, make_float3(M.m[2]));
-  return r;
-}
-
-// transform vector by matrix with translation
-__device__ float4 mul(const float3x4 &M, const float4 &v) {
-  float4 r;
-  r.x = dot(v, M.m[0]);
-  r.y = dot(v, M.m[1]);
-  r.z = dot(v, M.m[2]);
-  r.w = 1.0f;
-  return r;
-}
-
-__device__ uint rgbaFloatToInt(float4 rgba) {
-  rgba.x = __saturatef(rgba.x);  // clamp to [0.0, 1.0]
-  rgba.y = __saturatef(rgba.y);
-  rgba.z = __saturatef(rgba.z);
-  rgba.w = __saturatef(rgba.w);
-  return (uint(rgba.w * 255) << 24) | (uint(rgba.z * 255) << 16) |
-         (uint(rgba.y * 255) << 8) | uint(rgba.x * 255);
-}
-
-template <int TFMODE>
-__device__ void d_render(uint *d_output, uint imageW, uint imageH,
-                         float density, float brightness, float transferOffset,
-                         float transferScale, hipTextureObject_t volumeTex,
-                         hipTextureObject_t transferTex,
-                         hipTextureObject_t transferLayerPreintTex,
-                         float transferWeight = 0.0f) {
-  const float rayscale =
-      float(TFMODE != TF_SINGLE_1D ? VOLUMERENDER_TF_PREINTRAY : 1);
-  const int maxSteps = 512;
-  const float tstep = 0.01f * rayscale;
-  const float opacityThreshold = 0.95f;
-  const float3 boxMin = make_float3(-1.0f, -1.0f, -1.0f);
-  const float3 boxMax = make_float3(1.0f, 1.0f, 1.0f);
-
-  density *= rayscale;
-
-  uint x = blockIdx.x * blockDim.x + threadIdx.x;
-  uint y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  if ((x >= imageW) || (y >= imageH)) return;
-
-  float u = (x / (float)imageW) * 2.0f - 1.0f;
-  float v = (y / (float)imageH) * 2.0f - 1.0f;
-
-  // calculate eye ray in world space
-  Ray eyeRay;
-  eyeRay.o =
-      make_float3(mul(c_invViewMatrix, make_float4(0.0f, 0.0f, 0.0f, 1.0f)));
-  eyeRay.d = normalize(make_float3(u, v, -2.0f));
-  eyeRay.d = mul(c_invViewMatrix, eyeRay.d);
-
-  // find intersection with box
-  float tnear, tfar;
-  int hit = intersectBox(eyeRay, boxMin, boxMax, &tnear, &tfar);
-
-  if (!hit) return;
-
-  if (tnear < 0.0f) tnear = 0.0f;  // clamp to near plane
-
-  // march along ray from front to back, accumulating color
-  float4 sum = make_float4(0.0f);
-  float t = tnear;
-  float3 pos = eyeRay.o + eyeRay.d * tnear;
-  float3 step = eyeRay.d * tstep;
-
-  float lastsample = 0;
-
-  // lastsample = (lastsample-transferOffset)*transferScale;
-  for (int i = 0; i < maxSteps; i++) {
-    // read from 3D texture
-    // remap position to [0, 1] coordinates
-    float3 coord = make_float3(pos.x * 0.5f + 0.5f, pos.y * 0.5f + 0.5f,
-                               pos.z * 0.5f + 0.5f);
-    float sample = tex3D<float>(volumeTex, coord.x, coord.y, coord.z);
-    // sample = (sample-transferOffset)*transferScale;
-    // sample *= 64.0f;    // scale for 10-bit data
-
-    // lookup in transfer function texture
-    float4 col;
-    int tfid = (pos.x < 0);
-
-    if (TFMODE != TF_SINGLE_1D) {
-      col = tex2DLayered<float4>(transferLayerPreintTex, sample,
-                                 TFMODE == TF_LAYERED_2D ? sample : lastsample,
-                                 tfid);
-      col.w *= density;
-      lastsample = sample;
-    } else {
-      col = tex1D<float4>(transferTex, sample);
-      col.w *= 0;
-    }
-
-    // "under" operator for back-to-front blending
-    // sum = lerp(sum, col, col.w);
-
-    // pre-multiply alpha
-    col.x *= col.w;
-    col.y *= col.w;
-    col.z *= col.w;
-    // "over" operator for front-to-back blending
-    sum = sum + col * (1.0f - sum.w);
-
-    // exit early if opaque
-    if (sum.w > opacityThreshold) break;
-
-    t += tstep;
-
-    if (t > tfar) break;
-
-    pos += step;
-  }
-
-  sum *= brightness;
-
-  // write output color
-  d_output[y * imageW + x] = rgbaFloatToInt(sum);
-}
-
-__global__ void d_render_regular(uint *d_output, uint imageW, uint imageH,
-                                 float density, float brightness,
-                                 float transferOffset, float transferScale,
-                                 hipTextureObject_t volumeTex,
-                                 hipTextureObject_t transferTex,
-                                 hipTextureObject_t transferLayerPreintTex,
-                                 float transferWeight = 0.0f) {
-  d_render<TF_SINGLE_1D>(d_output, imageW, imageH, density, brightness,
-                         transferOffset, transferScale, volumeTex, transferTex,
-                         transferLayerPreintTex, transferWeight);
-}
-
-__global__ void d_render_preint(uint *d_output, uint imageW, uint imageH,
-                                float density, float brightness,
-                                float transferOffset, float transferScale,
-                                hipTextureObject_t volumeTex,
-                                hipTextureObject_t transferTex,
-                                hipTextureObject_t transferLayerPreintTex,
-                                float transferWeight = 0.0f) {
-  d_render<TF_LAYERED_2D_PREINT>(d_output, imageW, imageH, density, brightness,
-                                 transferOffset, transferScale, volumeTex,
-                                 transferTex, transferLayerPreintTex,
-                                 transferWeight);
-}
-
-__global__ void d_render_preint_off(uint *d_output, uint imageW, uint imageH,
-                                    float density, float brightness,
-                                    float transferOffset, float transferScale,
-                                    hipTextureObject_t volumeTex,
-                                    hipTextureObject_t transferTex,
-                                    hipTextureObject_t transferLayerPreintTex,
-                                    float transferWeight = 0.0f) {
-  d_render<TF_LAYERED_2D>(d_output, imageW, imageH, density, brightness,
-                          transferOffset, transferScale, volumeTex, transferTex,
-                          transferLayerPreintTex, transferWeight);
-}
-
-//////////////////////////////////////////////////////////////////////////
-
-__global__ void d_integrate_trapezoidal(
-    hipExtent extent, hipTextureObject_t transferTex,
-    hipSurfaceObject_t transferIntegrateSurf) {
-  uint x = blockIdx.x * blockDim.x + threadIdx.x;
-
-  // for higher speed could use hierarchical approach for sum
-  if (x >= extent.width) {
-    return;
-  }
-
-  float stepsize = 1.0 / float(extent.width - 1);
-  float to = float(x) * stepsize;
-
-  float4 outclr = make_float4(0, 0, 0, 0);
-  float incr = stepsize;
-
-  float4 lastval = tex1D<float4>(transferTex, 0);
-
-  float cur = incr;
-
-  while (cur < to + incr * 0.5) {
-    float4 val = tex1D<float4>(transferTex, cur);
-    float4 trapezoid = (lastval + val) / 2.0f;
-    lastval = val;
-
-    outclr += trapezoid;
-    cur += incr;
-  }
-
-  // surface writes need byte offsets for x!
-  surf1Dwrite(outclr, transferIntegrateSurf, x * sizeof(float4));
-}
-
-__global__ void d_preintegrate(int layer, float steps, hipExtent extent,
-                               hipTextureObject_t transferTex,
-                               hipTextureObject_t transferIntegrateTex,
-                               hipSurfaceObject_t transferLayerPreintSurf) {
-  uint x = blockIdx.x * blockDim.x + threadIdx.x;
-  uint y = blockIdx.y * blockDim.y + threadIdx.y;
-
-  if (x >= extent.width || y >= extent.height) {
-    return;
-  }
-
-  float sx = float(x) / float(extent.width);
-  float sy = float(y) / float(extent.height);
-
-  float smax = max(sx, sy);
-  float smin = min(sx, sy);
-
-  float4 iv;
-
-  if (x != y) {
-    // assumes square textures!
-    float fracc = smax - smin;
-    fracc = 1.0 / (fracc * steps);
-
-    float4 intmax = tex1D<float4>(transferIntegrateTex, smax);
-    float4 intmin = tex1D<float4>(transferIntegrateTex, smin);
-    iv.x = (intmax.x - intmin.x) * fracc;
-    iv.y = (intmax.y - intmin.y) * fracc;
-    iv.z = (intmax.z - intmin.z) * fracc;
-    // iv.w = (intmax.w - intmin.w)*fracc;
-    iv.w = (1.0 - exp(-(intmax.w - intmin.w) * fracc));
-  } else {
-    float4 sample = tex1D<float4>(transferTex, smin);
-    iv.x = sample.x;
-    iv.y = sample.y;
-    iv.z = sample.z;
-    // iv.w = sample.w;
-    iv.w = (1.0 - exp(-sample.w));
-  }
-
-  iv.x = __saturatef(iv.x);
-  iv.y = __saturatef(iv.y);
-  iv.z = __saturatef(iv.z);
-  iv.w = __saturatef(iv.w);
-
-  // surface writes need byte offsets for x!
-  surf2DLayeredwrite(iv, transferLayerPreintSurf, x * sizeof(float4), y, layer);
-}
-
-//////////////////////////////////////////////////////////////////////////
-
-void VolumeRender_setTextureFilterMode(bool bLinearFilter, Volume *vol) {
-  if (vol->volumeTex) {
-    HIPCHECK(hipDestroyTextureObject(vol->volumeTex));
-  }
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = vol->content;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = true;
-  texDescr.filterMode =
-      bLinearFilter ? hipFilterModeLinear : hipFilterModePoint;
-
-  texDescr.addressMode[0] = hipAddressModeWrap;
-  texDescr.addressMode[1] = hipAddressModeWrap;
-  texDescr.addressMode[2] = hipAddressModeWrap;
-
-  texDescr.readMode = VolumeTypeInfo<VolumeType>::readMode;
-
-  HIPCHECK(
-      hipCreateTextureObject(&vol->volumeTex, &texRes, &texDescr, NULL));
-}
-
-static unsigned int iDivUp(size_t a, size_t b) {
-  size_t val = (a % b != 0) ? (a / b + 1) : (a / b);
-  if (val > UINT_MAX) {
-    fprintf(stderr, "\nUINT_MAX limit exceeded in iDivUp() exiting.....\n");
-    exit(EXIT_FAILURE);  // val exceeds limit
-  }
-
-  return static_cast<unsigned int>(val);
-}
-
-void VolumeRender_updateTF(int tfIdx, int numColors, float4 *colors) {
-  if (d_transferFunc) {
-    HIPCHECK(hipFreeArray(d_transferFunc));
-    d_transferFunc = 0;
-  }
-
-  hipChannelFormatDesc channelFloat4 = hipCreateChannelDesc<float4>();
-  HIPCHECK(
-      hipMallocArray(&d_transferFunc, &channelFloat4, numColors, 1));
-  HIPCHECK(hipMemcpy2DToArray(d_transferFunc, 0, 0, colors, 0,
-                                      sizeof(float4) * numColors, 1,
-                                      hipMemcpyHostToDevice));
-
-  hipResourceDesc texRes;
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = d_transferFunc;
-
-  hipTextureDesc texDescr;
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = true;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeClamp;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(
-      hipCreateTextureObject(&transferTex, &texRes, &texDescr, NULL));
-
-  if (tfIdx < 0 || tfIdx >= VOLUMERENDER_TFS) {
-    return;
-  }
-
-  {
-    hipExtent extent = {VOLUMERENDER_TF_PREINTSTEPS, 0, 0};
-    dim3 blockSize(32, 1, 1);
-    dim3 gridSize(iDivUp(extent.width, blockSize.x), 1, 1);
-    d_integrate_trapezoidal<<<gridSize, blockSize>>>(extent, transferTex,
-                                                     transferIntegrateSurf);
-  }
-
-  {
-    hipExtent extent = {VOLUMERENDER_TF_PREINTSIZE, VOLUMERENDER_TF_PREINTSIZE,
-                         VOLUMERENDER_TFS};
-    dim3 blockSize(16, 16, 1);
-    dim3 gridSize(iDivUp(extent.width, blockSize.x),
-                  iDivUp(extent.height, blockSize.y), 1);
-    d_preintegrate<<<gridSize, blockSize>>>(
-        tfIdx, float(VOLUMERENDER_TF_PREINTSTEPS), extent, transferTex,
-        transferIntegrateTex, transferLayerPreintSurf);
-  }
-}
-
-void VolumeRender_init() {
-  hipResourceDesc texRes;
-  hipTextureDesc texDescr;
-
-  hipChannelFormatDesc channelFloat4 = hipCreateChannelDesc<float4>();
-  hipExtent extent = {VOLUMERENDER_TF_PREINTSIZE, VOLUMERENDER_TF_PREINTSIZE,
-                       VOLUMERENDER_TFS};
-  HIPCHECK(
-      hipMalloc3DArray(&d_transferArray, &channelFloat4, extent,
-                        hipArrayLayered | hipArraySurfaceLoadStore));
-
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = d_transferArray;
-
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = true;
-  texDescr.filterMode = hipFilterModeLinear;
-  texDescr.addressMode[0] = hipAddressModeClamp;
-  texDescr.addressMode[1] = hipAddressModeClamp;
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(hipCreateTextureObject(&transferLayerPreintTex, &texRes,
-                                          &texDescr, NULL));
-
-  hipResourceDesc surfRes;
-  memset(&surfRes, 0, sizeof(hipResourceDesc));
-  surfRes.resType = hipResourceTypeArray;
-  surfRes.res.array.array = d_transferArray;
-
-  HIPCHECK(hipCreateSurfaceObject(&transferLayerPreintSurf, &surfRes));
-
-  HIPCHECK(hipMallocArray(&d_transferIntegrate, &channelFloat4,
-                                  VOLUMERENDER_TF_PREINTSTEPS, 0,
-                                  hipArraySurfaceLoadStore));
-
-  memset(&texRes, 0, sizeof(hipResourceDesc));
-
-  texRes.resType = hipResourceTypeArray;
-  texRes.res.array.array = d_transferIntegrate;
-
-  memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-  texDescr.normalizedCoords = true;
-  texDescr.filterMode = hipFilterModeLinear;
-
-  texDescr.addressMode[0] = hipAddressModeClamp;
-  texDescr.addressMode[1] = hipAddressModeClamp;
-  texDescr.addressMode[2] = hipAddressModeClamp;
-
-  texDescr.readMode = hipReadModeElementType;
-
-  HIPCHECK(
-      hipCreateTextureObject(&transferIntegrateTex, &texRes, &texDescr, NULL));
-
-  memset(&surfRes, 0, sizeof(hipResourceDesc));
-  surfRes.resType = hipResourceTypeArray;
-  surfRes.res.array.array = d_transferIntegrate;
-
-  HIPCHECK(hipCreateSurfaceObject(&transferIntegrateSurf, &surfRes));
-
-  // create transfer function texture
-  float4 transferFunc0[] = {
-    {  0.0, 0.0, 0.0, 0.0, },
-    {  1.0, 0.0, 0.0, 1.0, },
-    {  1.0, 0.5, 0.0, 1.0, },
-    {  1.0, 1.0, 0.0, 1.0, },
-    {  0.0, 1.0, 0.0, 1.0, },
-    {  0.0, 1.0, 1.0, 1.0, },
-    {  0.0, 0.0, 1.0, 1.0, },
-    {  1.0, 0.0, 1.0, 1.0, },
-    {  0.0, 0.0, 0.0, 0.0, },
-  };
-
-  float4 transferFunc1[] = {
-    {  0.0, 0.0, 0.0, 0.0, },
-    {  0.0, 1.0, 0.0, 0.125, },
-    {  0.0, 0.5, 1.0, 0.125, },
-    {  0.0, 1.0, 1.0, 0.125, },
-    {  0.0, 1.0, 0.0, 0.125, },
-    {  0.25, 0.75, 0.0, 1.0, },
-    {  0.75, 0.25, 0.0, 0.125, },
-    {  1.0, 0.75, 0.0, 0.125, },
-    {  0.0, 0.0, 0.0, 0.0, },
-  };
-
-  VolumeRender_updateTF(1, sizeof(transferFunc1) / sizeof(float4),
-                        transferFunc1);
-  VolumeRender_updateTF(0, sizeof(transferFunc0) / sizeof(float4),
-                        transferFunc0);
-}
-
-void VolumeRender_deinit() {
-  HIPCHECK(hipDestroyTextureObject(transferTex));
-  HIPCHECK(hipDestroyTextureObject(transferIntegrateTex));
-  HIPCHECK(hipDestroySurfaceObject(transferIntegrateSurf));
-  HIPCHECK(hipDestroyTextureObject(transferLayerPreintTex));
-  HIPCHECK(hipDestroySurfaceObject(transferLayerPreintSurf));
-  HIPCHECK(hipFreeArray(d_transferFunc));
-  HIPCHECK(hipFreeArray(d_transferArray));
-  HIPCHECK(hipFreeArray(d_transferIntegrate));
-  d_transferArray = 0;
-  d_transferFunc = 0;
-  d_transferIntegrate = 0;
-}
-
-void VolumeRender_setPreIntegrated(int state) { usePreInt = !!state; }
-
-void VolumeRender_render(dim3 gridSize, dim3 blockSize, uint *d_output,
-                         uint imageW, uint imageH, float density,
-                         float brightness, float transferOffset,
-                         float transferScale, hipTextureObject_t volumeTex) {
-  if (usePreInt) {
-    d_render_preint<<<gridSize, blockSize>>>(
-        d_output, imageW, imageH, density, brightness, transferOffset,
-        transferScale, volumeTex, transferTex, transferLayerPreintTex);
-  } else {
-    d_render_preint_off<<<gridSize, blockSize>>>(
-        d_output, imageW, imageH, density, brightness, transferOffset,
-        transferScale, volumeTex, transferTex, transferLayerPreintTex);
-  }
-}
-
-void VolumeRender_copyInvViewMatrix(float *invViewMatrix, size_t sizeofMatrix) {
-  HIPCHECK(
-      hipMemcpyToSymbol(HIP_SYMBOL(c_invViewMatrix), invViewMatrix, sizeofMatrix));
-}
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume_hipified.cpp b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume_hipified.h b/src/samples/Samples/5_Domain_Specific/volumeFiltering/volume_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/volumeRender/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/volumeRender/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/volumeRender/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/volumeRender/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/Makefile b/src/samples/Samples/5_Domain_Specific/volumeRender/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/volumeRender/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/README.md b/src/samples/Samples/5_Domain_Specific/volumeRender/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/data/Bucky.raw b/src/samples/Samples/5_Domain_Specific/volumeRender/data/Bucky.raw
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/data/ref_volume.ppm b/src/samples/Samples/5_Domain_Specific/volumeRender/data/ref_volume.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/doc/sshot_lg.JPG b/src/samples/Samples/5_Domain_Specific/volumeRender/doc/sshot_lg.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/doc/sshot_md.jpg b/src/samples/Samples/5_Domain_Specific/volumeRender/doc/sshot_md.jpg
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/doc/sshot_sm.JPG b/src/samples/Samples/5_Domain_Specific/volumeRender/doc/sshot_sm.JPG
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/findgllib.mk b/src/samples/Samples/5_Domain_Specific/volumeRender/findgllib.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender.cpp b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_hipified.cpp b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_kernel.cu b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_kernel.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_kernel.cu.hip b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_kernel.cu.hip
old mode 100644
new mode 100755
index c4e55f2..9df9611
--- a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_kernel.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_kernel.cu.hip
@@ -308,3 +308,7 @@ extern "C" void copyInvViewMatrix(float *invViewMatrix, size_t sizeofMatrix) {
   HIPCHECK(
       hipMemcpyToSymbol(HIP_SYMBOL(c_invViewMatrix), invViewMatrix, sizeofMatrix));
 }
+
+#endif  // #ifndef _VOLUMERENDER_KERNEL_CU_
+ViewMatrix), invViewMatrix, sizeofMatrix));
+}
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2017.sln b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2019.sln b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2022.sln b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/volumeRender/volumeRender_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/.vscode/c_cpp_properties.json b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/.vscode/extensions.json b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/.vscode/launch.json b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/.vscode/tasks.json b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/Build_instructions.txt b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/Build_instructions.txt
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/Makefile b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/NsightEclipse.xml b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/README.md b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/findvulkan.mk b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/findvulkan.mk
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/frag.spv b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/frag.spv
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/linmath.h b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/linmath.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/linmath_hipified.h b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/linmath_hipified.h
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/shader.frag b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/shader.frag
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/shader.vert b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/shader.vert
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/teapot1024.ppm b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/teapot1024.ppm
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vert.spv b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vert.spv
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA.cu b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA.cu.hip b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA.cu.hip
old mode 100644
new mode 100755
index c87a8e1..e69de29
--- a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA.cu.hip
+++ b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA.cu.hip
@@ -1,2647 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#define GLFW_INCLUDE_VULKAN
-#ifdef _WIN64
-#include <aclapi.h>
-#include <dxgi1_2.h>
-#include <windows.h>
-#include <VersionHelpers.h>
-#define _USE_MATH_DEFINES
-#endif
-
-#include <GLFW/glfw3.h>
-#include <vulkan/vulkan.h>
-#ifdef _WIN64
-#include <vulkan/vulkan_win32.h>
-#endif
-
-#include <algorithm>
-#include <array>
-#include <chrono>
-#include <cstdlib>
-#include <cstring>
-#include <fstream>
-#include <iostream>
-#include <set>
-#include <stdexcept>
-#include <thread>
-#include <vector>
-
-#include <hip/hip_runtime.h>
-#include <hip/hip_runtime.h>
-#include "helper_cuda_hipified.h"
-#include <helper_image.h>
-#include <helper_math.h>
-
-#include "linmath.h"
-
-#define WIDTH 800
-#define HEIGHT 600
-
-const int MAX_FRAMES = 4;
-
-const std::vector<const char*> validationLayers = {
-    "VK_LAYER_KHRONOS_validation"};
-
-#ifdef NDEBUG
-const bool enableValidationLayers = true;
-#else
-const bool enableValidationLayers = false;
-#endif
-
-std::string execution_path;
-
-VkResult CreateDebugUtilsMessengerEXT(
-    VkInstance instance, const VkDebugUtilsMessengerCreateInfoEXT* pCreateInfo,
-    const VkAllocationCallbacks* pAllocator,
-    VkDebugUtilsMessengerEXT* pDebugMessenger) {
-  auto func = (PFN_vkCreateDebugUtilsMessengerEXT)vkGetInstanceProcAddr(
-      instance, "vkCreateDebugUtilsMessengerEXT");
-  if (func != nullptr) {
-    return func(instance, pCreateInfo, pAllocator, pDebugMessenger);
-  } else {
-    return VK_ERROR_EXTENSION_NOT_PRESENT;
-  }
-};
-
-const std::vector<const char*> deviceExtensions = {
-    VK_KHR_SWAPCHAIN_EXTENSION_NAME,
-    VK_KHR_EXTERNAL_MEMORY_EXTENSION_NAME,
-    VK_KHR_EXTERNAL_SEMAPHORE_EXTENSION_NAME,
-#ifdef _WIN64
-    VK_KHR_EXTERNAL_MEMORY_WIN32_EXTENSION_NAME,
-    VK_KHR_EXTERNAL_SEMAPHORE_WIN32_EXTENSION_NAME,
-#else
-    VK_KHR_EXTERNAL_MEMORY_FD_EXTENSION_NAME,
-    VK_KHR_EXTERNAL_SEMAPHORE_FD_EXTENSION_NAME,
-#endif
-};
-
-#ifdef _WIN64
-class WindowsSecurityAttributes {
- protected:
-  SECURITY_ATTRIBUTES m_winSecurityAttributes;
-  PSECURITY_DESCRIPTOR m_winPSecurityDescriptor;
-
- public:
-  WindowsSecurityAttributes();
-  SECURITY_ATTRIBUTES* operator&();
-  ~WindowsSecurityAttributes();
-};
-
-WindowsSecurityAttributes::WindowsSecurityAttributes() {
-  m_winPSecurityDescriptor = (PSECURITY_DESCRIPTOR)calloc(
-      1, SECURITY_DESCRIPTOR_MIN_LENGTH + 2 * sizeof(void**));
-
-  PSID* ppSID =
-      (PSID*)((PBYTE)m_winPSecurityDescriptor + SECURITY_DESCRIPTOR_MIN_LENGTH);
-  PACL* ppACL = (PACL*)((PBYTE)ppSID + sizeof(PSID*));
-
-  InitializeSecurityDescriptor(m_winPSecurityDescriptor,
-                               SECURITY_DESCRIPTOR_REVISION);
-
-  SID_IDENTIFIER_AUTHORITY sidIdentifierAuthority =
-      SECURITY_WORLD_SID_AUTHORITY;
-  AllocateAndInitializeSid(&sidIdentifierAuthority, 1, SECURITY_WORLD_RID, 0, 0,
-                           0, 0, 0, 0, 0, ppSID);
-
-  EXPLICIT_ACCESS explicitAccess;
-  ZeroMemory(&explicitAccess, sizeof(EXPLICIT_ACCESS));
-  explicitAccess.grfAccessPermissions =
-      STANDARD_RIGHTS_ALL | SPECIFIC_RIGHTS_ALL;
-  explicitAccess.grfAccessMode = SET_ACCESS;
-  explicitAccess.grfInheritance = INHERIT_ONLY;
-  explicitAccess.Trustee.TrusteeForm = TRUSTEE_IS_SID;
-  explicitAccess.Trustee.TrusteeType = TRUSTEE_IS_WELL_KNOWN_GROUP;
-  explicitAccess.Trustee.ptstrName = (LPTSTR)*ppSID;
-
-  SetEntriesInAcl(1, &explicitAccess, NULL, ppACL);
-
-  SetSecurityDescriptorDacl(m_winPSecurityDescriptor, TRUE, *ppACL, FALSE);
-
-  m_winSecurityAttributes.nLength = sizeof(m_winSecurityAttributes);
-  m_winSecurityAttributes.lpSecurityDescriptor = m_winPSecurityDescriptor;
-  m_winSecurityAttributes.bInheritHandle = TRUE;
-}
-
-SECURITY_ATTRIBUTES* WindowsSecurityAttributes::operator&() {
-  return &m_winSecurityAttributes;
-}
-
-WindowsSecurityAttributes::~WindowsSecurityAttributes() {
-  PSID* ppSID =
-      (PSID*)((PBYTE)m_winPSecurityDescriptor + SECURITY_DESCRIPTOR_MIN_LENGTH);
-  PACL* ppACL = (PACL*)((PBYTE)ppSID + sizeof(PSID*));
-
-  if (*ppSID) {
-    FreeSid(*ppSID);
-  }
-  if (*ppACL) {
-    LocalFree(*ppACL);
-  }
-  free(m_winPSecurityDescriptor);
-}
-#endif
-
-void DestroyDebugUtilsMessengerEXT(VkInstance instance,
-                                   VkDebugUtilsMessengerEXT debugMessenger,
-                                   const VkAllocationCallbacks* pAllocator) {
-  auto func = (PFN_vkDestroyDebugUtilsMessengerEXT)vkGetInstanceProcAddr(
-      instance, "vkDestroyDebugUtilsMessengerEXT");
-  if (func != nullptr) {
-    func(instance, debugMessenger, pAllocator);
-  }
-}
-
-struct QueueFamilyIndices {
-  int graphicsFamily = -1;
-  int presentFamily = -1;
-
-  bool isComplete() { return graphicsFamily >= 0 && presentFamily >= 0; }
-};
-
-struct SwapChainSupportDetails {
-  VkSurfaceCapabilitiesKHR capabilities;
-  std::vector<VkSurfaceFormatKHR> formats;
-  std::vector<VkPresentModeKHR> presentModes;
-};
-
-typedef float vec2[2];
-
-struct Vertex {
-  vec4 pos;
-  vec3 color;
-  vec2 texCoord;
-
-  static VkVertexInputBindingDescription getBindingDescription() {
-    VkVertexInputBindingDescription bindingDescription = {};
-    bindingDescription.binding = 0;
-    bindingDescription.stride = sizeof(Vertex);
-    bindingDescription.inputRate = VK_VERTEX_INPUT_RATE_VERTEX;
-
-    return bindingDescription;
-  }
-
-  static std::array<VkVertexInputAttributeDescription, 3>
-  getAttributeDescriptions() {
-    std::array<VkVertexInputAttributeDescription, 3> attributeDescriptions = {};
-
-    attributeDescriptions[0].binding = 0;
-    attributeDescriptions[0].location = 0;
-    attributeDescriptions[0].format = VK_FORMAT_R32G32B32A32_SFLOAT;
-    attributeDescriptions[0].offset = offsetof(Vertex, pos);
-
-    attributeDescriptions[1].binding = 0;
-    attributeDescriptions[1].location = 1;
-    attributeDescriptions[1].format = VK_FORMAT_R32G32B32_SFLOAT;
-    attributeDescriptions[1].offset = offsetof(Vertex, color);
-
-    attributeDescriptions[2].binding = 0;
-    attributeDescriptions[2].location = 2;
-    attributeDescriptions[2].format = VK_FORMAT_R32G32_SFLOAT;
-    attributeDescriptions[2].offset = offsetof(Vertex, texCoord);
-
-    return attributeDescriptions;
-  }
-};
-
-struct UniformBufferObject {
-  alignas(16) mat4x4 model;
-  alignas(16) mat4x4 view;
-  alignas(16) mat4x4 proj;
-};
-
-const std::vector<Vertex> vertices = {
-    {{-1.0f, -1.0f, 0.0f, 1.0f}, {1.0f, 0.0f, 0.0f}, {0.0f, 0.0f}},
-    {{1.0f, -1.0f, 0.0f, 1.0f}, {0.0f, 1.0f, 0.0f}, {1.0f, 0.0f}},
-    {{1.0f, 1.0f, 0.0f, 1.0f}, {0.0f, 0.0f, 1.0f}, {1.0f, 1.0f}},
-    {{-1.0f, 1.0f, 0.0f, 1.0f}, {1.0f, 1.0f, 1.0f}, {0.0f, 1.0f}}};
-
-const std::vector<uint16_t> indices = {0, 1, 2, 2, 3, 0};
-
-// convert floating point rgba color to 32-bit integer
-__device__ unsigned int rgbaFloatToInt(float4 rgba) {
-  rgba.x = __saturatef(rgba.x);  // clamp to [0.0, 1.0]
-  rgba.y = __saturatef(rgba.y);
-  rgba.z = __saturatef(rgba.z);
-  rgba.w = __saturatef(rgba.w);
-  return ((unsigned int)(rgba.w * 255.0f) << 24) |
-         ((unsigned int)(rgba.z * 255.0f) << 16) |
-         ((unsigned int)(rgba.y * 255.0f) << 8) |
-         ((unsigned int)(rgba.x * 255.0f));
-}
-
-__device__ float4 rgbaIntToFloat(unsigned int c) {
-  float4 rgba;
-  rgba.x = (c & 0xff) * 0.003921568627f;          //  /255.0f;
-  rgba.y = ((c >> 8) & 0xff) * 0.003921568627f;   //  /255.0f;
-  rgba.z = ((c >> 16) & 0xff) * 0.003921568627f;  //  /255.0f;
-  rgba.w = ((c >> 24) & 0xff) * 0.003921568627f;  //  /255.0f;
-  return rgba;
-}
-
-int filter_radius = 14;
-int g_nFilterSign = 1;
-
-// This varies the filter radius, so we can see automatic animation
-void varySigma() {
-  filter_radius += g_nFilterSign;
-
-  if (filter_radius > 64) {
-    filter_radius = 64;  // clamp to 64 and then negate sign
-    g_nFilterSign = -1;
-  } else if (filter_radius < 0) {
-    filter_radius = 0;
-    g_nFilterSign = 1;
-  }
-}
-
-// row pass using texture lookups
-__global__ void d_boxfilter_rgba_x(hipSurfaceObject_t* dstSurfMipMapArray,
-                                   hipTextureObject_t textureMipMapInput,
-                                   size_t baseWidth, size_t baseHeight,
-                                   size_t mipLevels, int filter_radius) {
-  float scale = 1.0f / (float)((filter_radius << 1) + 1);
-  unsigned int y = blockIdx.x * blockDim.x + threadIdx.x;
-
-  if (y < baseHeight) {
-    for (uint32_t mipLevelIdx = 0; mipLevelIdx < mipLevels; mipLevelIdx++) {
-      uint32_t width =
-          (baseWidth >> mipLevelIdx) ? (baseWidth >> mipLevelIdx) : 1;
-      uint32_t height =
-          (baseHeight >> mipLevelIdx) ? (baseHeight >> mipLevelIdx) : 1;
-      if (y < height && filter_radius < width) {
-        float px = 1.0 / width;
-        float py = 1.0 / height;
-        float4 t = make_float4(0.0f);
-        for (int x = -filter_radius; x <= filter_radius; x++) {
-          t += tex2DLod<float4>(textureMipMapInput, x * px, y * py,
-                                (float)mipLevelIdx);
-        }
-
-        unsigned int dataB = rgbaFloatToInt(t * scale);
-        surf2Dwrite(dataB, dstSurfMipMapArray[mipLevelIdx], 0, y);
-
-        for (int x = 1; x < width; x++) {
-          t += tex2DLod<float4>(textureMipMapInput, (x + filter_radius) * px,
-                                y * py, (float)mipLevelIdx);
-          t -=
-              tex2DLod<float4>(textureMipMapInput, (x - filter_radius - 1) * px,
-                               y * py, (float)mipLevelIdx);
-          unsigned int dataB = rgbaFloatToInt(t * scale);
-          surf2Dwrite(dataB, dstSurfMipMapArray[mipLevelIdx],
-                      x * sizeof(uchar4), y);
-        }
-      }
-    }
-  }
-}
-
-// column pass using coalesced global memory reads
-__global__ void d_boxfilter_rgba_y(hipSurfaceObject_t* dstSurfMipMapArray,
-                                   hipSurfaceObject_t* srcSurfMipMapArray,
-                                   size_t baseWidth, size_t baseHeight,
-                                   size_t mipLevels, int filter_radius) {
-  unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;
-  float scale = 1.0f / (float)((filter_radius << 1) + 1);
-
-  for (uint32_t mipLevelIdx = 0; mipLevelIdx < mipLevels; mipLevelIdx++) {
-    uint32_t width =
-        (baseWidth >> mipLevelIdx) ? (baseWidth >> mipLevelIdx) : 1;
-    uint32_t height =
-        (baseHeight >> mipLevelIdx) ? (baseHeight >> mipLevelIdx) : 1;
-
-    if (x < width && height > filter_radius) {
-      float4 t;
-      // do left edge
-      int colInBytes = x * sizeof(uchar4);
-      unsigned int pixFirst = surf2Dread<unsigned int>(
-          srcSurfMipMapArray[mipLevelIdx], colInBytes, 0);
-      t = rgbaIntToFloat(pixFirst) * filter_radius;
-
-      for (int y = 0; (y < (filter_radius + 1)) && (y < height); y++) {
-        unsigned int pix = surf2Dread<unsigned int>(
-            srcSurfMipMapArray[mipLevelIdx], colInBytes, y);
-        t += rgbaIntToFloat(pix);
-      }
-
-      unsigned int dataB = rgbaFloatToInt(t * scale);
-      surf2Dwrite(dataB, dstSurfMipMapArray[mipLevelIdx], colInBytes, 0);
-
-      for (int y = 1; (y < filter_radius + 1) && ((y + filter_radius) < height);
-           y++) {
-        unsigned int pix = surf2Dread<unsigned int>(
-            srcSurfMipMapArray[mipLevelIdx], colInBytes, y + filter_radius);
-        t += rgbaIntToFloat(pix);
-        t -= rgbaIntToFloat(pixFirst);
-
-        dataB = rgbaFloatToInt(t * scale);
-        surf2Dwrite(dataB, dstSurfMipMapArray[mipLevelIdx], colInBytes, y);
-      }
-
-      // main loop
-      for (int y = (filter_radius + 1); y < (height - filter_radius); y++) {
-        unsigned int pix = surf2Dread<unsigned int>(
-            srcSurfMipMapArray[mipLevelIdx], colInBytes, y + filter_radius);
-        t += rgbaIntToFloat(pix);
-
-        pix = surf2Dread<unsigned int>(srcSurfMipMapArray[mipLevelIdx],
-                                       colInBytes, y - filter_radius - 1);
-        t -= rgbaIntToFloat(pix);
-
-        dataB = rgbaFloatToInt(t * scale);
-        surf2Dwrite(dataB, dstSurfMipMapArray[mipLevelIdx], colInBytes, y);
-      }
-
-      // do right edge
-      unsigned int pixLast = surf2Dread<unsigned int>(
-          srcSurfMipMapArray[mipLevelIdx], colInBytes, height - 1);
-      for (int y = height - filter_radius;
-           (y < height) && ((y - filter_radius - 1) > 1); y++) {
-        t += rgbaIntToFloat(pixLast);
-        unsigned int pix = surf2Dread<unsigned int>(
-            srcSurfMipMapArray[mipLevelIdx], colInBytes, y - filter_radius - 1);
-        t -= rgbaIntToFloat(pix);
-        dataB = rgbaFloatToInt(t * scale);
-        surf2Dwrite(dataB, dstSurfMipMapArray[mipLevelIdx], colInBytes, y);
-      }
-    }
-  }
-}
-
-class vulkanImageCUDA {
- public:
-  void loadImageData(const std::string& filename) {
-    // load image (needed so we can get the width and height before we create
-    // the window
-    char* image_path =
-        sdkFindFilePath(filename.c_str(), execution_path.c_str());
-
-    if (image_path == 0) {
-      printf("Error finding image file '%s'\n", filename.c_str());
-      exit(EXIT_FAILURE);
-    }
-
-    sdkLoadPPM4(image_path, (unsigned char**)&image_data, &imageWidth,
-                &imageHeight);
-
-    if (!image_data) {
-      printf("Error opening file '%s'\n", image_path);
-      exit(EXIT_FAILURE);
-    }
-
-    printf("Loaded '%s', %d x %d pixels\n", image_path, imageWidth,
-           imageHeight);
-  }
-
-  void run() {
-    initWindow();
-    initVulkan();
-    initCuda();
-    mainLoop();
-    cleanup();
-  }
-
- private:
-  GLFWwindow* window;
-
-  VkInstance instance;
-  VkDebugUtilsMessengerEXT debugMessenger;
-  VkSurfaceKHR surface;
-
-  VkPhysicalDevice physicalDevice = VK_NULL_HANDLE;
-  VkDevice device;
-  uint8_t vkDeviceUUID[VK_UUID_SIZE];
-
-  VkQueue graphicsQueue;
-  VkQueue presentQueue;
-
-  VkSwapchainKHR swapChain;
-  std::vector<VkImage> swapChainImages;
-  VkFormat swapChainImageFormat;
-  VkExtent2D swapChainExtent;
-  std::vector<VkImageView> swapChainImageViews;
-  std::vector<VkFramebuffer> swapChainFramebuffers;
-
-  VkRenderPass renderPass;
-  VkDescriptorSetLayout descriptorSetLayout;
-  VkPipelineLayout pipelineLayout;
-  VkPipeline graphicsPipeline;
-
-  VkCommandPool commandPool;
-
-  VkImage textureImage;
-  VkDeviceMemory textureImageMemory;
-  VkImageView textureImageView;
-  VkSampler textureSampler;
-
-  VkBuffer vertexBuffer;
-  VkDeviceMemory vertexBufferMemory;
-  VkBuffer indexBuffer;
-  VkDeviceMemory indexBufferMemory;
-
-  std::vector<VkBuffer> uniformBuffers;
-  std::vector<VkDeviceMemory> uniformBuffersMemory;
-
-  VkDescriptorPool descriptorPool;
-  std::vector<VkDescriptorSet> descriptorSets;
-
-  std::vector<VkCommandBuffer> commandBuffers;
-
-  std::vector<VkSemaphore> imageAvailableSemaphores;
-  std::vector<VkSemaphore> renderFinishedSemaphores;
-  VkSemaphore cudaUpdateVkSemaphore, vkUpdateCudaSemaphore;
-  std::vector<VkFence> inFlightFences;
-
-  size_t currentFrame = 0;
-
-  bool framebufferResized = false;
-
-#ifdef _WIN64
-  PFN_vkGetMemoryWin32HandleKHR fpGetMemoryWin32HandleKHR;
-  PFN_vkGetSemaphoreWin32HandleKHR fpGetSemaphoreWin32HandleKHR;
-#else
-  PFN_vkGetMemoryFdKHR fpGetMemoryFdKHR = NULL;
-  PFN_vkGetSemaphoreFdKHR fpGetSemaphoreFdKHR = NULL;
-#endif
-
-  PFN_vkGetPhysicalDeviceProperties2 fpGetPhysicalDeviceProperties2;
-
-  unsigned int* image_data = NULL;
-  unsigned int imageWidth, imageHeight;
-  unsigned int mipLevels = 1;
-  size_t totalImageMemSize;
-
-  // CUDA objects
-  hipExternalMemory_t cudaExtMemImageBuffer;
-  hipMipmappedArray_t cudaMipmappedImageArray, cudaMipmappedImageArrayTemp,
-      cudaMipmappedImageArrayOrig;
-  std::vector<hipSurfaceObject_t> surfaceObjectList, surfaceObjectListTemp;
-  hipSurfaceObject_t *d_surfaceObjectList, *d_surfaceObjectListTemp;
-  hipTextureObject_t textureObjMipMapInput;
-
-  hipExternalSemaphore_t cudaExtCudaUpdateVkSemaphore;
-  hipExternalSemaphore_t cudaExtVkUpdateCudaSemaphore;
-  hipStream_t streamToRun;
-
-  void initWindow() {
-    glfwInit();
-
-    glfwWindowHint(GLFW_CLIENT_API, GLFW_NO_API);
-
-    window = glfwCreateWindow(WIDTH, HEIGHT, "Vulkan Image CUDA Box Filter",
-                              nullptr, nullptr);
-    glfwSetWindowUserPointer(window, this);
-    glfwSetFramebufferSizeCallback(window, framebufferResizeCallback);
-  }
-
-  static void framebufferResizeCallback(GLFWwindow* window, int width,
-                                        int height) {
-    auto app =
-        reinterpret_cast<vulkanImageCUDA*>(glfwGetWindowUserPointer(window));
-    app->framebufferResized = true;
-  }
-
-  void initVulkan() {
-    createInstance();
-    setupDebugMessenger();
-    createSurface();
-    pickPhysicalDevice();
-    createLogicalDevice();
-    getKhrExtensionsFn();
-    createSwapChain();
-    createImageViews();
-    createRenderPass();
-    createDescriptorSetLayout();
-    createGraphicsPipeline();
-    createFramebuffers();
-    createCommandPool();
-    createTextureImage();
-    createTextureImageView();
-    createTextureSampler();
-    createVertexBuffer();
-    createIndexBuffer();
-    createUniformBuffers();
-    createDescriptorPool();
-    createDescriptorSets();
-    createCommandBuffers();
-    createSyncObjects();
-    createSyncObjectsExt();
-  }
-
-  void initCuda() {
-    setCudaVkDevice();
-    HIPCHECK(hipStreamCreate(&streamToRun));
-    cudaVkImportImageMem();
-    cudaVkImportSemaphore();
-  }
-
-  void mainLoop() {
-    updateUniformBuffer();
-    while (!glfwWindowShouldClose(window)) {
-      glfwPollEvents();
-      drawFrame();
-    }
-
-    vkDeviceWaitIdle(device);
-  }
-
-  void cleanupSwapChain() {
-    for (auto framebuffer : swapChainFramebuffers) {
-      vkDestroyFramebuffer(device, framebuffer, nullptr);
-    }
-
-    vkFreeCommandBuffers(device, commandPool,
-                         static_cast<uint32_t>(commandBuffers.size()),
-                         commandBuffers.data());
-
-    vkDestroyPipeline(device, graphicsPipeline, nullptr);
-    vkDestroyPipelineLayout(device, pipelineLayout, nullptr);
-    vkDestroyRenderPass(device, renderPass, nullptr);
-
-    for (auto imageView : swapChainImageViews) {
-      vkDestroyImageView(device, imageView, nullptr);
-    }
-
-    vkDestroySwapchainKHR(device, swapChain, nullptr);
-
-    for (size_t i = 0; i < swapChainImages.size(); i++) {
-      vkDestroyBuffer(device, uniformBuffers[i], nullptr);
-      vkFreeMemory(device, uniformBuffersMemory[i], nullptr);
-    }
-
-    vkDestroyDescriptorPool(device, descriptorPool, nullptr);
-  }
-
-  void cleanup() {
-    cleanupSwapChain();
-
-    vkDestroySampler(device, textureSampler, nullptr);
-    vkDestroyImageView(device, textureImageView, nullptr);
-
-    for (int i = 0; i < mipLevels; i++) {
-      HIPCHECK(hipDestroySurfaceObject(surfaceObjectList[i]));
-      HIPCHECK(hipDestroySurfaceObject(surfaceObjectListTemp[i]));
-    }
-
-    HIPCHECK(hipFree(d_surfaceObjectList));
-    HIPCHECK(hipFree(d_surfaceObjectListTemp));
-    HIPCHECK(hipFreeMipmappedArray(cudaMipmappedImageArrayTemp));
-    HIPCHECK(hipFreeMipmappedArray(cudaMipmappedImageArrayOrig));
-    HIPCHECK(hipFreeMipmappedArray(cudaMipmappedImageArray));
-    HIPCHECK(hipDestroyTextureObject(textureObjMipMapInput));
-    HIPCHECK(hipDestroyExternalMemory(cudaExtMemImageBuffer));
-    HIPCHECK(hipDestroyExternalSemaphore(cudaExtCudaUpdateVkSemaphore));
-    HIPCHECK(hipDestroyExternalSemaphore(cudaExtVkUpdateCudaSemaphore));
-
-    vkDestroyImage(device, textureImage, nullptr);
-    vkFreeMemory(device, textureImageMemory, nullptr);
-
-    vkDestroyDescriptorSetLayout(device, descriptorSetLayout, nullptr);
-
-    vkDestroyBuffer(device, indexBuffer, nullptr);
-    vkFreeMemory(device, indexBufferMemory, nullptr);
-
-    vkDestroyBuffer(device, vertexBuffer, nullptr);
-    vkFreeMemory(device, vertexBufferMemory, nullptr);
-
-    vkDestroySemaphore(device, cudaUpdateVkSemaphore, nullptr);
-    vkDestroySemaphore(device, vkUpdateCudaSemaphore, nullptr);
-
-    for (size_t i = 0; i < MAX_FRAMES; i++) {
-      vkDestroySemaphore(device, renderFinishedSemaphores[i], nullptr);
-      vkDestroySemaphore(device, imageAvailableSemaphores[i], nullptr);
-      vkDestroyFence(device, inFlightFences[i], nullptr);
-    }
-
-    vkDestroyCommandPool(device, commandPool, nullptr);
-
-    vkDestroyDevice(device, nullptr);
-
-    if (enableValidationLayers) {
-      DestroyDebugUtilsMessengerEXT(instance, debugMessenger, nullptr);
-    }
-
-    vkDestroySurfaceKHR(instance, surface, nullptr);
-    vkDestroyInstance(instance, nullptr);
-
-    glfwDestroyWindow(window);
-
-    glfwTerminate();
-  }
-
-  void recreateSwapChain() {
-    int width = 0, height = 0;
-    while (width == 0 || height == 0) {
-      glfwGetFramebufferSize(window, &width, &height);
-      glfwWaitEvents();
-    }
-
-    vkDeviceWaitIdle(device);
-
-    cleanupSwapChain();
-
-    createSwapChain();
-    createImageViews();
-    createRenderPass();
-    createGraphicsPipeline();
-    createFramebuffers();
-    createUniformBuffers();
-    createDescriptorPool();
-    createDescriptorSets();
-    createCommandBuffers();
-  }
-
-  void createInstance() {
-    if (enableValidationLayers && !checkValidationLayerSupport()) {
-      throw std::runtime_error(
-          "validation layers requested, but not available!");
-    }
-
-    VkApplicationInfo appInfo = {};
-    appInfo.sType = VK_STRUCTURE_TYPE_APPLICATION_INFO;
-    appInfo.pApplicationName = "Vulkan Image CUDA Interop";
-    appInfo.applicationVersion = VK_MAKE_VERSION(1, 0, 0);
-    appInfo.pEngineName = "No Engine";
-    appInfo.engineVersion = VK_MAKE_VERSION(1, 0, 0);
-    appInfo.apiVersion = VK_API_VERSION_1_1;
-
-    VkInstanceCreateInfo createInfo = {};
-    createInfo.sType = VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO;
-    createInfo.pApplicationInfo = &appInfo;
-
-    auto extensions = getRequiredExtensions();
-    createInfo.enabledExtensionCount = static_cast<uint32_t>(extensions.size());
-    createInfo.ppEnabledExtensionNames = extensions.data();
-
-    VkDebugUtilsMessengerCreateInfoEXT debugCreateInfo;
-    if (enableValidationLayers) {
-      createInfo.enabledLayerCount =
-          static_cast<uint32_t>(validationLayers.size());
-      createInfo.ppEnabledLayerNames = validationLayers.data();
-
-      populateDebugMessengerCreateInfo(debugCreateInfo);
-      createInfo.pNext = (VkDebugUtilsMessengerCreateInfoEXT*)&debugCreateInfo;
-    } else {
-      createInfo.enabledLayerCount = 0;
-
-      createInfo.pNext = nullptr;
-    }
-
-    if (vkCreateInstance(&createInfo, nullptr, &instance) != VK_SUCCESS) {
-      throw std::runtime_error("failed to create instance!");
-    }
-
-    fpGetPhysicalDeviceProperties2 =
-        (PFN_vkGetPhysicalDeviceProperties2)vkGetInstanceProcAddr(
-            instance, "vkGetPhysicalDeviceProperties2");
-    if (fpGetPhysicalDeviceProperties2 == NULL) {
-      throw std::runtime_error(
-          "Vulkan: Proc address for \"vkGetPhysicalDeviceProperties2KHR\" not "
-          "found.\n");
-    }
-
-#ifdef _WIN64
-    fpGetMemoryWin32HandleKHR =
-        (PFN_vkGetMemoryWin32HandleKHR)vkGetInstanceProcAddr(
-            instance, "vkGetMemoryWin32HandleKHR");
-    if (fpGetMemoryWin32HandleKHR == NULL) {
-      throw std::runtime_error(
-          "Vulkan: Proc address for \"vkGetMemoryWin32HandleKHR\" not "
-          "found.\n");
-    }
-#else
-    fpGetMemoryFdKHR = (PFN_vkGetMemoryFdKHR)vkGetInstanceProcAddr(
-        instance, "vkGetMemoryFdKHR");
-    if (fpGetMemoryFdKHR == NULL) {
-      throw std::runtime_error(
-          "Vulkan: Proc address for \"vkGetMemoryFdKHR\" not found.\n");
-    } else {
-      std::cout << "Vulkan proc address for vkGetMemoryFdKHR - "
-                << fpGetMemoryFdKHR << std::endl;
-    }
-#endif
-  }
-
-  void populateDebugMessengerCreateInfo(
-      VkDebugUtilsMessengerCreateInfoEXT& createInfo) {
-    createInfo = {};
-    createInfo.sType = VK_STRUCTURE_TYPE_DEBUG_UTILS_MESSENGER_CREATE_INFO_EXT;
-    createInfo.messageSeverity =
-        VK_DEBUG_UTILS_MESSAGE_SEVERITY_VERBOSE_BIT_EXT |
-        VK_DEBUG_UTILS_MESSAGE_SEVERITY_WARNING_BIT_EXT |
-        VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT;
-    createInfo.messageType = VK_DEBUG_UTILS_MESSAGE_TYPE_GENERAL_BIT_EXT |
-                             VK_DEBUG_UTILS_MESSAGE_TYPE_VALIDATION_BIT_EXT |
-                             VK_DEBUG_UTILS_MESSAGE_TYPE_PERFORMANCE_BIT_EXT;
-    createInfo.pfnUserCallback = debugCallback;
-  }
-
-  void setupDebugMessenger() {
-    if (!enableValidationLayers) return;
-
-    VkDebugUtilsMessengerCreateInfoEXT createInfo;
-    populateDebugMessengerCreateInfo(createInfo);
-
-    if (CreateDebugUtilsMessengerEXT(instance, &createInfo, nullptr,
-                                     &debugMessenger) != VK_SUCCESS) {
-      throw std::runtime_error("failed to set up debug messenger!");
-    }
-  }
-
-  void createSurface() {
-    if (glfwCreateWindowSurface(instance, window, nullptr, &surface) !=
-        VK_SUCCESS) {
-      throw std::runtime_error("failed to create window surface!");
-    }
-  }
-
-  void pickPhysicalDevice() {
-    uint32_t deviceCount = 0;
-    vkEnumeratePhysicalDevices(instance, &deviceCount, nullptr);
-
-    if (deviceCount == 0) {
-      throw std::runtime_error("failed to find GPUs with Vulkan support!");
-    }
-
-    std::vector<VkPhysicalDevice> devices(deviceCount);
-    vkEnumeratePhysicalDevices(instance, &deviceCount, devices.data());
-
-    for (const auto& device : devices) {
-      if (isDeviceSuitable(device)) {
-        physicalDevice = device;
-        break;
-      }
-    }
-
-    if (physicalDevice == VK_NULL_HANDLE) {
-      throw std::runtime_error("failed to find a suitable GPU!");
-    }
-
-    std::cout << "Selected physical device = " << physicalDevice << std::endl;
-
-    VkPhysicalDeviceIDProperties vkPhysicalDeviceIDProperties = {};
-    vkPhysicalDeviceIDProperties.sType =
-        VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ID_PROPERTIES;
-    vkPhysicalDeviceIDProperties.pNext = NULL;
-
-    VkPhysicalDeviceProperties2 vkPhysicalDeviceProperties2 = {};
-    vkPhysicalDeviceProperties2.sType =
-        VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROPERTIES_2;
-    vkPhysicalDeviceProperties2.pNext = &vkPhysicalDeviceIDProperties;
-
-    fpGetPhysicalDeviceProperties2(physicalDevice,
-                                   &vkPhysicalDeviceProperties2);
-
-    memcpy(vkDeviceUUID, vkPhysicalDeviceIDProperties.deviceUUID,
-           sizeof(vkDeviceUUID));
-  }
-
-  void getKhrExtensionsFn() {
-#ifdef _WIN64
-
-    fpGetSemaphoreWin32HandleKHR =
-        (PFN_vkGetSemaphoreWin32HandleKHR)vkGetDeviceProcAddr(
-            device, "vkGetSemaphoreWin32HandleKHR");
-    if (fpGetSemaphoreWin32HandleKHR == NULL) {
-      throw std::runtime_error(
-          "Vulkan: Proc address for \"vkGetSemaphoreWin32HandleKHR\" not "
-          "found.\n");
-    }
-#else
-    fpGetSemaphoreFdKHR = (PFN_vkGetSemaphoreFdKHR)vkGetDeviceProcAddr(
-        device, "vkGetSemaphoreFdKHR");
-    if (fpGetSemaphoreFdKHR == NULL) {
-      throw std::runtime_error(
-          "Vulkan: Proc address for \"vkGetSemaphoreFdKHR\" not found.\n");
-    }
-#endif
-  }
-
-  int setCudaVkDevice() {
-    int current_device = 0;
-    int device_count = 0;
-    int devices_prohibited = 0;
-
-    hipDeviceProp_t deviceProp;
-    HIPCHECK(hipGetDeviceCount(&device_count));
-
-    if (device_count == 0) {
-      fprintf(stderr, "CUDA error: no devices supporting CUDA.\n");
-      exit(EXIT_FAILURE);
-    }
-
-    // Find the GPU which is selected by Vulkan
-    while (current_device < device_count) {
-      hipGetDeviceProperties(&deviceProp, current_device);
-
-      if ((deviceProp.computeMode != hipComputeModeProhibited)) {
-        // Compare the cuda device UUID with vulkan UUID
-        int ret = memcmp(&deviceProp.uuid, &vkDeviceUUID, VK_UUID_SIZE);
-        if (ret == 0) {
-          HIPCHECK(hipSetDevice(current_device));
-          HIPCHECK(hipGetDeviceProperties(&deviceProp, current_device));
-          printf("GPU Device %d: \"%s\" with compute capability %d.%d\n\n",
-                 current_device, deviceProp.name, deviceProp.major,
-                 deviceProp.minor);
-
-          return current_device;
-        }
-
-      } else {
-        devices_prohibited++;
-      }
-
-      current_device++;
-    }
-
-    if (devices_prohibited == device_count) {
-      fprintf(stderr,
-              "CUDA error:"
-              " No Vulkan-CUDA Interop capable GPU found.\n");
-      exit(EXIT_FAILURE);
-    }
-
-    return -1;
-  }
-
-  void createLogicalDevice() {
-    QueueFamilyIndices indices = findQueueFamilies(physicalDevice);
-
-    std::vector<VkDeviceQueueCreateInfo> queueCreateInfos;
-    std::set<int> uniqueQueueFamilies = {indices.graphicsFamily,
-                                         indices.presentFamily};
-
-    float queuePriority = 1.0f;
-    for (int queueFamily : uniqueQueueFamilies) {
-      VkDeviceQueueCreateInfo queueCreateInfo = {};
-      queueCreateInfo.sType = VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO;
-      queueCreateInfo.queueFamilyIndex = queueFamily;
-      queueCreateInfo.queueCount = 1;
-      queueCreateInfo.pQueuePriorities = &queuePriority;
-      queueCreateInfos.push_back(queueCreateInfo);
-    }
-
-    VkPhysicalDeviceFeatures deviceFeatures = {};
-    deviceFeatures.samplerAnisotropy = VK_TRUE;
-
-    VkDeviceCreateInfo createInfo = {};
-    createInfo.sType = VK_STRUCTURE_TYPE_DEVICE_CREATE_INFO;
-
-    createInfo.pQueueCreateInfos = queueCreateInfos.data();
-    createInfo.queueCreateInfoCount = queueCreateInfos.size();
-
-    createInfo.pEnabledFeatures = &deviceFeatures;
-    std::vector<const char*> enabledExtensionNameList;
-
-    for (int i = 0; i < deviceExtensions.size(); i++) {
-      enabledExtensionNameList.push_back(deviceExtensions[i]);
-    }
-    if (enableValidationLayers) {
-      createInfo.enabledLayerCount =
-          static_cast<uint32_t>(validationLayers.size());
-      createInfo.ppEnabledLayerNames = validationLayers.data();
-    } else {
-      createInfo.enabledLayerCount = 0;
-    }
-    createInfo.enabledExtensionCount =
-        static_cast<uint32_t>(enabledExtensionNameList.size());
-    createInfo.ppEnabledExtensionNames = enabledExtensionNameList.data();
-
-    if (vkCreateDevice(physicalDevice, &createInfo, nullptr, &device) !=
-        VK_SUCCESS) {
-      throw std::runtime_error("failed to create logical device!");
-    }
-    vkGetDeviceQueue(device, indices.graphicsFamily, 0, &graphicsQueue);
-    vkGetDeviceQueue(device, indices.presentFamily, 0, &presentQueue);
-  }
-
-  void createSwapChain() {
-    SwapChainSupportDetails swapChainSupport =
-        querySwapChainSupport(physicalDevice);
-
-    VkSurfaceFormatKHR surfaceFormat =
-        chooseSwapSurfaceFormat(swapChainSupport.formats);
-    VkPresentModeKHR presentMode =
-        chooseSwapPresentMode(swapChainSupport.presentModes);
-    VkExtent2D extent = chooseSwapExtent(swapChainSupport.capabilities);
-
-    uint32_t imageCount = swapChainSupport.capabilities.minImageCount + 1;
-    if (swapChainSupport.capabilities.maxImageCount > 0 &&
-        imageCount > swapChainSupport.capabilities.maxImageCount) {
-      imageCount = swapChainSupport.capabilities.maxImageCount;
-    }
-
-    VkSwapchainCreateInfoKHR createInfo = {};
-    createInfo.sType = VK_STRUCTURE_TYPE_SWAPCHAIN_CREATE_INFO_KHR;
-    createInfo.surface = surface;
-
-    createInfo.minImageCount = imageCount;
-    createInfo.imageFormat = surfaceFormat.format;
-    createInfo.imageColorSpace = surfaceFormat.colorSpace;
-    createInfo.imageExtent = extent;
-    createInfo.imageArrayLayers = 1;
-    createInfo.imageUsage = VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT;
-
-    QueueFamilyIndices indices = findQueueFamilies(physicalDevice);
-    uint32_t queueFamilyIndices[] = {(uint32_t)indices.graphicsFamily,
-                                     (uint32_t)indices.presentFamily};
-
-    if (indices.graphicsFamily != indices.presentFamily) {
-      createInfo.imageSharingMode = VK_SHARING_MODE_CONCURRENT;
-      createInfo.queueFamilyIndexCount = 2;
-      createInfo.pQueueFamilyIndices = queueFamilyIndices;
-    } else {
-      createInfo.imageSharingMode = VK_SHARING_MODE_EXCLUSIVE;
-    }
-
-    createInfo.preTransform = swapChainSupport.capabilities.currentTransform;
-    createInfo.compositeAlpha = VK_COMPOSITE_ALPHA_OPAQUE_BIT_KHR;
-    createInfo.presentMode = presentMode;
-    createInfo.clipped = VK_TRUE;
-
-    if (vkCreateSwapchainKHR(device, &createInfo, nullptr, &swapChain) !=
-        VK_SUCCESS) {
-      throw std::runtime_error("failed to create swap chain!");
-    }
-
-    vkGetSwapchainImagesKHR(device, swapChain, &imageCount, nullptr);
-    swapChainImages.resize(imageCount);
-    vkGetSwapchainImagesKHR(device, swapChain, &imageCount,
-                            swapChainImages.data());
-
-    swapChainImageFormat = surfaceFormat.format;
-    swapChainExtent = extent;
-  }
-
-  void createImageViews() {
-    swapChainImageViews.resize(swapChainImages.size());
-
-    for (size_t i = 0; i < swapChainImages.size(); i++) {
-      swapChainImageViews[i] =
-          createImageView(swapChainImages[i], swapChainImageFormat);
-    }
-  }
-
-  void createRenderPass() {
-    VkAttachmentDescription colorAttachment = {};
-    colorAttachment.format = swapChainImageFormat;
-    colorAttachment.samples = VK_SAMPLE_COUNT_1_BIT;
-    colorAttachment.loadOp = VK_ATTACHMENT_LOAD_OP_CLEAR;
-    colorAttachment.storeOp = VK_ATTACHMENT_STORE_OP_STORE;
-    colorAttachment.stencilLoadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE;
-    colorAttachment.stencilStoreOp = VK_ATTACHMENT_STORE_OP_DONT_CARE;
-    colorAttachment.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED;
-    colorAttachment.finalLayout = VK_IMAGE_LAYOUT_PRESENT_SRC_KHR;
-
-    VkAttachmentReference colorAttachmentRef = {};
-    colorAttachmentRef.attachment = 0;
-    colorAttachmentRef.layout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL;
-
-    VkSubpassDescription subpass = {};
-    subpass.pipelineBindPoint = VK_PIPELINE_BIND_POINT_GRAPHICS;
-    subpass.colorAttachmentCount = 1;
-    subpass.pColorAttachments = &colorAttachmentRef;
-
-    VkSubpassDependency dependency = {};
-    dependency.srcSubpass = VK_SUBPASS_EXTERNAL;
-    dependency.dstSubpass = 0;
-    dependency.srcStageMask = VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT;
-    dependency.srcAccessMask = 0;
-    dependency.dstStageMask = VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT;
-    dependency.dstAccessMask = VK_ACCESS_COLOR_ATTACHMENT_READ_BIT |
-                               VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT;
-
-    VkRenderPassCreateInfo renderPassInfo = {};
-    renderPassInfo.sType = VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO;
-    renderPassInfo.attachmentCount = 1;
-    renderPassInfo.pAttachments = &colorAttachment;
-    renderPassInfo.subpassCount = 1;
-    renderPassInfo.pSubpasses = &subpass;
-    renderPassInfo.dependencyCount = 1;
-    renderPassInfo.pDependencies = &dependency;
-
-    if (vkCreateRenderPass(device, &renderPassInfo, nullptr, &renderPass) !=
-        VK_SUCCESS) {
-      throw std::runtime_error("failed to create render pass!");
-    }
-  }
-
-  void createDescriptorSetLayout() {
-    VkDescriptorSetLayoutBinding uboLayoutBinding = {};
-    uboLayoutBinding.binding = 0;
-    uboLayoutBinding.descriptorCount = 1;
-    uboLayoutBinding.descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
-    uboLayoutBinding.pImmutableSamplers = nullptr;
-    uboLayoutBinding.stageFlags = VK_SHADER_STAGE_VERTEX_BIT;
-
-    VkDescriptorSetLayoutBinding samplerLayoutBinding = {};
-    samplerLayoutBinding.binding = 1;
-    samplerLayoutBinding.descriptorCount = 1;
-    samplerLayoutBinding.descriptorType =
-        VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER;
-    samplerLayoutBinding.pImmutableSamplers = nullptr;
-    samplerLayoutBinding.stageFlags = VK_SHADER_STAGE_FRAGMENT_BIT;
-
-    std::array<VkDescriptorSetLayoutBinding, 2> bindings = {
-        uboLayoutBinding, samplerLayoutBinding};
-    VkDescriptorSetLayoutCreateInfo layoutInfo = {};
-    layoutInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO;
-    layoutInfo.bindingCount = static_cast<uint32_t>(bindings.size());
-    layoutInfo.pBindings = bindings.data();
-
-    if (vkCreateDescriptorSetLayout(device, &layoutInfo, nullptr,
-                                    &descriptorSetLayout) != VK_SUCCESS) {
-      throw std::runtime_error("failed to create descriptor set layout!");
-    }
-  }
-
-  void createGraphicsPipeline() {
-    auto vertShaderCode = readFile("vert.spv");
-    auto fragShaderCode = readFile("frag.spv");
-
-    VkShaderModule vertShaderModule = createShaderModule(vertShaderCode);
-    VkShaderModule fragShaderModule = createShaderModule(fragShaderCode);
-
-    VkPipelineShaderStageCreateInfo vertShaderStageInfo = {};
-    vertShaderStageInfo.sType =
-        VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO;
-    vertShaderStageInfo.stage = VK_SHADER_STAGE_VERTEX_BIT;
-    vertShaderStageInfo.module = vertShaderModule;
-    vertShaderStageInfo.pName = "main";
-
-    VkPipelineShaderStageCreateInfo fragShaderStageInfo = {};
-    fragShaderStageInfo.sType =
-        VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO;
-    fragShaderStageInfo.stage = VK_SHADER_STAGE_FRAGMENT_BIT;
-    fragShaderStageInfo.module = fragShaderModule;
-    fragShaderStageInfo.pName = "main";
-
-    VkPipelineShaderStageCreateInfo shaderStages[] = {vertShaderStageInfo,
-                                                      fragShaderStageInfo};
-
-    VkPipelineVertexInputStateCreateInfo vertexInputInfo = {};
-    vertexInputInfo.sType =
-        VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_STATE_CREATE_INFO;
-
-    auto bindingDescription = Vertex::getBindingDescription();
-    auto attributeDescriptions = Vertex::getAttributeDescriptions();
-
-    vertexInputInfo.vertexBindingDescriptionCount = 1;
-    vertexInputInfo.vertexAttributeDescriptionCount =
-        static_cast<uint32_t>(attributeDescriptions.size());
-    vertexInputInfo.pVertexBindingDescriptions = &bindingDescription;
-    vertexInputInfo.pVertexAttributeDescriptions = attributeDescriptions.data();
-
-    VkPipelineInputAssemblyStateCreateInfo inputAssembly = {};
-    inputAssembly.sType =
-        VK_STRUCTURE_TYPE_PIPELINE_INPUT_ASSEMBLY_STATE_CREATE_INFO;
-    inputAssembly.topology = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST;
-    inputAssembly.primitiveRestartEnable = VK_FALSE;
-
-    VkViewport viewport = {};
-    viewport.x = 0.0f;
-    viewport.y = 0.0f;
-    viewport.width = (float)swapChainExtent.width;
-    viewport.height = (float)swapChainExtent.height;
-    viewport.minDepth = 0.0f;
-    viewport.maxDepth = 1.0f;
-
-    VkRect2D scissor = {};
-    scissor.offset = {0, 0};
-    scissor.extent = swapChainExtent;
-
-    VkPipelineViewportStateCreateInfo viewportState = {};
-    viewportState.sType = VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_STATE_CREATE_INFO;
-    viewportState.viewportCount = 1;
-    viewportState.pViewports = &viewport;
-    viewportState.scissorCount = 1;
-    viewportState.pScissors = &scissor;
-
-    VkPipelineRasterizationStateCreateInfo rasterizer = {};
-    rasterizer.sType =
-        VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_CREATE_INFO;
-    rasterizer.depthClampEnable = VK_FALSE;
-    rasterizer.rasterizerDiscardEnable = VK_FALSE;
-    rasterizer.polygonMode = VK_POLYGON_MODE_FILL;
-    rasterizer.lineWidth = 1.0f;
-    rasterizer.cullMode = VK_CULL_MODE_BACK_BIT;
-    rasterizer.frontFace = VK_FRONT_FACE_COUNTER_CLOCKWISE;
-    rasterizer.depthBiasEnable = VK_FALSE;
-
-    VkPipelineMultisampleStateCreateInfo multisampling = {};
-    multisampling.sType =
-        VK_STRUCTURE_TYPE_PIPELINE_MULTISAMPLE_STATE_CREATE_INFO;
-    multisampling.sampleShadingEnable = VK_FALSE;
-    multisampling.rasterizationSamples = VK_SAMPLE_COUNT_1_BIT;
-
-    VkPipelineColorBlendAttachmentState colorBlendAttachment = {};
-    colorBlendAttachment.colorWriteMask =
-        VK_COLOR_COMPONENT_R_BIT | VK_COLOR_COMPONENT_G_BIT |
-        VK_COLOR_COMPONENT_B_BIT | VK_COLOR_COMPONENT_A_BIT;
-    colorBlendAttachment.blendEnable = VK_FALSE;
-
-    VkPipelineColorBlendStateCreateInfo colorBlending = {};
-    colorBlending.sType =
-        VK_STRUCTURE_TYPE_PIPELINE_COLOR_BLEND_STATE_CREATE_INFO;
-    colorBlending.logicOpEnable = VK_FALSE;
-    colorBlending.logicOp = VK_LOGIC_OP_COPY;
-    colorBlending.attachmentCount = 1;
-    colorBlending.pAttachments = &colorBlendAttachment;
-    colorBlending.blendConstants[0] = 0.0f;
-    colorBlending.blendConstants[1] = 0.0f;
-    colorBlending.blendConstants[2] = 0.0f;
-    colorBlending.blendConstants[3] = 0.0f;
-
-    VkPipelineLayoutCreateInfo pipelineLayoutInfo = {};
-    pipelineLayoutInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_LAYOUT_CREATE_INFO;
-    pipelineLayoutInfo.setLayoutCount = 1;
-    pipelineLayoutInfo.pSetLayouts = &descriptorSetLayout;
-
-    if (vkCreatePipelineLayout(device, &pipelineLayoutInfo, nullptr,
-                               &pipelineLayout) != VK_SUCCESS) {
-      throw std::runtime_error("failed to create pipeline layout!");
-    }
-
-    VkGraphicsPipelineCreateInfo pipelineInfo = {};
-    pipelineInfo.sType = VK_STRUCTURE_TYPE_GRAPHICS_PIPELINE_CREATE_INFO;
-    pipelineInfo.stageCount = 2;
-    pipelineInfo.pStages = shaderStages;
-    pipelineInfo.pVertexInputState = &vertexInputInfo;
-    pipelineInfo.pInputAssemblyState = &inputAssembly;
-    pipelineInfo.pViewportState = &viewportState;
-    pipelineInfo.pRasterizationState = &rasterizer;
-    pipelineInfo.pMultisampleState = &multisampling;
-    pipelineInfo.pColorBlendState = &colorBlending;
-    pipelineInfo.layout = pipelineLayout;
-    pipelineInfo.renderPass = renderPass;
-    pipelineInfo.subpass = 0;
-    pipelineInfo.basePipelineHandle = VK_NULL_HANDLE;
-
-    if (vkCreateGraphicsPipelines(device, VK_NULL_HANDLE, 1, &pipelineInfo,
-                                  nullptr, &graphicsPipeline) != VK_SUCCESS) {
-      throw std::runtime_error("failed to create graphics pipeline!");
-    }
-
-    vkDestroyShaderModule(device, fragShaderModule, nullptr);
-    vkDestroyShaderModule(device, vertShaderModule, nullptr);
-  }
-
-  void createFramebuffers() {
-    swapChainFramebuffers.resize(swapChainImageViews.size());
-
-    for (size_t i = 0; i < swapChainImageViews.size(); i++) {
-      VkImageView attachments[] = {swapChainImageViews[i]};
-
-      VkFramebufferCreateInfo framebufferInfo = {};
-      framebufferInfo.sType = VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO;
-      framebufferInfo.renderPass = renderPass;
-      framebufferInfo.attachmentCount = 1;
-      framebufferInfo.pAttachments = attachments;
-      framebufferInfo.width = swapChainExtent.width;
-      framebufferInfo.height = swapChainExtent.height;
-      framebufferInfo.layers = 1;
-
-      if (vkCreateFramebuffer(device, &framebufferInfo, nullptr,
-                              &swapChainFramebuffers[i]) != VK_SUCCESS) {
-        throw std::runtime_error("failed to create framebuffer!");
-      }
-    }
-  }
-
-  void createCommandPool() {
-    QueueFamilyIndices queueFamilyIndices = findQueueFamilies(physicalDevice);
-
-    VkCommandPoolCreateInfo poolInfo = {};
-    poolInfo.sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO;
-    poolInfo.queueFamilyIndex = queueFamilyIndices.graphicsFamily;
-
-    if (vkCreateCommandPool(device, &poolInfo, nullptr, &commandPool) !=
-        VK_SUCCESS) {
-      throw std::runtime_error("failed to create graphics command pool!");
-    }
-  }
-
-  void createTextureImage() {
-    VkDeviceSize imageSize = imageWidth * imageHeight * 4;
-    mipLevels = static_cast<uint32_t>(
-                    std::floor(std::log2(std::max(imageWidth, imageHeight)))) +
-                1;
-    printf("mipLevels = %d\n", mipLevels);
-
-    if (!image_data) {
-      throw std::runtime_error("failed to load texture image!");
-    }
-
-    VkBuffer stagingBuffer;
-    VkDeviceMemory stagingBufferMemory;
-    createBuffer(imageSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
-                 VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
-                     VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
-                 stagingBuffer, stagingBufferMemory);
-
-    void* data;
-    vkMapMemory(device, stagingBufferMemory, 0, imageSize, 0, &data);
-    memcpy(data, image_data, static_cast<size_t>(imageSize));
-    vkUnmapMemory(device, stagingBufferMemory);
-
-    // VK_FORMAT_R8G8B8A8_UNORM changed to VK_FORMAT_R8G8B8A8_UINT
-    createImage(
-        imageWidth, imageHeight, VK_FORMAT_R8G8B8A8_UNORM,
-        VK_IMAGE_TILING_OPTIMAL,
-        VK_IMAGE_USAGE_STORAGE_BIT | VK_IMAGE_USAGE_TRANSFER_SRC_BIT |
-            VK_IMAGE_USAGE_TRANSFER_DST_BIT | VK_IMAGE_USAGE_SAMPLED_BIT,
-        VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, textureImage, textureImageMemory);
-
-    transitionImageLayout(textureImage, VK_FORMAT_R8G8B8A8_UINT,
-                          VK_IMAGE_LAYOUT_UNDEFINED,
-                          VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL);
-    copyBufferToImage(stagingBuffer, textureImage,
-                      static_cast<uint32_t>(imageWidth),
-                      static_cast<uint32_t>(imageHeight));
-
-    vkDestroyBuffer(device, stagingBuffer, nullptr);
-    vkFreeMemory(device, stagingBufferMemory, nullptr);
-
-    generateMipmaps(textureImage, VK_FORMAT_R8G8B8A8_UNORM);
-  }
-
-  void generateMipmaps(VkImage image, VkFormat imageFormat) {
-    VkFormatProperties formatProperties;
-    vkGetPhysicalDeviceFormatProperties(physicalDevice, imageFormat,
-                                        &formatProperties);
-
-    if (!(formatProperties.optimalTilingFeatures &
-          VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_LINEAR_BIT)) {
-      throw std::runtime_error(
-          "texture image format does not support linear blitting!");
-    }
-
-    VkCommandBuffer commandBuffer = beginSingleTimeCommands();
-
-    VkImageMemoryBarrier barrier = {};
-    barrier.sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER;
-    barrier.image = image;
-    barrier.srcQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
-    barrier.dstQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
-    barrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
-    barrier.subresourceRange.baseArrayLayer = 0;
-    barrier.subresourceRange.layerCount = 1;
-    barrier.subresourceRange.levelCount = 1;
-
-    int32_t mipWidth = imageWidth;
-    int32_t mipHeight = imageHeight;
-
-    for (uint32_t i = 1; i < mipLevels; i++) {
-      barrier.subresourceRange.baseMipLevel = i - 1;
-      barrier.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
-      barrier.newLayout = VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL;
-      barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
-      barrier.dstAccessMask = VK_ACCESS_TRANSFER_READ_BIT;
-
-      vkCmdPipelineBarrier(commandBuffer, VK_PIPELINE_STAGE_TRANSFER_BIT,
-                           VK_PIPELINE_STAGE_TRANSFER_BIT, 0, 0, nullptr, 0,
-                           nullptr, 1, &barrier);
-
-      VkImageBlit blit = {};
-      blit.srcOffsets[0] = {0, 0, 0};
-      blit.srcOffsets[1] = {mipWidth, mipHeight, 1};
-      blit.srcSubresource.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
-      blit.srcSubresource.mipLevel = i - 1;
-      blit.srcSubresource.baseArrayLayer = 0;
-      blit.srcSubresource.layerCount = 1;
-      blit.dstOffsets[0] = {0, 0, 0};
-      blit.dstOffsets[1] = {mipWidth > 1 ? mipWidth / 2 : 1,
-                            mipHeight > 1 ? mipHeight / 2 : 1, 1};
-      blit.dstSubresource.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
-      blit.dstSubresource.mipLevel = i;
-      blit.dstSubresource.baseArrayLayer = 0;
-      blit.dstSubresource.layerCount = 1;
-
-      vkCmdBlitImage(commandBuffer, image, VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL,
-                     image, VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL, 1, &blit,
-                     VK_FILTER_LINEAR);
-
-      barrier.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL;
-      barrier.newLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
-      barrier.srcAccessMask = VK_ACCESS_TRANSFER_READ_BIT;
-      barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;
-
-      vkCmdPipelineBarrier(commandBuffer, VK_PIPELINE_STAGE_TRANSFER_BIT,
-                           VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT, 0, 0, nullptr,
-                           0, nullptr, 1, &barrier);
-
-      if (mipWidth > 1) mipWidth /= 2;
-      if (mipHeight > 1) mipHeight /= 2;
-    }
-
-    barrier.subresourceRange.baseMipLevel = mipLevels - 1;
-    barrier.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
-    barrier.newLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
-    barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
-    barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;
-
-    vkCmdPipelineBarrier(commandBuffer, VK_PIPELINE_STAGE_TRANSFER_BIT,
-                         VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT, 0, 0, nullptr,
-                         0, nullptr, 1, &barrier);
-
-    endSingleTimeCommands(commandBuffer);
-  }
-
-#ifdef _WIN64  // For windows
-  HANDLE getVkImageMemHandle(
-      VkExternalMemoryHandleTypeFlagsKHR externalMemoryHandleType) {
-    HANDLE handle;
-
-    VkMemoryGetWin32HandleInfoKHR vkMemoryGetWin32HandleInfoKHR = {};
-    vkMemoryGetWin32HandleInfoKHR.sType =
-        VK_STRUCTURE_TYPE_MEMORY_GET_WIN32_HANDLE_INFO_KHR;
-    vkMemoryGetWin32HandleInfoKHR.pNext = NULL;
-    vkMemoryGetWin32HandleInfoKHR.memory = textureImageMemory;
-    vkMemoryGetWin32HandleInfoKHR.handleType =
-        (VkExternalMemoryHandleTypeFlagBitsKHR)externalMemoryHandleType;
-
-    fpGetMemoryWin32HandleKHR(device, &vkMemoryGetWin32HandleInfoKHR, &handle);
-    return handle;
-  }
-  HANDLE getVkSemaphoreHandle(
-      VkExternalSemaphoreHandleTypeFlagBitsKHR externalSemaphoreHandleType,
-      VkSemaphore& semVkCuda) {
-    HANDLE handle;
-
-    VkSemaphoreGetWin32HandleInfoKHR vulkanSemaphoreGetWin32HandleInfoKHR = {};
-    vulkanSemaphoreGetWin32HandleInfoKHR.sType =
-        VK_STRUCTURE_TYPE_SEMAPHORE_GET_WIN32_HANDLE_INFO_KHR;
-    vulkanSemaphoreGetWin32HandleInfoKHR.pNext = NULL;
-    vulkanSemaphoreGetWin32HandleInfoKHR.semaphore = semVkCuda;
-    vulkanSemaphoreGetWin32HandleInfoKHR.handleType =
-        externalSemaphoreHandleType;
-
-    fpGetSemaphoreWin32HandleKHR(device, &vulkanSemaphoreGetWin32HandleInfoKHR,
-                                 &handle);
-
-    return handle;
-  }
-#else
-  int getVkImageMemHandle(
-      VkExternalMemoryHandleTypeFlagsKHR externalMemoryHandleType) {
-    if (externalMemoryHandleType ==
-        VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT_KHR) {
-      int fd;
-
-      VkMemoryGetFdInfoKHR vkMemoryGetFdInfoKHR = {};
-      vkMemoryGetFdInfoKHR.sType = VK_STRUCTURE_TYPE_MEMORY_GET_FD_INFO_KHR;
-      vkMemoryGetFdInfoKHR.pNext = NULL;
-      vkMemoryGetFdInfoKHR.memory = textureImageMemory;
-      vkMemoryGetFdInfoKHR.handleType =
-          VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT_KHR;
-
-      fpGetMemoryFdKHR(device, &vkMemoryGetFdInfoKHR, &fd);
-
-      return fd;
-    }
-    return -1;
-  }
-
-  int getVkSemaphoreHandle(
-      VkExternalSemaphoreHandleTypeFlagBitsKHR externalSemaphoreHandleType,
-      VkSemaphore& semVkCuda) {
-    if (externalSemaphoreHandleType ==
-        VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT) {
-      int fd;
-
-      VkSemaphoreGetFdInfoKHR vulkanSemaphoreGetFdInfoKHR = {};
-      vulkanSemaphoreGetFdInfoKHR.sType =
-          VK_STRUCTURE_TYPE_SEMAPHORE_GET_FD_INFO_KHR;
-      vulkanSemaphoreGetFdInfoKHR.pNext = NULL;
-      vulkanSemaphoreGetFdInfoKHR.semaphore = semVkCuda;
-      vulkanSemaphoreGetFdInfoKHR.handleType =
-          VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT_KHR;
-
-      fpGetSemaphoreFdKHR(device, &vulkanSemaphoreGetFdInfoKHR, &fd);
-
-      return fd;
-    }
-    return -1;
-  }
-#endif
-
-  void createTextureImageView() {
-    textureImageView = createImageView(textureImage, VK_FORMAT_R8G8B8A8_UNORM);
-  }
-
-  void createTextureSampler() {
-    VkSamplerCreateInfo samplerInfo = {};
-    samplerInfo.sType = VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO;
-    samplerInfo.magFilter = VK_FILTER_LINEAR;
-    samplerInfo.minFilter = VK_FILTER_LINEAR;
-    samplerInfo.addressModeU = VK_SAMPLER_ADDRESS_MODE_REPEAT;
-    samplerInfo.addressModeV = VK_SAMPLER_ADDRESS_MODE_REPEAT;
-    samplerInfo.addressModeW = VK_SAMPLER_ADDRESS_MODE_REPEAT;
-    samplerInfo.anisotropyEnable = VK_TRUE;
-    samplerInfo.maxAnisotropy = 16;
-    samplerInfo.borderColor = VK_BORDER_COLOR_INT_OPAQUE_BLACK;
-    samplerInfo.unnormalizedCoordinates = VK_FALSE;
-    samplerInfo.compareEnable = VK_FALSE;
-    samplerInfo.compareOp = VK_COMPARE_OP_ALWAYS;
-    samplerInfo.mipmapMode = VK_SAMPLER_MIPMAP_MODE_LINEAR;
-    samplerInfo.minLod = 0;  // Optional
-    samplerInfo.maxLod = static_cast<float>(mipLevels);
-    samplerInfo.mipLodBias = 0;  // Optional
-
-    if (vkCreateSampler(device, &samplerInfo, nullptr, &textureSampler) !=
-        VK_SUCCESS) {
-      throw std::runtime_error("failed to create texture sampler!");
-    }
-  }
-
-  VkImageView createImageView(VkImage image, VkFormat format) {
-    VkImageViewCreateInfo viewInfo = {};
-    viewInfo.sType = VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO;
-    viewInfo.image = image;
-    viewInfo.viewType = VK_IMAGE_VIEW_TYPE_2D;
-    viewInfo.format = format;
-    viewInfo.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
-    viewInfo.subresourceRange.baseMipLevel = 0;
-    viewInfo.subresourceRange.levelCount = mipLevels;
-    viewInfo.subresourceRange.baseArrayLayer = 0;
-    viewInfo.subresourceRange.layerCount = 1;
-
-    VkImageView imageView;
-    if (vkCreateImageView(device, &viewInfo, nullptr, &imageView) !=
-        VK_SUCCESS) {
-      throw std::runtime_error("failed to create texture image view!");
-    }
-
-    return imageView;
-  }
-
-  void createImage(uint32_t width, uint32_t height, VkFormat format,
-                   VkImageTiling tiling, VkImageUsageFlags usage,
-                   VkMemoryPropertyFlags properties, VkImage& image,
-                   VkDeviceMemory& imageMemory) {
-    VkImageCreateInfo imageInfo = {};
-    imageInfo.sType = VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO;
-    imageInfo.imageType = VK_IMAGE_TYPE_2D;
-    imageInfo.extent.width = width;
-    imageInfo.extent.height = height;
-    imageInfo.extent.depth = 1;
-    imageInfo.mipLevels = mipLevels;
-    imageInfo.arrayLayers = 1;
-    imageInfo.format = format;
-    imageInfo.tiling = tiling;
-    imageInfo.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED;
-    imageInfo.usage = usage;
-    imageInfo.samples = VK_SAMPLE_COUNT_1_BIT;
-    imageInfo.sharingMode = VK_SHARING_MODE_EXCLUSIVE;
-
-    VkExternalMemoryImageCreateInfo vkExternalMemImageCreateInfo = {};
-    vkExternalMemImageCreateInfo.sType =
-        VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_IMAGE_CREATE_INFO;
-    vkExternalMemImageCreateInfo.pNext = NULL;
-#ifdef _WIN64
-    vkExternalMemImageCreateInfo.handleTypes =
-        VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT;
-#else
-    vkExternalMemImageCreateInfo.handleTypes =
-        VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT_KHR;
-#endif
-
-    imageInfo.pNext = &vkExternalMemImageCreateInfo;
-
-    if (vkCreateImage(device, &imageInfo, nullptr, &image) != VK_SUCCESS) {
-      throw std::runtime_error("failed to create image!");
-    }
-
-    VkMemoryRequirements memRequirements;
-    vkGetImageMemoryRequirements(device, image, &memRequirements);
-
-#ifdef _WIN64
-    WindowsSecurityAttributes winSecurityAttributes;
-
-    VkExportMemoryWin32HandleInfoKHR vulkanExportMemoryWin32HandleInfoKHR = {};
-    vulkanExportMemoryWin32HandleInfoKHR.sType =
-        VK_STRUCTURE_TYPE_EXPORT_MEMORY_WIN32_HANDLE_INFO_KHR;
-    vulkanExportMemoryWin32HandleInfoKHR.pNext = NULL;
-    vulkanExportMemoryWin32HandleInfoKHR.pAttributes = &winSecurityAttributes;
-    vulkanExportMemoryWin32HandleInfoKHR.dwAccess =
-        DXGI_SHARED_RESOURCE_READ | DXGI_SHARED_RESOURCE_WRITE;
-    vulkanExportMemoryWin32HandleInfoKHR.name = (LPCWSTR)NULL;
-#endif
-    VkExportMemoryAllocateInfoKHR vulkanExportMemoryAllocateInfoKHR = {};
-    vulkanExportMemoryAllocateInfoKHR.sType =
-        VK_STRUCTURE_TYPE_EXPORT_MEMORY_ALLOCATE_INFO_KHR;
-#ifdef _WIN64
-    vulkanExportMemoryAllocateInfoKHR.pNext =
-        IsWindows8OrGreater() ? &vulkanExportMemoryWin32HandleInfoKHR : NULL;
-    vulkanExportMemoryAllocateInfoKHR.handleTypes =
-        IsWindows8OrGreater()
-            ? VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT
-            : VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT;
-#else
-    vulkanExportMemoryAllocateInfoKHR.pNext = NULL;
-    vulkanExportMemoryAllocateInfoKHR.handleTypes =
-        VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT_KHR;
-#endif
-
-    VkMemoryAllocateInfo allocInfo = {};
-    allocInfo.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO;
-    allocInfo.allocationSize = memRequirements.size;
-    allocInfo.pNext = &vulkanExportMemoryAllocateInfoKHR;
-    allocInfo.memoryTypeIndex =
-        findMemoryType(memRequirements.memoryTypeBits, properties);
-
-    VkMemoryRequirements vkMemoryRequirements = {};
-    vkGetImageMemoryRequirements(device, image, &vkMemoryRequirements);
-    totalImageMemSize = vkMemoryRequirements.size;
-
-    if (vkAllocateMemory(device, &allocInfo, nullptr, &textureImageMemory) !=
-        VK_SUCCESS) {
-      throw std::runtime_error("failed to allocate image memory!");
-    }
-
-    vkBindImageMemory(device, image, textureImageMemory, 0);
-  }
-
-  void cudaVkImportSemaphore() {
-    hipExternalSemaphoreHandleDesc externalSemaphoreHandleDesc;
-    memset(&externalSemaphoreHandleDesc, 0,
-           sizeof(externalSemaphoreHandleDesc));
-#ifdef _WIN64
-    externalSemaphoreHandleDesc.type =
-        IsWindows8OrGreater() ? hipExternalSemaphoreHandleTypeOpaqueWin32
-                              : hipExternalSemaphoreHandleTypeOpaqueWin32Kmt;
-    externalSemaphoreHandleDesc.handle.win32.handle = getVkSemaphoreHandle(
-        IsWindows8OrGreater()
-            ? VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_BIT
-            : VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT,
-        cudaUpdateVkSemaphore);
-#else
-    externalSemaphoreHandleDesc.type = hipExternalSemaphoreHandleTypeOpaqueFd;
-    externalSemaphoreHandleDesc.handle.fd = getVkSemaphoreHandle(
-        VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT, cudaUpdateVkSemaphore);
-#endif
-    externalSemaphoreHandleDesc.flags = 0;
-
-    HIPCHECK(hipImportExternalSemaphore(&cudaExtCudaUpdateVkSemaphore,
-                                                &externalSemaphoreHandleDesc));
-
-    memset(&externalSemaphoreHandleDesc, 0,
-           sizeof(externalSemaphoreHandleDesc));
-#ifdef _WIN64
-    externalSemaphoreHandleDesc.type =
-        IsWindows8OrGreater() ? hipExternalSemaphoreHandleTypeOpaqueWin32
-                              : hipExternalSemaphoreHandleTypeOpaqueWin32Kmt;
-    ;
-    externalSemaphoreHandleDesc.handle.win32.handle = getVkSemaphoreHandle(
-        IsWindows8OrGreater()
-            ? VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_BIT
-            : VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT,
-        vkUpdateCudaSemaphore);
-#else
-    externalSemaphoreHandleDesc.type = hipExternalSemaphoreHandleTypeOpaqueFd;
-    externalSemaphoreHandleDesc.handle.fd = getVkSemaphoreHandle(
-        VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT, vkUpdateCudaSemaphore);
-#endif
-    externalSemaphoreHandleDesc.flags = 0;
-    HIPCHECK(hipImportExternalSemaphore(&cudaExtVkUpdateCudaSemaphore,
-                                                &externalSemaphoreHandleDesc));
-    printf("CUDA Imported Vulkan semaphore\n");
-  }
-
-  void cudaVkImportImageMem() {
-    hipExternalMemoryHandleDesc cudaExtMemHandleDesc;
-    memset(&cudaExtMemHandleDesc, 0, sizeof(cudaExtMemHandleDesc));
-#ifdef _WIN64
-    cudaExtMemHandleDesc.type =
-        IsWindows8OrGreater() ? hipExternalMemoryHandleTypeOpaqueWin32
-                              : hipExternalMemoryHandleTypeOpaqueWin32Kmt;
-    cudaExtMemHandleDesc.handle.win32.handle = getVkImageMemHandle(
-        IsWindows8OrGreater()
-            ? VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT
-            : VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT);
-#else
-    cudaExtMemHandleDesc.type = hipExternalMemoryHandleTypeOpaqueFd;
-
-    cudaExtMemHandleDesc.handle.fd =
-        getVkImageMemHandle(VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT_KHR);
-#endif
-    cudaExtMemHandleDesc.size = totalImageMemSize;
-
-    HIPCHECK(hipImportExternalMemory(&cudaExtMemImageBuffer,
-                                             &cudaExtMemHandleDesc));
-
-    cudaExternalMemoryMipmappedArrayDesc externalMemoryMipmappedArrayDesc;
-
-    memset(&externalMemoryMipmappedArrayDesc, 0,
-           sizeof(externalMemoryMipmappedArrayDesc));
-
-    hipExtent extent = make_hipExtent(imageWidth, imageHeight, 0);
-    hipChannelFormatDesc formatDesc;
-    formatDesc.x = 8;
-    formatDesc.y = 8;
-    formatDesc.z = 8;
-    formatDesc.w = 8;
-    formatDesc.f = hipChannelFormatKindUnsigned;
-
-    externalMemoryMipmappedArrayDesc.offset = 0;
-    externalMemoryMipmappedArrayDesc.formatDesc = formatDesc;
-    externalMemoryMipmappedArrayDesc.extent = extent;
-    externalMemoryMipmappedArrayDesc.flags = 0;
-    externalMemoryMipmappedArrayDesc.numLevels = mipLevels;
-
-    HIPCHECK(cudaExternalMemoryGetMappedMipmappedArray(
-        &cudaMipmappedImageArray, cudaExtMemImageBuffer,
-        &externalMemoryMipmappedArrayDesc));
-
-    HIPCHECK(hipMallocMipmappedArray(&cudaMipmappedImageArrayTemp,
-                                             &formatDesc, extent, mipLevels));
-    HIPCHECK(hipMallocMipmappedArray(&cudaMipmappedImageArrayOrig,
-                                             &formatDesc, extent, mipLevels));
-
-    for (int mipLevelIdx = 0; mipLevelIdx < mipLevels; mipLevelIdx++) {
-      hipArray_t cudaMipLevelArray, cudaMipLevelArrayTemp,
-          cudaMipLevelArrayOrig;
-      hipResourceDesc resourceDesc;
-
-      HIPCHECK(hipGetMipmappedArrayLevel(
-          &cudaMipLevelArray, cudaMipmappedImageArray, mipLevelIdx));
-      HIPCHECK(hipGetMipmappedArrayLevel(
-          &cudaMipLevelArrayTemp, cudaMipmappedImageArrayTemp, mipLevelIdx));
-      HIPCHECK(hipGetMipmappedArrayLevel(
-          &cudaMipLevelArrayOrig, cudaMipmappedImageArrayOrig, mipLevelIdx));
-
-      uint32_t width =
-          (imageWidth >> mipLevelIdx) ? (imageWidth >> mipLevelIdx) : 1;
-      uint32_t height =
-          (imageHeight >> mipLevelIdx) ? (imageHeight >> mipLevelIdx) : 1;
-      HIPCHECK(cudaMemcpy2DArrayToArray(
-          cudaMipLevelArrayOrig, 0, 0, cudaMipLevelArray, 0, 0,
-          width * sizeof(uchar4), height, hipMemcpyDeviceToDevice));
-
-      memset(&resourceDesc, 0, sizeof(resourceDesc));
-      resourceDesc.resType = hipResourceTypeArray;
-      resourceDesc.res.array.array = cudaMipLevelArray;
-
-      hipSurfaceObject_t surfaceObject;
-      HIPCHECK(hipCreateSurfaceObject(&surfaceObject, &resourceDesc));
-
-      surfaceObjectList.push_back(surfaceObject);
-
-      memset(&resourceDesc, 0, sizeof(resourceDesc));
-      resourceDesc.resType = hipResourceTypeArray;
-      resourceDesc.res.array.array = cudaMipLevelArrayTemp;
-
-      hipSurfaceObject_t surfaceObjectTemp;
-      HIPCHECK(
-          hipCreateSurfaceObject(&surfaceObjectTemp, &resourceDesc));
-      surfaceObjectListTemp.push_back(surfaceObjectTemp);
-    }
-
-    hipResourceDesc resDescr;
-    memset(&resDescr, 0, sizeof(hipResourceDesc));
-
-    resDescr.resType = hipResourceTypeMipmappedArray;
-    resDescr.res.mipmap.mipmap = cudaMipmappedImageArrayOrig;
-
-    hipTextureDesc texDescr;
-    memset(&texDescr, 0, sizeof(hipTextureDesc));
-
-    texDescr.normalizedCoords = true;
-    texDescr.filterMode = hipFilterModeLinear;
-    texDescr.mipmapFilterMode = hipFilterModeLinear;
-
-    texDescr.addressMode[0] = hipAddressModeWrap;
-    texDescr.addressMode[1] = hipAddressModeWrap;
-
-    texDescr.maxMipmapLevelClamp = float(mipLevels - 1);
-
-    texDescr.readMode = hipReadModeNormalizedFloat;
-
-    HIPCHECK(hipCreateTextureObject(&textureObjMipMapInput, &resDescr,
-                                            &texDescr, NULL));
-
-    HIPCHECK(hipMalloc((void**)&d_surfaceObjectList,
-                               sizeof(hipSurfaceObject_t) * mipLevels));
-    HIPCHECK(hipMalloc((void**)&d_surfaceObjectListTemp,
-                               sizeof(hipSurfaceObject_t) * mipLevels));
-
-    HIPCHECK(hipMemcpy(d_surfaceObjectList, surfaceObjectList.data(),
-                               sizeof(hipSurfaceObject_t) * mipLevels,
-                               hipMemcpyHostToDevice));
-    HIPCHECK(hipMemcpy(
-        d_surfaceObjectListTemp, surfaceObjectListTemp.data(),
-        sizeof(hipSurfaceObject_t) * mipLevels, hipMemcpyHostToDevice));
-
-    printf("CUDA Kernel Vulkan image buffer\n");
-  }
-
-  void cudaUpdateVkImage() {
-    cudaVkSemaphoreWait(cudaExtVkUpdateCudaSemaphore);
-
-    int nthreads = 128;
-
-    /*Perform 2D box filter on image using CUDA */
-    d_boxfilter_rgba_x<<<imageHeight / nthreads, nthreads, 0, streamToRun>>>(
-        d_surfaceObjectListTemp, textureObjMipMapInput, imageWidth, imageHeight,
-        mipLevels, filter_radius);
-
-    d_boxfilter_rgba_y<<<imageWidth / nthreads, nthreads, 0, streamToRun>>>(
-        d_surfaceObjectList, d_surfaceObjectListTemp, imageWidth, imageHeight,
-        mipLevels, filter_radius);
-
-    varySigma();
-
-    cudaVkSemaphoreSignal(cudaExtCudaUpdateVkSemaphore);
-  }
-
-  void transitionImageLayout(VkImage image, VkFormat format,
-                             VkImageLayout oldLayout, VkImageLayout newLayout) {
-    VkCommandBuffer commandBuffer = beginSingleTimeCommands();
-
-    VkImageMemoryBarrier barrier = {};
-    barrier.sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER;
-    barrier.oldLayout = oldLayout;
-    barrier.newLayout = newLayout;
-    barrier.srcQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
-    barrier.dstQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED;
-    barrier.image = image;
-    barrier.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
-    barrier.subresourceRange.baseMipLevel = 0;
-    barrier.subresourceRange.levelCount = mipLevels;
-    barrier.subresourceRange.baseArrayLayer = 0;
-    barrier.subresourceRange.layerCount = 1;
-
-    VkPipelineStageFlags sourceStage;
-    VkPipelineStageFlags destinationStage;
-
-    if (oldLayout == VK_IMAGE_LAYOUT_UNDEFINED &&
-        newLayout == VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL) {
-      barrier.srcAccessMask = 0;
-      barrier.dstAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
-
-      sourceStage = VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT;
-      destinationStage = VK_PIPELINE_STAGE_TRANSFER_BIT;
-    } else if (oldLayout == VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL &&
-               newLayout == VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL) {
-      barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
-      barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;
-
-      sourceStage = VK_PIPELINE_STAGE_TRANSFER_BIT;
-      destinationStage = VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT;
-    } else {
-      throw std::invalid_argument("unsupported layout transition!");
-    }
-
-    vkCmdPipelineBarrier(commandBuffer, sourceStage, destinationStage, 0, 0,
-                         nullptr, 0, nullptr, 1, &barrier);
-
-    endSingleTimeCommands(commandBuffer);
-  }
-
-  void copyBufferToImage(VkBuffer buffer, VkImage image, uint32_t width,
-                         uint32_t height) {
-    VkCommandBuffer commandBuffer = beginSingleTimeCommands();
-
-    VkBufferImageCopy region = {};
-    region.bufferOffset = 0;
-    region.bufferRowLength = 0;
-    region.bufferImageHeight = 0;
-    region.imageSubresource.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
-    region.imageSubresource.mipLevel = 0;
-    region.imageSubresource.baseArrayLayer = 0;
-    region.imageSubresource.layerCount = 1;
-    region.imageOffset = {0, 0, 0};
-    region.imageExtent = {width, height, 1};
-
-    vkCmdCopyBufferToImage(commandBuffer, buffer, image,
-                           VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL, 1, &region);
-
-    endSingleTimeCommands(commandBuffer);
-  }
-
-  void createVertexBuffer() {
-    VkDeviceSize bufferSize = sizeof(vertices[0]) * vertices.size();
-
-    VkBuffer stagingBuffer;
-    VkDeviceMemory stagingBufferMemory;
-    createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
-                 VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
-                     VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
-                 stagingBuffer, stagingBufferMemory);
-
-    void* data;
-    vkMapMemory(device, stagingBufferMemory, 0, bufferSize, 0, &data);
-    memcpy(data, vertices.data(), (size_t)bufferSize);
-    vkUnmapMemory(device, stagingBufferMemory);
-
-    createBuffer(
-        bufferSize,
-        VK_BUFFER_USAGE_TRANSFER_DST_BIT | VK_BUFFER_USAGE_VERTEX_BUFFER_BIT,
-        VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, vertexBuffer, vertexBufferMemory);
-
-    copyBuffer(stagingBuffer, vertexBuffer, bufferSize);
-
-    vkDestroyBuffer(device, stagingBuffer, nullptr);
-    vkFreeMemory(device, stagingBufferMemory, nullptr);
-  }
-
-  void createIndexBuffer() {
-    VkDeviceSize bufferSize = sizeof(indices[0]) * indices.size();
-
-    VkBuffer stagingBuffer;
-    VkDeviceMemory stagingBufferMemory;
-    createBuffer(bufferSize, VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
-                 VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
-                     VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
-                 stagingBuffer, stagingBufferMemory);
-
-    void* data;
-    vkMapMemory(device, stagingBufferMemory, 0, bufferSize, 0, &data);
-    memcpy(data, indices.data(), (size_t)bufferSize);
-    vkUnmapMemory(device, stagingBufferMemory);
-
-    createBuffer(
-        bufferSize,
-        VK_BUFFER_USAGE_TRANSFER_DST_BIT | VK_BUFFER_USAGE_INDEX_BUFFER_BIT,
-        VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT, indexBuffer, indexBufferMemory);
-
-    copyBuffer(stagingBuffer, indexBuffer, bufferSize);
-
-    vkDestroyBuffer(device, stagingBuffer, nullptr);
-    vkFreeMemory(device, stagingBufferMemory, nullptr);
-  }
-
-  void createUniformBuffers() {
-    VkDeviceSize bufferSize = sizeof(UniformBufferObject);
-
-    uniformBuffers.resize(swapChainImages.size());
-    uniformBuffersMemory.resize(swapChainImages.size());
-
-    for (size_t i = 0; i < swapChainImages.size(); i++) {
-      createBuffer(bufferSize, VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT,
-                   VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT |
-                       VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
-                   uniformBuffers[i], uniformBuffersMemory[i]);
-    }
-  }
-
-  void createDescriptorPool() {
-    std::array<VkDescriptorPoolSize, 2> poolSizes = {};
-    poolSizes[0].type = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
-    poolSizes[0].descriptorCount =
-        static_cast<uint32_t>(swapChainImages.size());
-    poolSizes[1].type = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER;
-    poolSizes[1].descriptorCount =
-        static_cast<uint32_t>(swapChainImages.size());
-
-    VkDescriptorPoolCreateInfo poolInfo = {};
-    poolInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO;
-    poolInfo.poolSizeCount = static_cast<uint32_t>(poolSizes.size());
-    poolInfo.pPoolSizes = poolSizes.data();
-    poolInfo.maxSets = static_cast<uint32_t>(swapChainImages.size());
-
-    if (vkCreateDescriptorPool(device, &poolInfo, nullptr, &descriptorPool) !=
-        VK_SUCCESS) {
-      throw std::runtime_error("failed to create descriptor pool!");
-    }
-  }
-
-  void createDescriptorSets() {
-    std::vector<VkDescriptorSetLayout> layouts(swapChainImages.size(),
-                                               descriptorSetLayout);
-    VkDescriptorSetAllocateInfo allocInfo = {};
-    allocInfo.sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO;
-    allocInfo.descriptorPool = descriptorPool;
-    allocInfo.descriptorSetCount =
-        static_cast<uint32_t>(swapChainImages.size());
-    allocInfo.pSetLayouts = layouts.data();
-
-    descriptorSets.resize(swapChainImages.size());
-    if (vkAllocateDescriptorSets(device, &allocInfo, descriptorSets.data()) !=
-        VK_SUCCESS) {
-      throw std::runtime_error("failed to allocate descriptor sets!");
-    }
-
-    for (size_t i = 0; i < swapChainImages.size(); i++) {
-      VkDescriptorBufferInfo bufferInfo = {};
-      bufferInfo.buffer = uniformBuffers[i];
-      bufferInfo.offset = 0;
-      bufferInfo.range = sizeof(UniformBufferObject);
-
-      VkDescriptorImageInfo imageInfo = {};
-      imageInfo.imageLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
-      imageInfo.imageView = textureImageView;
-      imageInfo.sampler = textureSampler;
-
-      std::array<VkWriteDescriptorSet, 2> descriptorWrites = {};
-
-      descriptorWrites[0].sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET;
-      descriptorWrites[0].dstSet = descriptorSets[i];
-      descriptorWrites[0].dstBinding = 0;
-      descriptorWrites[0].dstArrayElement = 0;
-      descriptorWrites[0].descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
-      descriptorWrites[0].descriptorCount = 1;
-      descriptorWrites[0].pBufferInfo = &bufferInfo;
-
-      descriptorWrites[1].sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET;
-      descriptorWrites[1].dstSet = descriptorSets[i];
-      descriptorWrites[1].dstBinding = 1;
-      descriptorWrites[1].dstArrayElement = 0;
-      descriptorWrites[1].descriptorType =
-          VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER;
-      descriptorWrites[1].descriptorCount = 1;
-      descriptorWrites[1].pImageInfo = &imageInfo;
-
-      vkUpdateDescriptorSets(device,
-                             static_cast<uint32_t>(descriptorWrites.size()),
-                             descriptorWrites.data(), 0, nullptr);
-    }
-  }
-
-  void createBuffer(VkDeviceSize size, VkBufferUsageFlags usage,
-                    VkMemoryPropertyFlags properties, VkBuffer& buffer,
-                    VkDeviceMemory& bufferMemory) {
-    VkBufferCreateInfo bufferInfo = {};
-    bufferInfo.sType = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO;
-    bufferInfo.size = size;
-    bufferInfo.usage = usage;
-    bufferInfo.sharingMode = VK_SHARING_MODE_EXCLUSIVE;
-
-    if (vkCreateBuffer(device, &bufferInfo, nullptr, &buffer) != VK_SUCCESS) {
-      throw std::runtime_error("failed to create buffer!");
-    }
-
-    VkMemoryRequirements memRequirements;
-    vkGetBufferMemoryRequirements(device, buffer, &memRequirements);
-
-    VkMemoryAllocateInfo allocInfo = {};
-    allocInfo.sType = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO;
-    allocInfo.allocationSize = memRequirements.size;
-    allocInfo.memoryTypeIndex =
-        findMemoryType(memRequirements.memoryTypeBits, properties);
-
-    if (vkAllocateMemory(device, &allocInfo, nullptr, &bufferMemory) !=
-        VK_SUCCESS) {
-      throw std::runtime_error("failed to allocate buffer memory!");
-    }
-
-    vkBindBufferMemory(device, buffer, bufferMemory, 0);
-  }
-
-  VkCommandBuffer beginSingleTimeCommands() {
-    VkCommandBufferAllocateInfo allocInfo = {};
-    allocInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO;
-    allocInfo.level = VK_COMMAND_BUFFER_LEVEL_PRIMARY;
-    allocInfo.commandPool = commandPool;
-    allocInfo.commandBufferCount = 1;
-
-    VkCommandBuffer commandBuffer;
-    vkAllocateCommandBuffers(device, &allocInfo, &commandBuffer);
-
-    VkCommandBufferBeginInfo beginInfo = {};
-    beginInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO;
-    beginInfo.flags = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT;
-
-    vkBeginCommandBuffer(commandBuffer, &beginInfo);
-
-    return commandBuffer;
-  }
-
-  void endSingleTimeCommands(VkCommandBuffer commandBuffer) {
-    vkEndCommandBuffer(commandBuffer);
-
-    VkSubmitInfo submitInfo = {};
-    submitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;
-    submitInfo.commandBufferCount = 1;
-    submitInfo.pCommandBuffers = &commandBuffer;
-
-    vkQueueSubmit(graphicsQueue, 1, &submitInfo, VK_NULL_HANDLE);
-    vkQueueWaitIdle(graphicsQueue);
-
-    vkFreeCommandBuffers(device, commandPool, 1, &commandBuffer);
-  }
-
-  void copyBuffer(VkBuffer srcBuffer, VkBuffer dstBuffer, VkDeviceSize size) {
-    VkCommandBuffer commandBuffer = beginSingleTimeCommands();
-
-    VkBufferCopy copyRegion = {};
-    copyRegion.size = size;
-    vkCmdCopyBuffer(commandBuffer, srcBuffer, dstBuffer, 1, &copyRegion);
-
-    endSingleTimeCommands(commandBuffer);
-  }
-
-  uint32_t findMemoryType(uint32_t typeFilter,
-                          VkMemoryPropertyFlags properties) {
-    VkPhysicalDeviceMemoryProperties memProperties;
-    vkGetPhysicalDeviceMemoryProperties(physicalDevice, &memProperties);
-
-    for (uint32_t i = 0; i < memProperties.memoryTypeCount; i++) {
-      if ((typeFilter & (1 << i)) &&
-          (memProperties.memoryTypes[i].propertyFlags & properties) ==
-              properties) {
-        return i;
-      }
-    }
-
-    throw std::runtime_error("failed to find suitable memory type!");
-  }
-
-  void createCommandBuffers() {
-    commandBuffers.resize(swapChainFramebuffers.size());
-
-    VkCommandBufferAllocateInfo allocInfo = {};
-    allocInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO;
-    allocInfo.commandPool = commandPool;
-    allocInfo.level = VK_COMMAND_BUFFER_LEVEL_PRIMARY;
-    allocInfo.commandBufferCount = (uint32_t)commandBuffers.size();
-
-    if (vkAllocateCommandBuffers(device, &allocInfo, commandBuffers.data()) !=
-        VK_SUCCESS) {
-      throw std::runtime_error("failed to allocate command buffers!");
-    }
-
-    for (size_t i = 0; i < commandBuffers.size(); i++) {
-      VkCommandBufferBeginInfo beginInfo = {};
-      beginInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO;
-      beginInfo.flags = VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT;
-
-      if (vkBeginCommandBuffer(commandBuffers[i], &beginInfo) != VK_SUCCESS) {
-        throw std::runtime_error("failed to begin recording command buffer!");
-      }
-
-      VkRenderPassBeginInfo renderPassInfo = {};
-      renderPassInfo.sType = VK_STRUCTURE_TYPE_RENDER_PASS_BEGIN_INFO;
-      renderPassInfo.renderPass = renderPass;
-      renderPassInfo.framebuffer = swapChainFramebuffers[i];
-      renderPassInfo.renderArea.offset = {0, 0};
-      renderPassInfo.renderArea.extent = swapChainExtent;
-
-      VkClearValue clearColor = {0.0f, 0.0f, 0.0f, 1.0f};
-      renderPassInfo.clearValueCount = 1;
-      renderPassInfo.pClearValues = &clearColor;
-
-      vkCmdBeginRenderPass(commandBuffers[i], &renderPassInfo,
-                           VK_SUBPASS_CONTENTS_INLINE);
-
-      vkCmdBindPipeline(commandBuffers[i], VK_PIPELINE_BIND_POINT_GRAPHICS,
-                        graphicsPipeline);
-
-      VkBuffer vertexBuffers[] = {vertexBuffer};
-      VkDeviceSize offsets[] = {0};
-      vkCmdBindVertexBuffers(commandBuffers[i], 0, 1, vertexBuffers, offsets);
-
-      vkCmdBindIndexBuffer(commandBuffers[i], indexBuffer, 0,
-                           VK_INDEX_TYPE_UINT16);
-
-      vkCmdBindDescriptorSets(commandBuffers[i],
-                              VK_PIPELINE_BIND_POINT_GRAPHICS, pipelineLayout,
-                              0, 1, &descriptorSets[i], 0, nullptr);
-
-      vkCmdDrawIndexed(commandBuffers[i], static_cast<uint32_t>(indices.size()),
-                       1, 0, 0, 0);
-      // vkCmdDraw(commandBuffers[i], static_cast<uint32_t>(vertices.size()), 1,
-      // 0, 0);
-
-      vkCmdEndRenderPass(commandBuffers[i]);
-
-      if (vkEndCommandBuffer(commandBuffers[i]) != VK_SUCCESS) {
-        throw std::runtime_error("failed to record command buffer!");
-      }
-    }
-  }
-
-  void createSyncObjects() {
-    imageAvailableSemaphores.resize(MAX_FRAMES);
-    renderFinishedSemaphores.resize(MAX_FRAMES);
-    inFlightFences.resize(MAX_FRAMES);
-
-    VkSemaphoreCreateInfo semaphoreInfo = {};
-    semaphoreInfo.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO;
-
-    VkFenceCreateInfo fenceInfo = {};
-    fenceInfo.sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO;
-    fenceInfo.flags = VK_FENCE_CREATE_SIGNALED_BIT;
-
-    for (size_t i = 0; i < MAX_FRAMES; i++) {
-      if (vkCreateSemaphore(device, &semaphoreInfo, nullptr,
-                            &imageAvailableSemaphores[i]) != VK_SUCCESS ||
-          vkCreateSemaphore(device, &semaphoreInfo, nullptr,
-                            &renderFinishedSemaphores[i]) != VK_SUCCESS ||
-          vkCreateFence(device, &fenceInfo, nullptr, &inFlightFences[i]) !=
-              VK_SUCCESS) {
-        throw std::runtime_error(
-            "failed to create synchronization objects for a frame!");
-      }
-    }
-  }
-
-  void createSyncObjectsExt() {
-    VkSemaphoreCreateInfo semaphoreInfo = {};
-    semaphoreInfo.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO;
-
-    memset(&semaphoreInfo, 0, sizeof(semaphoreInfo));
-    semaphoreInfo.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO;
-
-#ifdef _WIN64
-    WindowsSecurityAttributes winSecurityAttributes;
-
-    VkExportSemaphoreWin32HandleInfoKHR
-        vulkanExportSemaphoreWin32HandleInfoKHR = {};
-    vulkanExportSemaphoreWin32HandleInfoKHR.sType =
-        VK_STRUCTURE_TYPE_EXPORT_SEMAPHORE_WIN32_HANDLE_INFO_KHR;
-    vulkanExportSemaphoreWin32HandleInfoKHR.pNext = NULL;
-    vulkanExportSemaphoreWin32HandleInfoKHR.pAttributes =
-        &winSecurityAttributes;
-    vulkanExportSemaphoreWin32HandleInfoKHR.dwAccess =
-        DXGI_SHARED_RESOURCE_READ | DXGI_SHARED_RESOURCE_WRITE;
-    vulkanExportSemaphoreWin32HandleInfoKHR.name = (LPCWSTR)NULL;
-#endif
-    VkExportSemaphoreCreateInfoKHR vulkanExportSemaphoreCreateInfo = {};
-    vulkanExportSemaphoreCreateInfo.sType =
-        VK_STRUCTURE_TYPE_EXPORT_SEMAPHORE_CREATE_INFO_KHR;
-#ifdef _WIN64
-    vulkanExportSemaphoreCreateInfo.pNext =
-        IsWindows8OrGreater() ? &vulkanExportSemaphoreWin32HandleInfoKHR : NULL;
-    vulkanExportSemaphoreCreateInfo.handleTypes =
-        IsWindows8OrGreater()
-            ? VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_BIT
-            : VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT;
-#else
-    vulkanExportSemaphoreCreateInfo.pNext = NULL;
-    vulkanExportSemaphoreCreateInfo.handleTypes =
-        VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT;
-#endif
-    semaphoreInfo.pNext = &vulkanExportSemaphoreCreateInfo;
-
-    if (vkCreateSemaphore(device, &semaphoreInfo, nullptr,
-                          &cudaUpdateVkSemaphore) != VK_SUCCESS ||
-        vkCreateSemaphore(device, &semaphoreInfo, nullptr,
-                          &vkUpdateCudaSemaphore) != VK_SUCCESS) {
-      throw std::runtime_error(
-          "failed to create synchronization objects for a CUDA-Vulkan!");
-    }
-  }
-
-  void updateUniformBuffer() {
-    UniformBufferObject ubo = {};
-
-    mat4x4_identity(ubo.model);
-    mat4x4 Model;
-    mat4x4_dup(Model, ubo.model);
-    mat4x4_rotate(ubo.model, Model, 0.0f, 0.0f, 1.0f, degreesToRadians(135.0f));
-
-    vec3 eye = {2.0f, 2.0f, 2.0f};
-    vec3 center = {0.0f, 0.0f, 0.0f};
-    vec3 up = {0.0f, 0.0f, 1.0f};
-    mat4x4_look_at(ubo.view, eye, center, up);
-
-    mat4x4_perspective(ubo.proj, degreesToRadians(45.0f),
-                       swapChainExtent.width / (float)swapChainExtent.height,
-                       0.1f, 10.0f);
-    ubo.proj[1][1] *= -1;
-
-    for (size_t i = 0; i < swapChainImages.size(); i++) {
-      void* data;
-      vkMapMemory(device, uniformBuffersMemory[i], 0, sizeof(ubo), 0, &data);
-      memcpy(data, &ubo, sizeof(ubo));
-      vkUnmapMemory(device, uniformBuffersMemory[i]);
-    }
-  }
-
-  void drawFrame() {
-    static int startSubmit = 0;
-
-    vkWaitForFences(device, 1, &inFlightFences[currentFrame], VK_TRUE,
-                    std::numeric_limits<uint64_t>::max());
-
-    uint32_t imageIndex;
-    VkResult result = vkAcquireNextImageKHR(
-        device, swapChain, std::numeric_limits<uint64_t>::max(),
-        imageAvailableSemaphores[currentFrame], VK_NULL_HANDLE, &imageIndex);
-
-    if (result == VK_ERROR_OUT_OF_DATE_KHR) {
-      recreateSwapChain();
-      return;
-    } else if (result != VK_SUCCESS && result != VK_SUBOPTIMAL_KHR) {
-      throw std::runtime_error("failed to acquire swap chain image!");
-    }
-
-    vkResetFences(device, 1, &inFlightFences[currentFrame]);
-
-    if (!startSubmit) {
-      submitVulkan(imageIndex);
-      startSubmit = 1;
-    } else {
-      submitVulkanCuda(imageIndex);
-    }
-
-    VkPresentInfoKHR presentInfo = {};
-    presentInfo.sType = VK_STRUCTURE_TYPE_PRESENT_INFO_KHR;
-
-    VkSemaphore signalSemaphores[] = {renderFinishedSemaphores[currentFrame]};
-
-    presentInfo.waitSemaphoreCount = 1;
-    presentInfo.pWaitSemaphores = signalSemaphores;
-
-    VkSwapchainKHR swapChains[] = {swapChain};
-    presentInfo.swapchainCount = 1;
-    presentInfo.pSwapchains = swapChains;
-    presentInfo.pImageIndices = &imageIndex;
-    presentInfo.pResults = nullptr;  // Optional
-
-    result = vkQueuePresentKHR(presentQueue, &presentInfo);
-
-    if (result == VK_ERROR_OUT_OF_DATE_KHR || result == VK_SUBOPTIMAL_KHR ||
-        framebufferResized) {
-      framebufferResized = false;
-      recreateSwapChain();
-    } else if (result != VK_SUCCESS) {
-      throw std::runtime_error("failed to present swap chain image!");
-    }
-
-    cudaUpdateVkImage();
-
-    currentFrame = (currentFrame + 1) % MAX_FRAMES;
-    // Added sleep of 10 millisecs so that CPU does not submit too much work to
-    // GPU
-    std::this_thread::sleep_for(std::chrono::microseconds(10000));
-    char title[256];
-    sprintf(title, "Vulkan Image CUDA Box Filter (radius=%d)", filter_radius);
-    glfwSetWindowTitle(window, title);
-  }
-
-  void cudaVkSemaphoreSignal(hipExternalSemaphore_t& extSemaphore) {
-    hipExternalSemaphoreSignalParams extSemaphoreSignalParams;
-    memset(&extSemaphoreSignalParams, 0, sizeof(extSemaphoreSignalParams));
-
-    extSemaphoreSignalParams.params.fence.value = 0;
-    extSemaphoreSignalParams.flags = 0;
-    HIPCHECK(hipSignalExternalSemaphoresAsync(
-        &extSemaphore, &extSemaphoreSignalParams, 1, streamToRun));
-  }
-
-  void cudaVkSemaphoreWait(hipExternalSemaphore_t& extSemaphore) {
-    hipExternalSemaphoreWaitParams extSemaphoreWaitParams;
-
-    memset(&extSemaphoreWaitParams, 0, sizeof(extSemaphoreWaitParams));
-
-    extSemaphoreWaitParams.params.fence.value = 0;
-    extSemaphoreWaitParams.flags = 0;
-
-    HIPCHECK(hipWaitExternalSemaphoresAsync(
-        &extSemaphore, &extSemaphoreWaitParams, 1, streamToRun));
-  }
-
-  void submitVulkan(uint32_t imageIndex) {
-    VkSubmitInfo submitInfo = {};
-    submitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;
-
-    VkSemaphore waitSemaphores[] = {imageAvailableSemaphores[currentFrame]};
-    VkPipelineStageFlags waitStages[] = {
-        VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT};
-    submitInfo.waitSemaphoreCount = 1;
-    submitInfo.pWaitSemaphores = waitSemaphores;
-    submitInfo.pWaitDstStageMask = waitStages;
-    submitInfo.commandBufferCount = 1;
-    submitInfo.pCommandBuffers = &commandBuffers[imageIndex];
-
-    VkSemaphore signalSemaphores[] = {renderFinishedSemaphores[currentFrame],
-                                      vkUpdateCudaSemaphore};
-
-    submitInfo.signalSemaphoreCount = 2;
-    submitInfo.pSignalSemaphores = signalSemaphores;
-
-    if (vkQueueSubmit(graphicsQueue, 1, &submitInfo,
-                      inFlightFences[currentFrame]) != VK_SUCCESS) {
-      throw std::runtime_error("failed to submit draw command buffer!");
-    }
-  }
-
-  void submitVulkanCuda(uint32_t imageIndex) {
-    VkSubmitInfo submitInfo = {};
-    submitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;
-
-    VkSemaphore waitSemaphores[] = {imageAvailableSemaphores[currentFrame],
-                                    cudaUpdateVkSemaphore};
-    VkPipelineStageFlags waitStages[] = {
-        VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT,
-        VK_PIPELINE_STAGE_ALL_COMMANDS_BIT};
-    submitInfo.waitSemaphoreCount = 2;
-    submitInfo.pWaitSemaphores = waitSemaphores;
-    submitInfo.pWaitDstStageMask = waitStages;
-    submitInfo.commandBufferCount = 1;
-    submitInfo.pCommandBuffers = &commandBuffers[imageIndex];
-
-    VkSemaphore signalSemaphores[] = {renderFinishedSemaphores[currentFrame],
-                                      vkUpdateCudaSemaphore};
-
-    submitInfo.signalSemaphoreCount = 2;
-    submitInfo.pSignalSemaphores = signalSemaphores;
-
-    if (vkQueueSubmit(graphicsQueue, 1, &submitInfo,
-                      inFlightFences[currentFrame]) != VK_SUCCESS) {
-      throw std::runtime_error("failed to submit draw command buffer!");
-    }
-  }
-
-  VkShaderModule createShaderModule(const std::vector<char>& code) {
-    VkShaderModuleCreateInfo createInfo = {};
-    createInfo.sType = VK_STRUCTURE_TYPE_SHADER_MODULE_CREATE_INFO;
-    createInfo.codeSize = code.size();
-    createInfo.pCode = reinterpret_cast<const uint32_t*>(code.data());
-
-    VkShaderModule shaderModule;
-    if (vkCreateShaderModule(device, &createInfo, nullptr, &shaderModule) !=
-        VK_SUCCESS) {
-      throw std::runtime_error("failed to create shader module!");
-    }
-
-    return shaderModule;
-  }
-
-  VkSurfaceFormatKHR chooseSwapSurfaceFormat(
-      const std::vector<VkSurfaceFormatKHR>& availableFormats) {
-    if (availableFormats.size() == 1 &&
-        availableFormats[0].format == VK_FORMAT_UNDEFINED) {
-      return {VK_FORMAT_B8G8R8A8_UNORM, VK_COLOR_SPACE_SRGB_NONLINEAR_KHR};
-    }
-
-    for (const auto& availableFormat : availableFormats) {
-      if (availableFormat.format == VK_FORMAT_B8G8R8A8_UNORM &&
-          availableFormat.colorSpace == VK_COLOR_SPACE_SRGB_NONLINEAR_KHR) {
-        return availableFormat;
-      }
-    }
-
-    return availableFormats[0];
-  }
-
-  VkPresentModeKHR chooseSwapPresentMode(
-      const std::vector<VkPresentModeKHR>& availablePresentModes) {
-    VkPresentModeKHR bestMode = VK_PRESENT_MODE_FIFO_KHR;
-
-    for (const auto& availablePresentMode : availablePresentModes) {
-      if (availablePresentMode == VK_PRESENT_MODE_MAILBOX_KHR) {
-        return availablePresentMode;
-      } else if (availablePresentMode == VK_PRESENT_MODE_IMMEDIATE_KHR) {
-        bestMode = availablePresentMode;
-      }
-    }
-
-    return bestMode;
-  }
-
-  VkExtent2D chooseSwapExtent(const VkSurfaceCapabilitiesKHR& capabilities) {
-    if (capabilities.currentExtent.width !=
-        std::numeric_limits<uint32_t>::max()) {
-      return capabilities.currentExtent;
-    } else {
-      int width, height;
-      glfwGetFramebufferSize(window, &width, &height);
-
-      VkExtent2D actualExtent = {static_cast<uint32_t>(width),
-                                 static_cast<uint32_t>(height)};
-
-      actualExtent.width = std::max(
-          capabilities.minImageExtent.width,
-          std::min(capabilities.maxImageExtent.width, actualExtent.width));
-      actualExtent.height = std::max(
-          capabilities.minImageExtent.height,
-          std::min(capabilities.maxImageExtent.height, actualExtent.height));
-
-      return actualExtent;
-    }
-  }
-
-  SwapChainSupportDetails querySwapChainSupport(VkPhysicalDevice device) {
-    SwapChainSupportDetails details;
-
-    vkGetPhysicalDeviceSurfaceCapabilitiesKHR(device, surface,
-                                              &details.capabilities);
-
-    uint32_t formatCount;
-    vkGetPhysicalDeviceSurfaceFormatsKHR(device, surface, &formatCount,
-                                         nullptr);
-
-    if (formatCount != 0) {
-      details.formats.resize(formatCount);
-      vkGetPhysicalDeviceSurfaceFormatsKHR(device, surface, &formatCount,
-                                           details.formats.data());
-    }
-
-    uint32_t presentModeCount;
-    vkGetPhysicalDeviceSurfacePresentModesKHR(device, surface,
-                                              &presentModeCount, nullptr);
-
-    if (presentModeCount != 0) {
-      details.presentModes.resize(presentModeCount);
-      vkGetPhysicalDeviceSurfacePresentModesKHR(
-          device, surface, &presentModeCount, details.presentModes.data());
-    }
-
-    return details;
-  }
-
-  bool isDeviceSuitable(VkPhysicalDevice device) {
-    QueueFamilyIndices indices = findQueueFamilies(device);
-
-    bool extensionsSupported = checkDeviceExtensionSupport(device);
-
-    bool swapChainAdequate = false;
-    if (extensionsSupported) {
-      SwapChainSupportDetails swapChainSupport = querySwapChainSupport(device);
-      swapChainAdequate = !swapChainSupport.formats.empty() &&
-                          !swapChainSupport.presentModes.empty();
-    }
-
-    VkPhysicalDeviceFeatures supportedFeatures;
-    vkGetPhysicalDeviceFeatures(device, &supportedFeatures);
-
-    return indices.isComplete() && extensionsSupported && swapChainAdequate &&
-           supportedFeatures.samplerAnisotropy;
-  }
-
-  bool checkDeviceExtensionSupport(VkPhysicalDevice device) {
-    uint32_t extensionCount;
-    vkEnumerateDeviceExtensionProperties(device, nullptr, &extensionCount,
-                                         nullptr);
-
-    std::vector<VkExtensionProperties> availableExtensions(extensionCount);
-    vkEnumerateDeviceExtensionProperties(device, nullptr, &extensionCount,
-                                         availableExtensions.data());
-
-    std::set<std::string> requiredExtensions(deviceExtensions.begin(),
-                                             deviceExtensions.end());
-
-    for (const auto& extension : availableExtensions) {
-      requiredExtensions.erase(extension.extensionName);
-    }
-
-    return requiredExtensions.empty();
-  }
-
-  QueueFamilyIndices findQueueFamilies(VkPhysicalDevice device) {
-    QueueFamilyIndices indices;
-
-    uint32_t queueFamilyCount = 0;
-    vkGetPhysicalDeviceQueueFamilyProperties(device, &queueFamilyCount,
-                                             nullptr);
-
-    std::vector<VkQueueFamilyProperties> queueFamilies(queueFamilyCount);
-    vkGetPhysicalDeviceQueueFamilyProperties(device, &queueFamilyCount,
-                                             queueFamilies.data());
-
-    int i = 0;
-    for (const auto& queueFamily : queueFamilies) {
-      if (queueFamily.queueCount > 0 &&
-          queueFamily.queueFlags & VK_QUEUE_GRAPHICS_BIT) {
-        indices.graphicsFamily = i;
-      }
-
-      VkBool32 presentSupport = false;
-      vkGetPhysicalDeviceSurfaceSupportKHR(device, i, surface, &presentSupport);
-
-      if (queueFamily.queueCount > 0 && presentSupport) {
-        indices.presentFamily = i;
-      }
-
-      if (indices.isComplete()) {
-        break;
-      }
-
-      i++;
-    }
-
-    return indices;
-  }
-
-  std::vector<const char*> getRequiredExtensions() {
-    uint32_t glfwExtensionCount = 0;
-    const char** glfwExtensions;
-    glfwExtensions = glfwGetRequiredInstanceExtensions(&glfwExtensionCount);
-
-    std::vector<const char*> extensions(glfwExtensions,
-                                        glfwExtensions + glfwExtensionCount);
-
-    if (enableValidationLayers) {
-      extensions.push_back(VK_EXT_DEBUG_UTILS_EXTENSION_NAME);
-    }
-
-    return extensions;
-  }
-
-  bool checkValidationLayerSupport() {
-    uint32_t layerCount;
-    vkEnumerateInstanceLayerProperties(&layerCount, nullptr);
-
-    std::vector<VkLayerProperties> availableLayers(layerCount);
-    vkEnumerateInstanceLayerProperties(&layerCount, availableLayers.data());
-
-    for (const char* layerName : validationLayers) {
-      bool layerFound = false;
-
-      for (const auto& layerProperties : availableLayers) {
-        if (strcmp(layerName, layerProperties.layerName) == 0) {
-          layerFound = true;
-          break;
-        }
-      }
-
-      if (!layerFound) {
-        return false;
-      }
-    }
-
-    return true;
-  }
-
-  static std::vector<char> readFile(const std::string& filename) {
-    char* file_path = sdkFindFilePath(filename.c_str(), execution_path.c_str());
-    std::ifstream file(file_path, std::ios::ate | std::ios::binary);
-
-    if (!file.is_open()) {
-      throw std::runtime_error("failed to open file!");
-    }
-
-    size_t fileSize = (size_t)file.tellg();
-    std::vector<char> buffer(fileSize);
-
-    file.seekg(0);
-    file.read(buffer.data(), fileSize);
-
-    file.close();
-
-    return buffer;
-  }
-
-  static VKAPI_ATTR VkBool32 VKAPI_CALL
-  debugCallback(VkDebugUtilsMessageSeverityFlagBitsEXT messageSeverity,
-                VkDebugUtilsMessageTypeFlagsEXT messageType,
-                const VkDebugUtilsMessengerCallbackDataEXT* pCallbackData,
-                void* pUserData) {
-    std::cerr << "validation layer: " << pCallbackData->pMessage << std::endl;
-
-    return VK_FALSE;
-  }
-};
-
-int main(int argc, char** argv) {
-  execution_path = argv[0];
-  std::string image_filename = "teapot1024.ppm";
-
-  if (checkCmdLineFlag(argc, (const char**)argv, "file")) {
-    getCmdLineArgumentString(argc, (const char**)argv, "file",
-                             (char**)&image_filename);
-  }
-
-  vulkanImageCUDA app;
-
-  try {
-    // This app only works on ppm images
-    app.loadImageData(image_filename);
-    app.run();
-  } catch (const std::exception& e) {
-    std::cerr << e.what() << std::endl;
-    return EXIT_FAILURE;
-  }
-
-  return EXIT_SUCCESS;
-}
-
-
-  try {
-    // This app only works on ppm images
-    app.loadImageData(image_filename);
-    app.run();
-  } catch (const std::exception& e) {
-    std::cerr << e.what() << std::endl;
-    return EXIT_FAILURE;
-  }
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2017.sln b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2017.vcxproj b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2019.sln b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2019.vcxproj b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2022.sln b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2022.vcxproj b/src/samples/Samples/5_Domain_Specific/vulkanImageCUDA/vulkanImageCUDA_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/README.md b/src/samples/Samples/6_Performance/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/.vscode/c_cpp_properties.json b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/.vscode/extensions.json b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/.vscode/launch.json b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/.vscode/tasks.json b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/Makefile b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/NsightEclipse.xml b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/README.md b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf.out b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2017.sln b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2017.vcxproj b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2019.sln b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2019.vcxproj b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2022.sln b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2022.vcxproj b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/UnifiedMemoryPerf_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/commonDefs.hpp b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/commonDefs.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/commonKernels.cu b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/commonKernels.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/commonKernels.cu.hip b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/commonKernels.cu.hip
old mode 100644
new mode 100755
index ed8cd7e..e69de29
--- a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/commonKernels.cu.hip
+++ b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/commonKernels.cu.hip
@@ -1,34 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "commonKernels.hpp"
-
-__global__ void spinWhileLessThanOne(volatile unsigned int *latch) {
-  while (latch[0] < 1)
-    ;
-}
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/commonKernels.hpp b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/commonKernels.hpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/helperFunctions.cpp b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/helperFunctions.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/helperFunctions_hipified.cpp b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/helperFunctions_hipified.cpp
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/matrixMultiplyPerf.cu b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/matrixMultiplyPerf.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/matrixMultiplyPerf.cu.hip b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/matrixMultiplyPerf.cu.hip
old mode 100644
new mode 100755
index 5964a15..e69de29
--- a/src/samples/Samples/6_Performance/UnifiedMemoryPerf/matrixMultiplyPerf.cu.hip
+++ b/src/samples/Samples/6_Performance/UnifiedMemoryPerf/matrixMultiplyPerf.cu.hip
@@ -1,699 +0,0 @@
-#include "hip/hip_runtime.h"
-/* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *  * Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  * Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in the
- *    documentation and/or other materials provided with the distribution.
- *  * Neither the name of NVIDIA CORPORATION nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
- * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
- * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
- * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
- * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
- * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
- * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "helper_cuda_hipified.h"
-#include <helper_timer.h>
-#include "commonDefs.hpp"
-#include "commonKernels.hpp"
-#include "HIPCHECK.h"
-#define VERIFY_GPU_CORRECTNESS 0
-
-size_t maxSampleSizeInMb = 64;
-int numKernelRuns = 20;
-int verboseResults = 0;
-
-const char *memAllocTypeStr[MEMALLOC_TYPE_COUNT] = {
-    "Managed_Memory_With_Hints",
-    "Managed_Memory_With_Hints_FullyAsync",
-    "Managed_Memory_NoHints",
-    "Zero_Copy",
-    "Memcpy_HostMalloc_DeviceCudaMalloc",
-    "MemcpyAsync_HostMalloc_DeviceCudaMalloc",
-    "Memcpy_HostCudaHostAlloc_DeviceCudaMalloc",
-    "MemcpyAsync_HostCudaHostAlloc_DeviceCudaMalloc"};
-
-const char *memAllocTypeShortStr[MEMALLOC_TYPE_COUNT] = {
-    "UMhint",   // Managed Memory With Hints
-    "UMhntAs",  // Managed Memory With_Hints Async
-    "UMeasy",   // Managed_Memory with No Hints
-    "0Copy",    // Zero Copy
-    "MemCopy",  // USE HOST PAGEABLE AND DEVICE_MEMORY
-    "CpAsync",  // USE HOST PAGEABLE AND DEVICE_MEMORY ASYNC
-    "CpHpglk",  // USE HOST PAGELOCKED AND DEVICE MEMORY
-    "CpPglAs"   // USE HOST PAGELOCKED AND DEVICE MEMORY ASYNC
-};
-
-static float RandFloat(float low, float high) {
-  float t = (float)rand() / (float)RAND_MAX;
-  return (1.0f - t) * low + t * high;
-}
-
-void fillMatrixWithRandomValues(float *matrix, unsigned int matrixDim) {
-  unsigned int i, j;
-  for (i = 0; i < matrixDim; ++i) {
-    for (j = 0; j < matrixDim; ++j) {
-      matrix[j + i * matrixDim] = RandFloat(0.0f, 10.0f);
-    }
-  }
-}
-
-#if VERIFY_GPU_CORRECTNESS
-void verifyMatrixMultiplyCorrectness(float *C, float *A, float *B,
-                                     unsigned int matrixDim) {
-  unsigned int i, j, k, numErrors = 0;
-  for (i = 0; i < matrixDim; ++i) {
-    for (j = 0; j < matrixDim; ++j) {
-      float result = 0.0f;
-      for (k = 0; k < matrixDim; ++k) {
-        result += A[k + i * matrixDim] * B[j + k * matrixDim];
-      }
-      if (fabs(C[j + i * matrixDim] - result) > 0.001 * matrixDim) {
-        printf("At [%u, %u]: Expected %f, Found %f\n", i, j, result,
-               C[j + i * matrixDim]);
-        ++numErrors;
-      }
-    }
-  }
-  if (numErrors != 0) {
-    printf("%d value mismatches occured\n", numErrors);
-    fflush(stdout);
-    exit(EXIT_FAILURE);  // exit since value mismatches occured
-  }
-}
-#endif
-
-void copyMatrix(float *dstMatrix, float *srcMatrix, unsigned int matrixDim) {
-  size_t size = matrixDim * matrixDim * sizeof(float);
-  memcpy(dstMatrix, srcMatrix, size);
-}
-
-void verifyMatrixData(float *expectedData, float *observedData,
-                      unsigned int matrixDim) {
-  unsigned int i, j, numErrors = 0;
-  for (i = 0; i < matrixDim; ++i) {
-    for (j = 0; j < matrixDim; ++j) {
-      if (expectedData[j + i * matrixDim] != observedData[j + i * matrixDim]) {
-        ++numErrors;
-        if (verboseResults) {
-          printf("At [%u, %u]: Expected %f, Found %f\n", i, j,
-                 expectedData[j + i * matrixDim],
-                 observedData[j + i * matrixDim]);
-        }
-      }
-    }
-  }
-  if (numErrors != 0) {
-    printf("%d value mismatches occured\n", numErrors);
-    fflush(stdout);
-    exit(EXIT_FAILURE);  // exit since value mismatches occured
-  }
-}
-
-#define BLOCK_SIZE 32
-__global__ void matrixMultiplyKernel(float *C, float *A, float *B,
-                                     unsigned int matrixDim) {
-  // Block index
-  int bx = blockIdx.x;
-  int by = blockIdx.y;
-
-  // Thread index
-  int tx = threadIdx.x;
-  int ty = threadIdx.y;
-
-  unsigned int wA = matrixDim;
-  unsigned int wB = matrixDim;
-
-  // Index of the first sub-matrix of A processed by the block
-  int aBegin = matrixDim * BLOCK_SIZE * by;
-
-  // Index of the last sub-matrix of A processed by the block
-  int aEnd = aBegin + wA - 1;
-
-  // Step size used to iterate through the sub-matrices of A
-  int aStep = BLOCK_SIZE;
-
-  // Index of the first sub-matrix of B processed by the block
-  int bBegin = BLOCK_SIZE * bx;
-
-  // Step size used to iterate through the sub-matrices of B
-  int bStep = BLOCK_SIZE * wB;
-
-  // Csub is used to store the element of the block sub-matrix
-  // that is computed by the thread
-  float Csub = 0;
-
-  // Loop over all the sub-matrices of A and B
-  // required to compute the block sub-matrix
-  for (int a = aBegin, b = bBegin; a <= aEnd; a += aStep, b += bStep) {
-    // Declaration of the shared memory array As used to
-    // store the sub-matrix of A
-    __shared__ float As[BLOCK_SIZE][BLOCK_SIZE];
-
-    // Declaration of the shared memory array Bs used to
-    // store the sub-matrix of B
-    __shared__ float Bs[BLOCK_SIZE][BLOCK_SIZE];
-
-    // Load the matrices from device memory
-    // to shared memory; each thread loads
-    // one element of each matrix
-    As[ty][tx] = A[a + wA * ty + tx];
-    Bs[ty][tx] = B[b + wB * ty + tx];
-
-    // Synchronize to make sure the matrices are loaded
-    __syncthreads();
-
-    // Multiply the two matrices together;
-    // each thread computes one element
-    // of the block sub-matrix
-#pragma unroll
-
-    for (int k = 0; k < BLOCK_SIZE; ++k) {
-      Csub += As[ty][k] * Bs[k][tx];
-    }
-
-    // Synchronize to make sure that the preceding
-    // computation is done before loading two new
-    // sub-matrices of A and B in the next iteration
-    __syncthreads();
-  }
-
-  // Write the block sub-matrix to device memory;
-  // each thread writes one element
-  int c = wB * BLOCK_SIZE * by + BLOCK_SIZE * bx;
-  C[c + wB * ty + tx] = Csub;
-}
-
-void runMatrixMultiplyKernel(unsigned int matrixDim, int allocType,
-                             unsigned int numLoops, double *gpuLaunchCallsTimes,
-                             double *gpuTransferToCallsTimes,
-                             double *gpuTransferFromCallsTimes,
-                             double *gpuLaunchAndTransferCallsTimes,
-                             double *gpuLaunchTransferSyncTimes,
-                             double *cpuAccessTimes, double *overallTimes,
-                             int device_id) {
-  float *dptrA = NULL, *hptrA = NULL;
-  float *dptrB = NULL, *hptrB = NULL;
-  float *dptrC = NULL, *hptrC = NULL;
-  float *randValuesX = NULL, *randValuesY = NULL;
-  float *randValuesVerifyXmulY = NULL, *randValuesVerifyYmulX = NULL;
-  bool copyRequired = false, hintsRequired = false;
-  bool someTransferOpRequired;
-  bool isAsync = false;
-  hipStream_t streamToRunOn;
-  unsigned int *latch;
-  size_t size = matrixDim * matrixDim * sizeof(float);
-  dim3 threads(32, 32);
-  dim3 grid(matrixDim / threads.x, matrixDim / threads.y);
-  StopWatchInterface *gpuLaunchCallsTimer = 0, *gpuTransferCallsTimer = 0;
-  StopWatchInterface *gpuSyncTimer = 0, *cpuAccessTimer = 0;
-  sdkCreateTimer(&gpuLaunchCallsTimer);
-  sdkCreateTimer(&gpuTransferCallsTimer);
-  sdkCreateTimer(&gpuSyncTimer);
-  sdkCreateTimer(&cpuAccessTimer);
-  unsigned int i;
-
-  hipDeviceProp_t deviceProp;
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, device_id));
-  HIPCHECK(hipStreamCreate(&streamToRunOn));
-
-  randValuesX = (float *)malloc(size);
-  if (!randValuesX) {
-    exit(EXIT_FAILURE);  // exit since memory allocation error
-  }
-  randValuesY = (float *)malloc(size);
-  if (!randValuesY) {
-    exit(EXIT_FAILURE);  // exit since memory allocation error
-  }
-  randValuesVerifyXmulY = (float *)malloc(size);
-  if (!randValuesVerifyXmulY) {
-    exit(EXIT_FAILURE);  // exit since memory allocation error
-  }
-  randValuesVerifyYmulX = (float *)malloc(size);
-  if (!randValuesVerifyYmulX) {
-    exit(EXIT_FAILURE);  // exit since memory allocation error
-  }
-  HIPCHECK(hipMalloc(&dptrA, size));
-  HIPCHECK(hipMalloc(&dptrB, size));
-  HIPCHECK(hipMalloc(&dptrC, size));
-
-  fillMatrixWithRandomValues(randValuesX, matrixDim);
-  fillMatrixWithRandomValues(randValuesY, matrixDim);
-
-  HIPCHECK(
-      hipMemcpyAsync(dptrA, randValuesX, size, hipMemcpyHostToDevice));
-  HIPCHECK(
-      hipMemcpyAsync(dptrB, randValuesY, size, hipMemcpyHostToDevice));
-  matrixMultiplyKernel<<<grid, threads>>>(dptrC, dptrA, dptrB, matrixDim);
-  HIPCHECK(hipMemcpyAsync(randValuesVerifyXmulY, dptrC, size,
-                                  hipMemcpyDeviceToHost));
-  HIPCHECK(hipStreamSynchronize(NULL));
-  matrixMultiplyKernel<<<grid, threads>>>(dptrC, dptrB, dptrA, matrixDim);
-  HIPCHECK(hipMemcpyAsync(randValuesVerifyYmulX, dptrC, size,
-                                  hipMemcpyDeviceToHost));
-  HIPCHECK(hipStreamSynchronize(NULL));
-#if VERIFY_GPU_CORRECTNESS
-  verifyMatrixMultiplyCorrectness(randValuesVerifyXmulY, randValuesX,
-                                  randValuesY, matrixDim);
-  verifyMatrixMultiplyCorrectness(randValuesVerifyYmulX, randValuesY,
-                                  randValuesX, matrixDim);
-#endif
-  HIPCHECK(hipFree(dptrA));
-  HIPCHECK(hipFree(dptrB));
-  HIPCHECK(hipFree(dptrC));
-
-  HIPCHECK(hipHostMalloc(&latch, sizeof(unsigned int)));
-
-  switch (allocType) {
-    case USE_HOST_PAGEABLE_AND_DEVICE_MEMORY:
-    case USE_HOST_PAGEABLE_AND_DEVICE_MEMORY_ASYNC:
-      hptrA = (float *)malloc(size);
-      if (!hptrA) {
-        exit(EXIT_FAILURE);  // exit since memory allocation error
-      }
-      hptrB = (float *)malloc(size);
-      if (!hptrB) {
-        exit(EXIT_FAILURE);  // exit since memory allocation error
-      }
-      hptrC = (float *)malloc(size);
-      if (!hptrC) {
-        exit(EXIT_FAILURE);  // exit since memory allocation error
-      }
-      HIPCHECK(hipMalloc(&dptrA, size));
-      HIPCHECK(hipMalloc(&dptrB, size));
-      HIPCHECK(hipMalloc(&dptrC, size));
-      copyRequired = true;
-      break;
-
-    case USE_HOST_PAGELOCKED_AND_DEVICE_MEMORY:
-    case USE_HOST_PAGELOCKED_AND_DEVICE_MEMORY_ASYNC:
-      HIPCHECK(hipHostMalloc(&hptrA, size));
-      HIPCHECK(hipHostMalloc(&hptrB, size));
-      HIPCHECK(hipHostMalloc(&hptrC, size));
-      HIPCHECK(hipMalloc(&dptrA, size));
-      HIPCHECK(hipMalloc(&dptrB, size));
-      HIPCHECK(hipMalloc(&dptrC, size));
-      copyRequired = true;
-      break;
-
-    case USE_ZERO_COPY:
-      HIPCHECK(hipHostMalloc(&hptrA, size));
-      HIPCHECK(hipHostMalloc(&hptrB, size));
-      HIPCHECK(hipHostMalloc(&hptrC, size));
-      HIPCHECK(hipHostGetDevicePointer((void **)&dptrA, hptrA, 0));
-      HIPCHECK(hipHostGetDevicePointer((void **)&dptrB, hptrB, 0));
-      HIPCHECK(hipHostGetDevicePointer((void **)&dptrC, hptrC, 0));
-      break;
-
-    case USE_MANAGED_MEMORY:
-      HIPCHECK(hipMallocManaged(&dptrA, size));
-      HIPCHECK(hipMallocManaged(&dptrB, size));
-      HIPCHECK(hipMallocManaged(&dptrC, size));
-      hptrA = dptrA;
-      hptrB = dptrB;
-      hptrC = dptrC;
-      break;
-
-    case USE_MANAGED_MEMORY_WITH_HINTS:
-    case USE_MANAGED_MEMORY_WITH_HINTS_ASYNC:
-      if (deviceProp.concurrentManagedAccess) {
-        HIPCHECK(hipMallocManaged(&dptrA, size));
-        HIPCHECK(hipMallocManaged(&dptrB, size));
-        HIPCHECK(hipMallocManaged(&dptrC, size));
-        HIPCHECK(hipMemPrefetchAsync(dptrA, size, hipCpuDeviceId));
-        HIPCHECK(hipMemPrefetchAsync(dptrB, size, hipCpuDeviceId));
-        HIPCHECK(hipMemPrefetchAsync(dptrC, size, hipCpuDeviceId));
-      } else {
-        HIPCHECK(hipMallocManaged(&dptrA, size, hipMemAttachHost));
-        HIPCHECK(hipMallocManaged(&dptrB, size, hipMemAttachHost));
-        HIPCHECK(hipMallocManaged(&dptrC, size, hipMemAttachHost));
-      }
-      hptrA = dptrA;
-      hptrB = dptrB;
-      hptrC = dptrC;
-      hintsRequired = true;
-      break;
-
-    default:
-      exit(EXIT_FAILURE);  // exit with error
-  }
-
-  if (allocType == USE_HOST_PAGEABLE_AND_DEVICE_MEMORY_ASYNC ||
-      allocType == USE_HOST_PAGELOCKED_AND_DEVICE_MEMORY_ASYNC ||
-      allocType == USE_MANAGED_MEMORY_WITH_HINTS_ASYNC) {
-    isAsync = true;
-  }
-
-  someTransferOpRequired = copyRequired || hintsRequired;
-
-  // fill buffers with 0 to avoid any first access page-fault overheads.
-  memset(hptrA, 0, size);
-  memset(hptrB, 0, size);
-  memset(hptrC, 0, size);
-
-  for (i = 0; i < numLoops; i++) {
-    cpuAccessTimes[i] = 0.0;
-    gpuLaunchCallsTimes[i] = 0.0;
-    gpuTransferToCallsTimes[i] = 0.0;
-    gpuTransferFromCallsTimes[i] = 0.0;
-
-    sdkStartTimer(&cpuAccessTimer);
-    {
-      copyMatrix(hptrA, (i & 0x1 == 0) ? randValuesX : randValuesY, matrixDim);
-      copyMatrix(hptrB, (i & 0x1 == 0) ? randValuesY : randValuesX, matrixDim);
-    }
-    sdkStopTimer(&cpuAccessTimer);
-    cpuAccessTimes[i] += sdkGetAverageTimerValue(&cpuAccessTimer);
-    sdkResetTimer(&cpuAccessTimer);
-
-    if (isAsync && hintsRequired) {
-      *latch = 0;
-      // Prevent any work on stream from starting until all work is pushed
-      spinWhileLessThanOne<<<1, 1, 0, streamToRunOn>>>(latch);
-    }
-
-    if (someTransferOpRequired) {
-      sdkStartTimer(&gpuTransferCallsTimer);
-      if (copyRequired) {
-        if (isAsync) {
-          HIPCHECK(hipMemcpyAsync(
-              dptrA, hptrA, size, hipMemcpyHostToDevice, streamToRunOn));
-          HIPCHECK(hipMemcpyAsync(
-              dptrB, hptrB, size, hipMemcpyHostToDevice, streamToRunOn));
-        } else {
-          HIPCHECK(
-              hipMemcpy(dptrA, hptrA, size, hipMemcpyHostToDevice));
-          HIPCHECK(
-              hipMemcpy(dptrB, hptrB, size, hipMemcpyHostToDevice));
-        }
-      }
-      if (hintsRequired) {
-        if (deviceProp.concurrentManagedAccess) {
-          HIPCHECK(
-              hipMemPrefetchAsync(dptrA, size, device_id, streamToRunOn));
-          HIPCHECK(
-              hipMemPrefetchAsync(dptrB, size, device_id, streamToRunOn));
-          HIPCHECK(
-              hipMemPrefetchAsync(dptrC, size, device_id, streamToRunOn));
-        } else {
-          HIPCHECK(hipStreamAttachMemAsync(streamToRunOn, dptrA, 0,
-                                                   hipMemAttachGlobal));
-          HIPCHECK(hipStreamAttachMemAsync(streamToRunOn, dptrB, 0,
-                                                   hipMemAttachGlobal));
-          HIPCHECK(hipStreamAttachMemAsync(streamToRunOn, dptrC, 0,
-                                                   hipMemAttachGlobal));
-        }
-        if (!isAsync) {
-          HIPCHECK(hipStreamSynchronize(streamToRunOn));
-        }
-      }
-
-      sdkStopTimer(&gpuTransferCallsTimer);
-      gpuTransferToCallsTimes[i] +=
-          sdkGetAverageTimerValue(&gpuTransferCallsTimer);
-      sdkResetTimer(&gpuTransferCallsTimer);
-    }
-
-    sdkStartTimer(&gpuLaunchCallsTimer);
-    {
-      matrixMultiplyKernel<<<grid, threads, 0, streamToRunOn>>>(
-          dptrC, dptrA, dptrB, matrixDim);
-      if (!isAsync) {
-        HIPCHECK(hipStreamSynchronize(streamToRunOn));
-      }
-    }
-    sdkStopTimer(&gpuLaunchCallsTimer);
-
-    gpuLaunchCallsTimes[i] += sdkGetAverageTimerValue(&gpuLaunchCallsTimer);
-    sdkResetTimer(&gpuLaunchCallsTimer);
-
-    if (someTransferOpRequired) {
-      sdkStartTimer(&gpuTransferCallsTimer);
-      if (hintsRequired) {
-        if (deviceProp.concurrentManagedAccess) {
-          HIPCHECK(hipMemPrefetchAsync(dptrA, size, hipCpuDeviceId));
-          HIPCHECK(hipMemPrefetchAsync(dptrB, size, hipCpuDeviceId));
-          HIPCHECK(hipMemPrefetchAsync(dptrC, size, hipCpuDeviceId));
-        } else {
-          HIPCHECK(hipStreamAttachMemAsync(streamToRunOn, dptrA, 0,
-                                                   hipMemAttachHost));
-          HIPCHECK(hipStreamAttachMemAsync(streamToRunOn, dptrB, 0,
-                                                   hipMemAttachHost));
-          HIPCHECK(hipStreamAttachMemAsync(streamToRunOn, dptrC, 0,
-                                                   hipMemAttachHost));
-        }
-        if (!isAsync) {
-          HIPCHECK(hipStreamSynchronize(streamToRunOn));
-        }
-      }
-      if (copyRequired) {
-        if (isAsync) {
-          HIPCHECK(hipMemcpyAsync(
-              hptrC, dptrC, size, hipMemcpyDeviceToHost, streamToRunOn));
-        } else {
-          HIPCHECK(
-              hipMemcpy(hptrC, dptrC, size, hipMemcpyDeviceToHost));
-        }
-      }
-      sdkStopTimer(&gpuTransferCallsTimer);
-      gpuTransferFromCallsTimes[i] +=
-          sdkGetAverageTimerValue(&gpuTransferCallsTimer);
-      sdkResetTimer(&gpuTransferCallsTimer);
-    }
-    gpuLaunchAndTransferCallsTimes[i] = gpuLaunchCallsTimes[i] +
-                                        gpuTransferToCallsTimes[i] +
-                                        gpuTransferFromCallsTimes[i];
-    gpuLaunchTransferSyncTimes[i] = gpuLaunchAndTransferCallsTimes[i];
-    if (isAsync) {
-      sdkStartTimer(&gpuSyncTimer);
-      {
-        if (hintsRequired) {
-          *latch = 1;
-        }
-        HIPCHECK(hipStreamSynchronize(streamToRunOn));
-      }
-      sdkStopTimer(&gpuSyncTimer);
-      gpuLaunchTransferSyncTimes[i] += sdkGetAverageTimerValue(&gpuSyncTimer);
-      sdkResetTimer(&gpuSyncTimer);
-    }
-
-    sdkStartTimer(&cpuAccessTimer);
-    {
-      verifyMatrixData(
-          (i & 0x1 == 0) ? randValuesVerifyXmulY : randValuesVerifyYmulX, hptrC,
-          matrixDim);
-    }
-    sdkStopTimer(&cpuAccessTimer);
-    cpuAccessTimes[i] += sdkGetAverageTimerValue(&cpuAccessTimer);
-    sdkResetTimer(&cpuAccessTimer);
-    overallTimes[i] = cpuAccessTimes[i] + gpuLaunchTransferSyncTimes[i];
-  }
-
-  switch (allocType) {
-    case USE_HOST_PAGEABLE_AND_DEVICE_MEMORY:
-    case USE_HOST_PAGEABLE_AND_DEVICE_MEMORY_ASYNC:
-      free(hptrA);
-      free(hptrB);
-      free(hptrC);
-      HIPCHECK(hipFree(dptrA));
-      HIPCHECK(hipFree(dptrB));
-      HIPCHECK(hipFree(dptrC));
-      break;
-
-    case USE_HOST_PAGELOCKED_AND_DEVICE_MEMORY:
-    case USE_HOST_PAGELOCKED_AND_DEVICE_MEMORY_ASYNC:
-      HIPCHECK(hipHostFree(hptrA));
-      HIPCHECK(hipHostFree(hptrB));
-      HIPCHECK(hipHostFree(hptrC));
-      HIPCHECK(hipFree(dptrA));
-      HIPCHECK(hipFree(dptrB));
-      HIPCHECK(hipFree(dptrC));
-      break;
-
-    case USE_ZERO_COPY:
-      HIPCHECK(hipHostFree(hptrA));
-      HIPCHECK(hipHostFree(hptrB));
-      HIPCHECK(hipHostFree(hptrC));
-      break;
-
-    case USE_MANAGED_MEMORY:
-    case USE_MANAGED_MEMORY_WITH_HINTS:
-    case USE_MANAGED_MEMORY_WITH_HINTS_ASYNC:
-      HIPCHECK(hipFree(dptrA));
-      HIPCHECK(hipFree(dptrB));
-      HIPCHECK(hipFree(dptrC));
-      break;
-
-    default:
-      exit(EXIT_FAILURE);  // exit due to error
-  }
-
-  HIPCHECK(hipStreamDestroy(streamToRunOn));
-  HIPCHECK(hipHostFree(latch));
-  free(randValuesX);
-  free(randValuesY);
-  free(randValuesVerifyXmulY);
-  free(randValuesVerifyYmulX);
-  sdkDeleteTimer(&gpuLaunchCallsTimer);
-  sdkDeleteTimer(&gpuTransferCallsTimer);
-  sdkDeleteTimer(&gpuSyncTimer);
-  sdkDeleteTimer(&cpuAccessTimer);
-}
-
-void matrixMultiplyPerfRunner(bool reportAsBandwidth,
-                              bool print_launch_transfer_results,
-                              bool print_std_deviation, int device_id) {
-  int i;
-  unsigned int minMatrixDim = 32;
-  unsigned int multiplierDim = 2;
-  unsigned int matrixDim;
-  unsigned int minSize = minMatrixDim * minMatrixDim * sizeof(float);
-  unsigned int maxSize =
-      (maxSampleSizeInMb * ONE_MB) /
-      4;  // 3 buffers are used, but dividing by 4 (power of 2)
-  unsigned int multiplier = multiplierDim * multiplierDim;
-  unsigned int numSizesToTest;
-
-  struct testResults *results;
-  struct resultsData *gpuLaunchCallsTimes;
-  struct resultsData *gpuTransferToCallsTimes;
-  struct resultsData *gpuTransferFromCallsTimes;
-  struct resultsData *gpuLaunchAndTransferCallsTimes;
-  struct resultsData *gpuLaunchTransferSyncTimes;
-  struct resultsData *cpuAccessTimes;
-  struct resultsData *overallTimes;
-  unsigned long *sizesToTest;
-  unsigned int j;
-
-  numSizesToTest = findNumSizesToTest(minSize, maxSize, multiplier);
-
-  createAndInitTestResults(&results, "matrixMultiplyPerf", numKernelRuns,
-                           numSizesToTest);
-
-  sizesToTest = getPtrSizesToTest(results);
-
-  createResultDataAndAddToTestResults(&gpuLaunchCallsTimes, results,
-                                      "GPU Kernel Launch Call Time", false,
-                                      reportAsBandwidth);
-  createResultDataAndAddToTestResults(&gpuTransferToCallsTimes, results,
-                                      "CPU to GPU Transfer Calls Time", false,
-                                      reportAsBandwidth);
-  createResultDataAndAddToTestResults(&gpuTransferFromCallsTimes, results,
-                                      "GPU to CPU Transfer Calls Time", false,
-                                      reportAsBandwidth);
-  createResultDataAndAddToTestResults(&gpuLaunchAndTransferCallsTimes, results,
-                                      "GPU Launch and Transfer Calls Time",
-                                      false, reportAsBandwidth);
-  createResultDataAndAddToTestResults(&gpuLaunchTransferSyncTimes, results,
-                                      "GPU Launch Transfer and Sync Time",
-                                      false, reportAsBandwidth);
-  createResultDataAndAddToTestResults(
-      &cpuAccessTimes, results, "CPU Access Time", false, reportAsBandwidth);
-  createResultDataAndAddToTestResults(&overallTimes, results, "Overall Time",
-                                      false, reportAsBandwidth);
-
-  printf("Running ");
-  for (matrixDim = minMatrixDim, j = 0;
-       matrixDim * matrixDim <= maxSize / sizeof(float);
-       matrixDim *= multiplierDim, ++j) {
-    sizesToTest[j] = matrixDim * matrixDim * sizeof(float);
-    for (i = MEMALLOC_TYPE_START; i <= MEMALLOC_TYPE_END; i++) {
-      printf(".");
-      fflush(stdout);
-      runMatrixMultiplyKernel(
-          matrixDim, i, numKernelRuns,
-          getPtrRunTimesInMs(gpuLaunchCallsTimes, i, j),
-          getPtrRunTimesInMs(gpuTransferToCallsTimes, i, j),
-          getPtrRunTimesInMs(gpuTransferFromCallsTimes, i, j),
-          getPtrRunTimesInMs(gpuLaunchAndTransferCallsTimes, i, j),
-          getPtrRunTimesInMs(gpuLaunchTransferSyncTimes, i, j),
-          getPtrRunTimesInMs(cpuAccessTimes, i, j),
-          getPtrRunTimesInMs(overallTimes, i, j), device_id);
-    }
-  }
-  printf("\n");
-  printResults(results, print_launch_transfer_results, print_std_deviation);
-  freeTestResultsAndAllResultsData(results);
-}
-
-static void usage() {
-  printf(
-      "./cudaMemoryTypesPerf [-device=<device_id>] [-reportAsBandwidth] "
-      "[-print-launch-transfer-results] [-print-std-deviation] [-verbose]\n");
-  printf("Options:\n");
-  printf(
-      "-reportAsBandwidth:             By default time taken is printed, this "
-      "option allows to instead print bandwidth.\n");
-  printf(
-      "-print-launch-transfer-results: By default overall results are printed, "
-      "this option allows to print data transfers and kernel time as well.\n");
-  printf(
-      "-print-std-deviation:           Prints std deviation of the results.\n");
-  printf(
-      "-kernel-iterations=<num>:       Number of times the kernel tests should "
-      "be run[default is 100 iterations].\n");
-  printf(
-      "-device=<device_id>:            Allows to pass GPU Device ID on which "
-      "the tests will be run.\n");
-  printf("-verbose:                       Prints highly verbose output.\n");
-}
-
-int main(int argc, char **argv) {
-  bool reportAsBandwidth = false;
-  bool print_launch_transfer_results = false;
-  bool print_std_deviation = false;
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "help") ||
-      checkCmdLineFlag(argc, (const char **)argv, "h")) {
-    usage();
-    printf("&&&& %s WAIVED\n", argv[0]);
-    exit(EXIT_WAIVED);
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "reportAsBandwidth")) {
-    reportAsBandwidth = true;
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv,
-                       "print-launch-transfer-results")) {
-    print_launch_transfer_results = true;
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "print-std-deviation")) {
-    print_std_deviation = true;
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "kernel-iterations")) {
-    numKernelRuns =
-        getCmdLineArgumentInt(argc, (const char **)argv, "kernel-iterations");
-  }
-
-  if (checkCmdLineFlag(argc, (const char **)argv, "verbose")) {
-    verboseResults = 1;
-  }
-
-  int device_id = findCudaDevice(argc, (const char **)argv);
-
-  matrixMultiplyPerfRunner(reportAsBandwidth, print_launch_transfer_results,
-                           print_std_deviation, device_id);
-
-  printf(
-      "\nNOTE: The CUDA Samples are not meant for performance measurements. "
-      "Results may vary when GPU Boost is enabled.\n");
-  exit(EXIT_SUCCESS);
-}
-
diff --git a/src/samples/Samples/6_Performance/alignedTypes/.vscode/c_cpp_properties.json b/src/samples/Samples/6_Performance/alignedTypes/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/alignedTypes/.vscode/extensions.json b/src/samples/Samples/6_Performance/alignedTypes/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/alignedTypes/.vscode/launch.json b/src/samples/Samples/6_Performance/alignedTypes/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/alignedTypes/.vscode/tasks.json b/src/samples/Samples/6_Performance/alignedTypes/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/alignedTypes/Makefile b/src/samples/Samples/6_Performance/alignedTypes/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/alignedTypes/NsightEclipse.xml b/src/samples/Samples/6_Performance/alignedTypes/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/alignedTypes/README.md b/src/samples/Samples/6_Performance/alignedTypes/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.cu b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.cu.hip b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.cu.hip
old mode 100644
new mode 100755
index f1a0ef8..7396d2e
--- a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.cu.hip
+++ b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.cu.hip
@@ -1,4 +1,4 @@
-#include "hip/hip_runtime.h"
+
 /* Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -38,15 +38,17 @@
 // includes, system
 #include <math.h>
 #include <stdio.h>
-#include "rocprofiler.h"
-#include "HIPCHECK.h"
 #include <stdlib.h>
 #include <string.h>
 
 // includes, project
 #include "helper_cuda_hipified.h"  // helper functions for CUDA error checking and initialization
 #include "helper_functions.h"  // helper utility functions
-
+#include "hip/hip_runtime.h"
+#include "HIPCHECK.h"
+#include "hip/hip_runtime_api.h"
+#include <hip/hip_cooperative_groups.h>
+#include <hip/nvidia_detail/nvidia_hip_runtime_api.h>
 ////////////////////////////////////////////////////////////////////////////////
 // Misaligned types
 ////////////////////////////////////////////////////////////////////////////////
@@ -182,9 +184,9 @@ int runTest(int packedElementSize, int memory_size) {
   const int numElements = iDivDown(memory_size, sizeof(TData));
 
   // Clean output buffer before current test
-  HIPCHECK(hipMemset(d_odata, 0, memory_size));
+  checkCudaErrors(hipMemset(d_odata, 0, memory_size));
   // Run test
-  HIPCHECK(hipDeviceSynchronize());
+  checkCudaErrors(hipDeviceSynchronize());
   sdkResetTimer(&hTimer);
   sdkStartTimer(&hTimer);
 
@@ -194,14 +196,14 @@ int runTest(int packedElementSize, int memory_size) {
     getLastCudaError("testKernel() execution failed\n");
   }
 
-  HIPCHECK(hipDeviceSynchronize());
+  checkCudaErrors(hipDeviceSynchronize());
   sdkStopTimer(&hTimer);
   double gpuTime = sdkGetTimerValue(&hTimer) / NUM_ITERATIONS;
   printf("Avg. time: %f ms / Copy throughput: %f GB/s.\n", gpuTime,
          (double)totalMemSizeAligned / (gpuTime * 0.001 * 1073741824.0));
 
   // Read back GPU results and run validation
-  HIPCHECK(
+  checkCudaErrors(
       hipMemcpy(h_odataGPU, d_odata, memory_size, hipMemcpyDeviceToHost));
   int flag = testCPU((TData *)h_odataGPU, (TData *)h_idataCPU, numElements,
                      packedElementSize);
@@ -222,7 +224,7 @@ int main(int argc, char **argv) {
   devID = findCudaDevice(argc, (const char **)argv);
 
   // get number of SMs on this GPU
-  HIPCHECK(hipGetDeviceProperties(&deviceProp, devID));
+  checkCudaErrors(hipGetDeviceProperties(&deviceProp, devID));
   printf("[%s] has %d MP(s) x %d (Cores/MP) = %d (Cores)\n", deviceProp.name,
          deviceProp.multiProcessorCount,
          _ConvertSMVer2Cores(deviceProp.major, deviceProp.minor),
@@ -246,8 +248,8 @@ int main(int argc, char **argv) {
   printf("Allocating memory...\n");
   h_idataCPU = (unsigned char *)malloc(MemorySize);
   h_odataGPU = (unsigned char *)malloc(MemorySize);
-  HIPCHECK(hipMalloc((void **)&d_idata, MemorySize));
-  HIPCHECK(hipMalloc((void **)&d_odata, MemorySize));
+  checkCudaErrors(hipMalloc((void **)&d_idata, MemorySize));
+  checkCudaErrors(hipMalloc((void **)&d_odata, MemorySize));
 
   printf("Generating host input data array...\n");
 
@@ -256,7 +258,7 @@ int main(int argc, char **argv) {
   }
 
   printf("Uploading input data to GPU memory...\n");
-  HIPCHECK(
+  checkCudaErrors(
       hipMemcpy(d_idata, h_idataCPU, MemorySize, hipMemcpyHostToDevice));
 
   printf("Testing misaligned types...\n");
@@ -300,8 +302,8 @@ int main(int argc, char **argv) {
   printf("\n[alignedTypes] -> Test Results: %d Failures\n", nTotalFailures);
 
   printf("Shutting down...\n");
-  HIPCHECK(hipFree(d_idata));
-  HIPCHECK(hipFree(d_odata));
+  checkCudaErrors(hipFree(d_idata));
+  checkCudaErrors(hipFree(d_odata));
   free(h_odataGPU);
   free(h_idataCPU);
 
diff --git a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.out b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2017.sln b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2017.vcxproj b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2019.sln b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2019.vcxproj b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2022.sln b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2022.vcxproj b/src/samples/Samples/6_Performance/alignedTypes/alignedTypes_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/alignedTypes/doc/alignedTypes.txt b/src/samples/Samples/6_Performance/alignedTypes/doc/alignedTypes.txt
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/.vscode/c_cpp_properties.json b/src/samples/Samples/6_Performance/transpose/.vscode/c_cpp_properties.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/.vscode/extensions.json b/src/samples/Samples/6_Performance/transpose/.vscode/extensions.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/.vscode/launch.json b/src/samples/Samples/6_Performance/transpose/.vscode/launch.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/.vscode/tasks.json b/src/samples/Samples/6_Performance/transpose/.vscode/tasks.json
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/Makefile b/src/samples/Samples/6_Performance/transpose/Makefile
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/NsightEclipse.xml b/src/samples/Samples/6_Performance/transpose/NsightEclipse.xml
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/README.md b/src/samples/Samples/6_Performance/transpose/README.md
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/doc/MatrixTranspose.docx b/src/samples/Samples/6_Performance/transpose/doc/MatrixTranspose.docx
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/doc/MatrixTranspose.pdf b/src/samples/Samples/6_Performance/transpose/doc/MatrixTranspose.pdf
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/transpose.cu b/src/samples/Samples/6_Performance/transpose/transpose.cu
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/transpose.cu.hip b/src/samples/Samples/6_Performance/transpose/transpose.cu.hip
old mode 100644
new mode 100755
index 578089c..17d876e
--- a/src/samples/Samples/6_Performance/transpose/transpose.cu.hip
+++ b/src/samples/Samples/6_Performance/transpose/transpose.cu.hip
@@ -40,13 +40,13 @@
 // -----------------------------------------------------------------------------
 
 #include <hip/hip_cooperative_groups.h>
-#include "HIPCHECK.h"
+
 namespace cg = cooperative_groups;
 // Utilities and system includes
 #include <helper_string.h>    // helper for string parsing
 #include <helper_image.h>     // helper for image and data comparison
 #include "helper_cuda_hipified.h"      // helper for cuda error checking functions
-
+#include "HIPCHECK.h"
 const char *sSDKsample = "Transpose";
 
 // Each block transposes/copies a tile of TILE_DIM x TILE_DIM elements
diff --git a/src/samples/Samples/6_Performance/transpose/transpose.out b/src/samples/Samples/6_Performance/transpose/transpose.out
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/transpose_vs2017.sln b/src/samples/Samples/6_Performance/transpose/transpose_vs2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/transpose_vs2017.vcxproj b/src/samples/Samples/6_Performance/transpose/transpose_vs2017.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/transpose_vs2019.sln b/src/samples/Samples/6_Performance/transpose/transpose_vs2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/transpose_vs2019.vcxproj b/src/samples/Samples/6_Performance/transpose/transpose_vs2019.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/transpose_vs2022.sln b/src/samples/Samples/6_Performance/transpose/transpose_vs2022.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples/6_Performance/transpose/transpose_vs2022.vcxproj b/src/samples/Samples/6_Performance/transpose/transpose_vs2022.vcxproj
old mode 100644
new mode 100755
diff --git a/src/samples/Samples_VS2017.sln b/src/samples/Samples_VS2017.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples_VS2019.sln b/src/samples/Samples_VS2019.sln
old mode 100644
new mode 100755
diff --git a/src/samples/Samples_VS2022.sln b/src/samples/Samples_VS2022.sln
old mode 100644
new mode 100755
